{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heated-peace",
   "metadata": {},
   "source": [
    "# Model with PD Dataset\n",
    "The aim of this notebook is to test the model defined previously on the PD Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-point",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "short-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utils librairies ---\n",
    "#Generics librairies\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "from os import path\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Measure librairies\n",
    "import time\n",
    "\n",
    "#Dataset librairies\n",
    "import pandas as pd\n",
    "\n",
    "# --- DL librairies ---\n",
    "#Pytorch librairies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Sklearn librairies\n",
    "from sklearn.model_selection import LeaveOneGroupOut, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Personal scripts ---\n",
    "sys.path.insert(1, '../scripts/')\n",
    "from data_manager.Datasets import Datasets\n",
    "from data_manager.RamanDataset import RamanDataset\n",
    "from data_manager.data_script import setsCreation\n",
    "from model_manager.ConvNet import ConvNet\n",
    "from model_manager.model_script import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-chicago",
   "metadata": {},
   "source": [
    "## GPU environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capable-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3,4\";\n",
    "gpus_list = [0, 1, 2, 3]\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-coordinate",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-destruction",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vertical-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, labels, names = pd.read_pickle(\"../data/dataset_PD_AD_RAW.pkl\")\n",
    "df = pd.DataFrame(df)\n",
    "labels = pd.Series(labels, name = 'label')\n",
    "names = pd.Series(names, name = 'names')\n",
    "df = pd.concat((df, labels, names), axis = 1)\n",
    "df = df[df.label != 1]\n",
    "df['label'] = df['label'].replace(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "broad-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set = df.drop(columns = ['label', \"names\"]).values\n",
    "Y_set = df.label.values\n",
    "groups = df.names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indie-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(LeaveOneGroupOut().split(X_set, Y_set, groups = groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-senator",
   "metadata": {},
   "source": [
    "### Create sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "light-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset, test_dataset = setsCreation(\"../train_settings/training_settings_pd_raw.pckl\", X_set, Y_set, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-catholic",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-grill",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "similar-accident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Let's train model 1 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9134990496245523; train accuracy : 0.6039964309195078; \n",
      " validation loss : 0.8452312052742578; validation accuracy : 0.7089552238805971\n",
      "Epoch 2:\t train loss : 0.7988845744461741; train accuracy : 0.7449203218433987; \n",
      " validation loss : 0.8048819899580921; validation accuracy : 0.7313432835820896\n",
      "Epoch 3:\t train loss : 0.7367257585951134; train accuracy : 0.8105882721267337; \n",
      " validation loss : 0.7457585649657005; validation accuracy : 0.7985074626865671\n",
      "Epoch 4:\t train loss : 0.6980118426100409; train accuracy : 0.8521375348298426; \n",
      " validation loss : 0.7205338737474324; validation accuracy : 0.8208955223880597\n",
      "Epoch 5:\t train loss : 0.6667140758810953; train accuracy : 0.8846075576844807; \n",
      " validation loss : 0.6721481066667528; validation accuracy : 0.8731343283582089\n",
      "Epoch 6:\t train loss : 0.6466687913382366; train accuracy : 0.9041944522713754; \n",
      " validation loss : 0.6922419239120442; validation accuracy : 0.8656716417910447\n",
      "Epoch 7:\t train loss : 0.6326359178395218; train accuracy : 0.9180246391784853; \n",
      " validation loss : 0.7330175814701113; validation accuracy : 0.8283582089552238\n",
      "Epoch 8:\t train loss : 0.632761172982299; train accuracy : 0.9183024952255722; \n",
      " validation loss : 0.6928708450594494; validation accuracy : 0.8582089552238806\n",
      "Epoch 9:\t train loss : 0.6110305482761498; train accuracy : 0.9403000845308538; \n",
      " validation loss : 0.7068223727864248; validation accuracy : 0.8507462686567164\n",
      "Epoch 10:\t train loss : 0.5977542150456666; train accuracy : 0.9542437619360696; \n",
      " validation loss : 0.6985786321572562; validation accuracy : 0.8432835820895522\n",
      "Epoch 11:\t train loss : 0.5904061362002269; train accuracy : 0.9616128173820482; \n",
      " validation loss : 0.6869588076931767; validation accuracy : 0.8656716417910447\n",
      "Epoch 12:\t train loss : 0.5886356741493358; train accuracy : 0.9631468958392035; \n",
      " validation loss : 0.6635596795135663; validation accuracy : 0.8880597014925373\n",
      "Epoch 13:\t train loss : 0.6105134129978915; train accuracy : 0.9401044112582574; \n",
      " validation loss : 0.720489087920651; validation accuracy : 0.8283582089552238\n",
      "Epoch 14:\t train loss : 0.5871872989554852; train accuracy : 0.9646848877618108; \n",
      " validation loss : 0.6755590497393072; validation accuracy : 0.8731343283582089\n",
      "Epoch 15:\t train loss : 0.5850798086499934; train accuracy : 0.9656162925393694; \n",
      " validation loss : 0.6598746750385783; validation accuracy : 0.8805970149253731\n",
      "Epoch 16:\t train loss : 0.5744284938166049; train accuracy : 0.9775601890986506; \n",
      " validation loss : 0.6310170778554339; validation accuracy : 0.9029850746268657\n",
      "Epoch 17:\t train loss : 0.5743440029507385; train accuracy : 0.9771766694843618; \n",
      " validation loss : 0.6835212593745371; validation accuracy : 0.8656716417910447\n",
      "Epoch 18:\t train loss : 0.5766319800731813; train accuracy : 0.9747581478350709; \n",
      " validation loss : 0.6437812644725083; validation accuracy : 0.9029850746268657\n",
      "Epoch 19:\t train loss : 0.5716897234026098; train accuracy : 0.9797791240098932; \n",
      " validation loss : 0.6997853054888655; validation accuracy : 0.8507462686567164\n",
      "Epoch 20:\t train loss : 0.6836664428235546; train accuracy : 0.8647702013086629; \n",
      " validation loss : 0.6718677168986553; validation accuracy : 0.8805970149253731\n",
      "Epoch 21:\t train loss : 0.6153116676324923; train accuracy : 0.9345198960583576; \n",
      " validation loss : 0.7363487354408463; validation accuracy : 0.8059701492537313\n",
      "Epoch 22:\t train loss : 0.6111269772078383; train accuracy : 0.9399674399674399; \n",
      " validation loss : 0.7034744643473471; validation accuracy : 0.8507462686567164\n",
      "Epoch 23:\t train loss : 0.5892130451689599; train accuracy : 0.9622428853198084; \n",
      " validation loss : 0.7157342332761141; validation accuracy : 0.8283582089552238\n",
      "Epoch 24:\t train loss : 0.5810973537681748; train accuracy : 0.9707077110923265; \n",
      " validation loss : 0.7117767880281157; validation accuracy : 0.835820895522388\n",
      "Epoch 25:\t train loss : 0.5691073672449891; train accuracy : 0.9828159732005886; \n",
      " validation loss : 0.6471495115860106; validation accuracy : 0.9029850746268657\n",
      "Epoch 26:\t train loss : 0.5706252063186821; train accuracy : 0.9809805579036348; \n",
      " validation loss : 0.631419518860243; validation accuracy : 0.917910447761194\n",
      "Epoch 27:\t train loss : 0.5667307117014249; train accuracy : 0.9848705425628502; \n",
      " validation loss : 0.661878319606798; validation accuracy : 0.8880597014925373\n",
      "Epoch 28:\t train loss : 0.5648195289341326; train accuracy : 0.986760746376131; \n",
      " validation loss : 0.6470036084226439; validation accuracy : 0.9029850746268657\n",
      "Epoch 29:\t train loss : 0.5657232259114305; train accuracy : 0.9860484956638803; \n",
      " validation loss : 0.6323399193473305; validation accuracy : 0.917910447761194\n",
      "Epoch 30:\t train loss : 0.5679258492094728; train accuracy : 0.9839430512507436; \n",
      " validation loss : 0.6347003969278391; validation accuracy : 0.9104477611940298\n",
      "Epoch 31:\t train loss : 0.5632762731992997; train accuracy : 0.9884591903822673; \n",
      " validation loss : 0.6656182872161752; validation accuracy : 0.8805970149253731\n",
      "Epoch 32:\t train loss : 0.6176915973277086; train accuracy : 0.9322931342162112; \n",
      " validation loss : 0.6739001027377153; validation accuracy : 0.8731343283582089\n",
      "Epoch 33:\t train loss : 0.5726728138963257; train accuracy : 0.978397670705363; \n",
      " validation loss : 0.6471920241343571; validation accuracy : 0.8955223880597015\n",
      "Epoch 34:\t train loss : 0.5634136080683336; train accuracy : 0.9879113052189975; \n",
      " validation loss : 0.6310038736666618; validation accuracy : 0.9253731343283582\n",
      "Epoch 35:\t train loss : 0.5656219402509179; train accuracy : 0.9857393318931781; \n",
      " validation loss : 0.7079718488272215; validation accuracy : 0.835820895522388\n",
      "Epoch 36:\t train loss : 0.6023182085527892; train accuracy : 0.948381390689083; \n",
      " validation loss : 0.7196330683881058; validation accuracy : 0.8283582089552238\n",
      "Epoch 37:\t train loss : 0.5722497788035064; train accuracy : 0.9789299020068251; \n",
      " validation loss : 0.6881942913671201; validation accuracy : 0.8656716417910447\n",
      "Epoch 38:\t train loss : 0.5628483983941142; train accuracy : 0.9889835947528255; \n",
      " validation loss : 0.6706092880760074; validation accuracy : 0.8805970149253731\n",
      "Epoch 39:\t train loss : 0.5640140697237733; train accuracy : 0.9872538430230738; \n",
      " validation loss : 0.634818298480669; validation accuracy : 0.917910447761194\n",
      "Epoch 40:\t train loss : 0.5611491078153948; train accuracy : 0.9904354904354904; \n",
      " validation loss : 0.6734951303483939; validation accuracy : 0.8805970149253731\n",
      "Epoch 41:\t train loss : 0.5599227573130429; train accuracy : 0.9914451645220876; \n",
      " validation loss : 0.6541831709150595; validation accuracy : 0.9029850746268657\n",
      "Epoch 42:\t train loss : 0.5592824092213238; train accuracy : 0.9921065401834632; \n",
      " validation loss : 0.6681524999183787; validation accuracy : 0.8805970149253731\n",
      "Epoch 43:\t train loss : 0.5609044417651243; train accuracy : 0.9905724617263079; \n",
      " validation loss : 0.6557964269747532; validation accuracy : 0.8955223880597015\n",
      "Epoch 44:\t train loss : 0.5629717559624832; train accuracy : 0.9884904981058827; \n",
      " validation loss : 0.6586578934807518; validation accuracy : 0.8880597014925373\n",
      "Epoch 45:\t train loss : 0.5611852378431668; train accuracy : 0.9902398171628941; \n",
      " validation loss : 0.6414300116568986; validation accuracy : 0.9104477611940298\n",
      "Epoch 46:\t train loss : 0.5569442069768958; train accuracy : 0.9945994176763407; \n",
      " validation loss : 0.6212939236220547; validation accuracy : 0.9328358208955224\n",
      "Epoch 47:\t train loss : 0.5594918705871288; train accuracy : 0.9917778090855014; \n",
      " validation loss : 0.6484614020606607; validation accuracy : 0.9029850746268657\n",
      "Epoch 48:\t train loss : 0.5579750422622705; train accuracy : 0.9935310416079647; \n",
      " validation loss : 0.6236700419749989; validation accuracy : 0.9328358208955224\n",
      "Epoch 49:\t train loss : 0.55950513598482; train accuracy : 0.9916408377946839; \n",
      " validation loss : 0.6188967978969899; validation accuracy : 0.9328358208955224\n",
      "Epoch 50:\t train loss : 0.5618688849982452; train accuracy : 0.9895001721924799; \n",
      " validation loss : 0.6352588498018522; validation accuracy : 0.917910447761194\n",
      "Epoch 51:\t train loss : 0.5822097208023724; train accuracy : 0.9687353245045552; \n",
      " validation loss : 0.6680173562873573; validation accuracy : 0.8880597014925373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:\t train loss : 0.5839856182965703; train accuracy : 0.9668451206912745; \n",
      " validation loss : 0.6333956131144967; validation accuracy : 0.9104477611940298\n",
      "Epoch 53:\t train loss : 0.5644104661900491; train accuracy : 0.9870072946996024; \n",
      " validation loss : 0.6120421848675859; validation accuracy : 0.9402985074626866\n",
      "Epoch 54:\t train loss : 0.5620617166184618; train accuracy : 0.9894492971416048; \n",
      " validation loss : 0.6360054513389658; validation accuracy : 0.917910447761194\n",
      "Epoch 55:\t train loss : 0.5597066932777806; train accuracy : 0.9917230205691744; \n",
      " validation loss : 0.6169705193175149; validation accuracy : 0.9328358208955224\n",
      "Epoch 56:\t train loss : 0.5584868029254976; train accuracy : 0.992979242979243; \n",
      " validation loss : 0.6738814023490343; validation accuracy : 0.8731343283582089\n",
      "Epoch 57:\t train loss : 0.6171246139052341; train accuracy : 0.9328801540340002; \n",
      " validation loss : 0.6827964322618134; validation accuracy : 0.8656716417910447\n",
      "Epoch 58:\t train loss : 0.5766144365964713; train accuracy : 0.9747268401114555; \n",
      " validation loss : 0.6792274857119011; validation accuracy : 0.8731343283582089\n",
      "Epoch 59:\t train loss : 0.5662049401555046; train accuracy : 0.9848196675119752; \n",
      " validation loss : 0.6661585626358092; validation accuracy : 0.8805970149253731\n",
      "Epoch 60:\t train loss : 0.5647195502028469; train accuracy : 0.9866276885507654; \n",
      " validation loss : 0.661379311524373; validation accuracy : 0.8880597014925373\n",
      "Epoch 61:\t train loss : 0.5604430111414217; train accuracy : 0.9909833755987602; \n",
      " validation loss : 0.6621052222145922; validation accuracy : 0.8880597014925373\n",
      "Epoch 62:\t train loss : 0.5605823944314542; train accuracy : 0.9906781252935098; \n",
      " validation loss : 0.6839992474102283; validation accuracy : 0.8656716417910447\n",
      "Epoch 63:\t train loss : 0.5619916969878913; train accuracy : 0.9892575373344604; \n",
      " validation loss : 0.6420039936051372; validation accuracy : 0.9104477611940298\n",
      "Epoch 64:\t train loss : 0.563112988165414; train accuracy : 0.9881617670079208; \n",
      " validation loss : 0.6393399045323737; validation accuracy : 0.9104477611940298\n",
      "Epoch 65:\t train loss : 0.562352496556092; train accuracy : 0.9889718543564697; \n",
      " validation loss : 0.6276354615848312; validation accuracy : 0.9253731343283582\n",
      "Epoch 66:\t train loss : 0.5577740086524969; train accuracy : 0.9938323784477631; \n",
      " validation loss : 0.6331078545564499; validation accuracy : 0.917910447761194\n",
      "Epoch 67:\t train loss : 0.5636420414778345; train accuracy : 0.9876921511536896; \n",
      " validation loss : 0.6040930168777537; validation accuracy : 0.9477611940298507\n",
      "Epoch 68:\t train loss : 0.5623422247214465; train accuracy : 0.988956200494662; \n",
      " validation loss : 0.6456934688013627; validation accuracy : 0.9029850746268657\n",
      "Epoch 69:\t train loss : 0.5592500118243275; train accuracy : 0.9922082902852134; \n",
      " validation loss : 0.6259379433818586; validation accuracy : 0.9253731343283582\n",
      "Epoch 70:\t train loss : 0.5574508914175904; train accuracy : 0.9941063210293979; \n",
      " validation loss : 0.6385936902118753; validation accuracy : 0.9104477611940298\n",
      "Epoch 71:\t train loss : 0.5584854571395843; train accuracy : 0.9928931467393006; \n",
      " validation loss : 0.6226656874905968; validation accuracy : 0.9328358208955224\n",
      "Epoch 72:\t train loss : 0.5617447159585762; train accuracy : 0.9896371434832973; \n",
      " validation loss : 0.64618000806197; validation accuracy : 0.9029850746268657\n",
      "Epoch 73:\t train loss : 0.5595347303852247; train accuracy : 0.991750414827338; \n",
      " validation loss : 0.6464779917485926; validation accuracy : 0.8955223880597015\n",
      "Epoch 74:\t train loss : 0.5571549178186913; train accuracy : 0.9942706865783789; \n",
      " validation loss : 0.6201829970693915; validation accuracy : 0.9328358208955224\n",
      "Epoch 75:\t train loss : 0.557330600409679; train accuracy : 0.9937658495350803; \n",
      " validation loss : 0.6820935330461512; validation accuracy : 0.8656716417910447\n",
      "Epoch 76:\t train loss : 0.6230756784419897; train accuracy : 0.9271195328887637; \n",
      " validation loss : 0.7229524519790331; validation accuracy : 0.8283582089552238\n",
      "Epoch 77:\t train loss : 0.5703706310201021; train accuracy : 0.9806557402711249; \n",
      " validation loss : 0.5961726357174408; validation accuracy : 0.9552238805970149\n",
      "Epoch 78:\t train loss : 0.5597907130301938; train accuracy : 0.9916682320528474; \n",
      " validation loss : 0.6300689580420595; validation accuracy : 0.917910447761194\n",
      "Epoch 79:\t train loss : 0.5587983569734889; train accuracy : 0.9925448483140791; \n",
      " validation loss : 0.6390508310290214; validation accuracy : 0.9104477611940298\n",
      "Epoch 80:\t train loss : 0.5566078607835995; train accuracy : 0.9949281487743026; \n",
      " validation loss : 0.6289002208988008; validation accuracy : 0.9253731343283582\n",
      "Epoch 81:\t train loss : 0.5591565358144204; train accuracy : 0.9922630788015403; \n",
      " validation loss : 0.6561069846145186; validation accuracy : 0.8955223880597015\n",
      "Epoch 82:\t train loss : 0.5588422871446465; train accuracy : 0.9924274443505212; \n",
      " validation loss : 0.63180286668706; validation accuracy : 0.917910447761194\n",
      "Epoch 83:\t train loss : 0.5798556367210732; train accuracy : 0.9711734134811058; \n",
      " validation loss : 0.7156923063285339; validation accuracy : 0.835820895522388\n",
      "Epoch 84:\t train loss : 0.5638870225893281; train accuracy : 0.9875590933283241; \n",
      " validation loss : 0.6459703657713068; validation accuracy : 0.9029850746268657\n",
      "Epoch 85:\t train loss : 0.5600262517476583; train accuracy : 0.9913121066967221; \n",
      " validation loss : 0.690692844735039; validation accuracy : 0.8582089552238806\n",
      "Epoch 86:\t train loss : 0.5590386914287485; train accuracy : 0.9923256942487712; \n",
      " validation loss : 0.6351911669212049; validation accuracy : 0.917910447761194\n",
      "Epoch 87:\t train loss : 0.5589187438398862; train accuracy : 0.9924352712814252; \n",
      " validation loss : 0.625154489475381; validation accuracy : 0.9253731343283582\n",
      "Epoch 88:\t train loss : 0.561309268789057; train accuracy : 0.990188942112019; \n",
      " validation loss : 0.6867129193842159; validation accuracy : 0.8656716417910447\n",
      "Epoch 89:\t train loss : 0.557035034515915; train accuracy : 0.9943528693528694; \n",
      " validation loss : 0.6893140166228313; validation accuracy : 0.8582089552238806\n",
      "Epoch 90:\t train loss : 0.5585142926125447; train accuracy : 0.9925096271250117; \n",
      " validation loss : 0.6186100092714032; validation accuracy : 0.9328358208955224\n",
      "Epoch 91:\t train loss : 0.607315661806137; train accuracy : 0.9433173663942894; \n",
      " validation loss : 0.61048445648127; validation accuracy : 0.9402985074626866\n",
      "Epoch 92:\t train loss : 0.5728418170534103; train accuracy : 0.9782959206036129; \n",
      " validation loss : 0.643096813487543; validation accuracy : 0.9104477611940298\n",
      "Epoch 93:\t train loss : 0.5647427059053366; train accuracy : 0.986326351710967; \n",
      " validation loss : 0.7052296957775397; validation accuracy : 0.8432835820895522\n",
      "Epoch 94:\t train loss : 0.5617171982702142; train accuracy : 0.9896136626905858; \n",
      " validation loss : 0.6599952405932256; validation accuracy : 0.8880597014925373\n",
      "Epoch 95:\t train loss : 0.5596270905687026; train accuracy : 0.991691712845559; \n",
      " validation loss : 0.6320573914578368; validation accuracy : 0.917910447761194\n",
      "Epoch 96:\t train loss : 0.5612209426977555; train accuracy : 0.990134153595692; \n",
      " validation loss : 0.6230838284726228; validation accuracy : 0.9253731343283582\n",
      "Epoch 97:\t train loss : 0.5614905354061648; train accuracy : 0.9897741147741148; \n",
      " validation loss : 0.6609971142397888; validation accuracy : 0.8955223880597015\n",
      "Epoch 98:\t train loss : 0.559868859660564; train accuracy : 0.9912807989731066; \n",
      " validation loss : 0.6836462100756258; validation accuracy : 0.8656716417910447\n",
      "Epoch 99:\t train loss : 0.6817066310086922; train accuracy : 0.8676192041576657; \n",
      " validation loss : 0.7362607057741932; validation accuracy : 0.8208955223880597\n",
      "Epoch 100:\t train loss : 0.5827182373595584; train accuracy : 0.9679956795341411; \n",
      " validation loss : 0.6964399433282374; validation accuracy : 0.8507462686567164\n",
      "Epoch 101:\t train loss : 0.5667759236252857; train accuracy : 0.9846239942393789; \n",
      " validation loss : 0.6659703411902942; validation accuracy : 0.8805970149253731\n",
      "Epoch 102:\t train loss : 0.563235502829001; train accuracy : 0.9880717573025265; \n",
      " validation loss : 0.6740164018702596; validation accuracy : 0.8731343283582089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103:\t train loss : 0.5613914821649514; train accuracy : 0.9899110860649322; \n",
      " validation loss : 0.6572151839795156; validation accuracy : 0.8955223880597015\n",
      "Epoch 104:\t train loss : 0.5608839457827769; train accuracy : 0.9905685482608559; \n",
      " validation loss : 0.688421088152272; validation accuracy : 0.8582089552238806\n",
      "Epoch 105:\t train loss : 0.5603327785263058; train accuracy : 0.9907290003443849; \n",
      " validation loss : 0.6526477197917643; validation accuracy : 0.8955223880597015\n",
      "Epoch 106:\t train loss : 0.5668585506318252; train accuracy : 0.9843500516577439; \n",
      " validation loss : 0.6250926932163431; validation accuracy : 0.9253731343283582\n",
      "Epoch 107:\t train loss : 0.5627541785985745; train accuracy : 0.9884591903822673; \n",
      " validation loss : 0.6168707755039404; validation accuracy : 0.9328358208955224\n",
      "Epoch 108:\t train loss : 0.5576588836572768; train accuracy : 0.9937501956732726; \n",
      " validation loss : 0.6331384502637121; validation accuracy : 0.917910447761194\n",
      "Epoch 109:\t train loss : 0.5590222624779082; train accuracy : 0.9924861463323001; \n",
      " validation loss : 0.6398678141343136; validation accuracy : 0.9104477611940298\n",
      "Epoch 110:\t train loss : 0.55843815580439; train accuracy : 0.992979242979243; \n",
      " validation loss : 0.6209704676226359; validation accuracy : 0.9328358208955224\n",
      "Epoch 111:\t train loss : 0.556752336112923; train accuracy : 0.9948968410506872; \n",
      " validation loss : 0.6186657292730416; validation accuracy : 0.9328358208955224\n",
      "Epoch 112:\t train loss : 0.5593590297243151; train accuracy : 0.9920478382016843; \n",
      " validation loss : 0.6174829462290908; validation accuracy : 0.9328358208955224\n",
      "Epoch 113:\t train loss : 0.5579059523120069; train accuracy : 0.9933901568516953; \n",
      " validation loss : 0.629819949983298; validation accuracy : 0.9253731343283582\n",
      "Epoch 114:\t train loss : 0.5586856375053838; train accuracy : 0.9925996368304061; \n",
      " validation loss : 0.6100183931196963; validation accuracy : 0.9402985074626866\n",
      "Epoch 115:\t train loss : 0.5589601435881304; train accuracy : 0.9922669922669922; \n",
      " validation loss : 0.6205920793637545; validation accuracy : 0.9328358208955224\n",
      "Epoch 116:\t train loss : 0.5578842770021202; train accuracy : 0.9934136376444068; \n",
      " validation loss : 0.6110818990080809; validation accuracy : 0.9402985074626866\n",
      "Epoch 117:\t train loss : 0.5589441000330027; train accuracy : 0.9921808960270498; \n",
      " validation loss : 0.6226251892233787; validation accuracy : 0.9253731343283582\n",
      "Epoch 118:\t train loss : 0.5576114316441169; train accuracy : 0.9938284649823111; \n",
      " validation loss : 0.5895452906704245; validation accuracy : 0.9626865671641791\n",
      "Epoch 119:\t train loss : 0.5577871193119458; train accuracy : 0.9935506089352243; \n",
      " validation loss : 0.5946546018284024; validation accuracy : 0.9552238805970149\n",
      "Epoch 120:\t train loss : 0.56041803138431; train accuracy : 0.9909207601515294; \n",
      " validation loss : 0.6346398658610667; validation accuracy : 0.917910447761194\n",
      "Epoch 121:\t train loss : 0.5581029610841511; train accuracy : 0.9932257913027144; \n",
      " validation loss : 0.6189797739976127; validation accuracy : 0.9328358208955224\n",
      "Epoch 122:\t train loss : 0.5781773893446882; train accuracy : 0.9728640305563383; \n",
      " validation loss : 0.6629318730789409; validation accuracy : 0.8880597014925373\n",
      "Epoch 123:\t train loss : 0.5652266441405571; train accuracy : 0.9858254281331205; \n",
      " validation loss : 0.6440763521444489; validation accuracy : 0.9104477611940298\n",
      "Epoch 124:\t train loss : 0.5854475612082842; train accuracy : 0.9657219561065715; \n",
      " validation loss : 0.7292715545044471; validation accuracy : 0.8283582089552238\n",
      "Epoch 125:\t train loss : 0.5606196171430904; train accuracy : 0.9908972793588178; \n",
      " validation loss : 0.6783305879768853; validation accuracy : 0.8731343283582089\n",
      "Epoch 126:\t train loss : 0.5587827309817592; train accuracy : 0.9927013869321561; \n",
      " validation loss : 0.6665126563535133; validation accuracy : 0.8880597014925373\n",
      "Epoch 127:\t train loss : 0.5574228676501429; train accuracy : 0.9940476190476191; \n",
      " validation loss : 0.6858863170703952; validation accuracy : 0.8582089552238806\n",
      "Epoch 128:\t train loss : 0.5579943510964376; train accuracy : 0.9933040606117529; \n",
      " validation loss : 0.6826465469215028; validation accuracy : 0.8656716417910447\n",
      "Epoch 129:\t train loss : 0.5559673239808381; train accuracy : 0.9954760339375723; \n",
      " validation loss : 0.6973340740591064; validation accuracy : 0.8507462686567164\n",
      "Epoch 130:\t train loss : 0.5569057128102756; train accuracy : 0.9945407156945618; \n",
      " validation loss : 0.6736290411905042; validation accuracy : 0.8731343283582089\n",
      "Epoch 131:\t train loss : 0.5568077429886628; train accuracy : 0.9946463792617639; \n",
      " validation loss : 0.6783267660301663; validation accuracy : 0.8731343283582089\n",
      "Epoch 132:\t train loss : 0.5681555186045437; train accuracy : 0.9826202999279923; \n",
      " validation loss : 0.7169778038373359; validation accuracy : 0.8283582089552238\n",
      "Epoch 133:\t train loss : 0.5769654621418048; train accuracy : 0.9741045991045991; \n",
      " validation loss : 0.685781588699868; validation accuracy : 0.8656716417910447\n",
      "Epoch 134:\t train loss : 0.5597193962326021; train accuracy : 0.991636924329232; \n",
      " validation loss : 0.6316705126891593; validation accuracy : 0.9253731343283582\n",
      "Epoch 135:\t train loss : 0.5581036837164286; train accuracy : 0.9932531855608778; \n",
      " validation loss : 0.6465022681996578; validation accuracy : 0.9029850746268657\n",
      "Epoch 136:\t train loss : 0.5572246083978574; train accuracy : 0.9941298018221095; \n",
      " validation loss : 0.6608155577988324; validation accuracy : 0.8880597014925373\n",
      "Epoch 137:\t train loss : 0.5566563967013051; train accuracy : 0.9947089947089947; \n",
      " validation loss : 0.6237144543175503; validation accuracy : 0.9253731343283582\n",
      "Epoch 138:\t train loss : 0.5569240839049859; train accuracy : 0.9944624463855233; \n",
      " validation loss : 0.6306478564593789; validation accuracy : 0.917910447761194\n",
      "Epoch 139:\t train loss : 0.5563175943409263; train accuracy : 0.995170783632322; \n",
      " validation loss : 0.6249699099537561; validation accuracy : 0.9253731343283582\n",
      "Epoch 140:\t train loss : 0.5555425728124017; train accuracy : 0.9959417363263517; \n",
      " validation loss : 0.6341327585717376; validation accuracy : 0.9104477611940298\n",
      "Epoch 141:\t train loss : 0.5651826021145956; train accuracy : 0.9858058608058607; \n",
      " validation loss : 0.6269707644235702; validation accuracy : 0.9253731343283582\n",
      "Epoch 142:\t train loss : 0.5628884539271648; train accuracy : 0.9882948248332863; \n",
      " validation loss : 0.611146831779743; validation accuracy : 0.9402985074626866\n",
      "Epoch 143:\t train loss : 0.5553621813645611; train accuracy : 0.996082621082621; \n",
      " validation loss : 0.6564013572294333; validation accuracy : 0.8955223880597015\n",
      "Epoch 144:\t train loss : 0.5562394554681254; train accuracy : 0.9951473028396105; \n",
      " validation loss : 0.6354831452540844; validation accuracy : 0.917910447761194\n",
      "Epoch 145:\t train loss : 0.5573469671916718; train accuracy : 0.9940476190476191; \n",
      " validation loss : 0.5823552266636988; validation accuracy : 0.9701492537313433\n",
      "Epoch 146:\t train loss : 0.5556366951010385; train accuracy : 0.9958047650355343; \n",
      " validation loss : 0.6397981606957123; validation accuracy : 0.9104477611940298\n",
      "Epoch 147:\t train loss : 0.5632773463802665; train accuracy : 0.9878526032372186; \n",
      " validation loss : 0.6992752130541141; validation accuracy : 0.8507462686567164\n",
      "Epoch 148:\t train loss : 0.5564395040641331; train accuracy : 0.9949007545161391; \n",
      " validation loss : 0.6553878586530462; validation accuracy : 0.8955223880597015\n",
      "Epoch 149:\t train loss : 0.5566022389271397; train accuracy : 0.9948185717416487; \n",
      " validation loss : 0.648256768006152; validation accuracy : 0.9029850746268657\n",
      "Epoch 150:\t train loss : 0.5566527466634181; train accuracy : 0.9947089947089947; \n",
      " validation loss : 0.6367953664313556; validation accuracy : 0.917910447761194\n",
      "Epoch 151:\t train loss : 0.5572866897865938; train accuracy : 0.9940750133057825; \n",
      " validation loss : 0.6491250242989312; validation accuracy : 0.9029850746268657\n",
      "Epoch 152:\t train loss : 0.5554816829295905; train accuracy : 0.9958908612754767; \n",
      " validation loss : 0.657116264455674; validation accuracy : 0.8955223880597015\n",
      "Epoch 153:\t train loss : 0.5709859910243134; train accuracy : 0.9797712970789894; \n",
      " validation loss : 0.6263401996429805; validation accuracy : 0.9253731343283582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154:\t train loss : 0.5698802745573439; train accuracy : 0.9813132024670487; \n",
      " validation loss : 0.6545363481737212; validation accuracy : 0.8955223880597015\n",
      "Epoch 155:\t train loss : 0.5646500055301468; train accuracy : 0.9865181115181115; \n",
      " validation loss : 0.6348649540402279; validation accuracy : 0.9104477611940298\n",
      "Epoch 156:\t train loss : 0.5587442887753798; train accuracy : 0.9927326946557715; \n",
      " validation loss : 0.6110739253457738; validation accuracy : 0.9402985074626866\n",
      "Epoch 157:\t train loss : 0.5564053448730155; train accuracy : 0.9950377258069566; \n",
      " validation loss : 0.6356400105746177; validation accuracy : 0.917910447761194\n",
      "Epoch 158:\t train loss : 0.556256056301211; train accuracy : 0.9950925143232835; \n",
      " validation loss : 0.5993546692209943; validation accuracy : 0.9477611940298507\n",
      "Epoch 159:\t train loss : 0.555912944165141; train accuracy : 0.9954760339375723; \n",
      " validation loss : 0.6260341452715991; validation accuracy : 0.9253731343283582\n",
      "Epoch 160:\t train loss : 0.5569535789172243; train accuracy : 0.9944311386619079; \n",
      " validation loss : 0.6549660869460657; validation accuracy : 0.8955223880597015\n",
      "Epoch 161:\t train loss : 0.5564426268681125; train accuracy : 0.995010331548793; \n",
      " validation loss : 0.6031082230724817; validation accuracy : 0.9477611940298507\n",
      "Epoch 162:\t train loss : 0.5567814032853223; train accuracy : 0.9944311386619079; \n",
      " validation loss : 0.801892141149996; validation accuracy : 0.746268656716418\n",
      "Epoch 163:\t train loss : 0.6358908182782508; train accuracy : 0.9138059234213081; \n",
      " validation loss : 0.7242143180139621; validation accuracy : 0.8208955223880597\n",
      "Epoch 164:\t train loss : 0.5722190367343578; train accuracy : 0.9788946808177578; \n",
      " validation loss : 0.7103272915141862; validation accuracy : 0.8432835820895522\n",
      "Epoch 165:\t train loss : 0.5635123473981154; train accuracy : 0.9879621802698726; \n",
      " validation loss : 0.6853402835768901; validation accuracy : 0.8656716417910447\n",
      "Epoch 166:\t train loss : 0.5618525184025299; train accuracy : 0.9895784415015184; \n",
      " validation loss : 0.6902934814794653; validation accuracy : 0.8582089552238806\n",
      "Epoch 167:\t train loss : 0.5602557620851137; train accuracy : 0.9910303371841833; \n",
      " validation loss : 0.6412809079607922; validation accuracy : 0.9104477611940298\n",
      "Epoch 168:\t train loss : 0.5588405478652689; train accuracy : 0.9925409348486272; \n",
      " validation loss : 0.7226242993797538; validation accuracy : 0.8283582089552238\n",
      "Epoch 169:\t train loss : 0.5580106748980158; train accuracy : 0.9933627625935318; \n",
      " validation loss : 0.7003452291631813; validation accuracy : 0.8507462686567164\n",
      "Epoch 170:\t train loss : 0.557779619870711; train accuracy : 0.9936601859678783; \n",
      " validation loss : 0.6872419820161442; validation accuracy : 0.8656716417910447\n",
      "Epoch 171:\t train loss : 0.5580749165712307; train accuracy : 0.9934958204188973; \n",
      " validation loss : 0.6952984730370624; validation accuracy : 0.8582089552238806\n",
      "Epoch 172:\t train loss : 0.5559105463751154; train accuracy : 0.9955308224538993; \n",
      " validation loss : 0.6588908407043367; validation accuracy : 0.8955223880597015\n",
      "Epoch 173:\t train loss : 0.558094199421472; train accuracy : 0.9933079740772048; \n",
      " validation loss : 0.6709499945996291; validation accuracy : 0.8805970149253731\n",
      "Epoch 174:\t train loss : 0.558248007734806; train accuracy : 0.9930614257537335; \n",
      " validation loss : 0.6132984628466932; validation accuracy : 0.9328358208955224\n",
      "Epoch 175:\t train loss : 0.5570750692774907; train accuracy : 0.9944311386619079; \n",
      " validation loss : 0.6800140804527436; validation accuracy : 0.8731343283582089\n",
      "Epoch 176:\t train loss : 0.5567901332643747; train accuracy : 0.9945681099527254; \n",
      " validation loss : 0.6405046043231296; validation accuracy : 0.9104477611940298\n",
      "Epoch 177:\t train loss : 0.5562196551981604; train accuracy : 0.995225572148649; \n",
      " validation loss : 0.648060076271749; validation accuracy : 0.9029850746268657\n",
      "Epoch 178:\t train loss : 0.5567228404817264; train accuracy : 0.9946816004508312; \n",
      " validation loss : 0.6397917237952129; validation accuracy : 0.9104477611940298\n",
      "Epoch 179:\t train loss : 0.5559548126339845; train accuracy : 0.9954173319557935; \n",
      " validation loss : 0.6711261758561328; validation accuracy : 0.8805970149253731\n",
      "Epoch 180:\t train loss : 0.5553405877942653; train accuracy : 0.9961608903916596; \n",
      " validation loss : 0.6547062247669806; validation accuracy : 0.8955223880597015\n",
      "Epoch 181:\t train loss : 0.5563429898342773; train accuracy : 0.9951433893741586; \n",
      " validation loss : 0.6094634994143109; validation accuracy : 0.9402985074626866\n",
      "Epoch 182:\t train loss : 0.5562750487227797; train accuracy : 0.9951433893741586; \n",
      " validation loss : 0.6111706624267768; validation accuracy : 0.9402985074626866\n",
      "Epoch 183:\t train loss : 0.5585870891266507; train accuracy : 0.992818790895714; \n",
      " validation loss : 0.6466095966023468; validation accuracy : 0.9029850746268657\n",
      "Epoch 184:\t train loss : 0.5583053064462166; train accuracy : 0.9930027237719545; \n",
      " validation loss : 0.6282433630913318; validation accuracy : 0.9253731343283582\n",
      "Epoch 185:\t train loss : 0.5583090909991955; train accuracy : 0.9930535988228296; \n",
      " validation loss : 0.6336078668915273; validation accuracy : 0.917910447761194\n",
      "Epoch 186:\t train loss : 0.5551100276543861; train accuracy : 0.9962430731661501; \n",
      " validation loss : 0.608822697096185; validation accuracy : 0.9328358208955224\n",
      "Epoch 187:\t train loss : 0.5566927504005931; train accuracy : 0.9946776869853793; \n",
      " validation loss : 0.6155228396757311; validation accuracy : 0.9402985074626866\n",
      "Epoch 188:\t train loss : 0.555677593074008; train accuracy : 0.9957225822610438; \n",
      " validation loss : 0.6385796028762284; validation accuracy : 0.9104477611940298\n",
      "Epoch 189:\t train loss : 0.5565748309991103; train accuracy : 0.9948733602579757; \n",
      " validation loss : 0.5972534272842805; validation accuracy : 0.9477611940298507\n",
      "Epoch 190:\t train loss : 0.559849992261045; train accuracy : 0.9915469146238377; \n",
      " validation loss : 0.6108865946459848; validation accuracy : 0.9402985074626866\n",
      "Epoch 191:\t train loss : 0.556979742139845; train accuracy : 0.9943254750947058; \n",
      " validation loss : 0.6165446444724263; validation accuracy : 0.9328358208955224\n",
      "Epoch 192:\t train loss : 0.5556817826493088; train accuracy : 0.9956130052283898; \n",
      " validation loss : 0.6374382177414225; validation accuracy : 0.9104477611940298\n",
      "Epoch 193:\t train loss : 0.5547789169538884; train accuracy : 0.9966031119877273; \n",
      " validation loss : 0.6194969968130439; validation accuracy : 0.9328358208955224\n",
      "Epoch 194:\t train loss : 0.5555699935247788; train accuracy : 0.9959143420681882; \n",
      " validation loss : 0.6327675985203723; validation accuracy : 0.917910447761194\n",
      "Epoch 195:\t train loss : 0.5580702276461995; train accuracy : 0.9933314548699164; \n",
      " validation loss : 0.699456161351851; validation accuracy : 0.8507462686567164\n",
      "Early stopping at epoch 195\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5573469671916718; Train accuracy : 0.9940476190476191; \n",
      " Validation loss : 0.5823552266636988; Validation accuracy : 0.9701492537313433\n",
      "------------------------------ Let's train model 2 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.895776084084546; train accuracy : 0.6415507819884795; \n",
      " validation loss : 0.7917765992049458; validation accuracy : 0.7686567164179104\n",
      "Epoch 2:\t train loss : 0.7706050683359746; train accuracy : 0.7742949500301581; \n",
      " validation loss : 0.7459278652294972; validation accuracy : 0.8134328358208955\n",
      "Epoch 3:\t train loss : 0.7310046338126023; train accuracy : 0.8170680029682253; \n",
      " validation loss : 0.7459877991702093; validation accuracy : 0.7910447761194029\n",
      "Epoch 4:\t train loss : 0.6934332417736463; train accuracy : 0.8550774915152224; \n",
      " validation loss : 0.7031012828122235; validation accuracy : 0.8507462686567164\n",
      "Epoch 5:\t train loss : 0.6646378487130947; train accuracy : 0.8844925659330555; \n",
      " validation loss : 0.6867517703412229; validation accuracy : 0.8582089552238806\n",
      "Epoch 6:\t train loss : 0.6412968209364334; train accuracy : 0.9091071017491695; \n",
      " validation loss : 0.6984128422367247; validation accuracy : 0.835820895522388\n",
      "Epoch 7:\t train loss : 0.6295195957157923; train accuracy : 0.9209365985526686; \n",
      " validation loss : 0.6440502858216549; validation accuracy : 0.9029850746268657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\t train loss : 0.6196720308415733; train accuracy : 0.9318279149503131; \n",
      " validation loss : 0.6554554053549325; validation accuracy : 0.8880597014925373\n",
      "Epoch 9:\t train loss : 0.6087123768931321; train accuracy : 0.9418868293360461; \n",
      " validation loss : 0.6590612044899213; validation accuracy : 0.9029850746268657\n",
      "Epoch 10:\t train loss : 0.6006161638936878; train accuracy : 0.9505185391907341; \n",
      " validation loss : 0.6504964266142741; validation accuracy : 0.8955223880597015\n",
      "Epoch 11:\t train loss : 0.5962155676626866; train accuracy : 0.9555184170150817; \n",
      " validation loss : 0.6508776548752029; validation accuracy : 0.9029850746268657\n",
      "Epoch 12:\t train loss : 0.597831154124761; train accuracy : 0.9533636243214428; \n",
      " validation loss : 0.6429420998705587; validation accuracy : 0.9104477611940298\n",
      "Epoch 13:\t train loss : 0.5869167633288623; train accuracy : 0.9642578343529642; \n",
      " validation loss : 0.6714538917063664; validation accuracy : 0.8731343283582089\n",
      "Epoch 14:\t train loss : 0.5835391189370974; train accuracy : 0.967433758290261; \n",
      " validation loss : 0.6530869954245817; validation accuracy : 0.9029850746268657\n",
      "Epoch 15:\t train loss : 0.5791303082840302; train accuracy : 0.9722735217067553; \n",
      " validation loss : 0.6541997823803748; validation accuracy : 0.8955223880597015\n",
      "Epoch 16:\t train loss : 0.5757568933779694; train accuracy : 0.9757278775259816; \n",
      " validation loss : 0.6478988867838344; validation accuracy : 0.9104477611940298\n",
      "Epoch 17:\t train loss : 0.5716701929900759; train accuracy : 0.9796828320059056; \n",
      " validation loss : 0.6635935673648173; validation accuracy : 0.8805970149253731\n",
      "Epoch 18:\t train loss : 0.5723082181696525; train accuracy : 0.9793786789339596; \n",
      " validation loss : 0.6636725888580687; validation accuracy : 0.8880597014925373\n",
      "Epoch 19:\t train loss : 0.574752039147108; train accuracy : 0.9767795526827844; \n",
      " validation loss : 0.661402753956148; validation accuracy : 0.8955223880597015\n",
      "Epoch 20:\t train loss : 0.5765291188801787; train accuracy : 0.9746524102684134; \n",
      " validation loss : 0.6544316806675909; validation accuracy : 0.8880597014925373\n",
      "Epoch 21:\t train loss : 0.5653450547882339; train accuracy : 0.9860395026036275; \n",
      " validation loss : 0.6571174108109584; validation accuracy : 0.8805970149253731\n",
      "Epoch 22:\t train loss : 0.5626150550465601; train accuracy : 0.9891077190577299; \n",
      " validation loss : 0.6381821918185245; validation accuracy : 0.9104477611940298\n",
      "Epoch 23:\t train loss : 0.5612727065049704; train accuracy : 0.9901880090384262; \n",
      " validation loss : 0.6120809224744806; validation accuracy : 0.9402985074626866\n",
      "Epoch 24:\t train loss : 0.5660263470225423; train accuracy : 0.9855427621214323; \n",
      " validation loss : 0.6551069722648789; validation accuracy : 0.8955223880597015\n",
      "Epoch 25:\t train loss : 0.5644778946578883; train accuracy : 0.9871721995089825; \n",
      " validation loss : 0.647639031456194; validation accuracy : 0.9104477611940298\n",
      "Epoch 26:\t train loss : 0.5616514641965592; train accuracy : 0.9898285554079445; \n",
      " validation loss : 0.6814410900788825; validation accuracy : 0.8656716417910447\n",
      "Epoch 27:\t train loss : 0.5589484446211559; train accuracy : 0.9926479193486366; \n",
      " validation loss : 0.6226890252896398; validation accuracy : 0.9253731343283582\n",
      "Epoch 28:\t train loss : 0.5853554816711377; train accuracy : 0.9654477609061061; \n",
      " validation loss : 0.6868500744091505; validation accuracy : 0.8582089552238806\n",
      "Epoch 29:\t train loss : 0.5793668183513592; train accuracy : 0.9721114782096508; \n",
      " validation loss : 0.7102118531979141; validation accuracy : 0.8283582089552238\n",
      "Epoch 30:\t train loss : 0.5736735962483471; train accuracy : 0.9777987548371913; \n",
      " validation loss : 0.6353268886142369; validation accuracy : 0.9104477611940298\n",
      "Epoch 31:\t train loss : 0.5758854720717286; train accuracy : 0.9750128284435208; \n",
      " validation loss : 0.6703895595055932; validation accuracy : 0.8805970149253731\n",
      "Epoch 32:\t train loss : 0.5643309333524456; train accuracy : 0.9869815411879846; \n",
      " validation loss : 0.6389818597781061; validation accuracy : 0.9104477611940298\n",
      "Epoch 33:\t train loss : 0.5627016430494245; train accuracy : 0.9885556780169992; \n",
      " validation loss : 0.6572976591150831; validation accuracy : 0.8880597014925373\n",
      "Epoch 34:\t train loss : 0.5605824080025129; train accuracy : 0.9909879380479417; \n",
      " validation loss : 0.6455119335720247; validation accuracy : 0.9029850746268657\n",
      "Epoch 35:\t train loss : 0.560426232772726; train accuracy : 0.9907429437130338; \n",
      " validation loss : 0.6280282895797354; validation accuracy : 0.9253731343283582\n",
      "Epoch 36:\t train loss : 0.5575263452798286; train accuracy : 0.9939722391196151; \n",
      " validation loss : 0.6259370065843906; validation accuracy : 0.9253731343283582\n",
      "Epoch 37:\t train loss : 0.556744600795824; train accuracy : 0.9944975944257037; \n",
      " validation loss : 0.6567623201261814; validation accuracy : 0.8955223880597015\n",
      "Epoch 38:\t train loss : 0.5618334280050176; train accuracy : 0.9894986811459819; \n",
      " validation loss : 0.6417583798922949; validation accuracy : 0.9104477611940298\n",
      "Epoch 39:\t train loss : 0.5649108032866497; train accuracy : 0.9863713059548413; \n",
      " validation loss : 0.6981417629567928; validation accuracy : 0.8507462686567164\n",
      "Epoch 40:\t train loss : 0.5641861561036071; train accuracy : 0.9869815411879846; \n",
      " validation loss : 0.7184296277078159; validation accuracy : 0.8208955223880597\n",
      "Epoch 41:\t train loss : 0.5617257691995243; train accuracy : 0.9894967520567306; \n",
      " validation loss : 0.671013843993545; validation accuracy : 0.8805970149253731\n",
      "Epoch 42:\t train loss : 0.5617764828512529; train accuracy : 0.9894928938782281; \n",
      " validation loss : 0.6396098078022654; validation accuracy : 0.9104477611940298\n",
      "Epoch 43:\t train loss : 0.5567999557098683; train accuracy : 0.9947760263076332; \n",
      " validation loss : 0.6222172047128552; validation accuracy : 0.9253731343283582\n",
      "Epoch 44:\t train loss : 0.5567869658895572; train accuracy : 0.9948036765869009; \n",
      " validation loss : 0.6220630288201868; validation accuracy : 0.9328358208955224\n",
      "Epoch 45:\t train loss : 0.5661730883045011; train accuracy : 0.9850154777260924; \n",
      " validation loss : 0.6562830769921645; validation accuracy : 0.8880597014925373\n",
      "Epoch 46:\t train loss : 0.5613284369341369; train accuracy : 0.9899124707903736; \n",
      " validation loss : 0.6508942383784505; validation accuracy : 0.9029850746268657\n",
      "Epoch 47:\t train loss : 0.567003375614868; train accuracy : 0.9843528355682905; \n",
      " validation loss : 0.683889222778304; validation accuracy : 0.8582089552238806\n",
      "Epoch 48:\t train loss : 0.5614396009902671; train accuracy : 0.9897989760394255; \n",
      " validation loss : 0.6281061449179962; validation accuracy : 0.9253731343283582\n",
      "Epoch 49:\t train loss : 0.5623181831413608; train accuracy : 0.9888588665443195; \n",
      " validation loss : 0.6477026720612635; validation accuracy : 0.8955223880597015\n",
      "Epoch 50:\t train loss : 0.561628669342655; train accuracy : 0.9894938584228538; \n",
      " validation loss : 0.6556141899858946; validation accuracy : 0.8955223880597015\n",
      "Epoch 51:\t train loss : 0.5791442158512919; train accuracy : 0.9716375652835954; \n",
      " validation loss : 0.6772776264058216; validation accuracy : 0.8656716417910447\n",
      "Epoch 52:\t train loss : 0.5780680246849242; train accuracy : 0.9728770051275192; \n",
      " validation loss : 0.6621070592175394; validation accuracy : 0.8955223880597015\n",
      "Epoch 53:\t train loss : 0.5666726578471947; train accuracy : 0.9845997589924496; \n",
      " validation loss : 0.6296765487069524; validation accuracy : 0.9253731343283582\n",
      "Epoch 54:\t train loss : 0.5628034527303507; train accuracy : 0.9885003774584635; \n",
      " validation loss : 0.6485422726262032; validation accuracy : 0.8955223880597015\n",
      "Epoch 55:\t train loss : 0.5596239168244803; train accuracy : 0.9917907606913341; \n",
      " validation loss : 0.6584276661891538; validation accuracy : 0.8880597014925373\n",
      "Epoch 56:\t train loss : 0.5597028491086101; train accuracy : 0.9915409436332981; \n",
      " validation loss : 0.6670610581253694; validation accuracy : 0.8880597014925373\n",
      "Epoch 57:\t train loss : 0.5619012486412401; train accuracy : 0.9894138012189272; \n",
      " validation loss : 0.6749188270357593; validation accuracy : 0.8805970149253731\n",
      "Epoch 58:\t train loss : 0.5622611604580237; train accuracy : 0.9891620550716399; \n",
      " validation loss : 0.6308430815503947; validation accuracy : 0.917910447761194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59:\t train loss : 0.5595689651229763; train accuracy : 0.9917078098535307; \n",
      " validation loss : 0.6383050051103741; validation accuracy : 0.9104477611940298\n",
      "Epoch 60:\t train loss : 0.5644548381824019; train accuracy : 0.9869243115401977; \n",
      " validation loss : 0.6558149368221707; validation accuracy : 0.8955223880597015\n",
      "Epoch 61:\t train loss : 0.5664015082532485; train accuracy : 0.9846550595509852; \n",
      " validation loss : 0.6271009764340728; validation accuracy : 0.9253731343283582\n",
      "Epoch 62:\t train loss : 0.5604474119722738; train accuracy : 0.9907657712691735; \n",
      " validation loss : 0.6412882375892655; validation accuracy : 0.9104477611940298\n",
      "Epoch 63:\t train loss : 0.5609536746940212; train accuracy : 0.9902433095969618; \n",
      " validation loss : 0.6482397777108064; validation accuracy : 0.9029850746268657\n",
      "Epoch 64:\t train loss : 0.5597476443289153; train accuracy : 0.9915952796472082; \n",
      " validation loss : 0.6173550172699874; validation accuracy : 0.9402985074626866\n",
      "Epoch 65:\t train loss : 0.5573582904566655; train accuracy : 0.9940857338705632; \n",
      " validation loss : 0.6671705426598389; validation accuracy : 0.8880597014925373\n",
      "Epoch 66:\t train loss : 0.5651328387310707; train accuracy : 0.986231125469251; \n",
      " validation loss : 0.6657337379734772; validation accuracy : 0.8880597014925373\n",
      "Epoch 67:\t train loss : 0.56313525162885; train accuracy : 0.9879740576077493; \n",
      " validation loss : 0.6120095465768233; validation accuracy : 0.9402985074626866\n",
      "Epoch 68:\t train loss : 0.5609779960879979; train accuracy : 0.9902127656838171; \n",
      " validation loss : 0.6519849184836773; validation accuracy : 0.9029850746268657\n",
      "Epoch 69:\t train loss : 0.5590433130548771; train accuracy : 0.9924247880252428; \n",
      " validation loss : 0.6408754862132662; validation accuracy : 0.9104477611940298\n",
      "Epoch 70:\t train loss : 0.5567831264651912; train accuracy : 0.9945271737942227; \n",
      " validation loss : 0.6403951660126161; validation accuracy : 0.9029850746268657\n",
      "Epoch 71:\t train loss : 0.5571404375295719; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6284741496751136; validation accuracy : 0.917910447761194\n",
      "Epoch 72:\t train loss : 0.5563653944100578; train accuracy : 0.9950801793795792; \n",
      " validation loss : 0.6437310801095926; validation accuracy : 0.9029850746268657\n",
      "Epoch 73:\t train loss : 0.5572353596964473; train accuracy : 0.9941124196052055; \n",
      " validation loss : 0.633760604116219; validation accuracy : 0.917910447761194\n",
      "Epoch 74:\t train loss : 0.5594269684931296; train accuracy : 0.9918508839729979; \n",
      " validation loss : 0.6578273541708164; validation accuracy : 0.8880597014925373\n",
      "Epoch 75:\t train loss : 0.5600826884436951; train accuracy : 0.9911538397235486; \n",
      " validation loss : 0.6413796292353748; validation accuracy : 0.9104477611940298\n",
      "Epoch 76:\t train loss : 0.5687303402954668; train accuracy : 0.9822552725224385; \n",
      " validation loss : 0.6340248288838889; validation accuracy : 0.9104477611940298\n",
      "Epoch 77:\t train loss : 0.5586805254001737; train accuracy : 0.99278520620035; \n",
      " validation loss : 0.6282769777807053; validation accuracy : 0.917910447761194\n",
      "Epoch 78:\t train loss : 0.5556164654521759; train accuracy : 0.9957981220959169; \n",
      " validation loss : 0.6390711459650136; validation accuracy : 0.9104477611940298\n",
      "Epoch 79:\t train loss : 0.5586779170317789; train accuracy : 0.9925955124239778; \n",
      " validation loss : 0.6252076541742052; validation accuracy : 0.9253731343283582\n",
      "Epoch 80:\t train loss : 0.5598670345371763; train accuracy : 0.9914589573401202; \n",
      " validation loss : 0.6326021301968158; validation accuracy : 0.917910447761194\n",
      "Epoch 81:\t train loss : 0.5688320670532547; train accuracy : 0.9822076883209079; \n",
      " validation loss : 0.6461520970202712; validation accuracy : 0.8880597014925373\n",
      "Epoch 82:\t train loss : 0.6479500455099958; train accuracy : 0.9012714627254944; \n",
      " validation loss : 0.6990614246524333; validation accuracy : 0.8507462686567164\n",
      "Epoch 83:\t train loss : 0.6146687884284262; train accuracy : 0.9353079919595559; \n",
      " validation loss : 0.6297158025142674; validation accuracy : 0.9253731343283582\n",
      "Epoch 84:\t train loss : 0.5822766810779628; train accuracy : 0.9684844689024382; \n",
      " validation loss : 0.6286687129789723; validation accuracy : 0.917910447761194\n",
      "Epoch 85:\t train loss : 0.5731001055649513; train accuracy : 0.9778826702196204; \n",
      " validation loss : 0.632425345819464; validation accuracy : 0.917910447761194\n",
      "Epoch 86:\t train loss : 0.568514540331603; train accuracy : 0.9830236930741838; \n",
      " validation loss : 0.6375602070515466; validation accuracy : 0.9104477611940298\n",
      "Epoch 87:\t train loss : 0.5608894955490099; train accuracy : 0.9902137302284427; \n",
      " validation loss : 0.640605991693582; validation accuracy : 0.9104477611940298\n",
      "Epoch 88:\t train loss : 0.5591792956578062; train accuracy : 0.9920939492186546; \n",
      " validation loss : 0.637800271532094; validation accuracy : 0.9104477611940298\n",
      "Epoch 89:\t train loss : 0.558311312947936; train accuracy : 0.9931160450069383; \n",
      " validation loss : 0.6330368300586487; validation accuracy : 0.917910447761194\n",
      "Epoch 90:\t train loss : 0.5574468380117775; train accuracy : 0.9940018184881342; \n",
      " validation loss : 0.6522302274103887; validation accuracy : 0.9029850746268657\n",
      "Epoch 91:\t train loss : 0.5577623140713642; train accuracy : 0.9936700151369203; \n",
      " validation loss : 0.6448306687702854; validation accuracy : 0.9104477611940298\n",
      "Epoch 92:\t train loss : 0.5553567126412023; train accuracy : 0.9960193243300595; \n",
      " validation loss : 0.6212609022090047; validation accuracy : 0.9328358208955224\n",
      "Epoch 93:\t train loss : 0.5552611996134089; train accuracy : 0.9961585402710241; \n",
      " validation loss : 0.6454565366623549; validation accuracy : 0.9029850746268657\n",
      "Epoch 94:\t train loss : 0.5561713025873192; train accuracy : 0.995216501686667; \n",
      " validation loss : 0.6581565417161196; validation accuracy : 0.8880597014925373\n",
      "Epoch 95:\t train loss : 0.5556189614549293; train accuracy : 0.9958267369198103; \n",
      " validation loss : 0.6270226218066879; validation accuracy : 0.9253731343283582\n",
      "Epoch 96:\t train loss : 0.5563386384368835; train accuracy : 0.9950792148349535; \n",
      " validation loss : 0.6249756007592341; validation accuracy : 0.9253731343283582\n",
      "Epoch 97:\t train loss : 0.555267918429147; train accuracy : 0.9962967916673633; \n",
      " validation loss : 0.6255436865821665; validation accuracy : 0.9253731343283582\n",
      "Epoch 98:\t train loss : 0.5595695240087124; train accuracy : 0.9915399790886725; \n",
      " validation loss : 0.626374584610135; validation accuracy : 0.9253731343283582\n",
      "Epoch 99:\t train loss : 0.562245838779339; train accuracy : 0.9890286263984289; \n",
      " validation loss : 0.6456255504017455; validation accuracy : 0.9029850746268657\n",
      "Epoch 100:\t train loss : 0.5749287532462419; train accuracy : 0.9761435962596245; \n",
      " validation loss : 0.6999110417942552; validation accuracy : 0.8507462686567164\n",
      "Epoch 101:\t train loss : 0.5649348140387253; train accuracy : 0.9861787185445922; \n",
      " validation loss : 0.6436318998728683; validation accuracy : 0.9104477611940298\n",
      "Epoch 102:\t train loss : 0.6024313709092589; train accuracy : 0.948077598258161; \n",
      " validation loss : 0.6404748358909005; validation accuracy : 0.9029850746268657\n",
      "Epoch 103:\t train loss : 0.5602499656150385; train accuracy : 0.9912911265752621; \n",
      " validation loss : 0.6398802690202651; validation accuracy : 0.9104477611940298\n",
      "Epoch 104:\t train loss : 0.5727052753706321; train accuracy : 0.9784006306835792; \n",
      " validation loss : 0.7505975713417466; validation accuracy : 0.8059701492537313\n",
      "Epoch 105:\t train loss : 0.6055059233272772; train accuracy : 0.944234209439934; \n",
      " validation loss : 0.6938450207336037; validation accuracy : 0.8582089552238806\n",
      "Epoch 106:\t train loss : 0.5814699110468854; train accuracy : 0.9697525235702555; \n",
      " validation loss : 0.636378629438025; validation accuracy : 0.917910447761194\n",
      "Epoch 107:\t train loss : 0.571052239018786; train accuracy : 0.9800136708124938; \n",
      " validation loss : 0.6520098241945051; validation accuracy : 0.8955223880597015\n",
      "Epoch 108:\t train loss : 0.5656046471774733; train accuracy : 0.9852929450633963; \n",
      " validation loss : 0.6257396507356602; validation accuracy : 0.9253731343283582\n",
      "Epoch 109:\t train loss : 0.5613539136590948; train accuracy : 0.9897722903047832; \n",
      " validation loss : 0.6453315503598606; validation accuracy : 0.9104477611940298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110:\t train loss : 0.5590840080374333; train accuracy : 0.9922322006149936; \n",
      " validation loss : 0.6429301904659019; validation accuracy : 0.9029850746268657\n",
      "Epoch 111:\t train loss : 0.5591812553683766; train accuracy : 0.9922035857911002; \n",
      " validation loss : 0.6341695430970495; validation accuracy : 0.917910447761194\n",
      "Epoch 112:\t train loss : 0.5598892476811166; train accuracy : 0.9913473916784233; \n",
      " validation loss : 0.6133040502809549; validation accuracy : 0.9402985074626866\n",
      "Epoch 113:\t train loss : 0.5587890544687719; train accuracy : 0.9924524383045106; \n",
      " validation loss : 0.6356619276943027; validation accuracy : 0.917910447761194\n",
      "Epoch 114:\t train loss : 0.5576651186846995; train accuracy : 0.9936967008715625; \n",
      " validation loss : 0.633078184020578; validation accuracy : 0.917910447761194\n",
      "Epoch 115:\t train loss : 0.5579406983263769; train accuracy : 0.9933658620649742; \n",
      " validation loss : 0.6379587195793309; validation accuracy : 0.9104477611940298\n",
      "Epoch 116:\t train loss : 0.5595691685768776; train accuracy : 0.9915943151025826; \n",
      " validation loss : 0.6555443990007603; validation accuracy : 0.8955223880597015\n",
      "Epoch 117:\t train loss : 0.5661029989751052; train accuracy : 0.9850698137400025; \n",
      " validation loss : 0.6619812802944214; validation accuracy : 0.8880597014925373\n",
      "Early stopping at epoch 117\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.56313525162885; Train accuracy : 0.9879740576077493; \n",
      " Validation loss : 0.6120095465768233; Validation accuracy : 0.9402985074626866\n",
      "------------------------------ Let's train model 3 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8964575178243587; train accuracy : 0.6342717793157028; \n",
      " validation loss : 0.8073182432647454; validation accuracy : 0.7368421052631579\n",
      "Epoch 2:\t train loss : 0.7768454219951406; train accuracy : 0.7665918535533306; \n",
      " validation loss : 0.7611204290188714; validation accuracy : 0.7819548872180451\n",
      "Epoch 3:\t train loss : 0.7254570029918317; train accuracy : 0.8222478193371217; \n",
      " validation loss : 0.7096422160479261; validation accuracy : 0.8345864661654135\n",
      "Epoch 4:\t train loss : 0.6905420366594041; train accuracy : 0.8577885441521008; \n",
      " validation loss : 0.727282323290755; validation accuracy : 0.8195488721804511\n",
      "Epoch 5:\t train loss : 0.6568386654357122; train accuracy : 0.8933569192463477; \n",
      " validation loss : 0.7141212951132391; validation accuracy : 0.8270676691729323\n",
      "Epoch 6:\t train loss : 0.6391108455191247; train accuracy : 0.9125947696461978; \n",
      " validation loss : 0.7427580925393001; validation accuracy : 0.7969924812030075\n",
      "Epoch 7:\t train loss : 0.6266621884491064; train accuracy : 0.9240001726456462; \n",
      " validation loss : 0.6773846821143309; validation accuracy : 0.8796992481203008\n",
      "Epoch 8:\t train loss : 0.6137036648715274; train accuracy : 0.938229950512744; \n",
      " validation loss : 0.7109191438190275; validation accuracy : 0.8270676691729323\n",
      "Epoch 9:\t train loss : 0.6291851304244335; train accuracy : 0.9228941614749333; \n",
      " validation loss : 0.7035215223602113; validation accuracy : 0.8345864661654135\n",
      "Epoch 10:\t train loss : 0.6038804401028982; train accuracy : 0.9479904990942848; \n",
      " validation loss : 0.7071801164638871; validation accuracy : 0.8270676691729323\n",
      "Epoch 11:\t train loss : 0.6024005044914553; train accuracy : 0.9486675937378187; \n",
      " validation loss : 0.6977233117824634; validation accuracy : 0.8345864661654135\n",
      "Epoch 12:\t train loss : 0.5814159099462933; train accuracy : 0.9702867401399778; \n",
      " validation loss : 0.6643087906031393; validation accuracy : 0.8796992481203008\n",
      "Epoch 13:\t train loss : 0.5930923995462868; train accuracy : 0.9579027870132708; \n",
      " validation loss : 0.7119667830692967; validation accuracy : 0.8345864661654135\n",
      "Epoch 14:\t train loss : 0.5815973476212645; train accuracy : 0.9698443356716927; \n",
      " validation loss : 0.7178313826943967; validation accuracy : 0.8270676691729323\n",
      "Epoch 15:\t train loss : 0.5826987247956664; train accuracy : 0.9689352484411312; \n",
      " validation loss : 0.7308419601743107; validation accuracy : 0.8120300751879699\n",
      "Epoch 16:\t train loss : 0.5759334167587709; train accuracy : 0.9755955937593994; \n",
      " validation loss : 0.687768361468552; validation accuracy : 0.849624060150376\n",
      "Epoch 17:\t train loss : 0.5723618193030965; train accuracy : 0.9789756718006266; \n",
      " validation loss : 0.7014095974717699; validation accuracy : 0.8571428571428571\n",
      "Epoch 18:\t train loss : 0.5669152348992909; train accuracy : 0.9848651812846725; \n",
      " validation loss : 0.6627706953360993; validation accuracy : 0.8796992481203008\n",
      "Epoch 19:\t train loss : 0.5616522882539324; train accuracy : 0.9900668057722992; \n",
      " validation loss : 0.6479922390785724; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5611961511056035; train accuracy : 0.9903952371382365; \n",
      " validation loss : 0.7051179903579603; validation accuracy : 0.8421052631578947\n",
      "Epoch 21:\t train loss : 0.5658020371671559; train accuracy : 0.9859435421761175; \n",
      " validation loss : 0.6664335704220015; validation accuracy : 0.8721804511278195\n",
      "Epoch 22:\t train loss : 0.5944574124271997; train accuracy : 0.9557528092009339; \n",
      " validation loss : 0.6793277668729296; validation accuracy : 0.8721804511278195\n",
      "Epoch 23:\t train loss : 0.5651091860914458; train accuracy : 0.98625106723334; \n",
      " validation loss : 0.7051019081666637; validation accuracy : 0.8421052631578947\n",
      "Epoch 24:\t train loss : 0.566626754502641; train accuracy : 0.9846716293297977; \n",
      " validation loss : 0.6705774586605066; validation accuracy : 0.8872180451127819\n",
      "Epoch 25:\t train loss : 0.560916432650823; train accuracy : 0.9905887890931113; \n",
      " validation loss : 0.6763795241049738; validation accuracy : 0.8646616541353384\n",
      "Epoch 26:\t train loss : 0.562662172748522; train accuracy : 0.9887881489554264; \n",
      " validation loss : 0.7253353469032021; validation accuracy : 0.8195488721804511\n",
      "Epoch 27:\t train loss : 0.5638281701136061; train accuracy : 0.987495329800392; \n",
      " validation loss : 0.6697725898627878; validation accuracy : 0.8872180451127819\n",
      "Epoch 28:\t train loss : 0.5767649772166902; train accuracy : 0.974389097427445; \n",
      " validation loss : 0.7118664097966554; validation accuracy : 0.8421052631578947\n",
      "Epoch 29:\t train loss : 0.5664658374527278; train accuracy : 0.9847889744174221; \n",
      " validation loss : 0.6832414433203344; validation accuracy : 0.8646616541353384\n",
      "Epoch 30:\t train loss : 0.5651011982405336; train accuracy : 0.9863373900564201; \n",
      " validation loss : 0.6746568211970786; validation accuracy : 0.8721804511278195\n",
      "Epoch 31:\t train loss : 0.5692709107912898; train accuracy : 0.9818303945357653; \n",
      " validation loss : 0.6972964700938533; validation accuracy : 0.849624060150376\n",
      "Epoch 32:\t train loss : 0.5605201025676094; train accuracy : 0.9905368605198522; \n",
      " validation loss : 0.6814745411750547; validation accuracy : 0.8721804511278195\n",
      "Epoch 33:\t train loss : 0.5615463265111509; train accuracy : 0.9896244013040142; \n",
      " validation loss : 0.6827910003723362; validation accuracy : 0.8646616541353384\n",
      "Epoch 34:\t train loss : 0.5603798699916176; train accuracy : 0.9911141443991999; \n",
      " validation loss : 0.6596091552147609; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.5649044849912805; train accuracy : 0.9865828705845539; \n",
      " validation loss : 0.680370790339025; validation accuracy : 0.8721804511278195\n",
      "Epoch 36:\t train loss : 0.565680650902786; train accuracy : 0.9853939085760376; \n",
      " validation loss : 0.6477189620757324; validation accuracy : 0.9172932330827067\n",
      "Epoch 37:\t train loss : 0.5559830594954628; train accuracy : 0.9956002336111399; \n",
      " validation loss : 0.65985504060383; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.5562314658920541; train accuracy : 0.9952131297013904; \n",
      " validation loss : 0.6660152883107759; validation accuracy : 0.8872180451127819\n",
      "Epoch 39:\t train loss : 0.5611584472753256; train accuracy : 0.9900701777575759; \n",
      " validation loss : 0.680558860939233; validation accuracy : 0.8646616541353384\n",
      "Epoch 40:\t train loss : 0.5559669383189231; train accuracy : 0.9955759553171487; \n",
      " validation loss : 0.6844920394274492; validation accuracy : 0.8721804511278195\n",
      "Epoch 41:\t train loss : 0.5593773357093103; train accuracy : 0.9919193744832433; \n",
      " validation loss : 0.684195968207202; validation accuracy : 0.849624060150376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:\t train loss : 0.5575231011058182; train accuracy : 0.9939688671343385; \n",
      " validation loss : 0.6593603274090654; validation accuracy : 0.8872180451127819\n",
      "Epoch 43:\t train loss : 0.5626046202177718; train accuracy : 0.9884286953249447; \n",
      " validation loss : 0.6660018204231732; validation accuracy : 0.8796992481203008\n",
      "Epoch 44:\t train loss : 0.5614994037894376; train accuracy : 0.9897660246856298; \n",
      " validation loss : 0.7087212913308627; validation accuracy : 0.8421052631578947\n",
      "Epoch 45:\t train loss : 0.5615046689104723; train accuracy : 0.9897801870237913; \n",
      " validation loss : 0.6907383551888957; validation accuracy : 0.8421052631578947\n",
      "Epoch 46:\t train loss : 0.5820245433333583; train accuracy : 0.9692050072632563; \n",
      " validation loss : 0.6907784322314912; validation accuracy : 0.8571428571428571\n",
      "Epoch 47:\t train loss : 0.5704425122994565; train accuracy : 0.980348069808188; \n",
      " validation loss : 0.7161595111067228; validation accuracy : 0.8345864661654135\n",
      "Epoch 48:\t train loss : 0.5685783950209049; train accuracy : 0.9826841812077912; \n",
      " validation loss : 0.6629679671663927; validation accuracy : 0.8872180451127819\n",
      "Epoch 49:\t train loss : 0.5623443531795093; train accuracy : 0.9889196563812124; \n",
      " validation loss : 0.7100165338692218; validation accuracy : 0.8345864661654135\n",
      "Epoch 50:\t train loss : 0.6112001567294544; train accuracy : 0.9385475915257964; \n",
      " validation loss : 0.6469256628472336; validation accuracy : 0.9022556390977443\n",
      "Epoch 51:\t train loss : 0.5710270095262231; train accuracy : 0.9798571087519203; \n",
      " validation loss : 0.664298364997894; validation accuracy : 0.8872180451127819\n",
      "Epoch 52:\t train loss : 0.5598407617582191; train accuracy : 0.9913663688978869; \n",
      " validation loss : 0.6963337405831768; validation accuracy : 0.849624060150376\n",
      "Epoch 53:\t train loss : 0.5610987620295147; train accuracy : 0.9901565005806559; \n",
      " validation loss : 0.6868914970893525; validation accuracy : 0.8646616541353384\n",
      "Epoch 54:\t train loss : 0.5585899831690159; train accuracy : 0.9927077446409038; \n",
      " validation loss : 0.687391897948123; validation accuracy : 0.8646616541353384\n",
      "Epoch 55:\t train loss : 0.5580059365735556; train accuracy : 0.9934711621075177; \n",
      " validation loss : 0.6753956004806778; validation accuracy : 0.8796992481203008\n",
      "Epoch 56:\t train loss : 0.5550090229857199; train accuracy : 0.9963744414306389; \n",
      " validation loss : 0.6817795473049182; validation accuracy : 0.8646616541353384\n",
      "Epoch 57:\t train loss : 0.5560811009784493; train accuracy : 0.9953271028037383; \n",
      " validation loss : 0.7166378364838206; validation accuracy : 0.8345864661654135\n",
      "Epoch 58:\t train loss : 0.556547708313621; train accuracy : 0.9948260257916409; \n",
      " validation loss : 0.6717521059097351; validation accuracy : 0.8872180451127819\n",
      "Epoch 59:\t train loss : 0.5588062039771918; train accuracy : 0.9925519589211266; \n",
      " validation loss : 0.6524218933904906; validation accuracy : 0.8947368421052632\n",
      "Epoch 60:\t train loss : 0.5611879927901424; train accuracy : 0.9900634337870227; \n",
      " validation loss : 0.6839819812015507; validation accuracy : 0.8646616541353384\n",
      "Epoch 61:\t train loss : 0.5768127721092541; train accuracy : 0.9737740473129998; \n",
      " validation loss : 0.7009087231791409; validation accuracy : 0.849624060150376\n",
      "Epoch 62:\t train loss : 0.5710787689554303; train accuracy : 0.9798328304579291; \n",
      " validation loss : 0.7081731340231695; validation accuracy : 0.849624060150376\n",
      "Epoch 63:\t train loss : 0.5573466253914955; train accuracy : 0.9939378448697942; \n",
      " validation loss : 0.6948234889645433; validation accuracy : 0.8571428571428571\n",
      "Epoch 64:\t train loss : 0.5549070600355516; train accuracy : 0.9963744414306389; \n",
      " validation loss : 0.6493134215810704; validation accuracy : 0.9022556390977443\n",
      "Epoch 65:\t train loss : 0.5538425334673185; train accuracy : 0.9976429822916821; \n",
      " validation loss : 0.6569311938736595; validation accuracy : 0.8947368421052632\n",
      "Epoch 66:\t train loss : 0.5604318329899131; train accuracy : 0.9906784839014678; \n",
      " validation loss : 0.6892825514778784; validation accuracy : 0.849624060150376\n",
      "Epoch 67:\t train loss : 0.5561273044128493; train accuracy : 0.9953547530830061; \n",
      " validation loss : 0.6861454918805618; validation accuracy : 0.8646616541353384\n",
      "Epoch 68:\t train loss : 0.5540157678123594; train accuracy : 0.9974804526013518; \n",
      " validation loss : 0.636235179905604; validation accuracy : 0.9097744360902256\n",
      "Epoch 69:\t train loss : 0.5547916248636375; train accuracy : 0.9967062447818528; \n",
      " validation loss : 0.7008092595281881; validation accuracy : 0.849624060150376\n",
      "Epoch 70:\t train loss : 0.5586198892217463; train accuracy : 0.9927697891699926; \n",
      " validation loss : 0.6619541827985851; validation accuracy : 0.8947368421052632\n",
      "Epoch 71:\t train loss : 0.5851338747074855; train accuracy : 0.9659766685594744; \n",
      " validation loss : 0.7265486749288954; validation accuracy : 0.8270676691729323\n",
      "Epoch 72:\t train loss : 0.5878893067904061; train accuracy : 0.9625770330036431; \n",
      " validation loss : 0.7876147247831443; validation accuracy : 0.7593984962406015\n",
      "Epoch 73:\t train loss : 0.6872765268902309; train accuracy : 0.8604638772705263; \n",
      " validation loss : 0.6858211147682824; validation accuracy : 0.8646616541353384\n",
      "Epoch 74:\t train loss : 0.6294357003903485; train accuracy : 0.919766307932393; \n",
      " validation loss : 0.6864647766717933; validation accuracy : 0.8571428571428571\n",
      "Epoch 75:\t train loss : 0.6003214987137913; train accuracy : 0.9502335437002548; \n",
      " validation loss : 0.7089974738962571; validation accuracy : 0.8345864661654135\n",
      "Epoch 76:\t train loss : 0.6007185143942579; train accuracy : 0.9494074073074967; \n",
      " validation loss : 0.6688681210941897; validation accuracy : 0.8721804511278195\n",
      "Epoch 77:\t train loss : 0.5807846043956241; train accuracy : 0.9700689098911118; \n",
      " validation loss : 0.681135414855557; validation accuracy : 0.8721804511278195\n",
      "Epoch 78:\t train loss : 0.5798409461953308; train accuracy : 0.9707911891373517; \n",
      " validation loss : 0.6399849741930405; validation accuracy : 0.9097744360902256\n",
      "Epoch 79:\t train loss : 0.5713306862472493; train accuracy : 0.9800162664569741; \n",
      " validation loss : 0.6237629861155652; validation accuracy : 0.924812030075188\n",
      "Epoch 80:\t train loss : 0.5749920233343428; train accuracy : 0.9760379982276846; \n",
      " validation loss : 0.647031082432562; validation accuracy : 0.9097744360902256\n",
      "Epoch 81:\t train loss : 0.5713779430643617; train accuracy : 0.9797363916790194; \n",
      " validation loss : 0.675821878051829; validation accuracy : 0.8796992481203008\n",
      "Epoch 82:\t train loss : 0.5672745394927011; train accuracy : 0.9837382638052449; \n",
      " validation loss : 0.636431577879484; validation accuracy : 0.9172932330827067\n",
      "Epoch 83:\t train loss : 0.5639689084062264; train accuracy : 0.9873328001100616; \n",
      " validation loss : 0.6308997049854288; validation accuracy : 0.9172932330827067\n",
      "Epoch 84:\t train loss : 0.5601698304931112; train accuracy : 0.9912834180600834; \n",
      " validation loss : 0.6481972016137921; validation accuracy : 0.9022556390977443\n",
      "Epoch 85:\t train loss : 0.5614140970579958; train accuracy : 0.9899946452873808; \n",
      " validation loss : 0.6765786650735988; validation accuracy : 0.8721804511278195\n",
      "Epoch 86:\t train loss : 0.5677140360059418; train accuracy : 0.9835413398650936; \n",
      " validation loss : 0.6524471840206656; validation accuracy : 0.8947368421052632\n",
      "Epoch 87:\t train loss : 0.5739436518376836; train accuracy : 0.9770543145900408; \n",
      " validation loss : 0.7042953084592283; validation accuracy : 0.8345864661654135\n",
      "Epoch 88:\t train loss : 0.5839952777936204; train accuracy : 0.9666955758204377; \n",
      " validation loss : 0.6719829429345683; validation accuracy : 0.8796992481203008\n",
      "Epoch 89:\t train loss : 0.5681792687828576; train accuracy : 0.9830645411469875; \n",
      " validation loss : 0.6637711907501206; validation accuracy : 0.8872180451127819\n",
      "Epoch 90:\t train loss : 0.5681552987138657; train accuracy : 0.9830470068235494; \n",
      " validation loss : 0.6466312785664255; validation accuracy : 0.9022556390977443\n",
      "Epoch 91:\t train loss : 0.5668176171929856; train accuracy : 0.9847026515943421; \n",
      " validation loss : 0.6275548309774907; validation accuracy : 0.9172932330827067\n",
      "Epoch 92:\t train loss : 0.5680371229766862; train accuracy : 0.9828811051479425; \n",
      " validation loss : 0.6821881352223551; validation accuracy : 0.8721804511278195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93:\t train loss : 0.5628131548720819; train accuracy : 0.9883524884576944; \n",
      " validation loss : 0.6396779124373022; validation accuracy : 0.9097744360902256\n",
      "Epoch 94:\t train loss : 0.5634529091664837; train accuracy : 0.9876302092114545; \n",
      " validation loss : 0.646276218630264; validation accuracy : 0.9022556390977443\n",
      "Epoch 95:\t train loss : 0.5626920122420724; train accuracy : 0.9885116461627482; \n",
      " validation loss : 0.6466684458177668; validation accuracy : 0.9022556390977443\n",
      "Epoch 96:\t train loss : 0.5622099025973792; train accuracy : 0.9887328483968908; \n",
      " validation loss : 0.6654245104739721; validation accuracy : 0.8872180451127819\n",
      "Epoch 97:\t train loss : 0.5665454334894928; train accuracy : 0.9844814493601995; \n",
      " validation loss : 0.6545513075960254; validation accuracy : 0.8872180451127819\n",
      "Epoch 98:\t train loss : 0.5623151724381933; train accuracy : 0.9887638706614351; \n",
      " validation loss : 0.65583281606644; validation accuracy : 0.8947368421052632\n",
      "Epoch 99:\t train loss : 0.5606053352137509; train accuracy : 0.9905678827843966; \n",
      " validation loss : 0.6625265983611707; validation accuracy : 0.8872180451127819\n",
      "Epoch 100:\t train loss : 0.5596477678814112; train accuracy : 0.9916738939551094; \n",
      " validation loss : 0.6310141582439132; validation accuracy : 0.9172932330827067\n",
      "Epoch 101:\t train loss : 0.5610686562236864; train accuracy : 0.9902016851833618; \n",
      " validation loss : 0.6829394051643616; validation accuracy : 0.8646616541353384\n",
      "Epoch 102:\t train loss : 0.5580316649024093; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.6487395190833097; validation accuracy : 0.8947368421052632\n",
      "Epoch 103:\t train loss : 0.5559864204974805; train accuracy : 0.9954896324940686; \n",
      " validation loss : 0.6039072969527977; validation accuracy : 0.9473684210526315\n",
      "Epoch 104:\t train loss : 0.5587293025964596; train accuracy : 0.9925553309064031; \n",
      " validation loss : 0.652764106330378; validation accuracy : 0.8947368421052632\n",
      "Epoch 105:\t train loss : 0.5571844595890685; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.6353908652621783; validation accuracy : 0.9172932330827067\n",
      "Epoch 106:\t train loss : 0.5555835759033133; train accuracy : 0.995869992433265; \n",
      " validation loss : 0.6332274289383398; validation accuracy : 0.9172932330827067\n",
      "Epoch 107:\t train loss : 0.5560357358199884; train accuracy : 0.9952859645833643; \n",
      " validation loss : 0.6124627127045403; validation accuracy : 0.9323308270676691\n",
      "Epoch 108:\t train loss : 0.557566695297604; train accuracy : 0.993879172325982; \n",
      " validation loss : 0.6569439042364535; validation accuracy : 0.8947368421052632\n",
      "Epoch 109:\t train loss : 0.564194366792366; train accuracy : 0.986807444803973; \n",
      " validation loss : 0.6366435811488325; validation accuracy : 0.9097744360902256\n",
      "Epoch 110:\t train loss : 0.5711285023310507; train accuracy : 0.9801437275004282; \n",
      " validation loss : 0.6433585739697149; validation accuracy : 0.9022556390977443\n",
      "Epoch 111:\t train loss : 0.5599387058108327; train accuracy : 0.991418297471146; \n",
      " validation loss : 0.6264303147616616; validation accuracy : 0.924812030075188\n",
      "Epoch 112:\t train loss : 0.5655556222634398; train accuracy : 0.9856117388249036; \n",
      " validation loss : 0.6397359490080258; validation accuracy : 0.9172932330827067\n",
      "Epoch 113:\t train loss : 0.5623701022621103; train accuracy : 0.9887739866172648; \n",
      " validation loss : 0.6496885506100594; validation accuracy : 0.9022556390977443\n",
      "Epoch 114:\t train loss : 0.5590042330445125; train accuracy : 0.9922754561284484; \n",
      " validation loss : 0.6198937506181487; validation accuracy : 0.9323308270676691\n",
      "Epoch 115:\t train loss : 0.5580110952375521; train accuracy : 0.9930773142272151; \n",
      " validation loss : 0.6675758920042953; validation accuracy : 0.8872180451127819\n",
      "Epoch 116:\t train loss : 0.5608915270432477; train accuracy : 0.9902671016977271; \n",
      " validation loss : 0.6348320336974523; validation accuracy : 0.9172932330827067\n",
      "Epoch 117:\t train loss : 0.5570401931580861; train accuracy : 0.994355971044088; \n",
      " validation loss : 0.6800750461155712; validation accuracy : 0.8721804511278195\n",
      "Epoch 118:\t train loss : 0.5582865220730909; train accuracy : 0.9931359867710273; \n",
      " validation loss : 0.6822663618974687; validation accuracy : 0.8721804511278195\n",
      "Epoch 119:\t train loss : 0.5594617620487687; train accuracy : 0.9918883522186989; \n",
      " validation loss : 0.6804121643986831; validation accuracy : 0.8721804511278195\n",
      "Epoch 120:\t train loss : 0.5622028423349689; train accuracy : 0.9892339254089881; \n",
      " validation loss : 0.6624590084241672; validation accuracy : 0.8872180451127819\n",
      "Epoch 121:\t train loss : 0.5612563648678546; train accuracy : 0.9899251823906836; \n",
      " validation loss : 0.6501615427229798; validation accuracy : 0.9022556390977443\n",
      "Epoch 122:\t train loss : 0.5721050603276389; train accuracy : 0.978920371242091; \n",
      " validation loss : 0.6562438867328864; validation accuracy : 0.8947368421052632\n",
      "Epoch 123:\t train loss : 0.580372791866651; train accuracy : 0.9703076464486925; \n",
      " validation loss : 0.635246659809636; validation accuracy : 0.9172932330827067\n",
      "Epoch 124:\t train loss : 0.5773948733088425; train accuracy : 0.9734354999912328; \n",
      " validation loss : 0.7162671398672454; validation accuracy : 0.8270676691729323\n",
      "Epoch 125:\t train loss : 0.5684713728615707; train accuracy : 0.9825978583847111; \n",
      " validation loss : 0.6793978118646671; validation accuracy : 0.8721804511278195\n",
      "Epoch 126:\t train loss : 0.5938660842939938; train accuracy : 0.95659647991713; \n",
      " validation loss : 0.6477918851519682; validation accuracy : 0.9022556390977443\n",
      "Epoch 127:\t train loss : 0.5610934902286966; train accuracy : 0.990225963477353; \n",
      " validation loss : 0.6355837081101945; validation accuracy : 0.9172932330827067\n",
      "Epoch 128:\t train loss : 0.5613670299098119; train accuracy : 0.9901187343455583; \n",
      " validation loss : 0.6467321524766619; validation accuracy : 0.9022556390977443\n",
      "Epoch 129:\t train loss : 0.5593396705020923; train accuracy : 0.991895096189252; \n",
      " validation loss : 0.6555722725835661; validation accuracy : 0.8947368421052632\n",
      "Epoch 130:\t train loss : 0.5556870925476334; train accuracy : 0.9957384850074791; \n",
      " validation loss : 0.6468714285934094; validation accuracy : 0.9022556390977443\n",
      "Epoch 131:\t train loss : 0.5558842279828027; train accuracy : 0.9955483050378808; \n",
      " validation loss : 0.5988336713534081; validation accuracy : 0.9548872180451128\n",
      "Epoch 132:\t train loss : 0.5577079974164617; train accuracy : 0.9935783912393125; \n",
      " validation loss : 0.6881443415000561; validation accuracy : 0.8646616541353384\n",
      "Epoch 133:\t train loss : 0.5562683136691953; train accuracy : 0.9951821074368461; \n",
      " validation loss : 0.6432709086689883; validation accuracy : 0.9022556390977443\n",
      "Epoch 134:\t train loss : 0.557354492178933; train accuracy : 0.9939101945905263; \n",
      " validation loss : 0.6514579929554519; validation accuracy : 0.9022556390977443\n",
      "Epoch 135:\t train loss : 0.5588227366542101; train accuracy : 0.9924723800685996; \n",
      " validation loss : 0.6323963850250933; validation accuracy : 0.9172932330827067\n",
      "Epoch 136:\t train loss : 0.5567463158917293; train accuracy : 0.9945218727196949; \n",
      " validation loss : 0.639867695591589; validation accuracy : 0.9097744360902256\n",
      "Epoch 137:\t train loss : 0.5563010107099718; train accuracy : 0.9950404840552304; \n",
      " validation loss : 0.6266904921011298; validation accuracy : 0.924812030075188\n",
      "Epoch 138:\t train loss : 0.5554103928123391; train accuracy : 0.9960392660941485; \n",
      " validation loss : 0.632397624099195; validation accuracy : 0.924812030075188\n",
      "Epoch 139:\t train loss : 0.5580561459620145; train accuracy : 0.9931393587563039; \n",
      " validation loss : 0.656110215376054; validation accuracy : 0.8872180451127819\n",
      "Epoch 140:\t train loss : 0.5554848270920995; train accuracy : 0.9959252929918007; \n",
      " validation loss : 0.6903949594509852; validation accuracy : 0.8646616541353384\n",
      "Epoch 141:\t train loss : 0.558913349424867; train accuracy : 0.9924137075247874; \n",
      " validation loss : 0.6704424349841493; validation accuracy : 0.8721804511278195\n",
      "Epoch 142:\t train loss : 0.5615319757283338; train accuracy : 0.9898975321114157; \n",
      " validation loss : 0.6402030274135162; validation accuracy : 0.9097744360902256\n",
      "Epoch 143:\t train loss : 0.557544131191086; train accuracy : 0.993799593473455; \n",
      " validation loss : 0.6478829116754987; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144:\t train loss : 0.5562868417951992; train accuracy : 0.9950715063197748; \n",
      " validation loss : 0.6507427987863527; validation accuracy : 0.8947368421052632\n",
      "Epoch 145:\t train loss : 0.5761126172774209; train accuracy : 0.9749353590422483; \n",
      " validation loss : 0.6712974541834565; validation accuracy : 0.8796992481203008\n",
      "Epoch 146:\t train loss : 0.5893084115243123; train accuracy : 0.9612761210839449; \n",
      " validation loss : 0.6961282041417374; validation accuracy : 0.8571428571428571\n",
      "Epoch 147:\t train loss : 0.5749523694430072; train accuracy : 0.976155343315309; \n",
      " validation loss : 0.6661763973242776; validation accuracy : 0.8872180451127819\n",
      "Epoch 148:\t train loss : 0.5641379198047141; train accuracy : 0.9870495533468303; \n",
      " validation loss : 0.6194169324197477; validation accuracy : 0.924812030075188\n",
      "Epoch 149:\t train loss : 0.5865464179314434; train accuracy : 0.9644626471702974; \n",
      " validation loss : 0.626017230520754; validation accuracy : 0.924812030075188\n",
      "Epoch 150:\t train loss : 0.57693512419917; train accuracy : 0.9739433209738833; \n",
      " validation loss : 0.6985826435387748; validation accuracy : 0.8571428571428571\n",
      "Epoch 151:\t train loss : 0.5704137594376547; train accuracy : 0.980721011379776; \n",
      " validation loss : 0.6642402369929684; validation accuracy : 0.8872180451127819\n",
      "Epoch 152:\t train loss : 0.5641448551150272; train accuracy : 0.9871878047431694; \n",
      " validation loss : 0.6259176259226753; validation accuracy : 0.924812030075188\n",
      "Epoch 153:\t train loss : 0.5637776142407344; train accuracy : 0.9875540023442042; \n",
      " validation loss : 0.6419333312952302; validation accuracy : 0.9097744360902256\n",
      "Epoch 154:\t train loss : 0.5577454614526252; train accuracy : 0.9936370637831247; \n",
      " validation loss : 0.6204953521458515; validation accuracy : 0.9323308270676691\n",
      "Epoch 155:\t train loss : 0.5580354898030172; train accuracy : 0.9932189376088308; \n",
      " validation loss : 0.639792132698705; validation accuracy : 0.9097744360902256\n",
      "Epoch 156:\t train loss : 0.5582377123438582; train accuracy : 0.9930530359332239; \n",
      " validation loss : 0.6462255037629049; validation accuracy : 0.8947368421052632\n",
      "Epoch 157:\t train loss : 0.557611115814222; train accuracy : 0.993747664900196; \n",
      " validation loss : 0.6614145845934148; validation accuracy : 0.8872180451127819\n",
      "Epoch 158:\t train loss : 0.5567665316234263; train accuracy : 0.9945771732782306; \n",
      " validation loss : 0.6684561658140151; validation accuracy : 0.8796992481203008\n",
      "Epoch 159:\t train loss : 0.5566487348489608; train accuracy : 0.9947983755123732; \n",
      " validation loss : 0.638851014600093; validation accuracy : 0.9097744360902256\n",
      "Epoch 160:\t train loss : 0.5694414791051887; train accuracy : 0.9817305837715791; \n",
      " validation loss : 0.6798231967325544; validation accuracy : 0.8646616541353384\n",
      "Epoch 161:\t train loss : 0.561763176955973; train accuracy : 0.9895623567749253; \n",
      " validation loss : 0.611108301989336; validation accuracy : 0.9398496240601504\n",
      "Epoch 162:\t train loss : 0.5561641130077241; train accuracy : 0.995348009112453; \n",
      " validation loss : 0.6253811666230387; validation accuracy : 0.924812030075188\n",
      "Epoch 163:\t train loss : 0.556486553058555; train accuracy : 0.9948503040856322; \n",
      " validation loss : 0.660689388181071; validation accuracy : 0.8947368421052632\n",
      "Epoch 164:\t train loss : 0.5605470442959386; train accuracy : 0.9907546907687182; \n",
      " validation loss : 0.6893093595100002; validation accuracy : 0.849624060150376\n",
      "Epoch 165:\t train loss : 0.557155790887827; train accuracy : 0.9942352539711871; \n",
      " validation loss : 0.6499278874375424; validation accuracy : 0.9022556390977443\n",
      "Epoch 166:\t train loss : 0.556286040492163; train accuracy : 0.9950748783050514; \n",
      " validation loss : 0.6772004296963371; validation accuracy : 0.8721804511278195\n",
      "Epoch 167:\t train loss : 0.5565089309361831; train accuracy : 0.9949332549234357; \n",
      " validation loss : 0.6288029490554529; validation accuracy : 0.924812030075188\n",
      "Epoch 168:\t train loss : 0.5595596301060147; train accuracy : 0.9916118494260207; \n",
      " validation loss : 0.671014014814675; validation accuracy : 0.8796992481203008\n",
      "Epoch 169:\t train loss : 0.565801219384503; train accuracy : 0.985304213767681; \n",
      " validation loss : 0.6499223550349054; validation accuracy : 0.9022556390977443\n",
      "Epoch 170:\t train loss : 0.5704467179507461; train accuracy : 0.9805584816894456; \n",
      " validation loss : 0.6392832093771487; validation accuracy : 0.9097744360902256\n",
      "Epoch 171:\t train loss : 0.5613912409073176; train accuracy : 0.9898732538174245; \n",
      " validation loss : 0.6530268835222123; validation accuracy : 0.8947368421052632\n",
      "Epoch 172:\t train loss : 0.5560097348257013; train accuracy : 0.9953790313769973; \n",
      " validation loss : 0.6195953297353884; validation accuracy : 0.9323308270676691\n",
      "Epoch 173:\t train loss : 0.5554121426785429; train accuracy : 0.9959320369623538; \n",
      " validation loss : 0.6548659277174136; validation accuracy : 0.8947368421052632\n",
      "Epoch 174:\t train loss : 0.5544538015401541; train accuracy : 0.9969861195598075; \n",
      " validation loss : 0.593903372410725; validation accuracy : 0.9624060150375939\n",
      "Epoch 175:\t train loss : 0.5554005961577754; train accuracy : 0.9959873375208894; \n",
      " validation loss : 0.6435290710528732; validation accuracy : 0.9097744360902256\n",
      "Epoch 176:\t train loss : 0.555895633416576; train accuracy : 0.99551391078806; \n",
      " validation loss : 0.6244929575847115; validation accuracy : 0.924812030075188\n",
      "Epoch 177:\t train loss : 0.5545657542286846; train accuracy : 0.9968411241929153; \n",
      " validation loss : 0.6413824622571738; validation accuracy : 0.9097744360902256\n",
      "Epoch 178:\t train loss : 0.5544817802129276; train accuracy : 0.9969793755892544; \n",
      " validation loss : 0.5972685154838355; validation accuracy : 0.9548872180451128\n",
      "Epoch 179:\t train loss : 0.5579721626873624; train accuracy : 0.9934158615489821; \n",
      " validation loss : 0.6427756137338015; validation accuracy : 0.9097744360902256\n",
      "Epoch 180:\t train loss : 0.5563225959356306; train accuracy : 0.9950748783050514; \n",
      " validation loss : 0.5990912360955902; validation accuracy : 0.9548872180451128\n",
      "Epoch 181:\t train loss : 0.5541316816339453; train accuracy : 0.9973145509257448; \n",
      " validation loss : 0.6207937713495044; validation accuracy : 0.9323308270676691\n",
      "Epoch 182:\t train loss : 0.5547936414050604; train accuracy : 0.9966475722380406; \n",
      " validation loss : 0.6115197408011502; validation accuracy : 0.9398496240601504\n",
      "Epoch 183:\t train loss : 0.5541137749403325; train accuracy : 0.9972282281026648; \n",
      " validation loss : 0.6295826943661079; validation accuracy : 0.9172932330827067\n",
      "Epoch 184:\t train loss : 0.5700043466682284; train accuracy : 0.9809698638931863; \n",
      " validation loss : 0.611576332132618; validation accuracy : 0.9398496240601504\n",
      "Epoch 185:\t train loss : 0.5902748862771432; train accuracy : 0.9605889104845813; \n",
      " validation loss : 0.6794241320665051; validation accuracy : 0.8721804511278195\n",
      "Epoch 186:\t train loss : 0.7003022038843402; train accuracy : 0.8492452822553995; \n",
      " validation loss : 0.7962321511137332; validation accuracy : 0.7518796992481203\n",
      "Epoch 187:\t train loss : 0.7005370221867323; train accuracy : 0.8486329297291756; \n",
      " validation loss : 0.6792794097228027; validation accuracy : 0.8721804511278195\n",
      "Epoch 188:\t train loss : 0.6544416723862967; train accuracy : 0.8956107542052029; \n",
      " validation loss : 0.7063974465021756; validation accuracy : 0.8421052631578947\n",
      "Epoch 189:\t train loss : 0.6205372351294093; train accuracy : 0.9295443908373718; \n",
      " validation loss : 0.6618236953194633; validation accuracy : 0.8947368421052632\n",
      "Epoch 190:\t train loss : 0.6065399632662052; train accuracy : 0.9441019256733517; \n",
      " validation loss : 0.708034179191373; validation accuracy : 0.8421052631578947\n",
      "Epoch 191:\t train loss : 0.5978491289301335; train accuracy : 0.9523073146453414; \n",
      " validation loss : 0.6654548560449979; validation accuracy : 0.8872180451127819\n",
      "Epoch 192:\t train loss : 0.5977865025697023; train accuracy : 0.9529500150390543; \n",
      " validation loss : 0.6982838091776342; validation accuracy : 0.849624060150376\n",
      "Epoch 193:\t train loss : 0.5862861349797024; train accuracy : 0.9645354820522711; \n",
      " validation loss : 0.6444988817689631; validation accuracy : 0.9022556390977443\n",
      "Epoch 194:\t train loss : 0.5776500948631813; train accuracy : 0.9730895343018574; \n",
      " validation loss : 0.6548700883893713; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195:\t train loss : 0.5781160685882253; train accuracy : 0.9727233367008227; \n",
      " validation loss : 0.6551246358615079; validation accuracy : 0.8947368421052632\n",
      "Epoch 196:\t train loss : 0.5711481244635014; train accuracy : 0.9800816829713395; \n",
      " validation loss : 0.656381458498377; validation accuracy : 0.8947368421052632\n",
      "Epoch 197:\t train loss : 0.568888953505461; train accuracy : 0.982494001238193; \n",
      " validation loss : 0.6505354392266922; validation accuracy : 0.8947368421052632\n",
      "Epoch 198:\t train loss : 0.5663022431557776; train accuracy : 0.9849481321224759; \n",
      " validation loss : 0.6292762919616398; validation accuracy : 0.924812030075188\n",
      "Epoch 199:\t train loss : 0.5704785981959698; train accuracy : 0.9804863212045271; \n",
      " validation loss : 0.6145780335069937; validation accuracy : 0.9398496240601504\n",
      "Epoch 200:\t train loss : 0.5663865604864371; train accuracy : 0.9848442749759577; \n",
      " validation loss : 0.6263133502682112; validation accuracy : 0.924812030075188\n",
      "Epoch 201:\t train loss : 0.5686108190523718; train accuracy : 0.9825425578261755; \n",
      " validation loss : 0.6567254202948264; validation accuracy : 0.8947368421052632\n",
      "Epoch 202:\t train loss : 0.5658070320746983; train accuracy : 0.9855153000459939; \n",
      " validation loss : 0.6769814200444684; validation accuracy : 0.8721804511278195\n",
      "Epoch 203:\t train loss : 0.5845078740829229; train accuracy : 0.9663293782194029; \n",
      " validation loss : 0.6875305770710775; validation accuracy : 0.8571428571428571\n",
      "Epoch 204:\t train loss : 0.5693288442702372; train accuracy : 0.9817440717126853; \n",
      " validation loss : 0.620266672449962; validation accuracy : 0.9323308270676691\n",
      "Epoch 205:\t train loss : 0.5664632825642185; train accuracy : 0.9847788584615924; \n",
      " validation loss : 0.6429332787531555; validation accuracy : 0.9097744360902256\n",
      "Epoch 206:\t train loss : 0.5619404985400679; train accuracy : 0.9893411545407828; \n",
      " validation loss : 0.6203590527964901; validation accuracy : 0.9323308270676691\n",
      "Epoch 207:\t train loss : 0.562181228020086; train accuracy : 0.9890403734541133; \n",
      " validation loss : 0.602768736519877; validation accuracy : 0.9473684210526315\n",
      "Epoch 208:\t train loss : 0.559949933329545; train accuracy : 0.9913144403246278; \n",
      " validation loss : 0.6282836676337066; validation accuracy : 0.9172932330827067\n",
      "Epoch 209:\t train loss : 0.5588218597026866; train accuracy : 0.9925587028916797; \n",
      " validation loss : 0.6398019675655037; validation accuracy : 0.9097744360902256\n",
      "Epoch 210:\t train loss : 0.5612890112239571; train accuracy : 0.9898321155970504; \n",
      " validation loss : 0.6843623813237926; validation accuracy : 0.8646616541353384\n",
      "Epoch 211:\t train loss : 0.5638676359398096; train accuracy : 0.9873226841542319; \n",
      " validation loss : 0.6134912390155912; validation accuracy : 0.9323308270676691\n",
      "Epoch 212:\t train loss : 0.561910787956705; train accuracy : 0.9895414504662107; \n",
      " validation loss : 0.6369731841821834; validation accuracy : 0.9172932330827067\n",
      "Epoch 213:\t train loss : 0.5633807133009843; train accuracy : 0.9879552685921152; \n",
      " validation loss : 0.6402541085899873; validation accuracy : 0.9097744360902256\n",
      "Epoch 214:\t train loss : 0.55913422169888; train accuracy : 0.9921958772759214; \n",
      " validation loss : 0.645656468158547; validation accuracy : 0.9097744360902256\n",
      "Epoch 215:\t train loss : 0.5594851256418486; train accuracy : 0.9918397956307163; \n",
      " validation loss : 0.6346382800688577; validation accuracy : 0.9172932330827067\n",
      "Epoch 216:\t train loss : 0.5633301125643286; train accuracy : 0.9877475542990789; \n",
      " validation loss : 0.6187368553710523; validation accuracy : 0.9323308270676691\n",
      "Epoch 217:\t train loss : 0.5599909561319575; train accuracy : 0.9914493197356903; \n",
      " validation loss : 0.6242990288373957; validation accuracy : 0.924812030075188\n",
      "Epoch 218:\t train loss : 0.5594059623825373; train accuracy : 0.9918917242039754; \n",
      " validation loss : 0.6355401120672632; validation accuracy : 0.9172932330827067\n",
      "Epoch 219:\t train loss : 0.5612923879748634; train accuracy : 0.9899359727435686; \n",
      " validation loss : 0.6527559413594397; validation accuracy : 0.9022556390977443\n",
      "Epoch 220:\t train loss : 0.567615867564091; train accuracy : 0.983624290702897; \n",
      " validation loss : 0.632636916414864; validation accuracy : 0.9172932330827067\n",
      "Epoch 221:\t train loss : 0.5707276210728593; train accuracy : 0.9804202302931064; \n",
      " validation loss : 0.6303267424185913; validation accuracy : 0.9172932330827067\n",
      "Epoch 222:\t train loss : 0.565350448076167; train accuracy : 0.9857466182359661; \n",
      " validation loss : 0.6194750008362343; validation accuracy : 0.9323308270676691\n",
      "Epoch 223:\t train loss : 0.5614989324180767; train accuracy : 0.9899285543759602; \n",
      " validation loss : 0.6122962618809359; validation accuracy : 0.9398496240601504\n",
      "Epoch 224:\t train loss : 0.5617826769208571; train accuracy : 0.9893202482320681; \n",
      " validation loss : 0.640340738538714; validation accuracy : 0.9097744360902256\n",
      "Early stopping at epoch 224\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5544538015401541; Train accuracy : 0.9969861195598075; \n",
      " Validation loss : 0.593903372410725; Validation accuracy : 0.9624060150375939\n",
      "------------------------------ Let's train model 4 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9087077456304694; train accuracy : 0.6210401090904677; \n",
      " validation loss : 0.8621181326025271; validation accuracy : 0.6766917293233082\n",
      "Epoch 2:\t train loss : 0.7807396708898782; train accuracy : 0.763749944362243; \n",
      " validation loss : 0.7479483335865026; validation accuracy : 0.8045112781954887\n",
      "Epoch 3:\t train loss : 0.7258063046496779; train accuracy : 0.8235851486978067; \n",
      " validation loss : 0.7063759863044353; validation accuracy : 0.8120300751879699\n",
      "Epoch 4:\t train loss : 0.6907139558545538; train accuracy : 0.8581446257973059; \n",
      " validation loss : 0.7339388451148089; validation accuracy : 0.8045112781954887\n",
      "Epoch 5:\t train loss : 0.6598393435767724; train accuracy : 0.8901319525278425; \n",
      " validation loss : 0.6544704380920866; validation accuracy : 0.8947368421052632\n",
      "Epoch 6:\t train loss : 0.6292707164385678; train accuracy : 0.9217638720102292; \n",
      " validation loss : 0.682133954202219; validation accuracy : 0.8646616541353384\n",
      "Epoch 7:\t train loss : 0.6158548535787967; train accuracy : 0.935620033908684; \n",
      " validation loss : 0.6403690082807705; validation accuracy : 0.9097744360902256\n",
      "Epoch 8:\t train loss : 0.6191858422832931; train accuracy : 0.9317247165171978; \n",
      " validation loss : 0.6106879798050044; validation accuracy : 0.9398496240601504\n",
      "Epoch 9:\t train loss : 0.6097732016949928; train accuracy : 0.941029372689347; \n",
      " validation loss : 0.6312359729228192; validation accuracy : 0.9097744360902256\n",
      "Epoch 10:\t train loss : 0.5948125140568699; train accuracy : 0.9567724975485667; \n",
      " validation loss : 0.6494744058812776; validation accuracy : 0.8947368421052632\n",
      "Epoch 11:\t train loss : 0.5994322965638965; train accuracy : 0.951795447280359; \n",
      " validation loss : 0.645020524023748; validation accuracy : 0.9097744360902256\n",
      "Epoch 12:\t train loss : 0.5988945387289368; train accuracy : 0.9517401467218234; \n",
      " validation loss : 0.6226626248277185; validation accuracy : 0.9323308270676691\n",
      "Epoch 13:\t train loss : 0.5831150691198881; train accuracy : 0.9683822428557748; \n",
      " validation loss : 0.6576517057481662; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.5810413640104586; train accuracy : 0.9706529377410127; \n",
      " validation loss : 0.6641761846226995; validation accuracy : 0.8796992481203008\n",
      "Epoch 15:\t train loss : 0.5924107299306222; train accuracy : 0.9586284382447873; \n",
      " validation loss : 0.6485256494577826; validation accuracy : 0.8947368421052632\n",
      "Epoch 16:\t train loss : 0.5854658691002543; train accuracy : 0.9653993846801268; \n",
      " validation loss : 0.6411585502925176; validation accuracy : 0.9097744360902256\n",
      "Epoch 17:\t train loss : 0.5744680699550359; train accuracy : 0.9769052728408166; \n",
      " validation loss : 0.636103475948299; validation accuracy : 0.8947368421052632\n",
      "Epoch 18:\t train loss : 0.5718041986652691; train accuracy : 0.9795529556799744; \n",
      " validation loss : 0.63533892020726; validation accuracy : 0.9097744360902256\n",
      "Epoch 19:\t train loss : 0.5679507667128428; train accuracy : 0.9836033843941824; \n",
      " validation loss : 0.6468850858145717; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:\t train loss : 0.5657669849618424; train accuracy : 0.9857843844710636; \n",
      " validation loss : 0.6384381635070447; validation accuracy : 0.9097744360902256\n",
      "Epoch 21:\t train loss : 0.5668975469693868; train accuracy : 0.9843155476845926; \n",
      " validation loss : 0.6115076352998857; validation accuracy : 0.9398496240601504\n",
      "Epoch 22:\t train loss : 0.5801747051505662; train accuracy : 0.9707669108433605; \n",
      " validation loss : 0.6326632665245795; validation accuracy : 0.9172932330827067\n",
      "Epoch 23:\t train loss : 0.5695551723233098; train accuracy : 0.9818027442564975; \n",
      " validation loss : 0.643257766116824; validation accuracy : 0.8947368421052632\n",
      "Epoch 24:\t train loss : 0.5687759291793458; train accuracy : 0.982407678415113; \n",
      " validation loss : 0.6535246762664456; validation accuracy : 0.8872180451127819\n",
      "Epoch 25:\t train loss : 0.5723721377767659; train accuracy : 0.979006694065171; \n",
      " validation loss : 0.6553859446487876; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5836877632276558; train accuracy : 0.9667994329669559; \n",
      " validation loss : 0.6422155738982662; validation accuracy : 0.9097744360902256\n",
      "Epoch 27:\t train loss : 0.5778141063242964; train accuracy : 0.9733141085212765; \n",
      " validation loss : 0.6194860645451368; validation accuracy : 0.9323308270676691\n",
      "Epoch 28:\t train loss : 0.5708002483326621; train accuracy : 0.9805895039539899; \n",
      " validation loss : 0.6365220133538213; validation accuracy : 0.9172932330827067\n",
      "Epoch 29:\t train loss : 0.5636770286479248; train accuracy : 0.9877752045783468; \n",
      " validation loss : 0.6307147920274025; validation accuracy : 0.9172932330827067\n",
      "Epoch 30:\t train loss : 0.570736099515319; train accuracy : 0.98050318113091; \n",
      " validation loss : 0.6266067452859453; validation accuracy : 0.9323308270676691\n",
      "Epoch 31:\t train loss : 0.5717320256604493; train accuracy : 0.9794180762689118; \n",
      " validation loss : 0.6230155448569739; validation accuracy : 0.9323308270676691\n",
      "Epoch 32:\t train loss : 0.5662734786130571; train accuracy : 0.9850863835188151; \n",
      " validation loss : 0.6290455565078218; validation accuracy : 0.924812030075188\n",
      "Epoch 33:\t train loss : 0.5652437310283249; train accuracy : 0.9857843844710636; \n",
      " validation loss : 0.6285799177135813; validation accuracy : 0.924812030075188\n",
      "Epoch 34:\t train loss : 0.5638138152808247; train accuracy : 0.9874467732124095; \n",
      " validation loss : 0.6441381061234432; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.5686070114380826; train accuracy : 0.9825769520759965; \n",
      " validation loss : 0.61015605035334; validation accuracy : 0.9398496240601504\n",
      "Epoch 36:\t train loss : 0.5733160568522762; train accuracy : 0.977703758954307; \n",
      " validation loss : 0.6368125294739558; validation accuracy : 0.9097744360902256\n",
      "Epoch 37:\t train loss : 0.5757387135778222; train accuracy : 0.9750250538506049; \n",
      " validation loss : 0.6526367325361382; validation accuracy : 0.9022556390977443\n",
      "Epoch 38:\t train loss : 0.5672399073775077; train accuracy : 0.9838212146430484; \n",
      " validation loss : 0.6402119271241327; validation accuracy : 0.9097744360902256\n",
      "Epoch 39:\t train loss : 0.5664766483548691; train accuracy : 0.9850378269308325; \n",
      " validation loss : 0.6180847071837611; validation accuracy : 0.9398496240601504\n",
      "Epoch 40:\t train loss : 0.5655418515907253; train accuracy : 0.9855942045014655; \n",
      " validation loss : 0.6212274388628883; validation accuracy : 0.9323308270676691\n",
      "Epoch 41:\t train loss : 0.5596481528188318; train accuracy : 0.9917844950721807; \n",
      " validation loss : 0.6017383946342665; validation accuracy : 0.9473684210526315\n",
      "Epoch 42:\t train loss : 0.56128419869801; train accuracy : 0.9901254783161115; \n",
      " validation loss : 0.6183484298384103; validation accuracy : 0.9323308270676691\n",
      "Epoch 43:\t train loss : 0.5594876495652809; train accuracy : 0.9920609978648589; \n",
      " validation loss : 0.6167313555956058; validation accuracy : 0.9323308270676691\n",
      "Epoch 44:\t train loss : 0.561604377088468; train accuracy : 0.9895724727307551; \n",
      " validation loss : 0.6311704225788662; validation accuracy : 0.924812030075188\n",
      "Epoch 45:\t train loss : 0.5677167976686446; train accuracy : 0.9833754381894867; \n",
      " validation loss : 0.6368728624588912; validation accuracy : 0.9097744360902256\n",
      "Epoch 46:\t train loss : 0.5796814103347464; train accuracy : 0.9709948570480562; \n",
      " validation loss : 0.642654285039129; validation accuracy : 0.8947368421052632\n",
      "Epoch 47:\t train loss : 0.5717085769024327; train accuracy : 0.9793661476956527; \n",
      " validation loss : 0.6423688617019522; validation accuracy : 0.9022556390977443\n",
      "Epoch 48:\t train loss : 0.5684733837251161; train accuracy : 0.9829121274124869; \n",
      " validation loss : 0.6574295668062631; validation accuracy : 0.8947368421052632\n",
      "Epoch 49:\t train loss : 0.5704689486368678; train accuracy : 0.9804721588663655; \n",
      " validation loss : 0.6337226923321414; validation accuracy : 0.9172932330827067\n",
      "Epoch 50:\t train loss : 0.5662092121244324; train accuracy : 0.9849757824017438; \n",
      " validation loss : 0.6343930149868592; validation accuracy : 0.9172932330827067\n",
      "Epoch 51:\t train loss : 0.5638937811414069; train accuracy : 0.9871635264491782; \n",
      " validation loss : 0.6604422631233067; validation accuracy : 0.8872180451127819\n",
      "Epoch 52:\t train loss : 0.5617373910499743; train accuracy : 0.9894652435989604; \n",
      " validation loss : 0.6314483580770456; validation accuracy : 0.924812030075188\n",
      "Epoch 53:\t train loss : 0.5588203925063102; train accuracy : 0.9925344245976884; \n",
      " validation loss : 0.6263317798255268; validation accuracy : 0.924812030075188\n",
      "Epoch 54:\t train loss : 0.5624605317738108; train accuracy : 0.9888016368965327; \n",
      " validation loss : 0.6158930150332504; validation accuracy : 0.9323308270676691\n",
      "Epoch 55:\t train loss : 0.5608347988197544; train accuracy : 0.9904849319465932; \n",
      " validation loss : 0.6314975082846322; validation accuracy : 0.9172932330827067\n",
      "Epoch 56:\t train loss : 0.5706687805983609; train accuracy : 0.9803649297345708; \n",
      " validation loss : 0.6188773530194251; validation accuracy : 0.924812030075188\n",
      "Epoch 57:\t train loss : 0.5765775949744605; train accuracy : 0.9745583710883284; \n",
      " validation loss : 0.6259035642819342; validation accuracy : 0.924812030075188\n",
      "Epoch 58:\t train loss : 0.561066431946972; train accuracy : 0.9903433085649774; \n",
      " validation loss : 0.6552108623294565; validation accuracy : 0.8947368421052632\n",
      "Epoch 59:\t train loss : 0.5670857640595477; train accuracy : 0.9839560940541109; \n",
      " validation loss : 0.6520698970988992; validation accuracy : 0.8947368421052632\n",
      "Epoch 60:\t train loss : 0.5697873532379562; train accuracy : 0.9812463666858645; \n",
      " validation loss : 0.6466529819658318; validation accuracy : 0.9022556390977443\n",
      "Epoch 61:\t train loss : 0.5601062681691962; train accuracy : 0.9911242603550295; \n",
      " validation loss : 0.6264753021512525; validation accuracy : 0.9172932330827067\n",
      "Epoch 62:\t train loss : 0.5628040876617334; train accuracy : 0.9885494123978457; \n",
      " validation loss : 0.6345039860675284; validation accuracy : 0.9172932330827067\n",
      "Epoch 63:\t train loss : 0.55718712649839; train accuracy : 0.9944112716026237; \n",
      " validation loss : 0.6208622962624726; validation accuracy : 0.9323308270676691\n",
      "Epoch 64:\t train loss : 0.559928217982773; train accuracy : 0.9914837139855113; \n",
      " validation loss : 0.6357882429066859; validation accuracy : 0.9097744360902256\n",
      "Epoch 65:\t train loss : 0.5583400503437868; train accuracy : 0.9929768290659735; \n",
      " validation loss : 0.6380823393762; validation accuracy : 0.9172932330827067\n",
      "Epoch 66:\t train loss : 0.5583185808002384; train accuracy : 0.9931427307415804; \n",
      " validation loss : 0.6318578095651817; validation accuracy : 0.9172932330827067\n",
      "Epoch 67:\t train loss : 0.5580909291083979; train accuracy : 0.9933329107111787; \n",
      " validation loss : 0.6103974190420492; validation accuracy : 0.9398496240601504\n",
      "Epoch 68:\t train loss : 0.5613468939560688; train accuracy : 0.9898489755234333; \n",
      " validation loss : 0.6357579348794088; validation accuracy : 0.9172932330827067\n",
      "Epoch 69:\t train loss : 0.5599290034195736; train accuracy : 0.9912901620306365; \n",
      " validation loss : 0.6378733568206253; validation accuracy : 0.9097744360902256\n",
      "Epoch 70:\t train loss : 0.5636054100668278; train accuracy : 0.9875297240502129; \n",
      " validation loss : 0.6439391879089189; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71:\t train loss : 0.5693337776779781; train accuracy : 0.9818823231090243; \n",
      " validation loss : 0.6198267011500506; validation accuracy : 0.9323308270676691\n",
      "Epoch 72:\t train loss : 0.5686773655660141; train accuracy : 0.9822727990040504; \n",
      " validation loss : 0.6563415729513864; validation accuracy : 0.8947368421052632\n",
      "Epoch 73:\t train loss : 0.5595247622764292; train accuracy : 0.991677265940386; \n",
      " validation loss : 0.6551454514905093; validation accuracy : 0.8947368421052632\n",
      "Epoch 74:\t train loss : 0.5568908489204677; train accuracy : 0.9944699441464359; \n",
      " validation loss : 0.6412115559764433; validation accuracy : 0.9022556390977443\n",
      "Epoch 75:\t train loss : 0.5555892315948308; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6258987705199175; validation accuracy : 0.924812030075188\n",
      "Epoch 76:\t train loss : 0.558378495295631; train accuracy : 0.9930011073599648; \n",
      " validation loss : 0.625527623089671; validation accuracy : 0.924812030075188\n",
      "Epoch 77:\t train loss : 0.5568793821723115; train accuracy : 0.9945805452635071; \n",
      " validation loss : 0.6233323796258367; validation accuracy : 0.924812030075188\n",
      "Epoch 78:\t train loss : 0.5623860845377912; train accuracy : 0.9887604986761586; \n",
      " validation loss : 0.6435606604434302; validation accuracy : 0.9022556390977443\n",
      "Epoch 79:\t train loss : 0.5835935962519329; train accuracy : 0.9673692984786951; \n",
      " validation loss : 0.664132803912148; validation accuracy : 0.8796992481203008\n",
      "Epoch 80:\t train loss : 0.5953637456446665; train accuracy : 0.9554108898938903; \n",
      " validation loss : 0.6609754854097397; validation accuracy : 0.8872180451127819\n",
      "Epoch 81:\t train loss : 0.5781034353780109; train accuracy : 0.9727577309506436; \n",
      " validation loss : 0.6250548608609833; validation accuracy : 0.924812030075188\n",
      "Epoch 82:\t train loss : 0.5624365165971975; train accuracy : 0.9886633855001935; \n",
      " validation loss : 0.6319355221487448; validation accuracy : 0.9172932330827067\n",
      "Epoch 83:\t train loss : 0.5580728769336663; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.648515483452016; validation accuracy : 0.8947368421052632\n",
      "Epoch 84:\t train loss : 0.5574819884593138; train accuracy : 0.9939169385610794; \n",
      " validation loss : 0.6472711469118719; validation accuracy : 0.9022556390977443\n",
      "Epoch 85:\t train loss : 0.5585786678764816; train accuracy : 0.9926969542880187; \n",
      " validation loss : 0.6414852564914749; validation accuracy : 0.9097744360902256\n",
      "Epoch 86:\t train loss : 0.5555890855163027; train accuracy : 0.9957971575512913; \n",
      " validation loss : 0.6331015558380971; validation accuracy : 0.9172932330827067\n",
      "Epoch 87:\t train loss : 0.5564530553002255; train accuracy : 0.9948570480561854; \n",
      " validation loss : 0.6510045169964829; validation accuracy : 0.9022556390977443\n",
      "Epoch 88:\t train loss : 0.559430782528096; train accuracy : 0.9918121453514486; \n",
      " validation loss : 0.6190648535721366; validation accuracy : 0.9323308270676691\n",
      "Epoch 89:\t train loss : 0.5596592111308859; train accuracy : 0.9915666648233147; \n",
      " validation loss : 0.6231214453043222; validation accuracy : 0.924812030075188\n",
      "Epoch 90:\t train loss : 0.5579108306280192; train accuracy : 0.9933086324171874; \n",
      " validation loss : 0.619244221818281; validation accuracy : 0.9323308270676691\n",
      "Epoch 91:\t train loss : 0.5552525077696537; train accuracy : 0.9960736603439695; \n",
      " validation loss : 0.6091459340797162; validation accuracy : 0.9473684210526315\n",
      "Early stopping at epoch 91\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5596481528188318; Train accuracy : 0.9917844950721807; \n",
      " Validation loss : 0.6017383946342665; Validation accuracy : 0.9473684210526315\n",
      "------------------------------ Let's train model 5 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8843506197933207; train accuracy : 0.6447512351582068; \n",
      " validation loss : 0.8191160194459972; validation accuracy : 0.706766917293233\n",
      "Epoch 2:\t train loss : 0.7800415386302413; train accuracy : 0.7629764109397993; \n",
      " validation loss : 0.7492387245283807; validation accuracy : 0.7894736842105263\n",
      "Epoch 3:\t train loss : 0.7309579463595273; train accuracy : 0.8173328135980027; \n",
      " validation loss : 0.702033741401175; validation accuracy : 0.8421052631578947\n",
      "Epoch 4:\t train loss : 0.674948052699134; train accuracy : 0.8744373842566053; \n",
      " validation loss : 0.6808253213567664; validation accuracy : 0.8721804511278195\n",
      "Epoch 5:\t train loss : 0.6449724929900813; train accuracy : 0.9052188890522428; \n",
      " validation loss : 0.7037933516643589; validation accuracy : 0.8421052631578947\n",
      "Epoch 6:\t train loss : 0.6160437553129178; train accuracy : 0.9351884197932838; \n",
      " validation loss : 0.6682241640805754; validation accuracy : 0.8796992481203008\n",
      "Epoch 7:\t train loss : 0.609003062586222; train accuracy : 0.9425191157845328; \n",
      " validation loss : 0.7158546110949849; validation accuracy : 0.8195488721804511\n",
      "Epoch 8:\t train loss : 0.5973614288685811; train accuracy : 0.9539764473572403; \n",
      " validation loss : 0.6551349556509835; validation accuracy : 0.8947368421052632\n",
      "Epoch 9:\t train loss : 0.5905261291991952; train accuracy : 0.9609928743207136; \n",
      " validation loss : 0.6569294291459299; validation accuracy : 0.8947368421052632\n",
      "Epoch 10:\t train loss : 0.5821353470603201; train accuracy : 0.9698821019067903; \n",
      " validation loss : 0.6630090177313529; validation accuracy : 0.8872180451127819\n",
      "Epoch 11:\t train loss : 0.5896673022213088; train accuracy : 0.9617495478167744; \n",
      " validation loss : 0.6820620030996238; validation accuracy : 0.8646616541353384\n",
      "Epoch 12:\t train loss : 0.5824602617139509; train accuracy : 0.9689352484411312; \n",
      " validation loss : 0.664843087295877; validation accuracy : 0.8947368421052632\n",
      "Epoch 13:\t train loss : 0.577598425797972; train accuracy : 0.9739156706946155; \n",
      " validation loss : 0.6891405760528023; validation accuracy : 0.849624060150376\n",
      "Epoch 14:\t train loss : 0.5662058735246348; train accuracy : 0.9859988427346531; \n",
      " validation loss : 0.6524798646114178; validation accuracy : 0.9022556390977443\n",
      "Epoch 15:\t train loss : 0.565241632946535; train accuracy : 0.9867696785688755; \n",
      " validation loss : 0.6899870287876895; validation accuracy : 0.849624060150376\n",
      "Epoch 16:\t train loss : 0.5723022100087534; train accuracy : 0.9790653666089832; \n",
      " validation loss : 0.6962649368362859; validation accuracy : 0.8571428571428571\n",
      "Epoch 17:\t train loss : 0.5656654468260987; train accuracy : 0.985867335308867; \n",
      " validation loss : 0.7022541855167209; validation accuracy : 0.8421052631578947\n",
      "Epoch 18:\t train loss : 0.5654141379282426; train accuracy : 0.9861438381015453; \n",
      " validation loss : 0.6663147636015216; validation accuracy : 0.8872180451127819\n",
      "Epoch 19:\t train loss : 0.5653276094959938; train accuracy : 0.9862234169540722; \n",
      " validation loss : 0.6654940382654698; validation accuracy : 0.8872180451127819\n",
      "Epoch 20:\t train loss : 0.5714620935588457; train accuracy : 0.9797222293408578; \n",
      " validation loss : 0.701556543401598; validation accuracy : 0.849624060150376\n",
      "Epoch 21:\t train loss : 0.5687975665780733; train accuracy : 0.9826046023552643; \n",
      " validation loss : 0.7150579081102982; validation accuracy : 0.8345864661654135\n",
      "Epoch 22:\t train loss : 0.5706682426598622; train accuracy : 0.980085054956616; \n",
      " validation loss : 0.7267392845488884; validation accuracy : 0.8270676691729323\n",
      "Epoch 23:\t train loss : 0.5598081051112257; train accuracy : 0.9917015442343773; \n",
      " validation loss : 0.7190948659248411; validation accuracy : 0.8345864661654135\n",
      "Epoch 24:\t train loss : 0.5608666356879629; train accuracy : 0.9902360794331828; \n",
      " validation loss : 0.6834887399002166; validation accuracy : 0.8646616541353384\n",
      "Epoch 25:\t train loss : 0.562029771303565; train accuracy : 0.9895758447160317; \n",
      " validation loss : 0.7138861048910545; validation accuracy : 0.8345864661654135\n",
      "Epoch 26:\t train loss : 0.5607430455230245; train accuracy : 0.9906231833429322; \n",
      " validation loss : 0.7044234092751576; validation accuracy : 0.849624060150376\n",
      "Epoch 27:\t train loss : 0.5642391649008915; train accuracy : 0.9871115978759191; \n",
      " validation loss : 0.6630625415115685; validation accuracy : 0.8872180451127819\n",
      "Epoch 28:\t train loss : 0.55821666940032; train accuracy : 0.9933052604319108; \n",
      " validation loss : 0.6943336748457029; validation accuracy : 0.8646616541353384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:\t train loss : 0.5580272496781324; train accuracy : 0.9933571890051699; \n",
      " validation loss : 0.67693121764526; validation accuracy : 0.8721804511278195\n",
      "Epoch 30:\t train loss : 0.5751300707858615; train accuracy : 0.9757095668617473; \n",
      " validation loss : 0.6697126168081737; validation accuracy : 0.8796992481203008\n",
      "Epoch 31:\t train loss : 0.5666208572864284; train accuracy : 0.984650723021083; \n",
      " validation loss : 0.6672023250236531; validation accuracy : 0.8872180451127819\n",
      "Epoch 32:\t train loss : 0.5703407566179166; train accuracy : 0.9806724547917934; \n",
      " validation loss : 0.6937577368156674; validation accuracy : 0.8571428571428571\n",
      "Epoch 33:\t train loss : 0.5638440877496316; train accuracy : 0.9874191229331416; \n",
      " validation loss : 0.706094227491699; validation accuracy : 0.849624060150376\n",
      "Epoch 34:\t train loss : 0.5674947160434753; train accuracy : 0.9834374827185755; \n",
      " validation loss : 0.7262846703904781; validation accuracy : 0.8195488721804511\n",
      "Epoch 35:\t train loss : 0.5773590032254645; train accuracy : 0.9734665222557772; \n",
      " validation loss : 0.6705824905651764; validation accuracy : 0.8872180451127819\n",
      "Epoch 36:\t train loss : 0.5856186324289139; train accuracy : 0.965292155548332; \n",
      " validation loss : 0.7278718342272991; validation accuracy : 0.8195488721804511\n",
      "Epoch 37:\t train loss : 0.5681841830722036; train accuracy : 0.9832405587784242; \n",
      " validation loss : 0.677309825465087; validation accuracy : 0.8721804511278195\n",
      "Epoch 38:\t train loss : 0.5598704920640277; train accuracy : 0.9914702260444049; \n",
      " validation loss : 0.7001471595876401; validation accuracy : 0.849624060150376\n",
      "Epoch 39:\t train loss : 0.5579888378821048; train accuracy : 0.9934954404015091; \n",
      " validation loss : 0.7240461703141687; validation accuracy : 0.8195488721804511\n",
      "Epoch 40:\t train loss : 0.5584592443758343; train accuracy : 0.9930287576392326; \n",
      " validation loss : 0.6870241551669316; validation accuracy : 0.8646616541353384\n",
      "Epoch 41:\t train loss : 0.5576147560857987; train accuracy : 0.9937200146209282; \n",
      " validation loss : 0.6751319130924521; validation accuracy : 0.8721804511278195\n",
      "Epoch 42:\t train loss : 0.5598674677176408; train accuracy : 0.9912072111928331; \n",
      " validation loss : 0.6572721862515253; validation accuracy : 0.8872180451127819\n",
      "Epoch 43:\t train loss : 0.5547950254170583; train accuracy : 0.9966543162085937; \n",
      " validation loss : 0.6759532203892284; validation accuracy : 0.8721804511278195\n",
      "Epoch 44:\t train loss : 0.5555117663502247; train accuracy : 0.995824807830559; \n",
      " validation loss : 0.6715525657787061; validation accuracy : 0.8796992481203008\n",
      "Epoch 45:\t train loss : 0.5553752769522515; train accuracy : 0.9959596872416216; \n",
      " validation loss : 0.7325815878100763; validation accuracy : 0.8120300751879699\n",
      "Epoch 46:\t train loss : 0.5609523196734107; train accuracy : 0.9903433085649774; \n",
      " validation loss : 0.7059794325461585; validation accuracy : 0.8421052631578947\n",
      "Epoch 47:\t train loss : 0.5627025425105222; train accuracy : 0.9883005598844353; \n",
      " validation loss : 0.6824508015212459; validation accuracy : 0.8571428571428571\n",
      "Epoch 48:\t train loss : 0.5816855784463815; train accuracy : 0.9689177141176931; \n",
      " validation loss : 0.7080427171179454; validation accuracy : 0.8421052631578947\n",
      "Epoch 49:\t train loss : 0.5646221626555114; train accuracy : 0.9867278659514461; \n",
      " validation loss : 0.709663233445886; validation accuracy : 0.8345864661654135\n",
      "Epoch 50:\t train loss : 0.5615064102432064; train accuracy : 0.9899319263612367; \n",
      " validation loss : 0.6678931627036169; validation accuracy : 0.8796992481203008\n",
      "Epoch 51:\t train loss : 0.5589695344268876; train accuracy : 0.9925276806271353; \n",
      " validation loss : 0.7303226138101858; validation accuracy : 0.8120300751879699\n",
      "Epoch 52:\t train loss : 0.5587258431744132; train accuracy : 0.9927455108760013; \n",
      " validation loss : 0.6897683019478853; validation accuracy : 0.8571428571428571\n",
      "Epoch 53:\t train loss : 0.5594236458397148; train accuracy : 0.9919503967477876; \n",
      " validation loss : 0.676881499438069; validation accuracy : 0.8721804511278195\n",
      "Epoch 54:\t train loss : 0.5547148333191291; train accuracy : 0.996764917325665; \n",
      " validation loss : 0.6748309722392968; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5538389941125309; train accuracy : 0.9976463542769587; \n",
      " validation loss : 0.6657871123495848; validation accuracy : 0.8947368421052632\n",
      "Epoch 56:\t train loss : 0.5541712330409959; train accuracy : 0.9971796715146823; \n",
      " validation loss : 0.6752519963721696; validation accuracy : 0.8721804511278195\n",
      "Epoch 57:\t train loss : 0.5592496539724489; train accuracy : 0.9919713030565023; \n",
      " validation loss : 0.687364861270248; validation accuracy : 0.8646616541353384\n",
      "Epoch 58:\t train loss : 0.5607774933143249; train accuracy : 0.9904053530940663; \n",
      " validation loss : 0.6737478962682147; validation accuracy : 0.8796992481203008\n",
      "Epoch 59:\t train loss : 0.5575432686304143; train accuracy : 0.9937786871647404; \n",
      " validation loss : 0.6840027324603432; validation accuracy : 0.8646616541353384\n",
      "Epoch 60:\t train loss : 0.5549360800741545; train accuracy : 0.9963501631366477; \n",
      " validation loss : 0.6851222033183518; validation accuracy : 0.8646616541353384\n",
      "Epoch 61:\t train loss : 0.5541564787571073; train accuracy : 0.9973179229110214; \n",
      " validation loss : 0.6990205879583978; validation accuracy : 0.849624060150376\n",
      "Epoch 62:\t train loss : 0.5817399452224615; train accuracy : 0.9692184952043625; \n",
      " validation loss : 0.6539217218997981; validation accuracy : 0.8947368421052632\n",
      "Epoch 63:\t train loss : 0.5624882320489915; train accuracy : 0.9888016368965327; \n",
      " validation loss : 0.6978028725532943; validation accuracy : 0.8571428571428571\n",
      "Epoch 64:\t train loss : 0.5565333139800289; train accuracy : 0.994774097218382; \n",
      " validation loss : 0.6886192183281595; validation accuracy : 0.8646616541353384\n",
      "Early stopping at epoch 64\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5662058735246348; Train accuracy : 0.9859988427346531; \n",
      " Validation loss : 0.6524798646114178; Validation accuracy : 0.9022556390977443\n",
      "------------------------------ Let's train model 6 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8909676590810671; train accuracy : 0.644764966195926; \n",
      " validation loss : 0.8363960911482455; validation accuracy : 0.6791044776119403\n",
      "Epoch 2:\t train loss : 0.7838401286459316; train accuracy : 0.7612745621288914; \n",
      " validation loss : 0.7783840837133307; validation accuracy : 0.7761194029850746\n",
      "Epoch 3:\t train loss : 0.7562640922998763; train accuracy : 0.7884785787499244; \n",
      " validation loss : 0.8073091509978018; validation accuracy : 0.7313432835820896\n",
      "Epoch 4:\t train loss : 0.728827537502086; train accuracy : 0.8191607432909491; \n",
      " validation loss : 0.763674648935923; validation accuracy : 0.7761194029850746\n",
      "Epoch 5:\t train loss : 0.6933779713418253; train accuracy : 0.8555160378050051; \n",
      " validation loss : 0.7219063876231839; validation accuracy : 0.835820895522388\n",
      "Epoch 6:\t train loss : 0.657283036695481; train accuracy : 0.8929487286658805; \n",
      " validation loss : 0.7105066024119031; validation accuracy : 0.8432835820895522\n",
      "Epoch 7:\t train loss : 0.6386838706282486; train accuracy : 0.9120254922714254; \n",
      " validation loss : 0.6734792475144963; validation accuracy : 0.8880597014925373\n",
      "Epoch 8:\t train loss : 0.6078645953462233; train accuracy : 0.9443753544701499; \n",
      " validation loss : 0.6832710573254488; validation accuracy : 0.8582089552238806\n",
      "Epoch 9:\t train loss : 0.5963104989249506; train accuracy : 0.9559608214833667; \n",
      " validation loss : 0.6511842484771213; validation accuracy : 0.8955223880597015\n",
      "Epoch 10:\t train loss : 0.594426266696828; train accuracy : 0.9572861057989709; \n",
      " validation loss : 0.6377040680559005; validation accuracy : 0.9104477611940298\n",
      "Epoch 11:\t train loss : 0.5897508220720166; train accuracy : 0.9622326121540339; \n",
      " validation loss : 0.6753705073050694; validation accuracy : 0.8731343283582089\n",
      "Epoch 12:\t train loss : 0.5823401828959037; train accuracy : 0.9693959635736507; \n",
      " validation loss : 0.6493210877677384; validation accuracy : 0.9029850746268657\n",
      "Epoch 13:\t train loss : 0.5859272538551253; train accuracy : 0.965855763282744; \n",
      " validation loss : 0.66480893217329; validation accuracy : 0.8880597014925373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\t train loss : 0.5716514155089082; train accuracy : 0.9800927634717947; \n",
      " validation loss : 0.6635455481778562; validation accuracy : 0.8880597014925373\n",
      "Epoch 15:\t train loss : 0.5752374633160654; train accuracy : 0.9760291369640508; \n",
      " validation loss : 0.6527906876911905; validation accuracy : 0.8955223880597015\n",
      "Epoch 16:\t train loss : 0.57321217994475; train accuracy : 0.9780189925267082; \n",
      " validation loss : 0.6712173684839873; validation accuracy : 0.8880597014925373\n",
      "Epoch 17:\t train loss : 0.5713785889173734; train accuracy : 0.9804531816469021; \n",
      " validation loss : 0.6471157280043577; validation accuracy : 0.9104477611940298\n",
      "Epoch 18:\t train loss : 0.5638564907467227; train accuracy : 0.9878615274014267; \n",
      " validation loss : 0.6597702664475698; validation accuracy : 0.8880597014925373\n",
      "Epoch 19:\t train loss : 0.5615824844050632; train accuracy : 0.9901298148460137; \n",
      " validation loss : 0.6234056383790767; validation accuracy : 0.9253731343283582\n",
      "Epoch 20:\t train loss : 0.5739505128487996; train accuracy : 0.9777463479125326; \n",
      " validation loss : 0.6610776119144188; validation accuracy : 0.8880597014925373\n",
      "Epoch 21:\t train loss : 0.5691832440332043; train accuracy : 0.9819186464480966; \n",
      " validation loss : 0.6420597984569517; validation accuracy : 0.9029850746268657\n",
      "Epoch 22:\t train loss : 0.5600469464216902; train accuracy : 0.9916229299264759; \n",
      " validation loss : 0.6698737227189838; validation accuracy : 0.8805970149253731\n",
      "Epoch 23:\t train loss : 0.5836092654542401; train accuracy : 0.967567186963472; \n",
      " validation loss : 0.6489765625680733; validation accuracy : 0.8955223880597015\n",
      "Epoch 24:\t train loss : 0.5630837359378555; train accuracy : 0.9881666450179984; \n",
      " validation loss : 0.6340973635713518; validation accuracy : 0.917910447761194\n",
      "Epoch 25:\t train loss : 0.5659318512516639; train accuracy : 0.9854016170912163; \n",
      " validation loss : 0.6441555392412444; validation accuracy : 0.9104477611940298\n",
      "Epoch 26:\t train loss : 0.5591009205491261; train accuracy : 0.9923170805420484; \n",
      " validation loss : 0.6724225396124247; validation accuracy : 0.8805970149253731\n",
      "Epoch 27:\t train loss : 0.5671540349061521; train accuracy : 0.9840744036863609; \n",
      " validation loss : 0.6348319251953382; validation accuracy : 0.917910447761194\n",
      "Epoch 28:\t train loss : 0.5579693509716465; train accuracy : 0.9934478483581521; \n",
      " validation loss : 0.6499539456431083; validation accuracy : 0.9029850746268657\n",
      "Epoch 29:\t train loss : 0.5597563763267167; train accuracy : 0.991677265940386; \n",
      " validation loss : 0.6546144904423644; validation accuracy : 0.8955223880597015\n",
      "Epoch 30:\t train loss : 0.5611210756051628; train accuracy : 0.9899648777150324; \n",
      " validation loss : 0.6186725975200333; validation accuracy : 0.9328358208955224\n",
      "Epoch 31:\t train loss : 0.5602627002183217; train accuracy : 0.9912072111928331; \n",
      " validation loss : 0.6486702780948791; validation accuracy : 0.9029850746268657\n",
      "Epoch 32:\t train loss : 0.5577810894143004; train accuracy : 0.9938082665332594; \n",
      " validation loss : 0.6847308146905079; validation accuracy : 0.8582089552238806\n",
      "Epoch 33:\t train loss : 0.5574539932913771; train accuracy : 0.9938912173710629; \n",
      " validation loss : 0.6710215611264289; validation accuracy : 0.8805970149253731\n",
      "Epoch 34:\t train loss : 0.5584545781960403; train accuracy : 0.9928385776696345; \n",
      " validation loss : 0.6614401661351524; validation accuracy : 0.8880597014925373\n",
      "Epoch 35:\t train loss : 0.5586357476730157; train accuracy : 0.9927575559210823; \n",
      " validation loss : 0.6490448126084443; validation accuracy : 0.9029850746268657\n",
      "Epoch 36:\t train loss : 0.5618369151858432; train accuracy : 0.9894652435989604; \n",
      " validation loss : 0.6304037830249647; validation accuracy : 0.9253731343283582\n",
      "Epoch 37:\t train loss : 0.5564396034820276; train accuracy : 0.9949676491732566; \n",
      " validation loss : 0.6571029007803181; validation accuracy : 0.8880597014925373\n",
      "Epoch 38:\t train loss : 0.5654837477891563; train accuracy : 0.9855970981353424; \n",
      " validation loss : 0.6722476980454931; validation accuracy : 0.8731343283582089\n",
      "Epoch 39:\t train loss : 0.561165938750256; train accuracy : 0.9901851154045493; \n",
      " validation loss : 0.6292954197827136; validation accuracy : 0.917910447761194\n",
      "Epoch 40:\t train loss : 0.5631341862266938; train accuracy : 0.9880599020794296; \n",
      " validation loss : 0.6836568384035767; validation accuracy : 0.8656716417910447\n",
      "Epoch 41:\t train loss : 0.5715879634135603; train accuracy : 0.9793738562108315; \n",
      " validation loss : 0.6800476311609427; validation accuracy : 0.8656716417910447\n",
      "Epoch 42:\t train loss : 0.5730230920438004; train accuracy : 0.9778817056749948; \n",
      " validation loss : 0.6288875561285174; validation accuracy : 0.9253731343283582\n",
      "Epoch 43:\t train loss : 0.5632104539352886; train accuracy : 0.9882219455765341; \n",
      " validation loss : 0.68307440400202; validation accuracy : 0.8656716417910447\n",
      "Epoch 44:\t train loss : 0.5663409298593566; train accuracy : 0.9848524696843625; \n",
      " validation loss : 0.7001356671816074; validation accuracy : 0.8507462686567164\n",
      "Epoch 45:\t train loss : 0.5619582869537548; train accuracy : 0.9894385578643181; \n",
      " validation loss : 0.6514029344967274; validation accuracy : 0.9029850746268657\n",
      "Epoch 46:\t train loss : 0.5566678074138732; train accuracy : 0.994858012600811; \n",
      " validation loss : 0.639087708485145; validation accuracy : 0.917910447761194\n",
      "Epoch 47:\t train loss : 0.5570461962989119; train accuracy : 0.9944432584117937; \n",
      " validation loss : 0.6565542534462755; validation accuracy : 0.8955223880597015\n",
      "Epoch 48:\t train loss : 0.5652469039180139; train accuracy : 0.9857697516233286; \n",
      " validation loss : 0.6810348011847313; validation accuracy : 0.8656716417910447\n",
      "Epoch 49:\t train loss : 0.566847637103929; train accuracy : 0.9844605430514848; \n",
      " validation loss : 0.6595898054336619; validation accuracy : 0.8880597014925373\n",
      "Epoch 50:\t train loss : 0.5609631038072959; train accuracy : 0.9901050582006227; \n",
      " validation loss : 0.6400787968312356; validation accuracy : 0.9104477611940298\n",
      "Epoch 51:\t train loss : 0.5580830395731804; train accuracy : 0.9931980313001161; \n",
      " validation loss : 0.6504551644550168; validation accuracy : 0.9029850746268657\n",
      "Epoch 52:\t train loss : 0.561461733698807; train accuracy : 0.9901050582006227; \n",
      " validation loss : 0.6262155550651461; validation accuracy : 0.9253731343283582\n",
      "Epoch 53:\t train loss : 0.5574719007548044; train accuracy : 0.9939722391196151; \n",
      " validation loss : 0.6654151831357991; validation accuracy : 0.8880597014925373\n",
      "Epoch 54:\t train loss : 0.5744219720182749; train accuracy : 0.976513659880988; \n",
      " validation loss : 0.7454422844840743; validation accuracy : 0.8059701492537313\n",
      "Epoch 55:\t train loss : 0.6046232252730211; train accuracy : 0.9457234663418937; \n",
      " validation loss : 0.6485131646454264; validation accuracy : 0.9029850746268657\n",
      "Epoch 56:\t train loss : 0.5938187890242076; train accuracy : 0.9565662339933819; \n",
      " validation loss : 0.6796214534243511; validation accuracy : 0.8656716417910447\n",
      "Epoch 57:\t train loss : 0.5947608255561219; train accuracy : 0.9560141929526511; \n",
      " validation loss : 0.672917551829119; validation accuracy : 0.8805970149253731\n",
      "Epoch 58:\t train loss : 0.5744885628170739; train accuracy : 0.9765831070940328; \n",
      " validation loss : 0.6787709284433667; validation accuracy : 0.8731343283582089\n",
      "Epoch 59:\t train loss : 0.5602949949642582; train accuracy : 0.990960287768674; \n",
      " validation loss : 0.6814437964075417; validation accuracy : 0.8656716417910447\n",
      "Epoch 60:\t train loss : 0.5561706299626832; train accuracy : 0.9953004170690961; \n",
      " validation loss : 0.6440077042046514; validation accuracy : 0.9029850746268657\n",
      "Epoch 61:\t train loss : 0.5559677339878059; train accuracy : 0.995273731334454; \n",
      " validation loss : 0.6208774343291913; validation accuracy : 0.9328358208955224\n",
      "Epoch 62:\t train loss : 0.554897286027093; train accuracy : 0.996460764253719; \n",
      " validation loss : 0.6299749327650964; validation accuracy : 0.9253731343283582\n",
      "Epoch 63:\t train loss : 0.5538630584618341; train accuracy : 0.9976220759829674; \n",
      " validation loss : 0.6520149345565104; validation accuracy : 0.8955223880597015\n",
      "Epoch 64:\t train loss : 0.5561199852892493; train accuracy : 0.9952718022452026; \n",
      " validation loss : 0.6410928557904045; validation accuracy : 0.9104477611940298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:\t train loss : 0.562730203921807; train accuracy : 0.9886109785755348; \n",
      " validation loss : 0.6454491552743147; validation accuracy : 0.9104477611940298\n",
      "Epoch 66:\t train loss : 0.5635079069695099; train accuracy : 0.9877882220098795; \n",
      " validation loss : 0.7123622937262625; validation accuracy : 0.835820895522388\n",
      "Epoch 67:\t train loss : 0.5748290738897947; train accuracy : 0.976117875069608; \n",
      " validation loss : 0.6858247752601021; validation accuracy : 0.8582089552238806\n",
      "Epoch 68:\t train loss : 0.568729892915765; train accuracy : 0.9822237640646682; \n",
      " validation loss : 0.6218719644822186; validation accuracy : 0.9328358208955224\n",
      "Epoch 69:\t train loss : 0.5615992241062066; train accuracy : 0.989686445833103; \n",
      " validation loss : 0.64349188572363; validation accuracy : 0.9104477611940298\n",
      "Epoch 70:\t train loss : 0.5601802455169834; train accuracy : 0.9910422740618517; \n",
      " validation loss : 0.6661326903301055; validation accuracy : 0.8805970149253731\n",
      "Epoch 71:\t train loss : 0.5587194324888328; train accuracy : 0.9927279765525632; \n",
      " validation loss : 0.6283981139914502; validation accuracy : 0.917910447761194\n",
      "Epoch 72:\t train loss : 0.5655000391121352; train accuracy : 0.9857353495316814; \n",
      " validation loss : 0.677979341352781; validation accuracy : 0.8731343283582089\n",
      "Epoch 73:\t train loss : 0.567392818905617; train accuracy : 0.9836596494973436; \n",
      " validation loss : 0.6573861533026173; validation accuracy : 0.8955223880597015\n",
      "Epoch 74:\t train loss : 0.5582335217587397; train accuracy : 0.9931160450069383; \n",
      " validation loss : 0.6893849764355455; validation accuracy : 0.8582089552238806\n",
      "Epoch 75:\t train loss : 0.5589119951079459; train accuracy : 0.9925373182315653; \n",
      " validation loss : 0.6545655761035916; validation accuracy : 0.8955223880597015\n",
      "Epoch 76:\t train loss : 0.5616768616003412; train accuracy : 0.9894157303081784; \n",
      " validation loss : 0.6489615165323077; validation accuracy : 0.9029850746268657\n",
      "Epoch 77:\t train loss : 0.5805678582901047; train accuracy : 0.9701187290131165; \n",
      " validation loss : 0.6638121287623275; validation accuracy : 0.8805970149253731\n",
      "Epoch 78:\t train loss : 0.5654730048397649; train accuracy : 0.9858173358248593; \n",
      " validation loss : 0.6622662475497298; validation accuracy : 0.8880597014925373\n",
      "Epoch 79:\t train loss : 0.5576454158846734; train accuracy : 0.9937243511508304; \n",
      " validation loss : 0.6416103228501375; validation accuracy : 0.9029850746268657\n",
      "Epoch 80:\t train loss : 0.5555042697767718; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6631663117802209; validation accuracy : 0.8880597014925373\n",
      "Early stopping at epoch 80\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5611210756051628; Train accuracy : 0.9899648777150324; \n",
      " Validation loss : 0.6186725975200333; Validation accuracy : 0.9328358208955224\n",
      "------------------------------ Let's train model 7 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.884176808516793; train accuracy : 0.6518991928025369; \n",
      " validation loss : 0.7917510167518279; validation accuracy : 0.7761194029850746\n",
      "Epoch 2:\t train loss : 0.7752820425531118; train accuracy : 0.7681669485723874; \n",
      " validation loss : 0.7595082272828863; validation accuracy : 0.7761194029850746\n",
      "Epoch 3:\t train loss : 0.7408466913400484; train accuracy : 0.807089007202421; \n",
      " validation loss : 0.7490106912317227; validation accuracy : 0.7910447761194029\n",
      "Epoch 4:\t train loss : 0.7057682817961602; train accuracy : 0.8427855177371775; \n",
      " validation loss : 0.7145097559129031; validation accuracy : 0.8283582089552238\n",
      "Epoch 5:\t train loss : 0.6720841404740123; train accuracy : 0.8781809739381816; \n",
      " validation loss : 0.6716944449083387; validation accuracy : 0.8582089552238806\n",
      "Epoch 6:\t train loss : 0.643372214041085; train accuracy : 0.90701139572889; \n",
      " validation loss : 0.6751509031835715; validation accuracy : 0.8656716417910447\n",
      "Epoch 7:\t train loss : 0.6180051138230549; train accuracy : 0.9339956846495184; \n",
      " validation loss : 0.6404677610909331; validation accuracy : 0.917910447761194\n",
      "Epoch 8:\t train loss : 0.6027557003689117; train accuracy : 0.9492057218915843; \n",
      " validation loss : 0.6831352264841853; validation accuracy : 0.8731343283582089\n",
      "Epoch 9:\t train loss : 0.589441597201466; train accuracy : 0.9628704422328459; \n",
      " validation loss : 0.6592877946887652; validation accuracy : 0.8731343283582089\n",
      "Epoch 10:\t train loss : 0.5835647598262392; train accuracy : 0.9687425511101111; \n",
      " validation loss : 0.6362321094998645; validation accuracy : 0.9104477611940298\n",
      "Epoch 11:\t train loss : 0.5823061234799322; train accuracy : 0.9696597776154781; \n",
      " validation loss : 0.6588817041257578; validation accuracy : 0.8805970149253731\n",
      "Epoch 12:\t train loss : 0.5760003192142976; train accuracy : 0.9750365651106869; \n",
      " validation loss : 0.6764588128235488; validation accuracy : 0.8656716417910447\n",
      "Epoch 13:\t train loss : 0.5766311068615745; train accuracy : 0.9751195159484903; \n",
      " validation loss : 0.6994215200849165; validation accuracy : 0.8507462686567164\n",
      "Epoch 14:\t train loss : 0.573733954260994; train accuracy : 0.9781002637264568; \n",
      " validation loss : 0.6599684016977767; validation accuracy : 0.8805970149253731\n",
      "Epoch 15:\t train loss : 0.5858126361252332; train accuracy : 0.9649821131296874; \n",
      " validation loss : 0.6711406387405286; validation accuracy : 0.8731343283582089\n",
      "Epoch 16:\t train loss : 0.5846585674816143; train accuracy : 0.966894749688696; \n",
      " validation loss : 0.6695288744878239; validation accuracy : 0.8656716417910447\n",
      "Epoch 17:\t train loss : 0.578967842408149; train accuracy : 0.9727566088934739; \n",
      " validation loss : 0.6484957421539219; validation accuracy : 0.8955223880597015\n",
      "Epoch 18:\t train loss : 0.5882238020216299; train accuracy : 0.9629131094741298; \n",
      " validation loss : 0.7122941804389648; validation accuracy : 0.8432835820895522\n",
      "Epoch 19:\t train loss : 0.5767572596478437; train accuracy : 0.9745491097563533; \n",
      " validation loss : 0.6678328570914756; validation accuracy : 0.8805970149253731\n",
      "Epoch 20:\t train loss : 0.5677983495827545; train accuracy : 0.9836634522422469; \n",
      " validation loss : 0.6411493093770725; validation accuracy : 0.9029850746268657\n",
      "Epoch 21:\t train loss : 0.5663657540956081; train accuracy : 0.9856218547807333; \n",
      " validation loss : 0.693370722610189; validation accuracy : 0.8582089552238806\n",
      "Epoch 22:\t train loss : 0.5676316902606889; train accuracy : 0.9838696375143734; \n",
      " validation loss : 0.6876908322323945; validation accuracy : 0.8731343283582089\n",
      "Epoch 23:\t train loss : 0.5771191819219063; train accuracy : 0.9739496230980899; \n",
      " validation loss : 0.7244907283906288; validation accuracy : 0.8208955223880597\n",
      "Epoch 24:\t train loss : 0.5775971559508627; train accuracy : 0.973958204219242; \n",
      " validation loss : 0.6924045034848104; validation accuracy : 0.8582089552238806\n",
      "Epoch 25:\t train loss : 0.5637926542482844; train accuracy : 0.9879745121632625; \n",
      " validation loss : 0.6972688679459286; validation accuracy : 0.8507462686567164\n",
      "Epoch 26:\t train loss : 0.5674974086613774; train accuracy : 0.9838396035903411; \n",
      " validation loss : 0.6530595271353865; validation accuracy : 0.8955223880597015\n",
      "Epoch 27:\t train loss : 0.5607786941598583; train accuracy : 0.990945725362171; \n",
      " validation loss : 0.6886334892812761; validation accuracy : 0.8582089552238806\n",
      "Epoch 28:\t train loss : 0.5644047990178236; train accuracy : 0.9867831665099818; \n",
      " validation loss : 0.6479611015650906; validation accuracy : 0.9104477611940298\n",
      "Epoch 29:\t train loss : 0.563454454877857; train accuracy : 0.9879468618839947; \n",
      " validation loss : 0.6970382232034301; validation accuracy : 0.8432835820895522\n",
      "Epoch 30:\t train loss : 0.5607685678401596; train accuracy : 0.9905886553764538; \n",
      " validation loss : 0.7087006418663605; validation accuracy : 0.835820895522388\n",
      "Epoch 31:\t train loss : 0.5628499980201059; train accuracy : 0.9885527843831222; \n",
      " validation loss : 0.6851400423695868; validation accuracy : 0.8582089552238806\n",
      "Epoch 32:\t train loss : 0.5615825501596928; train accuracy : 0.9897693966709064; \n",
      " validation loss : 0.6890079524561918; validation accuracy : 0.8582089552238806\n",
      "Epoch 33:\t train loss : 0.5592468065331333; train accuracy : 0.992285572084278; \n",
      " validation loss : 0.713571276689952; validation accuracy : 0.835820895522388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:\t train loss : 0.561025703567585; train accuracy : 0.9902694853424916; \n",
      " validation loss : 0.6778120860872489; validation accuracy : 0.8731343283582089\n",
      "Epoch 35:\t train loss : 0.5610990452692242; train accuracy : 0.9903374192182789; \n",
      " validation loss : 0.6903234452530785; validation accuracy : 0.8507462686567164\n",
      "Epoch 36:\t train loss : 0.5583661594131403; train accuracy : 0.9929239121522024; \n",
      " validation loss : 0.6678791650263827; validation accuracy : 0.8805970149253731\n",
      "Epoch 37:\t train loss : 0.5609683842238142; train accuracy : 0.9904251373456113; \n",
      " validation loss : 0.6776057535678012; validation accuracy : 0.8731343283582089\n",
      "Epoch 38:\t train loss : 0.5749582135399863; train accuracy : 0.9761552095986514; \n",
      " validation loss : 0.6587441432640778; validation accuracy : 0.8955223880597015\n",
      "Epoch 39:\t train loss : 0.5603971597869949; train accuracy : 0.9912625117513687; \n",
      " validation loss : 0.7079044808598973; validation accuracy : 0.8432835820895522\n",
      "Epoch 40:\t train loss : 0.5622021742911418; train accuracy : 0.9890102058134236; \n",
      " validation loss : 0.6387547319146952; validation accuracy : 0.9104477611940298\n",
      "Epoch 41:\t train loss : 0.5588706285579648; train accuracy : 0.9924262071253817; \n",
      " validation loss : 0.685331711933755; validation accuracy : 0.8582089552238806\n",
      "Epoch 42:\t train loss : 0.5655889591497424; train accuracy : 0.9855815711842137; \n",
      " validation loss : 0.6486341901486891; validation accuracy : 0.8955223880597015\n",
      "Epoch 43:\t train loss : 0.5624284910359906; train accuracy : 0.9887360866655098; \n",
      " validation loss : 0.6924368725494512; validation accuracy : 0.8582089552238806\n",
      "Epoch 44:\t train loss : 0.5589551397935545; train accuracy : 0.992370906566846; \n",
      " validation loss : 0.6347949008590585; validation accuracy : 0.917910447761194\n",
      "Epoch 45:\t train loss : 0.5558758685649531; train accuracy : 0.9955356717206292; \n",
      " validation loss : 0.6760290845969948; validation accuracy : 0.8805970149253731\n",
      "Epoch 46:\t train loss : 0.567602818282046; train accuracy : 0.9834675166426078; \n",
      " validation loss : 0.6538482756737621; validation accuracy : 0.8955223880597015\n",
      "Epoch 47:\t train loss : 0.565881154593326; train accuracy : 0.9850988831194092; \n",
      " validation loss : 0.6824416201717108; validation accuracy : 0.8656716417910447\n",
      "Epoch 48:\t train loss : 0.5587766990517211; train accuracy : 0.9927153432353115; \n",
      " validation loss : 0.6480115476046577; validation accuracy : 0.9029850746268657\n",
      "Epoch 49:\t train loss : 0.5557728616527212; train accuracy : 0.99568655643422; \n",
      " validation loss : 0.6760006675032808; validation accuracy : 0.8731343283582089\n",
      "Epoch 50:\t train loss : 0.5570868597249455; train accuracy : 0.9942384922398061; \n",
      " validation loss : 0.7013728031529501; validation accuracy : 0.8507462686567164\n",
      "Epoch 51:\t train loss : 0.5569696979446743; train accuracy : 0.9943467097121129; \n",
      " validation loss : 0.6799034245209445; validation accuracy : 0.8731343283582089\n",
      "Epoch 52:\t train loss : 0.5555810688426565; train accuracy : 0.9956589061549521; \n",
      " validation loss : 0.7202253641148614; validation accuracy : 0.8283582089552238\n",
      "Epoch 53:\t train loss : 0.5603400322219494; train accuracy : 0.9910010259207066; \n",
      " validation loss : 0.6529261683933907; validation accuracy : 0.9029850746268657\n",
      "Epoch 54:\t train loss : 0.5574352856894834; train accuracy : 0.9939445888403473; \n",
      " validation loss : 0.6521889709861368; validation accuracy : 0.8955223880597015\n",
      "Epoch 55:\t train loss : 0.5609579631849804; train accuracy : 0.990357203469824; \n",
      " validation loss : 0.6254444052725757; validation accuracy : 0.9328358208955224\n",
      "Epoch 56:\t train loss : 0.5691241971751833; train accuracy : 0.9818938343691065; \n",
      " validation loss : 0.6762234911805549; validation accuracy : 0.8656716417910447\n",
      "Epoch 57:\t train loss : 0.5590565284115783; train accuracy : 0.9922026212464746; \n",
      " validation loss : 0.657480755787823; validation accuracy : 0.8880597014925373\n",
      "Epoch 58:\t train loss : 0.5573101283904682; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.6501617765288955; validation accuracy : 0.8955223880597015\n",
      "Epoch 59:\t train loss : 0.5581093326574188; train accuracy : 0.9932130482621323; \n",
      " validation loss : 0.6632345769066398; validation accuracy : 0.8880597014925373\n",
      "Epoch 60:\t train loss : 0.5564359741699305; train accuracy : 0.9949273655767371; \n",
      " validation loss : 0.6641004341748818; validation accuracy : 0.8805970149253731\n",
      "Epoch 61:\t train loss : 0.5590857723816642; train accuracy : 0.9921094207361839; \n",
      " validation loss : 0.6762747310433482; validation accuracy : 0.8805970149253731\n",
      "Epoch 62:\t train loss : 0.5586813030631533; train accuracy : 0.992675059638792; \n",
      " validation loss : 0.6613524681631215; validation accuracy : 0.8880597014925373\n",
      "Epoch 63:\t train loss : 0.5798133125512016; train accuracy : 0.9709293068170334; \n",
      " validation loss : 0.6754002685186583; validation accuracy : 0.8731343283582089\n",
      "Epoch 64:\t train loss : 0.5593869982728163; train accuracy : 0.9920944037741678; \n",
      " validation loss : 0.6685159926265902; validation accuracy : 0.8805970149253731\n",
      "Epoch 65:\t train loss : 0.5618572849940965; train accuracy : 0.9893822927611569; \n",
      " validation loss : 0.6959814556826428; validation accuracy : 0.8582089552238806\n",
      "Epoch 66:\t train loss : 0.5562302060297781; train accuracy : 0.9951762180901476; \n",
      " validation loss : 0.7001805459707143; validation accuracy : 0.8507462686567164\n",
      "Epoch 67:\t train loss : 0.5553169585958706; train accuracy : 0.9960886773059856; \n",
      " validation loss : 0.6563137971658538; validation accuracy : 0.8955223880597015\n",
      "Epoch 68:\t train loss : 0.5545718366556136; train accuracy : 0.9966819664878616; \n",
      " validation loss : 0.6605901879592607; validation accuracy : 0.8880597014925373\n",
      "Epoch 69:\t train loss : 0.5581675041638146; train accuracy : 0.9930621635485415; \n",
      " validation loss : 0.6605919216428645; validation accuracy : 0.8880597014925373\n",
      "Epoch 70:\t train loss : 0.5569441428227648; train accuracy : 0.9946634961013107; \n",
      " validation loss : 0.6685194944596708; validation accuracy : 0.8880597014925373\n",
      "Epoch 71:\t train loss : 0.5662156824600579; train accuracy : 0.9849456147610539; \n",
      " validation loss : 0.6742162033317316; validation accuracy : 0.8731343283582089\n",
      "Epoch 72:\t train loss : 0.5601559454593877; train accuracy : 0.9910010259207066; \n",
      " validation loss : 0.6745924490725881; validation accuracy : 0.8805970149253731\n",
      "Epoch 73:\t train loss : 0.5595095411504444; train accuracy : 0.9918431676159929; \n",
      " validation loss : 0.6898506419809001; validation accuracy : 0.8582089552238806\n",
      "Epoch 74:\t train loss : 0.5587272335627355; train accuracy : 0.9925668421664852; \n",
      " validation loss : 0.6705840228314326; validation accuracy : 0.8805970149253731\n",
      "Epoch 75:\t train loss : 0.5609181984107974; train accuracy : 0.9901991678219398; \n",
      " validation loss : 0.70065630067259; validation accuracy : 0.8507462686567164\n",
      "Epoch 76:\t train loss : 0.5568873597229871; train accuracy : 0.9945679119462555; \n",
      " validation loss : 0.660820319573825; validation accuracy : 0.8880597014925373\n",
      "Epoch 77:\t train loss : 0.5558836443896997; train accuracy : 0.9954930044793452; \n",
      " validation loss : 0.6580059606898659; validation accuracy : 0.8880597014925373\n",
      "Epoch 78:\t train loss : 0.5553512833988072; train accuracy : 0.9960736603439695; \n",
      " validation loss : 0.6411789853472697; validation accuracy : 0.9104477611940298\n",
      "Epoch 79:\t train loss : 0.5628189360277356; train accuracy : 0.9884295499487993; \n",
      " validation loss : 0.6486110577853865; validation accuracy : 0.9104477611940298\n",
      "Epoch 80:\t train loss : 0.5948196760546131; train accuracy : 0.955540734582109; \n",
      " validation loss : 0.6488160739998222; validation accuracy : 0.9029850746268657\n",
      "Epoch 81:\t train loss : 0.5585092178819084; train accuracy : 0.992855978276415; \n",
      " validation loss : 0.6490469015889637; validation accuracy : 0.9029850746268657\n",
      "Epoch 82:\t train loss : 0.5569177844551085; train accuracy : 0.9944170272326647; \n",
      " validation loss : 0.6935073869020187; validation accuracy : 0.8582089552238806\n",
      "Epoch 83:\t train loss : 0.5548194544958786; train accuracy : 0.996599015650058; \n",
      " validation loss : 0.6504634613896024; validation accuracy : 0.9029850746268657\n",
      "Epoch 84:\t train loss : 0.5592887683070792; train accuracy : 0.9919261184537964; \n",
      " validation loss : 0.6685708393048744; validation accuracy : 0.8805970149253731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85:\t train loss : 0.5570718833911188; train accuracy : 0.9943340763948613; \n",
      " validation loss : 0.6249504149716125; validation accuracy : 0.9253731343283582\n",
      "Epoch 86:\t train loss : 0.5558333355835514; train accuracy : 0.9955657056446615; \n",
      " validation loss : 0.6532191302967394; validation accuracy : 0.8955223880597015\n",
      "Epoch 87:\t train loss : 0.565660856688497; train accuracy : 0.9853477356328195; \n",
      " validation loss : 0.6910530296242562; validation accuracy : 0.8582089552238806\n",
      "Epoch 88:\t train loss : 0.5641059634328716; train accuracy : 0.9872856388263315; \n",
      " validation loss : 0.6477244490972119; validation accuracy : 0.9029850746268657\n",
      "Epoch 89:\t train loss : 0.5568007325796209; train accuracy : 0.9944146435879002; \n",
      " validation loss : 0.633456893271227; validation accuracy : 0.917910447761194\n",
      "Epoch 90:\t train loss : 0.5539589320136878; train accuracy : 0.9974561743073604; \n",
      " validation loss : 0.6373162647371107; validation accuracy : 0.9104477611940298\n",
      "Epoch 91:\t train loss : 0.5553359685041059; train accuracy : 0.9960057264681822; \n",
      " validation loss : 0.6394267003904431; validation accuracy : 0.9104477611940298\n",
      "Epoch 92:\t train loss : 0.5545432628817917; train accuracy : 0.996807584566949; \n",
      " validation loss : 0.6275960462061931; validation accuracy : 0.9253731343283582\n",
      "Epoch 93:\t train loss : 0.5557497775761192; train accuracy : 0.9955483050378808; \n",
      " validation loss : 0.6267748495715193; validation accuracy : 0.9253731343283582\n",
      "Epoch 94:\t train loss : 0.5551282199715767; train accuracy : 0.9962545789815925; \n",
      " validation loss : 0.626030318903078; validation accuracy : 0.9253731343283582\n",
      "Epoch 95:\t train loss : 0.5550882154076195; train accuracy : 0.9963651800986638; \n",
      " validation loss : 0.6536669660574501; validation accuracy : 0.8880597014925373\n",
      "Epoch 96:\t train loss : 0.5902542244001721; train accuracy : 0.9602033821058834; \n",
      " validation loss : 0.6720806273700922; validation accuracy : 0.8731343283582089\n",
      "Epoch 97:\t train loss : 0.5882249501934634; train accuracy : 0.9625109886023642; \n",
      " validation loss : 0.6352480169005924; validation accuracy : 0.917910447761194\n",
      "Epoch 98:\t train loss : 0.5675603324858621; train accuracy : 0.9836610685974825; \n",
      " validation loss : 0.6735931514045688; validation accuracy : 0.8731343283582089\n",
      "Epoch 99:\t train loss : 0.562646058306644; train accuracy : 0.9885527843831222; \n",
      " validation loss : 0.6627736185067913; validation accuracy : 0.8880597014925373\n",
      "Epoch 100:\t train loss : 0.5571062048593624; train accuracy : 0.9942487419122933; \n",
      " validation loss : 0.6419794907639099; validation accuracy : 0.9104477611940298\n",
      "Epoch 101:\t train loss : 0.5558748109474255; train accuracy : 0.9954677378448419; \n",
      " validation loss : 0.6790215725310684; validation accuracy : 0.8731343283582089\n",
      "Epoch 102:\t train loss : 0.5542689559174383; train accuracy : 0.9971796715146823; \n",
      " validation loss : 0.6608557277772595; validation accuracy : 0.8955223880597015\n",
      "Epoch 103:\t train loss : 0.5536901571366835; train accuracy : 0.9977326771000387; \n",
      " validation loss : 0.6547599185444839; validation accuracy : 0.8955223880597015\n",
      "Epoch 104:\t train loss : 0.5559089960680418; train accuracy : 0.9955080214413614; \n",
      " validation loss : 0.6631612453208455; validation accuracy : 0.8880597014925373\n",
      "Epoch 105:\t train loss : 0.5553547678186419; train accuracy : 0.9960183597854338; \n",
      " validation loss : 0.6459243385689531; validation accuracy : 0.9104477611940298\n",
      "Epoch 106:\t train loss : 0.5594416453806503; train accuracy : 0.9917649840677184; \n",
      " validation loss : 0.6406924313040759; validation accuracy : 0.9104477611940298\n",
      "Epoch 107:\t train loss : 0.5561162275154375; train accuracy : 0.9951485678108797; \n",
      " validation loss : 0.6735127903105439; validation accuracy : 0.8805970149253731\n",
      "Epoch 108:\t train loss : 0.5590072758665303; train accuracy : 0.9923432562875781; \n",
      " validation loss : 0.6678557813137638; validation accuracy : 0.8805970149253731\n",
      "Epoch 109:\t train loss : 0.5560454879655935; train accuracy : 0.9954100536415418; \n",
      " validation loss : 0.6858778626321248; validation accuracy : 0.8656716417910447\n",
      "Epoch 110:\t train loss : 0.5539775861978015; train accuracy : 0.9974561743073604; \n",
      " validation loss : 0.6699548339919024; validation accuracy : 0.8880597014925373\n",
      "Epoch 111:\t train loss : 0.5542908519913325; train accuracy : 0.9971117376388949; \n",
      " validation loss : 0.6720789455447265; validation accuracy : 0.8805970149253731\n",
      "Epoch 112:\t train loss : 0.5537138858961136; train accuracy : 0.9977879776585743; \n",
      " validation loss : 0.6248465245864249; validation accuracy : 0.9253731343283582\n",
      "Epoch 113:\t train loss : 0.5534760653333586; train accuracy : 0.9979815296134491; \n",
      " validation loss : 0.6377098546516129; validation accuracy : 0.9104477611940298\n",
      "Epoch 114:\t train loss : 0.554396822324992; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.6764341496033524; validation accuracy : 0.8731343283582089\n",
      "Epoch 115:\t train loss : 0.5547389081581497; train accuracy : 0.9965208321017835; \n",
      " validation loss : 0.6386801915673577; validation accuracy : 0.9104477611940298\n",
      "Epoch 116:\t train loss : 0.5574987163444985; train accuracy : 0.9939193222058439; \n",
      " validation loss : 0.6544940990272139; validation accuracy : 0.8955223880597015\n",
      "Epoch 117:\t train loss : 0.5587330068104416; train accuracy : 0.9925897251562241; \n",
      " validation loss : 0.6423339314926098; validation accuracy : 0.9104477611940298\n",
      "Epoch 118:\t train loss : 0.5619702374457731; train accuracy : 0.9890781396892109; \n",
      " validation loss : 0.6475323105322828; validation accuracy : 0.9029850746268657\n",
      "Epoch 119:\t train loss : 0.5679077120854448; train accuracy : 0.98315073025341; \n",
      " validation loss : 0.6487655956678914; validation accuracy : 0.9029850746268657\n",
      "Epoch 120:\t train loss : 0.5580936578710003; train accuracy : 0.993225681579384; \n",
      " validation loss : 0.6631027590088077; validation accuracy : 0.8880597014925373\n",
      "Epoch 121:\t train loss : 0.5545321605464382; train accuracy : 0.9967246337291454; \n",
      " validation loss : 0.6267322378846811; validation accuracy : 0.9253731343283582\n",
      "Epoch 122:\t train loss : 0.5555522465850798; train accuracy : 0.995729223675504; \n",
      " validation loss : 0.6536106856439434; validation accuracy : 0.8955223880597015\n",
      "Epoch 123:\t train loss : 0.5536338597717123; train accuracy : 0.9977326771000387; \n",
      " validation loss : 0.6409104675547673; validation accuracy : 0.9104477611940298\n",
      "Epoch 124:\t train loss : 0.5546961744689874; train accuracy : 0.9967246337291454; \n",
      " validation loss : 0.6846845005040306; validation accuracy : 0.8656716417910447\n",
      "Epoch 125:\t train loss : 0.5547489727429714; train accuracy : 0.9966819664878616; \n",
      " validation loss : 0.6588088665090559; validation accuracy : 0.8880597014925373\n",
      "Epoch 126:\t train loss : 0.5544424616930413; train accuracy : 0.9970011365218236; \n",
      " validation loss : 0.665652814378105; validation accuracy : 0.8805970149253731\n",
      "Epoch 127:\t train loss : 0.553332352242436; train accuracy : 0.9980241968547331; \n",
      " validation loss : 0.6613587579915895; validation accuracy : 0.8880597014925373\n",
      "Epoch 128:\t train loss : 0.5555984055420544; train accuracy : 0.9957418569927556; \n",
      " validation loss : 0.643773230322451; validation accuracy : 0.9104477611940298\n",
      "Epoch 129:\t train loss : 0.5543610063863138; train accuracy : 0.9970287868010915; \n",
      " validation loss : 0.6335311287170317; validation accuracy : 0.917910447761194\n",
      "Epoch 130:\t train loss : 0.552972115975516; train accuracy : 0.9984239340817342; \n",
      " validation loss : 0.6245349892944765; validation accuracy : 0.9253731343283582\n",
      "Epoch 131:\t train loss : 0.5562642290227058; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6400128016242402; validation accuracy : 0.9104477611940298\n",
      "Epoch 132:\t train loss : 0.7339478012339783; train accuracy : 0.8140380467842725; \n",
      " validation loss : 0.8295825975791375; validation accuracy : 0.7238805970149254\n",
      "Epoch 133:\t train loss : 0.6722978593175465; train accuracy : 0.8766585400271163; \n",
      " validation loss : 0.7436182788458645; validation accuracy : 0.7985074626865671\n",
      "Epoch 134:\t train loss : 0.6096891717625063; train accuracy : 0.9403149652845977; \n",
      " validation loss : 0.6702556823593062; validation accuracy : 0.8805970149253731\n",
      "Epoch 135:\t train loss : 0.5882514203431052; train accuracy : 0.9626089564021838; \n",
      " validation loss : 0.7281723212623787; validation accuracy : 0.8208955223880597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136:\t train loss : 0.5783310606380162; train accuracy : 0.9724121722250084; \n",
      " validation loss : 0.6995794998702694; validation accuracy : 0.8507462686567164\n",
      "Epoch 137:\t train loss : 0.5708233684242743; train accuracy : 0.9805768706367383; \n",
      " validation loss : 0.7123967953826317; validation accuracy : 0.835820895522388\n",
      "Epoch 138:\t train loss : 0.5673820030439646; train accuracy : 0.9838798871868606; \n",
      " validation loss : 0.6545291203403125; validation accuracy : 0.8955223880597015\n",
      "Epoch 139:\t train loss : 0.5666789889110617; train accuracy : 0.9843396922619263; \n",
      " validation loss : 0.690184897642246; validation accuracy : 0.8582089552238806\n",
      "Epoch 140:\t train loss : 0.5646894877287402; train accuracy : 0.986594381844636; \n",
      " validation loss : 0.704894267600865; validation accuracy : 0.8432835820895522\n",
      "Epoch 141:\t train loss : 0.5847636595243855; train accuracy : 0.9662966932172912; \n",
      " validation loss : 0.7031082487000793; validation accuracy : 0.8507462686567164\n",
      "Epoch 142:\t train loss : 0.5617699090614272; train accuracy : 0.9897164797571352; \n",
      " validation loss : 0.6808470189276878; validation accuracy : 0.8656716417910447\n",
      "Epoch 143:\t train loss : 0.5594486664334238; train accuracy : 0.9919411354158125; \n",
      " validation loss : 0.7340924174700932; validation accuracy : 0.8208955223880597\n",
      "Epoch 144:\t train loss : 0.5602476530349717; train accuracy : 0.9909583586794226; \n",
      " validation loss : 0.6867668322373307; validation accuracy : 0.8656716417910447\n",
      "Epoch 145:\t train loss : 0.5567591566902225; train accuracy : 0.9946508627840589; \n",
      " validation loss : 0.7013688703508913; validation accuracy : 0.8507462686567164\n",
      "Epoch 146:\t train loss : 0.5586915459037978; train accuracy : 0.9928385776696345; \n",
      " validation loss : 0.6673434407355913; validation accuracy : 0.8880597014925373\n",
      "Epoch 147:\t train loss : 0.559579256068372; train accuracy : 0.9917752337402056; \n",
      " validation loss : 0.6568963356599276; validation accuracy : 0.9029850746268657\n",
      "Epoch 148:\t train loss : 0.5599105505287552; train accuracy : 0.9913628631959528; \n",
      " validation loss : 0.6785805189323586; validation accuracy : 0.8731343283582089\n",
      "Epoch 149:\t train loss : 0.5572648304802198; train accuracy : 0.9941657910744899; \n",
      " validation loss : 0.707598392471647; validation accuracy : 0.8432835820895522\n",
      "Epoch 150:\t train loss : 0.5564538730453878; train accuracy : 0.9951059005695957; \n",
      " validation loss : 0.6802175009325198; validation accuracy : 0.8656716417910447\n",
      "Epoch 151:\t train loss : 0.5559750475627088; train accuracy : 0.9954930044793452; \n",
      " validation loss : 0.6908473289675895; validation accuracy : 0.8582089552238806\n",
      "Epoch 152:\t train loss : 0.5569017013546651; train accuracy : 0.994484961108452; \n",
      " validation loss : 0.6640011845431435; validation accuracy : 0.8880597014925373\n",
      "Epoch 153:\t train loss : 0.5571467046946941; train accuracy : 0.9942511255570577; \n",
      " validation loss : 0.6916644789578973; validation accuracy : 0.8507462686567164\n",
      "Epoch 154:\t train loss : 0.5596558748691488; train accuracy : 0.9917776173849701; \n",
      " validation loss : 0.6608249465458195; validation accuracy : 0.8880597014925373\n",
      "Epoch 155:\t train loss : 0.5579008748374102; train accuracy : 0.9935172013340783; \n",
      " validation loss : 0.6283793652964111; validation accuracy : 0.9253731343283582\n",
      "Epoch 156:\t train loss : 0.5639104028021935; train accuracy : 0.9871876710265118; \n",
      " validation loss : 0.6852846963098759; validation accuracy : 0.8582089552238806\n",
      "Epoch 157:\t train loss : 0.5580618145745928; train accuracy : 0.9933512996584714; \n",
      " validation loss : 0.648890051344189; validation accuracy : 0.9029850746268657\n",
      "Epoch 158:\t train loss : 0.5552400755060011; train accuracy : 0.9961439778645212; \n",
      " validation loss : 0.6726433491824708; validation accuracy : 0.8656716417910447\n",
      "Epoch 159:\t train loss : 0.5545977045303445; train accuracy : 0.9967925676049328; \n",
      " validation loss : 0.6719442158863822; validation accuracy : 0.8805970149253731\n",
      "Epoch 160:\t train loss : 0.5555218852090897; train accuracy : 0.995729223675504; \n",
      " validation loss : 0.6813859400848659; validation accuracy : 0.8731343283582089\n",
      "Epoch 161:\t train loss : 0.5547045666034381; train accuracy : 0.9967372670463972; \n",
      " validation loss : 0.6731018792815698; validation accuracy : 0.8731343283582089\n",
      "Epoch 162:\t train loss : 0.5572163717234316; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.7003783161454764; validation accuracy : 0.8507462686567164\n",
      "Epoch 163:\t train loss : 0.556194160114291; train accuracy : 0.9952188853314314; \n",
      " validation loss : 0.7359274954902826; validation accuracy : 0.8134328358208955\n",
      "Epoch 164:\t train loss : 0.5557316253936591; train accuracy : 0.9957568739547717; \n",
      " validation loss : 0.66387826896055; validation accuracy : 0.8880597014925373\n",
      "Epoch 165:\t train loss : 0.5561502979985485; train accuracy : 0.9952868192072188; \n",
      " validation loss : 0.7129313321465544; validation accuracy : 0.835820895522388\n",
      "Epoch 166:\t train loss : 0.5555668700113828; train accuracy : 0.9957418569927556; \n",
      " validation loss : 0.6578515054249116; validation accuracy : 0.8880597014925373\n",
      "Epoch 167:\t train loss : 0.554138424045536; train accuracy : 0.9972073217939501; \n",
      " validation loss : 0.6715317676684155; validation accuracy : 0.8805970149253731\n",
      "Epoch 168:\t train loss : 0.5540639638353163; train accuracy : 0.9973179229110214; \n",
      " validation loss : 0.6454565607492189; validation accuracy : 0.9029850746268657\n",
      "Epoch 169:\t train loss : 0.5538992287442328; train accuracy : 0.9974561743073604; \n",
      " validation loss : 0.6614831743090682; validation accuracy : 0.8880597014925373\n",
      "Epoch 170:\t train loss : 0.5538245499011156; train accuracy : 0.9976370929449836; \n",
      " validation loss : 0.683200351755397; validation accuracy : 0.8656716417910447\n",
      "Epoch 171:\t train loss : 0.5547859905372737; train accuracy : 0.9966013992948225; \n",
      " validation loss : 0.6960923242922047; validation accuracy : 0.8507462686567164\n",
      "Epoch 172:\t train loss : 0.5566908822749382; train accuracy : 0.9947235639493752; \n",
      " validation loss : 0.6756834352361599; validation accuracy : 0.8731343283582089\n",
      "Epoch 173:\t train loss : 0.5573793289209068; train accuracy : 0.9939217058506084; \n",
      " validation loss : 0.672668588457192; validation accuracy : 0.8805970149253731\n",
      "Epoch 174:\t train loss : 0.5856919122144802; train accuracy : 0.9648865289746323; \n",
      " validation loss : 0.6924256931714057; validation accuracy : 0.8582089552238806\n",
      "Epoch 175:\t train loss : 0.5656076525245719; train accuracy : 0.9856495050600012; \n",
      " validation loss : 0.7426171454418217; validation accuracy : 0.8059701492537313\n",
      "Epoch 176:\t train loss : 0.5583585232208998; train accuracy : 0.9930321296245092; \n",
      " validation loss : 0.7173532028507426; validation accuracy : 0.835820895522388\n",
      "Epoch 177:\t train loss : 0.5651182728306421; train accuracy : 0.9858707072941437; \n",
      " validation loss : 0.7309275562811298; validation accuracy : 0.8208955223880597\n",
      "Epoch 178:\t train loss : 0.5599174640537814; train accuracy : 0.9913225795994333; \n",
      " validation loss : 0.6795016110545169; validation accuracy : 0.8731343283582089\n",
      "Epoch 179:\t train loss : 0.5601571709905391; train accuracy : 0.9910689597964939; \n",
      " validation loss : 0.6882821755102314; validation accuracy : 0.8582089552238806\n",
      "Epoch 180:\t train loss : 0.5549242138681172; train accuracy : 0.996460764253719; \n",
      " validation loss : 0.670074186368426; validation accuracy : 0.8805970149253731\n",
      "Early stopping at epoch 180\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.552972115975516; Train accuracy : 0.9984239340817342; \n",
      " Validation loss : 0.6245349892944765; Validation accuracy : 0.9253731343283582\n",
      "------------------------------ Let's train model 8 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9066761567947119; train accuracy : 0.6236488337369417; \n",
      " validation loss : 0.8501999084943225; validation accuracy : 0.7014925373134329\n",
      "Epoch 2:\t train loss : 0.7755041060936539; train accuracy : 0.7681279732088084; \n",
      " validation loss : 0.8156208560609421; validation accuracy : 0.7388059701492538\n",
      "Epoch 3:\t train loss : 0.7187994418089074; train accuracy : 0.8287315980961175; \n",
      " validation loss : 0.797352298641534; validation accuracy : 0.7611940298507462\n",
      "Epoch 4:\t train loss : 0.6739800718243346; train accuracy : 0.875753148595173; \n",
      " validation loss : 0.7382428546978209; validation accuracy : 0.8134328358208955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\t train loss : 0.6424513558573365; train accuracy : 0.907799822266577; \n",
      " validation loss : 0.7377926280861188; validation accuracy : 0.8208955223880597\n",
      "Epoch 6:\t train loss : 0.6229474733882261; train accuracy : 0.9285060232596721; \n",
      " validation loss : 0.7674977081930154; validation accuracy : 0.7761194029850746\n",
      "Epoch 7:\t train loss : 0.6198504976150168; train accuracy : 0.9318594234080834; \n",
      " validation loss : 0.742267750833626; validation accuracy : 0.7985074626865671\n",
      "Epoch 8:\t train loss : 0.6102347621215567; train accuracy : 0.9414977963370453; \n",
      " validation loss : 0.7281803871446828; validation accuracy : 0.8208955223880597\n",
      "Epoch 9:\t train loss : 0.5927223102578527; train accuracy : 0.9593322264647897; \n",
      " validation loss : 0.6635452416288949; validation accuracy : 0.8731343283582089\n",
      "Epoch 10:\t train loss : 0.5788442041008492; train accuracy : 0.973349953508949; \n",
      " validation loss : 0.7009727971377405; validation accuracy : 0.8507462686567164\n",
      "Epoch 11:\t train loss : 0.5779746543904112; train accuracy : 0.9739563305635899; \n",
      " validation loss : 0.7118259063073595; validation accuracy : 0.835820895522388\n",
      "Epoch 12:\t train loss : 0.5770270019562013; train accuracy : 0.9749527051618571; \n",
      " validation loss : 0.7100612035353264; validation accuracy : 0.8432835820895522\n",
      "Epoch 13:\t train loss : 0.5715416436324663; train accuracy : 0.9803721598983498; \n",
      " validation loss : 0.6759334533604963; validation accuracy : 0.8731343283582089\n",
      "Epoch 14:\t train loss : 0.5735642866823092; train accuracy : 0.9784070609810833; \n",
      " validation loss : 0.6867006658134716; validation accuracy : 0.8582089552238806\n",
      "Epoch 15:\t train loss : 0.5774040449812273; train accuracy : 0.973795251611111; \n",
      " validation loss : 0.6916857901721335; validation accuracy : 0.8656716417910447\n",
      "Epoch 16:\t train loss : 0.5720952559815995; train accuracy : 0.9795741599780855; \n",
      " validation loss : 0.6768463859593322; validation accuracy : 0.8731343283582089\n",
      "Epoch 17:\t train loss : 0.5626360586022839; train accuracy : 0.9891906698955334; \n",
      " validation loss : 0.6683075990602942; validation accuracy : 0.8955223880597015\n",
      "Epoch 18:\t train loss : 0.5590250788535969; train accuracy : 0.9926212336139943; \n",
      " validation loss : 0.6772858507421505; validation accuracy : 0.8656716417910447\n",
      "Epoch 19:\t train loss : 0.5631651298957056; train accuracy : 0.9886109785755348; \n",
      " validation loss : 0.6704547370272216; validation accuracy : 0.8731343283582089\n",
      "Epoch 20:\t train loss : 0.5583524933916361; train accuracy : 0.9933124905956899; \n",
      " validation loss : 0.703546312069597; validation accuracy : 0.8432835820895522\n",
      "Epoch 21:\t train loss : 0.5727784320562451; train accuracy : 0.9784385694388537; \n",
      " validation loss : 0.7276167866521579; validation accuracy : 0.8208955223880597\n",
      "Epoch 22:\t train loss : 0.5632822923277533; train accuracy : 0.988279175224321; \n",
      " validation loss : 0.7209195230052676; validation accuracy : 0.8283582089552238\n",
      "Epoch 23:\t train loss : 0.5696995545593887; train accuracy : 0.9812331767341548; \n",
      " validation loss : 0.6910720397042388; validation accuracy : 0.8582089552238806\n",
      "Epoch 24:\t train loss : 0.5600369040198655; train accuracy : 0.9915181160771585; \n",
      " validation loss : 0.690305889048247; validation accuracy : 0.8582089552238806\n",
      "Epoch 25:\t train loss : 0.597984823322987; train accuracy : 0.952406474537951; \n",
      " validation loss : 0.7663708717153508; validation accuracy : 0.7761194029850746\n",
      "Epoch 26:\t train loss : 0.5889064986798233; train accuracy : 0.9615538942524715; \n",
      " validation loss : 0.6993785456400003; validation accuracy : 0.8507462686567164\n",
      "Epoch 27:\t train loss : 0.5802271954632263; train accuracy : 0.9711112454328812; \n",
      " validation loss : 0.6808746805555618; validation accuracy : 0.8731343283582089\n",
      "Epoch 28:\t train loss : 0.5671352749957278; train accuracy : 0.9842489862635985; \n",
      " validation loss : 0.6800628658475993; validation accuracy : 0.8582089552238806\n",
      "Epoch 29:\t train loss : 0.5622986978260988; train accuracy : 0.9890562766776968; \n",
      " validation loss : 0.693945004708752; validation accuracy : 0.8507462686567164\n",
      "Epoch 30:\t train loss : 0.5616956801531995; train accuracy : 0.9899430147035183; \n",
      " validation loss : 0.6900026212805701; validation accuracy : 0.8656716417910447\n",
      "Epoch 31:\t train loss : 0.5592005592351605; train accuracy : 0.9920939492186546; \n",
      " validation loss : 0.7072199784537061; validation accuracy : 0.8432835820895522\n",
      "Epoch 32:\t train loss : 0.5581324709395401; train accuracy : 0.9932829112271708; \n",
      " validation loss : 0.6966152967089513; validation accuracy : 0.8507462686567164\n",
      "Epoch 33:\t train loss : 0.5575641385219705; train accuracy : 0.9937243511508304; \n",
      " validation loss : 0.724451021175126; validation accuracy : 0.8208955223880597\n",
      "Epoch 34:\t train loss : 0.5565063360498675; train accuracy : 0.9949419279832401; \n",
      " validation loss : 0.6993200364457808; validation accuracy : 0.8507462686567164\n",
      "Epoch 35:\t train loss : 0.5766127331551625; train accuracy : 0.9745742821537381; \n",
      " validation loss : 0.7837906530600571; validation accuracy : 0.7611940298507462\n",
      "Epoch 36:\t train loss : 0.5756812571853944; train accuracy : 0.975234995222289; \n",
      " validation loss : 0.7049362471731658; validation accuracy : 0.8432835820895522\n",
      "Epoch 37:\t train loss : 0.5578058532850125; train accuracy : 0.993559414019849; \n",
      " validation loss : 0.7203201663863678; validation accuracy : 0.8283582089552238\n",
      "Epoch 38:\t train loss : 0.5587819576324581; train accuracy : 0.9925096679522974; \n",
      " validation loss : 0.713313731560397; validation accuracy : 0.835820895522388\n",
      "Epoch 39:\t train loss : 0.5591470499270021; train accuracy : 0.9921788291457092; \n",
      " validation loss : 0.7176003581573168; validation accuracy : 0.835820895522388\n",
      "Epoch 40:\t train loss : 0.5590275391382044; train accuracy : 0.9921788291457092; \n",
      " validation loss : 0.7135719003780937; validation accuracy : 0.835820895522388\n",
      "Epoch 41:\t train loss : 0.5908645037408001; train accuracy : 0.9595534286989322; \n",
      " validation loss : 0.7036004471191244; validation accuracy : 0.8507462686567164\n",
      "Epoch 42:\t train loss : 0.5705133725395788; train accuracy : 0.9808756521929244; \n",
      " validation loss : 0.6600798322447378; validation accuracy : 0.8955223880597015\n",
      "Epoch 43:\t train loss : 0.5627790631459444; train accuracy : 0.9887235087818573; \n",
      " validation loss : 0.691054960051469; validation accuracy : 0.8582089552238806\n",
      "Epoch 44:\t train loss : 0.5623662250757551; train accuracy : 0.9890257327645521; \n",
      " validation loss : 0.6881055295841746; validation accuracy : 0.8656716417910447\n",
      "Epoch 45:\t train loss : 0.5585554248995823; train accuracy : 0.9928681570381536; \n",
      " validation loss : 0.6781435301716151; validation accuracy : 0.8731343283582089\n",
      "Epoch 46:\t train loss : 0.5577488662068167; train accuracy : 0.9936700151369203; \n",
      " validation loss : 0.7037639135125402; validation accuracy : 0.8507462686567164\n",
      "Epoch 47:\t train loss : 0.5568664877969737; train accuracy : 0.9944985589703293; \n",
      " validation loss : 0.703712370046381; validation accuracy : 0.8432835820895522\n",
      "Epoch 48:\t train loss : 0.5561633691306037; train accuracy : 0.9953299964376152; \n",
      " validation loss : 0.6812097078928723; validation accuracy : 0.8656716417910447\n",
      "Epoch 49:\t train loss : 0.5572195135526833; train accuracy : 0.9940847693259376; \n",
      " validation loss : 0.6719349338832887; validation accuracy : 0.8805970149253731\n",
      "Epoch 50:\t train loss : 0.5564697616996601; train accuracy : 0.9949428925278657; \n",
      " validation loss : 0.6568725901275076; validation accuracy : 0.8880597014925373\n",
      "Epoch 51:\t train loss : 0.5564043407505567; train accuracy : 0.9950792148349535; \n",
      " validation loss : 0.6899703969735649; validation accuracy : 0.8582089552238806\n",
      "Epoch 52:\t train loss : 0.5558099421411757; train accuracy : 0.9956055346856677; \n",
      " validation loss : 0.6990986309538981; validation accuracy : 0.8507462686567164\n",
      "Epoch 53:\t train loss : 0.5564244184718437; train accuracy : 0.9949438570724913; \n",
      " validation loss : 0.6721244316569679; validation accuracy : 0.8805970149253731\n",
      "Epoch 54:\t train loss : 0.5591003170539613; train accuracy : 0.9923161159974228; \n",
      " validation loss : 0.6634730382509672; validation accuracy : 0.8880597014925373\n",
      "Epoch 55:\t train loss : 0.5577785926640916; train accuracy : 0.9936423648576524; \n",
      " validation loss : 0.6886446347504955; validation accuracy : 0.8582089552238806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56:\t train loss : 0.5622172770520257; train accuracy : 0.9890266973091777; \n",
      " validation loss : 0.6866807603714262; validation accuracy : 0.8656716417910447\n",
      "Epoch 57:\t train loss : 0.5702480858307859; train accuracy : 0.9808984797490641; \n",
      " validation loss : 0.6976590652672665; validation accuracy : 0.8507462686567164\n",
      "Epoch 58:\t train loss : 0.5596916970506356; train accuracy : 0.9916505802057438; \n",
      " validation loss : 0.7013895516070172; validation accuracy : 0.8432835820895522\n",
      "Epoch 59:\t train loss : 0.5577868150627181; train accuracy : 0.9935603785644747; \n",
      " validation loss : 0.6868366202828993; validation accuracy : 0.8656716417910447\n",
      "Epoch 60:\t train loss : 0.5568763410556374; train accuracy : 0.9945271737942227; \n",
      " validation loss : 0.7117477948111097; validation accuracy : 0.8432835820895522\n",
      "Epoch 61:\t train loss : 0.5571160997731055; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.704764081641998; validation accuracy : 0.8507462686567164\n",
      "Epoch 62:\t train loss : 0.5603215157653716; train accuracy : 0.991064458588241; \n",
      " validation loss : 0.7461819390613542; validation accuracy : 0.8059701492537313\n",
      "Epoch 63:\t train loss : 0.6760515087185436; train accuracy : 0.8724913801861957; \n",
      " validation loss : 0.7577654731927325; validation accuracy : 0.7910447761194029\n",
      "Epoch 64:\t train loss : 0.6048845839377469; train accuracy : 0.9454231714484502; \n",
      " validation loss : 0.7095773321372293; validation accuracy : 0.8432835820895522\n",
      "Epoch 65:\t train loss : 0.5792839325568245; train accuracy : 0.9716909367528798; \n",
      " validation loss : 0.7122211680863423; validation accuracy : 0.835820895522388\n",
      "Epoch 66:\t train loss : 0.5701880126677878; train accuracy : 0.9807296844395803; \n",
      " validation loss : 0.6861823043504686; validation accuracy : 0.8656716417910447\n",
      "Epoch 67:\t train loss : 0.568914002083364; train accuracy : 0.9823935239187777; \n",
      " validation loss : 0.6662436245817561; validation accuracy : 0.8880597014925373\n",
      "Epoch 68:\t train loss : 0.5657739505194959; train accuracy : 0.9852968032418988; \n",
      " validation loss : 0.6742605344862962; validation accuracy : 0.8731343283582089\n",
      "Epoch 69:\t train loss : 0.565326365710644; train accuracy : 0.9859012512072883; \n",
      " validation loss : 0.7028481377476061; validation accuracy : 0.8507462686567164\n",
      "Epoch 70:\t train loss : 0.5653526104621074; train accuracy : 0.9858192649141105; \n",
      " validation loss : 0.657071561357558; validation accuracy : 0.8955223880597015\n",
      "Epoch 71:\t train loss : 0.5627102391171572; train accuracy : 0.9886653145894448; \n",
      " validation loss : 0.7062652287620438; validation accuracy : 0.8432835820895522\n",
      "Epoch 72:\t train loss : 0.5595999351470734; train accuracy : 0.991652509294995; \n",
      " validation loss : 0.6756330718873461; validation accuracy : 0.8731343283582089\n",
      "Epoch 73:\t train loss : 0.5595814407728984; train accuracy : 0.9919003972637798; \n",
      " validation loss : 0.6979651603155725; validation accuracy : 0.8507462686567164\n",
      "Epoch 74:\t train loss : 0.5592792315630412; train accuracy : 0.9921206349532967; \n",
      " validation loss : 0.6426489983256044; validation accuracy : 0.9104477611940298\n",
      "Epoch 75:\t train loss : 0.5572961001524771; train accuracy : 0.9941410344290988; \n",
      " validation loss : 0.6610491734083627; validation accuracy : 0.8880597014925373\n",
      "Epoch 76:\t train loss : 0.5636690261810121; train accuracy : 0.9875612325079832; \n",
      " validation loss : 0.659256831541922; validation accuracy : 0.8880597014925373\n",
      "Epoch 77:\t train loss : 0.5582491653556928; train accuracy : 0.9931427307415804; \n",
      " validation loss : 0.6697591406876238; validation accuracy : 0.8805970149253731\n",
      "Epoch 78:\t train loss : 0.5589314134848259; train accuracy : 0.9923161159974228; \n",
      " validation loss : 0.6633222474472771; validation accuracy : 0.8880597014925373\n",
      "Epoch 79:\t train loss : 0.5608056421281046; train accuracy : 0.9907143288891403; \n",
      " validation loss : 0.6757791923195885; validation accuracy : 0.8731343283582089\n",
      "Epoch 80:\t train loss : 0.5581805440902935; train accuracy : 0.9930330941691348; \n",
      " validation loss : 0.6647293525066836; validation accuracy : 0.8880597014925373\n",
      "Epoch 81:\t train loss : 0.5568170985394869; train accuracy : 0.9946110891766519; \n",
      " validation loss : 0.643787391408395; validation accuracy : 0.9104477611940298\n",
      "Epoch 82:\t train loss : 0.5618278244296027; train accuracy : 0.9894424160428207; \n",
      " validation loss : 0.6799190425812293; validation accuracy : 0.8731343283582089\n",
      "Epoch 83:\t train loss : 0.5598595897262214; train accuracy : 0.9913502853123003; \n",
      " validation loss : 0.6673118826325724; validation accuracy : 0.8880597014925373\n",
      "Epoch 84:\t train loss : 0.5562003914154846; train accuracy : 0.9953290318929895; \n",
      " validation loss : 0.6959725044016873; validation accuracy : 0.8507462686567164\n",
      "Epoch 85:\t train loss : 0.5570532276901576; train accuracy : 0.9944699441464359; \n",
      " validation loss : 0.6697830399727784; validation accuracy : 0.8805970149253731\n",
      "Epoch 86:\t train loss : 0.5577685723417264; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.6826229599993188; validation accuracy : 0.8656716417910447\n",
      "Epoch 87:\t train loss : 0.5564335520923173; train accuracy : 0.9949686137178823; \n",
      " validation loss : 0.6792563890193216; validation accuracy : 0.8731343283582089\n",
      "Epoch 88:\t train loss : 0.5572722988785648; train accuracy : 0.9940304333120276; \n",
      " validation loss : 0.6670193649357263; validation accuracy : 0.8805970149253731\n",
      "Epoch 89:\t train loss : 0.5574767926137545; train accuracy : 0.9938388104464041; \n",
      " validation loss : 0.6879955748234303; validation accuracy : 0.8582089552238806\n",
      "Epoch 90:\t train loss : 0.5650526138121998; train accuracy : 0.9862340191031278; \n",
      " validation loss : 0.6924531332355809; validation accuracy : 0.8582089552238806\n",
      "Epoch 91:\t train loss : 0.5659758109257607; train accuracy : 0.9849907210807015; \n",
      " validation loss : 0.6889012372993637; validation accuracy : 0.8582089552238806\n",
      "Epoch 92:\t train loss : 0.5598269023539131; train accuracy : 0.9915142578986559; \n",
      " validation loss : 0.6832408163802556; validation accuracy : 0.8656716417910447\n",
      "Epoch 93:\t train loss : 0.5830294480225393; train accuracy : 0.9676530314351524; \n",
      " validation loss : 0.6698798003729751; validation accuracy : 0.8880597014925373\n",
      "Epoch 94:\t train loss : 0.5694485559303556; train accuracy : 0.981643108200044; \n",
      " validation loss : 0.666733602098781; validation accuracy : 0.8880597014925373\n",
      "Epoch 95:\t train loss : 0.5611206495349637; train accuracy : 0.9901327084798905; \n",
      " validation loss : 0.6404815655133859; validation accuracy : 0.9104477611940298\n",
      "Epoch 96:\t train loss : 0.5592146757258087; train accuracy : 0.9919862417354601; \n",
      " validation loss : 0.6410295058262993; validation accuracy : 0.9104477611940298\n",
      "Epoch 97:\t train loss : 0.557886281547176; train accuracy : 0.9933935123442421; \n",
      " validation loss : 0.6781227142176149; validation accuracy : 0.8731343283582089\n",
      "Epoch 98:\t train loss : 0.5575399195519373; train accuracy : 0.9937806162539916; \n",
      " validation loss : 0.6705610552078092; validation accuracy : 0.8731343283582089\n",
      "Epoch 99:\t train loss : 0.556863771748837; train accuracy : 0.994553859528865; \n",
      " validation loss : 0.6843957226796811; validation accuracy : 0.8656716417910447\n",
      "Epoch 100:\t train loss : 0.5578912805469536; train accuracy : 0.9935327282852068; \n",
      " validation loss : 0.6807690734430809; validation accuracy : 0.8731343283582089\n",
      "Epoch 101:\t train loss : 0.5580264188337081; train accuracy : 0.9933391763303321; \n",
      " validation loss : 0.7133409328912959; validation accuracy : 0.835820895522388\n",
      "Epoch 102:\t train loss : 0.5571667313142451; train accuracy : 0.9942230207222768; \n",
      " validation loss : 0.6913514168784292; validation accuracy : 0.8582089552238806\n",
      "Epoch 103:\t train loss : 0.5584960492579042; train accuracy : 0.9927871352896013; \n",
      " validation loss : 0.6528883240879972; validation accuracy : 0.8955223880597015\n",
      "Epoch 104:\t train loss : 0.6070449676928399; train accuracy : 0.9432741660225652; \n",
      " validation loss : 0.7443874083067231; validation accuracy : 0.8059701492537313\n",
      "Epoch 105:\t train loss : 0.5867773333487558; train accuracy : 0.9640604242195869; \n",
      " validation loss : 0.676562352888324; validation accuracy : 0.8731343283582089\n",
      "Epoch 106:\t train loss : 0.5756869501327824; train accuracy : 0.9753636011723719; \n",
      " validation loss : 0.6846122146002962; validation accuracy : 0.8656716417910447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107:\t train loss : 0.569861006546639; train accuracy : 0.9812016682763844; \n",
      " validation loss : 0.6950506477899525; validation accuracy : 0.8582089552238806\n",
      "Epoch 108:\t train loss : 0.5659586550049109; train accuracy : 0.9855141472975388; \n",
      " validation loss : 0.7415984561505549; validation accuracy : 0.8059701492537313\n",
      "Epoch 109:\t train loss : 0.5598738348638155; train accuracy : 0.9914589573401202; \n",
      " validation loss : 0.7152800129670694; validation accuracy : 0.835820895522388\n",
      "Epoch 110:\t train loss : 0.5607668552886883; train accuracy : 0.9905455335796566; \n",
      " validation loss : 0.6886160740676365; validation accuracy : 0.8582089552238806\n",
      "Epoch 111:\t train loss : 0.5633026436743628; train accuracy : 0.987846416202292; \n",
      " validation loss : 0.7265142129497424; validation accuracy : 0.8208955223880597\n",
      "Epoch 112:\t train loss : 0.577282527686676; train accuracy : 0.9735997705669851; \n",
      " validation loss : 0.6992143566556085; validation accuracy : 0.8507462686567164\n",
      "Epoch 113:\t train loss : 0.5606611244190135; train accuracy : 0.9907133643445147; \n",
      " validation loss : 0.6960543115892188; validation accuracy : 0.8582089552238806\n",
      "Epoch 114:\t train loss : 0.5587894688947113; train accuracy : 0.9925945478793522; \n",
      " validation loss : 0.6788523872010056; validation accuracy : 0.8731343283582089\n",
      "Epoch 115:\t train loss : 0.5562185859456474; train accuracy : 0.9951097587480983; \n",
      " validation loss : 0.6840784486549307; validation accuracy : 0.8656716417910447\n",
      "Epoch 116:\t train loss : 0.5563550483417187; train accuracy : 0.9950248788210435; \n",
      " validation loss : 0.6969613010867235; validation accuracy : 0.8582089552238806\n",
      "Epoch 117:\t train loss : 0.5588475905664264; train accuracy : 0.9923714165559584; \n",
      " validation loss : 0.7004049899001519; validation accuracy : 0.8507462686567164\n",
      "Epoch 118:\t train loss : 0.5568396676968889; train accuracy : 0.994499523514955; \n",
      " validation loss : 0.6843581918446869; validation accuracy : 0.8656716417910447\n",
      "Epoch 119:\t train loss : 0.5547472475650439; train accuracy : 0.9965732944600415; \n",
      " validation loss : 0.6862638186321864; validation accuracy : 0.8656716417910447\n",
      "Epoch 120:\t train loss : 0.5547518709278784; train accuracy : 0.9966848601217384; \n",
      " validation loss : 0.691823212900777; validation accuracy : 0.8582089552238806\n",
      "Epoch 121:\t train loss : 0.5556190475327346; train accuracy : 0.9957142067134878; \n",
      " validation loss : 0.6586257945731352; validation accuracy : 0.8880597014925373\n",
      "Epoch 122:\t train loss : 0.5550915985751282; train accuracy : 0.9963797425051667; \n",
      " validation loss : 0.678743183421979; validation accuracy : 0.8731343283582089\n",
      "Epoch 123:\t train loss : 0.554646351690533; train accuracy : 0.9967925676049328; \n",
      " validation loss : 0.6909585866213949; validation accuracy : 0.8582089552238806\n",
      "Epoch 124:\t train loss : 0.5543006653060141; train accuracy : 0.9970719640314879; \n",
      " validation loss : 0.6692953370056826; validation accuracy : 0.8805970149253731\n",
      "Epoch 125:\t train loss : 0.5553662461303597; train accuracy : 0.9960212534193107; \n",
      " validation loss : 0.6778746980570827; validation accuracy : 0.8656716417910447\n",
      "Epoch 126:\t train loss : 0.558105133845511; train accuracy : 0.9932276106686352; \n",
      " validation loss : 0.6709491203022069; validation accuracy : 0.8805970149253731\n",
      "Epoch 127:\t train loss : 0.5586141795229669; train accuracy : 0.9927289410971888; \n",
      " validation loss : 0.6712743689303013; validation accuracy : 0.8805970149253731\n",
      "Epoch 128:\t train loss : 0.5556016534180848; train accuracy : 0.9959373380368816; \n",
      " validation loss : 0.6656417141563358; validation accuracy : 0.8880597014925373\n",
      "Epoch 129:\t train loss : 0.5557004568610953; train accuracy : 0.995716135802739; \n",
      " validation loss : 0.700996135823267; validation accuracy : 0.8507462686567164\n",
      "Epoch 130:\t train loss : 0.5572408556423428; train accuracy : 0.9942220561776511; \n",
      " validation loss : 0.6633053715248188; validation accuracy : 0.8880597014925373\n",
      "Epoch 131:\t train loss : 0.556078966497023; train accuracy : 0.9952174662312926; \n",
      " validation loss : 0.6777906585360407; validation accuracy : 0.8731343283582089\n",
      "Epoch 132:\t train loss : 0.5547362220760613; train accuracy : 0.9967105813117549; \n",
      " validation loss : 0.6700805043807422; validation accuracy : 0.8805970149253731\n",
      "Epoch 133:\t train loss : 0.5551551458282917; train accuracy : 0.9962414911088276; \n",
      " validation loss : 0.6840555626179635; validation accuracy : 0.8656716417910447\n",
      "Epoch 134:\t train loss : 0.5610486227013821; train accuracy : 0.9903510170801563; \n",
      " validation loss : 0.6867610435889661; validation accuracy : 0.8656716417910447\n",
      "Epoch 135:\t train loss : 0.5692690143178121; train accuracy : 0.9818919607134544; \n",
      " validation loss : 0.6729196987032182; validation accuracy : 0.8805970149253731\n",
      "Epoch 136:\t train loss : 0.5605273712291675; train accuracy : 0.9907181870676428; \n",
      " validation loss : 0.671436773656208; validation accuracy : 0.8805970149253731\n",
      "Epoch 137:\t train loss : 0.5561665153883791; train accuracy : 0.995191745041276; \n",
      " validation loss : 0.6708981508662836; validation accuracy : 0.8805970149253731\n",
      "Epoch 138:\t train loss : 0.5549173543892625; train accuracy : 0.9965456441807736; \n",
      " validation loss : 0.689797140571308; validation accuracy : 0.8656716417910447\n",
      "Epoch 139:\t train loss : 0.5542352964559184; train accuracy : 0.9972397947963461; \n",
      " validation loss : 0.6643239814000867; validation accuracy : 0.8880597014925373\n",
      "Epoch 140:\t train loss : 0.5566589505405967; train accuracy : 0.9947779553968844; \n",
      " validation loss : 0.6778672670264502; validation accuracy : 0.8731343283582089\n",
      "Epoch 141:\t train loss : 0.5561525629641327; train accuracy : 0.9952489746890629; \n",
      " validation loss : 0.6999488754764872; validation accuracy : 0.8432835820895522\n",
      "Epoch 142:\t train loss : 0.5559997633233584; train accuracy : 0.9953843324515251; \n",
      " validation loss : 0.6760723644977694; validation accuracy : 0.8731343283582089\n",
      "Epoch 143:\t train loss : 0.5537378387752203; train accuracy : 0.9977059913653965; \n",
      " validation loss : 0.6604141926246314; validation accuracy : 0.8880597014925373\n",
      "Epoch 144:\t train loss : 0.5532936594109799; train accuracy : 0.9981197810097882; \n",
      " validation loss : 0.7079196560642833; validation accuracy : 0.8432835820895522\n",
      "Epoch 145:\t train loss : 0.5543816950018211; train accuracy : 0.9970452782968456; \n",
      " validation loss : 0.6897066316204995; validation accuracy : 0.8582089552238806\n",
      "Early stopping at epoch 145\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5611206495349637; Train accuracy : 0.9901327084798905; \n",
      " Validation loss : 0.6404815655133859; Validation accuracy : 0.9104477611940298\n",
      "------------------------------ Let's train model 9 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.88532051768344; train accuracy : 0.6499035202755548; \n",
      " validation loss : 0.836508311463545; validation accuracy : 0.7089552238805971\n",
      "Epoch 2:\t train loss : 0.7681332388093827; train accuracy : 0.7770138290896738; \n",
      " validation loss : 0.771578960305382; validation accuracy : 0.7611940298507462\n",
      "Epoch 3:\t train loss : 0.7228480102677023; train accuracy : 0.8253494797797458; \n",
      " validation loss : 0.7228912876690816; validation accuracy : 0.8283582089552238\n",
      "Epoch 4:\t train loss : 0.6827256537231543; train accuracy : 0.866273868116068; \n",
      " validation loss : 0.6713023040307198; validation accuracy : 0.8731343283582089\n",
      "Epoch 5:\t train loss : 0.6638224034860638; train accuracy : 0.8860724555818014; \n",
      " validation loss : 0.6383258397957995; validation accuracy : 0.917910447761194\n",
      "Epoch 6:\t train loss : 0.634583084434639; train accuracy : 0.9168496851818203; \n",
      " validation loss : 0.6499756572829622; validation accuracy : 0.8955223880597015\n",
      "Epoch 7:\t train loss : 0.6185740223703358; train accuracy : 0.9334699717967151; \n",
      " validation loss : 0.645354458602886; validation accuracy : 0.9029850746268657\n",
      "Epoch 8:\t train loss : 0.6089472416070378; train accuracy : 0.9426217204793769; \n",
      " validation loss : 0.6464875240724326; validation accuracy : 0.9029850746268657\n",
      "Epoch 9:\t train loss : 0.6001123432661005; train accuracy : 0.952326474747395; \n",
      " validation loss : 0.6673026402705029; validation accuracy : 0.8731343283582089\n",
      "Epoch 10:\t train loss : 0.5918410191817732; train accuracy : 0.9593244641770882; \n",
      " validation loss : 0.6729280900785872; validation accuracy : 0.8731343283582089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\t train loss : 0.587374077053967; train accuracy : 0.964717749899274; \n",
      " validation loss : 0.6143503212833132; validation accuracy : 0.9328358208955224\n",
      "Epoch 12:\t train loss : 0.5780448518177632; train accuracy : 0.9738951738412558; \n",
      " validation loss : 0.6460054289976209; validation accuracy : 0.9029850746268657\n",
      "Epoch 13:\t train loss : 0.5843494147300312; train accuracy : 0.9672057812783909; \n",
      " validation loss : 0.6585620259441479; validation accuracy : 0.8880597014925373\n",
      "Epoch 14:\t train loss : 0.5758972454120561; train accuracy : 0.975528021583018; \n",
      " validation loss : 0.6441832759332348; validation accuracy : 0.9104477611940298\n",
      "Epoch 15:\t train loss : 0.5744255836124628; train accuracy : 0.9774358908524976; \n",
      " validation loss : 0.6483390105715586; validation accuracy : 0.9029850746268657\n",
      "Epoch 16:\t train loss : 0.5765433884541208; train accuracy : 0.9748644148805903; \n",
      " validation loss : 0.6534514810617559; validation accuracy : 0.8955223880597015\n",
      "Epoch 17:\t train loss : 0.5664327783418941; train accuracy : 0.9852061130817421; \n",
      " validation loss : 0.6458364644316886; validation accuracy : 0.9029850746268657\n",
      "Epoch 18:\t train loss : 0.5850283622933796; train accuracy : 0.9656005838158965; \n",
      " validation loss : 0.639344106942884; validation accuracy : 0.9104477611940298\n",
      "Epoch 19:\t train loss : 0.5697936329384815; train accuracy : 0.9812797734257116; \n",
      " validation loss : 0.629288627252239; validation accuracy : 0.917910447761194\n",
      "Epoch 20:\t train loss : 0.5673669813097652; train accuracy : 0.9840709703668007; \n",
      " validation loss : 0.6557436743424478; validation accuracy : 0.8955223880597015\n",
      "Epoch 21:\t train loss : 0.5657633614594599; train accuracy : 0.985564085447263; \n",
      " validation loss : 0.6597422760499685; validation accuracy : 0.8880597014925373\n",
      "Epoch 22:\t train loss : 0.5629421444635394; train accuracy : 0.9886628917452066; \n",
      " validation loss : 0.6312425994469406; validation accuracy : 0.9104477611940298\n",
      "Epoch 23:\t train loss : 0.5713293934590769; train accuracy : 0.9798419589037849; \n",
      " validation loss : 0.6617810403032531; validation accuracy : 0.8880597014925373\n",
      "Epoch 24:\t train loss : 0.569248641598099; train accuracy : 0.9818056224867872; \n",
      " validation loss : 0.6305871647336594; validation accuracy : 0.9104477611940298\n",
      "Epoch 25:\t train loss : 0.568483708532937; train accuracy : 0.9827175879476383; \n",
      " validation loss : 0.6523130254057263; validation accuracy : 0.9029850746268657\n",
      "Epoch 26:\t train loss : 0.5634774503154043; train accuracy : 0.9881923432426668; \n",
      " validation loss : 0.6366118292615683; validation accuracy : 0.9104477611940298\n",
      "Epoch 27:\t train loss : 0.5596286377499917; train accuracy : 0.9920362258158807; \n",
      " validation loss : 0.6504470154531684; validation accuracy : 0.9029850746268657\n",
      "Epoch 28:\t train loss : 0.5622808591212594; train accuracy : 0.9893808114961962; \n",
      " validation loss : 0.689481778817785; validation accuracy : 0.8582089552238806\n",
      "Epoch 29:\t train loss : 0.5814030636049781; train accuracy : 0.9695279109819009; \n",
      " validation loss : 0.6540887690499482; validation accuracy : 0.8955223880597015\n",
      "Epoch 30:\t train loss : 0.5612593184775971; train accuracy : 0.9902113073842046; \n",
      " validation loss : 0.6443142901683852; validation accuracy : 0.9029850746268657\n",
      "Epoch 31:\t train loss : 0.5613962926808095; train accuracy : 0.9896578080438613; \n",
      " validation loss : 0.6570865693920125; validation accuracy : 0.8955223880597015\n",
      "Epoch 32:\t train loss : 0.5632747332619235; train accuracy : 0.9881918494876798; \n",
      " validation loss : 0.656733905923015; validation accuracy : 0.8880597014925373\n",
      "Epoch 33:\t train loss : 0.5592264296344411; train accuracy : 0.9922292840157686; \n",
      " validation loss : 0.630541571448217; validation accuracy : 0.9253731343283582\n",
      "Epoch 34:\t train loss : 0.5591764808418496; train accuracy : 0.9923956794463624; \n",
      " validation loss : 0.6390524307220109; validation accuracy : 0.9104477611940298\n",
      "Epoch 35:\t train loss : 0.5634573704130948; train accuracy : 0.9879375656694133; \n",
      " validation loss : 0.6862995156587809; validation accuracy : 0.8656716417910447\n",
      "Epoch 36:\t train loss : 0.5767340827522806; train accuracy : 0.9744782984808147; \n",
      " validation loss : 0.6792440174836171; validation accuracy : 0.8731343283582089\n",
      "Epoch 37:\t train loss : 0.562707734186358; train accuracy : 0.9887176985487554; \n",
      " validation loss : 0.64822478162832; validation accuracy : 0.9029850746268657\n",
      "Epoch 38:\t train loss : 0.5635461807524452; train accuracy : 0.9877217947401269; \n",
      " validation loss : 0.6369217047010397; validation accuracy : 0.9104477611940298\n",
      "Epoch 39:\t train loss : 0.5655464343648219; train accuracy : 0.9855927232365047; \n",
      " validation loss : 0.6416983923892257; validation accuracy : 0.9029850746268657\n",
      "Epoch 40:\t train loss : 0.5611561825695557; train accuracy : 0.9900172616743429; \n",
      " validation loss : 0.644040293854737; validation accuracy : 0.9029850746268657\n",
      "Epoch 41:\t train loss : 0.5610282587708375; train accuracy : 0.9901555130706821; \n",
      " validation loss : 0.6763951125956622; validation accuracy : 0.8731343283582089\n",
      "Epoch 42:\t train loss : 0.5896485764036429; train accuracy : 0.9612333209565417; \n",
      " validation loss : 0.6263629939575808; validation accuracy : 0.9253731343283582\n",
      "Epoch 43:\t train loss : 0.5644535769293566; train accuracy : 0.9869757309548827; \n",
      " validation loss : 0.646768887014943; validation accuracy : 0.9029850746268657\n",
      "Epoch 44:\t train loss : 0.5592324643451774; train accuracy : 0.9923117410985851; \n",
      " validation loss : 0.6053580874966005; validation accuracy : 0.9477611940298507\n",
      "Epoch 45:\t train loss : 0.5614435727813702; train accuracy : 0.9899609736058335; \n",
      " validation loss : 0.6182431216432094; validation accuracy : 0.9328358208955224\n",
      "Epoch 46:\t train loss : 0.5588535201000447; train accuracy : 0.9925610873669825; \n",
      " validation loss : 0.6333925818604746; validation accuracy : 0.917910447761194\n",
      "Epoch 47:\t train loss : 0.5631301941452285; train accuracy : 0.9882757878354571; \n",
      " validation loss : 0.6448127353291788; validation accuracy : 0.9029850746268657\n",
      "Epoch 48:\t train loss : 0.5595954121462392; train accuracy : 0.9918421801060191; \n",
      " validation loss : 0.7255499430639081; validation accuracy : 0.8208955223880597\n",
      "Epoch 49:\t train loss : 0.5767625193091176; train accuracy : 0.974284252770953; \n",
      " validation loss : 0.6246965933247223; validation accuracy : 0.9253731343283582\n",
      "Epoch 50:\t train loss : 0.5601342031501835; train accuracy : 0.9911509231243235; \n",
      " validation loss : 0.6517456427197663; validation accuracy : 0.8880597014925373\n",
      "Epoch 51:\t train loss : 0.5609617152295172; train accuracy : 0.9904325096183472; \n",
      " validation loss : 0.6368178599538918; validation accuracy : 0.9104477611940298\n",
      "Epoch 52:\t train loss : 0.5636862782503056; train accuracy : 0.98755589306452; \n",
      " validation loss : 0.6560853833839433; validation accuracy : 0.8955223880597015\n",
      "Epoch 53:\t train loss : 0.5584675916387477; train accuracy : 0.9929486850317188; \n",
      " validation loss : 0.615610897106878; validation accuracy : 0.9402985074626866\n",
      "Epoch 54:\t train loss : 0.5636779749290898; train accuracy : 0.9875005925059843; \n",
      " validation loss : 0.6478896525050161; validation accuracy : 0.9029850746268657\n",
      "Epoch 55:\t train loss : 0.5716804182120321; train accuracy : 0.9792608092841738; \n",
      " validation loss : 0.6623727294532271; validation accuracy : 0.8880597014925373\n",
      "Epoch 56:\t train loss : 0.5621635090022512; train accuracy : 0.9891329464927596; \n",
      " validation loss : 0.6383772349848028; validation accuracy : 0.917910447761194\n",
      "Epoch 57:\t train loss : 0.5620586569956059; train accuracy : 0.9891882470512953; \n",
      " validation loss : 0.6560760745410574; validation accuracy : 0.8955223880597015\n",
      "Epoch 58:\t train loss : 0.5711186742816; train accuracy : 0.9799239222316145; \n",
      " validation loss : 0.6633712050104036; validation accuracy : 0.8880597014925373\n",
      "Epoch 59:\t train loss : 0.562068737977207; train accuracy : 0.9891329464927596; \n",
      " validation loss : 0.6520314415284768; validation accuracy : 0.8955223880597015\n",
      "Epoch 60:\t train loss : 0.5614185253533456; train accuracy : 0.9899348045915264; \n",
      " validation loss : 0.6390913780042725; validation accuracy : 0.9104477611940298\n",
      "Epoch 61:\t train loss : 0.5591884171978676; train accuracy : 0.9920915263744163; \n",
      " validation loss : 0.6586159873518352; validation accuracy : 0.8880597014925373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62:\t train loss : 0.5576352857098933; train accuracy : 0.9937781934097534; \n",
      " validation loss : 0.6373649717945077; validation accuracy : 0.9104477611940298\n",
      "Epoch 63:\t train loss : 0.558027072782529; train accuracy : 0.9933629454657492; \n",
      " validation loss : 0.6431406744394506; validation accuracy : 0.9029850746268657\n",
      "Epoch 64:\t train loss : 0.5571614415711588; train accuracy : 0.9942749109266004; \n",
      " validation loss : 0.6108076032826385; validation accuracy : 0.9402985074626866\n",
      "Epoch 65:\t train loss : 0.5868424704989852; train accuracy : 0.9639988426383107; \n",
      " validation loss : 0.6641809459706244; validation accuracy : 0.8805970149253731\n",
      "Epoch 66:\t train loss : 0.5787950340204994; train accuracy : 0.9725684541913874; \n",
      " validation loss : 0.656007480823508; validation accuracy : 0.8955223880597015\n",
      "Epoch 67:\t train loss : 0.5672445432470574; train accuracy : 0.9838779121669129; \n",
      " validation loss : 0.6308945192819442; validation accuracy : 0.917910447761194\n",
      "Epoch 68:\t train loss : 0.5626968461480499; train accuracy : 0.9887176985487554; \n",
      " validation loss : 0.6563622024881428; validation accuracy : 0.8955223880597015\n",
      "Epoch 69:\t train loss : 0.5602050556234933; train accuracy : 0.9912057299278723; \n",
      " validation loss : 0.6339421887827128; validation accuracy : 0.917910447761194\n",
      "Epoch 70:\t train loss : 0.5572144422138813; train accuracy : 0.9941929475987707; \n",
      " validation loss : 0.6380246036046473; validation accuracy : 0.9104477611940298\n",
      "Epoch 71:\t train loss : 0.555732309842635; train accuracy : 0.99585196435484; \n",
      " validation loss : 0.6140890526622367; validation accuracy : 0.9328358208955224\n",
      "Epoch 72:\t train loss : 0.5699978894990061; train accuracy : 0.9809746328437917; \n",
      " validation loss : 0.6715465478828443; validation accuracy : 0.8805970149253731\n",
      "Epoch 73:\t train loss : 0.5591083030184738; train accuracy : 0.9922297777707555; \n",
      " validation loss : 0.6338363993264746; validation accuracy : 0.917910447761194\n",
      "Epoch 74:\t train loss : 0.5565534721799078; train accuracy : 0.9949118548597341; \n",
      " validation loss : 0.6324692244014044; validation accuracy : 0.9253731343283582\n",
      "Epoch 75:\t train loss : 0.557576120302075; train accuracy : 0.9938887945268247; \n",
      " validation loss : 0.6433423956469035; validation accuracy : 0.9029850746268657\n",
      "Epoch 76:\t train loss : 0.5577228399722073; train accuracy : 0.9936675922926821; \n",
      " validation loss : 0.6040131633607829; validation accuracy : 0.9477611940298507\n",
      "Epoch 77:\t train loss : 0.5555484417942755; train accuracy : 0.9959892282412052; \n",
      " validation loss : 0.6477921883657375; validation accuracy : 0.9029850746268657\n",
      "Epoch 78:\t train loss : 0.556226668698916; train accuracy : 0.9951325633388897; \n",
      " validation loss : 0.6196319384957469; validation accuracy : 0.9328358208955224\n",
      "Epoch 79:\t train loss : 0.5592506282593299; train accuracy : 0.9920915263744163; \n",
      " validation loss : 0.6390717706781253; validation accuracy : 0.9104477611940298\n",
      "Epoch 80:\t train loss : 0.5567606997908227; train accuracy : 0.9946625085913368; \n",
      " validation loss : 0.6489531337577367; validation accuracy : 0.9029850746268657\n",
      "Epoch 81:\t train loss : 0.5567475376999135; train accuracy : 0.9946901588706045; \n",
      " validation loss : 0.6369873918666601; validation accuracy : 0.917910447761194\n",
      "Epoch 82:\t train loss : 0.5568628928610468; train accuracy : 0.9944684628814751; \n",
      " validation loss : 0.6065760549054614; validation accuracy : 0.9477611940298507\n",
      "Epoch 83:\t train loss : 0.5581100075361717; train accuracy : 0.9933056698872659; \n",
      " validation loss : 0.6394620592445768; validation accuracy : 0.9029850746268657\n",
      "Epoch 84:\t train loss : 0.5612604684471967; train accuracy : 0.9900730559878654; \n",
      " validation loss : 0.6315692974637171; validation accuracy : 0.917910447761194\n",
      "Epoch 85:\t train loss : 0.5575961484954135; train accuracy : 0.993833493968289; \n",
      " validation loss : 0.6367962422715472; validation accuracy : 0.9104477611940298\n",
      "Epoch 86:\t train loss : 0.5561424129349543; train accuracy : 0.9952708147352288; \n",
      " validation loss : 0.6249536135035555; validation accuracy : 0.9253731343283582\n",
      "Epoch 87:\t train loss : 0.5646286787184338; train accuracy : 0.9863950750902584; \n",
      " validation loss : 0.6379746870815488; validation accuracy : 0.9104477611940298\n",
      "Epoch 88:\t train loss : 0.5575642150122653; train accuracy : 0.9938058436890213; \n",
      " validation loss : 0.6409660743094103; validation accuracy : 0.9104477611940298\n",
      "Epoch 89:\t train loss : 0.5566716843626249; train accuracy : 0.9946901588706045; \n",
      " validation loss : 0.6427458299195662; validation accuracy : 0.9104477611940298\n",
      "Epoch 90:\t train loss : 0.556285608989732; train accuracy : 0.9951607073731444; \n",
      " validation loss : 0.6567717754553996; validation accuracy : 0.8955223880597015\n",
      "Epoch 91:\t train loss : 0.5663077545917118; train accuracy : 0.9850120673718804; \n",
      " validation loss : 0.5931110851948518; validation accuracy : 0.9552238805970149\n",
      "Epoch 92:\t train loss : 0.5854606313040197; train accuracy : 0.965292974459042; \n",
      " validation loss : 0.6651379480943435; validation accuracy : 0.8880597014925373\n",
      "Epoch 93:\t train loss : 0.5830707668228629; train accuracy : 0.9681167592292682; \n",
      " validation loss : 0.6351911021105401; validation accuracy : 0.917910447761194\n",
      "Epoch 94:\t train loss : 0.5665593271231977; train accuracy : 0.9845963256728892; \n",
      " validation loss : 0.6682944235945315; validation accuracy : 0.8731343283582089\n",
      "Epoch 95:\t train loss : 0.5624655533452781; train accuracy : 0.9886900482694875; \n",
      " validation loss : 0.630031717893682; validation accuracy : 0.917910447761194\n",
      "Epoch 96:\t train loss : 0.5585910714027694; train accuracy : 0.9927546393218571; \n",
      " validation loss : 0.6425744436444539; validation accuracy : 0.9104477611940298\n",
      "Epoch 97:\t train loss : 0.5615126116050975; train accuracy : 0.9899348045915264; \n",
      " validation loss : 0.6445988998735321; validation accuracy : 0.9029850746268657\n",
      "Epoch 98:\t train loss : 0.5572384994665095; train accuracy : 0.9942186228580908; \n",
      " validation loss : 0.6432540329498347; validation accuracy : 0.9104477611940298\n",
      "Epoch 99:\t train loss : 0.5595794257993697; train accuracy : 0.9917315789889478; \n",
      " validation loss : 0.6330889687312384; validation accuracy : 0.9104477611940298\n",
      "Epoch 100:\t train loss : 0.5586547594775573; train accuracy : 0.9927822896011249; \n",
      " validation loss : 0.6298783533444181; validation accuracy : 0.917910447761194\n",
      "Epoch 101:\t train loss : 0.5565579857156152; train accuracy : 0.9949113611047471; \n",
      " validation loss : 0.6113906943751533; validation accuracy : 0.9402985074626866\n",
      "Epoch 102:\t train loss : 0.5800822153765436; train accuracy : 0.9706349096625876; \n",
      " validation loss : 0.6396168000863348; validation accuracy : 0.9104477611940298\n",
      "Epoch 103:\t train loss : 0.5572065287546892; train accuracy : 0.9940542024474447; \n",
      " validation loss : 0.6355720546164016; validation accuracy : 0.9104477611940298\n",
      "Epoch 104:\t train loss : 0.5567909094612797; train accuracy : 0.9945800515085202; \n",
      " validation loss : 0.6043700366256629; validation accuracy : 0.9477611940298507\n",
      "Epoch 105:\t train loss : 0.5564771252343912; train accuracy : 0.9948565543011985; \n",
      " validation loss : 0.6289473308339742; validation accuracy : 0.9253731343283582\n",
      "Epoch 106:\t train loss : 0.5570305061840967; train accuracy : 0.9944136560779264; \n",
      " validation loss : 0.6046954986102139; validation accuracy : 0.9477611940298507\n",
      "Epoch 107:\t train loss : 0.5561629503072097; train accuracy : 0.9953537655730322; \n",
      " validation loss : 0.6308889280430677; validation accuracy : 0.9253731343283582\n",
      "Epoch 108:\t train loss : 0.5632676506946367; train accuracy : 0.987998791287792; \n",
      " validation loss : 0.6383566453201662; validation accuracy : 0.9104477611940298\n",
      "Epoch 109:\t train loss : 0.5607866831473195; train accuracy : 0.9904043655840924; \n",
      " validation loss : 0.6406290762946767; validation accuracy : 0.9104477611940298\n",
      "Epoch 110:\t train loss : 0.555618881736629; train accuracy : 0.9957137129585009; \n",
      " validation loss : 0.613739406560898; validation accuracy : 0.9402985074626866\n",
      "Epoch 111:\t train loss : 0.5559731386466382; train accuracy : 0.995381909607287; \n",
      " validation loss : 0.6227293765129778; validation accuracy : 0.917910447761194\n",
      "Epoch 112:\t train loss : 0.5572203532300165; train accuracy : 0.9940537086924578; \n",
      " validation loss : 0.6274365134889057; validation accuracy : 0.9253731343283582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113:\t train loss : 0.5916133963057618; train accuracy : 0.9591570812365204; \n",
      " validation loss : 0.6396933725824637; validation accuracy : 0.9029850746268657\n",
      "Epoch 114:\t train loss : 0.5670580072665036; train accuracy : 0.9843766047037075; \n",
      " validation loss : 0.6388315132158; validation accuracy : 0.9104477611940298\n",
      "Epoch 115:\t train loss : 0.5580233224122085; train accuracy : 0.9934192335342586; \n",
      " validation loss : 0.6169610224787604; validation accuracy : 0.9328358208955224\n",
      "Epoch 116:\t train loss : 0.557146196253559; train accuracy : 0.9942210916330255; \n",
      " validation loss : 0.6229329524636877; validation accuracy : 0.9253731343283582\n",
      "Epoch 117:\t train loss : 0.5566792505821967; train accuracy : 0.9946911463805784; \n",
      " validation loss : 0.6051802464540083; validation accuracy : 0.9477611940298507\n",
      "Epoch 118:\t train loss : 0.5562397737802073; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6278272261579418; validation accuracy : 0.9253731343283582\n",
      "Epoch 119:\t train loss : 0.5554042821880765; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6331300579388114; validation accuracy : 0.917910447761194\n",
      "Epoch 120:\t train loss : 0.5545102503474243; train accuracy : 0.9969031687220041; \n",
      " validation loss : 0.7089328697246143; validation accuracy : 0.8432835820895522\n",
      "Epoch 121:\t train loss : 0.5859433444727948; train accuracy : 0.9646886183550454; \n",
      " validation loss : 0.6519291521086443; validation accuracy : 0.8955223880597015\n",
      "Epoch 122:\t train loss : 0.5741309992535183; train accuracy : 0.9767446338708021; \n",
      " validation loss : 0.6438422950395332; validation accuracy : 0.9029850746268657\n",
      "Epoch 123:\t train loss : 0.5648460620343321; train accuracy : 0.9863950750902584; \n",
      " validation loss : 0.6538274970512669; validation accuracy : 0.8955223880597015\n",
      "Epoch 124:\t train loss : 0.5589350240385201; train accuracy : 0.9925339308427015; \n",
      " validation loss : 0.6255000740350869; validation accuracy : 0.9253731343283582\n",
      "Epoch 125:\t train loss : 0.5556444064606555; train accuracy : 0.9957137129585009; \n",
      " validation loss : 0.6141009016733209; validation accuracy : 0.9328358208955224\n",
      "Epoch 126:\t train loss : 0.5719190630526556; train accuracy : 0.9791507019220894; \n",
      " validation loss : 0.6309517736599031; validation accuracy : 0.9253731343283582\n",
      "Epoch 127:\t train loss : 0.561926502995338; train accuracy : 0.9894094492854377; \n",
      " validation loss : 0.611335752362785; validation accuracy : 0.9402985074626866\n",
      "Epoch 128:\t train loss : 0.5552196845930962; train accuracy : 0.9961566111817729; \n",
      " validation loss : 0.5930150959140502; validation accuracy : 0.9552238805970149\n",
      "Epoch 129:\t train loss : 0.555466750640985; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6268978612429938; validation accuracy : 0.9253731343283582\n",
      "Epoch 130:\t train loss : 0.5591522494514363; train accuracy : 0.9922845845743042; \n",
      " validation loss : 0.6191943877782825; validation accuracy : 0.9328358208955224\n",
      "Epoch 131:\t train loss : 0.5623123026770324; train accuracy : 0.9889942013414336; \n",
      " validation loss : 0.6494420627465182; validation accuracy : 0.9029850746268657\n",
      "Epoch 132:\t train loss : 0.5560870949288502; train accuracy : 0.995381909607287; \n",
      " validation loss : 0.63378450873267; validation accuracy : 0.917910447761194\n",
      "Epoch 133:\t train loss : 0.555020343592206; train accuracy : 0.9963501631366477; \n",
      " validation loss : 0.6120700978996746; validation accuracy : 0.9402985074626866\n",
      "Epoch 134:\t train loss : 0.5567975309765353; train accuracy : 0.9945524012292524; \n",
      " validation loss : 0.6263956459445121; validation accuracy : 0.9253731343283582\n",
      "Epoch 135:\t train loss : 0.5571802302153722; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.606181363901425; validation accuracy : 0.9477611940298507\n",
      "Epoch 136:\t train loss : 0.5548323958035312; train accuracy : 0.9965713653707903; \n",
      " validation loss : 0.6021566658466183; validation accuracy : 0.9477611940298507\n",
      "Epoch 137:\t train loss : 0.5542256348840198; train accuracy : 0.9972626223524858; \n",
      " validation loss : 0.6173227730745033; validation accuracy : 0.9328358208955224\n",
      "Epoch 138:\t train loss : 0.555583383927574; train accuracy : 0.9957695072720234; \n",
      " validation loss : 0.6502333823991627; validation accuracy : 0.9029850746268657\n",
      "Epoch 139:\t train loss : 0.5554720512484069; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6255271953802617; validation accuracy : 0.9253731343283582\n",
      "Epoch 140:\t train loss : 0.5583726152951438; train accuracy : 0.9929486850317188; \n",
      " validation loss : 0.6376402332890148; validation accuracy : 0.9104477611940298\n",
      "Epoch 141:\t train loss : 0.5576630316066457; train accuracy : 0.9937510368854725; \n",
      " validation loss : 0.6369154021942058; validation accuracy : 0.917910447761194\n",
      "Epoch 142:\t train loss : 0.5573053825838142; train accuracy : 0.9939717453646282; \n",
      " validation loss : 0.6406044536101066; validation accuracy : 0.9104477611940298\n",
      "Epoch 143:\t train loss : 0.5612160479951361; train accuracy : 0.9901145314067672; \n",
      " validation loss : 0.9220422442316263; validation accuracy : 0.6268656716417911\n",
      "Epoch 144:\t train loss : 0.749475705873567; train accuracy : 0.7988634747710952; \n",
      " validation loss : 0.7920845422308997; validation accuracy : 0.753731343283582\n",
      "Epoch 145:\t train loss : 0.6573000695495432; train accuracy : 0.8923179624114204; \n",
      " validation loss : 0.772476959858834; validation accuracy : 0.7761194029850746\n",
      "Epoch 146:\t train loss : 0.6458441005823611; train accuracy : 0.9040994501544466; \n",
      " validation loss : 0.6659213504716444; validation accuracy : 0.8805970149253731\n",
      "Epoch 147:\t train loss : 0.6074969355634628; train accuracy : 0.9430651124576358; \n",
      " validation loss : 0.6777089629726765; validation accuracy : 0.8731343283582089\n",
      "Epoch 148:\t train loss : 0.5930509236653648; train accuracy : 0.9581631524478397; \n",
      " validation loss : 0.6590922307145345; validation accuracy : 0.8955223880597015\n",
      "Epoch 149:\t train loss : 0.5873791580644264; train accuracy : 0.9631950095195961; \n",
      " validation loss : 0.6727054892171845; validation accuracy : 0.8805970149253731\n",
      "Epoch 150:\t train loss : 0.5767895958169938; train accuracy : 0.9741168698303853; \n",
      " validation loss : 0.6408190687293168; validation accuracy : 0.9104477611940298\n",
      "Epoch 151:\t train loss : 0.5772835137926573; train accuracy : 0.9737850664791714; \n",
      " validation loss : 0.6419784791092015; validation accuracy : 0.9104477611940298\n",
      "Epoch 152:\t train loss : 0.5733042899610331; train accuracy : 0.977876320300835; \n",
      " validation loss : 0.6424669167165336; validation accuracy : 0.9104477611940298\n",
      "Epoch 153:\t train loss : 0.5717965207064182; train accuracy : 0.9792321714949321; \n",
      " validation loss : 0.6544181187930641; validation accuracy : 0.8880597014925373\n",
      "Epoch 154:\t train loss : 0.5695969395049177; train accuracy : 0.9815834327426707; \n",
      " validation loss : 0.6369217279486921; validation accuracy : 0.917910447761194\n",
      "Epoch 155:\t train loss : 0.5652654938122726; train accuracy : 0.9860899345083385; \n",
      " validation loss : 0.6169292097695502; validation accuracy : 0.9328358208955224\n",
      "Epoch 156:\t train loss : 0.5677076178008053; train accuracy : 0.9836028906391955; \n",
      " validation loss : 0.6499308347991779; validation accuracy : 0.9029850746268657\n",
      "Epoch 157:\t train loss : 0.5704264204717612; train accuracy : 0.9807262740853683; \n",
      " validation loss : 0.642594873569407; validation accuracy : 0.9104477611940298\n",
      "Epoch 158:\t train loss : 0.5655691432956546; train accuracy : 0.9856761678292951; \n",
      " validation loss : 0.6370289434326833; validation accuracy : 0.9104477611940298\n",
      "Epoch 159:\t train loss : 0.5626972994194355; train accuracy : 0.9886890607595137; \n",
      " validation loss : 0.6325707200267707; validation accuracy : 0.9104477611940298\n",
      "Epoch 160:\t train loss : 0.5621003041980461; train accuracy : 0.9893264984476343; \n",
      " validation loss : 0.6283153377373324; validation accuracy : 0.9253731343283582\n",
      "Epoch 161:\t train loss : 0.5599571878173949; train accuracy : 0.991511364264779; \n",
      " validation loss : 0.6139180326222351; validation accuracy : 0.9328358208955224\n",
      "Epoch 162:\t train loss : 0.5641017767071611; train accuracy : 0.9872798840268286; \n",
      " validation loss : 0.6026994732766712; validation accuracy : 0.9477611940298507\n",
      "Epoch 163:\t train loss : 0.5607850197946109; train accuracy : 0.9906542056074766; \n",
      " validation loss : 0.6128440839420772; validation accuracy : 0.9328358208955224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164:\t train loss : 0.5625576383109938; train accuracy : 0.9887186860587291; \n",
      " validation loss : 0.6243574056082856; validation accuracy : 0.9253731343283582\n",
      "Epoch 165:\t train loss : 0.5644694182352891; train accuracy : 0.9868646360828245; \n",
      " validation loss : 0.620738097943446; validation accuracy : 0.9328358208955224\n",
      "Epoch 166:\t train loss : 0.5602982931187946; train accuracy : 0.9909297208901809; \n",
      " validation loss : 0.6006508117516071; validation accuracy : 0.9477611940298507\n",
      "Epoch 167:\t train loss : 0.5620139801373814; train accuracy : 0.9893260046926474; \n",
      " validation loss : 0.6188521235286463; validation accuracy : 0.9328358208955224\n",
      "Epoch 168:\t train loss : 0.5614892065390711; train accuracy : 0.9897136023573838; \n",
      " validation loss : 0.651663011376655; validation accuracy : 0.8955223880597015\n",
      "Epoch 169:\t train loss : 0.5610555074008741; train accuracy : 0.9899604798508465; \n",
      " validation loss : 0.6334272758482424; validation accuracy : 0.917910447761194\n",
      "Epoch 170:\t train loss : 0.5638287570185898; train accuracy : 0.9873628348646322; \n",
      " validation loss : 0.6773107675504221; validation accuracy : 0.8731343283582089\n",
      "Epoch 171:\t train loss : 0.5616641248234601; train accuracy : 0.9895758447160317; \n",
      " validation loss : 0.5960899390301317; validation accuracy : 0.9552238805970149\n",
      "Epoch 172:\t train loss : 0.5585631719647542; train accuracy : 0.9926440382047859; \n",
      " validation loss : 0.6135740631587424; validation accuracy : 0.9402985074626866\n",
      "Epoch 173:\t train loss : 0.5592771178370988; train accuracy : 0.9920633823401617; \n",
      " validation loss : 0.5946662251455133; validation accuracy : 0.9552238805970149\n",
      "Epoch 174:\t train loss : 0.5649860770974349; train accuracy : 0.9861180785425933; \n",
      " validation loss : 0.6347469498231664; validation accuracy : 0.917910447761194\n",
      "Epoch 175:\t train loss : 0.5700782299830509; train accuracy : 0.9810304271573143; \n",
      " validation loss : 0.6260959796287354; validation accuracy : 0.9253731343283582\n",
      "Epoch 176:\t train loss : 0.5588408498401167; train accuracy : 0.9924786302841658; \n",
      " validation loss : 0.627959508054715; validation accuracy : 0.9253731343283582\n",
      "Epoch 177:\t train loss : 0.5711850416254728; train accuracy : 0.9801732685000119; \n",
      " validation loss : 0.6648749832571321; validation accuracy : 0.8880597014925373\n",
      "Epoch 178:\t train loss : 0.5608762184978541; train accuracy : 0.9902379701534986; \n",
      " validation loss : 0.6252950580615523; validation accuracy : 0.9253731343283582\n",
      "Early stopping at epoch 178\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5552196845930962; Train accuracy : 0.9961566111817729; \n",
      " Validation loss : 0.5930150959140502; Validation accuracy : 0.9552238805970149\n",
      "------------------------------ Let's train model 10 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8980650554702179; train accuracy : 0.6338688270751535; \n",
      " validation loss : 0.8723392103754772; validation accuracy : 0.6390977443609023\n",
      "Epoch 2:\t train loss : 0.7665183764555709; train accuracy : 0.7790466183708455; \n",
      " validation loss : 0.8122246189714128; validation accuracy : 0.7518796992481203\n",
      "Epoch 3:\t train loss : 0.7092199632316373; train accuracy : 0.8414532986783166; \n",
      " validation loss : 0.7932546868851166; validation accuracy : 0.7443609022556391\n",
      "Epoch 4:\t train loss : 0.6757191991969517; train accuracy : 0.8739700270972737; \n",
      " validation loss : 0.7640343699597536; validation accuracy : 0.7894736842105263\n",
      "Epoch 5:\t train loss : 0.6565618857684925; train accuracy : 0.8939335287286402; \n",
      " validation loss : 0.7397064033136326; validation accuracy : 0.8045112781954887\n",
      "Epoch 6:\t train loss : 0.6305578214118256; train accuracy : 0.920629873361721; \n",
      " validation loss : 0.709184145061893; validation accuracy : 0.8421052631578947\n",
      "Epoch 7:\t train loss : 0.6174809401572637; train accuracy : 0.933722280595034; \n",
      " validation loss : 0.6957452337966918; validation accuracy : 0.8721804511278195\n",
      "Epoch 8:\t train loss : 0.606585409935619; train accuracy : 0.9449344688381353; \n",
      " validation loss : 0.7065347586492002; validation accuracy : 0.8345864661654135\n",
      "Epoch 9:\t train loss : 0.6092325711256339; train accuracy : 0.941436708510756; \n",
      " validation loss : 0.731544299533144; validation accuracy : 0.8195488721804511\n",
      "Epoch 10:\t train loss : 0.5965959167733785; train accuracy : 0.9550544710501576; \n",
      " validation loss : 0.6994788199800448; validation accuracy : 0.849624060150376\n",
      "Epoch 11:\t train loss : 0.5874543771474188; train accuracy : 0.9648150196316982; \n",
      " validation loss : 0.6810828888835048; validation accuracy : 0.8796992481203008\n",
      "Epoch 12:\t train loss : 0.5812082791438706; train accuracy : 0.970856605651717; \n",
      " validation loss : 0.6849127031883815; validation accuracy : 0.8571428571428571\n",
      "Epoch 13:\t train loss : 0.577589023740511; train accuracy : 0.9741469888845877; \n",
      " validation loss : 0.7217740532296775; validation accuracy : 0.8270676691729323\n",
      "Epoch 14:\t train loss : 0.5724255024780999; train accuracy : 0.9790963888735277; \n",
      " validation loss : 0.7010853665607396; validation accuracy : 0.8421052631578947\n",
      "Epoch 15:\t train loss : 0.583087603573406; train accuracy : 0.968713709008461; \n",
      " validation loss : 0.6964238536062983; validation accuracy : 0.849624060150376\n",
      "Epoch 16:\t train loss : 0.5746686333668114; train accuracy : 0.9769534922302715; \n",
      " validation loss : 0.7042925417668465; validation accuracy : 0.8345864661654135\n",
      "Epoch 17:\t train loss : 0.5733230709932027; train accuracy : 0.978266880495493; \n",
      " validation loss : 0.6539267547806425; validation accuracy : 0.9022556390977443\n",
      "Epoch 18:\t train loss : 0.5766744419100762; train accuracy : 0.9748520710059172; \n",
      " validation loss : 0.6745659544308128; validation accuracy : 0.8721804511278195\n",
      "Epoch 19:\t train loss : 0.5693634911633239; train accuracy : 0.9820549687551844; \n",
      " validation loss : 0.6426816514600475; validation accuracy : 0.9097744360902256\n",
      "Epoch 20:\t train loss : 0.5629687433038795; train accuracy : 0.9887601614776309; \n",
      " validation loss : 0.7246317550778812; validation accuracy : 0.8270676691729323\n",
      "Epoch 21:\t train loss : 0.5789182080125378; train accuracy : 0.9723773710114472; \n",
      " validation loss : 0.6675927496881584; validation accuracy : 0.8872180451127819\n",
      "Epoch 22:\t train loss : 0.5636365898379162; train accuracy : 0.9878062268428911; \n",
      " validation loss : 0.6606004631052276; validation accuracy : 0.8947368421052632\n",
      "Epoch 23:\t train loss : 0.5747362944929653; train accuracy : 0.9763451860863794; \n",
      " validation loss : 0.6670518104406032; validation accuracy : 0.8796992481203008\n",
      "Epoch 24:\t train loss : 0.5638701346943872; train accuracy : 0.9876403251672842; \n",
      " validation loss : 0.6635336961776288; validation accuracy : 0.8947368421052632\n",
      "Epoch 25:\t train loss : 0.5789090780210676; train accuracy : 0.9719626168224299; \n",
      " validation loss : 0.6859954670326138; validation accuracy : 0.8721804511278195\n",
      "Epoch 26:\t train loss : 0.5681439712133064; train accuracy : 0.9830227285295582; \n",
      " validation loss : 0.693296924048995; validation accuracy : 0.8571428571428571\n",
      "Epoch 27:\t train loss : 0.5750945588746714; train accuracy : 0.9759857324558978; \n",
      " validation loss : 0.7012259121121462; validation accuracy : 0.8421052631578947\n",
      "Epoch 28:\t train loss : 0.569834959091758; train accuracy : 0.9814051871923907; \n",
      " validation loss : 0.693318027767484; validation accuracy : 0.8571428571428571\n",
      "Epoch 29:\t train loss : 0.565456309526083; train accuracy : 0.9859121827130454; \n",
      " validation loss : 0.6689466495082704; validation accuracy : 0.8796992481203008\n",
      "Epoch 30:\t train loss : 0.5656895008818322; train accuracy : 0.9857186307581707; \n",
      " validation loss : 0.6807675054161896; validation accuracy : 0.8721804511278195\n",
      "Epoch 31:\t train loss : 0.5681347237986563; train accuracy : 0.9830642039484598; \n",
      " validation loss : 0.6784958696915948; validation accuracy : 0.8721804511278195\n",
      "Epoch 32:\t train loss : 0.5597835348562038; train accuracy : 0.9917740419178234; \n",
      " validation loss : 0.6870922014986821; validation accuracy : 0.8646616541353384\n",
      "Epoch 33:\t train loss : 0.5581443866048487; train accuracy : 0.993363932975723; \n",
      " validation loss : 0.6875771926964132; validation accuracy : 0.8646616541353384\n",
      "Epoch 34:\t train loss : 0.5572729735083538; train accuracy : 0.9941657910744899; \n",
      " validation loss : 0.6773339752106972; validation accuracy : 0.8721804511278195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:\t train loss : 0.5560012063862978; train accuracy : 0.9954653542000774; \n",
      " validation loss : 0.6723332190116049; validation accuracy : 0.8796992481203008\n",
      "Epoch 36:\t train loss : 0.5561585047967028; train accuracy : 0.99536857822264; \n",
      " validation loss : 0.679717036979057; validation accuracy : 0.8646616541353384\n",
      "Epoch 37:\t train loss : 0.5569160675060529; train accuracy : 0.9945667201238733; \n",
      " validation loss : 0.658451536830821; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.6019604491391115; train accuracy : 0.9480313001161311; \n",
      " validation loss : 0.6921956331641317; validation accuracy : 0.8646616541353384\n",
      "Epoch 39:\t train loss : 0.5647546218560563; train accuracy : 0.9864237128795; \n",
      " validation loss : 0.6660843555123525; validation accuracy : 0.8796992481203008\n",
      "Epoch 40:\t train loss : 0.559291178307951; train accuracy : 0.9922579218050103; \n",
      " validation loss : 0.6914516023614921; validation accuracy : 0.8571428571428571\n",
      "Epoch 41:\t train loss : 0.5590748335220711; train accuracy : 0.9922993972239119; \n",
      " validation loss : 0.6556542096624796; validation accuracy : 0.8947368421052632\n",
      "Epoch 42:\t train loss : 0.5570537394985009; train accuracy : 0.9942072664933915; \n",
      " validation loss : 0.6935418453138109; validation accuracy : 0.8571428571428571\n",
      "Epoch 43:\t train loss : 0.5604834323433942; train accuracy : 0.9906265553282088; \n",
      " validation loss : 0.6825863113529526; validation accuracy : 0.8646616541353384\n",
      "Epoch 44:\t train loss : 0.558353713092473; train accuracy : 0.9929906542056075; \n",
      " validation loss : 0.6973439414847724; validation accuracy : 0.8421052631578947\n",
      "Epoch 45:\t train loss : 0.5574663298444921; train accuracy : 0.9939722391196151; \n",
      " validation loss : 0.6626900984230932; validation accuracy : 0.8872180451127819\n",
      "Epoch 46:\t train loss : 0.5572851988737031; train accuracy : 0.9940137145385168; \n",
      " validation loss : 0.6524593336588533; validation accuracy : 0.8947368421052632\n",
      "Epoch 47:\t train loss : 0.5596194154996762; train accuracy : 0.9918984681745285; \n",
      " validation loss : 0.7014365786664252; validation accuracy : 0.8421052631578947\n",
      "Epoch 48:\t train loss : 0.5590710962253842; train accuracy : 0.9922717469446442; \n",
      " validation loss : 0.6811058646465514; validation accuracy : 0.8721804511278195\n",
      "Epoch 49:\t train loss : 0.5566481834635775; train accuracy : 0.9947187966598463; \n",
      " validation loss : 0.6990195697089546; validation accuracy : 0.849624060150376\n",
      "Epoch 50:\t train loss : 0.5572463523981686; train accuracy : 0.9941519659348559; \n",
      " validation loss : 0.7187249974917042; validation accuracy : 0.8345864661654135\n",
      "Epoch 51:\t train loss : 0.5562017495289375; train accuracy : 0.9952026765470331; \n",
      " validation loss : 0.6585578132864169; validation accuracy : 0.8872180451127819\n",
      "Epoch 52:\t train loss : 0.5583504223330726; train accuracy : 0.9930874301830448; \n",
      " validation loss : 0.6831583436723571; validation accuracy : 0.8721804511278195\n",
      "Epoch 53:\t train loss : 0.5689978025277521; train accuracy : 0.9819028922192115; \n",
      " validation loss : 0.6856079253314247; validation accuracy : 0.8571428571428571\n",
      "Epoch 54:\t train loss : 0.5630072473604332; train accuracy : 0.9881242050544711; \n",
      " validation loss : 0.7704277173751901; validation accuracy : 0.7819548872180451\n",
      "Epoch 55:\t train loss : 0.6011904613445127; train accuracy : 0.9493999889398883; \n",
      " validation loss : 0.6943232829869005; validation accuracy : 0.8571428571428571\n",
      "Epoch 56:\t train loss : 0.5598277434650245; train accuracy : 0.9915251894044129; \n",
      " validation loss : 0.6772774694660969; validation accuracy : 0.8721804511278195\n",
      "Epoch 57:\t train loss : 0.5593945947514827; train accuracy : 0.9918155173367251; \n",
      " validation loss : 0.7278812830585389; validation accuracy : 0.8195488721804511\n",
      "Epoch 58:\t train loss : 0.5582923918041672; train accuracy : 0.9931565558812144; \n",
      " validation loss : 0.7184994959046039; validation accuracy : 0.8345864661654135\n",
      "Epoch 59:\t train loss : 0.5608866915488621; train accuracy : 0.9904606536526018; \n",
      " validation loss : 0.6984386441354549; validation accuracy : 0.8571428571428571\n",
      "Epoch 60:\t train loss : 0.5856856262515704; train accuracy : 0.9650915224243765; \n",
      " validation loss : 0.8196257285363263; validation accuracy : 0.7218045112781954\n",
      "Epoch 61:\t train loss : 0.681512950932922; train accuracy : 0.8669192058839794; \n",
      " validation loss : 0.7570243371883326; validation accuracy : 0.7894736842105263\n",
      "Epoch 62:\t train loss : 0.6599781530750208; train accuracy : 0.8892882818116463; \n",
      " validation loss : 0.7346284901948592; validation accuracy : 0.8195488721804511\n",
      "Epoch 63:\t train loss : 0.6218929967564224; train accuracy : 0.9282060498811038; \n",
      " validation loss : 0.7364380135477798; validation accuracy : 0.8120300751879699\n",
      "Epoch 64:\t train loss : 0.6010414947129609; train accuracy : 0.9496626665929326; \n",
      " validation loss : 0.7307117588403857; validation accuracy : 0.8045112781954887\n",
      "Epoch 65:\t train loss : 0.5890286115096403; train accuracy : 0.9613863850024885; \n",
      " validation loss : 0.680946939394164; validation accuracy : 0.8646616541353384\n",
      "Epoch 66:\t train loss : 0.5840768091726951; train accuracy : 0.9664602112481336; \n",
      " validation loss : 0.6810102227260515; validation accuracy : 0.8721804511278195\n",
      "Epoch 67:\t train loss : 0.5779384274781487; train accuracy : 0.9734419067632583; \n",
      " validation loss : 0.7062154074323572; validation accuracy : 0.8421052631578947\n",
      "Epoch 68:\t train loss : 0.5743636741372966; train accuracy : 0.9770087927888071; \n",
      " validation loss : 0.8100465453335665; validation accuracy : 0.7443609022556391\n",
      "Epoch 69:\t train loss : 0.603124240574489; train accuracy : 0.9473538682740695; \n",
      " validation loss : 0.6747734296678258; validation accuracy : 0.8721804511278195\n",
      "Early stopping at epoch 69\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5693634911633239; Train accuracy : 0.9820549687551844; \n",
      " Validation loss : 0.6426816514600475; Validation accuracy : 0.9097744360902256\n",
      "------------------------------ Let's train model 11 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8992950712496857; train accuracy : 0.62872780422059; \n",
      " validation loss : 0.8422542806697842; validation accuracy : 0.7089552238805971\n",
      "Epoch 2:\t train loss : 0.7772805918077801; train accuracy : 0.7668817815525053; \n",
      " validation loss : 0.8090644926732611; validation accuracy : 0.7164179104477612\n",
      "Epoch 3:\t train loss : 0.712651016210837; train accuracy : 0.8368836077569964; \n",
      " validation loss : 0.6908192884732953; validation accuracy : 0.8507462686567164\n",
      "Epoch 4:\t train loss : 0.6831554467795631; train accuracy : 0.8667430157323659; \n",
      " validation loss : 0.6816190652456222; validation accuracy : 0.8731343283582089\n",
      "Epoch 5:\t train loss : 0.6610746241227405; train accuracy : 0.8882549330027303; \n",
      " validation loss : 0.6839418818116948; validation accuracy : 0.8805970149253731\n",
      "Epoch 6:\t train loss : 0.6364594397183733; train accuracy : 0.9147686571866934; \n",
      " validation loss : 0.6570896805176862; validation accuracy : 0.9029850746268657\n",
      "Epoch 7:\t train loss : 0.6246267678908639; train accuracy : 0.9264161765708252; \n",
      " validation loss : 0.7076924443864084; validation accuracy : 0.8283582089552238\n",
      "Epoch 8:\t train loss : 0.6146812380751666; train accuracy : 0.9372139321397844; \n",
      " validation loss : 0.7018482077827545; validation accuracy : 0.8507462686567164\n",
      "Epoch 9:\t train loss : 0.6110387328656521; train accuracy : 0.940544504732056; \n",
      " validation loss : 0.6924641947794055; validation accuracy : 0.8582089552238806\n",
      "Epoch 10:\t train loss : 0.6036205842753612; train accuracy : 0.9478001309208571; \n",
      " validation loss : 0.6745211650558521; validation accuracy : 0.8805970149253731\n",
      "Epoch 11:\t train loss : 0.5989355962237196; train accuracy : 0.9519515309895328; \n",
      " validation loss : 0.6609588277748397; validation accuracy : 0.8805970149253731\n",
      "Epoch 12:\t train loss : 0.595234262590051; train accuracy : 0.9563775047616353; \n",
      " validation loss : 0.6202341731388961; validation accuracy : 0.9253731343283582\n",
      "Epoch 13:\t train loss : 0.5894566292428152; train accuracy : 0.9619056315259482; \n",
      " validation loss : 0.6706151600700375; validation accuracy : 0.8805970149253731\n",
      "Epoch 14:\t train loss : 0.5992119141119241; train accuracy : 0.9516187630936933; \n",
      " validation loss : 0.6728474636927788; validation accuracy : 0.8731343283582089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\t train loss : 0.587198181158294; train accuracy : 0.9635646482820174; \n",
      " validation loss : 0.6696440867214505; validation accuracy : 0.8656716417910447\n",
      "Epoch 16:\t train loss : 0.5814462752461454; train accuracy : 0.9700033051729171; \n",
      " validation loss : 0.6518821928181316; validation accuracy : 0.8880597014925373\n",
      "Epoch 17:\t train loss : 0.5738688509217649; train accuracy : 0.9775556895915346; \n",
      " validation loss : 0.6489963762892323; validation accuracy : 0.8955223880597015\n",
      "Epoch 18:\t train loss : 0.5707437384848926; train accuracy : 0.9807907722658696; \n",
      " validation loss : 0.6497268139394076; validation accuracy : 0.9029850746268657\n",
      "Epoch 19:\t train loss : 0.573163441949244; train accuracy : 0.9782707386739955; \n",
      " validation loss : 0.6557324354935603; validation accuracy : 0.9029850746268657\n",
      "Epoch 20:\t train loss : 0.572451963758141; train accuracy : 0.9791841624344592; \n",
      " validation loss : 0.6650513847201968; validation accuracy : 0.8880597014925373\n",
      "Epoch 21:\t train loss : 0.5716362219101313; train accuracy : 0.9795397578864383; \n",
      " validation loss : 0.6482279956479884; validation accuracy : 0.9029850746268657\n",
      "Epoch 22:\t train loss : 0.5687298316731046; train accuracy : 0.9827224336361146; \n",
      " validation loss : 0.6207592780478505; validation accuracy : 0.9328358208955224\n",
      "Epoch 23:\t train loss : 0.5713657483060407; train accuracy : 0.980181501577352; \n",
      " validation loss : 0.6538358849146872; validation accuracy : 0.8955223880597015\n",
      "Epoch 24:\t train loss : 0.5774344921173578; train accuracy : 0.9741212676945712; \n",
      " validation loss : 0.6800940927224443; validation accuracy : 0.8731343283582089\n",
      "Epoch 25:\t train loss : 0.5717414606661949; train accuracy : 0.9791317555098004; \n",
      " validation loss : 0.6375157371238294; validation accuracy : 0.917910447761194\n",
      "Epoch 26:\t train loss : 0.568694401571146; train accuracy : 0.9826652039883277; \n",
      " validation loss : 0.6883392036652758; validation accuracy : 0.8656716417910447\n",
      "Epoch 27:\t train loss : 0.5707191750428334; train accuracy : 0.9805084822054377; \n",
      " validation loss : 0.6499785499927528; validation accuracy : 0.8955223880597015\n",
      "Epoch 28:\t train loss : 0.5766952876246809; train accuracy : 0.9741260904176993; \n",
      " validation loss : 0.6060019001421927; validation accuracy : 0.9477611940298507\n",
      "Epoch 29:\t train loss : 0.565851332695522; train accuracy : 0.9855723414899514; \n",
      " validation loss : 0.6765157737479721; validation accuracy : 0.8731343283582089\n",
      "Epoch 30:\t train loss : 0.5686847937060299; train accuracy : 0.9824726165780786; \n",
      " validation loss : 0.6937771335148867; validation accuracy : 0.8507462686567164\n",
      "Epoch 31:\t train loss : 0.5637614065742261; train accuracy : 0.9875879182426254; \n",
      " validation loss : 0.6674006895389495; validation accuracy : 0.8805970149253731\n",
      "Epoch 32:\t train loss : 0.567015255417963; train accuracy : 0.9842126550827001; \n",
      " validation loss : 0.6195460051775902; validation accuracy : 0.9328358208955224\n",
      "Epoch 33:\t train loss : 0.5611168974192633; train accuracy : 0.9904625827418532; \n",
      " validation loss : 0.6556814705519844; validation accuracy : 0.8880597014925373\n",
      "Epoch 34:\t train loss : 0.5563716625008623; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6374252386757195; validation accuracy : 0.917910447761194\n",
      "Epoch 35:\t train loss : 0.5602699247637333; train accuracy : 0.990960287768674; \n",
      " validation loss : 0.6721100280664468; validation accuracy : 0.8805970149253731\n",
      "Epoch 36:\t train loss : 0.5651240229772478; train accuracy : 0.9861539618992012; \n",
      " validation loss : 0.6526593493978791; validation accuracy : 0.8955223880597015\n",
      "Epoch 37:\t train loss : 0.5644612672225058; train accuracy : 0.9869500327302143; \n",
      " validation loss : 0.6177745013363982; validation accuracy : 0.9328358208955224\n",
      "Epoch 38:\t train loss : 0.5615811220065922; train accuracy : 0.9895491589813894; \n",
      " validation loss : 0.6278337598013789; validation accuracy : 0.917910447761194\n",
      "Epoch 39:\t train loss : 0.5631904360865717; train accuracy : 0.9881685741072497; \n",
      " validation loss : 0.6302466588173838; validation accuracy : 0.917910447761194\n",
      "Epoch 40:\t train loss : 0.5664670874051553; train accuracy : 0.9847437976565424; \n",
      " validation loss : 0.6580024802027783; validation accuracy : 0.8955223880597015\n",
      "Epoch 41:\t train loss : 0.560955602083408; train accuracy : 0.9903777028147984; \n",
      " validation loss : 0.6613366777354172; validation accuracy : 0.8880597014925373\n",
      "Epoch 42:\t train loss : 0.5585320886573504; train accuracy : 0.9928405067588857; \n",
      " validation loss : 0.7047984999238821; validation accuracy : 0.8432835820895522\n",
      "Epoch 43:\t train loss : 0.5678589780106231; train accuracy : 0.983275439221471; \n",
      " validation loss : 0.6846999531378414; validation accuracy : 0.8656716417910447\n",
      "Epoch 44:\t train loss : 0.566674596258284; train accuracy : 0.9848257839497202; \n",
      " validation loss : 0.6618506336579464; validation accuracy : 0.8880597014925373\n",
      "Epoch 45:\t train loss : 0.6198562501705378; train accuracy : 0.9300306467979047; \n",
      " validation loss : 0.7539506662972726; validation accuracy : 0.7910447761194029\n",
      "Epoch 46:\t train loss : 0.6305584936240437; train accuracy : 0.9190563795624568; \n",
      " validation loss : 0.6914173288444285; validation accuracy : 0.8582089552238806\n",
      "Epoch 47:\t train loss : 0.5828355721794739; train accuracy : 0.9677645970968493; \n",
      " validation loss : 0.661550501863392; validation accuracy : 0.8880597014925373\n",
      "Epoch 48:\t train loss : 0.5697686071297353; train accuracy : 0.9814801001583139; \n",
      " validation loss : 0.6910970068766822; validation accuracy : 0.8582089552238806\n",
      "Epoch 49:\t train loss : 0.5719931755660718; train accuracy : 0.979298621730033; \n",
      " validation loss : 0.6991628073143045; validation accuracy : 0.8507462686567164\n",
      "Epoch 50:\t train loss : 0.5691156599466407; train accuracy : 0.9824163514749173; \n",
      " validation loss : 0.6202015649412603; validation accuracy : 0.9328358208955224\n",
      "Epoch 51:\t train loss : 0.5632219891552501; train accuracy : 0.9881161671825909; \n",
      " validation loss : 0.6339492655166402; validation accuracy : 0.9253731343283582\n",
      "Epoch 52:\t train loss : 0.5602351212724693; train accuracy : 0.9910175174164608; \n",
      " validation loss : 0.6833918734646887; validation accuracy : 0.8656716417910447\n",
      "Epoch 53:\t train loss : 0.5677194145084672; train accuracy : 0.9835004996341161; \n",
      " validation loss : 0.693630035134402; validation accuracy : 0.8582089552238806\n",
      "Epoch 54:\t train loss : 0.574037212672666; train accuracy : 0.9770026840061782; \n",
      " validation loss : 0.6879417185041838; validation accuracy : 0.8656716417910447\n",
      "Epoch 55:\t train loss : 0.5626030830080934; train accuracy : 0.9888370035328055; \n",
      " validation loss : 0.6742705585677926; validation accuracy : 0.8805970149253731\n",
      "Epoch 56:\t train loss : 0.5700165006794558; train accuracy : 0.9812045619102613; \n",
      " validation loss : 0.6518095913097119; validation accuracy : 0.8955223880597015\n",
      "Epoch 57:\t train loss : 0.5657575783283679; train accuracy : 0.9853205953426641; \n",
      " validation loss : 0.636865193669025; validation accuracy : 0.917910447761194\n",
      "Epoch 58:\t train loss : 0.5596289240614112; train accuracy : 0.9915952796472082; \n",
      " validation loss : 0.6707325106946744; validation accuracy : 0.8805970149253731\n",
      "Epoch 59:\t train loss : 0.558009799738288; train accuracy : 0.9933391763303321; \n",
      " validation loss : 0.6499507622104969; validation accuracy : 0.9029850746268657\n",
      "Epoch 60:\t train loss : 0.5592428860059302; train accuracy : 0.9921235285871736; \n",
      " validation loss : 0.6678558738865216; validation accuracy : 0.8880597014925373\n",
      "Epoch 61:\t train loss : 0.5597863007214944; train accuracy : 0.9915419081779238; \n",
      " validation loss : 0.6925184672080097; validation accuracy : 0.8582089552238806\n",
      "Epoch 62:\t train loss : 0.5586724786828444; train accuracy : 0.9928681570381536; \n",
      " validation loss : 0.6312041276909842; validation accuracy : 0.9104477611940298\n",
      "Epoch 63:\t train loss : 0.5577730487306378; train accuracy : 0.9934793568159225; \n",
      " validation loss : 0.6352843555687232; validation accuracy : 0.9104477611940298\n",
      "Epoch 64:\t train loss : 0.5651528386813776; train accuracy : 0.9857639643555749; \n",
      " validation loss : 0.666878146884565; validation accuracy : 0.8731343283582089\n",
      "Epoch 65:\t train loss : 0.5591209177306685; train accuracy : 0.9922045503357259; \n",
      " validation loss : 0.63744306753881; validation accuracy : 0.9104477611940298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66:\t train loss : 0.5575174073505744; train accuracy : 0.9938654961810462; \n",
      " validation loss : 0.6583902005197874; validation accuracy : 0.8880597014925373\n",
      "Epoch 67:\t train loss : 0.5647468355865529; train accuracy : 0.9862645630162725; \n",
      " validation loss : 0.6973723164298392; validation accuracy : 0.8582089552238806\n",
      "Epoch 68:\t train loss : 0.5675989658702123; train accuracy : 0.9834680266317202; \n",
      " validation loss : 0.6764135621696136; validation accuracy : 0.8731343283582089\n",
      "Epoch 69:\t train loss : 0.564122000388761; train accuracy : 0.9870111205565036; \n",
      " validation loss : 0.6946528329764988; validation accuracy : 0.8507462686567164\n",
      "Epoch 70:\t train loss : 0.5594520936191337; train accuracy : 0.9916801595742628; \n",
      " validation loss : 0.6379185080924489; validation accuracy : 0.9104477611940298\n",
      "Epoch 71:\t train loss : 0.5616492388566474; train accuracy : 0.9897713257601576; \n",
      " validation loss : 0.6318593313623871; validation accuracy : 0.917910447761194\n",
      "Epoch 72:\t train loss : 0.5627290331053691; train accuracy : 0.9885289922823569; \n",
      " validation loss : 0.6762588456834386; validation accuracy : 0.8731343283582089\n",
      "Epoch 73:\t train loss : 0.555644445635252; train accuracy : 0.9957990866405425; \n",
      " validation loss : 0.6364870151206178; validation accuracy : 0.917910447761194\n",
      "Epoch 74:\t train loss : 0.5616086731749967; train accuracy : 0.9897169897462476; \n",
      " validation loss : 0.6871500483243728; validation accuracy : 0.8656716417910447\n",
      "Epoch 75:\t train loss : 0.5575325497011158; train accuracy : 0.9937806162539916; \n",
      " validation loss : 0.6728060069969592; validation accuracy : 0.8805970149253731\n",
      "Epoch 76:\t train loss : 0.5566958296832418; train accuracy : 0.994774097218382; \n",
      " validation loss : 0.6936169816503991; validation accuracy : 0.8582089552238806\n",
      "Epoch 77:\t train loss : 0.5603418902946731; train accuracy : 0.9909869735033161; \n",
      " validation loss : 0.6743425066095882; validation accuracy : 0.8731343283582089\n",
      "Epoch 78:\t train loss : 0.557828768751386; train accuracy : 0.9935021843720622; \n",
      " validation loss : 0.6907866857866011; validation accuracy : 0.8582089552238806\n",
      "Early stopping at epoch 78\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5766952876246809; Train accuracy : 0.9741260904176993; \n",
      " Validation loss : 0.6060019001421927; Validation accuracy : 0.9477611940298507\n",
      "------------------------------ Let's train model 12 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.915565881581271; train accuracy : 0.6021539567549632; \n",
      " validation loss : 0.8665590719587306; validation accuracy : 0.6466165413533834\n",
      "Epoch 2:\t train loss : 0.8182479539775313; train accuracy : 0.7175109218603107; \n",
      " validation loss : 0.836481960443638; validation accuracy : 0.7142857142857143\n",
      "Epoch 3:\t train loss : 0.7703212225423769; train accuracy : 0.7738760161477631; \n",
      " validation loss : 0.7906767791212289; validation accuracy : 0.7293233082706767\n",
      "Epoch 4:\t train loss : 0.7325265732872287; train accuracy : 0.8149228557208428; \n",
      " validation loss : 0.7549752696554682; validation accuracy : 0.7894736842105263\n",
      "Epoch 5:\t train loss : 0.7003931522753322; train accuracy : 0.8477299120721119; \n",
      " validation loss : 0.7698659420146007; validation accuracy : 0.7669172932330827\n",
      "Epoch 6:\t train loss : 0.6900622248599994; train accuracy : 0.8581125919371786; \n",
      " validation loss : 0.7472526440036495; validation accuracy : 0.7894736842105263\n",
      "Epoch 7:\t train loss : 0.6565254880882778; train accuracy : 0.893809102471935; \n",
      " validation loss : 0.7080251392956624; validation accuracy : 0.8345864661654135\n",
      "Epoch 8:\t train loss : 0.6439953606979243; train accuracy : 0.9063485041198917; \n",
      " validation loss : 0.7263509167628468; validation accuracy : 0.8270676691729323\n",
      "Epoch 9:\t train loss : 0.6349207495806337; train accuracy : 0.9157081236520489; \n",
      " validation loss : 0.7136246911461127; validation accuracy : 0.8195488721804511\n",
      "Epoch 10:\t train loss : 0.6270592672858458; train accuracy : 0.9234502018470386; \n",
      " validation loss : 0.6750017402033223; validation accuracy : 0.8796992481203008\n",
      "Epoch 11:\t train loss : 0.6057268666449931; train accuracy : 0.9458607531936073; \n",
      " validation loss : 0.67514506597496; validation accuracy : 0.8721804511278195\n",
      "Epoch 12:\t train loss : 0.6001978057496443; train accuracy : 0.9509484045788863; \n",
      " validation loss : 0.7228604312909767; validation accuracy : 0.8270676691729323\n",
      "Epoch 13:\t train loss : 0.6009272858693969; train accuracy : 0.9504645246916994; \n",
      " validation loss : 0.6563803073252487; validation accuracy : 0.8872180451127819\n",
      "Epoch 14:\t train loss : 0.5914753707405053; train accuracy : 0.9598656196427584; \n",
      " validation loss : 0.7009790894165507; validation accuracy : 0.849624060150376\n",
      "Epoch 15:\t train loss : 0.6024725394625187; train accuracy : 0.948363103467345; \n",
      " validation loss : 0.6771763031513373; validation accuracy : 0.8721804511278195\n",
      "Epoch 16:\t train loss : 0.5881565943362267; train accuracy : 0.9634878062268429; \n",
      " validation loss : 0.6465163671679861; validation accuracy : 0.9097744360902256\n",
      "Epoch 17:\t train loss : 0.5877277484696706; train accuracy : 0.9632113034341647; \n",
      " validation loss : 0.7213501021597075; validation accuracy : 0.8421052631578947\n",
      "Epoch 18:\t train loss : 0.5973341732827747; train accuracy : 0.953602831388597; \n",
      " validation loss : 0.6570770494083904; validation accuracy : 0.8947368421052632\n",
      "Epoch 19:\t train loss : 0.5832140880495614; train accuracy : 0.9679118509096942; \n",
      " validation loss : 0.67551398665085; validation accuracy : 0.8721804511278195\n",
      "Epoch 20:\t train loss : 0.5712308321164621; train accuracy : 0.9801885749046065; \n",
      " validation loss : 0.6754673722377035; validation accuracy : 0.8646616541353384\n",
      "Epoch 21:\t train loss : 0.5779791804460374; train accuracy : 0.973331305646187; \n",
      " validation loss : 0.6733379685656544; validation accuracy : 0.8721804511278195\n",
      "Epoch 22:\t train loss : 0.5771707313644917; train accuracy : 0.9740778631864182; \n",
      " validation loss : 0.6232177965886191; validation accuracy : 0.9323308270676691\n",
      "Epoch 23:\t train loss : 0.5721399327753818; train accuracy : 0.9791378642924293; \n",
      " validation loss : 0.6569898290032696; validation accuracy : 0.8947368421052632\n",
      "Epoch 24:\t train loss : 0.5851423093594835; train accuracy : 0.9653265497981529; \n",
      " validation loss : 0.6471540513333197; validation accuracy : 0.9022556390977443\n",
      "Epoch 25:\t train loss : 0.5970073960515092; train accuracy : 0.9539346347398109; \n",
      " validation loss : 0.6838863089679249; validation accuracy : 0.8721804511278195\n",
      "Epoch 26:\t train loss : 0.5729715345963248; train accuracy : 0.9783083559143947; \n",
      " validation loss : 0.6274018645541679; validation accuracy : 0.9172932330827067\n",
      "Epoch 27:\t train loss : 0.5707914943241553; train accuracy : 0.98027152574241; \n",
      " validation loss : 0.6496934638861811; validation accuracy : 0.8872180451127819\n",
      "Epoch 28:\t train loss : 0.5709816129200552; train accuracy : 0.9803406514405796; \n",
      " validation loss : 0.6378571532058761; validation accuracy : 0.9172932330827067\n",
      "Epoch 29:\t train loss : 0.5643618529019254; train accuracy : 0.9867969916496157; \n",
      " validation loss : 0.659226480648203; validation accuracy : 0.8947368421052632\n",
      "Epoch 30:\t train loss : 0.5619573250454685; train accuracy : 0.9894652435989604; \n",
      " validation loss : 0.6329976465816092; validation accuracy : 0.9172932330827067\n",
      "Epoch 31:\t train loss : 0.561567141558591; train accuracy : 0.9898661726483438; \n",
      " validation loss : 0.6544625163126357; validation accuracy : 0.8872180451127819\n",
      "Epoch 32:\t train loss : 0.5640739320002012; train accuracy : 0.9871149698611956; \n",
      " validation loss : 0.6520456045409789; validation accuracy : 0.8947368421052632\n",
      "Epoch 33:\t train loss : 0.575760753788849; train accuracy : 0.9752115246363988; \n",
      " validation loss : 0.6717440717076067; validation accuracy : 0.8796992481203008\n",
      "Epoch 34:\t train loss : 0.5840267387278677; train accuracy : 0.9665155118066693; \n",
      " validation loss : 0.6483670050164112; validation accuracy : 0.9022556390977443\n",
      "Epoch 35:\t train loss : 0.5678972248709697; train accuracy : 0.983520433556379; \n",
      " validation loss : 0.6737908248084706; validation accuracy : 0.8796992481203008\n",
      "Epoch 36:\t train loss : 0.5643332541608367; train accuracy : 0.9872532212575347; \n",
      " validation loss : 0.6543264563726595; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:\t train loss : 0.5688528912690506; train accuracy : 0.9824420726649339; \n",
      " validation loss : 0.6450878670029707; validation accuracy : 0.9097744360902256\n",
      "Epoch 38:\t train loss : 0.5622929263865525; train accuracy : 0.9891334402477465; \n",
      " validation loss : 0.6476189810470078; validation accuracy : 0.9097744360902256\n",
      "Epoch 39:\t train loss : 0.5755988045694291; train accuracy : 0.9752668251949345; \n",
      " validation loss : 0.6527725792664103; validation accuracy : 0.8947368421052632\n",
      "Epoch 40:\t train loss : 0.5606976048244906; train accuracy : 0.9908339324227174; \n",
      " validation loss : 0.6419074766600255; validation accuracy : 0.9097744360902256\n",
      "Epoch 41:\t train loss : 0.5583148955817494; train accuracy : 0.9930044793452414; \n",
      " validation loss : 0.6318186609290563; validation accuracy : 0.9172932330827067\n",
      "Epoch 42:\t train loss : 0.5575063796399753; train accuracy : 0.993820162583642; \n",
      " validation loss : 0.6615139124020386; validation accuracy : 0.8947368421052632\n",
      "Epoch 43:\t train loss : 0.5583516679741941; train accuracy : 0.9930321296245092; \n",
      " validation loss : 0.6252782215508472; validation accuracy : 0.924812030075188\n",
      "Epoch 44:\t train loss : 0.5688872964596092; train accuracy : 0.9820273184759166; \n",
      " validation loss : 0.6920518620964884; validation accuracy : 0.8571428571428571\n",
      "Epoch 45:\t train loss : 0.5654726179314378; train accuracy : 0.9858845324337776; \n",
      " validation loss : 0.6596092858014156; validation accuracy : 0.8872180451127819\n",
      "Epoch 46:\t train loss : 0.5586525879637565; train accuracy : 0.9928109273903666; \n",
      " validation loss : 0.6291699645502679; validation accuracy : 0.924812030075188\n",
      "Epoch 47:\t train loss : 0.5613873290607285; train accuracy : 0.9898938229276115; \n",
      " validation loss : 0.6254876551572716; validation accuracy : 0.9323308270676691\n",
      "Epoch 48:\t train loss : 0.561400229828966; train accuracy : 0.9897832218105402; \n",
      " validation loss : 0.6463723457274819; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.5696322923839351; train accuracy : 0.981501963169828; \n",
      " validation loss : 0.6376916654904523; validation accuracy : 0.9172932330827067\n",
      "Epoch 50:\t train loss : 0.5633474575552201; train accuracy : 0.9879030028203285; \n",
      " validation loss : 0.6871686029873784; validation accuracy : 0.8646616541353384\n",
      "Epoch 51:\t train loss : 0.5613203786720594; train accuracy : 0.9900873748824863; \n",
      " validation loss : 0.6395938359983303; validation accuracy : 0.9097744360902256\n",
      "Epoch 52:\t train loss : 0.5566562165456871; train accuracy : 0.9947049715202123; \n",
      " validation loss : 0.6443660538013313; validation accuracy : 0.9097744360902256\n",
      "Epoch 53:\t train loss : 0.5624048008199272; train accuracy : 0.9887601614776309; \n",
      " validation loss : 0.6527047934499334; validation accuracy : 0.8947368421052632\n",
      "Epoch 54:\t train loss : 0.5621623468203761; train accuracy : 0.9891334402477465; \n",
      " validation loss : 0.6469857679511749; validation accuracy : 0.9022556390977443\n",
      "Epoch 55:\t train loss : 0.5579940721151717; train accuracy : 0.9933915832549909; \n",
      " validation loss : 0.6678247211995316; validation accuracy : 0.8872180451127819\n",
      "Epoch 56:\t train loss : 0.5723546649700364; train accuracy : 0.9787092849637781; \n",
      " validation loss : 0.6471242840790037; validation accuracy : 0.9022556390977443\n",
      "Epoch 57:\t train loss : 0.5606894294134209; train accuracy : 0.9906956810263784; \n",
      " validation loss : 0.6914687577550507; validation accuracy : 0.8571428571428571\n",
      "Epoch 58:\t train loss : 0.5657201550554267; train accuracy : 0.9854974285240281; \n",
      " validation loss : 0.6979291562241274; validation accuracy : 0.8571428571428571\n",
      "Epoch 59:\t train loss : 0.5678362982721212; train accuracy : 0.9831195045069955; \n",
      " validation loss : 0.6676471622976263; validation accuracy : 0.8796992481203008\n",
      "Epoch 60:\t train loss : 0.560737271319571; train accuracy : 0.990598905048941; \n",
      " validation loss : 0.6343636985250588; validation accuracy : 0.9097744360902256\n",
      "Epoch 61:\t train loss : 0.5577249558612356; train accuracy : 0.9936680860476691; \n",
      " validation loss : 0.6354738076451872; validation accuracy : 0.9172932330827067\n",
      "Epoch 62:\t train loss : 0.5557790526647522; train accuracy : 0.9956312558756844; \n",
      " validation loss : 0.6535332020342223; validation accuracy : 0.8947368421052632\n",
      "Epoch 63:\t train loss : 0.5570030598286951; train accuracy : 0.9944699441464359; \n",
      " validation loss : 0.6771108549107471; validation accuracy : 0.8721804511278195\n",
      "Epoch 64:\t train loss : 0.5776097982642557; train accuracy : 0.9734419067632583; \n",
      " validation loss : 0.6595634618636277; validation accuracy : 0.8947368421052632\n",
      "Epoch 65:\t train loss : 0.5617926267076918; train accuracy : 0.9895481944367638; \n",
      " validation loss : 0.6300195117309554; validation accuracy : 0.924812030075188\n",
      "Epoch 66:\t train loss : 0.5608558982674364; train accuracy : 0.9903915279544323; \n",
      " validation loss : 0.6303656355835187; validation accuracy : 0.924812030075188\n",
      "Epoch 67:\t train loss : 0.5581141178078065; train accuracy : 0.9932118564397501; \n",
      " validation loss : 0.6406606565219444; validation accuracy : 0.9022556390977443\n",
      "Epoch 68:\t train loss : 0.5606212057315989; train accuracy : 0.9905850799093071; \n",
      " validation loss : 0.648424221665671; validation accuracy : 0.9022556390977443\n",
      "Epoch 69:\t train loss : 0.5580659111272264; train accuracy : 0.9932533318586517; \n",
      " validation loss : 0.6314885517118571; validation accuracy : 0.9172932330827067\n",
      "Epoch 70:\t train loss : 0.5612336351864443; train accuracy : 0.9899629486257812; \n",
      " validation loss : 0.6503834814175933; validation accuracy : 0.9022556390977443\n",
      "Epoch 71:\t train loss : 0.559866288920707; train accuracy : 0.9914560637062434; \n",
      " validation loss : 0.6299091037615697; validation accuracy : 0.924812030075188\n",
      "Epoch 72:\t train loss : 0.5639645732402548; train accuracy : 0.9869767184648565; \n",
      " validation loss : 0.6298210998600967; validation accuracy : 0.924812030075188\n",
      "Early stopping at epoch 72\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5771707313644917; Train accuracy : 0.9740778631864182; \n",
      " Validation loss : 0.6232177965886191; Validation accuracy : 0.9323308270676691\n",
      "------------------------------ Let's train model 13 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8901280972162754; train accuracy : 0.647270782556855; \n",
      " validation loss : 0.8054532203048729; validation accuracy : 0.7443609022556391\n",
      "Epoch 2:\t train loss : 0.7671576149932088; train accuracy : 0.7768743854556833; \n",
      " validation loss : 0.7780006437631647; validation accuracy : 0.7744360902255639\n",
      "Epoch 3:\t train loss : 0.6951987722059887; train accuracy : 0.8541178009800338; \n",
      " validation loss : 0.747607938288091; validation accuracy : 0.7969924812030075\n",
      "Epoch 4:\t train loss : 0.6602184722677161; train accuracy : 0.8906195415988336; \n",
      " validation loss : 0.7606868322971001; validation accuracy : 0.7819548872180451\n",
      "Epoch 5:\t train loss : 0.645958181085; train accuracy : 0.904766368628128; \n",
      " validation loss : 0.7544023303201401; validation accuracy : 0.7969924812030075\n",
      "Epoch 6:\t train loss : 0.6222843677213122; train accuracy : 0.9292604696770852; \n",
      " validation loss : 0.6991091453410849; validation accuracy : 0.849624060150376\n",
      "Epoch 7:\t train loss : 0.615906114847171; train accuracy : 0.935063656338051; \n",
      " validation loss : 0.6919678708034295; validation accuracy : 0.8571428571428571\n",
      "Epoch 8:\t train loss : 0.605849073788714; train accuracy : 0.9464346650876784; \n",
      " validation loss : 0.6914244360297688; validation accuracy : 0.8646616541353384\n",
      "Epoch 9:\t train loss : 0.5952762876427862; train accuracy : 0.9569107489449058; \n",
      " validation loss : 0.6739455878302055; validation accuracy : 0.8872180451127819\n",
      "Epoch 10:\t train loss : 0.5947340010836629; train accuracy : 0.956762381592737; \n",
      " validation loss : 0.700821095150425; validation accuracy : 0.8421052631578947\n",
      "Epoch 11:\t train loss : 0.592577926647089; train accuracy : 0.9590917490217871; \n",
      " validation loss : 0.7257911194386447; validation accuracy : 0.8195488721804511\n",
      "Epoch 12:\t train loss : 0.5914076193637496; train accuracy : 0.9597620996947679; \n",
      " validation loss : 0.7049879145974574; validation accuracy : 0.8345864661654135\n",
      "Epoch 13:\t train loss : 0.5876150827164942; train accuracy : 0.9637990404678697; \n",
      " validation loss : 0.6881481122107389; validation accuracy : 0.8721804511278195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\t train loss : 0.5735613203036966; train accuracy : 0.9782911587894842; \n",
      " validation loss : 0.671659731974066; validation accuracy : 0.8721804511278195\n",
      "Epoch 15:\t train loss : 0.5694992958722079; train accuracy : 0.9826221366787024; \n",
      " validation loss : 0.6816137139158872; validation accuracy : 0.8646616541353384\n",
      "Epoch 16:\t train loss : 0.569448317510229; train accuracy : 0.9823975624592833; \n",
      " validation loss : 0.6928437106711091; validation accuracy : 0.8646616541353384\n",
      "Epoch 17:\t train loss : 0.5770417191308677; train accuracy : 0.974641321926132; \n",
      " validation loss : 0.6660797031677453; validation accuracy : 0.8796992481203008\n",
      "Epoch 18:\t train loss : 0.5862251707628371; train accuracy : 0.964836937535996; \n",
      " validation loss : 0.6775629103641332; validation accuracy : 0.8796992481203008\n",
      "Epoch 19:\t train loss : 0.5777477990532208; train accuracy : 0.9739224146651686; \n",
      " validation loss : 0.6856649631176177; validation accuracy : 0.8571428571428571\n",
      "Epoch 20:\t train loss : 0.5701703987775427; train accuracy : 0.9813603397882124; \n",
      " validation loss : 0.6767542976348827; validation accuracy : 0.8571428571428571\n",
      "Epoch 21:\t train loss : 0.5669472851170845; train accuracy : 0.9845987944478239; \n",
      " validation loss : 0.6943993024176635; validation accuracy : 0.8571428571428571\n",
      "Epoch 22:\t train loss : 0.5746269579624252; train accuracy : 0.9767326271946566; \n",
      " validation loss : 0.7121311803796411; validation accuracy : 0.8421052631578947\n",
      "Epoch 23:\t train loss : 0.5795254578732201; train accuracy : 0.9716901604120836; \n",
      " validation loss : 0.7277069615361806; validation accuracy : 0.8195488721804511\n",
      "Epoch 24:\t train loss : 0.5763072536600298; train accuracy : 0.9749144527335336; \n",
      " validation loss : 0.6650925598179882; validation accuracy : 0.8872180451127819\n",
      "Epoch 25:\t train loss : 0.5688807864313856; train accuracy : 0.9826632748990765; \n",
      " validation loss : 0.6914677990967527; validation accuracy : 0.8571428571428571\n",
      "Epoch 26:\t train loss : 0.5641776207219661; train accuracy : 0.9871702704197313; \n",
      " validation loss : 0.6876784111255964; validation accuracy : 0.8646616541353384\n",
      "Epoch 27:\t train loss : 0.567273108101284; train accuracy : 0.9840909734651735; \n",
      " validation loss : 0.7147614763073428; validation accuracy : 0.8195488721804511\n",
      "Epoch 28:\t train loss : 0.578774260672169; train accuracy : 0.9721561687773046; \n",
      " validation loss : 0.6727204017485439; validation accuracy : 0.8571428571428571\n",
      "Epoch 29:\t train loss : 0.5627198202102788; train accuracy : 0.9888812157490595; \n",
      " validation loss : 0.6547087453961334; validation accuracy : 0.9022556390977443\n",
      "Epoch 30:\t train loss : 0.5628261897131213; train accuracy : 0.9886566415296404; \n",
      " validation loss : 0.667427656624783; validation accuracy : 0.8872180451127819\n",
      "Epoch 31:\t train loss : 0.56524825635086; train accuracy : 0.9858916136028584; \n",
      " validation loss : 0.7046584258419906; validation accuracy : 0.8421052631578947\n",
      "Epoch 32:\t train loss : 0.5626212212345848; train accuracy : 0.9887739866172648; \n",
      " validation loss : 0.6899099736229244; validation accuracy : 0.8571428571428571\n",
      "Epoch 33:\t train loss : 0.5610139545992495; train accuracy : 0.99039186515296; \n",
      " validation loss : 0.689255288549593; validation accuracy : 0.8646616541353384\n",
      "Epoch 34:\t train loss : 0.5616583572289027; train accuracy : 0.9897970469501742; \n",
      " validation loss : 0.6678548492402508; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.5639235872176029; train accuracy : 0.9873051498307938; \n",
      " validation loss : 0.6774961019363963; validation accuracy : 0.8721804511278195\n",
      "Epoch 36:\t train loss : 0.561533348744087; train accuracy : 0.9899285543759602; \n",
      " validation loss : 0.6624245473392156; validation accuracy : 0.8872180451127819\n",
      "Epoch 37:\t train loss : 0.5624361630473181; train accuracy : 0.9889951888514074; \n",
      " validation loss : 0.688265229225676; validation accuracy : 0.8646616541353384\n",
      "Epoch 38:\t train loss : 0.5684127200635308; train accuracy : 0.9827846663690327; \n",
      " validation loss : 0.7000414197147145; validation accuracy : 0.849624060150376\n",
      "Epoch 39:\t train loss : 0.5770610987083087; train accuracy : 0.9738118135480973; \n",
      " validation loss : 0.6539085310404174; validation accuracy : 0.8947368421052632\n",
      "Epoch 40:\t train loss : 0.5615652241720595; train accuracy : 0.9898799977879776; \n",
      " validation loss : 0.6868788807575047; validation accuracy : 0.8646616541353384\n",
      "Epoch 41:\t train loss : 0.5676376130743744; train accuracy : 0.9839250717895666; \n",
      " validation loss : 0.7121741128678855; validation accuracy : 0.8270676691729323\n",
      "Epoch 42:\t train loss : 0.5624804406597289; train accuracy : 0.988746336337997; \n",
      " validation loss : 0.6628747174426337; validation accuracy : 0.8872180451127819\n",
      "Epoch 43:\t train loss : 0.5629305960470113; train accuracy : 0.9882938159138822; \n",
      " validation loss : 0.7102875163227973; validation accuracy : 0.8345864661654135\n",
      "Epoch 44:\t train loss : 0.6038051911727234; train accuracy : 0.9460617235160904; \n",
      " validation loss : 0.7522266069461269; validation accuracy : 0.7969924812030075\n",
      "Epoch 45:\t train loss : 0.5778435692968321; train accuracy : 0.9733694090798122; \n",
      " validation loss : 0.685241701264367; validation accuracy : 0.8721804511278195\n",
      "Epoch 46:\t train loss : 0.5696927459204719; train accuracy : 0.981294923273847; \n",
      " validation loss : 0.7032465349786728; validation accuracy : 0.8421052631578947\n",
      "Epoch 47:\t train loss : 0.5626860997067469; train accuracy : 0.9887948929259796; \n",
      " validation loss : 0.6506166101946756; validation accuracy : 0.8947368421052632\n",
      "Epoch 48:\t train loss : 0.5674900844331885; train accuracy : 0.9836863352319859; \n",
      " validation loss : 0.7234605088456513; validation accuracy : 0.8195488721804511\n",
      "Epoch 49:\t train loss : 0.5657745992721399; train accuracy : 0.9853143297235107; \n",
      " validation loss : 0.7196549160596315; validation accuracy : 0.8345864661654135\n",
      "Epoch 50:\t train loss : 0.5597963190359752; train accuracy : 0.9916428716905651; \n",
      " validation loss : 0.6223330215100108; validation accuracy : 0.924812030075188\n",
      "Epoch 51:\t train loss : 0.5593291309364518; train accuracy : 0.9921196704086711; \n",
      " validation loss : 0.6579945631563368; validation accuracy : 0.8947368421052632\n",
      "Epoch 52:\t train loss : 0.5620965506480075; train accuracy : 0.9891334402477465; \n",
      " validation loss : 0.656831483711339; validation accuracy : 0.8872180451127819\n",
      "Epoch 53:\t train loss : 0.5591402795917383; train accuracy : 0.992251177834457; \n",
      " validation loss : 0.6960516675044279; validation accuracy : 0.8571428571428571\n",
      "Epoch 54:\t train loss : 0.5654043000567707; train accuracy : 0.9857014336332601; \n",
      " validation loss : 0.7083013127952118; validation accuracy : 0.8345864661654135\n",
      "Epoch 55:\t train loss : 0.5824872618523372; train accuracy : 0.9682514098270442; \n",
      " validation loss : 0.711017898846373; validation accuracy : 0.8421052631578947\n",
      "Epoch 56:\t train loss : 0.5720197946503656; train accuracy : 0.9790134380357242; \n",
      " validation loss : 0.679623256424675; validation accuracy : 0.8721804511278195\n",
      "Epoch 57:\t train loss : 0.5630263279886387; train accuracy : 0.9882971878991588; \n",
      " validation loss : 0.6500486125919112; validation accuracy : 0.9022556390977443\n",
      "Epoch 58:\t train loss : 0.5629325239029963; train accuracy : 0.9882108650760787; \n",
      " validation loss : 0.6787623328188693; validation accuracy : 0.8721804511278195\n",
      "Epoch 59:\t train loss : 0.5610736771860315; train accuracy : 0.9901774068893705; \n",
      " validation loss : 0.6694099726465401; validation accuracy : 0.8721804511278195\n",
      "Epoch 60:\t train loss : 0.557464891224676; train accuracy : 0.9940275396781507; \n",
      " validation loss : 0.6726327600311695; validation accuracy : 0.8796992481203008\n",
      "Epoch 61:\t train loss : 0.5619259882236152; train accuracy : 0.989181996835729; \n",
      " validation loss : 0.6584680807400444; validation accuracy : 0.8947368421052632\n",
      "Epoch 62:\t train loss : 0.5595174731256015; train accuracy : 0.991895096189252; \n",
      " validation loss : 0.6524055038529056; validation accuracy : 0.8947368421052632\n",
      "Epoch 63:\t train loss : 0.5582611426700262; train accuracy : 0.9931117084770361; \n",
      " validation loss : 0.6681857403938799; validation accuracy : 0.8872180451127819\n",
      "Epoch 64:\t train loss : 0.5575743253035366; train accuracy : 0.9939135665758029; \n",
      " validation loss : 0.6756525681208775; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:\t train loss : 0.5566125407369902; train accuracy : 0.9947707252331053; \n",
      " validation loss : 0.6638787540486369; validation accuracy : 0.8947368421052632\n",
      "Epoch 66:\t train loss : 0.5630886108567729; train accuracy : 0.988189958767364; \n",
      " validation loss : 0.6609232673739734; validation accuracy : 0.8872180451127819\n",
      "Epoch 67:\t train loss : 0.5581146010262075; train accuracy : 0.9932533318586517; \n",
      " validation loss : 0.6712659447512217; validation accuracy : 0.8796992481203008\n",
      "Epoch 68:\t train loss : 0.5557256245813053; train accuracy : 0.9957418569927556; \n",
      " validation loss : 0.651992272255393; validation accuracy : 0.9022556390977443\n",
      "Epoch 69:\t train loss : 0.5572632712480092; train accuracy : 0.994217719647749; \n",
      " validation loss : 0.6693137726438688; validation accuracy : 0.8796992481203008\n",
      "Epoch 70:\t train loss : 0.5570112617735365; train accuracy : 0.9943836213233559; \n",
      " validation loss : 0.6306466514650622; validation accuracy : 0.9172932330827067\n",
      "Epoch 71:\t train loss : 0.5573264488264082; train accuracy : 0.9939169385610794; \n",
      " validation loss : 0.6878914918085057; validation accuracy : 0.8646616541353384\n",
      "Epoch 72:\t train loss : 0.5584855437924788; train accuracy : 0.9929114125516082; \n",
      " validation loss : 0.6631936470515043; validation accuracy : 0.8872180451127819\n",
      "Epoch 73:\t train loss : 0.5796856854273325; train accuracy : 0.9711681770912716; \n",
      " validation loss : 0.6875827689329939; validation accuracy : 0.8571428571428571\n",
      "Epoch 74:\t train loss : 0.6054002451125579; train accuracy : 0.945031919212628; \n",
      " validation loss : 0.6611988850468529; validation accuracy : 0.8872180451127819\n",
      "Epoch 75:\t train loss : 0.5793794655866663; train accuracy : 0.9716517197799307; \n",
      " validation loss : 0.6968053615265244; validation accuracy : 0.8571428571428571\n",
      "Epoch 76:\t train loss : 0.5687748110858615; train accuracy : 0.9822727990040504; \n",
      " validation loss : 0.6995883966944001; validation accuracy : 0.8421052631578947\n",
      "Epoch 77:\t train loss : 0.5709679626747012; train accuracy : 0.9801612618238664; \n",
      " validation loss : 0.6895303729530395; validation accuracy : 0.8571428571428571\n",
      "Epoch 78:\t train loss : 0.5715745943032947; train accuracy : 0.9795907219150718; \n",
      " validation loss : 0.649626174343084; validation accuracy : 0.8947368421052632\n",
      "Epoch 79:\t train loss : 0.5579114749667224; train accuracy : 0.9934711621075177; \n",
      " validation loss : 0.6545110804571049; validation accuracy : 0.8947368421052632\n",
      "Epoch 80:\t train loss : 0.5575112115885442; train accuracy : 0.9937442929149194; \n",
      " validation loss : 0.6566564281066123; validation accuracy : 0.8947368421052632\n",
      "Epoch 81:\t train loss : 0.5564380115930433; train accuracy : 0.9949952994525244; \n",
      " validation loss : 0.6824330441425108; validation accuracy : 0.8721804511278195\n",
      "Epoch 82:\t train loss : 0.5584620341168102; train accuracy : 0.9926935823027422; \n",
      " validation loss : 0.6567871661299999; validation accuracy : 0.8947368421052632\n",
      "Epoch 83:\t train loss : 0.5590336359547262; train accuracy : 0.992285572084278; \n",
      " validation loss : 0.6436917294171949; validation accuracy : 0.9097744360902256\n",
      "Epoch 84:\t train loss : 0.5572927965053805; train accuracy : 0.9941104905159542; \n",
      " validation loss : 0.6671734979636695; validation accuracy : 0.8796992481203008\n",
      "Epoch 85:\t train loss : 0.5594555849234487; train accuracy : 0.9919470247625111; \n",
      " validation loss : 0.6629688027447305; validation accuracy : 0.8872180451127819\n",
      "Epoch 86:\t train loss : 0.5587853617834895; train accuracy : 0.9925897251562241; \n",
      " validation loss : 0.668048552664241; validation accuracy : 0.8872180451127819\n",
      "Epoch 87:\t train loss : 0.5554178524982842; train accuracy : 0.9958801083890947; \n",
      " validation loss : 0.6723664646416083; validation accuracy : 0.8796992481203008\n",
      "Epoch 88:\t train loss : 0.5551182306350989; train accuracy : 0.9962672122988442; \n",
      " validation loss : 0.6657763947637463; validation accuracy : 0.8872180451127819\n",
      "Epoch 89:\t train loss : 0.5564265103997624; train accuracy : 0.9949366269087122; \n",
      " validation loss : 0.6676364973747577; validation accuracy : 0.8721804511278195\n",
      "Epoch 90:\t train loss : 0.5564395728937501; train accuracy : 0.9948260257916409; \n",
      " validation loss : 0.6728930124578408; validation accuracy : 0.8796992481203008\n",
      "Epoch 91:\t train loss : 0.5578594516892535; train accuracy : 0.9934468838135265; \n",
      " validation loss : 0.6899643038799151; validation accuracy : 0.8571428571428571\n",
      "Epoch 92:\t train loss : 0.5574934924226886; train accuracy : 0.9938306157379995; \n",
      " validation loss : 0.683818053733366; validation accuracy : 0.8571428571428571\n",
      "Epoch 93:\t train loss : 0.5571017852709984; train accuracy : 0.9943006704855524; \n",
      " validation loss : 0.6616670203192047; validation accuracy : 0.8872180451127819\n",
      "Epoch 94:\t train loss : 0.5585059387158506; train accuracy : 0.9930287576392326; \n",
      " validation loss : 0.6421345763627255; validation accuracy : 0.9097744360902256\n",
      "Epoch 95:\t train loss : 0.5567025080108464; train accuracy : 0.9947740972183818; \n",
      " validation loss : 0.6714631406125711; validation accuracy : 0.8796992481203008\n",
      "Epoch 96:\t train loss : 0.5572986712399545; train accuracy : 0.9940241676928742; \n",
      " validation loss : 0.6398622517803593; validation accuracy : 0.9097744360902256\n",
      "Epoch 97:\t train loss : 0.5584027347415235; train accuracy : 0.99280755540509; \n",
      " validation loss : 0.6986178748057396; validation accuracy : 0.849624060150376\n",
      "Epoch 98:\t train loss : 0.5582753264636114; train accuracy : 0.9929458068014292; \n",
      " validation loss : 0.6933237867703262; validation accuracy : 0.8571428571428571\n",
      "Epoch 99:\t train loss : 0.5711471072710486; train accuracy : 0.9800371727656888; \n",
      " validation loss : 0.6846968766907517; validation accuracy : 0.8646616541353384\n",
      "Epoch 100:\t train loss : 0.5873213594444033; train accuracy : 0.9634051925875671; \n",
      " validation loss : 0.706856686667749; validation accuracy : 0.849624060150376\n",
      "Early stopping at epoch 100\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5597963190359752; Train accuracy : 0.9916428716905651; \n",
      " Validation loss : 0.6223330215100108; Validation accuracy : 0.924812030075188\n",
      "------------------------------ Let's train model 14 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8730519208154047; train accuracy : 0.6644776862246309; \n",
      " validation loss : 0.8370353098918332; validation accuracy : 0.6992481203007519\n",
      "Epoch 2:\t train loss : 0.7881272154552242; train accuracy : 0.753400984349942; \n",
      " validation loss : 0.8010569883085624; validation accuracy : 0.7293233082706767\n",
      "Epoch 3:\t train loss : 0.7347135541633432; train accuracy : 0.8120195763977216; \n",
      " validation loss : 0.733504941901426; validation accuracy : 0.8195488721804511\n",
      "Epoch 4:\t train loss : 0.6853120077742051; train accuracy : 0.864195653376099; \n",
      " validation loss : 0.7300003387358286; validation accuracy : 0.8195488721804511\n",
      "Epoch 5:\t train loss : 0.6480998658503886; train accuracy : 0.90383232870652; \n",
      " validation loss : 0.6895999977291216; validation accuracy : 0.8571428571428571\n",
      "Epoch 6:\t train loss : 0.6252173969473037; train accuracy : 0.9262843554719903; \n",
      " validation loss : 0.726287913015784; validation accuracy : 0.7969924812030075\n",
      "Epoch 7:\t train loss : 0.6140803012782761; train accuracy : 0.9374827185754576; \n",
      " validation loss : 0.716980627968831; validation accuracy : 0.8270676691729323\n",
      "Epoch 8:\t train loss : 0.6042036642295802; train accuracy : 0.9477824476027208; \n",
      " validation loss : 0.6947411234474945; validation accuracy : 0.849624060150376\n",
      "Epoch 9:\t train loss : 0.5946620163506401; train accuracy : 0.9573217939501188; \n",
      " validation loss : 0.7123145328638506; validation accuracy : 0.8270676691729323\n",
      "Epoch 10:\t train loss : 0.5868241523505321; train accuracy : 0.9647597190731626; \n",
      " validation loss : 0.7012796639637797; validation accuracy : 0.849624060150376\n",
      "Epoch 11:\t train loss : 0.5769973949638089; train accuracy : 0.9749764972626224; \n",
      " validation loss : 0.6946257015029043; validation accuracy : 0.8571428571428571\n",
      "Epoch 12:\t train loss : 0.5739488030185457; train accuracy : 0.9782254050765913; \n",
      " validation loss : 0.6776141578748965; validation accuracy : 0.8721804511278195\n",
      "Epoch 13:\t train loss : 0.5703219764921548; train accuracy : 0.9814051871923907; \n",
      " validation loss : 0.6675400952664334; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\t train loss : 0.5666969301911153; train accuracy : 0.9847785212630648; \n",
      " validation loss : 0.7632155961878639; validation accuracy : 0.7819548872180451\n",
      "Epoch 15:\t train loss : 0.5877903829504664; train accuracy : 0.963169828015263; \n",
      " validation loss : 0.6851104685292342; validation accuracy : 0.8646616541353384\n",
      "Epoch 16:\t train loss : 0.5669204251897682; train accuracy : 0.9848476469612343; \n",
      " validation loss : 0.7002962956401992; validation accuracy : 0.849624060150376\n",
      "Epoch 17:\t train loss : 0.5706127423985998; train accuracy : 0.9810042581430073; \n",
      " validation loss : 0.7355426274568589; validation accuracy : 0.8045112781954887\n",
      "Epoch 18:\t train loss : 0.5727299038851967; train accuracy : 0.9783774816125643; \n",
      " validation loss : 0.6709972033089647; validation accuracy : 0.8721804511278195\n",
      "Epoch 19:\t train loss : 0.5652070730388944; train accuracy : 0.9864098877398662; \n",
      " validation loss : 0.6525727037290123; validation accuracy : 0.8947368421052632\n",
      "Epoch 20:\t train loss : 0.5664856392784707; train accuracy : 0.9848752972405022; \n",
      " validation loss : 0.6742028226253104; validation accuracy : 0.8721804511278195\n",
      "Epoch 21:\t train loss : 0.5604704754322344; train accuracy : 0.9909583586794226; \n",
      " validation loss : 0.6746229713298719; validation accuracy : 0.8796992481203008\n",
      "Epoch 22:\t train loss : 0.5589274861742944; train accuracy : 0.9928524028092683; \n",
      " validation loss : 0.6522604964848057; validation accuracy : 0.9022556390977443\n",
      "Epoch 23:\t train loss : 0.5822298184928923; train accuracy : 0.9685754576121218; \n",
      " validation loss : 0.7564357003984846; validation accuracy : 0.7969924812030075\n",
      "Epoch 24:\t train loss : 0.5691500944520808; train accuracy : 0.9822623458496931; \n",
      " validation loss : 0.6927054017491666; validation accuracy : 0.849624060150376\n",
      "Epoch 25:\t train loss : 0.5674978746239846; train accuracy : 0.9835757341149146; \n",
      " validation loss : 0.7070099095940382; validation accuracy : 0.8421052631578947\n",
      "Epoch 26:\t train loss : 0.5650653735113099; train accuracy : 0.9863822374605984; \n",
      " validation loss : 0.672689555893541; validation accuracy : 0.8796992481203008\n",
      "Epoch 27:\t train loss : 0.5574053026764705; train accuracy : 0.9941104905159542; \n",
      " validation loss : 0.6745870444087839; validation accuracy : 0.8721804511278195\n",
      "Epoch 28:\t train loss : 0.5562705759723693; train accuracy : 0.9951473759884975; \n",
      " validation loss : 0.7088313766148115; validation accuracy : 0.8421052631578947\n",
      "Epoch 29:\t train loss : 0.5726959913882543; train accuracy : 0.9784051318918321; \n",
      " validation loss : 0.6976563576386882; validation accuracy : 0.8421052631578947\n",
      "Epoch 30:\t train loss : 0.561189165771268; train accuracy : 0.9903638776751645; \n",
      " validation loss : 0.6613769141074733; validation accuracy : 0.8872180451127819\n",
      "Epoch 31:\t train loss : 0.5648687511947537; train accuracy : 0.9865757894154731; \n",
      " validation loss : 0.6845357198655202; validation accuracy : 0.8646616541353384\n",
      "Epoch 32:\t train loss : 0.559428246177241; train accuracy : 0.9922164463861085; \n",
      " validation loss : 0.6662929719096469; validation accuracy : 0.8872180451127819\n",
      "Epoch 33:\t train loss : 0.5570248859595345; train accuracy : 0.994456119006802; \n",
      " validation loss : 0.7030441155143868; validation accuracy : 0.8345864661654135\n",
      "Epoch 34:\t train loss : 0.5639804503206367; train accuracy : 0.9872532212575347; \n",
      " validation loss : 0.6709176636234389; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.5567450449345466; train accuracy : 0.9946911463805784; \n",
      " validation loss : 0.6970967693382359; validation accuracy : 0.849624060150376\n",
      "Epoch 36:\t train loss : 0.5547305787651854; train accuracy : 0.9968893435823701; \n",
      " validation loss : 0.6780078877005934; validation accuracy : 0.8721804511278195\n",
      "Epoch 37:\t train loss : 0.5544471686173847; train accuracy : 0.9970552452579771; \n",
      " validation loss : 0.6779836728661062; validation accuracy : 0.8721804511278195\n",
      "Epoch 38:\t train loss : 0.5540885415341089; train accuracy : 0.9974699994469944; \n",
      " validation loss : 0.677695041823569; validation accuracy : 0.8796992481203008\n",
      "Epoch 39:\t train loss : 0.553648287494564; train accuracy : 0.9979262290549135; \n",
      " validation loss : 0.6879451792747568; validation accuracy : 0.8646616541353384\n",
      "Epoch 40:\t train loss : 0.582850627179966; train accuracy : 0.967939501188962; \n",
      " validation loss : 0.6952891151210759; validation accuracy : 0.8571428571428571\n",
      "Epoch 41:\t train loss : 0.6150911881666181; train accuracy : 0.9349803683017198; \n",
      " validation loss : 0.7343222828303018; validation accuracy : 0.8120300751879699\n",
      "Epoch 42:\t train loss : 0.6075481040820047; train accuracy : 0.94297129901012; \n",
      " validation loss : 0.6854109149329743; validation accuracy : 0.8721804511278195\n",
      "Epoch 43:\t train loss : 0.5956618718622976; train accuracy : 0.954833268816015; \n",
      " validation loss : 0.6984721934851353; validation accuracy : 0.849624060150376\n",
      "Epoch 44:\t train loss : 0.5713111792031749; train accuracy : 0.9800364983686335; \n",
      " validation loss : 0.6686878306247694; validation accuracy : 0.8796992481203008\n",
      "Epoch 45:\t train loss : 0.5595217707133938; train accuracy : 0.9918846430348947; \n",
      " validation loss : 0.6919972732805931; validation accuracy : 0.8571428571428571\n",
      "Epoch 46:\t train loss : 0.5591658662188983; train accuracy : 0.9921058452690372; \n",
      " validation loss : 0.6680932974128273; validation accuracy : 0.8872180451127819\n",
      "Epoch 47:\t train loss : 0.5561502501282747; train accuracy : 0.9951750262677653; \n",
      " validation loss : 0.6760455048752775; validation accuracy : 0.8796992481203008\n",
      "Epoch 48:\t train loss : 0.5570893888911254; train accuracy : 0.9944699441464359; \n",
      " validation loss : 0.6423745187457001; validation accuracy : 0.9097744360902256\n",
      "Epoch 49:\t train loss : 0.5567893998974601; train accuracy : 0.9946358458220428; \n",
      " validation loss : 0.6905342760264135; validation accuracy : 0.8571428571428571\n",
      "Epoch 50:\t train loss : 0.5594376158757568; train accuracy : 0.9917325664989216; \n",
      " validation loss : 0.6600252809562178; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5548909563971676; train accuracy : 0.996460764253719; \n",
      " validation loss : 0.6759760567572246; validation accuracy : 0.8796992481203008\n",
      "Epoch 52:\t train loss : 0.5543297637121353; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.6817771970922238; validation accuracy : 0.8646616541353384\n",
      "Epoch 53:\t train loss : 0.5690471444749947; train accuracy : 0.981972017917381; \n",
      " validation loss : 0.6716914484661891; validation accuracy : 0.8796992481203008\n",
      "Epoch 54:\t train loss : 0.559822308528792; train accuracy : 0.9914560637062434; \n",
      " validation loss : 0.658914178975111; validation accuracy : 0.8947368421052632\n",
      "Epoch 55:\t train loss : 0.5572246151346328; train accuracy : 0.9941657910744899; \n",
      " validation loss : 0.6904742448552504; validation accuracy : 0.8571428571428571\n",
      "Epoch 56:\t train loss : 0.5629672207782749; train accuracy : 0.9883039318697119; \n",
      " validation loss : 0.6578088528472146; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5592639359192495; train accuracy : 0.9920920201294033; \n",
      " validation loss : 0.6694043188600999; validation accuracy : 0.8796992481203008\n",
      "Epoch 58:\t train loss : 0.5594288623968217; train accuracy : 0.9918431676159929; \n",
      " validation loss : 0.6870981300657488; validation accuracy : 0.8646616541353384\n",
      "Epoch 59:\t train loss : 0.557149730051448; train accuracy : 0.994290217331195; \n",
      " validation loss : 0.6897143842555137; validation accuracy : 0.8646616541353384\n",
      "Epoch 60:\t train loss : 0.5586617103229116; train accuracy : 0.9926726759940275; \n",
      " validation loss : 0.656211746390973; validation accuracy : 0.8947368421052632\n",
      "Epoch 61:\t train loss : 0.5574071086654622; train accuracy : 0.9939584139799812; \n",
      " validation loss : 0.707698551059597; validation accuracy : 0.8421052631578947\n",
      "Epoch 62:\t train loss : 0.560079307555101; train accuracy : 0.9912348614721008; \n",
      " validation loss : 0.6862256144837808; validation accuracy : 0.8646616541353384\n",
      "Epoch 63:\t train loss : 0.5559842886511991; train accuracy : 0.99536857822264; \n",
      " validation loss : 0.6743132571775929; validation accuracy : 0.8796992481203008\n",
      "Epoch 64:\t train loss : 0.5560262003893484; train accuracy : 0.9953409279433723; \n",
      " validation loss : 0.6613124984533763; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:\t train loss : 0.5546486086679394; train accuracy : 0.996916993861638; \n",
      " validation loss : 0.67084327011213; validation accuracy : 0.8796992481203008\n",
      "Epoch 66:\t train loss : 0.5553528586141141; train accuracy : 0.9959354089476303; \n",
      " validation loss : 0.703279157947765; validation accuracy : 0.8421052631578947\n",
      "Epoch 67:\t train loss : 0.591130355831472; train accuracy : 0.9595476414311784; \n",
      " validation loss : 0.6871745229868363; validation accuracy : 0.8571428571428571\n",
      "Epoch 68:\t train loss : 0.5648701634309706; train accuracy : 0.9865066637173036; \n",
      " validation loss : 0.9368239703426637; validation accuracy : 0.6165413533834586\n",
      "Epoch 69:\t train loss : 0.73475648957631; train accuracy : 0.8122269534922303; \n",
      " validation loss : 0.7386413266017021; validation accuracy : 0.8195488721804511\n",
      "Epoch 70:\t train loss : 0.6588987882705936; train accuracy : 0.8896892108610297; \n",
      " validation loss : 0.7237390944710568; validation accuracy : 0.8270676691729323\n",
      "Epoch 71:\t train loss : 0.617374364173439; train accuracy : 0.9325747940054194; \n",
      " validation loss : 0.6646858128142996; validation accuracy : 0.8872180451127819\n",
      "Epoch 72:\t train loss : 0.6142465144707248; train accuracy : 0.935726925841951; \n",
      " validation loss : 0.6808279463451071; validation accuracy : 0.8646616541353384\n",
      "Epoch 73:\t train loss : 0.6015543846934645; train accuracy : 0.9485013548636841; \n",
      " validation loss : 0.7008906352568512; validation accuracy : 0.849624060150376\n",
      "Epoch 74:\t train loss : 0.584428233625174; train accuracy : 0.966391085549964; \n",
      " validation loss : 0.6779080996103423; validation accuracy : 0.8646616541353384\n",
      "Epoch 75:\t train loss : 0.5788528972417392; train accuracy : 0.9721423436376707; \n",
      " validation loss : 0.6844593706875977; validation accuracy : 0.8646616541353384\n",
      "Epoch 76:\t train loss : 0.5718132517016411; train accuracy : 0.9790687385942598; \n",
      " validation loss : 0.6313088188216753; validation accuracy : 0.9172932330827067\n",
      "Epoch 77:\t train loss : 0.620206203507508; train accuracy : 0.9292705856329149; \n",
      " validation loss : 0.6723617876507169; validation accuracy : 0.8796992481203008\n",
      "Epoch 78:\t train loss : 0.5952522001810787; train accuracy : 0.955317148703202; \n",
      " validation loss : 0.6462902543855514; validation accuracy : 0.9097744360902256\n",
      "Epoch 79:\t train loss : 0.5778763269455572; train accuracy : 0.9729718520157054; \n",
      " validation loss : 0.7118495618844471; validation accuracy : 0.8421052631578947\n",
      "Epoch 80:\t train loss : 0.5755759162367728; train accuracy : 0.9754050765912736; \n",
      " validation loss : 0.6576071741929925; validation accuracy : 0.8947368421052632\n",
      "Epoch 81:\t train loss : 0.5750232328788205; train accuracy : 0.9761654592711386; \n",
      " validation loss : 0.6875990743533268; validation accuracy : 0.8646616541353384\n",
      "Epoch 82:\t train loss : 0.5663836190227605; train accuracy : 0.9849444229386717; \n",
      " validation loss : 0.7004107393428215; validation accuracy : 0.849624060150376\n",
      "Epoch 83:\t train loss : 0.5695618621996484; train accuracy : 0.9813360614942211; \n",
      " validation loss : 0.6972413096864086; validation accuracy : 0.8571428571428571\n",
      "Epoch 84:\t train loss : 0.5620030084501769; train accuracy : 0.989368467621523; \n",
      " validation loss : 0.6708199752318067; validation accuracy : 0.8796992481203008\n",
      "Epoch 85:\t train loss : 0.5613675567342993; train accuracy : 0.9904330033733341; \n",
      " validation loss : 0.6848376762893177; validation accuracy : 0.8646616541353384\n",
      "Epoch 86:\t train loss : 0.5618169440693543; train accuracy : 0.9897140961123707; \n",
      " validation loss : 0.6529666693302769; validation accuracy : 0.8947368421052632\n",
      "Epoch 87:\t train loss : 0.5608882114701155; train accuracy : 0.9907095061660123; \n",
      " validation loss : 0.6508116388905615; validation accuracy : 0.9022556390977443\n",
      "Epoch 88:\t train loss : 0.5639037754202819; train accuracy : 0.9873776475142398; \n",
      " validation loss : 0.6682293326480979; validation accuracy : 0.8796992481203008\n",
      "Epoch 89:\t train loss : 0.6272236739685644; train accuracy : 0.9223303655366919; \n",
      " validation loss : 0.6953057968603084; validation accuracy : 0.8571428571428571\n",
      "Epoch 90:\t train loss : 0.6097269964595029; train accuracy : 0.940344522479677; \n",
      " validation loss : 0.7102363850965104; validation accuracy : 0.8421052631578947\n",
      "Epoch 91:\t train loss : 0.6000703122041481; train accuracy : 0.9506719017862081; \n",
      " validation loss : 0.6763389698183354; validation accuracy : 0.8721804511278195\n",
      "Epoch 92:\t train loss : 0.5749518053481425; train accuracy : 0.9760686832937012; \n",
      " validation loss : 0.6664158122016131; validation accuracy : 0.8796992481203008\n",
      "Epoch 93:\t train loss : 0.577555137593366; train accuracy : 0.9738428358126417; \n",
      " validation loss : 0.6653004305045297; validation accuracy : 0.8872180451127819\n",
      "Epoch 94:\t train loss : 0.5690056465993291; train accuracy : 0.9819305424984792; \n",
      " validation loss : 0.6640337748891031; validation accuracy : 0.8872180451127819\n",
      "Epoch 95:\t train loss : 0.5729209491277272; train accuracy : 0.9782115799369574; \n",
      " validation loss : 0.6779700150301472; validation accuracy : 0.8646616541353384\n",
      "Epoch 96:\t train loss : 0.5660893582310389; train accuracy : 0.9852762262898855; \n",
      " validation loss : 0.6922530493483804; validation accuracy : 0.849624060150376\n",
      "Epoch 97:\t train loss : 0.5626978091844234; train accuracy : 0.9885389592434883; \n",
      " validation loss : 0.6755780131465662; validation accuracy : 0.8721804511278195\n",
      "Epoch 98:\t train loss : 0.5642450349321554; train accuracy : 0.9871840955593651; \n",
      " validation loss : 0.6641031707533348; validation accuracy : 0.8872180451127819\n",
      "Epoch 99:\t train loss : 0.5610054164632112; train accuracy : 0.9905297793507715; \n",
      " validation loss : 0.6694419244954426; validation accuracy : 0.8796992481203008\n",
      "Epoch 100:\t train loss : 0.5589050594020214; train accuracy : 0.9923823480617154; \n",
      " validation loss : 0.677879478461634; validation accuracy : 0.8721804511278195\n",
      "Epoch 101:\t train loss : 0.561500256901127; train accuracy : 0.9900182491843168; \n",
      " validation loss : 0.6507719670230628; validation accuracy : 0.9022556390977443\n",
      "Epoch 102:\t train loss : 0.5677992479347582; train accuracy : 0.9832992313222364; \n",
      " validation loss : 0.6795736914015258; validation accuracy : 0.8721804511278195\n",
      "Epoch 103:\t train loss : 0.5620613404984962; train accuracy : 0.989202565945916; \n",
      " validation loss : 0.659447993237286; validation accuracy : 0.8872180451127819\n",
      "Epoch 104:\t train loss : 0.5588168489643064; train accuracy : 0.992589725156224; \n",
      " validation loss : 0.6344294109621116; validation accuracy : 0.9172932330827067\n",
      "Epoch 105:\t train loss : 0.5591720197714853; train accuracy : 0.992147320687939; \n",
      " validation loss : 0.6634818478155556; validation accuracy : 0.8872180451127819\n",
      "Epoch 106:\t train loss : 0.5620163034942209; train accuracy : 0.9891887408062822; \n",
      " validation loss : 0.6392850311417447; validation accuracy : 0.9097744360902256\n",
      "Epoch 107:\t train loss : 0.5599012739968876; train accuracy : 0.9917187413592877; \n",
      " validation loss : 0.6907439424024019; validation accuracy : 0.8571428571428571\n",
      "Epoch 108:\t train loss : 0.5613513629139041; train accuracy : 0.9900320743239507; \n",
      " validation loss : 0.6621400972666404; validation accuracy : 0.8872180451127819\n",
      "Epoch 109:\t train loss : 0.5585848921245913; train accuracy : 0.9927003262732953; \n",
      " validation loss : 0.6745301078763021; validation accuracy : 0.8721804511278195\n",
      "Epoch 110:\t train loss : 0.5577296122593549; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.6712865854854674; validation accuracy : 0.8796992481203008\n",
      "Epoch 111:\t train loss : 0.5658047789103866; train accuracy : 0.9854144776862246; \n",
      " validation loss : 0.679316566768973; validation accuracy : 0.8721804511278195\n",
      "Epoch 112:\t train loss : 0.5593497118236337; train accuracy : 0.9920367195708677; \n",
      " validation loss : 0.6645706095742503; validation accuracy : 0.8872180451127819\n",
      "Epoch 113:\t train loss : 0.5611078542526047; train accuracy : 0.9900597246032184; \n",
      " validation loss : 0.6477751271476098; validation accuracy : 0.9022556390977443\n",
      "Epoch 114:\t train loss : 0.5589783223853719; train accuracy : 0.9923685229220816; \n",
      " validation loss : 0.6818438006955424; validation accuracy : 0.8721804511278195\n",
      "Epoch 115:\t train loss : 0.557940369694304; train accuracy : 0.9934468838135265; \n",
      " validation loss : 0.6267066514623783; validation accuracy : 0.924812030075188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116:\t train loss : 0.5563089434109427; train accuracy : 0.9951473759884975; \n",
      " validation loss : 0.6515090947893066; validation accuracy : 0.9022556390977443\n",
      "Epoch 117:\t train loss : 0.5567709473496216; train accuracy : 0.9945667201238733; \n",
      " validation loss : 0.6678303802775433; validation accuracy : 0.8796992481203008\n",
      "Epoch 118:\t train loss : 0.5581145853693923; train accuracy : 0.9932533318586517; \n",
      " validation loss : 0.6416095673655847; validation accuracy : 0.9097744360902256\n",
      "Epoch 119:\t train loss : 0.5584789032744032; train accuracy : 0.9928938782281701; \n",
      " validation loss : 0.6689255492386588; validation accuracy : 0.8796992481203008\n",
      "Epoch 120:\t train loss : 0.5750683841076352; train accuracy : 0.9757645302217552; \n",
      " validation loss : 0.6755058857793267; validation accuracy : 0.8721804511278195\n",
      "Epoch 121:\t train loss : 0.5910233775522572; train accuracy : 0.9597826688049549; \n",
      " validation loss : 0.6918380703803373; validation accuracy : 0.8571428571428571\n",
      "Epoch 122:\t train loss : 0.5846752616907193; train accuracy : 0.966252834153625; \n",
      " validation loss : 0.646360499500951; validation accuracy : 0.9022556390977443\n",
      "Epoch 123:\t train loss : 0.5806766670982354; train accuracy : 0.9702344743681911; \n",
      " validation loss : 0.6574138549245513; validation accuracy : 0.8947368421052632\n",
      "Epoch 124:\t train loss : 0.5665036489810302; train accuracy : 0.9846955704252613; \n",
      " validation loss : 0.6731043062069753; validation accuracy : 0.8796992481203008\n",
      "Epoch 125:\t train loss : 0.5705180978992761; train accuracy : 0.9806171542332578; \n",
      " validation loss : 0.6742598981768928; validation accuracy : 0.8721804511278195\n",
      "Epoch 126:\t train loss : 0.5621856253948809; train accuracy : 0.9890919648288448; \n",
      " validation loss : 0.6551531757082361; validation accuracy : 0.8947368421052632\n",
      "Epoch 127:\t train loss : 0.556965295037726; train accuracy : 0.9943178676104628; \n",
      " validation loss : 0.6744591558621492; validation accuracy : 0.8796992481203008\n",
      "Epoch 128:\t train loss : 0.5567394812297976; train accuracy : 0.9946773212409445; \n",
      " validation loss : 0.6576021570113173; validation accuracy : 0.8947368421052632\n",
      "Epoch 129:\t train loss : 0.5572182783762344; train accuracy : 0.9942349167726594; \n",
      " validation loss : 0.6558422388182837; validation accuracy : 0.8947368421052632\n",
      "Epoch 130:\t train loss : 0.5566037803782588; train accuracy : 0.994774097218382; \n",
      " validation loss : 0.6753448392284349; validation accuracy : 0.8721804511278195\n",
      "Epoch 131:\t train loss : 0.5570675552831055; train accuracy : 0.9943731681689985; \n",
      " validation loss : 0.6352109836424112; validation accuracy : 0.9172932330827067\n",
      "Epoch 132:\t train loss : 0.5564373056432979; train accuracy : 0.9948708731958192; \n",
      " validation loss : 0.6253847221792466; validation accuracy : 0.924812030075188\n",
      "Epoch 133:\t train loss : 0.5556581465936764; train accuracy : 0.9956312558756844; \n",
      " validation loss : 0.6536029141211364; validation accuracy : 0.9022556390977443\n",
      "Epoch 134:\t train loss : 0.5556841364906097; train accuracy : 0.9957695072720234; \n",
      " validation loss : 0.662693681588509; validation accuracy : 0.8872180451127819\n",
      "Epoch 135:\t train loss : 0.556880482996812; train accuracy : 0.9944837692860697; \n",
      " validation loss : 0.6479738320256387; validation accuracy : 0.9022556390977443\n",
      "Epoch 136:\t train loss : 0.5739029809005777; train accuracy : 0.977340596140021; \n",
      " validation loss : 0.6661638421576574; validation accuracy : 0.8796992481203008\n",
      "Epoch 137:\t train loss : 0.5585869928312959; train accuracy : 0.9927418016921971; \n",
      " validation loss : 0.6796996643805405; validation accuracy : 0.8721804511278195\n",
      "Epoch 138:\t train loss : 0.5564026122025229; train accuracy : 0.9950367748714262; \n",
      " validation loss : 0.6658530413339355; validation accuracy : 0.8796992481203008\n",
      "Epoch 139:\t train loss : 0.5562425610216452; train accuracy : 0.995064425150694; \n",
      " validation loss : 0.6780449168014185; validation accuracy : 0.8721804511278195\n",
      "Epoch 140:\t train loss : 0.5550429459456252; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.6703719141651765; validation accuracy : 0.8796992481203008\n",
      "Epoch 141:\t train loss : 0.5732325792830263; train accuracy : 0.9776862246308687; \n",
      " validation loss : 0.6493319280638059; validation accuracy : 0.9022556390977443\n",
      "Epoch 142:\t train loss : 0.559435490898439; train accuracy : 0.9919261184537964; \n",
      " validation loss : 0.6508619001279891; validation accuracy : 0.9022556390977443\n",
      "Epoch 143:\t train loss : 0.5551794482975053; train accuracy : 0.9961013106232373; \n",
      " validation loss : 0.6836649673431833; validation accuracy : 0.8646616541353384\n",
      "Epoch 144:\t train loss : 0.5684533256923124; train accuracy : 0.9828430017143173; \n",
      " validation loss : 0.6413700142641653; validation accuracy : 0.9097744360902256\n",
      "Epoch 145:\t train loss : 0.5636154920033004; train accuracy : 0.9874744234916772; \n",
      " validation loss : 0.6542840030797679; validation accuracy : 0.8947368421052632\n",
      "Epoch 146:\t train loss : 0.5567710269068019; train accuracy : 0.994608195542775; \n",
      " validation loss : 0.6505927702987675; validation accuracy : 0.9022556390977443\n",
      "Epoch 147:\t train loss : 0.5790233389339144; train accuracy : 0.9716031631919483; \n",
      " validation loss : 0.7015392014929043; validation accuracy : 0.8421052631578947\n",
      "Epoch 148:\t train loss : 0.6277068596499538; train accuracy : 0.9224409666537632; \n",
      " validation loss : 0.6744372733989209; validation accuracy : 0.8796992481203008\n",
      "Epoch 149:\t train loss : 0.5906593598865209; train accuracy : 0.959450865453741; \n",
      " validation loss : 0.6537856907287191; validation accuracy : 0.9022556390977443\n",
      "Epoch 150:\t train loss : 0.5858650736401595; train accuracy : 0.9651329978432782; \n",
      " validation loss : 0.6767794092051075; validation accuracy : 0.8721804511278195\n",
      "Epoch 151:\t train loss : 0.5915957145685191; train accuracy : 0.9585660565171709; \n",
      " validation loss : 0.6491201304993833; validation accuracy : 0.9022556390977443\n",
      "Epoch 152:\t train loss : 0.5730387156521572; train accuracy : 0.9779903777028148; \n",
      " validation loss : 0.648330190450139; validation accuracy : 0.9097744360902256\n",
      "Epoch 153:\t train loss : 0.5687096491954542; train accuracy : 0.9824835480838356; \n",
      " validation loss : 0.6303390107978316; validation accuracy : 0.9172932330827067\n",
      "Epoch 154:\t train loss : 0.565494083225422; train accuracy : 0.9855250788032959; \n",
      " validation loss : 0.6816141813212198; validation accuracy : 0.8646616541353384\n",
      "Epoch 155:\t train loss : 0.5658980118036343; train accuracy : 0.9853868274069568; \n",
      " validation loss : 0.6787249319921443; validation accuracy : 0.8721804511278195\n",
      "Epoch 156:\t train loss : 0.5631496816832005; train accuracy : 0.9881795056130067; \n",
      " validation loss : 0.6418126182256055; validation accuracy : 0.9022556390977443\n",
      "Epoch 157:\t train loss : 0.5639711858935775; train accuracy : 0.9870734944422939; \n",
      " validation loss : 0.6644607037233459; validation accuracy : 0.8872180451127819\n",
      "Epoch 158:\t train loss : 0.5589687614964376; train accuracy : 0.9922579218050103; \n",
      " validation loss : 0.6287767971893636; validation accuracy : 0.924812030075188\n",
      "Epoch 159:\t train loss : 0.5609843264161979; train accuracy : 0.9903915279544323; \n",
      " validation loss : 0.6568292008294232; validation accuracy : 0.8947368421052632\n",
      "Epoch 160:\t train loss : 0.5615917694215314; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.6673925517394669; validation accuracy : 0.8872180451127819\n",
      "Epoch 161:\t train loss : 0.5588709241869598; train accuracy : 0.9925067743184206; \n",
      " validation loss : 0.6346832889174887; validation accuracy : 0.9172932330827067\n",
      "Epoch 162:\t train loss : 0.559830023272354; train accuracy : 0.9915251894044129; \n",
      " validation loss : 0.6511026103114184; validation accuracy : 0.8947368421052632\n",
      "Epoch 163:\t train loss : 0.558889445585562; train accuracy : 0.9922993972239119; \n",
      " validation loss : 0.6499449073580347; validation accuracy : 0.9022556390977443\n",
      "Epoch 164:\t train loss : 0.5599949493652988; train accuracy : 0.9913454625891721; \n",
      " validation loss : 0.6348241595694101; validation accuracy : 0.9172932330827067\n",
      "Epoch 165:\t train loss : 0.5586881768023476; train accuracy : 0.9926726759940275; \n",
      " validation loss : 0.6752007641408067; validation accuracy : 0.8721804511278195\n",
      "Epoch 166:\t train loss : 0.5554280482995186; train accuracy : 0.9960321849250677; \n",
      " validation loss : 0.6696799962233493; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167:\t train loss : 0.5546279065678036; train accuracy : 0.9968478681634685; \n",
      " validation loss : 0.6392721308126482; validation accuracy : 0.9097744360902256\n",
      "Epoch 168:\t train loss : 0.5556770977194324; train accuracy : 0.9957280318531218; \n",
      " validation loss : 0.6583564180684304; validation accuracy : 0.8947368421052632\n",
      "Epoch 169:\t train loss : 0.5546027766150408; train accuracy : 0.9968063927445667; \n",
      " validation loss : 0.6625999316503849; validation accuracy : 0.8872180451127819\n",
      "Epoch 170:\t train loss : 0.5573362335391613; train accuracy : 0.9940966653763202; \n",
      " validation loss : 0.6717598065612075; validation accuracy : 0.8796992481203008\n",
      "Epoch 171:\t train loss : 0.5564210237966406; train accuracy : 0.9949261737543549; \n",
      " validation loss : 0.6346513270711835; validation accuracy : 0.9172932330827067\n",
      "Epoch 172:\t train loss : 0.5552259523095692; train accuracy : 0.996142786042139; \n",
      " validation loss : 0.6409715078360166; validation accuracy : 0.9097744360902256\n",
      "Epoch 173:\t train loss : 0.5655307119615558; train accuracy : 0.985663330199635; \n",
      " validation loss : 0.65652903772424; validation accuracy : 0.8947368421052632\n",
      "Epoch 174:\t train loss : 0.5564035804051999; train accuracy : 0.9949814743128905; \n",
      " validation loss : 0.6956969720337294; validation accuracy : 0.849624060150376\n",
      "Epoch 175:\t train loss : 0.5558122988100213; train accuracy : 0.9955621301775148; \n",
      " validation loss : 0.6633717998142066; validation accuracy : 0.8872180451127819\n",
      "Epoch 176:\t train loss : 0.5714629900458821; train accuracy : 0.9794973179229111; \n",
      " validation loss : 0.6518986599628028; validation accuracy : 0.9022556390977443\n",
      "Epoch 177:\t train loss : 0.5674421568369115; train accuracy : 0.9834098324393077; \n",
      " validation loss : 0.6832791013201731; validation accuracy : 0.8721804511278195\n",
      "Epoch 178:\t train loss : 0.5667713699829771; train accuracy : 0.9843775922136814; \n",
      " validation loss : 0.6323423012897981; validation accuracy : 0.9172932330827067\n",
      "Epoch 179:\t train loss : 0.5602696140158137; train accuracy : 0.9909307084001548; \n",
      " validation loss : 0.6371714075521104; validation accuracy : 0.9097744360902256\n",
      "Epoch 180:\t train loss : 0.5557838129728857; train accuracy : 0.9956589061549521; \n",
      " validation loss : 0.664385434749647; validation accuracy : 0.8872180451127819\n",
      "Epoch 181:\t train loss : 0.5562420484407204; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6783976743622215; validation accuracy : 0.8721804511278195\n",
      "Epoch 182:\t train loss : 0.5550855506227212; train accuracy : 0.9963639882762816; \n",
      " validation loss : 0.6717463944388112; validation accuracy : 0.8796992481203008\n",
      "Early stopping at epoch 182\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5564373056432979; Train accuracy : 0.9948708731958192; \n",
      " Validation loss : 0.6253847221792466; Validation accuracy : 0.924812030075188\n",
      "------------------------------ Let's train model 15 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9072912196037942; train accuracy : 0.6270759627355164; \n",
      " validation loss : 0.841323421985902; validation accuracy : 0.706766917293233\n",
      "Epoch 2:\t train loss : 0.7722262256412249; train accuracy : 0.7737013473104372; \n",
      " validation loss : 0.7850917973411919; validation accuracy : 0.7593984962406015\n",
      "Epoch 3:\t train loss : 0.7364612857290782; train accuracy : 0.8103831519430054; \n",
      " validation loss : 0.7721258343707132; validation accuracy : 0.7593984962406015\n",
      "Epoch 4:\t train loss : 0.716663304152328; train accuracy : 0.8315625914651006; \n",
      " validation loss : 0.7439421954634069; validation accuracy : 0.7969924812030075\n",
      "Epoch 5:\t train loss : 0.6882915394773867; train accuracy : 0.8611349023405624; \n",
      " validation loss : 0.7394840302175144; validation accuracy : 0.8045112781954887\n",
      "Epoch 6:\t train loss : 0.6650584345535665; train accuracy : 0.8844987139248155; \n",
      " validation loss : 0.7163538970752437; validation accuracy : 0.8345864661654135\n",
      "Epoch 7:\t train loss : 0.6549492500278188; train accuracy : 0.8952236502954534; \n",
      " validation loss : 0.6908833599807451; validation accuracy : 0.8646616541353384\n",
      "Epoch 8:\t train loss : 0.6355324369701124; train accuracy : 0.9151871519268199; \n",
      " validation loss : 0.7461472397580078; validation accuracy : 0.7969924812030075\n",
      "Epoch 9:\t train loss : 0.6209464860342617; train accuracy : 0.9306638899491909; \n",
      " validation loss : 0.6826712069393416; validation accuracy : 0.8646616541353384\n",
      "Epoch 10:\t train loss : 0.6136769660783098; train accuracy : 0.9383574115561982; \n",
      " validation loss : 0.7010280282395283; validation accuracy : 0.8421052631578947\n",
      "Epoch 11:\t train loss : 0.6056217605772793; train accuracy : 0.9450386631831811; \n",
      " validation loss : 0.6880969953321487; validation accuracy : 0.8571428571428571\n",
      "Epoch 12:\t train loss : 0.5989426065566507; train accuracy : 0.9528461578925361; \n",
      " validation loss : 0.6890075535100068; validation accuracy : 0.849624060150376\n",
      "Epoch 13:\t train loss : 0.5908061914792297; train accuracy : 0.9611068474230614; \n",
      " validation loss : 0.6760111760922264; validation accuracy : 0.8721804511278195\n",
      "Epoch 14:\t train loss : 0.5813496817179155; train accuracy : 0.9704836640801292; \n",
      " validation loss : 0.665201912351761; validation accuracy : 0.8796992481203008\n",
      "Epoch 15:\t train loss : 0.5802665641468465; train accuracy : 0.970936184504244; \n",
      " validation loss : 0.6582701183584098; validation accuracy : 0.8872180451127819\n",
      "Epoch 16:\t train loss : 0.5784159504253447; train accuracy : 0.9734489879323391; \n",
      " validation loss : 0.6595235983084954; validation accuracy : 0.8872180451127819\n",
      "Epoch 17:\t train loss : 0.5732182508577836; train accuracy : 0.9783188090687521; \n",
      " validation loss : 0.6535486772384003; validation accuracy : 0.8947368421052632\n",
      "Epoch 18:\t train loss : 0.5725452924751306; train accuracy : 0.9788407923895641; \n",
      " validation loss : 0.695927056097272; validation accuracy : 0.8571428571428571\n",
      "Epoch 19:\t train loss : 0.5692358595812343; train accuracy : 0.9823523778565774; \n",
      " validation loss : 0.6932610156885952; validation accuracy : 0.849624060150376\n",
      "Epoch 20:\t train loss : 0.5684958312260078; train accuracy : 0.9829020114566572; \n",
      " validation loss : 0.6619034910616092; validation accuracy : 0.8947368421052632\n",
      "Epoch 21:\t train loss : 0.5695327532322719; train accuracy : 0.9820725030786226; \n",
      " validation loss : 0.6424653252093554; validation accuracy : 0.9022556390977443\n",
      "Epoch 22:\t train loss : 0.5814790961327475; train accuracy : 0.969432953467952; \n",
      " validation loss : 0.7022142944280823; validation accuracy : 0.849624060150376\n",
      "Epoch 23:\t train loss : 0.5841732892908361; train accuracy : 0.9668992437311422; \n",
      " validation loss : 0.6591134901147951; validation accuracy : 0.9022556390977443\n",
      "Epoch 24:\t train loss : 0.5709426732921944; train accuracy : 0.9802853508820439; \n",
      " validation loss : 0.6563412674434835; validation accuracy : 0.8872180451127819\n",
      "Epoch 25:\t train loss : 0.5665460148368204; train accuracy : 0.9848442749759577; \n",
      " validation loss : 0.6539348436823089; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5632852201459584; train accuracy : 0.9884664615600423; \n",
      " validation loss : 0.6409216010192699; validation accuracy : 0.9097744360902256\n",
      "Epoch 27:\t train loss : 0.56549931651701; train accuracy : 0.9858396850295993; \n",
      " validation loss : 0.6611720710345508; validation accuracy : 0.8796992481203008\n",
      "Epoch 28:\t train loss : 0.5659267632377298; train accuracy : 0.9853730022673229; \n",
      " validation loss : 0.656727045042815; validation accuracy : 0.8872180451127819\n",
      "Epoch 29:\t train loss : 0.5633440090658777; train accuracy : 0.9882108650760787; \n",
      " validation loss : 0.6647855887466725; validation accuracy : 0.8872180451127819\n",
      "Epoch 30:\t train loss : 0.5664473587483331; train accuracy : 0.9847856024321455; \n",
      " validation loss : 0.649434864446775; validation accuracy : 0.9022556390977443\n",
      "Epoch 31:\t train loss : 0.5745468903604447; train accuracy : 0.9769673173699054; \n",
      " validation loss : 0.6657226431381008; validation accuracy : 0.8796992481203008\n",
      "Epoch 32:\t train loss : 0.5630045499852878; train accuracy : 0.9884664615600423; \n",
      " validation loss : 0.6294779214756357; validation accuracy : 0.924812030075188\n",
      "Epoch 33:\t train loss : 0.5620255235808816; train accuracy : 0.9894308493491394; \n",
      " validation loss : 0.6478396572130318; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:\t train loss : 0.564555425109249; train accuracy : 0.9871392481551868; \n",
      " validation loss : 0.6451307200472968; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.5599570934633052; train accuracy : 0.9913973911624312; \n",
      " validation loss : 0.6710137327992922; validation accuracy : 0.8796992481203008\n",
      "Epoch 36:\t train loss : 0.5627095231825179; train accuracy : 0.9888292871758004; \n",
      " validation loss : 0.6238992584564509; validation accuracy : 0.924812030075188\n",
      "Epoch 37:\t train loss : 0.5592843321711768; train accuracy : 0.9920643698501355; \n",
      " validation loss : 0.6454162233094067; validation accuracy : 0.9022556390977443\n",
      "Epoch 38:\t train loss : 0.5611340890053517; train accuracy : 0.9901841508599237; \n",
      " validation loss : 0.638500187446247; validation accuracy : 0.9172932330827067\n",
      "Epoch 39:\t train loss : 0.5628246012362028; train accuracy : 0.9886566415296404; \n",
      " validation loss : 0.6400137103249764; validation accuracy : 0.9172932330827067\n",
      "Epoch 40:\t train loss : 0.5604614642407361; train accuracy : 0.990816735297807; \n",
      " validation loss : 0.646267770879969; validation accuracy : 0.9022556390977443\n",
      "Epoch 41:\t train loss : 0.5659614647998152; train accuracy : 0.9852866794442429; \n",
      " validation loss : 0.6540113038764191; validation accuracy : 0.8947368421052632\n",
      "Epoch 42:\t train loss : 0.5692026083002351; train accuracy : 0.9820482247846313; \n",
      " validation loss : 0.6548827036034629; validation accuracy : 0.8947368421052632\n",
      "Epoch 43:\t train loss : 0.5728021274296927; train accuracy : 0.9783498313332964; \n",
      " validation loss : 0.6469518003210366; validation accuracy : 0.9022556390977443\n",
      "Epoch 44:\t train loss : 0.5606331584815146; train accuracy : 0.990782341047986; \n",
      " validation loss : 0.6636490462360508; validation accuracy : 0.8796992481203008\n",
      "Epoch 45:\t train loss : 0.5615497097864806; train accuracy : 0.9899285543759602; \n",
      " validation loss : 0.6201439846745812; validation accuracy : 0.924812030075188\n",
      "Epoch 46:\t train loss : 0.5609541815994379; train accuracy : 0.9904296313880575; \n",
      " validation loss : 0.614065058971337; validation accuracy : 0.9398496240601504\n",
      "Epoch 47:\t train loss : 0.5585220064320304; train accuracy : 0.9930044793452414; \n",
      " validation loss : 0.6169497178691363; validation accuracy : 0.9323308270676691\n",
      "Epoch 48:\t train loss : 0.5576458603050819; train accuracy : 0.9938306157379995; \n",
      " validation loss : 0.6155708155660489; validation accuracy : 0.9323308270676691\n",
      "Epoch 49:\t train loss : 0.5569711970713808; train accuracy : 0.9944389218818915; \n",
      " validation loss : 0.629783601536465; validation accuracy : 0.9172932330827067\n",
      "Epoch 50:\t train loss : 0.558461549507111; train accuracy : 0.9929458068014292; \n",
      " validation loss : 0.663532714274072; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5569991911417552; train accuracy : 0.9943869933086324; \n",
      " validation loss : 0.6282212078536449; validation accuracy : 0.9172932330827067\n",
      "Epoch 52:\t train loss : 0.5631608932087019; train accuracy : 0.9881832147968109; \n",
      " validation loss : 0.64123553263172; validation accuracy : 0.9097744360902256\n",
      "Epoch 53:\t train loss : 0.5596617001297921; train accuracy : 0.9918121453514486; \n",
      " validation loss : 0.6610366205669779; validation accuracy : 0.8872180451127819\n",
      "Epoch 54:\t train loss : 0.5587225412858221; train accuracy : 0.9925344245976884; \n",
      " validation loss : 0.6584171705404985; validation accuracy : 0.8947368421052632\n",
      "Epoch 55:\t train loss : 0.5562640478815166; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6408516118136882; validation accuracy : 0.9097744360902256\n",
      "Epoch 56:\t train loss : 0.5580437623823384; train accuracy : 0.9933329107111787; \n",
      " validation loss : 0.6210777675457061; validation accuracy : 0.9323308270676691\n",
      "Epoch 57:\t train loss : 0.5649401446675756; train accuracy : 0.9861202342046094; \n",
      " validation loss : 0.8011443989745949; validation accuracy : 0.7518796992481203\n",
      "Epoch 58:\t train loss : 0.6486975561078865; train accuracy : 0.9009472581038922; \n",
      " validation loss : 0.6710507556500588; validation accuracy : 0.8796992481203008\n",
      "Epoch 59:\t train loss : 0.5876985601707813; train accuracy : 0.9630801332069063; \n",
      " validation loss : 0.700532679081684; validation accuracy : 0.849624060150376\n",
      "Epoch 60:\t train loss : 0.5779247759299324; train accuracy : 0.9729202606409739; \n",
      " validation loss : 0.6625548217292032; validation accuracy : 0.8796992481203008\n",
      "Epoch 61:\t train loss : 0.5677356635957362; train accuracy : 0.9831609799258972; \n",
      " validation loss : 0.6598169118109204; validation accuracy : 0.8872180451127819\n",
      "Epoch 62:\t train loss : 0.5598176872237952; train accuracy : 0.9915632928380381; \n",
      " validation loss : 0.6351976309430566; validation accuracy : 0.9172932330827067\n",
      "Epoch 63:\t train loss : 0.5579440201959737; train accuracy : 0.9933915832549909; \n",
      " validation loss : 0.6119384215158776; validation accuracy : 0.9398496240601504\n",
      "Epoch 64:\t train loss : 0.5556366858531677; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6445793155551627; validation accuracy : 0.9097744360902256\n",
      "Epoch 65:\t train loss : 0.5568531710944813; train accuracy : 0.9944908504551505; \n",
      " validation loss : 0.6273161237362699; validation accuracy : 0.924812030075188\n",
      "Epoch 66:\t train loss : 0.5588784812633553; train accuracy : 0.9924238234806172; \n",
      " validation loss : 0.6566888736055259; validation accuracy : 0.8947368421052632\n",
      "Epoch 67:\t train loss : 0.5582904367317153; train accuracy : 0.9929491787867057; \n",
      " validation loss : 0.6472198984462019; validation accuracy : 0.9022556390977443\n",
      "Epoch 68:\t train loss : 0.5561929216908331; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.6370520026964475; validation accuracy : 0.9097744360902256\n",
      "Epoch 69:\t train loss : 0.5622732743321903; train accuracy : 0.9890160951601221; \n",
      " validation loss : 0.6561976141273065; validation accuracy : 0.8872180451127819\n",
      "Epoch 70:\t train loss : 0.5567055999397178; train accuracy : 0.9945771732782306; \n",
      " validation loss : 0.6320184675099623; validation accuracy : 0.9172932330827067\n",
      "Epoch 71:\t train loss : 0.5546102176337957; train accuracy : 0.9968755184427363; \n",
      " validation loss : 0.6251099156122072; validation accuracy : 0.924812030075188\n",
      "Epoch 72:\t train loss : 0.5606118272565874; train accuracy : 0.9905678827843966; \n",
      " validation loss : 0.7030111269553815; validation accuracy : 0.8421052631578947\n",
      "Epoch 73:\t train loss : 0.5608858245035409; train accuracy : 0.9904330033733341; \n",
      " validation loss : 0.6413296771350436; validation accuracy : 0.9097744360902256\n",
      "Epoch 74:\t train loss : 0.5574842137787897; train accuracy : 0.9937166426356516; \n",
      " validation loss : 0.663591695980221; validation accuracy : 0.8872180451127819\n",
      "Epoch 75:\t train loss : 0.556729882285088; train accuracy : 0.9947430749538375; \n",
      " validation loss : 0.6317628246250219; validation accuracy : 0.924812030075188\n",
      "Epoch 76:\t train loss : 0.5568995042915115; train accuracy : 0.9944355498966149; \n",
      " validation loss : 0.6287171462266384; validation accuracy : 0.924812030075188\n",
      "Epoch 77:\t train loss : 0.555787379328381; train accuracy : 0.99568655643422; \n",
      " validation loss : 0.6491441232093826; validation accuracy : 0.9022556390977443\n",
      "Epoch 78:\t train loss : 0.5567103853021725; train accuracy : 0.9946358458220428; \n",
      " validation loss : 0.6704957432664456; validation accuracy : 0.8796992481203008\n",
      "Epoch 79:\t train loss : 0.5559482082722254; train accuracy : 0.9954275879649799; \n",
      " validation loss : 0.6375419400776873; validation accuracy : 0.9097744360902256\n",
      "Epoch 80:\t train loss : 0.5568651803734722; train accuracy : 0.9944112716026237; \n",
      " validation loss : 0.6426435652484551; validation accuracy : 0.9097744360902256\n",
      "Epoch 81:\t train loss : 0.556662126006787; train accuracy : 0.9946877743953019; \n",
      " validation loss : 0.6619347259293172; validation accuracy : 0.8872180451127819\n",
      "Epoch 82:\t train loss : 0.555539612411981; train accuracy : 0.995824807830559; \n",
      " validation loss : 0.6152008570563555; validation accuracy : 0.9398496240601504\n",
      "Epoch 83:\t train loss : 0.5550287973760012; train accuracy : 0.996460764253719; \n",
      " validation loss : 0.6143968693333266; validation accuracy : 0.9398496240601504\n",
      "Epoch 84:\t train loss : 0.5555235023191281; train accuracy : 0.9958801083890947; \n",
      " validation loss : 0.6000886188885655; validation accuracy : 0.9473684210526315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85:\t train loss : 0.5569642575877521; train accuracy : 0.9941900693684811; \n",
      " validation loss : 0.6241953709195778; validation accuracy : 0.924812030075188\n",
      "Epoch 86:\t train loss : 0.556035835984143; train accuracy : 0.9953513810977296; \n",
      " validation loss : 0.6675832905241208; validation accuracy : 0.8872180451127819\n",
      "Epoch 87:\t train loss : 0.5646328248869519; train accuracy : 0.9865343139965713; \n",
      " validation loss : 0.6284577947991794; validation accuracy : 0.924812030075188\n",
      "Epoch 88:\t train loss : 0.5588762372471722; train accuracy : 0.9925863531709475; \n",
      " validation loss : 0.6523991289825244; validation accuracy : 0.8947368421052632\n",
      "Epoch 89:\t train loss : 0.5628471205914668; train accuracy : 0.9881312862235518; \n",
      " validation loss : 0.6376647483356241; validation accuracy : 0.9097744360902256\n",
      "Epoch 90:\t train loss : 0.5580682946652419; train accuracy : 0.9931670090355718; \n",
      " validation loss : 0.6691136686508663; validation accuracy : 0.8796992481203008\n",
      "Epoch 91:\t train loss : 0.5591684144048406; train accuracy : 0.9922026212464746; \n",
      " validation loss : 0.6274043635957262; validation accuracy : 0.924812030075188\n",
      "Epoch 92:\t train loss : 0.5577931324801602; train accuracy : 0.993363932975723; \n",
      " validation loss : 0.6365053470515536; validation accuracy : 0.9172932330827067\n",
      "Epoch 93:\t train loss : 0.563823476989966; train accuracy : 0.9874123789625885; \n",
      " validation loss : 0.630916797490146; validation accuracy : 0.924812030075188\n",
      "Epoch 94:\t train loss : 0.5614425457313622; train accuracy : 0.989738374406362; \n",
      " validation loss : 0.652586943119538; validation accuracy : 0.8947368421052632\n",
      "Epoch 95:\t train loss : 0.5600061667832272; train accuracy : 0.9913420906038956; \n",
      " validation loss : 0.6542997233216105; validation accuracy : 0.8947368421052632\n",
      "Epoch 96:\t train loss : 0.5915676174008501; train accuracy : 0.9591746998595906; \n",
      " validation loss : 0.6639493399079464; validation accuracy : 0.8796992481203008\n",
      "Epoch 97:\t train loss : 0.5726589230420279; train accuracy : 0.9782392302162252; \n",
      " validation loss : 0.6418981338939689; validation accuracy : 0.9097744360902256\n",
      "Epoch 98:\t train loss : 0.5635698068732993; train accuracy : 0.9876855097699901; \n",
      " validation loss : 0.6387850201324353; validation accuracy : 0.9172932330827067\n",
      "Epoch 99:\t train loss : 0.5614878575517221; train accuracy : 0.9898732538174245; \n",
      " validation loss : 0.6631983758840699; validation accuracy : 0.8872180451127819\n",
      "Epoch 100:\t train loss : 0.5562917633940131; train accuracy : 0.9950782502903279; \n",
      " validation loss : 0.6307534904797346; validation accuracy : 0.9172932330827067\n",
      "Epoch 101:\t train loss : 0.5560660301101088; train accuracy : 0.9952063857308373; \n",
      " validation loss : 0.6592166185226106; validation accuracy : 0.8947368421052632\n",
      "Epoch 102:\t train loss : 0.5573815765002278; train accuracy : 0.993999889398883; \n",
      " validation loss : 0.6407985335746078; validation accuracy : 0.9097744360902256\n",
      "Epoch 103:\t train loss : 0.5570256394992953; train accuracy : 0.9942696482210079; \n",
      " validation loss : 0.6667628023050843; validation accuracy : 0.8796992481203008\n",
      "Epoch 104:\t train loss : 0.555402489756053; train accuracy : 0.9959873375208894; \n",
      " validation loss : 0.6593296141450734; validation accuracy : 0.8872180451127819\n",
      "Epoch 105:\t train loss : 0.5551665604472826; train accuracy : 0.9960736603439695; \n",
      " validation loss : 0.6596298700376869; validation accuracy : 0.8872180451127819\n",
      "Epoch 106:\t train loss : 0.5765672875469724; train accuracy : 0.9744066317508832; \n",
      " validation loss : 0.6439678446674837; validation accuracy : 0.9097744360902256\n",
      "Epoch 107:\t train loss : 0.5656577408700046; train accuracy : 0.9854802313991177; \n",
      " validation loss : 0.6636730066690336; validation accuracy : 0.8796992481203008\n",
      "Epoch 108:\t train loss : 0.5579900831988864; train accuracy : 0.993225681579384; \n",
      " validation loss : 0.641133572525109; validation accuracy : 0.9097744360902256\n",
      "Epoch 109:\t train loss : 0.5551316213789755; train accuracy : 0.996288118607559; \n",
      " validation loss : 0.6667958384945718; validation accuracy : 0.8872180451127819\n",
      "Epoch 110:\t train loss : 0.5553459976691708; train accuracy : 0.9961842614610408; \n",
      " validation loss : 0.6637171645808708; validation accuracy : 0.8872180451127819\n",
      "Epoch 111:\t train loss : 0.562892052254301; train accuracy : 0.9883315821489796; \n",
      " validation loss : 0.6484534032606613; validation accuracy : 0.9022556390977443\n",
      "Epoch 112:\t train loss : 0.5575267665024206; train accuracy : 0.9937233866062047; \n",
      " validation loss : 0.6368229438975033; validation accuracy : 0.9172932330827067\n",
      "Epoch 113:\t train loss : 0.5571050246451437; train accuracy : 0.9942487419122933; \n",
      " validation loss : 0.6455727925120066; validation accuracy : 0.9022556390977443\n",
      "Epoch 114:\t train loss : 0.555967297446866; train accuracy : 0.9953824033622739; \n",
      " validation loss : 0.6577731972551201; validation accuracy : 0.8947368421052632\n",
      "Epoch 115:\t train loss : 0.5561039693873634; train accuracy : 0.9953824033622739; \n",
      " validation loss : 0.6596235757353511; validation accuracy : 0.8872180451127819\n",
      "Epoch 116:\t train loss : 0.5619464771850233; train accuracy : 0.9892649476735325; \n",
      " validation loss : 0.672221132350145; validation accuracy : 0.8796992481203008\n",
      "Epoch 117:\t train loss : 0.5641157066252844; train accuracy : 0.9870562973173834; \n",
      " validation loss : 0.6353924903811986; validation accuracy : 0.9172932330827067\n",
      "Epoch 118:\t train loss : 0.5578415730745738; train accuracy : 0.9934988123867856; \n",
      " validation loss : 0.6566962574525896; validation accuracy : 0.8947368421052632\n",
      "Epoch 119:\t train loss : 0.559382055476325; train accuracy : 0.992078532188297; \n",
      " validation loss : 0.6616119069038013; validation accuracy : 0.8872180451127819\n",
      "Epoch 120:\t train loss : 0.5642751942455739; train accuracy : 0.9869942527882947; \n",
      " validation loss : 0.6563732446286633; validation accuracy : 0.8947368421052632\n",
      "Epoch 121:\t train loss : 0.557877979622684; train accuracy : 0.9934920684162325; \n",
      " validation loss : 0.6307544442764438; validation accuracy : 0.9172932330827067\n",
      "Epoch 122:\t train loss : 0.5582774911400765; train accuracy : 0.9930011073599648; \n",
      " validation loss : 0.6464563724189294; validation accuracy : 0.9022556390977443\n",
      "Epoch 123:\t train loss : 0.5598437469426064; train accuracy : 0.9915632928380381; \n",
      " validation loss : 0.6644210448946722; validation accuracy : 0.8872180451127819\n",
      "Epoch 124:\t train loss : 0.5609895146959442; train accuracy : 0.9901807788746472; \n",
      " validation loss : 0.6519580901011884; validation accuracy : 0.8947368421052632\n",
      "Epoch 125:\t train loss : 0.5928541954510534; train accuracy : 0.9576748408085751; \n",
      " validation loss : 0.7307371221884202; validation accuracy : 0.8195488721804511\n",
      "Epoch 126:\t train loss : 0.5843255956295776; train accuracy : 0.9662808216314204; \n",
      " validation loss : 0.676958730004196; validation accuracy : 0.8721804511278195\n",
      "Epoch 127:\t train loss : 0.5677090510775173; train accuracy : 0.9834307387480223; \n",
      " validation loss : 0.6602382690057442; validation accuracy : 0.8872180451127819\n",
      "Epoch 128:\t train loss : 0.5584771217140151; train accuracy : 0.9929215285074379; \n",
      " validation loss : 0.6374039250667057; validation accuracy : 0.9097744360902256\n",
      "Epoch 129:\t train loss : 0.5554084305501206; train accuracy : 0.9959873375208894; \n",
      " validation loss : 0.6359047808572168; validation accuracy : 0.9172932330827067\n",
      "Epoch 130:\t train loss : 0.5562663637495653; train accuracy : 0.99505060001106; \n",
      " validation loss : 0.5961695140815989; validation accuracy : 0.9548872180451128\n",
      "Epoch 131:\t train loss : 0.556148633036855; train accuracy : 0.9952718022452026; \n",
      " validation loss : 0.6503020792120688; validation accuracy : 0.9022556390977443\n",
      "Epoch 132:\t train loss : 0.5543033691807947; train accuracy : 0.9970137698390754; \n",
      " validation loss : 0.6497463492807155; validation accuracy : 0.9022556390977443\n",
      "Epoch 133:\t train loss : 0.5550657261109967; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.6164520825745355; validation accuracy : 0.9323308270676691\n",
      "Epoch 134:\t train loss : 0.5549455789000621; train accuracy : 0.9964540202831659; \n",
      " validation loss : 0.6491151635042121; validation accuracy : 0.9022556390977443\n",
      "Epoch 135:\t train loss : 0.5555889845705376; train accuracy : 0.9958490861245504; \n",
      " validation loss : 0.6398989622174586; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136:\t train loss : 0.5585777982406191; train accuracy : 0.992714488611457; \n",
      " validation loss : 0.6486505695647108; validation accuracy : 0.9022556390977443\n",
      "Epoch 137:\t train loss : 0.5685724226393805; train accuracy : 0.982276170989327; \n",
      " validation loss : 0.6211767914006784; validation accuracy : 0.9323308270676691\n",
      "Epoch 138:\t train loss : 0.5562034467006016; train accuracy : 0.9951268068783105; \n",
      " validation loss : 0.6546386237196076; validation accuracy : 0.8947368421052632\n",
      "Epoch 139:\t train loss : 0.5570946938066467; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6268863756043492; validation accuracy : 0.924812030075188\n",
      "Epoch 140:\t train loss : 0.5561517126019702; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.6366186882381055; validation accuracy : 0.9172932330827067\n",
      "Epoch 141:\t train loss : 0.5551490412342529; train accuracy : 0.9962672122988442; \n",
      " validation loss : 0.6422372149297372; validation accuracy : 0.9097744360902256\n",
      "Epoch 142:\t train loss : 0.5544157851747602; train accuracy : 0.9969584692805398; \n",
      " validation loss : 0.6186889934520453; validation accuracy : 0.9323308270676691\n",
      "Epoch 143:\t train loss : 0.5555356395337882; train accuracy : 0.9959252929918007; \n",
      " validation loss : 0.6254135202434139; validation accuracy : 0.924812030075188\n",
      "Epoch 144:\t train loss : 0.5551239122982069; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.643609282601171; validation accuracy : 0.9022556390977443\n",
      "Epoch 145:\t train loss : 0.5547539692862475; train accuracy : 0.9966543162085937; \n",
      " validation loss : 0.632106939599697; validation accuracy : 0.9172932330827067\n",
      "Epoch 146:\t train loss : 0.5547885350719469; train accuracy : 0.9966266659293259; \n",
      " validation loss : 0.646582323961367; validation accuracy : 0.9022556390977443\n",
      "Epoch 147:\t train loss : 0.5536783251516584; train accuracy : 0.9976497262622352; \n",
      " validation loss : 0.6390490994796961; validation accuracy : 0.9097744360902256\n",
      "Epoch 148:\t train loss : 0.5537499832226876; train accuracy : 0.9975667754244317; \n",
      " validation loss : 0.6309600761534759; validation accuracy : 0.9172932330827067\n",
      "Epoch 149:\t train loss : 0.5547776061269742; train accuracy : 0.9966475722380406; \n",
      " validation loss : 0.6341895049270275; validation accuracy : 0.9172932330827067\n",
      "Epoch 150:\t train loss : 0.5580472681453651; train accuracy : 0.9933362826964552; \n",
      " validation loss : 0.6639860407348542; validation accuracy : 0.8872180451127819\n",
      "Epoch 151:\t train loss : 0.5612484409763737; train accuracy : 0.990087712081014; \n",
      " validation loss : 0.6718648587084233; validation accuracy : 0.8721804511278195\n",
      "Epoch 152:\t train loss : 0.5582470870121891; train accuracy : 0.9929700850954204; \n",
      " validation loss : 0.6436823302120525; validation accuracy : 0.9097744360902256\n",
      "Epoch 153:\t train loss : 0.5586680853850653; train accuracy : 0.9926140034502153; \n",
      " validation loss : 0.6373701670819208; validation accuracy : 0.9172932330827067\n",
      "Epoch 154:\t train loss : 0.5549476946328817; train accuracy : 0.9964054636951833; \n",
      " validation loss : 0.6153664925027345; validation accuracy : 0.9323308270676691\n",
      "Epoch 155:\t train loss : 0.5554857222825923; train accuracy : 0.9959354089476303; \n",
      " validation loss : 0.6490310082260721; validation accuracy : 0.9022556390977443\n",
      "Epoch 156:\t train loss : 0.5560623500811952; train accuracy : 0.9952650582746495; \n",
      " validation loss : 0.6225658475226609; validation accuracy : 0.924812030075188\n",
      "Epoch 157:\t train loss : 0.5608707922882938; train accuracy : 0.9903777028147984; \n",
      " validation loss : 0.6481295729060009; validation accuracy : 0.9022556390977443\n",
      "Epoch 158:\t train loss : 0.5608698611717668; train accuracy : 0.9903884931676834; \n",
      " validation loss : 0.6588062280466751; validation accuracy : 0.8947368421052632\n",
      "Epoch 159:\t train loss : 0.5625857718201761; train accuracy : 0.9886013409711047; \n",
      " validation loss : 0.6377100227095222; validation accuracy : 0.9097744360902256\n",
      "Epoch 160:\t train loss : 0.5545969750453428; train accuracy : 0.9968478681634685; \n",
      " validation loss : 0.6239013075118817; validation accuracy : 0.924812030075188\n",
      "Epoch 161:\t train loss : 0.5541193871105452; train accuracy : 0.9971796715146822; \n",
      " validation loss : 0.6347557751587337; validation accuracy : 0.9172932330827067\n",
      "Epoch 162:\t train loss : 0.558876313884071; train accuracy : 0.9923617789515283; \n",
      " validation loss : 0.6496019620148784; validation accuracy : 0.9022556390977443\n",
      "Epoch 163:\t train loss : 0.5636544389816971; train accuracy : 0.9876612314759989; \n",
      " validation loss : 0.6544797579294912; validation accuracy : 0.8947368421052632\n",
      "Epoch 164:\t train loss : 0.5586483604936076; train accuracy : 0.9927279765525632; \n",
      " validation loss : 0.6364055737965392; validation accuracy : 0.9172932330827067\n",
      "Epoch 165:\t train loss : 0.5580406659802732; train accuracy : 0.9932499598733752; \n",
      " validation loss : 0.6588681775370328; validation accuracy : 0.8947368421052632\n",
      "Epoch 166:\t train loss : 0.5568978470159882; train accuracy : 0.9945528949842394; \n",
      " validation loss : 0.6507623289727449; validation accuracy : 0.8947368421052632\n",
      "Epoch 167:\t train loss : 0.5563261647886442; train accuracy : 0.9950748783050514; \n",
      " validation loss : 0.613950000648514; validation accuracy : 0.9398496240601504\n",
      "Epoch 168:\t train loss : 0.5540191680927199; train accuracy : 0.9974008737488248; \n",
      " validation loss : 0.6388881011637614; validation accuracy : 0.9097744360902256\n",
      "Epoch 169:\t train loss : 0.5531334564667032; train accuracy : 0.9982856826853951; \n",
      " validation loss : 0.621796852784686; validation accuracy : 0.924812030075188\n",
      "Epoch 170:\t train loss : 0.5532978830532743; train accuracy : 0.9982027318475917; \n",
      " validation loss : 0.653831488754839; validation accuracy : 0.8872180451127819\n",
      "Epoch 171:\t train loss : 0.5531489380759705; train accuracy : 0.9982580324061273; \n",
      " validation loss : 0.6414623361650105; validation accuracy : 0.9097744360902256\n",
      "Epoch 172:\t train loss : 0.5549924439901294; train accuracy : 0.9963467911513711; \n",
      " validation loss : 0.6445660014155269; validation accuracy : 0.9097744360902256\n",
      "Epoch 173:\t train loss : 0.5552006695644505; train accuracy : 0.9961842614610408; \n",
      " validation loss : 0.6424237600267539; validation accuracy : 0.9022556390977443\n",
      "Epoch 174:\t train loss : 0.5569662331446238; train accuracy : 0.9944389218818915; \n",
      " validation loss : 0.6941452381852973; validation accuracy : 0.8571428571428571\n",
      "Epoch 175:\t train loss : 0.5602044289568185; train accuracy : 0.9911451666637443; \n",
      " validation loss : 0.6171314109830671; validation accuracy : 0.9398496240601504\n",
      "Epoch 176:\t train loss : 0.5627594983699582; train accuracy : 0.9884907398540335; \n",
      " validation loss : 0.6431421094512685; validation accuracy : 0.9097744360902256\n",
      "Epoch 177:\t train loss : 0.5557594663193574; train accuracy : 0.9956036055964165; \n",
      " validation loss : 0.660396154602714; validation accuracy : 0.8872180451127819\n",
      "Epoch 178:\t train loss : 0.5544765726818864; train accuracy : 0.9969550972952632; \n",
      " validation loss : 0.6449391777117119; validation accuracy : 0.9097744360902256\n",
      "Epoch 179:\t train loss : 0.5558458152090063; train accuracy : 0.9955381890820512; \n",
      " validation loss : 0.5942033913399337; validation accuracy : 0.9548872180451128\n",
      "Epoch 180:\t train loss : 0.5537428214337705; train accuracy : 0.997677376541503; \n",
      " validation loss : 0.6390052162618968; validation accuracy : 0.9097744360902256\n",
      "Epoch 181:\t train loss : 0.554186776460812; train accuracy : 0.9972349720732179; \n",
      " validation loss : 0.649010968450863; validation accuracy : 0.9022556390977443\n",
      "Epoch 182:\t train loss : 0.5549055682532508; train accuracy : 0.9965160648122546; \n",
      " validation loss : 0.6267573838828796; validation accuracy : 0.924812030075188\n",
      "Epoch 183:\t train loss : 0.5557084933530544; train accuracy : 0.9957142067134878; \n",
      " validation loss : 0.6462169819488551; validation accuracy : 0.9022556390977443\n",
      "Epoch 184:\t train loss : 0.5622291813068921; train accuracy : 0.9889884448808542; \n",
      " validation loss : 0.6443236592143302; validation accuracy : 0.9022556390977443\n",
      "Epoch 185:\t train loss : 0.5622041128275665; train accuracy : 0.9891887408062822; \n",
      " validation loss : 0.6522274875812452; validation accuracy : 0.8947368421052632\n",
      "Epoch 186:\t train loss : 0.5565736970105191; train accuracy : 0.9948017474976497; \n",
      " validation loss : 0.6476513292961016; validation accuracy : 0.9022556390977443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187:\t train loss : 0.5555558448242855; train accuracy : 0.9958767364038181; \n",
      " validation loss : 0.6356555563519749; validation accuracy : 0.9172932330827067\n",
      "Epoch 188:\t train loss : 0.5546360738256395; train accuracy : 0.9968202178842006; \n",
      " validation loss : 0.6694044421129043; validation accuracy : 0.8796992481203008\n",
      "Epoch 189:\t train loss : 0.5545298403967723; train accuracy : 0.9968202178842006; \n",
      " validation loss : 0.6265342168130169; validation accuracy : 0.924812030075188\n",
      "Epoch 190:\t train loss : 0.5538776449139782; train accuracy : 0.9975944257036996; \n",
      " validation loss : 0.6268261778196009; validation accuracy : 0.924812030075188\n",
      "Epoch 191:\t train loss : 0.5689319234156269; train accuracy : 0.982069131093346; \n",
      " validation loss : 0.6918860692434647; validation accuracy : 0.8646616541353384\n",
      "Epoch 192:\t train loss : 0.5670760282009555; train accuracy : 0.9843465699491369; \n",
      " validation loss : 0.6343618767941448; validation accuracy : 0.9172932330827067\n",
      "Epoch 193:\t train loss : 0.5610627376117644; train accuracy : 0.9902671016977271; \n",
      " validation loss : 0.6328184497118102; validation accuracy : 0.9172932330827067\n",
      "Epoch 194:\t train loss : 0.5548517330758089; train accuracy : 0.9965437150915224; \n",
      " validation loss : 0.6483189943001713; validation accuracy : 0.9022556390977443\n",
      "Epoch 195:\t train loss : 0.5541411562745432; train accuracy : 0.9973179229110214; \n",
      " validation loss : 0.6375830607382353; validation accuracy : 0.9172932330827067\n",
      "Epoch 196:\t train loss : 0.553749627293353; train accuracy : 0.9976220759829674; \n",
      " validation loss : 0.6487561713149148; validation accuracy : 0.9022556390977443\n",
      "Epoch 197:\t train loss : 0.5537950596858865; train accuracy : 0.9976187039976908; \n",
      " validation loss : 0.6434537150117516; validation accuracy : 0.9097744360902256\n",
      "Epoch 198:\t train loss : 0.5543678111577341; train accuracy : 0.9970103978537987; \n",
      " validation loss : 0.6374458869506329; validation accuracy : 0.9097744360902256\n",
      "Epoch 199:\t train loss : 0.5559465247893149; train accuracy : 0.9954309599502564; \n",
      " validation loss : 0.6200499881466734; validation accuracy : 0.924812030075188\n",
      "Epoch 200:\t train loss : 0.5550641657577653; train accuracy : 0.9962361900342999; \n",
      " validation loss : 0.6143698543057418; validation accuracy : 0.9398496240601504\n",
      "Epoch 201:\t train loss : 0.5537374889594999; train accuracy : 0.9977050268207709; \n",
      " validation loss : 0.6190263016223957; validation accuracy : 0.9323308270676691\n",
      "Epoch 202:\t train loss : 0.5536631707580082; train accuracy : 0.9977879776585743; \n",
      " validation loss : 0.6334075071123663; validation accuracy : 0.9097744360902256\n",
      "Epoch 203:\t train loss : 0.5533013281079701; train accuracy : 0.9981197810097882; \n",
      " validation loss : 0.6050811296551232; validation accuracy : 0.9473684210526315\n",
      "Epoch 204:\t train loss : 0.5550530824245007; train accuracy : 0.9962672122988442; \n",
      " validation loss : 0.649481981404022; validation accuracy : 0.9022556390977443\n",
      "Epoch 205:\t train loss : 0.5542405753916783; train accuracy : 0.9971520212354145; \n",
      " validation loss : 0.6277781287499153; validation accuracy : 0.924812030075188\n",
      "Epoch 206:\t train loss : 0.5559669931746406; train accuracy : 0.9954862605087921; \n",
      " validation loss : 0.668892697327675; validation accuracy : 0.8796992481203008\n",
      "Epoch 207:\t train loss : 0.5775171122112343; train accuracy : 0.9733417588005444; \n",
      " validation loss : 0.6788029751383962; validation accuracy : 0.8721804511278195\n",
      "Epoch 208:\t train loss : 0.5658503911070533; train accuracy : 0.9853453519880551; \n",
      " validation loss : 0.6128116238642767; validation accuracy : 0.9398496240601504\n",
      "Epoch 209:\t train loss : 0.5582332747158517; train accuracy : 0.9930287576392326; \n",
      " validation loss : 0.6348929683086002; validation accuracy : 0.9172932330827067\n",
      "Epoch 210:\t train loss : 0.5545977524889245; train accuracy : 0.9968202178842006; \n",
      " validation loss : 0.6231373925288686; validation accuracy : 0.924812030075188\n",
      "Epoch 211:\t train loss : 0.5550245652818474; train accuracy : 0.9964054636951833; \n",
      " validation loss : 0.6130575744279362; validation accuracy : 0.9398496240601504\n",
      "Epoch 212:\t train loss : 0.5533387918587859; train accuracy : 0.998113037039235; \n",
      " validation loss : 0.6375826156853461; validation accuracy : 0.9172932330827067\n",
      "Epoch 213:\t train loss : 0.5540670350001746; train accuracy : 0.9973179229110214; \n",
      " validation loss : 0.6416581606947865; validation accuracy : 0.9097744360902256\n",
      "Epoch 214:\t train loss : 0.553450386213374; train accuracy : 0.9980091798927169; \n",
      " validation loss : 0.6269517689023231; validation accuracy : 0.924812030075188\n",
      "Epoch 215:\t train loss : 0.5534513718961784; train accuracy : 0.9979815296134491; \n",
      " validation loss : 0.6567156400096238; validation accuracy : 0.8947368421052632\n",
      "Epoch 216:\t train loss : 0.5537136155726491; train accuracy : 0.9977326771000387; \n",
      " validation loss : 0.6560415516865595; validation accuracy : 0.8947368421052632\n",
      "Epoch 217:\t train loss : 0.5536651032486246; train accuracy : 0.9977603273793065; \n",
      " validation loss : 0.6523643403798446; validation accuracy : 0.8947368421052632\n",
      "Epoch 218:\t train loss : 0.5544322928386943; train accuracy : 0.9969861195598075; \n",
      " validation loss : 0.6345494540744803; validation accuracy : 0.9172932330827067\n",
      "Epoch 219:\t train loss : 0.5563397934337735; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6451920667193144; validation accuracy : 0.9097744360902256\n",
      "Epoch 220:\t train loss : 0.5542767974247065; train accuracy : 0.9971796715146823; \n",
      " validation loss : 0.656730424739507; validation accuracy : 0.8947368421052632\n",
      "Epoch 221:\t train loss : 0.5535437223178321; train accuracy : 0.9978432782171099; \n",
      " validation loss : 0.6546232945086852; validation accuracy : 0.8947368421052632\n",
      "Epoch 222:\t train loss : 0.5531631031723244; train accuracy : 0.9982856826853951; \n",
      " validation loss : 0.6333442928390227; validation accuracy : 0.9172932330827067\n",
      "Epoch 223:\t train loss : 0.5532339398759937; train accuracy : 0.9981440593037795; \n",
      " validation loss : 0.6151165602678158; validation accuracy : 0.9323308270676691\n",
      "Epoch 224:\t train loss : 0.5550829175987105; train accuracy : 0.9962948625781121; \n",
      " validation loss : 0.6118203193198246; validation accuracy : 0.9398496240601504\n",
      "Epoch 225:\t train loss : 0.5549339697444526; train accuracy : 0.9965713653707903; \n",
      " validation loss : 0.6401895476076186; validation accuracy : 0.9097744360902256\n",
      "Epoch 226:\t train loss : 0.5537931450797072; train accuracy : 0.9976220759829674; \n",
      " validation loss : 0.6188859968927699; validation accuracy : 0.9323308270676691\n",
      "Epoch 227:\t train loss : 0.5626931396408746; train accuracy : 0.9887537547056054; \n",
      " validation loss : 0.7018038243830668; validation accuracy : 0.849624060150376\n",
      "Epoch 228:\t train loss : 0.564556689170927; train accuracy : 0.9867555162307139; \n",
      " validation loss : 0.6266808497684354; validation accuracy : 0.924812030075188\n",
      "Epoch 229:\t train loss : 0.5571304907032892; train accuracy : 0.9941934413537576; \n",
      " validation loss : 0.6179100111404745; validation accuracy : 0.9323308270676691\n",
      "Early stopping at epoch 229\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5558458152090063; Train accuracy : 0.9955381890820512; \n",
      " Validation loss : 0.5942033913399337; Validation accuracy : 0.9548872180451128\n",
      "------------------------------ Let's train model 16 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.904635958067269; train accuracy : 0.6264032516728419; \n",
      " validation loss : 0.8706107294720877; validation accuracy : 0.6466165413533834\n",
      "Epoch 2:\t train loss : 0.7964153128959668; train accuracy : 0.7464469391140851; \n",
      " validation loss : 0.7706159839176887; validation accuracy : 0.7593984962406015\n",
      "Epoch 3:\t train loss : 0.7468008525322007; train accuracy : 0.8008765138527899; \n",
      " validation loss : 0.7648022080580313; validation accuracy : 0.7894736842105263\n",
      "Epoch 4:\t train loss : 0.711100631342319; train accuracy : 0.837997013769839; \n",
      " validation loss : 0.7266098743303505; validation accuracy : 0.8120300751879699\n",
      "Epoch 5:\t train loss : 0.6799974349957775; train accuracy : 0.8693247801802798; \n",
      " validation loss : 0.6971639884464829; validation accuracy : 0.849624060150376\n",
      "Epoch 6:\t train loss : 0.6661283137625151; train accuracy : 0.8825830890891998; \n",
      " validation loss : 0.6867568307098317; validation accuracy : 0.8646616541353384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\t train loss : 0.6424989726904222; train accuracy : 0.9080766465741305; \n",
      " validation loss : 0.6920098324852053; validation accuracy : 0.8721804511278195\n",
      "Epoch 8:\t train loss : 0.6422255029546036; train accuracy : 0.9085605264613172; \n",
      " validation loss : 0.7003128466390602; validation accuracy : 0.8421052631578947\n",
      "Epoch 9:\t train loss : 0.6178140749846722; train accuracy : 0.9333766521041863; \n",
      " validation loss : 0.6977330759083457; validation accuracy : 0.8571428571428571\n",
      "Epoch 10:\t train loss : 0.6065827225295424; train accuracy : 0.9447823923021622; \n",
      " validation loss : 0.6948136556029629; validation accuracy : 0.849624060150376\n",
      "Epoch 11:\t train loss : 0.6139375936195113; train accuracy : 0.9367361610352265; \n",
      " validation loss : 0.7150739457550327; validation accuracy : 0.8270676691729323\n",
      "Epoch 12:\t train loss : 0.6026663909885599; train accuracy : 0.9489022839130675; \n",
      " validation loss : 0.663048327755225; validation accuracy : 0.8721804511278195\n",
      "Epoch 13:\t train loss : 0.5953087353595167; train accuracy : 0.9561190068019687; \n",
      " validation loss : 0.672061248905493; validation accuracy : 0.8721804511278195\n",
      "Epoch 14:\t train loss : 0.5939415032415203; train accuracy : 0.9569623403196372; \n",
      " validation loss : 0.6581333470409462; validation accuracy : 0.8872180451127819\n",
      "Epoch 15:\t train loss : 0.593914113885066; train accuracy : 0.9574462202068241; \n",
      " validation loss : 0.6994666386937405; validation accuracy : 0.849624060150376\n",
      "Epoch 16:\t train loss : 0.5866172560463713; train accuracy : 0.9645661671182879; \n",
      " validation loss : 0.7093114157630981; validation accuracy : 0.8421052631578947\n",
      "Epoch 17:\t train loss : 0.5805144811262977; train accuracy : 0.9709119062102527; \n",
      " validation loss : 0.6282345504314703; validation accuracy : 0.9172932330827067\n",
      "Epoch 18:\t train loss : 0.5733509552652547; train accuracy : 0.978571033567439; \n",
      " validation loss : 0.6544020995842748; validation accuracy : 0.8947368421052632\n",
      "Epoch 19:\t train loss : 0.5758092931034812; train accuracy : 0.9758613061991926; \n",
      " validation loss : 0.7066727348802628; validation accuracy : 0.8421052631578947\n",
      "Epoch 20:\t train loss : 0.571858749786137; train accuracy : 0.9797323452966875; \n",
      " validation loss : 0.6692418662207105; validation accuracy : 0.8796992481203008\n",
      "Epoch 21:\t train loss : 0.576304017689717; train accuracy : 0.9750041475418901; \n",
      " validation loss : 0.6716202504494566; validation accuracy : 0.8872180451127819\n",
      "Epoch 22:\t train loss : 0.5664063499530404; train accuracy : 0.9850411989161091; \n",
      " validation loss : 0.6786271294947115; validation accuracy : 0.8646616541353384\n",
      "Epoch 23:\t train loss : 0.5840778029052001; train accuracy : 0.9666814134822762; \n",
      " validation loss : 0.7285210964810809; validation accuracy : 0.8120300751879699\n",
      "Epoch 24:\t train loss : 0.5895664715040972; train accuracy : 0.961165182768346; \n",
      " validation loss : 0.6813121993768421; validation accuracy : 0.8646616541353384\n",
      "Epoch 25:\t train loss : 0.5769663383805143; train accuracy : 0.9740640380467843; \n",
      " validation loss : 0.6579441353357103; validation accuracy : 0.8872180451127819\n",
      "Epoch 26:\t train loss : 0.5657576197247394; train accuracy : 0.9858983575734115; \n",
      " validation loss : 0.6787400707554886; validation accuracy : 0.8721804511278195\n",
      "Epoch 27:\t train loss : 0.566475541631097; train accuracy : 0.9849720732179394; \n",
      " validation loss : 0.6675360266617654; validation accuracy : 0.8721804511278195\n",
      "Epoch 28:\t train loss : 0.5706934143773363; train accuracy : 0.9804097771387491; \n",
      " validation loss : 0.6510390885226347; validation accuracy : 0.9022556390977443\n",
      "Epoch 29:\t train loss : 0.5629992411297952; train accuracy : 0.9884007078471493; \n",
      " validation loss : 0.699731462952027; validation accuracy : 0.849624060150376\n",
      "Epoch 30:\t train loss : 0.5645183405073562; train accuracy : 0.9870043687441243; \n",
      " validation loss : 0.6552405151027182; validation accuracy : 0.8947368421052632\n",
      "Epoch 31:\t train loss : 0.5604232352577442; train accuracy : 0.9912901620306365; \n",
      " validation loss : 0.6471396566813213; validation accuracy : 0.9022556390977443\n",
      "Epoch 32:\t train loss : 0.5654454512819935; train accuracy : 0.9857601061770724; \n",
      " validation loss : 0.6667606006733785; validation accuracy : 0.8721804511278195\n",
      "Epoch 33:\t train loss : 0.5739389558739662; train accuracy : 0.9769396670906376; \n",
      " validation loss : 0.6592064670028963; validation accuracy : 0.8947368421052632\n",
      "Epoch 34:\t train loss : 0.5722698180096475; train accuracy : 0.9787092849637782; \n",
      " validation loss : 0.6742065594169082; validation accuracy : 0.8721804511278195\n",
      "Epoch 35:\t train loss : 0.5744942965900963; train accuracy : 0.9767599402753968; \n",
      " validation loss : 0.6807342789130835; validation accuracy : 0.8646616541353384\n",
      "Epoch 36:\t train loss : 0.570817091359953; train accuracy : 0.9804789028369186; \n",
      " validation loss : 0.6850313937923918; validation accuracy : 0.8646616541353384\n",
      "Epoch 37:\t train loss : 0.5708882896313302; train accuracy : 0.9802577006027761; \n",
      " validation loss : 0.6751251802046639; validation accuracy : 0.8721804511278195\n",
      "Epoch 38:\t train loss : 0.5670686961786455; train accuracy : 0.9842946413758779; \n",
      " validation loss : 0.6510167188047017; validation accuracy : 0.9022556390977443\n",
      "Epoch 39:\t train loss : 0.5637897998832787; train accuracy : 0.9877371011447216; \n",
      " validation loss : 0.7015877190509078; validation accuracy : 0.849624060150376\n",
      "Epoch 40:\t train loss : 0.565424605442821; train accuracy : 0.9857186307581707; \n",
      " validation loss : 0.7093867699692461; validation accuracy : 0.8421052631578947\n",
      "Epoch 41:\t train loss : 0.5774380268789616; train accuracy : 0.9737598849748382; \n",
      " validation loss : 0.7282960529390959; validation accuracy : 0.8270676691729323\n",
      "Epoch 42:\t train loss : 0.5634247527330504; train accuracy : 0.9879030028203285; \n",
      " validation loss : 0.686626919903211; validation accuracy : 0.8646616541353384\n",
      "Epoch 43:\t train loss : 0.5800705428494651; train accuracy : 0.9705248023005032; \n",
      " validation loss : 0.6720816512604832; validation accuracy : 0.8721804511278195\n",
      "Epoch 44:\t train loss : 0.5678931574590166; train accuracy : 0.9834927832771111; \n",
      " validation loss : 0.6539890285812394; validation accuracy : 0.8947368421052632\n",
      "Epoch 45:\t train loss : 0.561222083364942; train accuracy : 0.9902532765580933; \n",
      " validation loss : 0.6531955947769181; validation accuracy : 0.8947368421052632\n",
      "Epoch 46:\t train loss : 0.5610854920748328; train accuracy : 0.9903362273958967; \n",
      " validation loss : 0.6510331984061918; validation accuracy : 0.8947368421052632\n",
      "Epoch 47:\t train loss : 0.5621600275605774; train accuracy : 0.989202565945916; \n",
      " validation loss : 0.6183605003752664; validation accuracy : 0.9323308270676691\n",
      "Epoch 48:\t train loss : 0.5601828368958555; train accuracy : 0.9912486866117348; \n",
      " validation loss : 0.6549544975974836; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.5590897227898958; train accuracy : 0.9924099983409832; \n",
      " validation loss : 0.6550230387160139; validation accuracy : 0.8947368421052632\n",
      "Epoch 50:\t train loss : 0.5655693686961073; train accuracy : 0.9855250788032959; \n",
      " validation loss : 0.6720335764298775; validation accuracy : 0.8721804511278195\n",
      "Epoch 51:\t train loss : 0.5583409695662128; train accuracy : 0.9931565558812144; \n",
      " validation loss : 0.6414349960175992; validation accuracy : 0.9097744360902256\n",
      "Epoch 52:\t train loss : 0.5608474587612674; train accuracy : 0.9905021290715036; \n",
      " validation loss : 0.6583964263830191; validation accuracy : 0.8872180451127819\n",
      "Epoch 53:\t train loss : 0.56552633484501; train accuracy : 0.9856356799203672; \n",
      " validation loss : 0.6447854164400255; validation accuracy : 0.9022556390977443\n",
      "Epoch 54:\t train loss : 0.5621124757133028; train accuracy : 0.989202565945916; \n",
      " validation loss : 0.6759572327185313; validation accuracy : 0.8721804511278195\n",
      "Epoch 55:\t train loss : 0.5666430122492108; train accuracy : 0.9846540950063596; \n",
      " validation loss : 0.6618884886817235; validation accuracy : 0.8872180451127819\n",
      "Epoch 56:\t train loss : 0.5569862901375249; train accuracy : 0.994456119006802; \n",
      " validation loss : 0.6415760474279936; validation accuracy : 0.9097744360902256\n",
      "Epoch 57:\t train loss : 0.5594611693310243; train accuracy : 0.9917878670574573; \n",
      " validation loss : 0.6549402837043743; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58:\t train loss : 0.5723336591343222; train accuracy : 0.9786678095448764; \n",
      " validation loss : 0.7193269566842645; validation accuracy : 0.8270676691729323\n",
      "Epoch 59:\t train loss : 0.5673686013627468; train accuracy : 0.9837416357905214; \n",
      " validation loss : 0.7015241480573201; validation accuracy : 0.849624060150376\n",
      "Epoch 60:\t train loss : 0.5788912909961332; train accuracy : 0.9723497207321794; \n",
      " validation loss : 0.6967930719624054; validation accuracy : 0.8571428571428571\n",
      "Epoch 61:\t train loss : 0.5845542066499043; train accuracy : 0.9659763313609467; \n",
      " validation loss : 0.7268816006677091; validation accuracy : 0.8195488721804511\n",
      "Epoch 62:\t train loss : 0.5648008878094357; train accuracy : 0.9864237128795; \n",
      " validation loss : 0.6618401270016818; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.5654500505418039; train accuracy : 0.9858707072941437; \n",
      " validation loss : 0.6444266374934526; validation accuracy : 0.9022556390977443\n",
      "Epoch 64:\t train loss : 0.558921624427025; train accuracy : 0.9924929491787867; \n",
      " validation loss : 0.6482570920805264; validation accuracy : 0.9097744360902256\n",
      "Epoch 65:\t train loss : 0.5576187013878323; train accuracy : 0.9936680860476691; \n",
      " validation loss : 0.6350189810061796; validation accuracy : 0.9172932330827067\n",
      "Epoch 66:\t train loss : 0.5569321360938814; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6467879366357205; validation accuracy : 0.9022556390977443\n",
      "Epoch 67:\t train loss : 0.5571261014181588; train accuracy : 0.9944008184482663; \n",
      " validation loss : 0.6308440761836722; validation accuracy : 0.924812030075188\n",
      "Epoch 68:\t train loss : 0.5567762818319807; train accuracy : 0.994760272078748; \n",
      " validation loss : 0.6308357512817258; validation accuracy : 0.9172932330827067\n",
      "Epoch 69:\t train loss : 0.5606899465653843; train accuracy : 0.9905574296300392; \n",
      " validation loss : 0.674501542213513; validation accuracy : 0.8796992481203008\n",
      "Epoch 70:\t train loss : 0.6263467570859679; train accuracy : 0.9237267046397168; \n",
      " validation loss : 0.7175589539544318; validation accuracy : 0.8345864661654135\n",
      "Epoch 71:\t train loss : 0.6523077979367238; train accuracy : 0.8973206879389481; \n",
      " validation loss : 0.659046850150657; validation accuracy : 0.8947368421052632\n",
      "Epoch 72:\t train loss : 0.6157857128680988; train accuracy : 0.93434441187856; \n",
      " validation loss : 0.6885022220464627; validation accuracy : 0.849624060150376\n",
      "Epoch 73:\t train loss : 0.5972104697709179; train accuracy : 0.9530913012221424; \n",
      " validation loss : 0.6828192764531638; validation accuracy : 0.8646616541353384\n",
      "Epoch 74:\t train loss : 0.5825117414716652; train accuracy : 0.968713709008461; \n",
      " validation loss : 0.6846852957175951; validation accuracy : 0.8646616541353384\n",
      "Epoch 75:\t train loss : 0.5800669908626059; train accuracy : 0.9706215782779406; \n",
      " validation loss : 0.6891471518244561; validation accuracy : 0.8571428571428571\n",
      "Epoch 76:\t train loss : 0.5892882533422824; train accuracy : 0.9614416855610242; \n",
      " validation loss : 0.7316324832082779; validation accuracy : 0.8195488721804511\n",
      "Epoch 77:\t train loss : 0.5749870391623176; train accuracy : 0.9758889564784604; \n",
      " validation loss : 0.6654291917124269; validation accuracy : 0.8872180451127819\n",
      "Epoch 78:\t train loss : 0.5692405849671284; train accuracy : 0.9819305424984792; \n",
      " validation loss : 0.6911812796833049; validation accuracy : 0.8571428571428571\n",
      "Epoch 79:\t train loss : 0.5658831988899822; train accuracy : 0.9852900514295194; \n",
      " validation loss : 0.6549490969448419; validation accuracy : 0.8947368421052632\n",
      "Epoch 80:\t train loss : 0.563801521194928; train accuracy : 0.9877232760050877; \n",
      " validation loss : 0.660039450674889; validation accuracy : 0.8872180451127819\n",
      "Epoch 81:\t train loss : 0.5652293973756297; train accuracy : 0.9860227838301167; \n",
      " validation loss : 0.6609809447607822; validation accuracy : 0.8947368421052632\n",
      "Epoch 82:\t train loss : 0.5683195201845773; train accuracy : 0.983202455344799; \n",
      " validation loss : 0.6827700549212609; validation accuracy : 0.8646616541353384\n",
      "Epoch 83:\t train loss : 0.5624639407305282; train accuracy : 0.9887878117568988; \n",
      " validation loss : 0.6915901918771404; validation accuracy : 0.8571428571428571\n",
      "Epoch 84:\t train loss : 0.5609945963976901; train accuracy : 0.9903362273958967; \n",
      " validation loss : 0.6667794236132726; validation accuracy : 0.8872180451127819\n",
      "Epoch 85:\t train loss : 0.560297796070954; train accuracy : 0.9911933860531992; \n",
      " validation loss : 0.674376488408675; validation accuracy : 0.8721804511278195\n",
      "Epoch 86:\t train loss : 0.5587917877760492; train accuracy : 0.9926312005751258; \n",
      " validation loss : 0.6520023735661858; validation accuracy : 0.8947368421052632\n",
      "Epoch 87:\t train loss : 0.5626053105621398; train accuracy : 0.9886357352209257; \n",
      " validation loss : 0.642260781605266; validation accuracy : 0.9022556390977443\n",
      "Epoch 88:\t train loss : 0.5600268777921786; train accuracy : 0.9912072111928331; \n",
      " validation loss : 0.6608550228524938; validation accuracy : 0.8872180451127819\n",
      "Epoch 89:\t train loss : 0.6185578879487471; train accuracy : 0.9317314604877509; \n",
      " validation loss : 0.6690704868524435; validation accuracy : 0.8796992481203008\n",
      "Epoch 90:\t train loss : 0.5813597592204128; train accuracy : 0.9697091190621026; \n",
      " validation loss : 0.7004237303926484; validation accuracy : 0.8421052631578947\n",
      "Epoch 91:\t train loss : 0.5711983103344797; train accuracy : 0.9797599955759553; \n",
      " validation loss : 0.6590476922727755; validation accuracy : 0.8872180451127819\n",
      "Epoch 92:\t train loss : 0.5630094203307084; train accuracy : 0.988138030194105; \n",
      " validation loss : 0.662241098341067; validation accuracy : 0.8947368421052632\n",
      "Epoch 93:\t train loss : 0.5617852914534578; train accuracy : 0.9894514184593264; \n",
      " validation loss : 0.6496442128302483; validation accuracy : 0.9022556390977443\n",
      "Epoch 94:\t train loss : 0.5609104811384016; train accuracy : 0.990280926837361; \n",
      " validation loss : 0.6676066173923457; validation accuracy : 0.8796992481203008\n",
      "Epoch 95:\t train loss : 0.5611229975035451; train accuracy : 0.9903085771166289; \n",
      " validation loss : 0.639120932244507; validation accuracy : 0.9097744360902256\n",
      "Epoch 96:\t train loss : 0.5588202279594578; train accuracy : 0.9924238234806172; \n",
      " validation loss : 0.653337589123422; validation accuracy : 0.8947368421052632\n",
      "Epoch 97:\t train loss : 0.5587112044793446; train accuracy : 0.9924929491787867; \n",
      " validation loss : 0.6488364358225341; validation accuracy : 0.9022556390977443\n",
      "Early stopping at epoch 97\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5621600275605774; Train accuracy : 0.989202565945916; \n",
      " Validation loss : 0.6183605003752664; Validation accuracy : 0.9323308270676691\n",
      "------------------------------ Let's train model 17 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9038070743501566; train accuracy : 0.615909970690704; \n",
      " validation loss : 0.8799563156570372; validation accuracy : 0.6390977443609023\n",
      "Epoch 2:\t train loss : 0.8131000244688759; train accuracy : 0.7269534922302715; \n",
      " validation loss : 0.7837886462723118; validation accuracy : 0.7744360902255639\n",
      "Epoch 3:\t train loss : 0.7870330558565544; train accuracy : 0.7559033346236798; \n",
      " validation loss : 0.7661233806392723; validation accuracy : 0.7894736842105263\n",
      "Epoch 4:\t train loss : 0.742908816840349; train accuracy : 0.8040701211082232; \n",
      " validation loss : 0.754295831835647; validation accuracy : 0.7969924812030075\n",
      "Epoch 5:\t train loss : 0.7005733658925352; train accuracy : 0.8474948846983354; \n",
      " validation loss : 0.7607138486543407; validation accuracy : 0.7669172932330827\n",
      "Epoch 6:\t train loss : 0.6760335501807083; train accuracy : 0.8734170215119172; \n",
      " validation loss : 0.7642338339061421; validation accuracy : 0.7744360902255639\n",
      "Epoch 7:\t train loss : 0.6518035778627677; train accuracy : 0.8980672454791794; \n",
      " validation loss : 0.7190692345374181; validation accuracy : 0.8195488721804511\n",
      "Epoch 8:\t train loss : 0.6353115076000194; train accuracy : 0.9145606370624343; \n",
      " validation loss : 0.6760586729742336; validation accuracy : 0.8796992481203008\n",
      "Epoch 9:\t train loss : 0.6169238178538178; train accuracy : 0.9339296576895426; \n",
      " validation loss : 0.6860581906440495; validation accuracy : 0.8721804511278195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\t train loss : 0.6097749312984735; train accuracy : 0.9417823370016037; \n",
      " validation loss : 0.7469651465427384; validation accuracy : 0.7969924812030075\n",
      "Epoch 11:\t train loss : 0.5950302774721316; train accuracy : 0.9565614112702538; \n",
      " validation loss : 0.7611036920201207; validation accuracy : 0.7894736842105263\n",
      "Epoch 12:\t train loss : 0.6144931312192822; train accuracy : 0.9356854504230493; \n",
      " validation loss : 0.6842625469523654; validation accuracy : 0.8646616541353384\n",
      "Epoch 13:\t train loss : 0.597085543345813; train accuracy : 0.9537963833434717; \n",
      " validation loss : 0.8189602766612524; validation accuracy : 0.7293233082706767\n",
      "Epoch 14:\t train loss : 0.6235482952809264; train accuracy : 0.9262981806116242; \n",
      " validation loss : 0.6949174853941168; validation accuracy : 0.8571428571428571\n",
      "Epoch 15:\t train loss : 0.596294005865778; train accuracy : 0.9543493889288281; \n",
      " validation loss : 0.6754239689437821; validation accuracy : 0.8796992481203008\n",
      "Epoch 16:\t train loss : 0.591147407477518; train accuracy : 0.9605707017640878; \n",
      " validation loss : 0.6958695526864784; validation accuracy : 0.8571428571428571\n",
      "Epoch 17:\t train loss : 0.5838570084700331; train accuracy : 0.967621522977382; \n",
      " validation loss : 0.657731036636447; validation accuracy : 0.8872180451127819\n",
      "Epoch 18:\t train loss : 0.5775745491103257; train accuracy : 0.9746170436321406; \n",
      " validation loss : 0.7156717033070997; validation accuracy : 0.8345864661654135\n",
      "Epoch 19:\t train loss : 0.5735657727976872; train accuracy : 0.9779212520046453; \n",
      " validation loss : 0.7460547993295893; validation accuracy : 0.8045112781954887\n",
      "Epoch 20:\t train loss : 0.5928730003707107; train accuracy : 0.9577227229995023; \n",
      " validation loss : 0.7096687739008916; validation accuracy : 0.8345864661654135\n",
      "Epoch 21:\t train loss : 0.5911416349917757; train accuracy : 0.9596997179671515; \n",
      " validation loss : 0.6808902740236303; validation accuracy : 0.8646616541353384\n",
      "Epoch 22:\t train loss : 0.5763920245296078; train accuracy : 0.9749073715644528; \n",
      " validation loss : 0.7158711277869118; validation accuracy : 0.8270676691729323\n",
      "Epoch 23:\t train loss : 0.5707786530807976; train accuracy : 0.9807277553503291; \n",
      " validation loss : 0.707909212241252; validation accuracy : 0.8421052631578947\n",
      "Epoch 24:\t train loss : 0.5688529937214571; train accuracy : 0.9827877011557816; \n",
      " validation loss : 0.700126734640712; validation accuracy : 0.849624060150376\n",
      "Epoch 25:\t train loss : 0.5628903512012826; train accuracy : 0.9888154620361665; \n",
      " validation loss : 0.6751384285299342; validation accuracy : 0.8646616541353384\n",
      "Epoch 26:\t train loss : 0.5668253230288395; train accuracy : 0.9848199966819665; \n",
      " validation loss : 0.7147948576971712; validation accuracy : 0.8421052631578947\n",
      "Epoch 27:\t train loss : 0.5683662328808065; train accuracy : 0.9830780290880938; \n",
      " validation loss : 0.7404334907668684; validation accuracy : 0.8045112781954887\n",
      "Epoch 28:\t train loss : 0.5847306006876366; train accuracy : 0.9656860034286346; \n",
      " validation loss : 0.7239618584195152; validation accuracy : 0.8270676691729323\n",
      "Epoch 29:\t train loss : 0.567839729894384; train accuracy : 0.9838107614886911; \n",
      " validation loss : 0.7285521841398924; validation accuracy : 0.8195488721804511\n",
      "Epoch 30:\t train loss : 0.5629449499186285; train accuracy : 0.9883454072886136; \n",
      " validation loss : 0.6994081959680615; validation accuracy : 0.849624060150376\n",
      "Epoch 31:\t train loss : 0.5657482670220145; train accuracy : 0.9856909804789028; \n",
      " validation loss : 0.7361770999756493; validation accuracy : 0.8045112781954887\n",
      "Epoch 32:\t train loss : 0.5612730973746874; train accuracy : 0.9900044240446828; \n",
      " validation loss : 0.696511038091088; validation accuracy : 0.8571428571428571\n",
      "Epoch 33:\t train loss : 0.5662844393726613; train accuracy : 0.9852624011502517; \n",
      " validation loss : 0.6983773278935624; validation accuracy : 0.849624060150376\n",
      "Epoch 34:\t train loss : 0.5623480456265691; train accuracy : 0.9892302162251839; \n",
      " validation loss : 0.6879970504308198; validation accuracy : 0.8646616541353384\n",
      "Epoch 35:\t train loss : 0.5592401662035906; train accuracy : 0.9922717469446442; \n",
      " validation loss : 0.7095081950971766; validation accuracy : 0.8345864661654135\n",
      "Epoch 36:\t train loss : 0.5628878741616765; train accuracy : 0.9885527843831222; \n",
      " validation loss : 0.6930285205909688; validation accuracy : 0.8571428571428571\n",
      "Epoch 37:\t train loss : 0.5565972718239698; train accuracy : 0.994608195542775; \n",
      " validation loss : 0.742086154240851; validation accuracy : 0.8120300751879699\n",
      "Epoch 38:\t train loss : 0.5946674711216432; train accuracy : 0.9561604822208705; \n",
      " validation loss : 0.6804065910400269; validation accuracy : 0.8721804511278195\n",
      "Epoch 39:\t train loss : 0.571589334657636; train accuracy : 0.9795802687607145; \n",
      " validation loss : 0.6724268017433858; validation accuracy : 0.8796992481203008\n",
      "Epoch 40:\t train loss : 0.5699310911232124; train accuracy : 0.9811010341204446; \n",
      " validation loss : 0.6771839676712937; validation accuracy : 0.8796992481203008\n",
      "Epoch 41:\t train loss : 0.5749282412193808; train accuracy : 0.9760410330144335; \n",
      " validation loss : 0.7182580404427782; validation accuracy : 0.8345864661654135\n",
      "Epoch 42:\t train loss : 0.5632867775015888; train accuracy : 0.9881795056130067; \n",
      " validation loss : 0.691312970144038; validation accuracy : 0.8571428571428571\n",
      "Epoch 43:\t train loss : 0.5578476119638813; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.7079242729128095; validation accuracy : 0.8345864661654135\n",
      "Epoch 44:\t train loss : 0.5562510200612248; train accuracy : 0.995230326826301; \n",
      " validation loss : 0.7183625680769222; validation accuracy : 0.8345864661654135\n",
      "Epoch 45:\t train loss : 0.5694871445295857; train accuracy : 0.9818199413814079; \n",
      " validation loss : 0.6818036431474671; validation accuracy : 0.8646616541353384\n",
      "Epoch 46:\t train loss : 0.5565214166459242; train accuracy : 0.994912348614721; \n",
      " validation loss : 0.6929815951431355; validation accuracy : 0.8571428571428571\n",
      "Epoch 47:\t train loss : 0.5743722073875183; train accuracy : 0.9763175358071117; \n",
      " validation loss : 0.6687821696284243; validation accuracy : 0.8796992481203008\n",
      "Epoch 48:\t train loss : 0.5594273071952612; train accuracy : 0.991981419012332; \n",
      " validation loss : 0.7065896342717148; validation accuracy : 0.8421052631578947\n",
      "Epoch 49:\t train loss : 0.5582347611403026; train accuracy : 0.9930183044848753; \n",
      " validation loss : 0.6933249012226544; validation accuracy : 0.8571428571428571\n",
      "Epoch 50:\t train loss : 0.5575377864819296; train accuracy : 0.9939031134214455; \n",
      " validation loss : 0.682961875764637; validation accuracy : 0.8646616541353384\n",
      "Epoch 51:\t train loss : 0.5580856635402927; train accuracy : 0.9932809821379196; \n",
      " validation loss : 0.6886136723706489; validation accuracy : 0.8571428571428571\n",
      "Epoch 52:\t train loss : 0.5565638669443518; train accuracy : 0.9949399988939888; \n",
      " validation loss : 0.6867777001989265; validation accuracy : 0.8646616541353384\n",
      "Epoch 53:\t train loss : 0.5596082068028989; train accuracy : 0.9917602167781895; \n",
      " validation loss : 0.6812812488456135; validation accuracy : 0.8646616541353384\n",
      "Epoch 54:\t train loss : 0.5592181838752981; train accuracy : 0.9919952441519659; \n",
      " validation loss : 0.6837873901988957; validation accuracy : 0.8646616541353384\n",
      "Epoch 55:\t train loss : 0.5548913073823065; train accuracy : 0.9965160648122546; \n",
      " validation loss : 0.7031709695239835; validation accuracy : 0.849624060150376\n",
      "Epoch 56:\t train loss : 0.5547011667869253; train accuracy : 0.9967787424652989; \n",
      " validation loss : 0.6885743555665284; validation accuracy : 0.8646616541353384\n",
      "Epoch 57:\t train loss : 0.5548933078941636; train accuracy : 0.996446939114085; \n",
      " validation loss : 0.6830061054685882; validation accuracy : 0.8721804511278195\n",
      "Epoch 58:\t train loss : 0.5549247485790028; train accuracy : 0.9965575402311563; \n",
      " validation loss : 0.6638803113601459; validation accuracy : 0.8872180451127819\n",
      "Epoch 59:\t train loss : 0.5544152472538308; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.6561725528452866; validation accuracy : 0.8947368421052632\n",
      "Epoch 60:\t train loss : 0.5614703267924891; train accuracy : 0.9895620195763977; \n",
      " validation loss : 0.6655284158747978; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61:\t train loss : 0.5839560812020453; train accuracy : 0.9667505391804457; \n",
      " validation loss : 0.750259685942781; validation accuracy : 0.7969924812030075\n",
      "Epoch 62:\t train loss : 0.570647492276754; train accuracy : 0.980575678814356; \n",
      " validation loss : 0.6948412022856585; validation accuracy : 0.8571428571428571\n",
      "Epoch 63:\t train loss : 0.5604258218334095; train accuracy : 0.9906818558867444; \n",
      " validation loss : 0.6725013423393342; validation accuracy : 0.8796992481203008\n",
      "Epoch 64:\t train loss : 0.5585685816059446; train accuracy : 0.9927003262732953; \n",
      " validation loss : 0.7242111754653038; validation accuracy : 0.8270676691729323\n",
      "Epoch 65:\t train loss : 0.5555488113683743; train accuracy : 0.9957971575512913; \n",
      " validation loss : 0.6680461587640752; validation accuracy : 0.8796992481203008\n",
      "Epoch 66:\t train loss : 0.554756176102642; train accuracy : 0.9966681413482276; \n",
      " validation loss : 0.6781729703425238; validation accuracy : 0.8721804511278195\n",
      "Epoch 67:\t train loss : 0.5534224531079269; train accuracy : 0.9981336061494221; \n",
      " validation loss : 0.6903655665866467; validation accuracy : 0.8571428571428571\n",
      "Epoch 68:\t train loss : 0.5562779060198919; train accuracy : 0.9949399988939889; \n",
      " validation loss : 0.6945539026392927; validation accuracy : 0.8571428571428571\n",
      "Epoch 69:\t train loss : 0.5624830975935016; train accuracy : 0.9887048609190953; \n",
      " validation loss : 0.6869763856419839; validation accuracy : 0.8646616541353384\n",
      "Epoch 70:\t train loss : 0.5652352445992272; train accuracy : 0.9859951335508489; \n",
      " validation loss : 0.6756264081129487; validation accuracy : 0.8721804511278195\n",
      "Epoch 71:\t train loss : 0.5573361848086044; train accuracy : 0.9939307637007133; \n",
      " validation loss : 0.7233032493149136; validation accuracy : 0.8270676691729323\n",
      "Epoch 72:\t train loss : 0.5595440256747921; train accuracy : 0.9917187413592877; \n",
      " validation loss : 0.6825586112856702; validation accuracy : 0.8721804511278195\n",
      "Epoch 73:\t train loss : 0.5617413189082668; train accuracy : 0.9892993419233534; \n",
      " validation loss : 0.7043614209474774; validation accuracy : 0.8421052631578947\n",
      "Epoch 74:\t train loss : 0.580888458485657; train accuracy : 0.9699579715755129; \n",
      " validation loss : 0.6749071919331477; validation accuracy : 0.8796992481203008\n",
      "Epoch 75:\t train loss : 0.5603768732872985; train accuracy : 0.990750981584914; \n",
      " validation loss : 0.6845496276450406; validation accuracy : 0.8646616541353384\n",
      "Epoch 76:\t train loss : 0.5687731617091971; train accuracy : 0.982276170989327; \n",
      " validation loss : 0.7127407545054425; validation accuracy : 0.8421052631578947\n",
      "Epoch 77:\t train loss : 0.5564176109895121; train accuracy : 0.9948985234750871; \n",
      " validation loss : 0.6960512829722292; validation accuracy : 0.849624060150376\n",
      "Epoch 78:\t train loss : 0.5576678311605238; train accuracy : 0.9937372117458386; \n",
      " validation loss : 0.6705608215819572; validation accuracy : 0.8872180451127819\n",
      "Epoch 79:\t train loss : 0.5579269455477385; train accuracy : 0.9933224575568214; \n",
      " validation loss : 0.706026668029269; validation accuracy : 0.8421052631578947\n",
      "Epoch 80:\t train loss : 0.5570727179269223; train accuracy : 0.9943316927500968; \n",
      " validation loss : 0.6935617812661231; validation accuracy : 0.8571428571428571\n",
      "Epoch 81:\t train loss : 0.5551359605162495; train accuracy : 0.9961980866006747; \n",
      " validation loss : 0.6819256804582049; validation accuracy : 0.8721804511278195\n",
      "Epoch 82:\t train loss : 0.5539258596810251; train accuracy : 0.9974285240280927; \n",
      " validation loss : 0.6750911759820086; validation accuracy : 0.8721804511278195\n",
      "Epoch 83:\t train loss : 0.5608880658344726; train accuracy : 0.9904606536526018; \n",
      " validation loss : 0.7023800657571473; validation accuracy : 0.849624060150376\n",
      "Epoch 84:\t train loss : 0.5609332430903515; train accuracy : 0.9903915279544323; \n",
      " validation loss : 0.7015356832146878; validation accuracy : 0.849624060150376\n",
      "Epoch 85:\t train loss : 0.5961872773031909; train accuracy : 0.9543908643477299; \n",
      " validation loss : 0.7186216696556279; validation accuracy : 0.8345864661654135\n",
      "Epoch 86:\t train loss : 0.5649797362397023; train accuracy : 0.9865066637173036; \n",
      " validation loss : 0.6822902902647936; validation accuracy : 0.8646616541353384\n",
      "Epoch 87:\t train loss : 0.5589701843911961; train accuracy : 0.9925620748769562; \n",
      " validation loss : 0.6880315991144756; validation accuracy : 0.8646616541353384\n",
      "Epoch 88:\t train loss : 0.5626359415959716; train accuracy : 0.9888016368965327; \n",
      " validation loss : 0.7202038976472208; validation accuracy : 0.8270676691729323\n",
      "Epoch 89:\t train loss : 0.5740258351026709; train accuracy : 0.9768152408339325; \n",
      " validation loss : 0.6977190367353867; validation accuracy : 0.849624060150376\n",
      "Epoch 90:\t train loss : 0.5568743228147128; train accuracy : 0.9944975944257037; \n",
      " validation loss : 0.6726480658775525; validation accuracy : 0.8721804511278195\n",
      "Epoch 91:\t train loss : 0.5552452502270288; train accuracy : 0.9961704363214068; \n",
      " validation loss : 0.6871185970512061; validation accuracy : 0.8646616541353384\n",
      "Epoch 92:\t train loss : 0.5550482969151032; train accuracy : 0.9962395620195764; \n",
      " validation loss : 0.6449764861621177; validation accuracy : 0.9097744360902256\n",
      "Epoch 93:\t train loss : 0.5614177119296814; train accuracy : 0.9897832218105402; \n",
      " validation loss : 0.7064986313657987; validation accuracy : 0.8421052631578947\n",
      "Epoch 94:\t train loss : 0.5553362077655095; train accuracy : 0.9960874854836034; \n",
      " validation loss : 0.6932393495346681; validation accuracy : 0.8646616541353384\n",
      "Epoch 95:\t train loss : 0.5551560297782201; train accuracy : 0.9962672122988442; \n",
      " validation loss : 0.6772314100323168; validation accuracy : 0.8721804511278195\n",
      "Epoch 96:\t train loss : 0.5548064894035378; train accuracy : 0.9965851905104242; \n",
      " validation loss : 0.7143102061752302; validation accuracy : 0.8345864661654135\n",
      "Epoch 97:\t train loss : 0.5541280659613861; train accuracy : 0.9971381960957806; \n",
      " validation loss : 0.6901200915952245; validation accuracy : 0.8646616541353384\n",
      "Epoch 98:\t train loss : 0.554988073896877; train accuracy : 0.9965298899518885; \n",
      " validation loss : 0.7094443289001324; validation accuracy : 0.8421052631578947\n",
      "Epoch 99:\t train loss : 0.5755508861368913; train accuracy : 0.975488027429077; \n",
      " validation loss : 0.7127209565237282; validation accuracy : 0.8345864661654135\n",
      "Epoch 100:\t train loss : 0.5664237090874914; train accuracy : 0.9845711441685561; \n",
      " validation loss : 0.667818769801567; validation accuracy : 0.8796992481203008\n",
      "Epoch 101:\t train loss : 0.5591695181311346; train accuracy : 0.9920228944312337; \n",
      " validation loss : 0.7045617535216627; validation accuracy : 0.849624060150376\n",
      "Epoch 102:\t train loss : 0.5569140663441221; train accuracy : 0.9943731681689985; \n",
      " validation loss : 0.6915368990769575; validation accuracy : 0.8646616541353384\n",
      "Epoch 103:\t train loss : 0.5543410954822311; train accuracy : 0.9970275949787093; \n",
      " validation loss : 0.6870303539137984; validation accuracy : 0.8646616541353384\n",
      "Epoch 104:\t train loss : 0.5544313809273592; train accuracy : 0.9970137698390754; \n",
      " validation loss : 0.6496656243775883; validation accuracy : 0.9022556390977443\n",
      "Epoch 105:\t train loss : 0.5574643949176294; train accuracy : 0.9939031134214455; \n",
      " validation loss : 0.6658552694480175; validation accuracy : 0.8872180451127819\n",
      "Epoch 106:\t train loss : 0.5561149754922773; train accuracy : 0.9951473759884975; \n",
      " validation loss : 0.6883678003663045; validation accuracy : 0.8646616541353384\n",
      "Epoch 107:\t train loss : 0.5555128957867134; train accuracy : 0.9957971575512913; \n",
      " validation loss : 0.6717533981703316; validation accuracy : 0.8796992481203008\n",
      "Epoch 108:\t train loss : 0.5586561835950083; train accuracy : 0.9928247525300006; \n",
      " validation loss : 0.6891125114510988; validation accuracy : 0.8571428571428571\n",
      "Epoch 109:\t train loss : 0.5557956177029405; train accuracy : 0.995534479898247; \n",
      " validation loss : 0.6893932619006234; validation accuracy : 0.8646616541353384\n",
      "Epoch 110:\t train loss : 0.5551136369965319; train accuracy : 0.9963501631366477; \n",
      " validation loss : 0.6761234090931432; validation accuracy : 0.8721804511278195\n",
      "Epoch 111:\t train loss : 0.5547215419999999; train accuracy : 0.9965713653707903; \n",
      " validation loss : 0.6629745452509163; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112:\t train loss : 0.5535364656417456; train accuracy : 0.9979400541945473; \n",
      " validation loss : 0.6808005746471573; validation accuracy : 0.8721804511278195\n",
      "Epoch 113:\t train loss : 0.5558700007249884; train accuracy : 0.9954930044793452; \n",
      " validation loss : 0.6765051893047117; validation accuracy : 0.8721804511278195\n",
      "Epoch 114:\t train loss : 0.5537001346483785; train accuracy : 0.9977326771000387; \n",
      " validation loss : 0.6834919777079107; validation accuracy : 0.8646616541353384\n",
      "Epoch 115:\t train loss : 0.5559183616938806; train accuracy : 0.9954791793397113; \n",
      " validation loss : 0.6815300868204301; validation accuracy : 0.8721804511278195\n",
      "Epoch 116:\t train loss : 0.5559423274219177; train accuracy : 0.9954791793397113; \n",
      " validation loss : 0.6883118479899213; validation accuracy : 0.8646616541353384\n",
      "Epoch 117:\t train loss : 0.5939348275376387; train accuracy : 0.956685837526959; \n",
      " validation loss : 0.6845790753707176; validation accuracy : 0.8646616541353384\n",
      "Epoch 118:\t train loss : 0.5970058892305041; train accuracy : 0.9533539788751866; \n",
      " validation loss : 0.6623813580113245; validation accuracy : 0.8947368421052632\n",
      "Epoch 119:\t train loss : 0.5780676461060386; train accuracy : 0.9729303765968036; \n",
      " validation loss : 0.670876370543248; validation accuracy : 0.8796992481203008\n",
      "Epoch 120:\t train loss : 0.5593031824883101; train accuracy : 0.9920643698501355; \n",
      " validation loss : 0.6842630522177957; validation accuracy : 0.8646616541353384\n",
      "Epoch 121:\t train loss : 0.5582631590133286; train accuracy : 0.9929353536470719; \n",
      " validation loss : 0.6657808623629233; validation accuracy : 0.8796992481203008\n",
      "Epoch 122:\t train loss : 0.555758646313127; train accuracy : 0.9955068296189792; \n",
      " validation loss : 0.6601309379767522; validation accuracy : 0.8947368421052632\n",
      "Epoch 123:\t train loss : 0.5713895323763072; train accuracy : 0.9795111430625449; \n",
      " validation loss : 0.6836152843903238; validation accuracy : 0.8646616541353384\n",
      "Epoch 124:\t train loss : 0.565898500245837; train accuracy : 0.9853177017087873; \n",
      " validation loss : 0.7042847985482567; validation accuracy : 0.8421052631578947\n",
      "Epoch 125:\t train loss : 0.557325717657719; train accuracy : 0.9940551899574186; \n",
      " validation loss : 0.6832250599022559; validation accuracy : 0.8646616541353384\n",
      "Epoch 126:\t train loss : 0.557590513537678; train accuracy : 0.9936957363269369; \n",
      " validation loss : 0.7465939549440228; validation accuracy : 0.7969924812030075\n",
      "Epoch 127:\t train loss : 0.5561980684932759; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.6643279128439499; validation accuracy : 0.8872180451127819\n",
      "Epoch 128:\t train loss : 0.5545265873931675; train accuracy : 0.9969308190012719; \n",
      " validation loss : 0.6837648266413365; validation accuracy : 0.8646616541353384\n",
      "Epoch 129:\t train loss : 0.5535122498496676; train accuracy : 0.9979124039152796; \n",
      " validation loss : 0.6929309575337799; validation accuracy : 0.8571428571428571\n",
      "Epoch 130:\t train loss : 0.5540022901477303; train accuracy : 0.9973870486091909; \n",
      " validation loss : 0.6764295711425842; validation accuracy : 0.8721804511278195\n",
      "Epoch 131:\t train loss : 0.5546785865273156; train accuracy : 0.9967096167671293; \n",
      " validation loss : 0.6800115952878426; validation accuracy : 0.8721804511278195\n",
      "Epoch 132:\t train loss : 0.5536725559102943; train accuracy : 0.9977326771000387; \n",
      " validation loss : 0.679279040691563; validation accuracy : 0.8721804511278195\n",
      "Epoch 133:\t train loss : 0.5536628751760145; train accuracy : 0.9975944257036996; \n",
      " validation loss : 0.6698601944914799; validation accuracy : 0.8796992481203008\n",
      "Epoch 134:\t train loss : 0.5643061500872498; train accuracy : 0.9870734944422939; \n",
      " validation loss : 0.6936683546310347; validation accuracy : 0.8571428571428571\n",
      "Epoch 135:\t train loss : 0.5565342465574518; train accuracy : 0.9948017474976497; \n",
      " validation loss : 0.6525789207696944; validation accuracy : 0.8947368421052632\n",
      "Epoch 136:\t train loss : 0.5600637288516315; train accuracy : 0.9911795609135652; \n",
      " validation loss : 0.686913685440594; validation accuracy : 0.8646616541353384\n",
      "Epoch 137:\t train loss : 0.5560352655876676; train accuracy : 0.9952856273848366; \n",
      " validation loss : 0.7093359065470729; validation accuracy : 0.8421052631578947\n",
      "Epoch 138:\t train loss : 0.5538376250916045; train accuracy : 0.9976082508433335; \n",
      " validation loss : 0.6790792354827218; validation accuracy : 0.8646616541353384\n",
      "Epoch 139:\t train loss : 0.5589810004183567; train accuracy : 0.9922579218050103; \n",
      " validation loss : 0.6747811257790112; validation accuracy : 0.8721804511278195\n",
      "Epoch 140:\t train loss : 0.5557508105157912; train accuracy : 0.9957142067134878; \n",
      " validation loss : 0.6695679365539492; validation accuracy : 0.8796992481203008\n",
      "Epoch 141:\t train loss : 0.5551333036670684; train accuracy : 0.9962395620195764; \n",
      " validation loss : 0.6562725894509964; validation accuracy : 0.8947368421052632\n",
      "Epoch 142:\t train loss : 0.5786915674486952; train accuracy : 0.9720317425205994; \n",
      " validation loss : 0.7428245255786856; validation accuracy : 0.8045112781954887\n",
      "Early stopping at epoch 142\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5550482969151032; Train accuracy : 0.9962395620195764; \n",
      " Validation loss : 0.6449764861621177; Validation accuracy : 0.9097744360902256\n",
      "------------------------------ Let's train model 18 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.907277018443647; train accuracy : 0.6224769120168113; \n",
      " validation loss : 0.8560134937036166; validation accuracy : 0.6842105263157895\n",
      "Epoch 2:\t train loss : 0.8064529906544616; train accuracy : 0.7360227838301167; \n",
      " validation loss : 0.7556764520508032; validation accuracy : 0.7894736842105263\n",
      "Epoch 3:\t train loss : 0.771413665117664; train accuracy : 0.7736409887739866; \n",
      " validation loss : 0.7825175727538911; validation accuracy : 0.7669172932330827\n",
      "Epoch 4:\t train loss : 0.7574059597681663; train accuracy : 0.7894845987944479; \n",
      " validation loss : 0.741603071591835; validation accuracy : 0.8045112781954887\n",
      "Epoch 5:\t train loss : 0.7202326120213407; train accuracy : 0.8279323121163523; \n",
      " validation loss : 0.763532455715723; validation accuracy : 0.7744360902255639\n",
      "Epoch 6:\t train loss : 0.6894422044881846; train accuracy : 0.8591080019908202; \n",
      " validation loss : 0.7683746555750938; validation accuracy : 0.7669172932330827\n",
      "Epoch 7:\t train loss : 0.6680312590261384; train accuracy : 0.8824586628324946; \n",
      " validation loss : 0.6772796089210515; validation accuracy : 0.8796992481203008\n",
      "Epoch 8:\t train loss : 0.6533662757768793; train accuracy : 0.897196261682243; \n",
      " validation loss : 0.6853668132289221; validation accuracy : 0.8646616541353384\n",
      "Epoch 9:\t train loss : 0.638057548830326; train accuracy : 0.9122933141624731; \n",
      " validation loss : 0.6639257305146882; validation accuracy : 0.8872180451127819\n",
      "Epoch 10:\t train loss : 0.6322226971945307; train accuracy : 0.9182242990654206; \n",
      " validation loss : 0.6618598759662775; validation accuracy : 0.8872180451127819\n",
      "Epoch 11:\t train loss : 0.6197158381663155; train accuracy : 0.931565558812144; \n",
      " validation loss : 0.6745017731591751; validation accuracy : 0.8796992481203008\n",
      "Epoch 12:\t train loss : 0.6066719870270864; train accuracy : 0.9449068185588675; \n",
      " validation loss : 0.6598678429043502; validation accuracy : 0.8872180451127819\n",
      "Epoch 13:\t train loss : 0.6026607425185156; train accuracy : 0.9486534313996572; \n",
      " validation loss : 0.65701921499334; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.6002812369480501; train accuracy : 0.9506166012276724; \n",
      " validation loss : 0.6481234528339505; validation accuracy : 0.9097744360902256\n",
      "Epoch 15:\t train loss : 0.588000925956066; train accuracy : 0.9634186805286733; \n",
      " validation loss : 0.6414890087690465; validation accuracy : 0.9097744360902256\n",
      "Epoch 16:\t train loss : 0.5888208511622043; train accuracy : 0.9624509207542996; \n",
      " validation loss : 0.6618998736390453; validation accuracy : 0.8796992481203008\n",
      "Epoch 17:\t train loss : 0.5867736821869772; train accuracy : 0.9645799922579218; \n",
      " validation loss : 0.6601798718074233; validation accuracy : 0.8947368421052632\n",
      "Epoch 18:\t train loss : 0.5901425789625293; train accuracy : 0.9613449095835868; \n",
      " validation loss : 0.6618672720980996; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:\t train loss : 0.5958435115753996; train accuracy : 0.9552894984239341; \n",
      " validation loss : 0.6785870027137342; validation accuracy : 0.8571428571428571\n",
      "Epoch 20:\t train loss : 0.5836517177356126; train accuracy : 0.9672482442072665; \n",
      " validation loss : 0.6479186402728354; validation accuracy : 0.8947368421052632\n",
      "Epoch 21:\t train loss : 0.5770127081023193; train accuracy : 0.9740363877675164; \n",
      " validation loss : 0.6336083618887436; validation accuracy : 0.9172932330827067\n",
      "Epoch 22:\t train loss : 0.5736909847088171; train accuracy : 0.9777830006083061; \n",
      " validation loss : 0.6101771924783711; validation accuracy : 0.9473684210526315\n",
      "Epoch 23:\t train loss : 0.5831865017634744; train accuracy : 0.9683127799590776; \n",
      " validation loss : 0.6513158078570349; validation accuracy : 0.8947368421052632\n",
      "Epoch 24:\t train loss : 0.5712980259983362; train accuracy : 0.9803544765802135; \n",
      " validation loss : 0.6485673971417615; validation accuracy : 0.9022556390977443\n",
      "Epoch 25:\t train loss : 0.569299384510927; train accuracy : 0.9820826190344523; \n",
      " validation loss : 0.636165946893504; validation accuracy : 0.9172932330827067\n",
      "Epoch 26:\t train loss : 0.5913902166121245; train accuracy : 0.9595061660122767; \n",
      " validation loss : 0.6199548142839136; validation accuracy : 0.9323308270676691\n",
      "Epoch 27:\t train loss : 0.5747682645380309; train accuracy : 0.9765525631808881; \n",
      " validation loss : 0.6388163774257675; validation accuracy : 0.9097744360902256\n",
      "Epoch 28:\t train loss : 0.574633974045956; train accuracy : 0.9764834374827186; \n",
      " validation loss : 0.6081400213531339; validation accuracy : 0.9398496240601504\n",
      "Epoch 29:\t train loss : 0.5815304117276451; train accuracy : 0.969626168224299; \n",
      " validation loss : 0.6350590340506016; validation accuracy : 0.9097744360902256\n",
      "Epoch 30:\t train loss : 0.5759066706774216; train accuracy : 0.9750179726815241; \n",
      " validation loss : 0.6312407794133695; validation accuracy : 0.9172932330827067\n",
      "Epoch 31:\t train loss : 0.5658030272733483; train accuracy : 0.9857186307581707; \n",
      " validation loss : 0.6244410268891656; validation accuracy : 0.924812030075188\n",
      "Epoch 32:\t train loss : 0.5673973429979255; train accuracy : 0.9841287397002709; \n",
      " validation loss : 0.6882633408508418; validation accuracy : 0.8571428571428571\n",
      "Epoch 33:\t train loss : 0.6300607825538845; train accuracy : 0.9196482884477133; \n",
      " validation loss : 0.7279924395390596; validation accuracy : 0.8195488721804511\n",
      "Epoch 34:\t train loss : 0.6077486035883413; train accuracy : 0.9424459437040315; \n",
      " validation loss : 0.6325041166162608; validation accuracy : 0.9172932330827067\n",
      "Epoch 35:\t train loss : 0.5907517332887237; train accuracy : 0.9599762207598297; \n",
      " validation loss : 0.6364562605580245; validation accuracy : 0.9097744360902256\n",
      "Epoch 36:\t train loss : 0.5794166666721798; train accuracy : 0.9719211414035281; \n",
      " validation loss : 0.6766886414813381; validation accuracy : 0.8721804511278195\n",
      "Epoch 37:\t train loss : 0.5793918986682753; train accuracy : 0.9716861140297517; \n",
      " validation loss : 0.626581257247757; validation accuracy : 0.924812030075188\n",
      "Epoch 38:\t train loss : 0.5777370788008434; train accuracy : 0.9734557319028923; \n",
      " validation loss : 0.680943478350793; validation accuracy : 0.8646616541353384\n",
      "Epoch 39:\t train loss : 0.5716669737705822; train accuracy : 0.9793175911076701; \n",
      " validation loss : 0.6361316532414913; validation accuracy : 0.9097744360902256\n",
      "Epoch 40:\t train loss : 0.5678557719364877; train accuracy : 0.9834789581374772; \n",
      " validation loss : 0.6302039664736905; validation accuracy : 0.924812030075188\n",
      "Epoch 41:\t train loss : 0.5686590858558929; train accuracy : 0.9830089033899242; \n",
      " validation loss : 0.6218890856086949; validation accuracy : 0.924812030075188\n",
      "Epoch 42:\t train loss : 0.5671903147057028; train accuracy : 0.9840457888624675; \n",
      " validation loss : 0.6307245705221959; validation accuracy : 0.924812030075188\n",
      "Epoch 43:\t train loss : 0.6095200488590927; train accuracy : 0.9403859978985788; \n",
      " validation loss : 0.6625107049978975; validation accuracy : 0.8796992481203008\n",
      "Epoch 44:\t train loss : 0.5822496854326046; train accuracy : 0.9682851296798097; \n",
      " validation loss : 0.6427565177490243; validation accuracy : 0.9097744360902256\n",
      "Epoch 45:\t train loss : 0.5827089530201812; train accuracy : 0.9684648564950505; \n",
      " validation loss : 0.6365124626465627; validation accuracy : 0.9172932330827067\n",
      "Epoch 46:\t train loss : 0.5739175156082933; train accuracy : 0.9773129458607532; \n",
      " validation loss : 0.6370288665152927; validation accuracy : 0.9172932330827067\n",
      "Epoch 47:\t train loss : 0.5988484737223106; train accuracy : 0.952054415749599; \n",
      " validation loss : 0.6485618035362737; validation accuracy : 0.8947368421052632\n",
      "Epoch 48:\t train loss : 0.5766796976762735; train accuracy : 0.9742299397223912; \n",
      " validation loss : 0.6149553739645376; validation accuracy : 0.9323308270676691\n",
      "Epoch 49:\t train loss : 0.5739941037151601; train accuracy : 0.9769811425095394; \n",
      " validation loss : 0.625371883068354; validation accuracy : 0.9323308270676691\n",
      "Epoch 50:\t train loss : 0.5788743568769135; train accuracy : 0.9720317425205994; \n",
      " validation loss : 0.6640511095128093; validation accuracy : 0.8796992481203008\n",
      "Epoch 51:\t train loss : 0.5716236042644641; train accuracy : 0.9794558425040093; \n",
      " validation loss : 0.634900507604207; validation accuracy : 0.924812030075188\n",
      "Epoch 52:\t train loss : 0.568012897598696; train accuracy : 0.9832577559033346; \n",
      " validation loss : 0.6438241675527493; validation accuracy : 0.9022556390977443\n",
      "Epoch 53:\t train loss : 0.5659940194186056; train accuracy : 0.9853177017087873; \n",
      " validation loss : 0.6227025487294633; validation accuracy : 0.9323308270676691\n",
      "Epoch 54:\t train loss : 0.5637309911413402; train accuracy : 0.9874882486313111; \n",
      " validation loss : 0.613240861128657; validation accuracy : 0.9323308270676691\n",
      "Epoch 55:\t train loss : 0.5887281420740966; train accuracy : 0.9622711939390588; \n",
      " validation loss : 0.6113310103086262; validation accuracy : 0.9398496240601504\n",
      "Epoch 56:\t train loss : 0.5694970802951932; train accuracy : 0.9818199413814079; \n",
      " validation loss : 0.6368792622923428; validation accuracy : 0.9022556390977443\n",
      "Epoch 57:\t train loss : 0.566870481540852; train accuracy : 0.9844467179118509; \n",
      " validation loss : 0.6288244304214329; validation accuracy : 0.924812030075188\n",
      "Epoch 58:\t train loss : 0.5648276161245454; train accuracy : 0.9864651882984018; \n",
      " validation loss : 0.650575658560231; validation accuracy : 0.8947368421052632\n",
      "Epoch 59:\t train loss : 0.5715356900770063; train accuracy : 0.9791793397113311; \n",
      " validation loss : 0.6366755288680791; validation accuracy : 0.9097744360902256\n",
      "Epoch 60:\t train loss : 0.58026944623631; train accuracy : 0.9704280263230659; \n",
      " validation loss : 0.6314109040522524; validation accuracy : 0.9172932330827067\n",
      "Epoch 61:\t train loss : 0.5725610571770011; train accuracy : 0.9785157330089034; \n",
      " validation loss : 0.6351601711522237; validation accuracy : 0.9172932330827067\n",
      "Epoch 62:\t train loss : 0.5680614080922622; train accuracy : 0.9830642039484598; \n",
      " validation loss : 0.635723121139181; validation accuracy : 0.9172932330827067\n",
      "Epoch 63:\t train loss : 0.5629493312864505; train accuracy : 0.9884698335453188; \n",
      " validation loss : 0.6220259586464787; validation accuracy : 0.924812030075188\n",
      "Epoch 64:\t train loss : 0.5869913491619608; train accuracy : 0.9639163855554941; \n",
      " validation loss : 0.6562521015331447; validation accuracy : 0.8947368421052632\n",
      "Epoch 65:\t train loss : 0.5661730902766772; train accuracy : 0.9849444229386717; \n",
      " validation loss : 0.6449205242237197; validation accuracy : 0.9022556390977443\n",
      "Epoch 66:\t train loss : 0.5614800363636882; train accuracy : 0.9900320743239507; \n",
      " validation loss : 0.6340628209836305; validation accuracy : 0.9172932330827067\n",
      "Epoch 67:\t train loss : 0.5605578078593735; train accuracy : 0.9907924570038157; \n",
      " validation loss : 0.6170960600799786; validation accuracy : 0.9323308270676691\n",
      "Epoch 68:\t train loss : 0.5616213352137879; train accuracy : 0.9897555715312725; \n",
      " validation loss : 0.6349982157211377; validation accuracy : 0.9172932330827067\n",
      "Epoch 69:\t train loss : 0.559485509880244; train accuracy : 0.9918569927556268; \n",
      " validation loss : 0.6358170979511455; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70:\t train loss : 0.5598049819003947; train accuracy : 0.9915804899629486; \n",
      " validation loss : 0.6058912887127177; validation accuracy : 0.9398496240601504\n",
      "Epoch 71:\t train loss : 0.5595702320659851; train accuracy : 0.9917602167781895; \n",
      " validation loss : 0.6048674322863786; validation accuracy : 0.9548872180451128\n",
      "Epoch 72:\t train loss : 0.5616664366395331; train accuracy : 0.9894928938782281; \n",
      " validation loss : 0.6206693608503357; validation accuracy : 0.9323308270676691\n",
      "Epoch 73:\t train loss : 0.5614271503430269; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.6440369311008094; validation accuracy : 0.9022556390977443\n",
      "Epoch 74:\t train loss : 0.5576649772313883; train accuracy : 0.9937786871647404; \n",
      " validation loss : 0.6246319753057799; validation accuracy : 0.9323308270676691\n",
      "Epoch 75:\t train loss : 0.5644003803383271; train accuracy : 0.9867969916496157; \n",
      " validation loss : 0.6392976130325078; validation accuracy : 0.9097744360902256\n",
      "Epoch 76:\t train loss : 0.5590905228598536; train accuracy : 0.9922440966653763; \n",
      " validation loss : 0.6185198726807023; validation accuracy : 0.9323308270676691\n",
      "Epoch 77:\t train loss : 0.5607638896591582; train accuracy : 0.990598905048941; \n",
      " validation loss : 0.6252787175782446; validation accuracy : 0.924812030075188\n",
      "Epoch 78:\t train loss : 0.5614763555184602; train accuracy : 0.9898108720898081; \n",
      " validation loss : 0.6157839351453857; validation accuracy : 0.9323308270676691\n",
      "Epoch 79:\t train loss : 0.5614657484319693; train accuracy : 0.9898799977879776; \n",
      " validation loss : 0.6568866938416642; validation accuracy : 0.8872180451127819\n",
      "Epoch 80:\t train loss : 0.5634451665923452; train accuracy : 0.987820051982525; \n",
      " validation loss : 0.6215548963572838; validation accuracy : 0.924812030075188\n",
      "Epoch 81:\t train loss : 0.5602244790249512; train accuracy : 0.9912348614721008; \n",
      " validation loss : 0.6357822619664537; validation accuracy : 0.9097744360902256\n",
      "Epoch 82:\t train loss : 0.5618302289433436; train accuracy : 0.989368467621523; \n",
      " validation loss : 0.6286738970047757; validation accuracy : 0.924812030075188\n",
      "Epoch 83:\t train loss : 0.5607448740638771; train accuracy : 0.990598905048941; \n",
      " validation loss : 0.6274458803152425; validation accuracy : 0.924812030075188\n",
      "Epoch 84:\t train loss : 0.5647386802136074; train accuracy : 0.9866172648343748; \n",
      " validation loss : 0.6414262788718261; validation accuracy : 0.9097744360902256\n",
      "Epoch 85:\t train loss : 0.5650057296574736; train accuracy : 0.9864098877398662; \n",
      " validation loss : 0.6072271287349088; validation accuracy : 0.9473684210526315\n",
      "Epoch 86:\t train loss : 0.5600284547607437; train accuracy : 0.9913454625891721; \n",
      " validation loss : 0.6137592226263339; validation accuracy : 0.9398496240601504\n",
      "Epoch 87:\t train loss : 0.5599712568145179; train accuracy : 0.9914007631477078; \n",
      " validation loss : 0.6332922451277859; validation accuracy : 0.9172932330827067\n",
      "Epoch 88:\t train loss : 0.5701450154374065; train accuracy : 0.980879831886302; \n",
      " validation loss : 0.6647989496908739; validation accuracy : 0.8872180451127819\n",
      "Epoch 89:\t train loss : 0.5694819787075761; train accuracy : 0.9817093402643366; \n",
      " validation loss : 0.6176438710122517; validation accuracy : 0.9323308270676691\n",
      "Epoch 90:\t train loss : 0.5632573809578946; train accuracy : 0.9879859536581319; \n",
      " validation loss : 0.588986040357058; validation accuracy : 0.9624060150375939\n",
      "Epoch 91:\t train loss : 0.5624441514944866; train accuracy : 0.9888154620361665; \n",
      " validation loss : 0.6763454804940381; validation accuracy : 0.8721804511278195\n",
      "Epoch 92:\t train loss : 0.5628362200119095; train accuracy : 0.9882486313111762; \n",
      " validation loss : 0.6048403323567566; validation accuracy : 0.9473684210526315\n",
      "Epoch 93:\t train loss : 0.5614723956403191; train accuracy : 0.9897693966709064; \n",
      " validation loss : 0.6242116495384816; validation accuracy : 0.924812030075188\n",
      "Epoch 94:\t train loss : 0.5589190749289972; train accuracy : 0.9925620748769562; \n",
      " validation loss : 0.6193627981544684; validation accuracy : 0.9323308270676691\n",
      "Epoch 95:\t train loss : 0.5578324034855058; train accuracy : 0.9935713100702317; \n",
      " validation loss : 0.6400320126726304; validation accuracy : 0.9097744360902256\n",
      "Epoch 96:\t train loss : 0.5690487480227446; train accuracy : 0.9820411436155505; \n",
      " validation loss : 0.6359242591209945; validation accuracy : 0.9172932330827067\n",
      "Epoch 97:\t train loss : 0.5619477166779139; train accuracy : 0.9892993419233534; \n",
      " validation loss : 0.6227688286667851; validation accuracy : 0.924812030075188\n",
      "Epoch 98:\t train loss : 0.5626704736226917; train accuracy : 0.9886495603605596; \n",
      " validation loss : 0.6306662332148936; validation accuracy : 0.924812030075188\n",
      "Epoch 99:\t train loss : 0.5593016698720206; train accuracy : 0.9920090692915998; \n",
      " validation loss : 0.632774276280843; validation accuracy : 0.9172932330827067\n",
      "Epoch 100:\t train loss : 0.5602959824577868; train accuracy : 0.9909307084001548; \n",
      " validation loss : 0.6351284206599394; validation accuracy : 0.9172932330827067\n",
      "Epoch 101:\t train loss : 0.5597234805115696; train accuracy : 0.991677265940386; \n",
      " validation loss : 0.6571421986710498; validation accuracy : 0.8947368421052632\n",
      "Epoch 102:\t train loss : 0.5633181996464827; train accuracy : 0.9877371011447216; \n",
      " validation loss : 0.7020675366153568; validation accuracy : 0.8421052631578947\n",
      "Epoch 103:\t train loss : 0.6003320117109762; train accuracy : 0.9504230492727976; \n",
      " validation loss : 0.6343075391984793; validation accuracy : 0.9172932330827067\n",
      "Epoch 104:\t train loss : 0.5693913341504281; train accuracy : 0.9817508156832384; \n",
      " validation loss : 0.627911168444653; validation accuracy : 0.924812030075188\n",
      "Epoch 105:\t train loss : 0.5615486595366446; train accuracy : 0.9897970469501742; \n",
      " validation loss : 0.6251368252791706; validation accuracy : 0.924812030075188\n",
      "Epoch 106:\t train loss : 0.5606481486307707; train accuracy : 0.9906403804678428; \n",
      " validation loss : 0.6426422228359844; validation accuracy : 0.9022556390977443\n",
      "Epoch 107:\t train loss : 0.5575505558195827; train accuracy : 0.9938892882818117; \n",
      " validation loss : 0.6418485583112845; validation accuracy : 0.9097744360902256\n",
      "Epoch 108:\t train loss : 0.557889203755038; train accuracy : 0.9934054083946248; \n",
      " validation loss : 0.6206832781429727; validation accuracy : 0.9323308270676691\n",
      "Epoch 109:\t train loss : 0.5590816327156438; train accuracy : 0.9922440966653763; \n",
      " validation loss : 0.6088016370696813; validation accuracy : 0.9473684210526315\n",
      "Epoch 110:\t train loss : 0.5564064229569726; train accuracy : 0.9948432229165515; \n",
      " validation loss : 0.6190350217818432; validation accuracy : 0.9323308270676691\n",
      "Epoch 111:\t train loss : 0.5639905754859189; train accuracy : 0.9871702704197313; \n",
      " validation loss : 0.6098040228958229; validation accuracy : 0.9398496240601504\n",
      "Epoch 112:\t train loss : 0.5615668768427303; train accuracy : 0.989672620693469; \n",
      " validation loss : 0.6157985547728763; validation accuracy : 0.9398496240601504\n",
      "Epoch 113:\t train loss : 0.5572622199161483; train accuracy : 0.9941104905159542; \n",
      " validation loss : 0.6309768085759212; validation accuracy : 0.9172932330827067\n",
      "Epoch 114:\t train loss : 0.5570569799885668; train accuracy : 0.9942625670519272; \n",
      " validation loss : 0.6327118178441937; validation accuracy : 0.9172932330827067\n",
      "Epoch 115:\t train loss : 0.5565585860517455; train accuracy : 0.9948017474976497; \n",
      " validation loss : 0.6061601696768447; validation accuracy : 0.9473684210526315\n",
      "Epoch 116:\t train loss : 0.5557448158009706; train accuracy : 0.9956727312945861; \n",
      " validation loss : 0.6422475071796654; validation accuracy : 0.9097744360902256\n",
      "Epoch 117:\t train loss : 0.5557781531488984; train accuracy : 0.9956589061549521; \n",
      " validation loss : 0.6062600535198; validation accuracy : 0.9398496240601504\n",
      "Epoch 118:\t train loss : 0.5561112536598926; train accuracy : 0.995216501686667; \n",
      " validation loss : 0.595726896173671; validation accuracy : 0.9548872180451128\n",
      "Epoch 119:\t train loss : 0.5832258246157391; train accuracy : 0.9673450201847039; \n",
      " validation loss : 0.6449878802220359; validation accuracy : 0.9022556390977443\n",
      "Epoch 120:\t train loss : 0.578756080254664; train accuracy : 0.9720593927998673; \n",
      " validation loss : 0.6328416248739326; validation accuracy : 0.9172932330827067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121:\t train loss : 0.5773901037594299; train accuracy : 0.9734004313443566; \n",
      " validation loss : 0.6311566566649723; validation accuracy : 0.924812030075188\n",
      "Epoch 122:\t train loss : 0.5732709538877482; train accuracy : 0.9778659514461097; \n",
      " validation loss : 0.6540951912353961; validation accuracy : 0.8947368421052632\n",
      "Epoch 123:\t train loss : 0.5618225755024704; train accuracy : 0.989368467621523; \n",
      " validation loss : 0.6543853448056309; validation accuracy : 0.8947368421052632\n",
      "Epoch 124:\t train loss : 0.5614289970362416; train accuracy : 0.9897970469501742; \n",
      " validation loss : 0.6307793304649703; validation accuracy : 0.924812030075188\n",
      "Epoch 125:\t train loss : 0.5582053829290435; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.6016459946673478; validation accuracy : 0.9473684210526315\n",
      "Epoch 126:\t train loss : 0.5597326559304833; train accuracy : 0.9915943151025826; \n",
      " validation loss : 0.6522136406902511; validation accuracy : 0.8947368421052632\n",
      "Epoch 127:\t train loss : 0.5597979578977805; train accuracy : 0.9915666648233147; \n",
      " validation loss : 0.6111670680569342; validation accuracy : 0.9398496240601504\n",
      "Epoch 128:\t train loss : 0.5570015556422564; train accuracy : 0.9943455178897307; \n",
      " validation loss : 0.615285327909368; validation accuracy : 0.9398496240601504\n",
      "Epoch 129:\t train loss : 0.5611357457071859; train accuracy : 0.9901565005806559; \n",
      " validation loss : 0.6116173806676143; validation accuracy : 0.9398496240601504\n",
      "Epoch 130:\t train loss : 0.557767604274488; train accuracy : 0.9935574849305978; \n",
      " validation loss : 0.626329109432028; validation accuracy : 0.9172932330827067\n",
      "Epoch 131:\t train loss : 0.5560518179885294; train accuracy : 0.9953962285019079; \n",
      " validation loss : 0.6177187891159068; validation accuracy : 0.9323308270676691\n",
      "Epoch 132:\t train loss : 0.5578401456951427; train accuracy : 0.9935436597909639; \n",
      " validation loss : 0.6312147675856112; validation accuracy : 0.9172932330827067\n",
      "Epoch 133:\t train loss : 0.5561409363989376; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6342648115494394; validation accuracy : 0.9172932330827067\n",
      "Epoch 134:\t train loss : 0.565342002845239; train accuracy : 0.9858430570148758; \n",
      " validation loss : 0.6546349706357589; validation accuracy : 0.8947368421052632\n",
      "Epoch 135:\t train loss : 0.556529639197311; train accuracy : 0.9948985234750871; \n",
      " validation loss : 0.6265965011584796; validation accuracy : 0.924812030075188\n",
      "Epoch 136:\t train loss : 0.5565121421323138; train accuracy : 0.994912348614721; \n",
      " validation loss : 0.6434666762940028; validation accuracy : 0.9097744360902256\n",
      "Epoch 137:\t train loss : 0.5582916010026959; train accuracy : 0.9930183044848753; \n",
      " validation loss : 0.6337634436818614; validation accuracy : 0.9172932330827067\n",
      "Epoch 138:\t train loss : 0.5584686585512173; train accuracy : 0.9929768290659735; \n",
      " validation loss : 0.5865456725337314; validation accuracy : 0.9699248120300752\n",
      "Epoch 139:\t train loss : 0.5567297615402259; train accuracy : 0.9946220206824089; \n",
      " validation loss : 0.6226297124952543; validation accuracy : 0.9323308270676691\n",
      "Epoch 140:\t train loss : 0.5580481788136828; train accuracy : 0.9933501078360891; \n",
      " validation loss : 0.6302505682025467; validation accuracy : 0.9172932330827067\n",
      "Epoch 141:\t train loss : 0.563632021661499; train accuracy : 0.987667975446552; \n",
      " validation loss : 0.6262659857280094; validation accuracy : 0.924812030075188\n",
      "Epoch 142:\t train loss : 0.5664028775078404; train accuracy : 0.9849444229386717; \n",
      " validation loss : 0.6253272403445227; validation accuracy : 0.924812030075188\n",
      "Epoch 143:\t train loss : 0.5696872420379832; train accuracy : 0.9813913620527568; \n",
      " validation loss : 0.6441827305989071; validation accuracy : 0.9097744360902256\n",
      "Epoch 144:\t train loss : 0.5614474600430065; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.6569123341891331; validation accuracy : 0.8947368421052632\n",
      "Epoch 145:\t train loss : 0.5616880958821021; train accuracy : 0.9897279212520046; \n",
      " validation loss : 0.6638210714410288; validation accuracy : 0.8872180451127819\n",
      "Epoch 146:\t train loss : 0.5745803664498043; train accuracy : 0.976718464856495; \n",
      " validation loss : 0.6201256109274307; validation accuracy : 0.9323308270676691\n",
      "Epoch 147:\t train loss : 0.5632783219240779; train accuracy : 0.9880274290770337; \n",
      " validation loss : 0.6179179687321078; validation accuracy : 0.9323308270676691\n",
      "Epoch 148:\t train loss : 0.5602899620971508; train accuracy : 0.9911519106342974; \n",
      " validation loss : 0.6174945696055185; validation accuracy : 0.9323308270676691\n",
      "Epoch 149:\t train loss : 0.5631911517102346; train accuracy : 0.9877647514239893; \n",
      " validation loss : 0.6813741447184463; validation accuracy : 0.8721804511278195\n",
      "Epoch 150:\t train loss : 0.5578963024115121; train accuracy : 0.9934054083946248; \n",
      " validation loss : 0.6218690709927504; validation accuracy : 0.9323308270676691\n",
      "Epoch 151:\t train loss : 0.5559296015244661; train accuracy : 0.9955206547586131; \n",
      " validation loss : 0.6145011085749328; validation accuracy : 0.9398496240601504\n",
      "Epoch 152:\t train loss : 0.5559243236775936; train accuracy : 0.9954930044793452; \n",
      " validation loss : 0.6310691801977362; validation accuracy : 0.9172932330827067\n",
      "Epoch 153:\t train loss : 0.5579375829636715; train accuracy : 0.9933362826964552; \n",
      " validation loss : 0.5963547340340243; validation accuracy : 0.9548872180451128\n",
      "Epoch 154:\t train loss : 0.5591088155350781; train accuracy : 0.9922993972239119; \n",
      " validation loss : 0.6212314517103034; validation accuracy : 0.9323308270676691\n",
      "Epoch 155:\t train loss : 0.5567854262641662; train accuracy : 0.994608195542775; \n",
      " validation loss : 0.6279016688282492; validation accuracy : 0.924812030075188\n",
      "Epoch 156:\t train loss : 0.5562263627185078; train accuracy : 0.9951473759884975; \n",
      " validation loss : 0.634242909036381; validation accuracy : 0.9172932330827067\n",
      "Epoch 157:\t train loss : 0.5555322122577697; train accuracy : 0.9958939335287287; \n",
      " validation loss : 0.6239276953893755; validation accuracy : 0.924812030075188\n",
      "Epoch 158:\t train loss : 0.555151460148043; train accuracy : 0.9962395620195764; \n",
      " validation loss : 0.6342188737320584; validation accuracy : 0.9172932330827067\n",
      "Epoch 159:\t train loss : 0.55697770188863; train accuracy : 0.9944699441464359; \n",
      " validation loss : 0.6133100400508016; validation accuracy : 0.9398496240601504\n",
      "Epoch 160:\t train loss : 0.5570675627714184; train accuracy : 0.9942349167726594; \n",
      " validation loss : 0.6191927948046976; validation accuracy : 0.9323308270676691\n",
      "Epoch 161:\t train loss : 0.5585326321289688; train accuracy : 0.9928385776696345; \n",
      " validation loss : 0.6339371156041613; validation accuracy : 0.9172932330827067\n",
      "Epoch 162:\t train loss : 0.5574209300993382; train accuracy : 0.9940690150970525; \n",
      " validation loss : 0.6196971882702331; validation accuracy : 0.9323308270676691\n",
      "Epoch 163:\t train loss : 0.5564562492383573; train accuracy : 0.9948293977769175; \n",
      " validation loss : 0.6347367706257246; validation accuracy : 0.9172932330827067\n",
      "Epoch 164:\t train loss : 0.5755210517322724; train accuracy : 0.975806005640657; \n",
      " validation loss : 0.6407864666776232; validation accuracy : 0.9097744360902256\n",
      "Epoch 165:\t train loss : 0.5876634105617985; train accuracy : 0.9630868771774594; \n",
      " validation loss : 0.6789574776923951; validation accuracy : 0.8721804511278195\n",
      "Epoch 166:\t train loss : 0.5668572401303726; train accuracy : 0.9843637670740475; \n",
      " validation loss : 0.632474737521508; validation accuracy : 0.9172932330827067\n",
      "Epoch 167:\t train loss : 0.5689751036547102; train accuracy : 0.9823591218271305; \n",
      " validation loss : 0.6327828393817299; validation accuracy : 0.9172932330827067\n",
      "Epoch 168:\t train loss : 0.5590435378184326; train accuracy : 0.9922302715257424; \n",
      " validation loss : 0.643070668432738; validation accuracy : 0.9097744360902256\n",
      "Epoch 169:\t train loss : 0.5569255898244606; train accuracy : 0.9944422938671681; \n",
      " validation loss : 0.6333855875415514; validation accuracy : 0.9172932330827067\n",
      "Epoch 170:\t train loss : 0.5578158537109834; train accuracy : 0.9935713100702317; \n",
      " validation loss : 0.6264644440737973; validation accuracy : 0.924812030075188\n",
      "Epoch 171:\t train loss : 0.5564966248366864; train accuracy : 0.9949538240336228; \n",
      " validation loss : 0.602331667767191; validation accuracy : 0.9473684210526315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172:\t train loss : 0.5556360423875526; train accuracy : 0.9957833324116574; \n",
      " validation loss : 0.6402633460967245; validation accuracy : 0.9097744360902256\n",
      "Epoch 173:\t train loss : 0.5586018328975507; train accuracy : 0.9928524028092683; \n",
      " validation loss : 0.6191552448940664; validation accuracy : 0.9323308270676691\n",
      "Epoch 174:\t train loss : 0.555775872886769; train accuracy : 0.9957142067134878; \n",
      " validation loss : 0.5922908149880106; validation accuracy : 0.9548872180451128\n",
      "Epoch 175:\t train loss : 0.5566910255025909; train accuracy : 0.9945805452635071; \n",
      " validation loss : 0.6224093262476804; validation accuracy : 0.924812030075188\n",
      "Epoch 176:\t train loss : 0.5792429573126894; train accuracy : 0.9716999391693856; \n",
      " validation loss : 0.6297504702478509; validation accuracy : 0.924812030075188\n",
      "Epoch 177:\t train loss : 0.5573344331613305; train accuracy : 0.9939445888403473; \n",
      " validation loss : 0.6207233256367831; validation accuracy : 0.9323308270676691\n",
      "Epoch 178:\t train loss : 0.5567917992785546; train accuracy : 0.9945528949842394; \n",
      " validation loss : 0.6189649409129672; validation accuracy : 0.9323308270676691\n",
      "Epoch 179:\t train loss : 0.5564439367499091; train accuracy : 0.9950920754299618; \n",
      " validation loss : 0.5922774358129985; validation accuracy : 0.9624060150375939\n",
      "Epoch 180:\t train loss : 0.5565543646832476; train accuracy : 0.9948155726372836; \n",
      " validation loss : 0.6405470593668307; validation accuracy : 0.9022556390977443\n",
      "Epoch 181:\t train loss : 0.5550105570968082; train accuracy : 0.9964054636951833; \n",
      " validation loss : 0.6070312606912839; validation accuracy : 0.9473684210526315\n",
      "Epoch 182:\t train loss : 0.5610128270754098; train accuracy : 0.9904330033733341; \n",
      " validation loss : 0.6178484373780023; validation accuracy : 0.9323308270676691\n",
      "Epoch 183:\t train loss : 0.5570633217720539; train accuracy : 0.9943178676104628; \n",
      " validation loss : 0.641817150421195; validation accuracy : 0.9097744360902256\n",
      "Epoch 184:\t train loss : 0.5581283698701832; train accuracy : 0.9932809821379196; \n",
      " validation loss : 0.6263190628007831; validation accuracy : 0.924812030075188\n",
      "Epoch 185:\t train loss : 0.5571835553778769; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.6352259637075747; validation accuracy : 0.9172932330827067\n",
      "Epoch 186:\t train loss : 0.5645487299700628; train accuracy : 0.9867278659514461; \n",
      " validation loss : 0.6197260854678793; validation accuracy : 0.9323308270676691\n",
      "Epoch 187:\t train loss : 0.5568194988474187; train accuracy : 0.9945805452635071; \n",
      " validation loss : 0.6265707325672923; validation accuracy : 0.924812030075188\n",
      "Epoch 188:\t train loss : 0.5786745642876885; train accuracy : 0.9722805950340099; \n",
      " validation loss : 0.6335516800570786; validation accuracy : 0.9172932330827067\n",
      "Early stopping at epoch 188\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5584686585512173; Train accuracy : 0.9929768290659735; \n",
      " Validation loss : 0.5865456725337314; Validation accuracy : 0.9699248120300752\n",
      "------------------------------ Let's train model 19 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8892377478071917; train accuracy : 0.6479289940828402; \n",
      " validation loss : 0.765279447484205; validation accuracy : 0.7819548872180451\n",
      "Epoch 2:\t train loss : 0.7560967217957917; train accuracy : 0.7900099541005364; \n",
      " validation loss : 0.7787271408326926; validation accuracy : 0.7744360902255639\n",
      "Epoch 3:\t train loss : 0.7170864988901676; train accuracy : 0.8314024221644639; \n",
      " validation loss : 0.7287632996316421; validation accuracy : 0.8270676691729323\n",
      "Epoch 4:\t train loss : 0.6944100287156894; train accuracy : 0.8539927003262733; \n",
      " validation loss : 0.7239722369530802; validation accuracy : 0.8195488721804511\n",
      "Epoch 5:\t train loss : 0.6627902987585953; train accuracy : 0.8869518332135155; \n",
      " validation loss : 0.7341276351211391; validation accuracy : 0.8120300751879699\n",
      "Epoch 6:\t train loss : 0.6514722914361053; train accuracy : 0.8984819996681966; \n",
      " validation loss : 0.7195222356651368; validation accuracy : 0.8195488721804511\n",
      "Epoch 7:\t train loss : 0.6296687439873075; train accuracy : 0.92140408118122; \n",
      " validation loss : 0.6916382636012315; validation accuracy : 0.8646616541353384\n",
      "Epoch 8:\t train loss : 0.613701854256983; train accuracy : 0.9377177459492341; \n",
      " validation loss : 0.6805398201397572; validation accuracy : 0.8571428571428571\n",
      "Epoch 9:\t train loss : 0.606822576457077; train accuracy : 0.944975944257037; \n",
      " validation loss : 0.7279075371148227; validation accuracy : 0.8195488721804511\n",
      "Epoch 10:\t train loss : 0.597455613952011; train accuracy : 0.9538378587623735; \n",
      " validation loss : 0.6633842259868037; validation accuracy : 0.8947368421052632\n",
      "Epoch 11:\t train loss : 0.594662634173427; train accuracy : 0.9570452911574406; \n",
      " validation loss : 0.715465116135159; validation accuracy : 0.8345864661654135\n",
      "Epoch 12:\t train loss : 0.6040229491151711; train accuracy : 0.9473815185533374; \n",
      " validation loss : 0.708272569179852; validation accuracy : 0.8421052631578947\n",
      "Epoch 13:\t train loss : 0.6009315893321875; train accuracy : 0.9502433224575568; \n",
      " validation loss : 0.6875825783194005; validation accuracy : 0.8571428571428571\n",
      "Epoch 14:\t train loss : 0.5868300851744793; train accuracy : 0.9648150196316982; \n",
      " validation loss : 0.6713633426209787; validation accuracy : 0.8721804511278195\n",
      "Epoch 15:\t train loss : 0.5781275396918721; train accuracy : 0.9734695570425261; \n",
      " validation loss : 0.6684784390382528; validation accuracy : 0.8796992481203008\n",
      "Epoch 16:\t train loss : 0.5764412059588621; train accuracy : 0.9753636011723719; \n",
      " validation loss : 0.6448656646171949; validation accuracy : 0.9022556390977443\n",
      "Epoch 17:\t train loss : 0.5729550603849073; train accuracy : 0.9783498313332964; \n",
      " validation loss : 0.6620963797843463; validation accuracy : 0.8872180451127819\n",
      "Epoch 18:\t train loss : 0.5719327776791309; train accuracy : 0.9798291212741249; \n",
      " validation loss : 0.6709401811448452; validation accuracy : 0.8721804511278195\n",
      "Epoch 19:\t train loss : 0.5773055772578062; train accuracy : 0.9742022894431234; \n",
      " validation loss : 0.6500162788140763; validation accuracy : 0.8947368421052632\n",
      "Epoch 20:\t train loss : 0.577772510326134; train accuracy : 0.9734972073217939; \n",
      " validation loss : 0.6340450566003815; validation accuracy : 0.924812030075188\n",
      "Epoch 21:\t train loss : 0.5942109674672829; train accuracy : 0.9567134878062269; \n",
      " validation loss : 0.6916691426449617; validation accuracy : 0.8646616541353384\n",
      "Epoch 22:\t train loss : 0.584527648561793; train accuracy : 0.9665155118066693; \n",
      " validation loss : 0.6863334317272388; validation accuracy : 0.8571428571428571\n",
      "Epoch 23:\t train loss : 0.5823366328766505; train accuracy : 0.969031687220041; \n",
      " validation loss : 0.6658564014116729; validation accuracy : 0.8872180451127819\n",
      "Epoch 24:\t train loss : 0.5671286871671402; train accuracy : 0.984432892772217; \n",
      " validation loss : 0.6686103852127693; validation accuracy : 0.8796992481203008\n",
      "Epoch 25:\t train loss : 0.5610264756069396; train accuracy : 0.9905159542111376; \n",
      " validation loss : 0.636337741875288; validation accuracy : 0.9172932330827067\n",
      "Epoch 26:\t train loss : 0.560838390913911; train accuracy : 0.9906127301885749; \n",
      " validation loss : 0.6720874520363289; validation accuracy : 0.8721804511278195\n",
      "Epoch 27:\t train loss : 0.5584761180150918; train accuracy : 0.9929906542056075; \n",
      " validation loss : 0.6342340693027124; validation accuracy : 0.9172932330827067\n",
      "Epoch 28:\t train loss : 0.5580233764935967; train accuracy : 0.993820162583642; \n",
      " validation loss : 0.6199982616744304; validation accuracy : 0.9323308270676691\n",
      "Epoch 29:\t train loss : 0.5601964746153869; train accuracy : 0.9914837139855113; \n",
      " validation loss : 0.6620143257257075; validation accuracy : 0.8872180451127819\n",
      "Epoch 30:\t train loss : 0.5608759174366599; train accuracy : 0.9905574296300392; \n",
      " validation loss : 0.661584851634205; validation accuracy : 0.8872180451127819\n",
      "Epoch 31:\t train loss : 0.5593310994131122; train accuracy : 0.9922440966653763; \n",
      " validation loss : 0.6295965864676311; validation accuracy : 0.924812030075188\n",
      "Epoch 32:\t train loss : 0.5603987996897454; train accuracy : 0.9912210363324669; \n",
      " validation loss : 0.6423013997391257; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:\t train loss : 0.5646985670839738; train accuracy : 0.986603439694741; \n",
      " validation loss : 0.6577637689085852; validation accuracy : 0.8947368421052632\n",
      "Epoch 34:\t train loss : 0.5664546342781678; train accuracy : 0.9845849693081901; \n",
      " validation loss : 0.6473609883764887; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.6469046292921309; train accuracy : 0.901965934855942; \n",
      " validation loss : 0.7180137477149835; validation accuracy : 0.8345864661654135\n",
      "Epoch 36:\t train loss : 0.6152621492658609; train accuracy : 0.9352015705358624; \n",
      " validation loss : 0.6364045270072125; validation accuracy : 0.9172932330827067\n",
      "Epoch 37:\t train loss : 0.5796246830551002; train accuracy : 0.9714096112370735; \n",
      " validation loss : 0.6536527760347429; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.5692949585408249; train accuracy : 0.9825526737820052; \n",
      " validation loss : 0.6097101256861951; validation accuracy : 0.9398496240601504\n",
      "Epoch 39:\t train loss : 0.5734139415867219; train accuracy : 0.9776862246308687; \n",
      " validation loss : 0.6734133627231876; validation accuracy : 0.8721804511278195\n",
      "Epoch 40:\t train loss : 0.5658708896241443; train accuracy : 0.9857877564563402; \n",
      " validation loss : 0.622590038256768; validation accuracy : 0.9323308270676691\n",
      "Epoch 41:\t train loss : 0.5631644618676372; train accuracy : 0.9883177570093458; \n",
      " validation loss : 0.6618841903483522; validation accuracy : 0.8872180451127819\n",
      "Epoch 42:\t train loss : 0.5664795818974173; train accuracy : 0.9848752972405022; \n",
      " validation loss : 0.6686010260331952; validation accuracy : 0.8796992481203008\n",
      "Epoch 43:\t train loss : 0.5618377724107262; train accuracy : 0.9896173201349333; \n",
      " validation loss : 0.6137926589915612; validation accuracy : 0.9398496240601504\n",
      "Epoch 44:\t train loss : 0.560781169634389; train accuracy : 0.9907786318641818; \n",
      " validation loss : 0.6397795483165258; validation accuracy : 0.9097744360902256\n",
      "Epoch 45:\t train loss : 0.5647668358905731; train accuracy : 0.9864098877398662; \n",
      " validation loss : 0.6564733649022079; validation accuracy : 0.8947368421052632\n",
      "Epoch 46:\t train loss : 0.5584002590890897; train accuracy : 0.9931150804623127; \n",
      " validation loss : 0.6354083484874238; validation accuracy : 0.9097744360902256\n",
      "Epoch 47:\t train loss : 0.5594047719588544; train accuracy : 0.9918846430348947; \n",
      " validation loss : 0.6243755191830161; validation accuracy : 0.924812030075188\n",
      "Epoch 48:\t train loss : 0.5770325107575067; train accuracy : 0.9742022894431234; \n",
      " validation loss : 0.636493548078706; validation accuracy : 0.9097744360902256\n",
      "Epoch 49:\t train loss : 0.5750125687579117; train accuracy : 0.9761654592711386; \n",
      " validation loss : 0.6932192427093667; validation accuracy : 0.8571428571428571\n",
      "Epoch 50:\t train loss : 0.5941555810129205; train accuracy : 0.9559807554056295; \n",
      " validation loss : 0.6696164569170372; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5699509724891363; train accuracy : 0.9810733838411768; \n",
      " validation loss : 0.6510206496711439; validation accuracy : 0.9022556390977443\n",
      "Epoch 52:\t train loss : 0.5733585577946508; train accuracy : 0.977810650887574; \n",
      " validation loss : 0.678068943064246; validation accuracy : 0.8721804511278195\n",
      "Epoch 53:\t train loss : 0.5669195032451863; train accuracy : 0.9846402698667257; \n",
      " validation loss : 0.6475657161153797; validation accuracy : 0.9022556390977443\n",
      "Epoch 54:\t train loss : 0.559561624443754; train accuracy : 0.991981419012332; \n",
      " validation loss : 0.6542444284177389; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5636959910696899; train accuracy : 0.9877232760050877; \n",
      " validation loss : 0.6558766394265131; validation accuracy : 0.8947368421052632\n",
      "Epoch 56:\t train loss : 0.5588766900615787; train accuracy : 0.992589725156224; \n",
      " validation loss : 0.6609849888802567; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5620445556562811; train accuracy : 0.9893269922026212; \n",
      " validation loss : 0.6292735923918524; validation accuracy : 0.924812030075188\n",
      "Epoch 58:\t train loss : 0.5646672155962976; train accuracy : 0.9867002156721782; \n",
      " validation loss : 0.6684732166073558; validation accuracy : 0.8796992481203008\n",
      "Epoch 59:\t train loss : 0.5637659669794908; train accuracy : 0.9874744234916772; \n",
      " validation loss : 0.6378066217055296; validation accuracy : 0.9097744360902256\n",
      "Epoch 60:\t train loss : 0.56157075840617; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.649627869274326; validation accuracy : 0.9022556390977443\n",
      "Epoch 61:\t train loss : 0.5574852604267149; train accuracy : 0.9941104905159542; \n",
      " validation loss : 0.6686863218478176; validation accuracy : 0.8796992481203008\n",
      "Epoch 62:\t train loss : 0.5582242973773778; train accuracy : 0.993377758115357; \n",
      " validation loss : 0.6790408030469717; validation accuracy : 0.8721804511278195\n",
      "Epoch 63:\t train loss : 0.5597463469275382; train accuracy : 0.9916357905214843; \n",
      " validation loss : 0.6504645770661901; validation accuracy : 0.9022556390977443\n",
      "Epoch 64:\t train loss : 0.5740845825398669; train accuracy : 0.9768981916717359; \n",
      " validation loss : 0.6861039007765938; validation accuracy : 0.8646616541353384\n",
      "Epoch 65:\t train loss : 0.570357884288743; train accuracy : 0.9809766078637394; \n",
      " validation loss : 0.6827274711847375; validation accuracy : 0.8721804511278195\n",
      "Epoch 66:\t train loss : 0.5619391833501572; train accuracy : 0.989520544157496; \n",
      " validation loss : 0.641763678634932; validation accuracy : 0.9022556390977443\n",
      "Epoch 67:\t train loss : 0.562606168898823; train accuracy : 0.9888016368965327; \n",
      " validation loss : 0.6900261532044166; validation accuracy : 0.8571428571428571\n",
      "Epoch 68:\t train loss : 0.5656162562917542; train accuracy : 0.9858707072941437; \n",
      " validation loss : 0.6909430420191373; validation accuracy : 0.8571428571428571\n",
      "Epoch 69:\t train loss : 0.5575965355097464; train accuracy : 0.9938616380025438; \n",
      " validation loss : 0.6697425419231705; validation accuracy : 0.8796992481203008\n",
      "Epoch 70:\t train loss : 0.5565137441846825; train accuracy : 0.9948846983354531; \n",
      " validation loss : 0.656252564137041; validation accuracy : 0.8947368421052632\n",
      "Epoch 71:\t train loss : 0.5572149427607908; train accuracy : 0.9942210916330255; \n",
      " validation loss : 0.6475673944204017; validation accuracy : 0.9022556390977443\n",
      "Epoch 72:\t train loss : 0.5595563273184688; train accuracy : 0.9916219653818503; \n",
      " validation loss : 0.66251684812923; validation accuracy : 0.8872180451127819\n",
      "Epoch 73:\t train loss : 0.5555547087030909; train accuracy : 0.9959768843665321; \n",
      " validation loss : 0.6634457037012786; validation accuracy : 0.8872180451127819\n",
      "Epoch 74:\t train loss : 0.558972020485762; train accuracy : 0.9921749709672067; \n",
      " validation loss : 0.6731723113597121; validation accuracy : 0.8721804511278195\n",
      "Epoch 75:\t train loss : 0.5590938936840276; train accuracy : 0.9923408726428137; \n",
      " validation loss : 0.6383435950100598; validation accuracy : 0.9097744360902256\n",
      "Epoch 76:\t train loss : 0.5558334189311377; train accuracy : 0.9956036055964165; \n",
      " validation loss : 0.6346576160286211; validation accuracy : 0.9172932330827067\n",
      "Epoch 77:\t train loss : 0.5557652133824422; train accuracy : 0.9956174307360505; \n",
      " validation loss : 0.6473616389587519; validation accuracy : 0.9097744360902256\n",
      "Epoch 78:\t train loss : 0.557449752512095; train accuracy : 0.9939169385610794; \n",
      " validation loss : 0.6859965561606024; validation accuracy : 0.8646616541353384\n",
      "Epoch 79:\t train loss : 0.556981767069411; train accuracy : 0.9945114195653376; \n",
      " validation loss : 0.6494647574936402; validation accuracy : 0.9022556390977443\n",
      "Epoch 80:\t train loss : 0.5582924605142672; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.6595163835689897; validation accuracy : 0.8947368421052632\n",
      "Epoch 81:\t train loss : 0.5545609288383371; train accuracy : 0.996764917325665; \n",
      " validation loss : 0.6748798990526541; validation accuracy : 0.8721804511278195\n",
      "Epoch 82:\t train loss : 0.5570679519415881; train accuracy : 0.9943731681689985; \n",
      " validation loss : 0.6819534442749724; validation accuracy : 0.8721804511278195\n",
      "Epoch 83:\t train loss : 0.5670193378595804; train accuracy : 0.9840181385831996; \n",
      " validation loss : 0.6636110816663167; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84:\t train loss : 0.565717228769549; train accuracy : 0.9855250788032959; \n",
      " validation loss : 0.6401519424191705; validation accuracy : 0.9097744360902256\n",
      "Epoch 85:\t train loss : 0.5571803043294888; train accuracy : 0.9942210916330255; \n",
      " validation loss : 0.662959827685079; validation accuracy : 0.8796992481203008\n",
      "Epoch 86:\t train loss : 0.5592005957704863; train accuracy : 0.9921058452690372; \n",
      " validation loss : 0.6571640455037969; validation accuracy : 0.8947368421052632\n",
      "Epoch 87:\t train loss : 0.5889193722924269; train accuracy : 0.9619946911463806; \n",
      " validation loss : 0.6545813350125613; validation accuracy : 0.8947368421052632\n",
      "Epoch 88:\t train loss : 0.567466808423613; train accuracy : 0.9835895592545485; \n",
      " validation loss : 0.6494531560961992; validation accuracy : 0.9022556390977443\n",
      "Early stopping at epoch 88\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5692949585408249; Train accuracy : 0.9825526737820052; \n",
      " Validation loss : 0.6097101256861951; Validation accuracy : 0.9398496240601504\n",
      "------------------------------ Let's train model 20 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8902024193878311; train accuracy : 0.6355140186915887; \n",
      " validation loss : 0.7876790073809249; validation accuracy : 0.7368421052631579\n",
      "Epoch 2:\t train loss : 0.7796203000646567; train accuracy : 0.7628159044406349; \n",
      " validation loss : 0.7756413432089069; validation accuracy : 0.7518796992481203\n",
      "Epoch 3:\t train loss : 0.7374273020670485; train accuracy : 0.809655477520323; \n",
      " validation loss : 0.7021223569282392; validation accuracy : 0.849624060150376\n",
      "Epoch 4:\t train loss : 0.6891604642768678; train accuracy : 0.8590527014322845; \n",
      " validation loss : 0.7077162331618535; validation accuracy : 0.8345864661654135\n",
      "Epoch 5:\t train loss : 0.6687663077719982; train accuracy : 0.8804263673063097; \n",
      " validation loss : 0.6949796232714401; validation accuracy : 0.8421052631578947\n",
      "Epoch 6:\t train loss : 0.6426414520784868; train accuracy : 0.9082563733893713; \n",
      " validation loss : 0.6389725989403967; validation accuracy : 0.9097744360902256\n",
      "Epoch 7:\t train loss : 0.6282127307561143; train accuracy : 0.9229801470994857; \n",
      " validation loss : 0.6603103235774029; validation accuracy : 0.8872180451127819\n",
      "Epoch 8:\t train loss : 0.6206736217827371; train accuracy : 0.9300586185920477; \n",
      " validation loss : 0.6619813965271124; validation accuracy : 0.8796992481203008\n",
      "Epoch 9:\t train loss : 0.614629561270614; train accuracy : 0.9366393850577891; \n",
      " validation loss : 0.6536831755884928; validation accuracy : 0.8947368421052632\n",
      "Epoch 10:\t train loss : 0.6037475387161301; train accuracy : 0.9478377481612564; \n",
      " validation loss : 0.6522974088763092; validation accuracy : 0.9097744360902256\n",
      "Epoch 11:\t train loss : 0.610535148892276; train accuracy : 0.9405242492949178; \n",
      " validation loss : 0.6234440997778485; validation accuracy : 0.924812030075188\n",
      "Epoch 12:\t train loss : 0.609523402151245; train accuracy : 0.9416440856052646; \n",
      " validation loss : 0.6157195285502841; validation accuracy : 0.9398496240601504\n",
      "Epoch 13:\t train loss : 0.5945352332882068; train accuracy : 0.9571558922745119; \n",
      " validation loss : 0.6332351037697629; validation accuracy : 0.924812030075188\n",
      "Epoch 14:\t train loss : 0.5851633716917823; train accuracy : 0.9670823425316596; \n",
      " validation loss : 0.647072995380172; validation accuracy : 0.9022556390977443\n",
      "Epoch 15:\t train loss : 0.5875363859758109; train accuracy : 0.9639993363932976; \n",
      " validation loss : 0.6272834918238338; validation accuracy : 0.9323308270676691\n",
      "Epoch 16:\t train loss : 0.5919716759729289; train accuracy : 0.9592987889177681; \n",
      " validation loss : 0.6253310555378461; validation accuracy : 0.924812030075188\n",
      "Epoch 17:\t train loss : 0.5840546135039308; train accuracy : 0.9671376430901952; \n",
      " validation loss : 0.6190064689208349; validation accuracy : 0.924812030075188\n",
      "Epoch 18:\t train loss : 0.5869234352737808; train accuracy : 0.9644555660012166; \n",
      " validation loss : 0.7020757168051623; validation accuracy : 0.849624060150376\n",
      "Epoch 19:\t train loss : 0.5839080206381672; train accuracy : 0.9675523972792125; \n",
      " validation loss : 0.6489047091581996; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5833911663559506; train accuracy : 0.9681054028645689; \n",
      " validation loss : 0.6203109206010237; validation accuracy : 0.924812030075188\n",
      "Epoch 21:\t train loss : 0.582024863349803; train accuracy : 0.9692528894541835; \n",
      " validation loss : 0.6244174058081288; validation accuracy : 0.924812030075188\n",
      "Epoch 22:\t train loss : 0.5805237012682135; train accuracy : 0.9705248023005032; \n",
      " validation loss : 0.611316836433437; validation accuracy : 0.9473684210526315\n",
      "Epoch 23:\t train loss : 0.583861660373947; train accuracy : 0.9677735995133551; \n",
      " validation loss : 0.6382888885496236; validation accuracy : 0.9172932330827067\n",
      "Epoch 24:\t train loss : 0.572393176130432; train accuracy : 0.9790134380357242; \n",
      " validation loss : 0.6128018627923352; validation accuracy : 0.9323308270676691\n",
      "Epoch 25:\t train loss : 0.5708290473921892; train accuracy : 0.9809074821655699; \n",
      " validation loss : 0.6273692718655045; validation accuracy : 0.9172932330827067\n",
      "Epoch 26:\t train loss : 0.5724750922533766; train accuracy : 0.9791240391527954; \n",
      " validation loss : 0.6215805620176396; validation accuracy : 0.9323308270676691\n",
      "Epoch 27:\t train loss : 0.574541575813974; train accuracy : 0.9765525631808881; \n",
      " validation loss : 0.719900596272814; validation accuracy : 0.8270676691729323\n",
      "Epoch 28:\t train loss : 0.5745449518593055; train accuracy : 0.9767046397168612; \n",
      " validation loss : 0.6199598178413284; validation accuracy : 0.9323308270676691\n",
      "Epoch 29:\t train loss : 0.5715615347799009; train accuracy : 0.9800088480893657; \n",
      " validation loss : 0.6686216441784976; validation accuracy : 0.8796992481203008\n",
      "Epoch 30:\t train loss : 0.5767820980451884; train accuracy : 0.9748105955870154; \n",
      " validation loss : 0.6179977006769399; validation accuracy : 0.9323308270676691\n",
      "Epoch 31:\t train loss : 0.5761998645738438; train accuracy : 0.9747552950284798; \n",
      " validation loss : 0.634229601655216; validation accuracy : 0.9022556390977443\n",
      "Epoch 32:\t train loss : 0.566624374405187; train accuracy : 0.984737045844163; \n",
      " validation loss : 0.6294094450673569; validation accuracy : 0.9172932330827067\n",
      "Epoch 33:\t train loss : 0.5656464098348893; train accuracy : 0.9857048056185368; \n",
      " validation loss : 0.6581111769523075; validation accuracy : 0.8872180451127819\n",
      "Epoch 34:\t train loss : 0.5870643529296337; train accuracy : 0.9635707570646463; \n",
      " validation loss : 0.686068057239814; validation accuracy : 0.8646616541353384\n",
      "Epoch 35:\t train loss : 0.5789549704936511; train accuracy : 0.9720593927998673; \n",
      " validation loss : 0.7397379625541943; validation accuracy : 0.8045112781954887\n",
      "Epoch 36:\t train loss : 0.5797904465893227; train accuracy : 0.9709948570480562; \n",
      " validation loss : 0.627754130706814; validation accuracy : 0.9172932330827067\n",
      "Epoch 37:\t train loss : 0.5705863231133101; train accuracy : 0.9807139302106951; \n",
      " validation loss : 0.6430222883582207; validation accuracy : 0.9097744360902256\n",
      "Epoch 38:\t train loss : 0.5651615407957223; train accuracy : 0.986285461483161; \n",
      " validation loss : 0.6119816984253085; validation accuracy : 0.9398496240601504\n",
      "Epoch 39:\t train loss : 0.5655636935902126; train accuracy : 0.9860504341093845; \n",
      " validation loss : 0.6209587954343435; validation accuracy : 0.924812030075188\n",
      "Epoch 40:\t train loss : 0.5647043446413171; train accuracy : 0.9867002156721782; \n",
      " validation loss : 0.6302816670068347; validation accuracy : 0.924812030075188\n",
      "Epoch 41:\t train loss : 0.5699234448337659; train accuracy : 0.9811286843997125; \n",
      " validation loss : 0.6170883820338754; validation accuracy : 0.9398496240601504\n",
      "Epoch 42:\t train loss : 0.5618505760664365; train accuracy : 0.989520544157496; \n",
      " validation loss : 0.6267248433002643; validation accuracy : 0.924812030075188\n",
      "Epoch 43:\t train loss : 0.5624105662699634; train accuracy : 0.9889951888514074; \n",
      " validation loss : 0.6181786898103702; validation accuracy : 0.9323308270676691\n",
      "Epoch 44:\t train loss : 0.5604414888125406; train accuracy : 0.9910827849361279; \n",
      " validation loss : 0.6407912741082218; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:\t train loss : 0.5689675843444575; train accuracy : 0.9824005972460322; \n",
      " validation loss : 0.6428992797315516; validation accuracy : 0.9097744360902256\n",
      "Epoch 46:\t train loss : 0.5620076016151724; train accuracy : 0.9894375933196925; \n",
      " validation loss : 0.613218344348265; validation accuracy : 0.9398496240601504\n",
      "Epoch 47:\t train loss : 0.5642748531520452; train accuracy : 0.9870043687441243; \n",
      " validation loss : 0.6784597070169515; validation accuracy : 0.8721804511278195\n",
      "Epoch 48:\t train loss : 0.574158225756175; train accuracy : 0.9768152408339325; \n",
      " validation loss : 0.6646491615362535; validation accuracy : 0.8796992481203008\n",
      "Epoch 49:\t train loss : 0.5742539363943517; train accuracy : 0.976884366532102; \n",
      " validation loss : 0.6182746393336147; validation accuracy : 0.9323308270676691\n",
      "Epoch 50:\t train loss : 0.5810251014910611; train accuracy : 0.9698611955980755; \n",
      " validation loss : 0.657228052447126; validation accuracy : 0.8947368421052632\n",
      "Epoch 51:\t train loss : 0.5672129350836794; train accuracy : 0.9841563899795388; \n",
      " validation loss : 0.6341339433011498; validation accuracy : 0.9172932330827067\n",
      "Epoch 52:\t train loss : 0.5659157132673814; train accuracy : 0.9856080296410994; \n",
      " validation loss : 0.7221492983153314; validation accuracy : 0.8195488721804511\n",
      "Epoch 53:\t train loss : 0.5812459109836563; train accuracy : 0.969031687220041; \n",
      " validation loss : 0.6006663305575489; validation accuracy : 0.9548872180451128\n",
      "Epoch 54:\t train loss : 0.564259378636601; train accuracy : 0.9870320190233921; \n",
      " validation loss : 0.6276783164980985; validation accuracy : 0.9172932330827067\n",
      "Epoch 55:\t train loss : 0.5581248730767749; train accuracy : 0.9934330586738926; \n",
      " validation loss : 0.6306661876259555; validation accuracy : 0.9172932330827067\n",
      "Epoch 56:\t train loss : 0.5628837996105575; train accuracy : 0.9883039318697119; \n",
      " validation loss : 0.615072433289861; validation accuracy : 0.9323308270676691\n",
      "Epoch 57:\t train loss : 0.5586812240585887; train accuracy : 0.9927003262732953; \n",
      " validation loss : 0.6109338264640969; validation accuracy : 0.9398496240601504\n",
      "Epoch 58:\t train loss : 0.5674230311090698; train accuracy : 0.9838660620472267; \n",
      " validation loss : 0.6384945020783532; validation accuracy : 0.9097744360902256\n",
      "Epoch 59:\t train loss : 0.5636378324243909; train accuracy : 0.9872808715368026; \n",
      " validation loss : 0.643331056982418; validation accuracy : 0.9022556390977443\n",
      "Epoch 60:\t train loss : 0.5734113935295934; train accuracy : 0.9778244760272079; \n",
      " validation loss : 0.6331859996524704; validation accuracy : 0.9097744360902256\n",
      "Epoch 61:\t train loss : 0.56366235313946; train accuracy : 0.9876956257258198; \n",
      " validation loss : 0.639432433383502; validation accuracy : 0.9097744360902256\n",
      "Epoch 62:\t train loss : 0.5654605018933059; train accuracy : 0.9858707072941436; \n",
      " validation loss : 0.6155755004664527; validation accuracy : 0.9323308270676691\n",
      "Epoch 63:\t train loss : 0.5585392259300939; train accuracy : 0.9929353536470719; \n",
      " validation loss : 0.6132897813044892; validation accuracy : 0.9398496240601504\n",
      "Epoch 64:\t train loss : 0.5592608830245326; train accuracy : 0.992147320687939; \n",
      " validation loss : 0.6535088515872328; validation accuracy : 0.8947368421052632\n",
      "Epoch 65:\t train loss : 0.5712553432264587; train accuracy : 0.9796355693192501; \n",
      " validation loss : 0.6381135228171936; validation accuracy : 0.9097744360902256\n",
      "Epoch 66:\t train loss : 0.5869297747167864; train accuracy : 0.9635431067853786; \n",
      " validation loss : 0.6402567867372793; validation accuracy : 0.9022556390977443\n",
      "Epoch 67:\t train loss : 0.5664165870159776; train accuracy : 0.9849997234972073; \n",
      " validation loss : 0.6281023401396684; validation accuracy : 0.9172932330827067\n",
      "Epoch 68:\t train loss : 0.5767366589243077; train accuracy : 0.9740502129071503; \n",
      " validation loss : 0.605694178455255; validation accuracy : 0.9473684210526315\n",
      "Epoch 69:\t train loss : 0.5611888161513737; train accuracy : 0.9901288503013881; \n",
      " validation loss : 0.6302294054752752; validation accuracy : 0.9172932330827067\n",
      "Epoch 70:\t train loss : 0.5587679988474963; train accuracy : 0.9924791240391528; \n",
      " validation loss : 0.6256969416434444; validation accuracy : 0.924812030075188\n",
      "Epoch 71:\t train loss : 0.5791220496509605; train accuracy : 0.9715616877730465; \n",
      " validation loss : 0.6045957031290232; validation accuracy : 0.9473684210526315\n",
      "Epoch 72:\t train loss : 0.5660953666691007; train accuracy : 0.9851656251728143; \n",
      " validation loss : 0.7095566596527645; validation accuracy : 0.8421052631578947\n",
      "Epoch 73:\t train loss : 0.5649794503505919; train accuracy : 0.9860227838301167; \n",
      " validation loss : 0.627021808596892; validation accuracy : 0.924812030075188\n",
      "Epoch 74:\t train loss : 0.5645635591425121; train accuracy : 0.9867002156721782; \n",
      " validation loss : 0.633572121700238; validation accuracy : 0.924812030075188\n",
      "Epoch 75:\t train loss : 0.5576165292091265; train accuracy : 0.993681911187303; \n",
      " validation loss : 0.6356789506134688; validation accuracy : 0.9172932330827067\n",
      "Epoch 76:\t train loss : 0.5674128306031688; train accuracy : 0.9839213626057624; \n",
      " validation loss : 0.6409698269308605; validation accuracy : 0.9097744360902256\n",
      "Epoch 77:\t train loss : 0.5587212481608146; train accuracy : 0.9926726759940275; \n",
      " validation loss : 0.6286900437993249; validation accuracy : 0.924812030075188\n",
      "Epoch 78:\t train loss : 0.5637596318226978; train accuracy : 0.9874744234916772; \n",
      " validation loss : 0.6322647921884712; validation accuracy : 0.9172932330827067\n",
      "Epoch 79:\t train loss : 0.5632195450167069; train accuracy : 0.9880965547752032; \n",
      " validation loss : 0.6590897498994779; validation accuracy : 0.8872180451127819\n",
      "Epoch 80:\t train loss : 0.5563807467316997; train accuracy : 0.9949676491732566; \n",
      " validation loss : 0.6198347537845855; validation accuracy : 0.9323308270676691\n",
      "Epoch 81:\t train loss : 0.5569644849443178; train accuracy : 0.9943593430293646; \n",
      " validation loss : 0.6138621624681493; validation accuracy : 0.9398496240601504\n",
      "Epoch 82:\t train loss : 0.5573382083099012; train accuracy : 0.9939584139799812; \n",
      " validation loss : 0.6280469924286834; validation accuracy : 0.924812030075188\n",
      "Epoch 83:\t train loss : 0.5570081829055; train accuracy : 0.9943178676104628; \n",
      " validation loss : 0.615084558689905; validation accuracy : 0.9323308270676691\n",
      "Epoch 84:\t train loss : 0.555697455450437; train accuracy : 0.99568655643422; \n",
      " validation loss : 0.619753218654361; validation accuracy : 0.9323308270676691\n",
      "Epoch 85:\t train loss : 0.5549645478676537; train accuracy : 0.9964054636951833; \n",
      " validation loss : 0.626725561117242; validation accuracy : 0.924812030075188\n",
      "Epoch 86:\t train loss : 0.5651337749157815; train accuracy : 0.9862163357849915; \n",
      " validation loss : 0.642018819447567; validation accuracy : 0.9097744360902256\n",
      "Epoch 87:\t train loss : 0.5595180469844684; train accuracy : 0.9918431676159929; \n",
      " validation loss : 0.6622762749680206; validation accuracy : 0.8872180451127819\n",
      "Epoch 88:\t train loss : 0.5635294620445588; train accuracy : 0.9877785765636233; \n",
      " validation loss : 0.6420891817965103; validation accuracy : 0.9097744360902256\n",
      "Epoch 89:\t train loss : 0.5572523406844894; train accuracy : 0.9940551899574186; \n",
      " validation loss : 0.6418792286944154; validation accuracy : 0.9097744360902256\n",
      "Epoch 90:\t train loss : 0.5590371935994205; train accuracy : 0.9923408726428137; \n",
      " validation loss : 0.61643099219179; validation accuracy : 0.9323308270676691\n",
      "Epoch 91:\t train loss : 0.557667846377174; train accuracy : 0.9937095614665707; \n",
      " validation loss : 0.6190786752845113; validation accuracy : 0.9323308270676691\n",
      "Epoch 92:\t train loss : 0.5868140407458525; train accuracy : 0.9636537079024499; \n",
      " validation loss : 0.6266466819359141; validation accuracy : 0.924812030075188\n",
      "Epoch 93:\t train loss : 0.5597761916850789; train accuracy : 0.9916634408007521; \n",
      " validation loss : 0.6263906298242139; validation accuracy : 0.924812030075188\n",
      "Epoch 94:\t train loss : 0.5585982339365685; train accuracy : 0.9928247525300006; \n",
      " validation loss : 0.6129407989281928; validation accuracy : 0.9398496240601504\n",
      "Epoch 95:\t train loss : 0.5614205994376285; train accuracy : 0.9898108720898081; \n",
      " validation loss : 0.6146368449120716; validation accuracy : 0.9323308270676691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96:\t train loss : 0.5582032921101574; train accuracy : 0.9932671569982857; \n",
      " validation loss : 0.6496756254549869; validation accuracy : 0.9022556390977443\n",
      "Epoch 97:\t train loss : 0.5579276155657639; train accuracy : 0.9935851352098656; \n",
      " validation loss : 0.6140486725562508; validation accuracy : 0.9398496240601504\n",
      "Epoch 98:\t train loss : 0.5557014164562315; train accuracy : 0.9955897804567826; \n",
      " validation loss : 0.6339186181076975; validation accuracy : 0.9172932330827067\n",
      "Epoch 99:\t train loss : 0.6042654370681769; train accuracy : 0.9456257258198307; \n",
      " validation loss : 0.6622888639314046; validation accuracy : 0.8872180451127819\n",
      "Epoch 100:\t train loss : 0.571625662091712; train accuracy : 0.9794143670851075; \n",
      " validation loss : 0.6228960579547689; validation accuracy : 0.924812030075188\n",
      "Epoch 101:\t train loss : 0.5695308519991555; train accuracy : 0.981806116241774; \n",
      " validation loss : 0.6519981087628739; validation accuracy : 0.8947368421052632\n",
      "Epoch 102:\t train loss : 0.5622928884724717; train accuracy : 0.9888984128739701; \n",
      " validation loss : 0.6297983562604164; validation accuracy : 0.9172932330827067\n",
      "Epoch 103:\t train loss : 0.5580615874254714; train accuracy : 0.9932395067190178; \n",
      " validation loss : 0.6382251246899425; validation accuracy : 0.9097744360902256\n",
      "Early stopping at epoch 103\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5812459109836563; Train accuracy : 0.969031687220041; \n",
      " Validation loss : 0.6006663305575489; Validation accuracy : 0.9548872180451128\n",
      "------------------------------ Let's train model 21 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.897993303401052; train accuracy : 0.6334678980257701; \n",
      " validation loss : 0.8119971941049601; validation accuracy : 0.7443609022556391\n",
      "Epoch 2:\t train loss : 0.788969131913966; train accuracy : 0.7545899463584582; \n",
      " validation loss : 0.8267292682617856; validation accuracy : 0.706766917293233\n",
      "Epoch 3:\t train loss : 0.7534348380723335; train accuracy : 0.7931482607974341; \n",
      " validation loss : 0.8095368256647548; validation accuracy : 0.7293233082706767\n",
      "Epoch 4:\t train loss : 0.7132729601528429; train accuracy : 0.8346513299784328; \n",
      " validation loss : 0.785102359544949; validation accuracy : 0.7443609022556391\n",
      "Epoch 5:\t train loss : 0.6840894619439818; train accuracy : 0.8646657081236521; \n",
      " validation loss : 0.747002717763776; validation accuracy : 0.7969924812030075\n",
      "Epoch 6:\t train loss : 0.6659187381115432; train accuracy : 0.8838964773544212; \n",
      " validation loss : 0.8058581544042481; validation accuracy : 0.7293233082706767\n",
      "Epoch 7:\t train loss : 0.6680106332484774; train accuracy : 0.8815462036166565; \n",
      " validation loss : 0.700166050149058; validation accuracy : 0.849624060150376\n",
      "Epoch 8:\t train loss : 0.641273538902985; train accuracy : 0.9093900348393519; \n",
      " validation loss : 0.7305098598357077; validation accuracy : 0.8120300751879699\n",
      "Epoch 9:\t train loss : 0.649604638329806; train accuracy : 0.9005004700547475; \n",
      " validation loss : 0.6929535581438517; validation accuracy : 0.8646616541353384\n",
      "Epoch 10:\t train loss : 0.6243816462826293; train accuracy : 0.926021677818946; \n",
      " validation loss : 0.6882408454064572; validation accuracy : 0.8571428571428571\n",
      "Epoch 11:\t train loss : 0.6140067300902956; train accuracy : 0.937565669413261; \n",
      " validation loss : 0.7096877688662293; validation accuracy : 0.8345864661654135\n",
      "Epoch 12:\t train loss : 0.5961774831930653; train accuracy : 0.9555521760769784; \n",
      " validation loss : 0.6880505821304207; validation accuracy : 0.8646616541353384\n",
      "Epoch 13:\t train loss : 0.6012849375366255; train accuracy : 0.950063595642316; \n",
      " validation loss : 0.701858255356171; validation accuracy : 0.8345864661654135\n",
      "Epoch 14:\t train loss : 0.5864360948709718; train accuracy : 0.9653265497981529; \n",
      " validation loss : 0.6451037148724303; validation accuracy : 0.9097744360902256\n",
      "Epoch 15:\t train loss : 0.577383875794275; train accuracy : 0.9746308687717746; \n",
      " validation loss : 0.6908080544477924; validation accuracy : 0.8571428571428571\n",
      "Epoch 16:\t train loss : 0.5780444588373657; train accuracy : 0.9738151855333739; \n",
      " validation loss : 0.6783935620581063; validation accuracy : 0.8796992481203008\n",
      "Epoch 17:\t train loss : 0.5913464712408547; train accuracy : 0.9599762207598297; \n",
      " validation loss : 0.6880576467756171; validation accuracy : 0.849624060150376\n",
      "Epoch 18:\t train loss : 0.5745689576160515; train accuracy : 0.9768152408339325; \n",
      " validation loss : 0.6751914751337683; validation accuracy : 0.8721804511278195\n",
      "Epoch 19:\t train loss : 0.5936034273681117; train accuracy : 0.9566305369684234; \n",
      " validation loss : 0.6871683726265947; validation accuracy : 0.849624060150376\n",
      "Epoch 20:\t train loss : 0.572298224480133; train accuracy : 0.9795802687607145; \n",
      " validation loss : 0.6921547664433015; validation accuracy : 0.8571428571428571\n",
      "Epoch 21:\t train loss : 0.5683445718953553; train accuracy : 0.9832439307637008; \n",
      " validation loss : 0.643608426424767; validation accuracy : 0.9097744360902256\n",
      "Epoch 22:\t train loss : 0.5690231048669858; train accuracy : 0.9826494497594426; \n",
      " validation loss : 0.6837894470049364; validation accuracy : 0.8646616541353384\n",
      "Epoch 23:\t train loss : 0.57187286748778; train accuracy : 0.9793867168058398; \n",
      " validation loss : 0.6915329447161528; validation accuracy : 0.8571428571428571\n",
      "Epoch 24:\t train loss : 0.5736467978187899; train accuracy : 0.9779212520046453; \n",
      " validation loss : 0.6806003316830914; validation accuracy : 0.8721804511278195\n",
      "Epoch 25:\t train loss : 0.5863389314964144; train accuracy : 0.9647873693524305; \n",
      " validation loss : 0.6733809568473824; validation accuracy : 0.8721804511278195\n",
      "Epoch 26:\t train loss : 0.5727671328433233; train accuracy : 0.9782945307747608; \n",
      " validation loss : 0.6282287307605419; validation accuracy : 0.9323308270676691\n",
      "Epoch 27:\t train loss : 0.5672317498111482; train accuracy : 0.9839490128850301; \n",
      " validation loss : 0.671649810903739; validation accuracy : 0.8796992481203008\n",
      "Epoch 28:\t train loss : 0.5654253426850625; train accuracy : 0.9857462810374384; \n",
      " validation loss : 0.6207539172110835; validation accuracy : 0.924812030075188\n",
      "Epoch 29:\t train loss : 0.5649251520002221; train accuracy : 0.9862439860642592; \n",
      " validation loss : 0.7250543120954489; validation accuracy : 0.8195488721804511\n",
      "Epoch 30:\t train loss : 0.5718775469215462; train accuracy : 0.9792622905491345; \n",
      " validation loss : 0.659836086032611; validation accuracy : 0.8947368421052632\n",
      "Epoch 31:\t train loss : 0.5728674629472451; train accuracy : 0.9783360061936626; \n",
      " validation loss : 0.6671519760638079; validation accuracy : 0.8721804511278195\n",
      "Epoch 32:\t train loss : 0.5691238159604297; train accuracy : 0.9820826190344523; \n",
      " validation loss : 0.6366517345751217; validation accuracy : 0.9097744360902256\n",
      "Epoch 33:\t train loss : 0.565726771562501; train accuracy : 0.9856495050600012; \n",
      " validation loss : 0.6596792244509757; validation accuracy : 0.8872180451127819\n",
      "Epoch 34:\t train loss : 0.5637014659552416; train accuracy : 0.9877094508654537; \n",
      " validation loss : 0.632994240956439; validation accuracy : 0.9172932330827067\n",
      "Epoch 35:\t train loss : 0.5633269930656352; train accuracy : 0.9881656804733728; \n",
      " validation loss : 0.634213142352882; validation accuracy : 0.9172932330827067\n",
      "Epoch 36:\t train loss : 0.5659201002571679; train accuracy : 0.9856495050600012; \n",
      " validation loss : 0.6941092157859259; validation accuracy : 0.8571428571428571\n",
      "Epoch 37:\t train loss : 0.5653085522355095; train accuracy : 0.9860089586904828; \n",
      " validation loss : 0.6502792200389228; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.5751773674285663; train accuracy : 0.9758474810595587; \n",
      " validation loss : 0.6566168516814089; validation accuracy : 0.8947368421052632\n",
      "Epoch 39:\t train loss : 0.5855644961990987; train accuracy : 0.9651191727036443; \n",
      " validation loss : 0.6618462225258601; validation accuracy : 0.8872180451127819\n",
      "Epoch 40:\t train loss : 0.5679020220767717; train accuracy : 0.9834236575789416; \n",
      " validation loss : 0.6693350108349538; validation accuracy : 0.8796992481203008\n",
      "Epoch 41:\t train loss : 0.5697217741037636; train accuracy : 0.9813637117734889; \n",
      " validation loss : 0.6768910220247948; validation accuracy : 0.8721804511278195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:\t train loss : 0.5685417727831638; train accuracy : 0.9824282475253; \n",
      " validation loss : 0.6697404477888649; validation accuracy : 0.8796992481203008\n",
      "Epoch 43:\t train loss : 0.5758492939584842; train accuracy : 0.9750594481004258; \n",
      " validation loss : 0.6587945133692117; validation accuracy : 0.8947368421052632\n",
      "Epoch 44:\t train loss : 0.5628977616821189; train accuracy : 0.9886495603605596; \n",
      " validation loss : 0.6630134951882978; validation accuracy : 0.8872180451127819\n",
      "Epoch 45:\t train loss : 0.5599913521942718; train accuracy : 0.9913039871702705; \n",
      " validation loss : 0.67836787957405; validation accuracy : 0.8721804511278195\n",
      "Epoch 46:\t train loss : 0.565667440006786; train accuracy : 0.985663330199635; \n",
      " validation loss : 0.6770662705629875; validation accuracy : 0.8796992481203008\n",
      "Epoch 47:\t train loss : 0.5619914590963313; train accuracy : 0.9891057899684786; \n",
      " validation loss : 0.6489586151039479; validation accuracy : 0.8947368421052632\n",
      "Epoch 48:\t train loss : 0.5634196607421699; train accuracy : 0.9877509262843555; \n",
      " validation loss : 0.6403962536920966; validation accuracy : 0.9097744360902256\n",
      "Epoch 49:\t train loss : 0.5635248440493472; train accuracy : 0.9878891776806946; \n",
      " validation loss : 0.6402547013481047; validation accuracy : 0.9097744360902256\n",
      "Epoch 50:\t train loss : 0.5624898349688686; train accuracy : 0.9887739866172648; \n",
      " validation loss : 0.6440658405114678; validation accuracy : 0.9022556390977443\n",
      "Epoch 51:\t train loss : 0.5637290054765948; train accuracy : 0.9876956257258198; \n",
      " validation loss : 0.688351832893925; validation accuracy : 0.8646616541353384\n",
      "Epoch 52:\t train loss : 0.6115159219480134; train accuracy : 0.9386855057236078; \n",
      " validation loss : 0.6822249702800978; validation accuracy : 0.8646616541353384\n",
      "Epoch 53:\t train loss : 0.5969606180412942; train accuracy : 0.9532157274788475; \n",
      " validation loss : 0.6448814174059398; validation accuracy : 0.9097744360902256\n",
      "Epoch 54:\t train loss : 0.5818913256629952; train accuracy : 0.9687551844273627; \n",
      " validation loss : 0.6637915706936764; validation accuracy : 0.8796992481203008\n",
      "Epoch 55:\t train loss : 0.5663303449739361; train accuracy : 0.9849305977990378; \n",
      " validation loss : 0.6498641759370553; validation accuracy : 0.9022556390977443\n",
      "Epoch 56:\t train loss : 0.5623259517373455; train accuracy : 0.9889813637117735; \n",
      " validation loss : 0.6603214862341649; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5588381211165475; train accuracy : 0.9927003262732953; \n",
      " validation loss : 0.6417125797326986; validation accuracy : 0.9097744360902256\n",
      "Epoch 58:\t train loss : 0.5623184994692866; train accuracy : 0.9889260631532378; \n",
      " validation loss : 0.6421017002192811; validation accuracy : 0.9097744360902256\n",
      "Epoch 59:\t train loss : 0.5688198546794507; train accuracy : 0.9823452966874966; \n",
      " validation loss : 0.6504489072338515; validation accuracy : 0.9022556390977443\n",
      "Epoch 60:\t train loss : 0.563002222661341; train accuracy : 0.9883039318697119; \n",
      " validation loss : 0.6649024481209592; validation accuracy : 0.8872180451127819\n",
      "Epoch 61:\t train loss : 0.5613197043090214; train accuracy : 0.9901565005806559; \n",
      " validation loss : 0.6319000998591309; validation accuracy : 0.9172932330827067\n",
      "Epoch 62:\t train loss : 0.5607874924995324; train accuracy : 0.9905436044904053; \n",
      " validation loss : 0.6474062058915692; validation accuracy : 0.9022556390977443\n",
      "Epoch 63:\t train loss : 0.5599474341384603; train accuracy : 0.9914284134269756; \n",
      " validation loss : 0.6713535183223499; validation accuracy : 0.8796992481203008\n",
      "Epoch 64:\t train loss : 0.5606409754906163; train accuracy : 0.9904883039318697; \n",
      " validation loss : 0.6304669096438573; validation accuracy : 0.9172932330827067\n",
      "Epoch 65:\t train loss : 0.5735249610111856; train accuracy : 0.9775479732345297; \n",
      " validation loss : 0.6880358285620383; validation accuracy : 0.8646616541353384\n",
      "Epoch 66:\t train loss : 0.5738574701750775; train accuracy : 0.977340596140021; \n",
      " validation loss : 0.7000756459016528; validation accuracy : 0.849624060150376\n",
      "Epoch 67:\t train loss : 0.5643526961484711; train accuracy : 0.9872255709782669; \n",
      " validation loss : 0.6611970739601073; validation accuracy : 0.8872180451127819\n",
      "Epoch 68:\t train loss : 0.5612888584105457; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.6391949910194021; validation accuracy : 0.9097744360902256\n",
      "Epoch 69:\t train loss : 0.5578943851855439; train accuracy : 0.9935574849305978; \n",
      " validation loss : 0.6527942138666685; validation accuracy : 0.8947368421052632\n",
      "Epoch 70:\t train loss : 0.559810759291673; train accuracy : 0.9914975391251452; \n",
      " validation loss : 0.710195014587725; validation accuracy : 0.8345864661654135\n",
      "Epoch 71:\t train loss : 0.5587421640491487; train accuracy : 0.9924652988995188; \n",
      " validation loss : 0.6749212438109312; validation accuracy : 0.8721804511278195\n",
      "Epoch 72:\t train loss : 0.5700863171991875; train accuracy : 0.9810180832826412; \n",
      " validation loss : 0.6832131595468559; validation accuracy : 0.8721804511278195\n",
      "Epoch 73:\t train loss : 0.5610014745421215; train accuracy : 0.9902532765580933; \n",
      " validation loss : 0.6513369152608424; validation accuracy : 0.9022556390977443\n",
      "Epoch 74:\t train loss : 0.5574629142244631; train accuracy : 0.9939031134214455; \n",
      " validation loss : 0.6321019451779608; validation accuracy : 0.9172932330827067\n",
      "Epoch 75:\t train loss : 0.5641238487410173; train accuracy : 0.9869628933252226; \n",
      " validation loss : 0.7097164115384719; validation accuracy : 0.8345864661654135\n",
      "Epoch 76:\t train loss : 0.5664771687073029; train accuracy : 0.9849167726594038; \n",
      " validation loss : 0.6488282766166217; validation accuracy : 0.9022556390977443\n",
      "Epoch 77:\t train loss : 0.6237016676167612; train accuracy : 0.926491732566499; \n",
      " validation loss : 0.7168903057648407; validation accuracy : 0.8345864661654135\n",
      "Epoch 78:\t train loss : 0.5943670048338578; train accuracy : 0.9560360559641652; \n",
      " validation loss : 0.6807137913770157; validation accuracy : 0.8646616541353384\n",
      "Early stopping at epoch 78\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5654253426850625; Train accuracy : 0.9857462810374384; \n",
      " Validation loss : 0.6207539172110835; Validation accuracy : 0.924812030075188\n",
      "------------------------------ Let's train model 22 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9065850761979457; train accuracy : 0.6133523198584305; \n",
      " validation loss : 0.8351765216728401; validation accuracy : 0.7218045112781954\n",
      "Epoch 2:\t train loss : 0.7902789653503426; train accuracy : 0.7489769396670907; \n",
      " validation loss : 0.7532266376934171; validation accuracy : 0.7894736842105263\n",
      "Epoch 3:\t train loss : 0.7202942030584811; train accuracy : 0.8274484322291655; \n",
      " validation loss : 0.711540789887648; validation accuracy : 0.849624060150376\n",
      "Epoch 4:\t train loss : 0.6686610586743271; train accuracy : 0.8818227064093347; \n",
      " validation loss : 0.7537037730720524; validation accuracy : 0.7894736842105263\n",
      "Epoch 5:\t train loss : 0.6407363016215186; train accuracy : 0.9100259912625117; \n",
      " validation loss : 0.7015076562450276; validation accuracy : 0.8421052631578947\n",
      "Epoch 6:\t train loss : 0.6174841963914964; train accuracy : 0.9345932643919703; \n",
      " validation loss : 0.6750190877275859; validation accuracy : 0.8646616541353384\n",
      "Epoch 7:\t train loss : 0.6179379382117787; train accuracy : 0.9333766521041863; \n",
      " validation loss : 0.6933769712986096; validation accuracy : 0.8571428571428571\n",
      "Epoch 8:\t train loss : 0.6128202549349174; train accuracy : 0.9382154509760549; \n",
      " validation loss : 0.6827745493695833; validation accuracy : 0.8646616541353384\n",
      "Epoch 9:\t train loss : 0.6033962724293528; train accuracy : 0.948515180003318; \n",
      " validation loss : 0.6737635749657113; validation accuracy : 0.8796992481203008\n",
      "Epoch 10:\t train loss : 0.588326004170137; train accuracy : 0.9637919592987889; \n",
      " validation loss : 0.6674740436771862; validation accuracy : 0.8796992481203008\n",
      "Epoch 11:\t train loss : 0.5973088102082541; train accuracy : 0.9542111375324891; \n",
      " validation loss : 0.6927670743162224; validation accuracy : 0.8571428571428571\n",
      "Epoch 12:\t train loss : 0.5829376091165466; train accuracy : 0.9689625615218713; \n",
      " validation loss : 0.7010592159492185; validation accuracy : 0.8421052631578947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\t train loss : 0.5844304998410185; train accuracy : 0.9671099928109274; \n",
      " validation loss : 0.6364815875685197; validation accuracy : 0.9172932330827067\n",
      "Epoch 14:\t train loss : 0.5749356282446996; train accuracy : 0.9763037106674778; \n",
      " validation loss : 0.6562869603700401; validation accuracy : 0.8947368421052632\n",
      "Epoch 15:\t train loss : 0.5735522984204227; train accuracy : 0.9773544212796549; \n",
      " validation loss : 0.6912338989452922; validation accuracy : 0.8571428571428571\n",
      "Epoch 16:\t train loss : 0.5811660386682331; train accuracy : 0.9704695017419676; \n",
      " validation loss : 0.6647661042404839; validation accuracy : 0.8947368421052632\n",
      "Epoch 17:\t train loss : 0.5832458501895569; train accuracy : 0.9679256760493281; \n",
      " validation loss : 0.6593512268877348; validation accuracy : 0.8947368421052632\n",
      "Epoch 18:\t train loss : 0.5696187472451296; train accuracy : 0.9817646408228723; \n",
      " validation loss : 0.6700537182980761; validation accuracy : 0.8646616541353384\n",
      "Epoch 19:\t train loss : 0.5656817985683684; train accuracy : 0.9859260078526794; \n",
      " validation loss : 0.647893949876008; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5700880456553666; train accuracy : 0.9816678648454349; \n",
      " validation loss : 0.7064325121195464; validation accuracy : 0.8345864661654135\n",
      "Epoch 21:\t train loss : 0.5669771176776861; train accuracy : 0.9845987944478239; \n",
      " validation loss : 0.6370260099058341; validation accuracy : 0.9172932330827067\n",
      "Epoch 22:\t train loss : 0.5636522198038425; train accuracy : 0.9875850246087485; \n",
      " validation loss : 0.6452327451133003; validation accuracy : 0.9022556390977443\n",
      "Epoch 23:\t train loss : 0.5636906392268368; train accuracy : 0.9877232760050877; \n",
      " validation loss : 0.6474592864833082; validation accuracy : 0.9022556390977443\n",
      "Epoch 24:\t train loss : 0.5617241886767587; train accuracy : 0.9898108720898081; \n",
      " validation loss : 0.6681915860304795; validation accuracy : 0.8721804511278195\n",
      "Epoch 25:\t train loss : 0.5622281252960981; train accuracy : 0.9891472653873804; \n",
      " validation loss : 0.642602968143372; validation accuracy : 0.9097744360902256\n",
      "Epoch 26:\t train loss : 0.5680674989639364; train accuracy : 0.9831056793673616; \n",
      " validation loss : 0.6751025590710288; validation accuracy : 0.8796992481203008\n",
      "Epoch 27:\t train loss : 0.5635067600823692; train accuracy : 0.9876956257258198; \n",
      " validation loss : 0.6504558957679719; validation accuracy : 0.9022556390977443\n",
      "Epoch 28:\t train loss : 0.5637491204775127; train accuracy : 0.987654150306918; \n",
      " validation loss : 0.6795946145613704; validation accuracy : 0.8721804511278195\n",
      "Epoch 29:\t train loss : 0.5722042026783138; train accuracy : 0.9787922358015816; \n",
      " validation loss : 0.6698029383063158; validation accuracy : 0.8721804511278195\n",
      "Epoch 30:\t train loss : 0.5791243016054666; train accuracy : 0.9717414145882873; \n",
      " validation loss : 0.6766436762939082; validation accuracy : 0.8721804511278195\n",
      "Epoch 31:\t train loss : 0.597518107019566; train accuracy : 0.9534092794337223; \n",
      " validation loss : 0.6916971527686233; validation accuracy : 0.8571428571428571\n",
      "Epoch 32:\t train loss : 0.5829064232810868; train accuracy : 0.9681607034231046; \n",
      " validation loss : 0.684987341394708; validation accuracy : 0.8721804511278195\n",
      "Epoch 33:\t train loss : 0.5706107045946476; train accuracy : 0.9803544765802135; \n",
      " validation loss : 0.6469938307739351; validation accuracy : 0.9022556390977443\n",
      "Epoch 34:\t train loss : 0.5636289860124458; train accuracy : 0.9878615274014267; \n",
      " validation loss : 0.6670673458867922; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.5610121334166028; train accuracy : 0.9904191782337002; \n",
      " validation loss : 0.6655728448759611; validation accuracy : 0.8872180451127819\n",
      "Epoch 36:\t train loss : 0.5694319045000656; train accuracy : 0.9817231654039705; \n",
      " validation loss : 0.6682659759344736; validation accuracy : 0.8872180451127819\n",
      "Epoch 37:\t train loss : 0.5631060240164788; train accuracy : 0.9882486313111762; \n",
      " validation loss : 0.7038630725567159; validation accuracy : 0.8421052631578947\n",
      "Epoch 38:\t train loss : 0.5589091566878706; train accuracy : 0.9924376486202511; \n",
      " validation loss : 0.663097527750658; validation accuracy : 0.8872180451127819\n",
      "Epoch 39:\t train loss : 0.5672845576311057; train accuracy : 0.983962838024664; \n",
      " validation loss : 0.647912172342102; validation accuracy : 0.9022556390977443\n",
      "Epoch 40:\t train loss : 0.5631793029082224; train accuracy : 0.9880689044959354; \n",
      " validation loss : 0.6812559959388228; validation accuracy : 0.8721804511278195\n",
      "Epoch 41:\t train loss : 0.5570426746101209; train accuracy : 0.9947326217994802; \n",
      " validation loss : 0.674343156935656; validation accuracy : 0.8721804511278195\n",
      "Epoch 42:\t train loss : 0.5567830795214581; train accuracy : 0.9946358458220428; \n",
      " validation loss : 0.6676872109268589; validation accuracy : 0.8872180451127819\n",
      "Epoch 43:\t train loss : 0.5647673806473537; train accuracy : 0.9861472100868218; \n",
      " validation loss : 0.7139937910033154; validation accuracy : 0.8345864661654135\n",
      "Epoch 44:\t train loss : 0.5610181231463442; train accuracy : 0.9904606536526018; \n",
      " validation loss : 0.6800581543304809; validation accuracy : 0.8721804511278195\n",
      "Epoch 45:\t train loss : 0.5615811392942623; train accuracy : 0.9898661726483438; \n",
      " validation loss : 0.6766929554256323; validation accuracy : 0.8646616541353384\n",
      "Epoch 46:\t train loss : 0.5608905164394609; train accuracy : 0.990280926837361; \n",
      " validation loss : 0.6855575994281512; validation accuracy : 0.8646616541353384\n",
      "Epoch 47:\t train loss : 0.5621815055842208; train accuracy : 0.9890090139910414; \n",
      " validation loss : 0.7090313655931997; validation accuracy : 0.8421052631578947\n",
      "Epoch 48:\t train loss : 0.5902421489465572; train accuracy : 0.9603494995299453; \n",
      " validation loss : 0.7299482384019329; validation accuracy : 0.8195488721804511\n",
      "Epoch 49:\t train loss : 0.5781625960666861; train accuracy : 0.9727921252004645; \n",
      " validation loss : 0.7081851443743303; validation accuracy : 0.8421052631578947\n",
      "Epoch 50:\t train loss : 0.5648547812098605; train accuracy : 0.9864098877398662; \n",
      " validation loss : 0.7058649957905001; validation accuracy : 0.8421052631578947\n",
      "Epoch 51:\t train loss : 0.5627843181400269; train accuracy : 0.9885113089642206; \n",
      " validation loss : 0.6340129611996655; validation accuracy : 0.9172932330827067\n",
      "Epoch 52:\t train loss : 0.55937111560774; train accuracy : 0.9920643698501355; \n",
      " validation loss : 0.659209617898389; validation accuracy : 0.8947368421052632\n",
      "Epoch 53:\t train loss : 0.5557642864979726; train accuracy : 0.9956312558756844; \n",
      " validation loss : 0.6717363094834923; validation accuracy : 0.8721804511278195\n",
      "Epoch 54:\t train loss : 0.5555992765150217; train accuracy : 0.9959077586683626; \n",
      " validation loss : 0.6584114976519331; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5558207783166333; train accuracy : 0.9956727312945861; \n",
      " validation loss : 0.6821917034614835; validation accuracy : 0.8721804511278195\n",
      "Epoch 56:\t train loss : 0.5554030441416614; train accuracy : 0.9961013106232373; \n",
      " validation loss : 0.6670568914032627; validation accuracy : 0.8796992481203008\n",
      "Epoch 57:\t train loss : 0.567389260427774; train accuracy : 0.9837692860697893; \n",
      " validation loss : 0.6621290845281279; validation accuracy : 0.8796992481203008\n",
      "Epoch 58:\t train loss : 0.5714306009626012; train accuracy : 0.9792069899905989; \n",
      " validation loss : 0.7028469118569354; validation accuracy : 0.849624060150376\n",
      "Epoch 59:\t train loss : 0.5639508304639695; train accuracy : 0.9872532212575347; \n",
      " validation loss : 0.6655241781609105; validation accuracy : 0.8796992481203008\n",
      "Epoch 60:\t train loss : 0.5624681074256968; train accuracy : 0.9888292871758004; \n",
      " validation loss : 0.6840293728596075; validation accuracy : 0.8646616541353384\n",
      "Epoch 61:\t train loss : 0.5570694205109484; train accuracy : 0.9942487419122933; \n",
      " validation loss : 0.6917650345012036; validation accuracy : 0.849624060150376\n",
      "Epoch 62:\t train loss : 0.5627275241015446; train accuracy : 0.988594259802024; \n",
      " validation loss : 0.6563381364116564; validation accuracy : 0.8947368421052632\n",
      "Epoch 63:\t train loss : 0.5596690967219777; train accuracy : 0.9917325664989216; \n",
      " validation loss : 0.6866753511935955; validation accuracy : 0.8646616541353384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:\t train loss : 0.5583032858188529; train accuracy : 0.9930321296245092; \n",
      " validation loss : 0.642794197410532; validation accuracy : 0.9097744360902256\n",
      "Epoch 65:\t train loss : 0.573972553108405; train accuracy : 0.9770917436266107; \n",
      " validation loss : 0.6818789166250439; validation accuracy : 0.8571428571428571\n",
      "Epoch 66:\t train loss : 0.5621507681747667; train accuracy : 0.9891334402477465; \n",
      " validation loss : 0.6727170300527131; validation accuracy : 0.8796992481203008\n",
      "Epoch 67:\t train loss : 0.5696420290707221; train accuracy : 0.9815849140076315; \n",
      " validation loss : 0.688143046051775; validation accuracy : 0.8646616541353384\n",
      "Epoch 68:\t train loss : 0.5577923194363995; train accuracy : 0.9935021843720622; \n",
      " validation loss : 0.6430649026623382; validation accuracy : 0.9097744360902256\n",
      "Epoch 69:\t train loss : 0.5588699793514655; train accuracy : 0.9927141514129293; \n",
      " validation loss : 0.6605254518846625; validation accuracy : 0.8947368421052632\n",
      "Epoch 70:\t train loss : 0.5573858673647848; train accuracy : 0.9939307637007133; \n",
      " validation loss : 0.6769071125587272; validation accuracy : 0.8721804511278195\n",
      "Epoch 71:\t train loss : 0.6107875572567427; train accuracy : 0.9399574185699275; \n",
      " validation loss : 0.6915599844344972; validation accuracy : 0.849624060150376\n",
      "Epoch 72:\t train loss : 0.6260442036931102; train accuracy : 0.9240170325720289; \n",
      " validation loss : 0.6896313971314105; validation accuracy : 0.8571428571428571\n",
      "Epoch 73:\t train loss : 0.5906297849632722; train accuracy : 0.96022507327324; \n",
      " validation loss : 0.6871683653293933; validation accuracy : 0.8646616541353384\n",
      "Epoch 74:\t train loss : 0.5735541082264586; train accuracy : 0.9774788475363602; \n",
      " validation loss : 0.6672664013060047; validation accuracy : 0.8796992481203008\n",
      "Epoch 75:\t train loss : 0.5639508470910235; train accuracy : 0.9871426201404634; \n",
      " validation loss : 0.6923462914093849; validation accuracy : 0.8571428571428571\n",
      "Epoch 76:\t train loss : 0.5625498124632131; train accuracy : 0.9885527843831222; \n",
      " validation loss : 0.6813347097884448; validation accuracy : 0.8646616541353384\n",
      "Epoch 77:\t train loss : 0.5593292043078856; train accuracy : 0.9920781949897693; \n",
      " validation loss : 0.6765636069199424; validation accuracy : 0.8721804511278195\n",
      "Epoch 78:\t train loss : 0.5615044169050811; train accuracy : 0.9898385223690759; \n",
      " validation loss : 0.6775977800317999; validation accuracy : 0.8646616541353384\n",
      "Epoch 79:\t train loss : 0.5567255470761642; train accuracy : 0.9947187966598463; \n",
      " validation loss : 0.6710655721039231; validation accuracy : 0.8796992481203008\n",
      "Epoch 80:\t train loss : 0.5567468706314976; train accuracy : 0.9945667201238733; \n",
      " validation loss : 0.6834634714246476; validation accuracy : 0.8571428571428571\n",
      "Epoch 81:\t train loss : 0.5580672371160417; train accuracy : 0.9933086324171874; \n",
      " validation loss : 0.659667556531818; validation accuracy : 0.8872180451127819\n",
      "Epoch 82:\t train loss : 0.5568489466531282; train accuracy : 0.9943869933086324; \n",
      " validation loss : 0.6443311545198648; validation accuracy : 0.9172932330827067\n",
      "Epoch 83:\t train loss : 0.5558119383352887; train accuracy : 0.9954515290604435; \n",
      " validation loss : 0.6624510429086591; validation accuracy : 0.8796992481203008\n",
      "Epoch 84:\t train loss : 0.562395917389045; train accuracy : 0.9889951888514074; \n",
      " validation loss : 0.679702168757036; validation accuracy : 0.8721804511278195\n",
      "Epoch 85:\t train loss : 0.5561918294487487; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.6706638067610571; validation accuracy : 0.8796992481203008\n",
      "Epoch 86:\t train loss : 0.5767288654866783; train accuracy : 0.9742022894431234; \n",
      " validation loss : 0.6847232288094373; validation accuracy : 0.8646616541353384\n",
      "Epoch 87:\t train loss : 0.5636560913917633; train accuracy : 0.9875850246087485; \n",
      " validation loss : 0.6799691792805762; validation accuracy : 0.8721804511278195\n",
      "Epoch 88:\t train loss : 0.5592268615679135; train accuracy : 0.9920505447105016; \n",
      " validation loss : 0.6627336605453615; validation accuracy : 0.8872180451127819\n",
      "Epoch 89:\t train loss : 0.5619784940187063; train accuracy : 0.9893408173422551; \n",
      " validation loss : 0.6400950024497649; validation accuracy : 0.9097744360902256\n",
      "Epoch 90:\t train loss : 0.5614951354947166; train accuracy : 0.9899352983465133; \n",
      " validation loss : 0.6772596667169467; validation accuracy : 0.8721804511278195\n",
      "Epoch 91:\t train loss : 0.5582642419937577; train accuracy : 0.9929215285074379; \n",
      " validation loss : 0.664378598247364; validation accuracy : 0.8872180451127819\n",
      "Epoch 92:\t train loss : 0.556086557947729; train accuracy : 0.9953271028037383; \n",
      " validation loss : 0.6693651353956708; validation accuracy : 0.8796992481203008\n",
      "Epoch 93:\t train loss : 0.5554335518447814; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6871819892087601; validation accuracy : 0.8646616541353384\n",
      "Epoch 94:\t train loss : 0.5580493855139078; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.6573923030260747; validation accuracy : 0.8872180451127819\n",
      "Epoch 95:\t train loss : 0.5584757358508339; train accuracy : 0.9928247525300006; \n",
      " validation loss : 0.6577655344375284; validation accuracy : 0.8947368421052632\n",
      "Epoch 96:\t train loss : 0.5551422547380903; train accuracy : 0.9962257368799424; \n",
      " validation loss : 0.656928334040619; validation accuracy : 0.8947368421052632\n",
      "Epoch 97:\t train loss : 0.5560609944722488; train accuracy : 0.9952718022452026; \n",
      " validation loss : 0.7000893917665378; validation accuracy : 0.849624060150376\n",
      "Epoch 98:\t train loss : 0.5562187554121777; train accuracy : 0.995216501686667; \n",
      " validation loss : 0.654686097146976; validation accuracy : 0.9022556390977443\n",
      "Epoch 99:\t train loss : 0.5551552989597034; train accuracy : 0.9962257368799424; \n",
      " validation loss : 0.6709574173030075; validation accuracy : 0.8796992481203008\n",
      "Epoch 100:\t train loss : 0.5550542816811543; train accuracy : 0.9963501631366477; \n",
      " validation loss : 0.6695910218275508; validation accuracy : 0.8796992481203008\n",
      "Epoch 101:\t train loss : 0.5544189869966957; train accuracy : 0.9969999446994414; \n",
      " validation loss : 0.655274029806857; validation accuracy : 0.8947368421052632\n",
      "Early stopping at epoch 101\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5627843181400269; Train accuracy : 0.9885113089642206; \n",
      " Validation loss : 0.6340129611996655; Validation accuracy : 0.9172932330827067\n",
      "------------------------------ Let's train model 23 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9023762777439742; train accuracy : 0.6261820494386994; \n",
      " validation loss : 0.788007156158221; validation accuracy : 0.7593984962406015\n",
      "Epoch 2:\t train loss : 0.7751300606265856; train accuracy : 0.7701017530277056; \n",
      " validation loss : 0.7089819896271224; validation accuracy : 0.849624060150376\n",
      "Epoch 3:\t train loss : 0.7251203739999056; train accuracy : 0.8237847702261792; \n",
      " validation loss : 0.6871078377190015; validation accuracy : 0.8721804511278195\n",
      "Epoch 4:\t train loss : 0.6979470308086839; train accuracy : 0.8501907869269479; \n",
      " validation loss : 0.7030817343181639; validation accuracy : 0.8421052631578947\n",
      "Epoch 5:\t train loss : 0.6682651864322199; train accuracy : 0.8816844550129956; \n",
      " validation loss : 0.6725020453472658; validation accuracy : 0.8646616541353384\n",
      "Epoch 6:\t train loss : 0.6557945088467342; train accuracy : 0.8941685561024166; \n",
      " validation loss : 0.639644663471801; validation accuracy : 0.9097744360902256\n",
      "Epoch 7:\t train loss : 0.6418745587584745; train accuracy : 0.908131947132666; \n",
      " validation loss : 0.6551730072851601; validation accuracy : 0.9097744360902256\n",
      "Epoch 8:\t train loss : 0.6248071889576355; train accuracy : 0.9260631532378477; \n",
      " validation loss : 0.6428757319050695; validation accuracy : 0.9022556390977443\n",
      "Epoch 9:\t train loss : 0.6226391566093129; train accuracy : 0.9282613504396394; \n",
      " validation loss : 0.6441416428449093; validation accuracy : 0.9022556390977443\n",
      "Epoch 10:\t train loss : 0.6135393400648337; train accuracy : 0.9374965437150915; \n",
      " validation loss : 0.6388328720610128; validation accuracy : 0.9097744360902256\n",
      "Epoch 11:\t train loss : 0.6061760888969517; train accuracy : 0.9450450699552065; \n",
      " validation loss : 0.6916040985246024; validation accuracy : 0.849624060150376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\t train loss : 0.6026590097411652; train accuracy : 0.948376928606979; \n",
      " validation loss : 0.6630344555414716; validation accuracy : 0.8796992481203008\n",
      "Epoch 13:\t train loss : 0.5926137341416865; train accuracy : 0.958856384449483; \n",
      " validation loss : 0.6239654618277201; validation accuracy : 0.9323308270676691\n",
      "Epoch 14:\t train loss : 0.5944904530500843; train accuracy : 0.9571558922745119; \n",
      " validation loss : 0.6217705177922592; validation accuracy : 0.9323308270676691\n",
      "Epoch 15:\t train loss : 0.5912315998142961; train accuracy : 0.9596582425482497; \n",
      " validation loss : 0.6288035613640411; validation accuracy : 0.924812030075188\n",
      "Epoch 16:\t train loss : 0.5837045868898507; train accuracy : 0.9676491732566499; \n",
      " validation loss : 0.6142554638483765; validation accuracy : 0.9398496240601504\n",
      "Epoch 17:\t train loss : 0.5833678147269296; train accuracy : 0.9676491732566499; \n",
      " validation loss : 0.6283529832508088; validation accuracy : 0.924812030075188\n",
      "Epoch 18:\t train loss : 0.5753985126229184; train accuracy : 0.9764696123430847; \n",
      " validation loss : 0.6096459229364687; validation accuracy : 0.9473684210526315\n",
      "Epoch 19:\t train loss : 0.5738706681730126; train accuracy : 0.9777000497705027; \n",
      " validation loss : 0.6509475672062275; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5766394550166655; train accuracy : 0.9747829453077476; \n",
      " validation loss : 0.6210342615645407; validation accuracy : 0.924812030075188\n",
      "Epoch 21:\t train loss : 0.580167711795699; train accuracy : 0.9707460045346458; \n",
      " validation loss : 0.6308445664084459; validation accuracy : 0.9097744360902256\n",
      "Epoch 22:\t train loss : 0.5740661626435616; train accuracy : 0.9769811425095394; \n",
      " validation loss : 0.6307650016928867; validation accuracy : 0.924812030075188\n",
      "Epoch 23:\t train loss : 0.5720285067984213; train accuracy : 0.9793728916662058; \n",
      " validation loss : 0.6266137866086632; validation accuracy : 0.924812030075188\n",
      "Epoch 24:\t train loss : 0.5755038718508336; train accuracy : 0.9757783553613891; \n",
      " validation loss : 0.6137472246160185; validation accuracy : 0.9398496240601504\n",
      "Epoch 25:\t train loss : 0.5737599884030582; train accuracy : 0.9772852955814854; \n",
      " validation loss : 0.6241391655176738; validation accuracy : 0.9323308270676691\n",
      "Epoch 26:\t train loss : 0.5678108507445275; train accuracy : 0.9837139855112537; \n",
      " validation loss : 0.626215247976158; validation accuracy : 0.9172932330827067\n",
      "Epoch 27:\t train loss : 0.5646872367968214; train accuracy : 0.9870043687441243; \n",
      " validation loss : 0.6133111081558626; validation accuracy : 0.9323308270676691\n",
      "Epoch 28:\t train loss : 0.5663051564981648; train accuracy : 0.9853038765691533; \n",
      " validation loss : 0.6500278527714439; validation accuracy : 0.9022556390977443\n",
      "Epoch 29:\t train loss : 0.577936206061572; train accuracy : 0.972722999502295; \n",
      " validation loss : 0.626526738781993; validation accuracy : 0.9172932330827067\n",
      "Epoch 30:\t train loss : 0.5633942122139844; train accuracy : 0.9879997787977659; \n",
      " validation loss : 0.6435921942921236; validation accuracy : 0.9022556390977443\n",
      "Epoch 31:\t train loss : 0.5639434498546674; train accuracy : 0.987363822374606; \n",
      " validation loss : 0.6526950495913727; validation accuracy : 0.8947368421052632\n",
      "Epoch 32:\t train loss : 0.564347139486982; train accuracy : 0.9870043687441243; \n",
      " validation loss : 0.6205023802034202; validation accuracy : 0.924812030075188\n",
      "Epoch 33:\t train loss : 0.5636316025979191; train accuracy : 0.9875573743294808; \n",
      " validation loss : 0.6226166830823243; validation accuracy : 0.924812030075188\n",
      "Epoch 34:\t train loss : 0.5626180938233327; train accuracy : 0.9887739866172648; \n",
      " validation loss : 0.6494365004345709; validation accuracy : 0.9022556390977443\n",
      "Epoch 35:\t train loss : 0.5677702788462221; train accuracy : 0.9829121274124869; \n",
      " validation loss : 0.6305855328377715; validation accuracy : 0.9097744360902256\n",
      "Epoch 36:\t train loss : 0.5720096765531046; train accuracy : 0.9790687385942598; \n",
      " validation loss : 0.613282689466372; validation accuracy : 0.9398496240601504\n",
      "Epoch 37:\t train loss : 0.5620992395066806; train accuracy : 0.9892855167837196; \n",
      " validation loss : 0.6366112969746132; validation accuracy : 0.9022556390977443\n",
      "Epoch 38:\t train loss : 0.5588272181960626; train accuracy : 0.9927418016921971; \n",
      " validation loss : 0.6427950408544939; validation accuracy : 0.9097744360902256\n",
      "Epoch 39:\t train loss : 0.5615295556867023; train accuracy : 0.9899214732068794; \n",
      " validation loss : 0.603259302391706; validation accuracy : 0.9473684210526315\n",
      "Epoch 40:\t train loss : 0.5605385922993893; train accuracy : 0.990903058120887; \n",
      " validation loss : 0.6299781845441602; validation accuracy : 0.924812030075188\n",
      "Epoch 41:\t train loss : 0.569870839659693; train accuracy : 0.9814466626112923; \n",
      " validation loss : 0.5859559840934303; validation accuracy : 0.9624060150375939\n",
      "Epoch 42:\t train loss : 0.5603376547135158; train accuracy : 0.9910966100757618; \n",
      " validation loss : 0.6294857842124484; validation accuracy : 0.9097744360902256\n",
      "Epoch 43:\t train loss : 0.5591063875373325; train accuracy : 0.9922164463861085; \n",
      " validation loss : 0.6076463896876272; validation accuracy : 0.9398496240601504\n",
      "Epoch 44:\t train loss : 0.5766728501581061; train accuracy : 0.9743820162583642; \n",
      " validation loss : 0.6918919295611864; validation accuracy : 0.8646616541353384\n",
      "Epoch 45:\t train loss : 0.6231559087788632; train accuracy : 0.9267544102195432; \n",
      " validation loss : 0.6714706722417811; validation accuracy : 0.8721804511278195\n",
      "Epoch 46:\t train loss : 0.5817076183474144; train accuracy : 0.9691975888956479; \n",
      " validation loss : 0.6289976179413; validation accuracy : 0.924812030075188\n",
      "Epoch 47:\t train loss : 0.5818491076842792; train accuracy : 0.9688934358237018; \n",
      " validation loss : 0.7719435855010206; validation accuracy : 0.7669172932330827\n",
      "Epoch 48:\t train loss : 0.6212342729487873; train accuracy : 0.9289249571420671; \n",
      " validation loss : 0.5914948740954238; validation accuracy : 0.9624060150375939\n",
      "Epoch 49:\t train loss : 0.5866561666029203; train accuracy : 0.9634463308079412; \n",
      " validation loss : 0.6398438403365614; validation accuracy : 0.9097744360902256\n",
      "Epoch 50:\t train loss : 0.5811778291073769; train accuracy : 0.9697229442017364; \n",
      " validation loss : 0.6572513025526477; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5717909008161101; train accuracy : 0.9793175911076701; \n",
      " validation loss : 0.6140753693908406; validation accuracy : 0.9398496240601504\n",
      "Epoch 52:\t train loss : 0.565122001518658; train accuracy : 0.9861057346679202; \n",
      " validation loss : 0.600484259310221; validation accuracy : 0.9548872180451128\n",
      "Epoch 53:\t train loss : 0.5671883947280905; train accuracy : 0.9841425648399049; \n",
      " validation loss : 0.6395924207632447; validation accuracy : 0.9172932330827067\n",
      "Epoch 54:\t train loss : 0.569627237641796; train accuracy : 0.9817369905436045; \n",
      " validation loss : 0.6072223076963082; validation accuracy : 0.9473684210526315\n",
      "Epoch 55:\t train loss : 0.5675418909252012; train accuracy : 0.983506608416745; \n",
      " validation loss : 0.6614624786795066; validation accuracy : 0.8872180451127819\n",
      "Epoch 56:\t train loss : 0.566224694476061; train accuracy : 0.9848199966819665; \n",
      " validation loss : 0.6086313223134127; validation accuracy : 0.9473684210526315\n",
      "Epoch 57:\t train loss : 0.5647332342108606; train accuracy : 0.9866587402532766; \n",
      " validation loss : 0.6267260409272886; validation accuracy : 0.924812030075188\n",
      "Epoch 58:\t train loss : 0.5632388141556036; train accuracy : 0.9878477022617929; \n",
      " validation loss : 0.6232557660268676; validation accuracy : 0.924812030075188\n",
      "Epoch 59:\t train loss : 0.5613941882569952; train accuracy : 0.9898661726483438; \n",
      " validation loss : 0.6418067975739381; validation accuracy : 0.9097744360902256\n",
      "Epoch 60:\t train loss : 0.5649635428629919; train accuracy : 0.9866725653929105; \n",
      " validation loss : 0.6298834793102417; validation accuracy : 0.924812030075188\n",
      "Epoch 61:\t train loss : 0.5585022984535201; train accuracy : 0.9927418016921971; \n",
      " validation loss : 0.6275825678003139; validation accuracy : 0.924812030075188\n",
      "Epoch 62:\t train loss : 0.5706665085029737; train accuracy : 0.9803959519991152; \n",
      " validation loss : 0.6209324351790442; validation accuracy : 0.9323308270676691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63:\t train loss : 0.560711965033035; train accuracy : 0.9906542056074766; \n",
      " validation loss : 0.6108662635566987; validation accuracy : 0.9398496240601504\n",
      "Epoch 64:\t train loss : 0.5612051807803577; train accuracy : 0.990142675441022; \n",
      " validation loss : 0.5843767685903736; validation accuracy : 0.9699248120300752\n",
      "Epoch 65:\t train loss : 0.5667798766095766; train accuracy : 0.9844190676325831; \n",
      " validation loss : 0.657952323933497; validation accuracy : 0.8947368421052632\n",
      "Epoch 66:\t train loss : 0.5689173596104139; train accuracy : 0.9822485207100592; \n",
      " validation loss : 0.5908128022704464; validation accuracy : 0.9624060150375939\n",
      "Epoch 67:\t train loss : 0.5580009129277609; train accuracy : 0.9933086324171874; \n",
      " validation loss : 0.6500815595825211; validation accuracy : 0.9022556390977443\n",
      "Epoch 68:\t train loss : 0.5659877807959415; train accuracy : 0.985193275452082; \n",
      " validation loss : 0.6322212847037335; validation accuracy : 0.9172932330827067\n",
      "Epoch 69:\t train loss : 0.5633742135031418; train accuracy : 0.987972128518498; \n",
      " validation loss : 0.6020090017044711; validation accuracy : 0.9473684210526315\n",
      "Epoch 70:\t train loss : 0.5583685971617489; train accuracy : 0.992907703367804; \n",
      " validation loss : 0.6288263041776111; validation accuracy : 0.9172932330827067\n",
      "Epoch 71:\t train loss : 0.5574447552574873; train accuracy : 0.993833987723276; \n",
      " validation loss : 0.6193244468768441; validation accuracy : 0.924812030075188\n",
      "Epoch 72:\t train loss : 0.5574833445671367; train accuracy : 0.9940413648177846; \n",
      " validation loss : 0.6316517206125829; validation accuracy : 0.924812030075188\n",
      "Epoch 73:\t train loss : 0.5581970706902435; train accuracy : 0.9931980313001161; \n",
      " validation loss : 0.6679090114308945; validation accuracy : 0.8872180451127819\n",
      "Epoch 74:\t train loss : 0.5607104367411605; train accuracy : 0.9906265553282088; \n",
      " validation loss : 0.6294682677249228; validation accuracy : 0.924812030075188\n",
      "Epoch 75:\t train loss : 0.5583907637197177; train accuracy : 0.9928938782281701; \n",
      " validation loss : 0.6343068545894281; validation accuracy : 0.9172932330827067\n",
      "Epoch 76:\t train loss : 0.5625643601348238; train accuracy : 0.988912238013604; \n",
      " validation loss : 0.6245556058122017; validation accuracy : 0.924812030075188\n",
      "Epoch 77:\t train loss : 0.5603101809614318; train accuracy : 0.9910274843775922; \n",
      " validation loss : 0.6320431125502889; validation accuracy : 0.9172932330827067\n",
      "Epoch 78:\t train loss : 0.5575808015723708; train accuracy : 0.993820162583642; \n",
      " validation loss : 0.677103545432525; validation accuracy : 0.8646616541353384\n",
      "Epoch 79:\t train loss : 0.5631642303198391; train accuracy : 0.9878062268428911; \n",
      " validation loss : 0.6448872473997189; validation accuracy : 0.9097744360902256\n",
      "Epoch 80:\t train loss : 0.5591216299004486; train accuracy : 0.9922717469446442; \n",
      " validation loss : 0.6729249876529935; validation accuracy : 0.8721804511278195\n",
      "Epoch 81:\t train loss : 0.5682580081274686; train accuracy : 0.9829397776917547; \n",
      " validation loss : 0.6114632621995142; validation accuracy : 0.9398496240601504\n",
      "Epoch 82:\t train loss : 0.5606716560255542; train accuracy : 0.9905712547696731; \n",
      " validation loss : 0.6000605975106316; validation accuracy : 0.9548872180451128\n",
      "Epoch 83:\t train loss : 0.5623821950791437; train accuracy : 0.9888016368965327; \n",
      " validation loss : 0.6276232883720806; validation accuracy : 0.924812030075188\n",
      "Epoch 84:\t train loss : 0.5603878592320093; train accuracy : 0.9908339324227174; \n",
      " validation loss : 0.61764984004049; validation accuracy : 0.9398496240601504\n",
      "Epoch 85:\t train loss : 0.5559280457059164; train accuracy : 0.9955206547586131; \n",
      " validation loss : 0.6477610182123439; validation accuracy : 0.9022556390977443\n",
      "Epoch 86:\t train loss : 0.555049108319922; train accuracy : 0.9963778134159155; \n",
      " validation loss : 0.6205915643159793; validation accuracy : 0.9323308270676691\n",
      "Epoch 87:\t train loss : 0.5572842575526007; train accuracy : 0.9940966653763202; \n",
      " validation loss : 0.6645193191076395; validation accuracy : 0.8872180451127819\n",
      "Epoch 88:\t train loss : 0.5762759268102062; train accuracy : 0.9745064425150693; \n",
      " validation loss : 0.641200007394252; validation accuracy : 0.9097744360902256\n",
      "Epoch 89:\t train loss : 0.5629907159676227; train accuracy : 0.9883039318697119; \n",
      " validation loss : 0.6466779476746082; validation accuracy : 0.9022556390977443\n",
      "Epoch 90:\t train loss : 0.5643308518686888; train accuracy : 0.9867831665099818; \n",
      " validation loss : 0.6145480104979699; validation accuracy : 0.9398496240601504\n",
      "Epoch 91:\t train loss : 0.5617374664222136; train accuracy : 0.989520544157496; \n",
      " validation loss : 0.6114305604487652; validation accuracy : 0.9398496240601504\n",
      "Epoch 92:\t train loss : 0.5572321793751281; train accuracy : 0.9940966653763202; \n",
      " validation loss : 0.627034856364424; validation accuracy : 0.924812030075188\n",
      "Epoch 93:\t train loss : 0.5550086999178004; train accuracy : 0.9963778134159155; \n",
      " validation loss : 0.6261517217727449; validation accuracy : 0.924812030075188\n",
      "Epoch 94:\t train loss : 0.5563307852224433; train accuracy : 0.994912348614721; \n",
      " validation loss : 0.6443387154917201; validation accuracy : 0.9022556390977443\n",
      "Epoch 95:\t train loss : 0.5638995203599829; train accuracy : 0.9871426201404634; \n",
      " validation loss : 0.6767531078065866; validation accuracy : 0.8721804511278195\n",
      "Epoch 96:\t train loss : 0.5595957265834618; train accuracy : 0.9917602167781895; \n",
      " validation loss : 0.6151699919182713; validation accuracy : 0.9323308270676691\n",
      "Epoch 97:\t train loss : 0.5554199416341153; train accuracy : 0.995990709506166; \n",
      " validation loss : 0.6205348396643192; validation accuracy : 0.9323308270676691\n",
      "Epoch 98:\t train loss : 0.55718332394585; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.6182574588603544; validation accuracy : 0.9323308270676691\n",
      "Epoch 99:\t train loss : 0.5544794163101597; train accuracy : 0.9969308190012719; \n",
      " validation loss : 0.614813602675997; validation accuracy : 0.9323308270676691\n",
      "Epoch 100:\t train loss : 0.558782505518561; train accuracy : 0.9925620748769562; \n",
      " validation loss : 0.6147409097154926; validation accuracy : 0.9323308270676691\n",
      "Epoch 101:\t train loss : 0.5610004246354737; train accuracy : 0.9904053530940663; \n",
      " validation loss : 0.6241699124386009; validation accuracy : 0.924812030075188\n",
      "Epoch 102:\t train loss : 0.5552833012221142; train accuracy : 0.9960598352043355; \n",
      " validation loss : 0.6231113753326346; validation accuracy : 0.924812030075188\n",
      "Epoch 103:\t train loss : 0.5565270193352613; train accuracy : 0.9946911463805784; \n",
      " validation loss : 0.6219960501662114; validation accuracy : 0.9323308270676691\n",
      "Epoch 104:\t train loss : 0.5560183663135007; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.5966316636239863; validation accuracy : 0.9473684210526315\n",
      "Epoch 105:\t train loss : 0.5649725693663046; train accuracy : 0.9863131117624288; \n",
      " validation loss : 0.6460258734985809; validation accuracy : 0.9022556390977443\n",
      "Epoch 106:\t train loss : 0.5959620062395916; train accuracy : 0.9545844163026046; \n",
      " validation loss : 0.6353518166639844; validation accuracy : 0.9097744360902256\n",
      "Epoch 107:\t train loss : 0.5681840090454093; train accuracy : 0.9830918542277277; \n",
      " validation loss : 0.6760709322607699; validation accuracy : 0.8646616541353384\n",
      "Epoch 108:\t train loss : 0.562067762110554; train accuracy : 0.9892163910855499; \n",
      " validation loss : 0.6227362409711139; validation accuracy : 0.924812030075188\n",
      "Epoch 109:\t train loss : 0.5618051821083369; train accuracy : 0.9893546424818891; \n",
      " validation loss : 0.6293743809326419; validation accuracy : 0.924812030075188\n",
      "Epoch 110:\t train loss : 0.5642718564101524; train accuracy : 0.98705966930266; \n",
      " validation loss : 0.6268652336642757; validation accuracy : 0.924812030075188\n",
      "Epoch 111:\t train loss : 0.5638125404993176; train accuracy : 0.987363822374606; \n",
      " validation loss : 0.618687013919626; validation accuracy : 0.9323308270676691\n",
      "Epoch 112:\t train loss : 0.5580219772880604; train accuracy : 0.9933086324171874; \n",
      " validation loss : 0.6259533889979882; validation accuracy : 0.924812030075188\n",
      "Epoch 113:\t train loss : 0.5560836537409175; train accuracy : 0.9953271028037383; \n",
      " validation loss : 0.602922079724363; validation accuracy : 0.9473684210526315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114:\t train loss : 0.5576622537710125; train accuracy : 0.9936266106287673; \n",
      " validation loss : 0.6445087945874989; validation accuracy : 0.9097744360902256\n",
      "Early stopping at epoch 114\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5612051807803577; Train accuracy : 0.990142675441022; \n",
      " Validation loss : 0.5843767685903736; Validation accuracy : 0.9699248120300752\n",
      "------------------------------ Let's train model 24 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.886732638685538; train accuracy : 0.6445003594536305; \n",
      " validation loss : 0.7838533573846618; validation accuracy : 0.7368421052631579\n",
      "Epoch 2:\t train loss : 0.7658361328509327; train accuracy : 0.7808577116628878; \n",
      " validation loss : 0.8029129812923442; validation accuracy : 0.7368421052631579\n",
      "Epoch 3:\t train loss : 0.7288226494867326; train accuracy : 0.8187247691201681; \n",
      " validation loss : 0.7034973852909184; validation accuracy : 0.8571428571428571\n",
      "Epoch 4:\t train loss : 0.70829687292105; train accuracy : 0.8392827517557927; \n",
      " validation loss : 0.7475523640083986; validation accuracy : 0.8045112781954887\n",
      "Epoch 5:\t train loss : 0.6748638199131627; train accuracy : 0.874232704750318; \n",
      " validation loss : 0.7000591221301815; validation accuracy : 0.8345864661654135\n",
      "Epoch 6:\t train loss : 0.655790891882925; train accuracy : 0.8946524359896035; \n",
      " validation loss : 0.6752819119183902; validation accuracy : 0.8721804511278195\n",
      "Epoch 7:\t train loss : 0.6416777612070432; train accuracy : 0.9092656085826467; \n",
      " validation loss : 0.6508102534631228; validation accuracy : 0.8947368421052632\n",
      "Epoch 8:\t train loss : 0.6368240469562375; train accuracy : 0.9135514018691588; \n",
      " validation loss : 0.666957000214278; validation accuracy : 0.8721804511278195\n",
      "Epoch 9:\t train loss : 0.6285978527757905; train accuracy : 0.9210308024111044; \n",
      " validation loss : 0.680515163782871; validation accuracy : 0.8646616541353384\n",
      "Epoch 10:\t train loss : 0.6093118661332065; train accuracy : 0.9417961621412376; \n",
      " validation loss : 0.704298875527584; validation accuracy : 0.849624060150376\n",
      "Epoch 11:\t train loss : 0.6147179508282042; train accuracy : 0.9357131007023171; \n",
      " validation loss : 0.6529959850057638; validation accuracy : 0.9022556390977443\n",
      "Epoch 12:\t train loss : 0.5982999979425129; train accuracy : 0.9528977492672676; \n",
      " validation loss : 0.6427083008423202; validation accuracy : 0.8947368421052632\n",
      "Epoch 13:\t train loss : 0.587233195700878; train accuracy : 0.9648288447713322; \n",
      " validation loss : 0.7131756321383018; validation accuracy : 0.8345864661654135\n",
      "Epoch 14:\t train loss : 0.5907608101585093; train accuracy : 0.9603633246695792; \n",
      " validation loss : 0.6565781388111809; validation accuracy : 0.9022556390977443\n",
      "Epoch 15:\t train loss : 0.5828139356470825; train accuracy : 0.9688519604048; \n",
      " validation loss : 0.6576575426419392; validation accuracy : 0.8947368421052632\n",
      "Epoch 16:\t train loss : 0.5764271407100146; train accuracy : 0.9747276447492119; \n",
      " validation loss : 0.6432688678420807; validation accuracy : 0.9022556390977443\n",
      "Epoch 17:\t train loss : 0.5808085206876654; train accuracy : 0.9701376983907537; \n",
      " validation loss : 0.6867352333203133; validation accuracy : 0.8571428571428571\n",
      "Epoch 18:\t train loss : 0.5882721225918096; train accuracy : 0.9629348006414865; \n",
      " validation loss : 0.6626149164382491; validation accuracy : 0.8872180451127819\n",
      "Epoch 19:\t train loss : 0.5735663743313519; train accuracy : 0.9777277000497705; \n",
      " validation loss : 0.7333159580112112; validation accuracy : 0.8195488721804511\n",
      "Epoch 20:\t train loss : 0.6090099188127798; train accuracy : 0.9415611347674612; \n",
      " validation loss : 0.6701026194134457; validation accuracy : 0.8721804511278195\n",
      "Epoch 21:\t train loss : 0.5867759853405746; train accuracy : 0.9638472598573246; \n",
      " validation loss : 0.6562457971989907; validation accuracy : 0.8947368421052632\n",
      "Epoch 22:\t train loss : 0.5807517468109453; train accuracy : 0.9704418514626998; \n",
      " validation loss : 0.6764165396171163; validation accuracy : 0.8721804511278195\n",
      "Epoch 23:\t train loss : 0.5831156114018834; train accuracy : 0.9679948017474976; \n",
      " validation loss : 0.6818704350370982; validation accuracy : 0.8646616541353384\n",
      "Epoch 24:\t train loss : 0.5679972381473908; train accuracy : 0.9834374827185755; \n",
      " validation loss : 0.6205396674803564; validation accuracy : 0.924812030075188\n",
      "Epoch 25:\t train loss : 0.5690613971539435; train accuracy : 0.9824697229442018; \n",
      " validation loss : 0.6516222204948009; validation accuracy : 0.9022556390977443\n",
      "Epoch 26:\t train loss : 0.564561706596552; train accuracy : 0.9865757894154731; \n",
      " validation loss : 0.618887115758066; validation accuracy : 0.9323308270676691\n",
      "Epoch 27:\t train loss : 0.567998826967596; train accuracy : 0.9832577559033346; \n",
      " validation loss : 0.6085150392287151; validation accuracy : 0.9398496240601504\n",
      "Epoch 28:\t train loss : 0.5635455037463117; train accuracy : 0.9880412542166676; \n",
      " validation loss : 0.6509651069442836; validation accuracy : 0.9022556390977443\n",
      "Epoch 29:\t train loss : 0.5712742459168112; train accuracy : 0.9800088480893657; \n",
      " validation loss : 0.6362616663493442; validation accuracy : 0.9172932330827067\n",
      "Epoch 30:\t train loss : 0.5962191944510258; train accuracy : 0.9541696621135873; \n",
      " validation loss : 0.6550101419374705; validation accuracy : 0.9022556390977443\n",
      "Epoch 31:\t train loss : 0.5732026476288417; train accuracy : 0.97779682574794; \n",
      " validation loss : 0.6339849920849988; validation accuracy : 0.924812030075188\n",
      "Epoch 32:\t train loss : 0.5808352364730371; train accuracy : 0.9703174252059946; \n",
      " validation loss : 0.6486512570057947; validation accuracy : 0.9022556390977443\n",
      "Epoch 33:\t train loss : 0.5754401037656095; train accuracy : 0.975488027429077; \n",
      " validation loss : 0.640725623817127; validation accuracy : 0.9022556390977443\n",
      "Epoch 34:\t train loss : 0.5662560041793149; train accuracy : 0.9849444229386717; \n",
      " validation loss : 0.654031801980899; validation accuracy : 0.8947368421052632\n",
      "Epoch 35:\t train loss : 0.5649629681098883; train accuracy : 0.9860504341093845; \n",
      " validation loss : 0.6211216230324428; validation accuracy : 0.924812030075188\n",
      "Epoch 36:\t train loss : 0.5635744864174339; train accuracy : 0.9875573743294808; \n",
      " validation loss : 0.639800693801341; validation accuracy : 0.9097744360902256\n",
      "Epoch 37:\t train loss : 0.595269767226588; train accuracy : 0.9553309738428358; \n",
      " validation loss : 0.6957783140997336; validation accuracy : 0.849624060150376\n",
      "Epoch 38:\t train loss : 0.7054035225037919; train accuracy : 0.8426975612453685; \n",
      " validation loss : 0.6507684849736768; validation accuracy : 0.9022556390977443\n",
      "Epoch 39:\t train loss : 0.6332967287869267; train accuracy : 0.9159016756069236; \n",
      " validation loss : 0.7039977380679177; validation accuracy : 0.8421052631578947\n",
      "Epoch 40:\t train loss : 0.6197853601692633; train accuracy : 0.929408837029254; \n",
      " validation loss : 0.6685489007132402; validation accuracy : 0.8872180451127819\n",
      "Epoch 41:\t train loss : 0.5955207976857154; train accuracy : 0.9550682961897915; \n",
      " validation loss : 0.6859286302467998; validation accuracy : 0.8646616541353384\n",
      "Epoch 42:\t train loss : 0.5811292580497539; train accuracy : 0.9697782447602721; \n",
      " validation loss : 0.6400753027233272; validation accuracy : 0.9097744360902256\n",
      "Epoch 43:\t train loss : 0.5741082434511788; train accuracy : 0.9769811425095394; \n",
      " validation loss : 0.6752841011274734; validation accuracy : 0.8796992481203008\n",
      "Epoch 44:\t train loss : 0.5726965501315006; train accuracy : 0.9784742575900016; \n",
      " validation loss : 0.6506401677699517; validation accuracy : 0.8947368421052632\n",
      "Epoch 45:\t train loss : 0.573983205928503; train accuracy : 0.9770640933473428; \n",
      " validation loss : 0.6716169143928582; validation accuracy : 0.8796992481203008\n",
      "Epoch 46:\t train loss : 0.5686599565092354; train accuracy : 0.9826079743405408; \n",
      " validation loss : 0.6742945989346206; validation accuracy : 0.8721804511278195\n",
      "Epoch 47:\t train loss : 0.568061972390895; train accuracy : 0.9829674279710225; \n",
      " validation loss : 0.6711361181297314; validation accuracy : 0.8796992481203008\n",
      "Epoch 48:\t train loss : 0.5624383110086567; train accuracy : 0.9886910357794614; \n",
      " validation loss : 0.6541027622891186; validation accuracy : 0.9022556390977443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49:\t train loss : 0.5602604266665069; train accuracy : 0.9909307084001548; \n",
      " validation loss : 0.655958853372726; validation accuracy : 0.8947368421052632\n",
      "Epoch 50:\t train loss : 0.5589477773952264; train accuracy : 0.9924791240391528; \n",
      " validation loss : 0.6297067219776408; validation accuracy : 0.924812030075188\n",
      "Epoch 51:\t train loss : 0.56109989237019; train accuracy : 0.9901150251617541; \n",
      " validation loss : 0.6259753449461046; validation accuracy : 0.924812030075188\n",
      "Epoch 52:\t train loss : 0.5601090835178572; train accuracy : 0.9911380854946635; \n",
      " validation loss : 0.6490120784157435; validation accuracy : 0.9022556390977443\n",
      "Epoch 53:\t train loss : 0.5573071705694784; train accuracy : 0.9942072664933915; \n",
      " validation loss : 0.6380177420650868; validation accuracy : 0.9097744360902256\n",
      "Epoch 54:\t train loss : 0.5598567609697565; train accuracy : 0.9912763368910026; \n",
      " validation loss : 0.6538469859799871; validation accuracy : 0.8947368421052632\n",
      "Epoch 55:\t train loss : 0.5935434415783708; train accuracy : 0.9570591162970746; \n",
      " validation loss : 0.6925859506727283; validation accuracy : 0.8571428571428571\n",
      "Epoch 56:\t train loss : 0.5691826172149348; train accuracy : 0.9820134933362827; \n",
      " validation loss : 0.6420092397651663; validation accuracy : 0.9022556390977443\n",
      "Epoch 57:\t train loss : 0.5613223824116018; train accuracy : 0.9899629486257812; \n",
      " validation loss : 0.6650488268879747; validation accuracy : 0.8872180451127819\n",
      "Epoch 58:\t train loss : 0.5619999659462133; train accuracy : 0.9893961179007909; \n",
      " validation loss : 0.7025591504130058; validation accuracy : 0.849624060150376\n",
      "Epoch 59:\t train loss : 0.6074306733748439; train accuracy : 0.9430404247082895; \n",
      " validation loss : 0.6460345731073788; validation accuracy : 0.9022556390977443\n",
      "Epoch 60:\t train loss : 0.5817593589742073; train accuracy : 0.9693634905712548; \n",
      " validation loss : 0.7312409003359426; validation accuracy : 0.8120300751879699\n",
      "Epoch 61:\t train loss : 0.6059773826138307; train accuracy : 0.9446994414643588; \n",
      " validation loss : 0.6619566906502435; validation accuracy : 0.8872180451127819\n",
      "Epoch 62:\t train loss : 0.5686010912798959; train accuracy : 0.9825941492009069; \n",
      " validation loss : 0.6641590708978115; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.5741814391004341; train accuracy : 0.9767046397168612; \n",
      " validation loss : 0.6579452991290701; validation accuracy : 0.8947368421052632\n",
      "Epoch 64:\t train loss : 0.5724910855760601; train accuracy : 0.9785433832881713; \n",
      " validation loss : 0.6715958847804155; validation accuracy : 0.8796992481203008\n",
      "Epoch 65:\t train loss : 0.561158439084098; train accuracy : 0.990598905048941; \n",
      " validation loss : 0.683664689339506; validation accuracy : 0.8646616541353384\n",
      "Epoch 66:\t train loss : 0.5615518299926784; train accuracy : 0.9898938229276115; \n",
      " validation loss : 0.638182004925858; validation accuracy : 0.9097744360902256\n",
      "Epoch 67:\t train loss : 0.5627451821256845; train accuracy : 0.9882209810319085; \n",
      " validation loss : 0.6634347278158892; validation accuracy : 0.8872180451127819\n",
      "Epoch 68:\t train loss : 0.566006709007777; train accuracy : 0.9851794503124481; \n",
      " validation loss : 0.654151253798174; validation accuracy : 0.8947368421052632\n",
      "Epoch 69:\t train loss : 0.557922856667897; train accuracy : 0.9934468838135265; \n",
      " validation loss : 0.6502352428976602; validation accuracy : 0.9022556390977443\n",
      "Epoch 70:\t train loss : 0.5567615485943067; train accuracy : 0.9946496709616767; \n",
      " validation loss : 0.6907118194331736; validation accuracy : 0.8571428571428571\n",
      "Epoch 71:\t train loss : 0.5618251525500382; train accuracy : 0.9894099430404247; \n",
      " validation loss : 0.648490646985268; validation accuracy : 0.8947368421052632\n",
      "Epoch 72:\t train loss : 0.560331940742556; train accuracy : 0.9908201072830836; \n",
      " validation loss : 0.6476180074250124; validation accuracy : 0.9022556390977443\n",
      "Epoch 73:\t train loss : 0.5638464458574804; train accuracy : 0.9873361720953382; \n",
      " validation loss : 0.6413130687817487; validation accuracy : 0.9097744360902256\n",
      "Epoch 74:\t train loss : 0.5609144193638288; train accuracy : 0.9904053530940662; \n",
      " validation loss : 0.693676852589913; validation accuracy : 0.8571428571428571\n",
      "Epoch 75:\t train loss : 0.5638740184765794; train accuracy : 0.9873361720953382; \n",
      " validation loss : 0.6335614062728823; validation accuracy : 0.9172932330827067\n",
      "Epoch 76:\t train loss : 0.5584399664011857; train accuracy : 0.9928247525300006; \n",
      " validation loss : 0.6339192995678984; validation accuracy : 0.9097744360902256\n",
      "Epoch 77:\t train loss : 0.5623506611112484; train accuracy : 0.9888707625947022; \n",
      " validation loss : 0.6747102683632229; validation accuracy : 0.8721804511278195\n",
      "Early stopping at epoch 77\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.567998826967596; Train accuracy : 0.9832577559033346; \n",
      " Validation loss : 0.6085150392287151; Validation accuracy : 0.9398496240601504\n",
      "------------------------------ Let's train model 25 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.896081861681306; train accuracy : 0.6343112315434386; \n",
      " validation loss : 0.8517070929914279; validation accuracy : 0.6917293233082706\n",
      "Epoch 2:\t train loss : 0.7848449669359924; train accuracy : 0.7603965050047006; \n",
      " validation loss : 0.8042014876378479; validation accuracy : 0.7368421052631579\n",
      "Epoch 3:\t train loss : 0.7422004846713808; train accuracy : 0.8044987004368744; \n",
      " validation loss : 0.7929807634826899; validation accuracy : 0.7368421052631579\n",
      "Epoch 4:\t train loss : 0.6986154708751924; train accuracy : 0.851255322678759; \n",
      " validation loss : 0.7299388285105533; validation accuracy : 0.8120300751879699\n",
      "Epoch 5:\t train loss : 0.6809121851460841; train accuracy : 0.8672648343748272; \n",
      " validation loss : 0.754761279734761; validation accuracy : 0.7819548872180451\n",
      "Epoch 6:\t train loss : 0.6638985598056754; train accuracy : 0.8862052756732843; \n",
      " validation loss : 0.7313764847769737; validation accuracy : 0.8195488721804511\n",
      "Epoch 7:\t train loss : 0.645837797149213; train accuracy : 0.9043853342918764; \n",
      " validation loss : 0.7244273249450335; validation accuracy : 0.8270676691729323\n",
      "Epoch 8:\t train loss : 0.6432656360457615; train accuracy : 0.9069982856826854; \n",
      " validation loss : 0.7101854772681104; validation accuracy : 0.849624060150376\n",
      "Epoch 9:\t train loss : 0.6289851812660587; train accuracy : 0.9217358845324338; \n",
      " validation loss : 0.6631702139292157; validation accuracy : 0.8872180451127819\n",
      "Epoch 10:\t train loss : 0.6187507148694206; train accuracy : 0.931717635348117; \n",
      " validation loss : 0.7098578343299369; validation accuracy : 0.8270676691729323\n",
      "Epoch 11:\t train loss : 0.6260342361697484; train accuracy : 0.9245009124592158; \n",
      " validation loss : 0.6660872628632477; validation accuracy : 0.8796992481203008\n",
      "Epoch 12:\t train loss : 0.6145428226596906; train accuracy : 0.9366946856163247; \n",
      " validation loss : 0.680529289381022; validation accuracy : 0.8646616541353384\n",
      "Epoch 13:\t train loss : 0.6050154837594409; train accuracy : 0.946054305148482; \n",
      " validation loss : 0.6401631906181535; validation accuracy : 0.9097744360902256\n",
      "Epoch 14:\t train loss : 0.5979218588934827; train accuracy : 0.9531604269203119; \n",
      " validation loss : 0.6806417085815901; validation accuracy : 0.8646616541353384\n",
      "Epoch 15:\t train loss : 0.6017875500384766; train accuracy : 0.9495105900569596; \n",
      " validation loss : 0.6242925378914493; validation accuracy : 0.9323308270676691\n",
      "Epoch 16:\t train loss : 0.5930212680415214; train accuracy : 0.9580960017696178; \n",
      " validation loss : 0.6454576500562279; validation accuracy : 0.9097744360902256\n",
      "Epoch 17:\t train loss : 0.5922550754353086; train accuracy : 0.9589393352872864; \n",
      " validation loss : 0.6457031925009868; validation accuracy : 0.8947368421052632\n",
      "Epoch 18:\t train loss : 0.589161358877031; train accuracy : 0.9621605928219875; \n",
      " validation loss : 0.6518496472747181; validation accuracy : 0.8947368421052632\n",
      "Epoch 19:\t train loss : 0.5966983458148659; train accuracy : 0.9541005364154178; \n",
      " validation loss : 0.6461929039522621; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5933200669216754; train accuracy : 0.9576950727202345; \n",
      " validation loss : 0.6505738073219666; validation accuracy : 0.9022556390977443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:\t train loss : 0.5802707665652468; train accuracy : 0.9711192833047614; \n",
      " validation loss : 0.6629210638730317; validation accuracy : 0.8872180451127819\n",
      "Epoch 22:\t train loss : 0.575569676429656; train accuracy : 0.9764004866449151; \n",
      " validation loss : 0.6587749279929105; validation accuracy : 0.8947368421052632\n",
      "Epoch 23:\t train loss : 0.5727860588354196; train accuracy : 0.9786263341259747; \n",
      " validation loss : 0.6470420937183249; validation accuracy : 0.9022556390977443\n",
      "Epoch 24:\t train loss : 0.5708981137236714; train accuracy : 0.9803959519991152; \n",
      " validation loss : 0.6347014804498698; validation accuracy : 0.9097744360902256\n",
      "Epoch 25:\t train loss : 0.5709978681449318; train accuracy : 0.9804512525576509; \n",
      " validation loss : 0.6651390147204054; validation accuracy : 0.8796992481203008\n",
      "Epoch 26:\t train loss : 0.5713140539325642; train accuracy : 0.9802438754631422; \n",
      " validation loss : 0.6098903652181006; validation accuracy : 0.9398496240601504\n",
      "Epoch 27:\t train loss : 0.5696034579742937; train accuracy : 0.9823038212685948; \n",
      " validation loss : 0.6369411768591059; validation accuracy : 0.9097744360902256\n",
      "Epoch 28:\t train loss : 0.575224844459802; train accuracy : 0.9760825084333352; \n",
      " validation loss : 0.656933890705941; validation accuracy : 0.8872180451127819\n",
      "Epoch 29:\t train loss : 0.5784752106008919; train accuracy : 0.9725432726870541; \n",
      " validation loss : 0.6351423948038003; validation accuracy : 0.9172932330827067\n",
      "Epoch 30:\t train loss : 0.575473531487283; train accuracy : 0.9758474810595587; \n",
      " validation loss : 0.6526752953840135; validation accuracy : 0.9022556390977443\n",
      "Epoch 31:\t train loss : 0.5700146695135189; train accuracy : 0.9812945860753194; \n",
      " validation loss : 0.6757422417082727; validation accuracy : 0.8721804511278195\n",
      "Epoch 32:\t train loss : 0.5646465096442529; train accuracy : 0.9867555162307139; \n",
      " validation loss : 0.6394717858811068; validation accuracy : 0.9172932330827067\n",
      "Epoch 33:\t train loss : 0.5648053990217901; train accuracy : 0.9867002156721782; \n",
      " validation loss : 0.6112407195726192; validation accuracy : 0.9323308270676691\n",
      "Epoch 34:\t train loss : 0.5657411546414238; train accuracy : 0.985663330199635; \n",
      " validation loss : 0.6554971299901613; validation accuracy : 0.8947368421052632\n",
      "Epoch 35:\t train loss : 0.5663941764425545; train accuracy : 0.985207100591716; \n",
      " validation loss : 0.6400829407722471; validation accuracy : 0.9022556390977443\n",
      "Epoch 36:\t train loss : 0.5704831559567021; train accuracy : 0.9807139302106951; \n",
      " validation loss : 0.6753824590299788; validation accuracy : 0.8796992481203008\n",
      "Epoch 37:\t train loss : 0.5968400085976181; train accuracy : 0.9537549079245701; \n",
      " validation loss : 0.6855100496756054; validation accuracy : 0.8646616541353384\n",
      "Epoch 38:\t train loss : 0.5825499894079817; train accuracy : 0.9685616324724879; \n",
      " validation loss : 0.6617058523604832; validation accuracy : 0.8872180451127819\n",
      "Epoch 39:\t train loss : 0.582581764433695; train accuracy : 0.968395730796881; \n",
      " validation loss : 0.6412238102829044; validation accuracy : 0.9097744360902256\n",
      "Epoch 40:\t train loss : 0.6076285182031564; train accuracy : 0.9425703699607366; \n",
      " validation loss : 0.6560664945242944; validation accuracy : 0.8872180451127819\n",
      "Epoch 41:\t train loss : 0.5717501916686089; train accuracy : 0.9794834927832771; \n",
      " validation loss : 0.6348675814342151; validation accuracy : 0.9172932330827067\n",
      "Epoch 42:\t train loss : 0.5661321233638438; train accuracy : 0.9854559531051263; \n",
      " validation loss : 0.6196428024714908; validation accuracy : 0.9323308270676691\n",
      "Epoch 43:\t train loss : 0.5630832328903174; train accuracy : 0.9884836586849527; \n",
      " validation loss : 0.6346439028403118; validation accuracy : 0.9172932330827067\n",
      "Epoch 44:\t train loss : 0.5676066403926419; train accuracy : 0.9837416357905215; \n",
      " validation loss : 0.6389239393095882; validation accuracy : 0.9097744360902256\n",
      "Epoch 45:\t train loss : 0.5650523424274735; train accuracy : 0.9863822374605984; \n",
      " validation loss : 0.6158578555160358; validation accuracy : 0.9398496240601504\n",
      "Epoch 46:\t train loss : 0.5629924625833974; train accuracy : 0.9884007078471493; \n",
      " validation loss : 0.6376336690381836; validation accuracy : 0.9172932330827067\n",
      "Epoch 47:\t train loss : 0.5754536581221709; train accuracy : 0.9752944754742023; \n",
      " validation loss : 0.6773082798434924; validation accuracy : 0.8721804511278195\n",
      "Epoch 48:\t train loss : 0.5887069515016182; train accuracy : 0.9621329425427196; \n",
      " validation loss : 0.6249191627796251; validation accuracy : 0.924812030075188\n",
      "Epoch 49:\t train loss : 0.5675530297081431; train accuracy : 0.9835619089752806; \n",
      " validation loss : 0.6447358324710686; validation accuracy : 0.9097744360902256\n",
      "Epoch 50:\t train loss : 0.5849930587593768; train accuracy : 0.9656721782890008; \n",
      " validation loss : 0.6451093752243995; validation accuracy : 0.9097744360902256\n",
      "Epoch 51:\t train loss : 0.5637496073762779; train accuracy : 0.9875711994691146; \n",
      " validation loss : 0.6045668773966809; validation accuracy : 0.9473684210526315\n",
      "Epoch 52:\t train loss : 0.5621070852476594; train accuracy : 0.9892855167837196; \n",
      " validation loss : 0.6347618019824465; validation accuracy : 0.9172932330827067\n",
      "Epoch 53:\t train loss : 0.5671130707993506; train accuracy : 0.9838798871868606; \n",
      " validation loss : 0.6569942781436097; validation accuracy : 0.8947368421052632\n",
      "Epoch 54:\t train loss : 0.5700063762148745; train accuracy : 0.9813775369131228; \n",
      " validation loss : 0.6641723097517722; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5626516603733015; train accuracy : 0.9887325111983631; \n",
      " validation loss : 0.6497838552446749; validation accuracy : 0.9022556390977443\n",
      "Epoch 56:\t train loss : 0.5635898637189921; train accuracy : 0.9875988497483824; \n",
      " validation loss : 0.6622052697973008; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5650569642872219; train accuracy : 0.9861610352264558; \n",
      " validation loss : 0.6574979745617642; validation accuracy : 0.8947368421052632\n",
      "Epoch 58:\t train loss : 0.5592919190944771; train accuracy : 0.9921196704086711; \n",
      " validation loss : 0.6522999253535519; validation accuracy : 0.9022556390977443\n",
      "Epoch 59:\t train loss : 0.5597760085490641; train accuracy : 0.9915943151025826; \n",
      " validation loss : 0.6455167453318711; validation accuracy : 0.9022556390977443\n",
      "Epoch 60:\t train loss : 0.5608705312176395; train accuracy : 0.9904883039318697; \n",
      " validation loss : 0.6102167168251166; validation accuracy : 0.9398496240601504\n",
      "Epoch 61:\t train loss : 0.5610108531268962; train accuracy : 0.9904191782337002; \n",
      " validation loss : 0.6502603695590489; validation accuracy : 0.9022556390977443\n",
      "Epoch 62:\t train loss : 0.5609297431026924; train accuracy : 0.9905297793507715; \n",
      " validation loss : 0.6280262520092371; validation accuracy : 0.924812030075188\n",
      "Epoch 63:\t train loss : 0.5602826160023596; train accuracy : 0.990916883260521; \n",
      " validation loss : 0.6546291706345455; validation accuracy : 0.8947368421052632\n",
      "Epoch 64:\t train loss : 0.5596350430878837; train accuracy : 0.9916081402422164; \n",
      " validation loss : 0.6281653069474478; validation accuracy : 0.924812030075188\n",
      "Epoch 65:\t train loss : 0.5617152159774156; train accuracy : 0.989520544157496; \n",
      " validation loss : 0.6458330068560584; validation accuracy : 0.9022556390977443\n",
      "Epoch 66:\t train loss : 0.5699494526798188; train accuracy : 0.9810457335619089; \n",
      " validation loss : 0.6822631587252074; validation accuracy : 0.8571428571428571\n",
      "Epoch 67:\t train loss : 0.5749877779151656; train accuracy : 0.9760825084333352; \n",
      " validation loss : 0.6298728563596382; validation accuracy : 0.924812030075188\n",
      "Epoch 68:\t train loss : 0.5705604060277164; train accuracy : 0.980575678814356; \n",
      " validation loss : 0.6779360509778605; validation accuracy : 0.8646616541353384\n",
      "Epoch 69:\t train loss : 0.5780251241987381; train accuracy : 0.9730686279931428; \n",
      " validation loss : 0.6591058179973253; validation accuracy : 0.8872180451127819\n",
      "Epoch 70:\t train loss : 0.5721707714528684; train accuracy : 0.9789443123375546; \n",
      " validation loss : 0.6632235380247204; validation accuracy : 0.8872180451127819\n",
      "Epoch 71:\t train loss : 0.5651735978306939; train accuracy : 0.9860504341093845; \n",
      " validation loss : 0.6468622422798949; validation accuracy : 0.9022556390977443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72:\t train loss : 0.5635691631676549; train accuracy : 0.9878891776806946; \n",
      " validation loss : 0.6544459109457977; validation accuracy : 0.8947368421052632\n",
      "Epoch 73:\t train loss : 0.5665821884152278; train accuracy : 0.9845158436100204; \n",
      " validation loss : 0.659441994946431; validation accuracy : 0.8872180451127819\n",
      "Epoch 74:\t train loss : 0.6239804574183784; train accuracy : 0.9263811314494277; \n",
      " validation loss : 0.6953558464185672; validation accuracy : 0.8571428571428571\n",
      "Epoch 75:\t train loss : 0.6227581849288342; train accuracy : 0.9270447381518553; \n",
      " validation loss : 0.6742699838344112; validation accuracy : 0.8721804511278195\n",
      "Epoch 76:\t train loss : 0.5925607038460926; train accuracy : 0.958234253165957; \n",
      " validation loss : 0.6483647710849965; validation accuracy : 0.9022556390977443\n",
      "Epoch 77:\t train loss : 0.583070325632554; train accuracy : 0.9675109218603107; \n",
      " validation loss : 0.6844900952062623; validation accuracy : 0.8571428571428571\n",
      "Epoch 78:\t train loss : 0.5797063374440441; train accuracy : 0.9707874799535475; \n",
      " validation loss : 0.7104597634970552; validation accuracy : 0.8421052631578947\n",
      "Epoch 79:\t train loss : 0.5679808788318566; train accuracy : 0.9831056793673616; \n",
      " validation loss : 0.6480168020408908; validation accuracy : 0.9022556390977443\n",
      "Epoch 80:\t train loss : 0.5673980697035169; train accuracy : 0.9836448598130841; \n",
      " validation loss : 0.6560867186496894; validation accuracy : 0.8947368421052632\n",
      "Epoch 81:\t train loss : 0.5645391001971956; train accuracy : 0.9866310899740087; \n",
      " validation loss : 0.6598573134147562; validation accuracy : 0.8947368421052632\n",
      "Epoch 82:\t train loss : 0.5863513947277347; train accuracy : 0.963778134159155; \n",
      " validation loss : 0.6377251874528054; validation accuracy : 0.9097744360902256\n",
      "Epoch 83:\t train loss : 0.5650683846503719; train accuracy : 0.9865757894154731; \n",
      " validation loss : 0.6703231373887921; validation accuracy : 0.8796992481203008\n",
      "Epoch 84:\t train loss : 0.562171375747896; train accuracy : 0.9894237681800586; \n",
      " validation loss : 0.6606636780186609; validation accuracy : 0.8947368421052632\n",
      "Epoch 85:\t train loss : 0.5629471791393792; train accuracy : 0.9883454072886136; \n",
      " validation loss : 0.6782426643522572; validation accuracy : 0.8721804511278195\n",
      "Epoch 86:\t train loss : 0.5646147857803319; train accuracy : 0.9866725653929105; \n",
      " validation loss : 0.642764904183801; validation accuracy : 0.9097744360902256\n",
      "Epoch 87:\t train loss : 0.5668214516442052; train accuracy : 0.9845158436100204; \n",
      " validation loss : 0.6426867476784339; validation accuracy : 0.9097744360902256\n",
      "Epoch 88:\t train loss : 0.5609685533207769; train accuracy : 0.9902256262788254; \n",
      " validation loss : 0.6438099801528762; validation accuracy : 0.9097744360902256\n",
      "Epoch 89:\t train loss : 0.5582701511680487; train accuracy : 0.9932118564397501; \n",
      " validation loss : 0.6228179250399708; validation accuracy : 0.9323308270676691\n",
      "Epoch 90:\t train loss : 0.5572592971517574; train accuracy : 0.9942349167726594; \n",
      " validation loss : 0.6421827991540889; validation accuracy : 0.9097744360902256\n",
      "Epoch 91:\t train loss : 0.5572011402876906; train accuracy : 0.9942072664933915; \n",
      " validation loss : 0.6408427118103025; validation accuracy : 0.9172932330827067\n",
      "Epoch 92:\t train loss : 0.5596131889434636; train accuracy : 0.9918569927556268; \n",
      " validation loss : 0.6806334989996679; validation accuracy : 0.8646616541353384\n",
      "Epoch 93:\t train loss : 0.5576782437251893; train accuracy : 0.9936680860476691; \n",
      " validation loss : 0.6315544329469229; validation accuracy : 0.9172932330827067\n",
      "Epoch 94:\t train loss : 0.5613178342111768; train accuracy : 0.9900044240446828; \n",
      " validation loss : 0.6400602346563676; validation accuracy : 0.8947368421052632\n",
      "Epoch 95:\t train loss : 0.5695937489942485; train accuracy : 0.981501963169828; \n",
      " validation loss : 0.6566871114115588; validation accuracy : 0.8947368421052632\n",
      "Epoch 96:\t train loss : 0.57104122058403; train accuracy : 0.980119449206437; \n",
      " validation loss : 0.6645371588109988; validation accuracy : 0.8872180451127819\n",
      "Epoch 97:\t train loss : 0.5637425972871435; train accuracy : 0.9876956257258198; \n",
      " validation loss : 0.647426829731291; validation accuracy : 0.9097744360902256\n",
      "Epoch 98:\t train loss : 0.5645388805841453; train accuracy : 0.9866449151136426; \n",
      " validation loss : 0.6646022569369219; validation accuracy : 0.8872180451127819\n",
      "Epoch 99:\t train loss : 0.5646329326628088; train accuracy : 0.9865066637173036; \n",
      " validation loss : 0.6571073455593702; validation accuracy : 0.8947368421052632\n",
      "Epoch 100:\t train loss : 0.5631975115398767; train accuracy : 0.9881795056130067; \n",
      " validation loss : 0.6239995376994102; validation accuracy : 0.924812030075188\n",
      "Epoch 101:\t train loss : 0.5598081792760023; train accuracy : 0.9915943151025826; \n",
      " validation loss : 0.6372896330584228; validation accuracy : 0.9097744360902256\n",
      "Early stopping at epoch 101\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5637496073762779; Train accuracy : 0.9875711994691146; \n",
      " Validation loss : 0.6045668773966809; Validation accuracy : 0.9473684210526315\n",
      "------------------------------ Let's train model 26 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9011136482490715; train accuracy : 0.6269147818392966; \n",
      " validation loss : 0.8174934598931811; validation accuracy : 0.7142857142857143\n",
      "Epoch 2:\t train loss : 0.7815083810494267; train accuracy : 0.7587513133882652; \n",
      " validation loss : 0.793837464078421; validation accuracy : 0.7518796992481203\n",
      "Epoch 3:\t train loss : 0.7421841270752184; train accuracy : 0.803627716639938; \n",
      " validation loss : 0.6995017167259866; validation accuracy : 0.849624060150376\n",
      "Epoch 4:\t train loss : 0.6948244390430824; train accuracy : 0.8556102416634408; \n",
      " validation loss : 0.7005149059532937; validation accuracy : 0.8571428571428571\n",
      "Epoch 5:\t train loss : 0.6617308680574716; train accuracy : 0.8888597024829951; \n",
      " validation loss : 0.6697562983805445; validation accuracy : 0.8721804511278195\n",
      "Epoch 6:\t train loss : 0.6396659397612009; train accuracy : 0.9121550627661339; \n",
      " validation loss : 0.6868715738521088; validation accuracy : 0.849624060150376\n",
      "Epoch 7:\t train loss : 0.6159260679772943; train accuracy : 0.9362799314273074; \n",
      " validation loss : 0.660839272145804; validation accuracy : 0.8947368421052632\n",
      "Epoch 8:\t train loss : 0.6072443892390365; train accuracy : 0.9442155615771719; \n",
      " validation loss : 0.6666384585668834; validation accuracy : 0.8872180451127819\n",
      "Epoch 9:\t train loss : 0.599699389144214; train accuracy : 0.9519023392136261; \n",
      " validation loss : 0.6459441282923524; validation accuracy : 0.9097744360902256\n",
      "Epoch 10:\t train loss : 0.5828350113605917; train accuracy : 0.9693634905712548; \n",
      " validation loss : 0.6990253618110287; validation accuracy : 0.849624060150376\n",
      "Epoch 11:\t train loss : 0.5834946764036492; train accuracy : 0.9685754576121218; \n",
      " validation loss : 0.6786006337965416; validation accuracy : 0.8646616541353384\n",
      "Epoch 12:\t train loss : 0.5825567381857848; train accuracy : 0.9688381352651662; \n",
      " validation loss : 0.6562222767403603; validation accuracy : 0.8872180451127819\n",
      "Epoch 13:\t train loss : 0.5777280525662284; train accuracy : 0.9740640380467843; \n",
      " validation loss : 0.6959064514714662; validation accuracy : 0.849624060150376\n",
      "Epoch 14:\t train loss : 0.5735848112147667; train accuracy : 0.9782115799369574; \n",
      " validation loss : 0.6714067017975633; validation accuracy : 0.8646616541353384\n",
      "Epoch 15:\t train loss : 0.5798958683135264; train accuracy : 0.9711192833047614; \n",
      " validation loss : 0.647022999154446; validation accuracy : 0.9022556390977443\n",
      "Epoch 16:\t train loss : 0.5739893930111567; train accuracy : 0.977036443068075; \n",
      " validation loss : 0.6788343114345183; validation accuracy : 0.8571428571428571\n",
      "Epoch 17:\t train loss : 0.5666918222308719; train accuracy : 0.9850135486368412; \n",
      " validation loss : 0.693102713551795; validation accuracy : 0.8646616541353384\n",
      "Epoch 18:\t train loss : 0.5723358948047257; train accuracy : 0.9793175911076701; \n",
      " validation loss : 0.6794320961625607; validation accuracy : 0.8571428571428571\n",
      "Epoch 19:\t train loss : 0.5654498683245281; train accuracy : 0.9860919095282863; \n",
      " validation loss : 0.6941770286539756; validation accuracy : 0.849624060150376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:\t train loss : 0.5799830200691305; train accuracy : 0.9709119062102527; \n",
      " validation loss : 0.7607199467070374; validation accuracy : 0.7819548872180451\n",
      "Epoch 21:\t train loss : 0.5839253145395769; train accuracy : 0.9666122877841066; \n",
      " validation loss : 0.6899399778168983; validation accuracy : 0.8571428571428571\n",
      "Epoch 22:\t train loss : 0.5660729665469242; train accuracy : 0.9854006525465907; \n",
      " validation loss : 0.6550443342913131; validation accuracy : 0.8947368421052632\n",
      "Epoch 23:\t train loss : 0.5622042811801754; train accuracy : 0.9893408173422552; \n",
      " validation loss : 0.6989188216420786; validation accuracy : 0.8421052631578947\n",
      "Epoch 24:\t train loss : 0.5612754985064206; train accuracy : 0.9902671016977271; \n",
      " validation loss : 0.6632802799302221; validation accuracy : 0.8872180451127819\n",
      "Epoch 25:\t train loss : 0.5665992787227387; train accuracy : 0.9850964994746447; \n",
      " validation loss : 0.6626060900201853; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5629743727650206; train accuracy : 0.9887739866172648; \n",
      " validation loss : 0.7248684111229281; validation accuracy : 0.8195488721804511\n",
      "Epoch 27:\t train loss : 0.5770873061844601; train accuracy : 0.9738566609522756; \n",
      " validation loss : 0.6959249906777358; validation accuracy : 0.849624060150376\n",
      "Epoch 28:\t train loss : 0.5650648444756369; train accuracy : 0.9860780843886523; \n",
      " validation loss : 0.6738204830102532; validation accuracy : 0.8796992481203008\n",
      "Epoch 29:\t train loss : 0.5644942345829119; train accuracy : 0.9867693413703479; \n",
      " validation loss : 0.6950971270836154; validation accuracy : 0.849624060150376\n",
      "Epoch 30:\t train loss : 0.5765815035346589; train accuracy : 0.974713819609578; \n",
      " validation loss : 0.6889752545078561; validation accuracy : 0.8646616541353384\n",
      "Epoch 31:\t train loss : 0.5638765204411353; train accuracy : 0.9877924017032572; \n",
      " validation loss : 0.678770121214903; validation accuracy : 0.8721804511278195\n",
      "Epoch 32:\t train loss : 0.5596336122582503; train accuracy : 0.9920367195708677; \n",
      " validation loss : 0.6943830119730185; validation accuracy : 0.8571428571428571\n",
      "Epoch 33:\t train loss : 0.5667672459576113; train accuracy : 0.9846126195874578; \n",
      " validation loss : 0.6654442986730418; validation accuracy : 0.8872180451127819\n",
      "Epoch 34:\t train loss : 0.5642595830899708; train accuracy : 0.9868661173477852; \n",
      " validation loss : 0.6828307235830903; validation accuracy : 0.8646616541353384\n",
      "Epoch 35:\t train loss : 0.560990616941802; train accuracy : 0.9906265553282088; \n",
      " validation loss : 0.6793418872703314; validation accuracy : 0.8721804511278195\n",
      "Epoch 36:\t train loss : 0.5685764867216067; train accuracy : 0.9826079743405408; \n",
      " validation loss : 0.6648292513069874; validation accuracy : 0.8796992481203008\n",
      "Epoch 37:\t train loss : 0.5626809603655252; train accuracy : 0.9887739866172648; \n",
      " validation loss : 0.6931368119113485; validation accuracy : 0.8571428571428571\n",
      "Epoch 38:\t train loss : 0.5846398117380393; train accuracy : 0.9660731073383841; \n",
      " validation loss : 0.7164122972017971; validation accuracy : 0.8270676691729323\n",
      "Epoch 39:\t train loss : 0.5733400189903104; train accuracy : 0.9777415251894044; \n",
      " validation loss : 0.7040395735490076; validation accuracy : 0.849624060150376\n",
      "Epoch 40:\t train loss : 0.5661683583437096; train accuracy : 0.9851379748935464; \n",
      " validation loss : 0.6730804104616483; validation accuracy : 0.8721804511278195\n",
      "Epoch 41:\t train loss : 0.5578464631053773; train accuracy : 0.9936127854891335; \n",
      " validation loss : 0.7048463124242578; validation accuracy : 0.8345864661654135\n",
      "Epoch 42:\t train loss : 0.5616048215137978; train accuracy : 0.9899076480672455; \n",
      " validation loss : 0.6811172551955093; validation accuracy : 0.8646616541353384\n",
      "Epoch 43:\t train loss : 0.5554373915685475; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6679410928399588; validation accuracy : 0.8872180451127819\n",
      "Epoch 44:\t train loss : 0.5605082602911008; train accuracy : 0.9907648067245479; \n",
      " validation loss : 0.6704958654988524; validation accuracy : 0.8721804511278195\n",
      "Epoch 45:\t train loss : 0.5564498178087084; train accuracy : 0.9949952994525244; \n",
      " validation loss : 0.6861175342236097; validation accuracy : 0.8646616541353384\n",
      "Epoch 46:\t train loss : 0.5574434590564009; train accuracy : 0.9939031134214455; \n",
      " validation loss : 0.673969515778946; validation accuracy : 0.8796992481203008\n",
      "Epoch 47:\t train loss : 0.5558755805858558; train accuracy : 0.9956727312945861; \n",
      " validation loss : 0.6814873426679642; validation accuracy : 0.8721804511278195\n",
      "Epoch 48:\t train loss : 0.6215542862254545; train accuracy : 0.9281230990433004; \n",
      " validation loss : 0.7141491086428204; validation accuracy : 0.8345864661654135\n",
      "Epoch 49:\t train loss : 0.5683351413720085; train accuracy : 0.9828015262954156; \n",
      " validation loss : 0.6577349950051857; validation accuracy : 0.8947368421052632\n",
      "Epoch 50:\t train loss : 0.5566779528731727; train accuracy : 0.9946358458220428; \n",
      " validation loss : 0.6627073386218274; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5639410753505252; train accuracy : 0.9873223469557042; \n",
      " validation loss : 0.6651877570314837; validation accuracy : 0.8796992481203008\n",
      "Epoch 52:\t train loss : 0.5587722416585904; train accuracy : 0.992589725156224; \n",
      " validation loss : 0.6639116387083872; validation accuracy : 0.8872180451127819\n",
      "Epoch 53:\t train loss : 0.5547521530944469; train accuracy : 0.996599015650058; \n",
      " validation loss : 0.67803557326407; validation accuracy : 0.8721804511278195\n",
      "Epoch 54:\t train loss : 0.5542814529352891; train accuracy : 0.9972902726317535; \n",
      " validation loss : 0.6710532458050651; validation accuracy : 0.8796992481203008\n",
      "Epoch 55:\t train loss : 0.5529571269764966; train accuracy : 0.9984377592213681; \n",
      " validation loss : 0.6427726235138065; validation accuracy : 0.9097744360902256\n",
      "Epoch 56:\t train loss : 0.5536841223271555; train accuracy : 0.9974838245866283; \n",
      " validation loss : 0.6639704390595227; validation accuracy : 0.8796992481203008\n",
      "Epoch 57:\t train loss : 0.6123340707396533; train accuracy : 0.9380218990211802; \n",
      " validation loss : 0.681743270079736; validation accuracy : 0.8721804511278195\n",
      "Epoch 58:\t train loss : 0.5801530568703561; train accuracy : 0.9705939279986728; \n",
      " validation loss : 0.7016544073316314; validation accuracy : 0.849624060150376\n",
      "Epoch 59:\t train loss : 0.5671879553609293; train accuracy : 0.9837554609301554; \n",
      " validation loss : 0.7202414998759449; validation accuracy : 0.8270676691729323\n",
      "Epoch 60:\t train loss : 0.5587338375632656; train accuracy : 0.9926726759940275; \n",
      " validation loss : 0.6830371676915918; validation accuracy : 0.8646616541353384\n",
      "Epoch 61:\t train loss : 0.5561448716295762; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.7164865335357556; validation accuracy : 0.8270676691729323\n",
      "Epoch 62:\t train loss : 0.5548914769666091; train accuracy : 0.9964331139744511; \n",
      " validation loss : 0.6706771610281622; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.5547331141877544; train accuracy : 0.9968063927445667; \n",
      " validation loss : 0.6524165788409025; validation accuracy : 0.8947368421052632\n",
      "Epoch 64:\t train loss : 0.5544828474138137; train accuracy : 0.9968755184427363; \n",
      " validation loss : 0.6689770667398824; validation accuracy : 0.8872180451127819\n",
      "Epoch 65:\t train loss : 0.575188943069965; train accuracy : 0.9759580821766299; \n",
      " validation loss : 0.6882809664387057; validation accuracy : 0.8646616541353384\n",
      "Epoch 66:\t train loss : 0.5603152629726023; train accuracy : 0.9909721838190566; \n",
      " validation loss : 0.671215496532545; validation accuracy : 0.8796992481203008\n",
      "Epoch 67:\t train loss : 0.5559973336772813; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.6857630532139205; validation accuracy : 0.8646616541353384\n",
      "Epoch 68:\t train loss : 0.5581201371033616; train accuracy : 0.9931427307415804; \n",
      " validation loss : 0.6669905753182517; validation accuracy : 0.8796992481203008\n",
      "Epoch 69:\t train loss : 0.5767537074380105; train accuracy : 0.9745340927943372; \n",
      " validation loss : 0.6686691324091523; validation accuracy : 0.8796992481203008\n",
      "Epoch 70:\t train loss : 0.5608908762120765; train accuracy : 0.9904606536526018; \n",
      " validation loss : 0.7044382930971457; validation accuracy : 0.8421052631578947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71:\t train loss : 0.5672427909221007; train accuracy : 0.9841702151191727; \n",
      " validation loss : 0.65831443486084; validation accuracy : 0.8872180451127819\n",
      "Epoch 72:\t train loss : 0.5742016897823307; train accuracy : 0.9767046397168612; \n",
      " validation loss : 0.6883198353851572; validation accuracy : 0.8646616541353384\n",
      "Epoch 73:\t train loss : 0.5551062636154078; train accuracy : 0.9961842614610408; \n",
      " validation loss : 0.6694020531572502; validation accuracy : 0.8796992481203008\n",
      "Epoch 74:\t train loss : 0.5536487031370297; train accuracy : 0.9978294530774761; \n",
      " validation loss : 0.6473656721700629; validation accuracy : 0.9022556390977443\n",
      "Epoch 75:\t train loss : 0.5528777429363573; train accuracy : 0.9985621854780733; \n",
      " validation loss : 0.659456411125516; validation accuracy : 0.8872180451127819\n",
      "Epoch 76:\t train loss : 0.5588290104390155; train accuracy : 0.9926450257147598; \n",
      " validation loss : 0.6416787415354679; validation accuracy : 0.9097744360902256\n",
      "Epoch 77:\t train loss : 0.5571102052478977; train accuracy : 0.9942487419122933; \n",
      " validation loss : 0.6657610429181606; validation accuracy : 0.8796992481203008\n",
      "Epoch 78:\t train loss : 0.5564855160403703; train accuracy : 0.9949676491732566; \n",
      " validation loss : 0.6641408298180763; validation accuracy : 0.8872180451127819\n",
      "Epoch 79:\t train loss : 0.5584312887404986; train accuracy : 0.9928524028092683; \n",
      " validation loss : 0.6909462071462958; validation accuracy : 0.8571428571428571\n",
      "Epoch 80:\t train loss : 0.5935983576639023; train accuracy : 0.9567964386440303; \n",
      " validation loss : 0.7087436507182517; validation accuracy : 0.8345864661654135\n",
      "Epoch 81:\t train loss : 0.560449353325568; train accuracy : 0.9907233313056462; \n",
      " validation loss : 0.7073701481081917; validation accuracy : 0.8421052631578947\n",
      "Epoch 82:\t train loss : 0.5567328320737376; train accuracy : 0.9946496709616767; \n",
      " validation loss : 0.6641837586753888; validation accuracy : 0.8872180451127819\n",
      "Epoch 83:\t train loss : 0.5547968711731526; train accuracy : 0.9965851905104242; \n",
      " validation loss : 0.6570645871286244; validation accuracy : 0.8872180451127819\n",
      "Epoch 84:\t train loss : 0.5567574691907372; train accuracy : 0.994456119006802; \n",
      " validation loss : 0.7232649164790536; validation accuracy : 0.8270676691729323\n",
      "Epoch 85:\t train loss : 0.5542711191483549; train accuracy : 0.9970967206768788; \n",
      " validation loss : 0.6843333820922025; validation accuracy : 0.8646616541353384\n",
      "Epoch 86:\t train loss : 0.5549013148576033; train accuracy : 0.9964745893933529; \n",
      " validation loss : 0.6865531221401786; validation accuracy : 0.8646616541353384\n",
      "Epoch 87:\t train loss : 0.5538772479710297; train accuracy : 0.9975529502847978; \n",
      " validation loss : 0.6389475888134385; validation accuracy : 0.9172932330827067\n",
      "Epoch 88:\t train loss : 0.5536907446843891; train accuracy : 0.9977050268207709; \n",
      " validation loss : 0.6924984694497244; validation accuracy : 0.849624060150376\n",
      "Epoch 89:\t train loss : 0.5531435216927362; train accuracy : 0.9983409832439307; \n",
      " validation loss : 0.6803120172424918; validation accuracy : 0.8721804511278195\n",
      "Epoch 90:\t train loss : 0.553430999201921; train accuracy : 0.9979262290549135; \n",
      " validation loss : 0.6639511273026246; validation accuracy : 0.8872180451127819\n",
      "Epoch 91:\t train loss : 0.553797519929842; train accuracy : 0.9976082508433335; \n",
      " validation loss : 0.6605083101707336; validation accuracy : 0.8947368421052632\n",
      "Epoch 92:\t train loss : 0.5563718655362225; train accuracy : 0.9949952994525245; \n",
      " validation loss : 0.654853709826041; validation accuracy : 0.8947368421052632\n",
      "Epoch 93:\t train loss : 0.5646748522598806; train accuracy : 0.9863407620416966; \n",
      " validation loss : 0.6511918921171583; validation accuracy : 0.8947368421052632\n",
      "Epoch 94:\t train loss : 0.5573755814547934; train accuracy : 0.9939031134214455; \n",
      " validation loss : 0.6338499359411899; validation accuracy : 0.9172932330827067\n",
      "Epoch 95:\t train loss : 0.5828857529351961; train accuracy : 0.9682713045401758; \n",
      " validation loss : 0.7244907101404634; validation accuracy : 0.8270676691729323\n",
      "Epoch 96:\t train loss : 0.6044879877655527; train accuracy : 0.9458054526350717; \n",
      " validation loss : 0.7296818331966071; validation accuracy : 0.8270676691729323\n",
      "Epoch 97:\t train loss : 0.5766548188141358; train accuracy : 0.9741331637449538; \n",
      " validation loss : 0.6816973137546979; validation accuracy : 0.8571428571428571\n",
      "Epoch 98:\t train loss : 0.5594489382402258; train accuracy : 0.9919675938726981; \n",
      " validation loss : 0.6749504961126891; validation accuracy : 0.8796992481203008\n",
      "Epoch 99:\t train loss : 0.5551530070482282; train accuracy : 0.9961980866006747; \n",
      " validation loss : 0.6798464391103052; validation accuracy : 0.8721804511278195\n",
      "Epoch 100:\t train loss : 0.5543069081269758; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.6526579953805236; validation accuracy : 0.8947368421052632\n",
      "Epoch 101:\t train loss : 0.5530525136913272; train accuracy : 0.9983686335231986; \n",
      " validation loss : 0.6773341307179596; validation accuracy : 0.8646616541353384\n",
      "Epoch 102:\t train loss : 0.5531392766778574; train accuracy : 0.9982580324061273; \n",
      " validation loss : 0.6644769017924153; validation accuracy : 0.8872180451127819\n",
      "Epoch 103:\t train loss : 0.5541469380757327; train accuracy : 0.9972764474921196; \n",
      " validation loss : 0.6751609757743869; validation accuracy : 0.8796992481203008\n",
      "Epoch 104:\t train loss : 0.5598112827678455; train accuracy : 0.9913316374495382; \n",
      " validation loss : 0.6501820071278209; validation accuracy : 0.9022556390977443\n",
      "Epoch 105:\t train loss : 0.5555975046919893; train accuracy : 0.9957280318531218; \n",
      " validation loss : 0.6870482926570896; validation accuracy : 0.8646616541353384\n",
      "Epoch 106:\t train loss : 0.5639463084081937; train accuracy : 0.9874052977935077; \n",
      " validation loss : 0.6589932310155082; validation accuracy : 0.8947368421052632\n",
      "Epoch 107:\t train loss : 0.5612200327874599; train accuracy : 0.990142675441022; \n",
      " validation loss : 0.7001880910391554; validation accuracy : 0.849624060150376\n",
      "Epoch 108:\t train loss : 0.57797612831992; train accuracy : 0.9727644749211967; \n",
      " validation loss : 0.7271943956399657; validation accuracy : 0.8270676691729323\n",
      "Epoch 109:\t train loss : 0.5595152252184267; train accuracy : 0.9917602167781895; \n",
      " validation loss : 0.6781752637120122; validation accuracy : 0.8721804511278195\n",
      "Epoch 110:\t train loss : 0.5575082104293014; train accuracy : 0.9937095614665709; \n",
      " validation loss : 0.6476207592815577; validation accuracy : 0.9022556390977443\n",
      "Epoch 111:\t train loss : 0.5619207777263444; train accuracy : 0.9892440413648178; \n",
      " validation loss : 0.6580618241095887; validation accuracy : 0.8872180451127819\n",
      "Epoch 112:\t train loss : 0.5553117471251146; train accuracy : 0.9961013106232373; \n",
      " validation loss : 0.6752663466973837; validation accuracy : 0.8721804511278195\n",
      "Epoch 113:\t train loss : 0.56236466684075; train accuracy : 0.9889951888514074; \n",
      " validation loss : 0.6646956099890013; validation accuracy : 0.8872180451127819\n",
      "Epoch 114:\t train loss : 0.5549591494864474; train accuracy : 0.9965160648122546; \n",
      " validation loss : 0.6887936097697038; validation accuracy : 0.8571428571428571\n",
      "Epoch 115:\t train loss : 0.553085438284561; train accuracy : 0.9983409832439307; \n",
      " validation loss : 0.6465546373667157; validation accuracy : 0.9022556390977443\n",
      "Epoch 116:\t train loss : 0.553301402867332; train accuracy : 0.9980921307305204; \n",
      " validation loss : 0.6668436144427684; validation accuracy : 0.8796992481203008\n",
      "Epoch 117:\t train loss : 0.5554353504606999; train accuracy : 0.9960460100647016; \n",
      " validation loss : 0.6648309400727537; validation accuracy : 0.8872180451127819\n",
      "Epoch 118:\t train loss : 0.5533946020683511; train accuracy : 0.9980783055908865; \n",
      " validation loss : 0.6704015862848592; validation accuracy : 0.8796992481203008\n",
      "Epoch 119:\t train loss : 0.5534237681211029; train accuracy : 0.9980368301719847; \n",
      " validation loss : 0.6474176959338978; validation accuracy : 0.9022556390977443\n",
      "Epoch 120:\t train loss : 0.5539850555679307; train accuracy : 0.9974423491677266; \n",
      " validation loss : 0.6520607861324529; validation accuracy : 0.8947368421052632\n",
      "Epoch 121:\t train loss : 0.5545935837528571; train accuracy : 0.9968478681634685; \n",
      " validation loss : 0.6830832823849957; validation accuracy : 0.8646616541353384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122:\t train loss : 0.5537911526261307; train accuracy : 0.9975529502847978; \n",
      " validation loss : 0.6604394866851232; validation accuracy : 0.8872180451127819\n",
      "Epoch 123:\t train loss : 0.5537928314468255; train accuracy : 0.997539125145164; \n",
      " validation loss : 0.68556702325158; validation accuracy : 0.8646616541353384\n",
      "Epoch 124:\t train loss : 0.5539999638939608; train accuracy : 0.9974008737488248; \n",
      " validation loss : 0.6766410058929883; validation accuracy : 0.8721804511278195\n",
      "Epoch 125:\t train loss : 0.5529647134643615; train accuracy : 0.9984792346402699; \n",
      " validation loss : 0.6546039588186253; validation accuracy : 0.8947368421052632\n",
      "Epoch 126:\t train loss : 0.554434611497382; train accuracy : 0.9969308190012719; \n",
      " validation loss : 0.6864373720967009; validation accuracy : 0.8571428571428571\n",
      "Epoch 127:\t train loss : 0.6020188578336452; train accuracy : 0.9485981308411214; \n",
      " validation loss : 0.7005551163570981; validation accuracy : 0.849624060150376\n",
      "Epoch 128:\t train loss : 0.5660148076757998; train accuracy : 0.9850964994746447; \n",
      " validation loss : 0.6948023665772088; validation accuracy : 0.8421052631578947\n",
      "Epoch 129:\t train loss : 0.584351670621894; train accuracy : 0.9663772604103301; \n",
      " validation loss : 0.700413259237649; validation accuracy : 0.8421052631578947\n",
      "Epoch 130:\t train loss : 0.5614559807105909; train accuracy : 0.9897832218105402; \n",
      " validation loss : 0.719614547969249; validation accuracy : 0.8345864661654135\n",
      "Epoch 131:\t train loss : 0.560333604971259; train accuracy : 0.9908892329812531; \n",
      " validation loss : 0.7176036541403014; validation accuracy : 0.8345864661654135\n",
      "Epoch 132:\t train loss : 0.5554991113323203; train accuracy : 0.995838632970193; \n",
      " validation loss : 0.6585613748904542; validation accuracy : 0.8872180451127819\n",
      "Epoch 133:\t train loss : 0.5548660091895874; train accuracy : 0.9965298899518885; \n",
      " validation loss : 0.6841975413018903; validation accuracy : 0.8646616541353384\n",
      "Epoch 134:\t train loss : 0.5548657267495007; train accuracy : 0.9965437150915224; \n",
      " validation loss : 0.6491266410774168; validation accuracy : 0.9022556390977443\n",
      "Epoch 135:\t train loss : 0.5738992298685983; train accuracy : 0.9772714704418515; \n",
      " validation loss : 0.666936772562282; validation accuracy : 0.8796992481203008\n",
      "Epoch 136:\t train loss : 0.5642141975261807; train accuracy : 0.9872117458386329; \n",
      " validation loss : 0.6829210311864086; validation accuracy : 0.8646616541353384\n",
      "Epoch 137:\t train loss : 0.555295476073651; train accuracy : 0.9962257368799424; \n",
      " validation loss : 0.6313737329087068; validation accuracy : 0.924812030075188\n",
      "Epoch 138:\t train loss : 0.5542123623092947; train accuracy : 0.9971796715146823; \n",
      " validation loss : 0.6790551133147245; validation accuracy : 0.8721804511278195\n",
      "Epoch 139:\t train loss : 0.5533830826284168; train accuracy : 0.9980091798927169; \n",
      " validation loss : 0.6269465038190688; validation accuracy : 0.924812030075188\n",
      "Epoch 140:\t train loss : 0.5532174368768699; train accuracy : 0.9981336061494221; \n",
      " validation loss : 0.6562777603300664; validation accuracy : 0.8947368421052632\n",
      "Epoch 141:\t train loss : 0.5531112430035291; train accuracy : 0.9982995078250291; \n",
      " validation loss : 0.6635265110602506; validation accuracy : 0.8872180451127819\n",
      "Epoch 142:\t train loss : 0.5529399644550237; train accuracy : 0.9984930597799038; \n",
      " validation loss : 0.6534702528493944; validation accuracy : 0.8947368421052632\n",
      "Epoch 143:\t train loss : 0.5532912210043113; train accuracy : 0.9980644804512525; \n",
      " validation loss : 0.6563573495047942; validation accuracy : 0.8872180451127819\n",
      "Epoch 144:\t train loss : 0.5529599889601793; train accuracy : 0.9984377592213681; \n",
      " validation loss : 0.6451244480066899; validation accuracy : 0.9097744360902256\n",
      "Epoch 145:\t train loss : 0.5524049155784542; train accuracy : 0.9990598905048941; \n",
      " validation loss : 0.6640598550189308; validation accuracy : 0.8872180451127819\n",
      "Epoch 146:\t train loss : 0.5524966727086209; train accuracy : 0.9988939888292871; \n",
      " validation loss : 0.6787780830440673; validation accuracy : 0.8721804511278195\n",
      "Epoch 147:\t train loss : 0.5543764237846566; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.6475775950540655; validation accuracy : 0.9022556390977443\n",
      "Epoch 148:\t train loss : 0.5639512906634412; train accuracy : 0.9869905436044903; \n",
      " validation loss : 0.6726884597843955; validation accuracy : 0.8796992481203008\n",
      "Epoch 149:\t train loss : 0.562236997215448; train accuracy : 0.9889951888514074; \n",
      " validation loss : 0.6966704109016841; validation accuracy : 0.8571428571428571\n",
      "Epoch 150:\t train loss : 0.5550272953884091; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.6485984396641666; validation accuracy : 0.9022556390977443\n",
      "Epoch 151:\t train loss : 0.5541966980318935; train accuracy : 0.9972073217939501; \n",
      " validation loss : 0.6657877274891731; validation accuracy : 0.8872180451127819\n",
      "Epoch 152:\t train loss : 0.5534531066155348; train accuracy : 0.9980644804512525; \n",
      " validation loss : 0.6354562572050395; validation accuracy : 0.9172932330827067\n",
      "Epoch 153:\t train loss : 0.5532007870908383; train accuracy : 0.9982303821268594; \n",
      " validation loss : 0.6774895931011784; validation accuracy : 0.8721804511278195\n",
      "Epoch 154:\t train loss : 0.5532454255586199; train accuracy : 0.9981750815683238; \n",
      " validation loss : 0.6871527320877541; validation accuracy : 0.8646616541353384\n",
      "Epoch 155:\t train loss : 0.5556966511914049; train accuracy : 0.99568655643422; \n",
      " validation loss : 0.6841949661426003; validation accuracy : 0.8646616541353384\n",
      "Epoch 156:\t train loss : 0.5590048007048836; train accuracy : 0.992285572084278; \n",
      " validation loss : 0.7031416984509675; validation accuracy : 0.849624060150376\n",
      "Epoch 157:\t train loss : 0.5545020325331437; train accuracy : 0.9969308190012719; \n",
      " validation loss : 0.6416569837493057; validation accuracy : 0.9097744360902256\n",
      "Epoch 158:\t train loss : 0.5535804958887456; train accuracy : 0.9978294530774761; \n",
      " validation loss : 0.6781636432323681; validation accuracy : 0.8721804511278195\n",
      "Epoch 159:\t train loss : 0.5542176521206279; train accuracy : 0.9971658463750483; \n",
      " validation loss : 0.6516103512703989; validation accuracy : 0.8947368421052632\n",
      "Epoch 160:\t train loss : 0.5550646204706234; train accuracy : 0.9963778134159155; \n",
      " validation loss : 0.659232802449602; validation accuracy : 0.8947368421052632\n",
      "Epoch 161:\t train loss : 0.5556638450670015; train accuracy : 0.9957833324116574; \n",
      " validation loss : 0.6753601897606523; validation accuracy : 0.8721804511278195\n",
      "Epoch 162:\t train loss : 0.5557627606797071; train accuracy : 0.9956174307360505; \n",
      " validation loss : 0.6669102520763872; validation accuracy : 0.8796992481203008\n",
      "Epoch 163:\t train loss : 0.5534673381584849; train accuracy : 0.9978709284963778; \n",
      " validation loss : 0.6853642408153746; validation accuracy : 0.8646616541353384\n",
      "Epoch 164:\t train loss : 0.5540768786369142; train accuracy : 0.9972902726317536; \n",
      " validation loss : 0.6492135831400101; validation accuracy : 0.9022556390977443\n",
      "Epoch 165:\t train loss : 0.5657534676056879; train accuracy : 0.9854697782447602; \n",
      " validation loss : 0.7317065302114719; validation accuracy : 0.8195488721804511\n",
      "Epoch 166:\t train loss : 0.574399794660003; train accuracy : 0.9765802134601559; \n",
      " validation loss : 0.7082569379807866; validation accuracy : 0.8421052631578947\n",
      "Epoch 167:\t train loss : 0.5573390995550396; train accuracy : 0.9939307637007133; \n",
      " validation loss : 0.6412417632598095; validation accuracy : 0.9097744360902256\n",
      "Epoch 168:\t train loss : 0.5549592820389461; train accuracy : 0.9964745893933529; \n",
      " validation loss : 0.6821506620921429; validation accuracy : 0.8646616541353384\n",
      "Epoch 169:\t train loss : 0.5544236873470212; train accuracy : 0.9969999446994414; \n",
      " validation loss : 0.6790656948432668; validation accuracy : 0.8721804511278195\n",
      "Epoch 170:\t train loss : 0.5589699272865705; train accuracy : 0.9921196704086711; \n",
      " validation loss : 0.6697634303159811; validation accuracy : 0.8796992481203008\n",
      "Epoch 171:\t train loss : 0.5545030896896008; train accuracy : 0.9968478681634685; \n",
      " validation loss : 0.6369707706960765; validation accuracy : 0.9172932330827067\n",
      "Epoch 172:\t train loss : 0.5544395049349766; train accuracy : 0.996916993861638; \n",
      " validation loss : 0.649372287754841; validation accuracy : 0.9022556390977443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173:\t train loss : 0.5538068808386477; train accuracy : 0.9976082508433335; \n",
      " validation loss : 0.6511674074208825; validation accuracy : 0.9022556390977443\n",
      "Epoch 174:\t train loss : 0.5543479592434902; train accuracy : 0.9970828955372449; \n",
      " validation loss : 0.6595621470866974; validation accuracy : 0.8872180451127819\n",
      "Epoch 175:\t train loss : 0.5664683472560015; train accuracy : 0.9848614721008682; \n",
      " validation loss : 0.6489472450811753; validation accuracy : 0.8872180451127819\n",
      "Epoch 176:\t train loss : 0.5651502372990223; train accuracy : 0.9859398329923132; \n",
      " validation loss : 0.6723482015632942; validation accuracy : 0.8796992481203008\n",
      "Epoch 177:\t train loss : 0.5564810176952929; train accuracy : 0.9946773212409445; \n",
      " validation loss : 0.6715209921379598; validation accuracy : 0.8796992481203008\n",
      "Epoch 178:\t train loss : 0.5713892542041318; train accuracy : 0.9798705966930266; \n",
      " validation loss : 0.6681188607970374; validation accuracy : 0.8872180451127819\n",
      "Epoch 179:\t train loss : 0.5619973592001367; train accuracy : 0.989064314549577; \n",
      " validation loss : 0.6286606910165091; validation accuracy : 0.924812030075188\n",
      "Epoch 180:\t train loss : 0.5672016869726918; train accuracy : 0.9838384117679588; \n",
      " validation loss : 0.654114426129756; validation accuracy : 0.8947368421052632\n",
      "Epoch 181:\t train loss : 0.558697884590089; train accuracy : 0.9927141514129293; \n",
      " validation loss : 0.6520883128844542; validation accuracy : 0.9022556390977443\n",
      "Epoch 182:\t train loss : 0.5556100904987186; train accuracy : 0.9957971575512913; \n",
      " validation loss : 0.6676363312712973; validation accuracy : 0.8796992481203008\n",
      "Epoch 183:\t train loss : 0.5555340047769783; train accuracy : 0.9958801083890947; \n",
      " validation loss : 0.6677197561210472; validation accuracy : 0.8796992481203008\n",
      "Epoch 184:\t train loss : 0.5540963693026095; train accuracy : 0.9974146988884588; \n",
      " validation loss : 0.6610015342761367; validation accuracy : 0.8872180451127819\n",
      "Epoch 185:\t train loss : 0.553610366019913; train accuracy : 0.9977741525189404; \n",
      " validation loss : 0.6518700332177184; validation accuracy : 0.9022556390977443\n",
      "Epoch 186:\t train loss : 0.5534643928148708; train accuracy : 0.9978709284963778; \n",
      " validation loss : 0.6522211485936104; validation accuracy : 0.8947368421052632\n",
      "Epoch 187:\t train loss : 0.5527757023220413; train accuracy : 0.9986727865951446; \n",
      " validation loss : 0.684736512268214; validation accuracy : 0.8646616541353384\n",
      "Epoch 188:\t train loss : 0.5525021114911287; train accuracy : 0.9989769396670907; \n",
      " validation loss : 0.6470197330343352; validation accuracy : 0.9097744360902256\n",
      "Epoch 189:\t train loss : 0.5519639300032688; train accuracy : 0.9994469944146436; \n",
      " validation loss : 0.6688619630316452; validation accuracy : 0.8796992481203008\n",
      "Early stopping at epoch 189\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5533830826284168; Train accuracy : 0.9980091798927169; \n",
      " Validation loss : 0.6269465038190688; Validation accuracy : 0.924812030075188\n",
      "------------------------------ Let's train model 27 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8992914697261021; train accuracy : 0.6277166399380634; \n",
      " validation loss : 0.8546712125702879; validation accuracy : 0.6691729323308271\n",
      "Epoch 2:\t train loss : 0.790226287028017; train accuracy : 0.7525023502737378; \n",
      " validation loss : 0.8006215605210175; validation accuracy : 0.7368421052631579\n",
      "Epoch 3:\t train loss : 0.756265915967757; train accuracy : 0.7881573853895925; \n",
      " validation loss : 0.7587077068115365; validation accuracy : 0.7894736842105263\n",
      "Epoch 4:\t train loss : 0.7169494685007438; train accuracy : 0.8310153182547144; \n",
      " validation loss : 0.807188033293713; validation accuracy : 0.7368421052631579\n",
      "Epoch 5:\t train loss : 0.6842702587762575; train accuracy : 0.8646104075651164; \n",
      " validation loss : 0.741618235935499; validation accuracy : 0.7969924812030075\n",
      "Epoch 6:\t train loss : 0.6482588639445485; train accuracy : 0.9011226013382735; \n",
      " validation loss : 0.6858838946121024; validation accuracy : 0.8721804511278195\n",
      "Epoch 7:\t train loss : 0.6305113898319631; train accuracy : 0.9200630426367307; \n",
      " validation loss : 0.7038692111074155; validation accuracy : 0.8421052631578947\n",
      "Epoch 8:\t train loss : 0.6268607028237353; train accuracy : 0.9244594370403141; \n",
      " validation loss : 0.6690998422165126; validation accuracy : 0.8872180451127819\n",
      "Epoch 9:\t train loss : 0.603975447733303; train accuracy : 0.9480036498368634; \n",
      " validation loss : 0.696210404529822; validation accuracy : 0.8421052631578947\n",
      "Epoch 10:\t train loss : 0.5995331526889465; train accuracy : 0.9521097163081347; \n",
      " validation loss : 0.6958442644632594; validation accuracy : 0.849624060150376\n",
      "Epoch 11:\t train loss : 0.5920985192401196; train accuracy : 0.959464690593375; \n",
      " validation loss : 0.7207727627858501; validation accuracy : 0.8120300751879699\n",
      "Epoch 12:\t train loss : 0.5958008860816773; train accuracy : 0.9549715202123541; \n",
      " validation loss : 0.6607256363428873; validation accuracy : 0.8796992481203008\n",
      "Epoch 13:\t train loss : 0.5830487929022647; train accuracy : 0.9689072609633357; \n",
      " validation loss : 0.6722635459663296; validation accuracy : 0.8796992481203008\n",
      "Epoch 14:\t train loss : 0.5778910022480496; train accuracy : 0.974257590001659; \n",
      " validation loss : 0.7374968755367898; validation accuracy : 0.8045112781954887\n",
      "Epoch 15:\t train loss : 0.5902092647725464; train accuracy : 0.9605568766244539; \n",
      " validation loss : 0.727286155213933; validation accuracy : 0.8195488721804511\n",
      "Epoch 16:\t train loss : 0.5812988896692883; train accuracy : 0.9701238732511198; \n",
      " validation loss : 0.6548879606704094; validation accuracy : 0.8872180451127819\n",
      "Epoch 17:\t train loss : 0.5810333766500911; train accuracy : 0.9700547475529503; \n",
      " validation loss : 0.6502980795550468; validation accuracy : 0.9022556390977443\n",
      "Epoch 18:\t train loss : 0.5720395974171885; train accuracy : 0.9793037659680363; \n",
      " validation loss : 0.6768366495943727; validation accuracy : 0.8721804511278195\n",
      "Epoch 19:\t train loss : 0.5888108933860361; train accuracy : 0.9624370956146657; \n",
      " validation loss : 0.6702478458614175; validation accuracy : 0.8796992481203008\n",
      "Epoch 20:\t train loss : 0.5988476484685737; train accuracy : 0.9517364375380192; \n",
      " validation loss : 0.6724083838794946; validation accuracy : 0.8646616541353384\n",
      "Epoch 21:\t train loss : 0.5763885489317159; train accuracy : 0.9747829453077476; \n",
      " validation loss : 0.710165715862772; validation accuracy : 0.8345864661654135\n",
      "Epoch 22:\t train loss : 0.5684669873346433; train accuracy : 0.983050378808826; \n",
      " validation loss : 0.6446391849700328; validation accuracy : 0.9097744360902256\n",
      "Epoch 23:\t train loss : 0.581441572450629; train accuracy : 0.970096222971852; \n",
      " validation loss : 0.7319412528655761; validation accuracy : 0.8195488721804511\n",
      "Epoch 24:\t train loss : 0.5676584760618459; train accuracy : 0.9837692860697893; \n",
      " validation loss : 0.6531820441520698; validation accuracy : 0.9022556390977443\n",
      "Epoch 25:\t train loss : 0.5613255489471023; train accuracy : 0.9903777028147984; \n",
      " validation loss : 0.6833788100319473; validation accuracy : 0.8646616541353384\n",
      "Epoch 26:\t train loss : 0.5848009108988051; train accuracy : 0.9665293369463032; \n",
      " validation loss : 0.6711823322647845; validation accuracy : 0.8721804511278195\n",
      "Epoch 27:\t train loss : 0.5653963384912419; train accuracy : 0.9858707072941437; \n",
      " validation loss : 0.6322289634976564; validation accuracy : 0.9172932330827067\n",
      "Epoch 28:\t train loss : 0.5715597316307547; train accuracy : 0.9801609246253388; \n",
      " validation loss : 0.7190942244342358; validation accuracy : 0.8270676691729323\n",
      "Epoch 29:\t train loss : 0.5605789761933293; train accuracy : 0.9907924570038157; \n",
      " validation loss : 0.7037325356476303; validation accuracy : 0.8421052631578947\n",
      "Epoch 30:\t train loss : 0.5603095021378953; train accuracy : 0.9910274843775922; \n",
      " validation loss : 0.7070309579310218; validation accuracy : 0.8421052631578947\n",
      "Epoch 31:\t train loss : 0.568298603785759; train accuracy : 0.9829536028313886; \n",
      " validation loss : 0.6501722110525732; validation accuracy : 0.9022556390977443\n",
      "Epoch 32:\t train loss : 0.5715014482083741; train accuracy : 0.9797323452966875; \n",
      " validation loss : 0.6624322557529934; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:\t train loss : 0.5654954711235247; train accuracy : 0.9857462810374384; \n",
      " validation loss : 0.6471383123741624; validation accuracy : 0.9022556390977443\n",
      "Epoch 34:\t train loss : 0.5889906686971289; train accuracy : 0.962091467123818; \n",
      " validation loss : 0.6280495232286782; validation accuracy : 0.9172932330827067\n",
      "Epoch 35:\t train loss : 0.5637459980825889; train accuracy : 0.9877371011447216; \n",
      " validation loss : 0.6577641583392501; validation accuracy : 0.8947368421052632\n",
      "Epoch 36:\t train loss : 0.5597238473995101; train accuracy : 0.9917049162196538; \n",
      " validation loss : 0.6715635796603866; validation accuracy : 0.8721804511278195\n",
      "Epoch 37:\t train loss : 0.5576959511381275; train accuracy : 0.9937233866062047; \n",
      " validation loss : 0.6357034462409379; validation accuracy : 0.9172932330827067\n",
      "Epoch 38:\t train loss : 0.5576435039297324; train accuracy : 0.9936957363269369; \n",
      " validation loss : 0.6785811931234453; validation accuracy : 0.8721804511278195\n",
      "Epoch 39:\t train loss : 0.5582995727413885; train accuracy : 0.9931289056019466; \n",
      " validation loss : 0.6803246914373565; validation accuracy : 0.8646616541353384\n",
      "Epoch 40:\t train loss : 0.5578360680452977; train accuracy : 0.993681911187303; \n",
      " validation loss : 0.6461798280762778; validation accuracy : 0.9022556390977443\n",
      "Epoch 41:\t train loss : 0.5569725552950653; train accuracy : 0.9943455178897307; \n",
      " validation loss : 0.6477109205540309; validation accuracy : 0.9022556390977443\n",
      "Epoch 42:\t train loss : 0.559945121633414; train accuracy : 0.9913454625891721; \n",
      " validation loss : 0.6582573316112216; validation accuracy : 0.8947368421052632\n",
      "Epoch 43:\t train loss : 0.5564889830754329; train accuracy : 0.9948708731958192; \n",
      " validation loss : 0.6805166594408735; validation accuracy : 0.8721804511278195\n",
      "Epoch 44:\t train loss : 0.5716301159785626; train accuracy : 0.979649394458884; \n",
      " validation loss : 0.6918671971519128; validation accuracy : 0.8646616541353384\n",
      "Epoch 45:\t train loss : 0.5684522805300292; train accuracy : 0.9825111983631034; \n",
      " validation loss : 0.6466590468398077; validation accuracy : 0.9097744360902256\n",
      "Epoch 46:\t train loss : 0.5604408999986682; train accuracy : 0.9910274843775922; \n",
      " validation loss : 0.6866749566509261; validation accuracy : 0.8646616541353384\n",
      "Epoch 47:\t train loss : 0.5612510174379893; train accuracy : 0.9903224022562628; \n",
      " validation loss : 0.6873793283427968; validation accuracy : 0.8646616541353384\n",
      "Epoch 48:\t train loss : 0.5618117168266019; train accuracy : 0.9895343692971299; \n",
      " validation loss : 0.72106515080908; validation accuracy : 0.8270676691729323\n",
      "Epoch 49:\t train loss : 0.5570798626195475; train accuracy : 0.994456119006802; \n",
      " validation loss : 0.6540857268298267; validation accuracy : 0.9022556390977443\n",
      "Epoch 50:\t train loss : 0.5604749361242164; train accuracy : 0.9908892329812531; \n",
      " validation loss : 0.6678408950575115; validation accuracy : 0.8796992481203008\n",
      "Epoch 51:\t train loss : 0.5644315219375347; train accuracy : 0.9867002156721782; \n",
      " validation loss : 0.6897650306300416; validation accuracy : 0.8646616541353384\n",
      "Epoch 52:\t train loss : 0.5677785009956345; train accuracy : 0.9834789581374772; \n",
      " validation loss : 0.7256439039682803; validation accuracy : 0.8270676691729323\n",
      "Epoch 53:\t train loss : 0.5650087352759148; train accuracy : 0.9860366089697505; \n",
      " validation loss : 0.669740957123368; validation accuracy : 0.8872180451127819\n",
      "Epoch 54:\t train loss : 0.5608779843356988; train accuracy : 0.9906542056074766; \n",
      " validation loss : 0.6791003482825713; validation accuracy : 0.8721804511278195\n",
      "Epoch 55:\t train loss : 0.5562525320529775; train accuracy : 0.995064425150694; \n",
      " validation loss : 0.6175980801593334; validation accuracy : 0.9323308270676691\n",
      "Epoch 56:\t train loss : 0.5722938154404944; train accuracy : 0.9788060609412155; \n",
      " validation loss : 0.6555555152551561; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5792653225084399; train accuracy : 0.9713266603992701; \n",
      " validation loss : 0.6885525871345968; validation accuracy : 0.8571428571428571\n",
      "Epoch 58:\t train loss : 0.564011612243766; train accuracy : 0.9872808715368026; \n",
      " validation loss : 0.7068088952213873; validation accuracy : 0.8421052631578947\n",
      "Epoch 59:\t train loss : 0.56183406893268; train accuracy : 0.9893546424818891; \n",
      " validation loss : 0.6397202803226244; validation accuracy : 0.9097744360902256\n",
      "Epoch 60:\t train loss : 0.5862774982838438; train accuracy : 0.9644417408615827; \n",
      " validation loss : 0.6835460369875402; validation accuracy : 0.8646616541353384\n",
      "Epoch 61:\t train loss : 0.5640102803204268; train accuracy : 0.9873499972349721; \n",
      " validation loss : 0.6735238241330647; validation accuracy : 0.8721804511278195\n",
      "Epoch 62:\t train loss : 0.5600478653634813; train accuracy : 0.9914007631477078; \n",
      " validation loss : 0.7426209568405582; validation accuracy : 0.8045112781954887\n",
      "Epoch 63:\t train loss : 0.5661978223202241; train accuracy : 0.9846264447270917; \n",
      " validation loss : 0.7258830205174128; validation accuracy : 0.8270676691729323\n",
      "Epoch 64:\t train loss : 0.5592873272365457; train accuracy : 0.9920643698501355; \n",
      " validation loss : 0.7115101349312724; validation accuracy : 0.8345864661654135\n",
      "Epoch 65:\t train loss : 0.5591190490414022; train accuracy : 0.992147320687939; \n",
      " validation loss : 0.6946750139416106; validation accuracy : 0.849624060150376\n",
      "Epoch 66:\t train loss : 0.5606967613037932; train accuracy : 0.9906956810263784; \n",
      " validation loss : 0.6965572360007171; validation accuracy : 0.849624060150376\n",
      "Epoch 67:\t train loss : 0.556069546553088; train accuracy : 0.9954377039208095; \n",
      " validation loss : 0.6678628541518905; validation accuracy : 0.8796992481203008\n",
      "Epoch 68:\t train loss : 0.5589312606250757; train accuracy : 0.9925205994580545; \n",
      " validation loss : 0.6569598076561987; validation accuracy : 0.8947368421052632\n",
      "Epoch 69:\t train loss : 0.5655960623892466; train accuracy : 0.9857048056185367; \n",
      " validation loss : 0.6797019475267787; validation accuracy : 0.8571428571428571\n",
      "Epoch 70:\t train loss : 0.5580365802934333; train accuracy : 0.9933915832549909; \n",
      " validation loss : 0.7041940593108155; validation accuracy : 0.849624060150376\n",
      "Epoch 71:\t train loss : 0.5561098888134735; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.6553521519800651; validation accuracy : 0.8947368421052632\n",
      "Epoch 72:\t train loss : 0.5625199580748665; train accuracy : 0.9886495603605596; \n",
      " validation loss : 0.6806272508818954; validation accuracy : 0.8721804511278195\n",
      "Epoch 73:\t train loss : 0.5590430063374675; train accuracy : 0.9923408726428137; \n",
      " validation loss : 0.6384735276691321; validation accuracy : 0.9097744360902256\n",
      "Epoch 74:\t train loss : 0.5590240292094795; train accuracy : 0.9923685229220816; \n",
      " validation loss : 0.6880361655733456; validation accuracy : 0.8646616541353384\n",
      "Epoch 75:\t train loss : 0.5564112773402087; train accuracy : 0.9949261737543549; \n",
      " validation loss : 0.6928185105914128; validation accuracy : 0.8571428571428571\n",
      "Epoch 76:\t train loss : 0.5689542455481985; train accuracy : 0.982124094453354; \n",
      " validation loss : 0.7489505729874629; validation accuracy : 0.7894736842105263\n",
      "Epoch 77:\t train loss : 0.5771116192458267; train accuracy : 0.9738566609522756; \n",
      " validation loss : 0.7130008048323122; validation accuracy : 0.8345864661654135\n",
      "Epoch 78:\t train loss : 0.5725558765439214; train accuracy : 0.9784466073107339; \n",
      " validation loss : 0.6400479535102884; validation accuracy : 0.9097744360902256\n",
      "Epoch 79:\t train loss : 0.558484951575851; train accuracy : 0.9930736050434109; \n",
      " validation loss : 0.6550756503343369; validation accuracy : 0.8947368421052632\n",
      "Epoch 80:\t train loss : 0.5574074129718449; train accuracy : 0.993986064259249; \n",
      " validation loss : 0.6690031993662536; validation accuracy : 0.8872180451127819\n",
      "Epoch 81:\t train loss : 0.5572803016812541; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.69041119161235; validation accuracy : 0.8571428571428571\n",
      "Epoch 82:\t train loss : 0.5565859547843152; train accuracy : 0.9948708731958192; \n",
      " validation loss : 0.6603343542668497; validation accuracy : 0.8872180451127819\n",
      "Epoch 83:\t train loss : 0.5571305919427212; train accuracy : 0.9943455178897307; \n",
      " validation loss : 0.657954987821609; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84:\t train loss : 0.5556450315528324; train accuracy : 0.9957695072720234; \n",
      " validation loss : 0.7060587145483574; validation accuracy : 0.8421052631578947\n",
      "Epoch 85:\t train loss : 0.5567847113136215; train accuracy : 0.9945390698446054; \n",
      " validation loss : 0.6648873776660286; validation accuracy : 0.8872180451127819\n",
      "Epoch 86:\t train loss : 0.5686753302746923; train accuracy : 0.9826356246198087; \n",
      " validation loss : 0.6563858704372706; validation accuracy : 0.8947368421052632\n",
      "Epoch 87:\t train loss : 0.5576784894661476; train accuracy : 0.9937233866062047; \n",
      " validation loss : 0.664242727627969; validation accuracy : 0.8872180451127819\n",
      "Epoch 88:\t train loss : 0.5574120372323862; train accuracy : 0.9939307637007133; \n",
      " validation loss : 0.694270310292138; validation accuracy : 0.8571428571428571\n",
      "Epoch 89:\t train loss : 0.6146535824554673; train accuracy : 0.9352845213736659; \n",
      " validation loss : 0.7187000104218323; validation accuracy : 0.8345864661654135\n",
      "Epoch 90:\t train loss : 0.5767459145253975; train accuracy : 0.9743405408394625; \n",
      " validation loss : 0.6799600271044184; validation accuracy : 0.8721804511278195\n",
      "Epoch 91:\t train loss : 0.5640767078742474; train accuracy : 0.9871287950008295; \n",
      " validation loss : 0.6664127542646995; validation accuracy : 0.8872180451127819\n",
      "Epoch 92:\t train loss : 0.562906498009503; train accuracy : 0.9884560084056849; \n",
      " validation loss : 0.6833961186744462; validation accuracy : 0.8571428571428571\n",
      "Epoch 93:\t train loss : 0.5588591969614062; train accuracy : 0.9925482497373224; \n",
      " validation loss : 0.6923929110053282; validation accuracy : 0.8571428571428571\n",
      "Epoch 94:\t train loss : 0.5576834661884483; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.6518382764991764; validation accuracy : 0.9022556390977443\n",
      "Epoch 95:\t train loss : 0.5565246375935645; train accuracy : 0.9948985234750871; \n",
      " validation loss : 0.6701110466309542; validation accuracy : 0.8796992481203008\n",
      "Epoch 96:\t train loss : 0.5568338242660568; train accuracy : 0.994760272078748; \n",
      " validation loss : 0.6808019860402326; validation accuracy : 0.8721804511278195\n",
      "Epoch 97:\t train loss : 0.6832244835939499; train accuracy : 0.8651219377315711; \n",
      " validation loss : 0.7390879363622903; validation accuracy : 0.8120300751879699\n",
      "Epoch 98:\t train loss : 0.6078617103568564; train accuracy : 0.9421832660509871; \n",
      " validation loss : 0.653450321907904; validation accuracy : 0.8947368421052632\n",
      "Epoch 99:\t train loss : 0.5888829101100206; train accuracy : 0.9620361665652823; \n",
      " validation loss : 0.7536641473505657; validation accuracy : 0.7969924812030075\n",
      "Epoch 100:\t train loss : 0.5796988444060263; train accuracy : 0.9709395564895206; \n",
      " validation loss : 0.6619769413940979; validation accuracy : 0.8872180451127819\n",
      "Epoch 101:\t train loss : 0.5746343819107111; train accuracy : 0.9764972626223525; \n",
      " validation loss : 0.6664336400387807; validation accuracy : 0.8796992481203008\n",
      "Epoch 102:\t train loss : 0.5693996636196582; train accuracy : 0.9818475916606758; \n",
      " validation loss : 0.6653486693238264; validation accuracy : 0.8872180451127819\n",
      "Epoch 103:\t train loss : 0.5668782350827613; train accuracy : 0.9844881933307527; \n",
      " validation loss : 0.6722500882377161; validation accuracy : 0.8721804511278195\n",
      "Epoch 104:\t train loss : 0.566284499682147; train accuracy : 0.9851103246142786; \n",
      " validation loss : 0.6713798599243136; validation accuracy : 0.8796992481203008\n",
      "Epoch 105:\t train loss : 0.5626001484648508; train accuracy : 0.988746336337997; \n",
      " validation loss : 0.6631396711552583; validation accuracy : 0.8872180451127819\n",
      "Early stopping at epoch 105\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5562525320529775; Train accuracy : 0.995064425150694; \n",
      " Validation loss : 0.6175980801593334; Validation accuracy : 0.9323308270676691\n",
      "------------------------------ Let's train model 28 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.883681853995383; train accuracy : 0.6465879555383509; \n",
      " validation loss : 0.8114710412319186; validation accuracy : 0.7293233082706767\n",
      "Epoch 2:\t train loss : 0.7826095630327666; train accuracy : 0.7585715865730244; \n",
      " validation loss : 0.7594632378934941; validation accuracy : 0.7819548872180451\n",
      "Epoch 3:\t train loss : 0.7167076523126228; train accuracy : 0.8299507825029033; \n",
      " validation loss : 0.7064364061146364; validation accuracy : 0.849624060150376\n",
      "Epoch 4:\t train loss : 0.6889005582948131; train accuracy : 0.8593430293645966; \n",
      " validation loss : 0.7274581229715513; validation accuracy : 0.8270676691729323\n",
      "Epoch 5:\t train loss : 0.6616523520765312; train accuracy : 0.8878781175689875; \n",
      " validation loss : 0.6962855874032284; validation accuracy : 0.849624060150376\n",
      "Epoch 6:\t train loss : 0.6519321152668535; train accuracy : 0.8975280650334568; \n",
      " validation loss : 0.6878731570447989; validation accuracy : 0.8646616541353384\n",
      "Epoch 7:\t train loss : 0.6319909114972517; train accuracy : 0.9186805286733396; \n",
      " validation loss : 0.6746963237053385; validation accuracy : 0.8796992481203008\n",
      "Epoch 8:\t train loss : 0.6180135617574084; train accuracy : 0.9330033733340707; \n",
      " validation loss : 0.6518911031227825; validation accuracy : 0.8947368421052632\n",
      "Epoch 9:\t train loss : 0.6100701303490061; train accuracy : 0.941422883371122; \n",
      " validation loss : 0.6572874118830891; validation accuracy : 0.8947368421052632\n",
      "Epoch 10:\t train loss : 0.6130382454265978; train accuracy : 0.9383813526516618; \n",
      " validation loss : 0.6731240914544891; validation accuracy : 0.8721804511278195\n",
      "Epoch 11:\t train loss : 0.6063626508853356; train accuracy : 0.9450450699552065; \n",
      " validation loss : 0.6422684224697012; validation accuracy : 0.9097744360902256\n",
      "Epoch 12:\t train loss : 0.5929638872574349; train accuracy : 0.9583172040037604; \n",
      " validation loss : 0.6575009923762599; validation accuracy : 0.8872180451127819\n",
      "Epoch 13:\t train loss : 0.5848734652408859; train accuracy : 0.9663357849914284; \n",
      " validation loss : 0.6365649069048935; validation accuracy : 0.9172932330827067\n",
      "Epoch 14:\t train loss : 0.5827352318023913; train accuracy : 0.9689902118011392; \n",
      " validation loss : 0.6558122134060946; validation accuracy : 0.9022556390977443\n",
      "Epoch 15:\t train loss : 0.5782494221843354; train accuracy : 0.9733036553669192; \n",
      " validation loss : 0.6317266798061305; validation accuracy : 0.924812030075188\n",
      "Epoch 16:\t train loss : 0.5761206339975095; train accuracy : 0.9760410330144335; \n",
      " validation loss : 0.6543292292316734; validation accuracy : 0.8947368421052632\n",
      "Epoch 17:\t train loss : 0.5804382408456018; train accuracy : 0.970856605651717; \n",
      " validation loss : 0.6388521442537268; validation accuracy : 0.8947368421052632\n",
      "Epoch 18:\t train loss : 0.5778176291317517; train accuracy : 0.97380136039374; \n",
      " validation loss : 0.6502701588471833; validation accuracy : 0.9022556390977443\n",
      "Epoch 19:\t train loss : 0.5682405482569642; train accuracy : 0.9834927832771111; \n",
      " validation loss : 0.6589456043123415; validation accuracy : 0.8872180451127819\n",
      "Epoch 20:\t train loss : 0.5712269147208063; train accuracy : 0.9803406514405796; \n",
      " validation loss : 0.6837788604082121; validation accuracy : 0.8721804511278195\n",
      "Epoch 21:\t train loss : 0.5752753078419384; train accuracy : 0.9762207598296743; \n",
      " validation loss : 0.6671730048698679; validation accuracy : 0.8796992481203008\n",
      "Epoch 22:\t train loss : 0.5642129676965636; train accuracy : 0.9876126748880164; \n",
      " validation loss : 0.6525833441995531; validation accuracy : 0.8872180451127819\n",
      "Epoch 23:\t train loss : 0.5639299236335332; train accuracy : 0.9876818005861859; \n",
      " validation loss : 0.6564090240099897; validation accuracy : 0.8872180451127819\n",
      "Epoch 24:\t train loss : 0.5615777458830762; train accuracy : 0.9899629486257812; \n",
      " validation loss : 0.6615150420551361; validation accuracy : 0.8872180451127819\n",
      "Epoch 25:\t train loss : 0.567669227130574; train accuracy : 0.9836310346734503; \n",
      " validation loss : 0.650922973643035; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5755056195485044; train accuracy : 0.9754603771498093; \n",
      " validation loss : 0.6370209204133304; validation accuracy : 0.9172932330827067\n",
      "Epoch 27:\t train loss : 0.5696401991054048; train accuracy : 0.9818199413814079; \n",
      " validation loss : 0.6379644713480342; validation accuracy : 0.9172932330827067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:\t train loss : 0.565842274594831; train accuracy : 0.9857186307581707; \n",
      " validation loss : 0.6711554096426542; validation accuracy : 0.8796992481203008\n",
      "Epoch 29:\t train loss : 0.5676688398301881; train accuracy : 0.9835619089752806; \n",
      " validation loss : 0.6812649127795491; validation accuracy : 0.8646616541353384\n",
      "Epoch 30:\t train loss : 0.5671458085946876; train accuracy : 0.9843084665155118; \n",
      " validation loss : 0.6503223341774949; validation accuracy : 0.8947368421052632\n",
      "Epoch 31:\t train loss : 0.5588087686384423; train accuracy : 0.9926726759940275; \n",
      " validation loss : 0.6324367751395688; validation accuracy : 0.9172932330827067\n",
      "Epoch 32:\t train loss : 0.5561424240929886; train accuracy : 0.9955206547586131; \n",
      " validation loss : 0.6680799961520466; validation accuracy : 0.8796992481203008\n",
      "Epoch 33:\t train loss : 0.5592098940292846; train accuracy : 0.9922440966653763; \n",
      " validation loss : 0.6417192099172797; validation accuracy : 0.9097744360902256\n",
      "Epoch 34:\t train loss : 0.5621468627640608; train accuracy : 0.9894652435989604; \n",
      " validation loss : 0.6592159031611062; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.5600233288206604; train accuracy : 0.9912348614721008; \n",
      " validation loss : 0.651826469943598; validation accuracy : 0.9022556390977443\n",
      "Epoch 36:\t train loss : 0.5667989969610872; train accuracy : 0.9845987944478239; \n",
      " validation loss : 0.6438179881672798; validation accuracy : 0.9022556390977443\n",
      "Epoch 37:\t train loss : 0.5618796047508519; train accuracy : 0.9893822927611569; \n",
      " validation loss : 0.6434591483396043; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.5581317998034648; train accuracy : 0.9934468838135265; \n",
      " validation loss : 0.6261892111556829; validation accuracy : 0.9172932330827067\n",
      "Epoch 39:\t train loss : 0.5647465305278031; train accuracy : 0.9863269369020627; \n",
      " validation loss : 0.6368537681697674; validation accuracy : 0.9097744360902256\n",
      "Epoch 40:\t train loss : 0.5580507984136552; train accuracy : 0.9934745340927943; \n",
      " validation loss : 0.6534217826707073; validation accuracy : 0.8947368421052632\n",
      "Epoch 41:\t train loss : 0.5562162743298361; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.6413278203877112; validation accuracy : 0.9097744360902256\n",
      "Epoch 42:\t train loss : 0.5578950461374427; train accuracy : 0.9935436597909639; \n",
      " validation loss : 0.665341294724611; validation accuracy : 0.8872180451127819\n",
      "Epoch 43:\t train loss : 0.5951898534083555; train accuracy : 0.9555245257977105; \n",
      " validation loss : 0.6429169660503041; validation accuracy : 0.9022556390977443\n",
      "Epoch 44:\t train loss : 0.5802982907602796; train accuracy : 0.9705248023005032; \n",
      " validation loss : 0.6291688817600034; validation accuracy : 0.924812030075188\n",
      "Epoch 45:\t train loss : 0.5702362506438508; train accuracy : 0.9806586296521594; \n",
      " validation loss : 0.6965410072919134; validation accuracy : 0.849624060150376\n",
      "Epoch 46:\t train loss : 0.5888656394690626; train accuracy : 0.9616905380744346; \n",
      " validation loss : 0.6975437326040744; validation accuracy : 0.849624060150376\n",
      "Epoch 47:\t train loss : 0.5670150146443756; train accuracy : 0.9841840402588066; \n",
      " validation loss : 0.6388862611023525; validation accuracy : 0.9097744360902256\n",
      "Epoch 48:\t train loss : 0.558585752100471; train accuracy : 0.9926173754354919; \n",
      " validation loss : 0.6227516005311262; validation accuracy : 0.9323308270676691\n",
      "Epoch 49:\t train loss : 0.5553247105979031; train accuracy : 0.9960874854836034; \n",
      " validation loss : 0.6169164250556833; validation accuracy : 0.9323308270676691\n",
      "Epoch 50:\t train loss : 0.5551379345161269; train accuracy : 0.9963916385555494; \n",
      " validation loss : 0.6416741081416861; validation accuracy : 0.9097744360902256\n",
      "Epoch 51:\t train loss : 0.5560166734020303; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.6634441339949186; validation accuracy : 0.8872180451127819\n",
      "Epoch 52:\t train loss : 0.5548003068443865; train accuracy : 0.9966128407896919; \n",
      " validation loss : 0.642166987871559; validation accuracy : 0.9097744360902256\n",
      "Epoch 53:\t train loss : 0.555206392771937; train accuracy : 0.9963778134159155; \n",
      " validation loss : 0.664252573006746; validation accuracy : 0.8796992481203008\n",
      "Epoch 54:\t train loss : 0.5569749709213236; train accuracy : 0.9944699441464359; \n",
      " validation loss : 0.649977846277086; validation accuracy : 0.9022556390977443\n",
      "Epoch 55:\t train loss : 0.5567900066350167; train accuracy : 0.9946220206824089; \n",
      " validation loss : 0.6366736504999447; validation accuracy : 0.9172932330827067\n",
      "Epoch 56:\t train loss : 0.5584965937384; train accuracy : 0.9926726759940275; \n",
      " validation loss : 0.6685433432705453; validation accuracy : 0.8796992481203008\n",
      "Epoch 57:\t train loss : 0.554620112649313; train accuracy : 0.9969031687220041; \n",
      " validation loss : 0.6351079796796114; validation accuracy : 0.9172932330827067\n",
      "Epoch 58:\t train loss : 0.5553351129144857; train accuracy : 0.9960874854836034; \n",
      " validation loss : 0.6540111025209104; validation accuracy : 0.8947368421052632\n",
      "Epoch 59:\t train loss : 0.5558289169208632; train accuracy : 0.9955068296189792; \n",
      " validation loss : 0.6477641870818892; validation accuracy : 0.9022556390977443\n",
      "Epoch 60:\t train loss : 0.5541375640901076; train accuracy : 0.9973455731902892; \n",
      " validation loss : 0.6521787606244385; validation accuracy : 0.9022556390977443\n",
      "Epoch 61:\t train loss : 0.578592982755391; train accuracy : 0.9723358955925455; \n",
      " validation loss : 0.6660340663323053; validation accuracy : 0.8796992481203008\n",
      "Epoch 62:\t train loss : 0.5828418964200062; train accuracy : 0.9679948017474976; \n",
      " validation loss : 0.6697019146596795; validation accuracy : 0.8796992481203008\n",
      "Epoch 63:\t train loss : 0.5630153019498646; train accuracy : 0.9882348061715424; \n",
      " validation loss : 0.64871649805228; validation accuracy : 0.9022556390977443\n",
      "Epoch 64:\t train loss : 0.5587851482796954; train accuracy : 0.9925482497373224; \n",
      " validation loss : 0.6337120705377651; validation accuracy : 0.9172932330827067\n",
      "Epoch 65:\t train loss : 0.5555050886111745; train accuracy : 0.9958939335287287; \n",
      " validation loss : 0.6496468496400762; validation accuracy : 0.9022556390977443\n",
      "Epoch 66:\t train loss : 0.5555390905000399; train accuracy : 0.9959077586683626; \n",
      " validation loss : 0.6385377312655038; validation accuracy : 0.9097744360902256\n",
      "Epoch 67:\t train loss : 0.5576237617277102; train accuracy : 0.9938478128629099; \n",
      " validation loss : 0.6713403099985383; validation accuracy : 0.8796992481203008\n",
      "Epoch 68:\t train loss : 0.5615881936837446; train accuracy : 0.989686445833103; \n",
      " validation loss : 0.669267255411255; validation accuracy : 0.8872180451127819\n",
      "Epoch 69:\t train loss : 0.5602446870322022; train accuracy : 0.9909583586794226; \n",
      " validation loss : 0.6522853466273119; validation accuracy : 0.8947368421052632\n",
      "Epoch 70:\t train loss : 0.5562078919276452; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6394468942433111; validation accuracy : 0.9022556390977443\n",
      "Epoch 71:\t train loss : 0.554788002027861; train accuracy : 0.9966957916274954; \n",
      " validation loss : 0.635423206698529; validation accuracy : 0.9172932330827067\n",
      "Epoch 72:\t train loss : 0.5540369310073584; train accuracy : 0.9974699994469944; \n",
      " validation loss : 0.6449332768934322; validation accuracy : 0.9022556390977443\n",
      "Epoch 73:\t train loss : 0.5574550190540374; train accuracy : 0.9939031134214455; \n",
      " validation loss : 0.6268457641236518; validation accuracy : 0.924812030075188\n",
      "Epoch 74:\t train loss : 0.5848957078424448; train accuracy : 0.9657413039871703; \n",
      " validation loss : 0.6568325272383874; validation accuracy : 0.8947368421052632\n",
      "Epoch 75:\t train loss : 0.5706890919748792; train accuracy : 0.9807001050710612; \n",
      " validation loss : 0.6526292865440946; validation accuracy : 0.8947368421052632\n",
      "Epoch 76:\t train loss : 0.5594447947854192; train accuracy : 0.9919122933141624; \n",
      " validation loss : 0.6563609699751847; validation accuracy : 0.8947368421052632\n",
      "Epoch 77:\t train loss : 0.5554372052230514; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6428711121391674; validation accuracy : 0.9022556390977443\n",
      "Epoch 78:\t train loss : 0.5587665676633304; train accuracy : 0.992451473759885; \n",
      " validation loss : 0.6455488173705518; validation accuracy : 0.9022556390977443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79:\t train loss : 0.5605784991943599; train accuracy : 0.9905712547696731; \n",
      " validation loss : 0.6601778453909632; validation accuracy : 0.8872180451127819\n",
      "Epoch 80:\t train loss : 0.5549630365407385; train accuracy : 0.9963363379970137; \n",
      " validation loss : 0.6602813808365675; validation accuracy : 0.8947368421052632\n",
      "Epoch 81:\t train loss : 0.5560544464672932; train accuracy : 0.9953132776641044; \n",
      " validation loss : 0.6563738362685356; validation accuracy : 0.8947368421052632\n",
      "Epoch 82:\t train loss : 0.5547555057051093; train accuracy : 0.9966543162085937; \n",
      " validation loss : 0.6445479774561625; validation accuracy : 0.9097744360902256\n",
      "Epoch 83:\t train loss : 0.554540047103497; train accuracy : 0.9967925676049328; \n",
      " validation loss : 0.6388347279721313; validation accuracy : 0.9172932330827067\n",
      "Epoch 84:\t train loss : 0.5553478350013291; train accuracy : 0.9959354089476303; \n",
      " validation loss : 0.665584189119266; validation accuracy : 0.8872180451127819\n",
      "Epoch 85:\t train loss : 0.5598248318194975; train accuracy : 0.9913592877288061; \n",
      " validation loss : 0.640157623222165; validation accuracy : 0.9097744360902256\n",
      "Epoch 86:\t train loss : 0.5579340920359775; train accuracy : 0.9931842061604822; \n",
      " validation loss : 0.6678433004219847; validation accuracy : 0.8796992481203008\n",
      "Epoch 87:\t train loss : 0.6240886193856292; train accuracy : 0.925551623071393; \n",
      " validation loss : 0.6601274979513425; validation accuracy : 0.8947368421052632\n",
      "Epoch 88:\t train loss : 0.5918695917064708; train accuracy : 0.9587596084720456; \n",
      " validation loss : 0.6280754306575103; validation accuracy : 0.924812030075188\n",
      "Epoch 89:\t train loss : 0.5612083893908946; train accuracy : 0.9901150251617541; \n",
      " validation loss : 0.6482640264615765; validation accuracy : 0.9022556390977443\n",
      "Epoch 90:\t train loss : 0.556460402198295; train accuracy : 0.9949538240336228; \n",
      " validation loss : 0.6263335173846547; validation accuracy : 0.924812030075188\n",
      "Epoch 91:\t train loss : 0.555579223976696; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6416974874138756; validation accuracy : 0.9097744360902256\n",
      "Epoch 92:\t train loss : 0.5550634959901097; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.6589863013116662; validation accuracy : 0.8947368421052632\n",
      "Epoch 93:\t train loss : 0.5538208685046371; train accuracy : 0.9974838245866283; \n",
      " validation loss : 0.6594259607192035; validation accuracy : 0.8947368421052632\n",
      "Epoch 94:\t train loss : 0.5565810305769694; train accuracy : 0.9948155726372836; \n",
      " validation loss : 0.6417347116751847; validation accuracy : 0.9097744360902256\n",
      "Epoch 95:\t train loss : 0.5575739691022783; train accuracy : 0.993833987723276; \n",
      " validation loss : 0.6431922875113117; validation accuracy : 0.9097744360902256\n",
      "Epoch 96:\t train loss : 0.5546811070666523; train accuracy : 0.9967372670463972; \n",
      " validation loss : 0.643399523893284; validation accuracy : 0.9097744360902256\n",
      "Epoch 97:\t train loss : 0.5569280566725077; train accuracy : 0.9944284687275341; \n",
      " validation loss : 0.679424492737067; validation accuracy : 0.8721804511278195\n",
      "Epoch 98:\t train loss : 0.5612200803417191; train accuracy : 0.9900044240446828; \n",
      " validation loss : 0.6479001966865582; validation accuracy : 0.9022556390977443\n",
      "Epoch 99:\t train loss : 0.5644328085916601; train accuracy : 0.9867140408118122; \n",
      " validation loss : 0.6667844971296444; validation accuracy : 0.8796992481203008\n",
      "Early stopping at epoch 99\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5553247105979031; Train accuracy : 0.9960874854836034; \n",
      " Validation loss : 0.6169164250556833; Validation accuracy : 0.9323308270676691\n",
      "------------------------------ Let's train model 29 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8981587993111059; train accuracy : 0.6391490188197242; \n",
      " validation loss : 0.817267265844368; validation accuracy : 0.7089552238805971\n",
      "Epoch 2:\t train loss : 0.7899830579389854; train accuracy : 0.751577751910904; \n",
      " validation loss : 0.7674805554297551; validation accuracy : 0.7761194029850746\n",
      "Epoch 3:\t train loss : 0.7483204693888402; train accuracy : 0.7977530438911091; \n",
      " validation loss : 0.7924751070971716; validation accuracy : 0.7388059701492538\n",
      "Epoch 4:\t train loss : 0.6996216249620772; train accuracy : 0.8494523221513806; \n",
      " validation loss : 0.7041122644208236; validation accuracy : 0.8507462686567164\n",
      "Epoch 5:\t train loss : 0.6559863396122475; train accuracy : 0.8948918469442395; \n",
      " validation loss : 0.7420831628101447; validation accuracy : 0.8059701492537313\n",
      "Epoch 6:\t train loss : 0.6307444278465584; train accuracy : 0.9212978636450082; \n",
      " validation loss : 0.6782762642575418; validation accuracy : 0.8656716417910447\n",
      "Epoch 7:\t train loss : 0.6178775585139379; train accuracy : 0.9339785514760528; \n",
      " validation loss : 0.7050487041747501; validation accuracy : 0.8432835820895522\n",
      "Epoch 8:\t train loss : 0.6051507198938475; train accuracy : 0.946673401645259; \n",
      " validation loss : 0.6650708577296023; validation accuracy : 0.8805970149253731\n",
      "Epoch 9:\t train loss : 0.5969161402374491; train accuracy : 0.9547027729858121; \n",
      " validation loss : 0.6819805972674398; validation accuracy : 0.8731343283582089\n",
      "Epoch 10:\t train loss : 0.5924300918138549; train accuracy : 0.9590263325074218; \n",
      " validation loss : 0.6746984287132364; validation accuracy : 0.8805970149253731\n",
      "Epoch 11:\t train loss : 0.5823775692419717; train accuracy : 0.9695057883499257; \n",
      " validation loss : 0.6723942372582922; validation accuracy : 0.8805970149253731\n",
      "Epoch 12:\t train loss : 0.5740367399132893; train accuracy : 0.9775412292639766; \n",
      " validation loss : 0.6620585711928434; validation accuracy : 0.8880597014925373\n",
      "Epoch 13:\t train loss : 0.6023322652974646; train accuracy : 0.9490027690743091; \n",
      " validation loss : 0.6890097042738265; validation accuracy : 0.8656716417910447\n",
      "Epoch 14:\t train loss : 0.5723870263030311; train accuracy : 0.9792663369314665; \n",
      " validation loss : 0.6633621983412403; validation accuracy : 0.8805970149253731\n",
      "Epoch 15:\t train loss : 0.5740713848062422; train accuracy : 0.977583041881406; \n",
      " validation loss : 0.6617559172095371; validation accuracy : 0.8880597014925373\n",
      "Epoch 16:\t train loss : 0.5690505216525833; train accuracy : 0.9826464149726937; \n",
      " validation loss : 0.6685419835988672; validation accuracy : 0.8731343283582089\n",
      "Epoch 17:\t train loss : 0.5725720785050581; train accuracy : 0.9789480215213588; \n",
      " validation loss : 0.6488397850007798; validation accuracy : 0.9104477611940298\n",
      "Epoch 18:\t train loss : 0.5686301520753082; train accuracy : 0.9828918955008275; \n",
      " validation loss : 0.6893877675365443; validation accuracy : 0.8656716417910447\n",
      "Epoch 19:\t train loss : 0.5679980014703576; train accuracy : 0.9837348918199683; \n",
      " validation loss : 0.6624706328934638; validation accuracy : 0.8955223880597015\n",
      "Epoch 20:\t train loss : 0.5664100508229654; train accuracy : 0.9852833074589663; \n",
      " validation loss : 0.6760025950243937; validation accuracy : 0.8805970149253731\n",
      "Epoch 21:\t train loss : 0.567836443488339; train accuracy : 0.9834098324393077; \n",
      " validation loss : 0.7059062216892422; validation accuracy : 0.835820895522388\n",
      "Epoch 22:\t train loss : 0.5822866078942048; train accuracy : 0.9686621176337296; \n",
      " validation loss : 0.6664968093798341; validation accuracy : 0.8880597014925373\n",
      "Epoch 23:\t train loss : 0.5680419653076907; train accuracy : 0.9832203268667647; \n",
      " validation loss : 0.6486114724546467; validation accuracy : 0.9029850746268657\n",
      "Epoch 24:\t train loss : 0.574620054479063; train accuracy : 0.9766051661512025; \n",
      " validation loss : 0.6869254291011822; validation accuracy : 0.8656716417910447\n",
      "Epoch 25:\t train loss : 0.5634937966063642; train accuracy : 0.9880105691506509; \n",
      " validation loss : 0.6768237793397377; validation accuracy : 0.8731343283582089\n",
      "Epoch 26:\t train loss : 0.572994515515982; train accuracy : 0.978333645803969; \n",
      " validation loss : 0.670488119382976; validation accuracy : 0.8731343283582089\n",
      "Epoch 27:\t train loss : 0.5762391661893655; train accuracy : 0.974749225454982; \n",
      " validation loss : 0.7139997855133666; validation accuracy : 0.8283582089552238\n",
      "Epoch 28:\t train loss : 0.5726993177303574; train accuracy : 0.9783498313332964; \n",
      " validation loss : 0.6921263637936121; validation accuracy : 0.8582089552238806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:\t train loss : 0.5615476732724786; train accuracy : 0.9896938642007114; \n",
      " validation loss : 0.6569952893156451; validation accuracy : 0.8955223880597015\n",
      "Epoch 30:\t train loss : 0.5696362441466701; train accuracy : 0.981806116241774; \n",
      " validation loss : 0.7051952419555846; validation accuracy : 0.8432835820895522\n",
      "Epoch 31:\t train loss : 0.5646094462197425; train accuracy : 0.9866833557457955; \n",
      " validation loss : 0.6581787248156996; validation accuracy : 0.8880597014925373\n",
      "Epoch 32:\t train loss : 0.5637166383364351; train accuracy : 0.9876477435348926; \n",
      " validation loss : 0.6651545999565942; validation accuracy : 0.8805970149253731\n",
      "Epoch 33:\t train loss : 0.5603299108516087; train accuracy : 0.9911970952370034; \n",
      " validation loss : 0.6822728807327676; validation accuracy : 0.8731343283582089\n",
      "Epoch 34:\t train loss : 0.558563847532203; train accuracy : 0.9928594839783491; \n",
      " validation loss : 0.6730106457678301; validation accuracy : 0.8731343283582089\n",
      "Epoch 35:\t train loss : 0.5576389991186975; train accuracy : 0.9937962214881785; \n",
      " validation loss : 0.6777777289198371; validation accuracy : 0.8731343283582089\n",
      "Epoch 36:\t train loss : 0.5586082563680039; train accuracy : 0.9927246045672866; \n",
      " validation loss : 0.6820668400555484; validation accuracy : 0.8656716417910447\n",
      "Epoch 37:\t train loss : 0.5592791091378727; train accuracy : 0.992112926438118; \n",
      " validation loss : 0.6757458960497523; validation accuracy : 0.8731343283582089\n",
      "Epoch 38:\t train loss : 0.5573821157820892; train accuracy : 0.9942076036919192; \n",
      " validation loss : 0.6737900645240852; validation accuracy : 0.8731343283582089\n",
      "Epoch 39:\t train loss : 0.5582226621744317; train accuracy : 0.9933261667406256; \n",
      " validation loss : 0.655549057267814; validation accuracy : 0.8955223880597015\n",
      "Epoch 40:\t train loss : 0.5708860608894872; train accuracy : 0.980268490955661; \n",
      " validation loss : 0.6647786787558094; validation accuracy : 0.8880597014925373\n",
      "Epoch 41:\t train loss : 0.5606043722301058; train accuracy : 0.9905921610783879; \n",
      " validation loss : 0.6762241440059982; validation accuracy : 0.8805970149253731\n",
      "Epoch 42:\t train loss : 0.5587961526432623; train accuracy : 0.9923860572455196; \n",
      " validation loss : 0.6583717282828827; validation accuracy : 0.8955223880597015\n",
      "Epoch 43:\t train loss : 0.5598709028051647; train accuracy : 0.9915079922795025; \n",
      " validation loss : 0.6835307702210386; validation accuracy : 0.8656716417910447\n",
      "Epoch 44:\t train loss : 0.5591567001193509; train accuracy : 0.9925762372151178; \n",
      " validation loss : 0.6654977792509889; validation accuracy : 0.8880597014925373\n",
      "Epoch 45:\t train loss : 0.5563684974411258; train accuracy : 0.9951787354515695; \n",
      " validation loss : 0.6769470029241946; validation accuracy : 0.8731343283582089\n",
      "Epoch 46:\t train loss : 0.5564664171457622; train accuracy : 0.9950371120699538; \n",
      " validation loss : 0.6712070082184916; validation accuracy : 0.8731343283582089\n",
      "Epoch 47:\t train loss : 0.5575557793318627; train accuracy : 0.9939034506199732; \n",
      " validation loss : 0.6853666002878249; validation accuracy : 0.8656716417910447\n",
      "Epoch 48:\t train loss : 0.563483246394315; train accuracy : 0.9878203891810526; \n",
      " validation loss : 0.6855419945585322; validation accuracy : 0.8582089552238806\n",
      "Epoch 49:\t train loss : 0.5672223634013905; train accuracy : 0.9838043547166656; \n",
      " validation loss : 0.6757084034004378; validation accuracy : 0.8731343283582089\n",
      "Epoch 50:\t train loss : 0.5721822492422146; train accuracy : 0.9788583267130022; \n",
      " validation loss : 0.6650475700171425; validation accuracy : 0.8805970149253731\n",
      "Epoch 51:\t train loss : 0.5669413951021353; train accuracy : 0.9844295207869405; \n",
      " validation loss : 0.6594325086731999; validation accuracy : 0.8880597014925373\n",
      "Epoch 52:\t train loss : 0.5579416840408234; train accuracy : 0.99344351182825; \n",
      " validation loss : 0.6583309817560978; validation accuracy : 0.8880597014925373\n",
      "Epoch 53:\t train loss : 0.5627192538666337; train accuracy : 0.9886566415296404; \n",
      " validation loss : 0.6713413852114928; validation accuracy : 0.8805970149253731\n",
      "Epoch 54:\t train loss : 0.5721423693857578; train accuracy : 0.97897229981535; \n",
      " validation loss : 0.6940911500648971; validation accuracy : 0.8582089552238806\n",
      "Epoch 55:\t train loss : 0.5732750455282757; train accuracy : 0.9777523155422894; \n",
      " validation loss : 0.6685937744589742; validation accuracy : 0.8805970149253731\n",
      "Epoch 56:\t train loss : 0.5613666112253246; train accuracy : 0.9898186276559442; \n",
      " validation loss : 0.6859814398841785; validation accuracy : 0.8656716417910447\n",
      "Epoch 57:\t train loss : 0.5689819893346717; train accuracy : 0.982200638519132; \n",
      " validation loss : 0.6843255565331461; validation accuracy : 0.8656716417910447\n",
      "Epoch 58:\t train loss : 0.5597838929385033; train accuracy : 0.991470226044405; \n",
      " validation loss : 0.6526609537776467; validation accuracy : 0.9029850746268657\n",
      "Epoch 59:\t train loss : 0.5560597249142063; train accuracy : 0.995348009112453; \n",
      " validation loss : 0.6761106573343006; validation accuracy : 0.8731343283582089\n",
      "Epoch 60:\t train loss : 0.5583218175049521; train accuracy : 0.9928284617138048; \n",
      " validation loss : 0.6583618663135669; validation accuracy : 0.8880597014925373\n",
      "Epoch 61:\t train loss : 0.5565065554469611; train accuracy : 0.9949609052027035; \n",
      " validation loss : 0.6625629586701344; validation accuracy : 0.8880597014925373\n",
      "Epoch 62:\t train loss : 0.5554709648669687; train accuracy : 0.9960702883586929; \n",
      " validation loss : 0.6810650053250703; validation accuracy : 0.8731343283582089\n",
      "Epoch 63:\t train loss : 0.5582244947755656; train accuracy : 0.9931602650650186; \n",
      " validation loss : 0.700604641590688; validation accuracy : 0.8507462686567164\n",
      "Epoch 64:\t train loss : 0.5797574198663713; train accuracy : 0.9708606520340489; \n",
      " validation loss : 0.6593799781900604; validation accuracy : 0.8955223880597015\n",
      "Epoch 65:\t train loss : 0.5708723665013561; train accuracy : 0.9803130011613117; \n",
      " validation loss : 0.6340423611220022; validation accuracy : 0.917910447761194\n",
      "Epoch 66:\t train loss : 0.5578252891069262; train accuracy : 0.9935298346513299; \n",
      " validation loss : 0.6599049236146025; validation accuracy : 0.8955223880597015\n",
      "Epoch 67:\t train loss : 0.5610780669450256; train accuracy : 0.9902468697860678; \n",
      " validation loss : 0.6746176426869102; validation accuracy : 0.8805970149253731\n",
      "Epoch 68:\t train loss : 0.5640119007896905; train accuracy : 0.9872053390666075; \n",
      " validation loss : 0.6550080069783689; validation accuracy : 0.8955223880597015\n",
      "Epoch 69:\t train loss : 0.5569145415332076; train accuracy : 0.9943735053675261; \n",
      " validation loss : 0.6660736821761226; validation accuracy : 0.8805970149253731\n",
      "Epoch 70:\t train loss : 0.5566669978435016; train accuracy : 0.9945980795869452; \n",
      " validation loss : 0.6770583366722034; validation accuracy : 0.8731343283582089\n",
      "Epoch 71:\t train loss : 0.5553309287917896; train accuracy : 0.9960291501383188; \n",
      " validation loss : 0.6712536478026425; validation accuracy : 0.8805970149253731\n",
      "Epoch 72:\t train loss : 0.5569484458022963; train accuracy : 0.9945704293076775; \n",
      " validation loss : 0.6905150146979107; validation accuracy : 0.8507462686567164\n",
      "Epoch 73:\t train loss : 0.5571326020003557; train accuracy : 0.9941900693684811; \n",
      " validation loss : 0.7278272248270579; validation accuracy : 0.8208955223880597\n",
      "Epoch 74:\t train loss : 0.5550323538839185; train accuracy : 0.9963643254748092; \n",
      " validation loss : 0.6679703697998958; validation accuracy : 0.8805970149253731\n",
      "Epoch 75:\t train loss : 0.5880234475282837; train accuracy : 0.9625136396804437; \n",
      " validation loss : 0.6779055945225319; validation accuracy : 0.8805970149253731\n",
      "Epoch 76:\t train loss : 0.5607532440483738; train accuracy : 0.9905436044904053; \n",
      " validation loss : 0.6677318485953521; validation accuracy : 0.8880597014925373\n",
      "Epoch 77:\t train loss : 0.5585235214639348; train accuracy : 0.9929458068014292; \n",
      " validation loss : 0.6604261884168986; validation accuracy : 0.8805970149253731\n",
      "Epoch 78:\t train loss : 0.5767128759626875; train accuracy : 0.9743209833248584; \n",
      " validation loss : 0.709759442729191; validation accuracy : 0.835820895522388\n",
      "Epoch 79:\t train loss : 0.5932856045290881; train accuracy : 0.9571562294730396; \n",
      " validation loss : 0.6563231477943479; validation accuracy : 0.8955223880597015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80:\t train loss : 0.557120714492136; train accuracy : 0.9943768773528027; \n",
      " validation loss : 0.6945111565039296; validation accuracy : 0.8582089552238806\n",
      "Epoch 81:\t train loss : 0.5585430155632731; train accuracy : 0.9927731611552691; \n",
      " validation loss : 0.6691076555966775; validation accuracy : 0.8805970149253731\n",
      "Epoch 82:\t train loss : 0.5601838958421523; train accuracy : 0.9910177056202901; \n",
      " validation loss : 0.6607296219530493; validation accuracy : 0.8880597014925373\n",
      "Epoch 83:\t train loss : 0.5746002831328536; train accuracy : 0.9764736587254166; \n",
      " validation loss : 0.6856788280859318; validation accuracy : 0.8656716417910447\n",
      "Epoch 84:\t train loss : 0.5616906631556866; train accuracy : 0.9895657287602019; \n",
      " validation loss : 0.666882560322265; validation accuracy : 0.8880597014925373\n",
      "Epoch 85:\t train loss : 0.5547861387060574; train accuracy : 0.9966995008112997; \n",
      " validation loss : 0.66760989174119; validation accuracy : 0.8805970149253731\n",
      "Epoch 86:\t train loss : 0.5539069020344107; train accuracy : 0.9975667754244317; \n",
      " validation loss : 0.7024447630961708; validation accuracy : 0.8432835820895522\n",
      "Epoch 87:\t train loss : 0.5554946475367213; train accuracy : 0.9958801083890947; \n",
      " validation loss : 0.7247734722140526; validation accuracy : 0.8208955223880597\n",
      "Epoch 88:\t train loss : 0.5534953720392496; train accuracy : 0.9978985787756456; \n",
      " validation loss : 0.6842616284601332; validation accuracy : 0.8656716417910447\n",
      "Epoch 89:\t train loss : 0.5529285909400738; train accuracy : 0.9985864637720646; \n",
      " validation loss : 0.6626006158050934; validation accuracy : 0.8880597014925373\n",
      "Epoch 90:\t train loss : 0.5532034585981082; train accuracy : 0.9982546604208508; \n",
      " validation loss : 0.675014439691921; validation accuracy : 0.8731343283582089\n",
      "Epoch 91:\t train loss : 0.557411431624643; train accuracy : 0.9937827335470723; \n",
      " validation loss : 0.6914801806967323; validation accuracy : 0.8582089552238806\n",
      "Epoch 92:\t train loss : 0.5577996600463284; train accuracy : 0.9935507409600447; \n",
      " validation loss : 0.7092335261425206; validation accuracy : 0.8432835820895522\n",
      "Epoch 93:\t train loss : 0.5577288371517045; train accuracy : 0.9937894775176254; \n",
      " validation loss : 0.6631777445896926; validation accuracy : 0.8880597014925373\n",
      "Epoch 94:\t train loss : 0.5573989366931859; train accuracy : 0.9938481500614376; \n",
      " validation loss : 0.6732459846775877; validation accuracy : 0.8805970149253731\n",
      "Epoch 95:\t train loss : 0.5554531255493694; train accuracy : 0.9958942707272563; \n",
      " validation loss : 0.6689040260595626; validation accuracy : 0.8880597014925373\n",
      "Epoch 96:\t train loss : 0.555744565672117; train accuracy : 0.995565839361319; \n",
      " validation loss : 0.6910251164869171; validation accuracy : 0.8582089552238806\n",
      "Epoch 97:\t train loss : 0.570941513868538; train accuracy : 0.980106635662386; \n",
      " validation loss : 0.6565866750798415; validation accuracy : 0.8955223880597015\n",
      "Epoch 98:\t train loss : 0.5708983111203054; train accuracy : 0.9801403555151517; \n",
      " validation loss : 0.7072915189832019; validation accuracy : 0.8432835820895522\n",
      "Epoch 99:\t train loss : 0.554564195991635; train accuracy : 0.9968755184427363; \n",
      " validation loss : 0.6745447741182203; validation accuracy : 0.8731343283582089\n",
      "Epoch 100:\t train loss : 0.5581506146366793; train accuracy : 0.993191287329563; \n",
      " validation loss : 0.7023418873257589; validation accuracy : 0.8507462686567164\n",
      "Epoch 101:\t train loss : 0.5630270822426323; train accuracy : 0.9882358177671253; \n",
      " validation loss : 0.6645159936200862; validation accuracy : 0.8880597014925373\n",
      "Epoch 102:\t train loss : 0.607453708115927; train accuracy : 0.9429237540177204; \n",
      " validation loss : 0.7062727835826996; validation accuracy : 0.835820895522388\n",
      "Epoch 103:\t train loss : 0.5753830151414262; train accuracy : 0.9754816206570516; \n",
      " validation loss : 0.653214738894781; validation accuracy : 0.8955223880597015\n",
      "Epoch 104:\t train loss : 0.5673630427821192; train accuracy : 0.9836141747470674; \n",
      " validation loss : 0.6674103593761085; validation accuracy : 0.8805970149253731\n",
      "Epoch 105:\t train loss : 0.5582804319233243; train accuracy : 0.9930429199773942; \n",
      " validation loss : 0.6858276923477374; validation accuracy : 0.8656716417910447\n",
      "Epoch 106:\t train loss : 0.5576320212886433; train accuracy : 0.9937409209296428; \n",
      " validation loss : 0.6801132248023111; validation accuracy : 0.8731343283582089\n",
      "Epoch 107:\t train loss : 0.5545990943126579; train accuracy : 0.9967413134287291; \n",
      " validation loss : 0.697267756383941; validation accuracy : 0.8432835820895522\n",
      "Epoch 108:\t train loss : 0.5558458154276779; train accuracy : 0.9954066816562652; \n",
      " validation loss : 0.6521039806102715; validation accuracy : 0.8955223880597015\n",
      "Epoch 109:\t train loss : 0.5540552881629085; train accuracy : 0.9973422012050126; \n",
      " validation loss : 0.6838947202621495; validation accuracy : 0.8582089552238806\n",
      "Epoch 110:\t train loss : 0.5532153286308084; train accuracy : 0.9981892439064854; \n",
      " validation loss : 0.6494681279304172; validation accuracy : 0.9029850746268657\n",
      "Epoch 111:\t train loss : 0.5537457337261025; train accuracy : 0.9976949108649412; \n",
      " validation loss : 0.6992658196683006; validation accuracy : 0.8507462686567164\n",
      "Epoch 112:\t train loss : 0.5598023173201307; train accuracy : 0.9913353466333424; \n",
      " validation loss : 0.7216610463179831; validation accuracy : 0.8208955223880597\n",
      "Epoch 113:\t train loss : 0.5532530843308343; train accuracy : 0.998147431289056; \n",
      " validation loss : 0.6585095427623484; validation accuracy : 0.8955223880597015\n",
      "Epoch 114:\t train loss : 0.5548458289868653; train accuracy : 0.9965922716795049; \n",
      " validation loss : 0.6783458011976619; validation accuracy : 0.8731343283582089\n",
      "Epoch 115:\t train loss : 0.554956708736901; train accuracy : 0.9963710694453624; \n",
      " validation loss : 0.6585307477281304; validation accuracy : 0.8955223880597015\n",
      "Early stopping at epoch 115\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5708723665013561; Train accuracy : 0.9803130011613117; \n",
      " Validation loss : 0.6340423611220022; Validation accuracy : 0.917910447761194\n",
      "------------------------------ Let's train model 30 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8956558702946399; train accuracy : 0.6372438471384658; \n",
      " validation loss : 0.8062786266777883; validation accuracy : 0.7238805970149254\n",
      "Epoch 2:\t train loss : 0.7785282207194821; train accuracy : 0.7662708405550018; \n",
      " validation loss : 0.7691816541792215; validation accuracy : 0.7910447761194029\n",
      "Epoch 3:\t train loss : 0.7324468476878708; train accuracy : 0.8139008069835164; \n",
      " validation loss : 0.7271944145006776; validation accuracy : 0.8208955223880597\n",
      "Epoch 4:\t train loss : 0.6881144057890426; train accuracy : 0.8606884514899454; \n",
      " validation loss : 0.7158154089105299; validation accuracy : 0.8208955223880597\n",
      "Epoch 5:\t train loss : 0.6629726803744919; train accuracy : 0.8874154811890429; \n",
      " validation loss : 0.6928217479884783; validation accuracy : 0.8432835820895522\n",
      "Epoch 6:\t train loss : 0.647809619259874; train accuracy : 0.9029070559466309; \n",
      " validation loss : 0.6645800162677703; validation accuracy : 0.8955223880597015\n",
      "Epoch 7:\t train loss : 0.6316770871713867; train accuracy : 0.9182212642786717; \n",
      " validation loss : 0.6677574804720178; validation accuracy : 0.8805970149253731\n",
      "Epoch 8:\t train loss : 0.60968731749345; train accuracy : 0.9412472029382131; \n",
      " validation loss : 0.662316046442253; validation accuracy : 0.8955223880597015\n",
      "Epoch 9:\t train loss : 0.6107587272209681; train accuracy : 0.9405282956772497; \n",
      " validation loss : 0.6835398505630439; validation accuracy : 0.8656716417910447\n",
      "Epoch 10:\t train loss : 0.5969380926949377; train accuracy : 0.9546643323536592; \n",
      " validation loss : 0.6695218626025892; validation accuracy : 0.8731343283582089\n",
      "Epoch 11:\t train loss : 0.6054319345815082; train accuracy : 0.9456125750772522; \n",
      " validation loss : 0.6518971476759998; validation accuracy : 0.8955223880597015\n",
      "Epoch 12:\t train loss : 0.5941860994594833; train accuracy : 0.9574023843982288; \n",
      " validation loss : 0.6252610116216609; validation accuracy : 0.917910447761194\n",
      "Epoch 13:\t train loss : 0.5885989469643691; train accuracy : 0.9626727973854975; \n",
      " validation loss : 0.6397294804526352; validation accuracy : 0.9104477611940298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\t train loss : 0.5775253191098424; train accuracy : 0.9742164517812849; \n",
      " validation loss : 0.6546562025464505; validation accuracy : 0.8805970149253731\n",
      "Epoch 15:\t train loss : 0.5744620184499816; train accuracy : 0.9771649157071121; \n",
      " validation loss : 0.6571077812725183; validation accuracy : 0.9029850746268657\n",
      "Epoch 16:\t train loss : 0.5741599672446202; train accuracy : 0.9773443053238252; \n",
      " validation loss : 0.6641557453205978; validation accuracy : 0.8880597014925373\n",
      "Epoch 17:\t train loss : 0.5708851727726573; train accuracy : 0.9808869130553829; \n",
      " validation loss : 0.6634258794399962; validation accuracy : 0.8805970149253731\n",
      "Epoch 18:\t train loss : 0.5679616803188859; train accuracy : 0.9837315198346918; \n",
      " validation loss : 0.6342867243836069; validation accuracy : 0.9104477611940298\n",
      "Epoch 19:\t train loss : 0.57473626448783; train accuracy : 0.9768432283117279; \n",
      " validation loss : 0.6481584765770652; validation accuracy : 0.9029850746268657\n",
      "Epoch 20:\t train loss : 0.5773783956057033; train accuracy : 0.9738050695775442; \n",
      " validation loss : 0.6782748461639326; validation accuracy : 0.8656716417910447\n",
      "Epoch 21:\t train loss : 0.5762720722086719; train accuracy : 0.9746966224846676; \n",
      " validation loss : 0.6687922835839107; validation accuracy : 0.8805970149253731\n",
      "Epoch 22:\t train loss : 0.572404922167953; train accuracy : 0.9783329714069137; \n",
      " validation loss : 0.6298578399185273; validation accuracy : 0.9253731343283582\n",
      "Epoch 23:\t train loss : 0.5633769681384024; train accuracy : 0.9880793576502928; \n",
      " validation loss : 0.6652192095350382; validation accuracy : 0.8880597014925373\n",
      "Epoch 24:\t train loss : 0.5649135296575608; train accuracy : 0.9863097397771522; \n",
      " validation loss : 0.6360771205009929; validation accuracy : 0.917910447761194\n",
      "Epoch 25:\t train loss : 0.5627279445376259; train accuracy : 0.9887604986761586; \n",
      " validation loss : 0.6230379637884825; validation accuracy : 0.9253731343283582\n",
      "Epoch 26:\t train loss : 0.5657547980273785; train accuracy : 0.9855011377078323; \n",
      " validation loss : 0.6469457023646934; validation accuracy : 0.9029850746268657\n",
      "Epoch 27:\t train loss : 0.5697268657530911; train accuracy : 0.9816611208748818; \n",
      " validation loss : 0.679301217269704; validation accuracy : 0.8656716417910447\n",
      "Epoch 28:\t train loss : 0.5843913603458392; train accuracy : 0.9667441324084203; \n",
      " validation loss : 0.6928271160850971; validation accuracy : 0.8582089552238806\n",
      "Epoch 29:\t train loss : 0.5656142319911843; train accuracy : 0.9857054800155921; \n",
      " validation loss : 0.6347215687788172; validation accuracy : 0.917910447761194\n",
      "Epoch 30:\t train loss : 0.5666292727052716; train accuracy : 0.984650723021083; \n",
      " validation loss : 0.6467803346739751; validation accuracy : 0.9029850746268657\n",
      "Epoch 31:\t train loss : 0.5637583095770682; train accuracy : 0.9877030440934282; \n",
      " validation loss : 0.6333134563302133; validation accuracy : 0.917910447761194\n",
      "Epoch 32:\t train loss : 0.5710903411965269; train accuracy : 0.9799886161777063; \n",
      " validation loss : 0.6253419091557355; validation accuracy : 0.9253731343283582\n",
      "Epoch 33:\t train loss : 0.5675410921377613; train accuracy : 0.9835865244677996; \n",
      " validation loss : 0.6519680549799816; validation accuracy : 0.8955223880597015\n",
      "Epoch 34:\t train loss : 0.5722984230218163; train accuracy : 0.9786924250373953; \n",
      " validation loss : 0.669771301042164; validation accuracy : 0.8805970149253731\n",
      "Epoch 35:\t train loss : 0.561587598825867; train accuracy : 0.9900324115224783; \n",
      " validation loss : 0.6429650631424879; validation accuracy : 0.9104477611940298\n",
      "Epoch 36:\t train loss : 0.5597499520874661; train accuracy : 0.9914216694564225; \n",
      " validation loss : 0.6107166905929604; validation accuracy : 0.9328358208955224\n",
      "Epoch 37:\t train loss : 0.559957676244634; train accuracy : 0.9913286026627893; \n",
      " validation loss : 0.6243447627726795; validation accuracy : 0.9253731343283582\n",
      "Epoch 38:\t train loss : 0.5651705532654691; train accuracy : 0.9858882416175818; \n",
      " validation loss : 0.642563119779732; validation accuracy : 0.9104477611940298\n",
      "Epoch 39:\t train loss : 0.5587352404574413; train accuracy : 0.9927556268318309; \n",
      " validation loss : 0.644283760496199; validation accuracy : 0.9029850746268657\n",
      "Epoch 40:\t train loss : 0.5593858608671242; train accuracy : 0.992112926438118; \n",
      " validation loss : 0.6201697322530526; validation accuracy : 0.9253731343283582\n",
      "Epoch 41:\t train loss : 0.5603314594520366; train accuracy : 0.9911175163844764; \n",
      " validation loss : 0.61645377956121; validation accuracy : 0.9402985074626866\n",
      "Epoch 42:\t train loss : 0.557764051805617; train accuracy : 0.9935264626660534; \n",
      " validation loss : 0.6096742169189697; validation accuracy : 0.9402985074626866\n",
      "Epoch 43:\t train loss : 0.5625387479307955; train accuracy : 0.9886910357794614; \n",
      " validation loss : 0.6304634057192701; validation accuracy : 0.917910447761194\n",
      "Epoch 44:\t train loss : 0.565181494340112; train accuracy : 0.985946914161394; \n",
      " validation loss : 0.6654760281285657; validation accuracy : 0.8880597014925373\n",
      "Epoch 45:\t train loss : 0.5602078782471934; train accuracy : 0.9910898661052087; \n",
      " validation loss : 0.64404553531438; validation accuracy : 0.9029850746268657\n",
      "Epoch 46:\t train loss : 0.5623413705976823; train accuracy : 0.9891233242919169; \n",
      " validation loss : 0.6248667917254792; validation accuracy : 0.9253731343283582\n",
      "Epoch 47:\t train loss : 0.5609212667257767; train accuracy : 0.9904990942847547; \n",
      " validation loss : 0.7272861091727568; validation accuracy : 0.8208955223880597\n",
      "Epoch 48:\t train loss : 0.5673984115343841; train accuracy : 0.9834759233507283; \n",
      " validation loss : 0.6634508279992666; validation accuracy : 0.8880597014925373\n",
      "Epoch 49:\t train loss : 0.5625103868145906; train accuracy : 0.9889506786457568; \n",
      " validation loss : 0.6452105266205962; validation accuracy : 0.9029850746268657\n",
      "Epoch 50:\t train loss : 0.5678207929089629; train accuracy : 0.9834449010861839; \n",
      " validation loss : 0.6444899395069641; validation accuracy : 0.9104477611940298\n",
      "Epoch 51:\t train loss : 0.5711615078277207; train accuracy : 0.9797397636642959; \n",
      " validation loss : 0.6433670242281805; validation accuracy : 0.9029850746268657\n",
      "Epoch 52:\t train loss : 0.5712674929200735; train accuracy : 0.9794632608716177; \n",
      " validation loss : 0.6140511150674541; validation accuracy : 0.9328358208955224\n",
      "Epoch 53:\t train loss : 0.58735750441894; train accuracy : 0.9629459281928991; \n",
      " validation loss : 0.6335063279307652; validation accuracy : 0.917910447761194\n",
      "Epoch 54:\t train loss : 0.57239625049844; train accuracy : 0.9787578415517606; \n",
      " validation loss : 0.6702748263573504; validation accuracy : 0.8805970149253731\n",
      "Epoch 55:\t train loss : 0.5563833206967466; train accuracy : 0.995095784613766; \n",
      " validation loss : 0.6412572151355319; validation accuracy : 0.9104477611940298\n",
      "Epoch 56:\t train loss : 0.5556338526546979; train accuracy : 0.9956831844489434; \n",
      " validation loss : 0.6257310964459887; validation accuracy : 0.9253731343283582\n",
      "Epoch 57:\t train loss : 0.5543494144605364; train accuracy : 0.9970313041625135; \n",
      " validation loss : 0.6277646413923946; validation accuracy : 0.9253731343283582\n",
      "Epoch 58:\t train loss : 0.554434612347812; train accuracy : 0.9969793755892544; \n",
      " validation loss : 0.6349094006472474; validation accuracy : 0.917910447761194\n",
      "Epoch 59:\t train loss : 0.5533934252886858; train accuracy : 0.9980887587452438; \n",
      " validation loss : 0.6206587425312134; validation accuracy : 0.9328358208955224\n",
      "Epoch 60:\t train loss : 0.5568961862740899; train accuracy : 0.9943802493380792; \n",
      " validation loss : 0.6148863225904995; validation accuracy : 0.9402985074626866\n",
      "Epoch 61:\t train loss : 0.5567801719295306; train accuracy : 0.9947154246745696; \n",
      " validation loss : 0.6274407933745761; validation accuracy : 0.9253731343283582\n",
      "Epoch 62:\t train loss : 0.5554971462217506; train accuracy : 0.9958457141392738; \n",
      " validation loss : 0.6269156740426335; validation accuracy : 0.9253731343283582\n",
      "Epoch 63:\t train loss : 0.5566578002665484; train accuracy : 0.9948226538063644; \n",
      " validation loss : 0.6195303095052207; validation accuracy : 0.9328358208955224\n",
      "Epoch 64:\t train loss : 0.5562317640796296; train accuracy : 0.9952374079953817; \n",
      " validation loss : 0.6185855686924366; validation accuracy : 0.9328358208955224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:\t train loss : 0.5614177635889726; train accuracy : 0.9897869309943444; \n",
      " validation loss : 0.6351219997590565; validation accuracy : 0.917910447761194\n",
      "Epoch 66:\t train loss : 0.5646644011139322; train accuracy : 0.9863582963651347; \n",
      " validation loss : 0.640831214576154; validation accuracy : 0.9104477611940298\n",
      "Epoch 67:\t train loss : 0.5636309966999968; train accuracy : 0.9874332852713031; \n",
      " validation loss : 0.6689516220307635; validation accuracy : 0.8805970149253731\n",
      "Epoch 68:\t train loss : 0.5675553110690014; train accuracy : 0.9836141747470674; \n",
      " validation loss : 0.6337348448433842; validation accuracy : 0.9104477611940298\n",
      "Epoch 69:\t train loss : 0.657378664010234; train accuracy : 0.8919609173418506; \n",
      " validation loss : 0.7305373805443102; validation accuracy : 0.8059701492537313\n",
      "Epoch 70:\t train loss : 0.7113954110909495; train accuracy : 0.8380395007843238; \n",
      " validation loss : 0.7178858231753302; validation accuracy : 0.8208955223880597\n",
      "Epoch 71:\t train loss : 0.6701221770167439; train accuracy : 0.8782187285457437; \n",
      " validation loss : 0.6685621609256766; validation accuracy : 0.8880597014925373\n",
      "Epoch 72:\t train loss : 0.6276895166018192; train accuracy : 0.9221685102434168; \n",
      " validation loss : 0.6813037980700628; validation accuracy : 0.8656716417910447\n",
      "Epoch 73:\t train loss : 0.6087159464308032; train accuracy : 0.9415304497014444; \n",
      " validation loss : 0.6565360540108894; validation accuracy : 0.8955223880597015\n",
      "Epoch 74:\t train loss : 0.5935152447220899; train accuracy : 0.9571319511790484; \n",
      " validation loss : 0.6286429601148636; validation accuracy : 0.917910447761194\n",
      "Epoch 75:\t train loss : 0.5895374611162548; train accuracy : 0.9609962463059901; \n",
      " validation loss : 0.6573872890440206; validation accuracy : 0.8880597014925373\n",
      "Epoch 76:\t train loss : 0.5791265325236246; train accuracy : 0.971859434072967; \n",
      " validation loss : 0.6268498696682251; validation accuracy : 0.9253731343283582\n",
      "Epoch 77:\t train loss : 0.577358271624681; train accuracy : 0.9737153747691876; \n",
      " validation loss : 0.6409663746479257; validation accuracy : 0.9029850746268657\n",
      "Epoch 78:\t train loss : 0.5744123518564936; train accuracy : 0.9767326271946566; \n",
      " validation loss : 0.6116772116980774; validation accuracy : 0.9402985074626866\n",
      "Epoch 79:\t train loss : 0.5761394847155622; train accuracy : 0.974997403571337; \n",
      " validation loss : 0.6104668060907749; validation accuracy : 0.9402985074626866\n",
      "Epoch 80:\t train loss : 0.5720110876687754; train accuracy : 0.9792110363729308; \n",
      " validation loss : 0.6525354560865004; validation accuracy : 0.9029850746268657\n",
      "Epoch 81:\t train loss : 0.5708980843280728; train accuracy : 0.9802617469851079; \n",
      " validation loss : 0.6685630265730231; validation accuracy : 0.8805970149253731\n",
      "Epoch 82:\t train loss : 0.5668774333450375; train accuracy : 0.9845542842421733; \n",
      " validation loss : 0.6533570123146355; validation accuracy : 0.8955223880597015\n",
      "Epoch 83:\t train loss : 0.5701579845055311; train accuracy : 0.9806623388359638; \n",
      " validation loss : 0.6351986806125889; validation accuracy : 0.9104477611940298\n",
      "Epoch 84:\t train loss : 0.5649623139012256; train accuracy : 0.98616474441026; \n",
      " validation loss : 0.621504196009014; validation accuracy : 0.9253731343283582\n",
      "Epoch 85:\t train loss : 0.5640894002627418; train accuracy : 0.987243105301705; \n",
      " validation loss : 0.6214382861718435; validation accuracy : 0.9253731343283582\n",
      "Epoch 86:\t train loss : 0.562621118044268; train accuracy : 0.9884839958834803; \n",
      " validation loss : 0.6089788400720539; validation accuracy : 0.9402985074626866\n",
      "Epoch 87:\t train loss : 0.5608852401882201; train accuracy : 0.9905820451225582; \n",
      " validation loss : 0.6058211549818416; validation accuracy : 0.9477611940298507\n",
      "Epoch 88:\t train loss : 0.559995161967732; train accuracy : 0.9913872752066015; \n",
      " validation loss : 0.6287534463799472; validation accuracy : 0.9253731343283582\n",
      "Epoch 89:\t train loss : 0.5699903317624548; train accuracy : 0.981219390803652; \n",
      " validation loss : 0.640896278858782; validation accuracy : 0.9104477611940298\n",
      "Epoch 90:\t train loss : 0.5627310517374187; train accuracy : 0.9886053873534366; \n",
      " validation loss : 0.6501700637859794; validation accuracy : 0.8955223880597015\n",
      "Epoch 91:\t train loss : 0.5597612903230946; train accuracy : 0.9918505859836013; \n",
      " validation loss : 0.6069821402396628; validation accuracy : 0.9402985074626866\n",
      "Epoch 92:\t train loss : 0.5588823764623629; train accuracy : 0.9924312418482256; \n",
      " validation loss : 0.612669038350537; validation accuracy : 0.9402985074626866\n",
      "Epoch 93:\t train loss : 0.5570891030663826; train accuracy : 0.9940936305895713; \n",
      " validation loss : 0.6246515402133864; validation accuracy : 0.9253731343283582\n",
      "Epoch 94:\t train loss : 0.5783585853765348; train accuracy : 0.9724158116436; \n",
      " validation loss : 0.6471757806421914; validation accuracy : 0.9029850746268657\n",
      "Epoch 95:\t train loss : 0.5777062566829926; train accuracy : 0.9730517680667599; \n",
      " validation loss : 0.6732041981171483; validation accuracy : 0.8805970149253731\n",
      "Epoch 96:\t train loss : 0.5873690081215037; train accuracy : 0.9634085645728436; \n",
      " validation loss : 0.6474211845869434; validation accuracy : 0.9029850746268657\n",
      "Epoch 97:\t train loss : 0.5679976631067615; train accuracy : 0.9832236988520413; \n",
      " validation loss : 0.6410594173405587; validation accuracy : 0.9104477611940298\n",
      "Epoch 98:\t train loss : 0.5687410804569261; train accuracy : 0.9819861802555425; \n",
      " validation loss : 0.6135807704167636; validation accuracy : 0.9402985074626866\n",
      "Epoch 99:\t train loss : 0.5643685741059908; train accuracy : 0.9869456962003121; \n",
      " validation loss : 0.6414786247571559; validation accuracy : 0.9104477611940298\n",
      "Epoch 100:\t train loss : 0.5647215061118228; train accuracy : 0.9866658214223574; \n",
      " validation loss : 0.6409822988857524; validation accuracy : 0.9104477611940298\n",
      "Epoch 101:\t train loss : 0.5679993985180056; train accuracy : 0.9831542359553441; \n",
      " validation loss : 0.6679935839935484; validation accuracy : 0.8805970149253731\n",
      "Epoch 102:\t train loss : 0.5615609861233595; train accuracy : 0.9897006081712645; \n",
      " validation loss : 0.6140206316583137; validation accuracy : 0.9328358208955224\n",
      "Epoch 103:\t train loss : 0.5591966511491434; train accuracy : 0.9919227464685199; \n",
      " validation loss : 0.6237528385997244; validation accuracy : 0.9253731343283582\n",
      "Epoch 104:\t train loss : 0.5570218289264767; train accuracy : 0.9942419979417402; \n",
      " validation loss : 0.6317363061959544; validation accuracy : 0.917910447761194\n",
      "Epoch 128:\t train loss : 0.5591594380262177; train accuracy : 0.9922478058491805; \n",
      " validation loss : 0.6099637225736178; validation accuracy : 0.9402985074626866\n",
      "Epoch 129:\t train loss : 0.5564363398737635; train accuracy : 0.9950162057612392; \n",
      " validation loss : 0.6490447814002946; validation accuracy : 0.9029850746268657\n",
      "Epoch 130:\t train loss : 0.5579364507095025; train accuracy : 0.9935264626660534; \n",
      " validation loss : 0.6283974549466075; validation accuracy : 0.9253731343283582\n",
      "Epoch 131:\t train loss : 0.5546774699042928; train accuracy : 0.9967028727965762; \n",
      " validation loss : 0.6373545088565847; validation accuracy : 0.9104477611940298\n",
      "Epoch 132:\t train loss : 0.554568901039925; train accuracy : 0.9967858236343796; \n",
      " validation loss : 0.6278840237634454; validation accuracy : 0.9253731343283582\n",
      "Epoch 133:\t train loss : 0.5624342168456358; train accuracy : 0.9887085701028995; \n",
      " validation loss : 0.6559010622154776; validation accuracy : 0.8955223880597015\n",
      "Epoch 134:\t train loss : 0.5796922422132869; train accuracy : 0.9711924553852628; \n",
      " validation loss : 0.6454875464814913; validation accuracy : 0.9029850746268657\n",
      "Epoch 135:\t train loss : 0.5673717594481354; train accuracy : 0.983703869555424; \n",
      " validation loss : 0.6369699830793573; validation accuracy : 0.917910447761194\n",
      "Epoch 136:\t train loss : 0.5687998615468125; train accuracy : 0.9822107544749616; \n",
      " validation loss : 0.6483733545190179; validation accuracy : 0.9029850746268657\n",
      "Epoch 137:\t train loss : 0.5646472054568153; train accuracy : 0.9865208260554651; \n",
      " validation loss : 0.6582300332265221; validation accuracy : 0.8880597014925373\n",
      "Epoch 138:\t train loss : 0.5667504764417396; train accuracy : 0.984564400198003; \n",
      " validation loss : 0.657520936503515; validation accuracy : 0.8955223880597015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139:\t train loss : 0.5605456439355008; train accuracy : 0.9907580627539948; \n",
      " validation loss : 0.613853279633486; validation accuracy : 0.9402985074626866\n",
      "Epoch 140:\t train loss : 0.5600351763446292; train accuracy : 0.9912733021042537; \n",
      " validation loss : 0.6780445959708313; validation accuracy : 0.8731343283582089\n",
      "Epoch 141:\t train loss : 0.5564586978659095; train accuracy : 0.9948779543649; \n",
      " validation loss : 0.6365264931471076; validation accuracy : 0.917910447761194\n",
      "Epoch 142:\t train loss : 0.5555275123500703; train accuracy : 0.9958423421539973; \n",
      " validation loss : 0.6679812759010186; validation accuracy : 0.8805970149253731\n",
      "Epoch 143:\t train loss : 0.5544072021038351; train accuracy : 0.997027932177237; \n",
      " validation loss : 0.6186815815714523; validation accuracy : 0.9328358208955224\n",
      "Epoch 144:\t train loss : 0.5694386366165555; train accuracy : 0.9819308796970069; \n",
      " validation loss : 0.613614521127245; validation accuracy : 0.9402985074626866\n",
      "Epoch 145:\t train loss : 0.5590609168530031; train accuracy : 0.9923793132749665; \n",
      " validation loss : 0.6228780220705726; validation accuracy : 0.9253731343283582\n",
      "Epoch 146:\t train loss : 0.5632437361418892; train accuracy : 0.9879964068124892; \n",
      " validation loss : 0.6273813721023439; validation accuracy : 0.917910447761194\n",
      "Epoch 147:\t train loss : 0.5567784895187776; train accuracy : 0.994539407043133; \n",
      " validation loss : 0.624963186231914; validation accuracy : 0.9253731343283582\n",
      "Epoch 148:\t train loss : 0.5596181955751888; train accuracy : 0.9914769700149582; \n",
      " validation loss : 0.6263269134454772; validation accuracy : 0.9253731343283582\n",
      "Epoch 149:\t train loss : 0.5550963104221343; train accuracy : 0.9962361900342999; \n",
      " validation loss : 0.6599184083101599; validation accuracy : 0.8955223880597015\n",
      "Epoch 150:\t train loss : 0.5561243172865692; train accuracy : 0.9951821074368461; \n",
      " validation loss : 0.639870732040568; validation accuracy : 0.9104477611940298\n",
      "Epoch 151:\t train loss : 0.5564196922217776; train accuracy : 0.9949818115114182; \n",
      " validation loss : 0.6183457696361275; validation accuracy : 0.9328358208955224\n",
      "Epoch 152:\t train loss : 0.5586763452935669; train accuracy : 0.9925762372151178; \n",
      " validation loss : 0.64951343632077; validation accuracy : 0.8955223880597015\n",
      "Epoch 153:\t train loss : 0.5560856633120808; train accuracy : 0.995313614862632; \n",
      " validation loss : 0.6392996089495704; validation accuracy : 0.9104477611940298\n",
      "Epoch 154:\t train loss : 0.566096896406684; train accuracy : 0.984868553269949; \n",
      " validation loss : 0.6147726676494673; validation accuracy : 0.9402985074626866\n",
      "Epoch 155:\t train loss : 0.559302102798352; train accuracy : 0.9920542538943058; \n",
      " validation loss : 0.6376044346880363; validation accuracy : 0.9104477611940298\n",
      "Epoch 156:\t train loss : 0.5560870366301807; train accuracy : 0.9951854794221227; \n",
      " validation loss : 0.596177664469468; validation accuracy : 0.9552238805970149\n",
      "Epoch 157:\t train loss : 0.5553486096413898; train accuracy : 0.9960911946674076; \n",
      " validation loss : 0.6537181280868571; validation accuracy : 0.8955223880597015\n",
      "Epoch 158:\t train loss : 0.5561805070988189; train accuracy : 0.9952097577161139; \n",
      " validation loss : 0.6187109205397765; validation accuracy : 0.9328358208955224\n",
      "Epoch 159:\t train loss : 0.5548726173258451; train accuracy : 0.9965888996942284; \n",
      " validation loss : 0.6440130191336505; validation accuracy : 0.9029850746268657\n",
      "Epoch 160:\t train loss : 0.5554495696462188; train accuracy : 0.9959873375208894; \n",
      " validation loss : 0.6186591178461321; validation accuracy : 0.9328358208955224\n",
      "Epoch 161:\t train loss : 0.5541819078749223; train accuracy : 0.997200577823397; \n",
      " validation loss : 0.6339020043377809; validation accuracy : 0.917910447761194\n",
      "Epoch 162:\t train loss : 0.5570178310725341; train accuracy : 0.9942352539711871; \n",
      " validation loss : 0.633333029698588; validation accuracy : 0.917910447761194\n",
      "Epoch 163:\t train loss : 0.5684866373292389; train accuracy : 0.9827536441044884; \n",
      " validation loss : 0.6017374291588112; validation accuracy : 0.9477611940298507\n",
      "Epoch 164:\t train loss : 0.576253228210884; train accuracy : 0.9748524082044449; \n",
      " validation loss : 0.6492070594971722; validation accuracy : 0.9029850746268657\n",
      "Epoch 165:\t train loss : 0.5850650393002815; train accuracy : 0.9656900498109665; \n",
      " validation loss : 0.6841450246405233; validation accuracy : 0.8656716417910447\n",
      "Epoch 166:\t train loss : 0.5769873692829726; train accuracy : 0.9741888015020171; \n",
      " validation loss : 0.645699426512766; validation accuracy : 0.9029850746268657\n",
      "Epoch 167:\t train loss : 0.5632681170207725; train accuracy : 0.9879694309302768; \n",
      " validation loss : 0.6575576507305593; validation accuracy : 0.8955223880597015\n",
      "Epoch 168:\t train loss : 0.5602887357366686; train accuracy : 0.991000171296852; \n",
      " validation loss : 0.6370038563152559; validation accuracy : 0.9104477611940298\n",
      "Epoch 169:\t train loss : 0.5565701615819185; train accuracy : 0.9946844024100253; \n",
      " validation loss : 0.604070317581794; validation accuracy : 0.9477611940298507\n",
      "Epoch 170:\t train loss : 0.5565452248919326; train accuracy : 0.9947120526892931; \n",
      " validation loss : 0.6350084315970336; validation accuracy : 0.917910447761194\n",
      "Epoch 171:\t train loss : 0.5561309420918206; train accuracy : 0.9953790313769973; \n",
      " validation loss : 0.6480275020613638; validation accuracy : 0.9029850746268657\n",
      "Epoch 172:\t train loss : 0.5549319303459157; train accuracy : 0.9964850425477102; \n",
      " validation loss : 0.640201140911546; validation accuracy : 0.9104477611940298\n",
      "Epoch 173:\t train loss : 0.5572655597021281; train accuracy : 0.9941523031333835; \n",
      " validation loss : 0.6270615482731938; validation accuracy : 0.9253731343283582\n",
      "Epoch 174:\t train loss : 0.5569731295277652; train accuracy : 0.9943492270735349; \n",
      " validation loss : 0.6343440818331804; validation accuracy : 0.917910447761194\n",
      "Epoch 175:\t train loss : 0.5552855272932262; train accuracy : 0.9961532391964963; \n",
      " validation loss : 0.626040638453042; validation accuracy : 0.9253731343283582\n",
      "Epoch 176:\t train loss : 0.5543466111185105; train accuracy : 0.9969760036039779; \n",
      " validation loss : 0.6222010154197198; validation accuracy : 0.9253731343283582\n",
      "Epoch 177:\t train loss : 0.5549606167838755; train accuracy : 0.9964506482978892; \n",
      " validation loss : 0.6175934287584396; validation accuracy : 0.9328358208955224\n",
      "Epoch 178:\t train loss : 0.5553644553325128; train accuracy : 0.9960669163734164; \n",
      " validation loss : 0.6385601914484612; validation accuracy : 0.9104477611940298\n",
      "Epoch 179:\t train loss : 0.5602099924842805; train accuracy : 0.9910622158259408; \n",
      " validation loss : 0.6213998349052621; validation accuracy : 0.9253731343283582\n",
      "Epoch 180:\t train loss : 0.5546513988248153; train accuracy : 0.996816845898924; \n",
      " validation loss : 0.6114450510853208; validation accuracy : 0.9402985074626866\n",
      "Epoch 181:\t train loss : 0.5555974784775073; train accuracy : 0.9957283690516494; \n",
      " validation loss : 0.618085073090939; validation accuracy : 0.9328358208955224\n",
      "Epoch 182:\t train loss : 0.575625351872557; train accuracy : 0.9755301772450341; \n",
      " validation loss : 0.6698135864360504; validation accuracy : 0.8805970149253731\n",
      "Epoch 183:\t train loss : 0.5698307696886846; train accuracy : 0.9812295067594817; \n",
      " validation loss : 0.6778099155019818; validation accuracy : 0.8731343283582089\n",
      "Epoch 184:\t train loss : 0.5592495376699076; train accuracy : 0.991940280791958; \n",
      " validation loss : 0.6419876097548662; validation accuracy : 0.9104477611940298\n",
      "Epoch 185:\t train loss : 0.5600709816535211; train accuracy : 0.9911869792811736; \n",
      " validation loss : 0.625901323039401; validation accuracy : 0.9253731343283582\n",
      "Epoch 186:\t train loss : 0.5572088807817092; train accuracy : 0.9941212808688392; \n",
      " validation loss : 0.6627348518890137; validation accuracy : 0.8880597014925373\n",
      "Epoch 187:\t train loss : 0.5565096661989691; train accuracy : 0.9949298829381591; \n",
      " validation loss : 0.6163901996149156; validation accuracy : 0.9328358208955224\n",
      "Epoch 188:\t train loss : 0.5588711293944787; train accuracy : 0.9924278698629491; \n",
      " validation loss : 0.626932026643732; validation accuracy : 0.917910447761194\n",
      "Epoch 189:\t train loss : 0.556489343607929; train accuracy : 0.9949507892468739; \n",
      " validation loss : 0.6530303947606754; validation accuracy : 0.9029850746268657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190:\t train loss : 0.5542596176010096; train accuracy : 0.997200577823397; \n",
      " validation loss : 0.6450987503912686; validation accuracy : 0.9029850746268657\n",
      "Epoch 191:\t train loss : 0.5560548120572767; train accuracy : 0.9953446371271765; \n",
      " validation loss : 0.6113974552732; validation accuracy : 0.9402985074626866\n",
      "Epoch 192:\t train loss : 0.5539953666828532; train accuracy : 0.9974426863662542; \n",
      " validation loss : 0.6412905262693451; validation accuracy : 0.9104477611940298\n",
      "Epoch 193:\t train loss : 0.5534745503003635; train accuracy : 0.9978918348050925; \n",
      " validation loss : 0.6332389054025368; validation accuracy : 0.917910447761194\n",
      "Epoch 194:\t train loss : 0.5605382588517823; train accuracy : 0.9908410135917982; \n",
      " validation loss : 0.6361376401911548; validation accuracy : 0.917910447761194\n",
      "Epoch 195:\t train loss : 0.5574147620859833; train accuracy : 0.9939135665758029; \n",
      " validation loss : 0.6421241387670324; validation accuracy : 0.9104477611940298\n",
      "Epoch 196:\t train loss : 0.5542296862712396; train accuracy : 0.9972214841321116; \n",
      " validation loss : 0.6539139633354092; validation accuracy : 0.8955223880597015\n",
      "Epoch 197:\t train loss : 0.5546542253041036; train accuracy : 0.9968134739136475; \n",
      " validation loss : 0.6322227855468552; validation accuracy : 0.917910447761194\n",
      "Epoch 198:\t train loss : 0.5559578730342879; train accuracy : 0.9954066816562652; \n",
      " validation loss : 0.6410745686261432; validation accuracy : 0.9104477611940298\n",
      "Epoch 199:\t train loss : 0.5609767441878123; train accuracy : 0.9903682612560241; \n",
      " validation loss : 0.6582539826329757; validation accuracy : 0.8955223880597015\n",
      "Epoch 200:\t train loss : 0.5621820052348351; train accuracy : 0.9890437454393899; \n",
      " validation loss : 0.6170736921569885; validation accuracy : 0.9328358208955224\n",
      "Epoch 201:\t train loss : 0.554065584172262; train accuracy : 0.9973354572344595; \n",
      " validation loss : 0.6256659732614314; validation accuracy : 0.9253731343283582\n",
      "Epoch 202:\t train loss : 0.5548344753233309; train accuracy : 0.9964439043273361; \n",
      " validation loss : 0.6193434309808206; validation accuracy : 0.9328358208955224\n",
      "Epoch 203:\t train loss : 0.5573754904024973; train accuracy : 0.9940349580457591; \n",
      " validation loss : 0.6355641212172637; validation accuracy : 0.917910447761194\n",
      "Epoch 204:\t train loss : 0.5541434368260256; train accuracy : 0.9972558783819326; \n",
      " validation loss : 0.6353815377125502; validation accuracy : 0.9104477611940298\n",
      "Epoch 205:\t train loss : 0.5560273634155469; train accuracy : 0.9952684302599261; \n",
      " validation loss : 0.5974233632439333; validation accuracy : 0.9552238805970149\n",
      "Epoch 206:\t train loss : 0.554018838212229; train accuracy : 0.9973664794990039; \n",
      " validation loss : 0.6081380286540117; validation accuracy : 0.9402985074626866\n",
      "Early stopping at epoch 206\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5560870366301807; Train accuracy : 0.9951854794221227; \n",
      " Validation loss : 0.596177664469468; Validation accuracy : 0.9552238805970149\n",
      "------------------------------ Let's train model 31 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8963698558026333; train accuracy : 0.6335626624088162; \n",
      " validation loss : 0.8558835443660441; validation accuracy : 0.6716417910447762\n",
      "Epoch 2:\t train loss : 0.7835621902424134; train accuracy : 0.7591457687611534; \n",
      " validation loss : 0.7880143757892923; validation accuracy : 0.753731343283582\n",
      "Epoch 3:\t train loss : 0.7375604934761633; train accuracy : 0.8088350396042704; \n",
      " validation loss : 0.7725409153047318; validation accuracy : 0.7686567164179104\n",
      "Epoch 4:\t train loss : 0.6940801412976303; train accuracy : 0.8551822109514418; \n",
      " validation loss : 0.7526900674953979; validation accuracy : 0.7910447761194029\n",
      "Epoch 5:\t train loss : 0.6752155519328598; train accuracy : 0.8751330578253655; \n",
      " validation loss : 0.6955798751985731; validation accuracy : 0.8507462686567164\n",
      "Epoch 6:\t train loss : 0.656274349271524; train accuracy : 0.8943325193325193; \n",
      " validation loss : 0.7175152586292556; validation accuracy : 0.8134328358208955\n",
      "Epoch 7:\t train loss : 0.6559694780566147; train accuracy : 0.8932915375223067; \n",
      " validation loss : 0.6949803460054031; validation accuracy : 0.8582089552238806\n",
      "Epoch 8:\t train loss : 0.6402140148864588; train accuracy : 0.9110156225540841; \n",
      " validation loss : 0.6728318370774619; validation accuracy : 0.8656716417910447\n",
      "Epoch 9:\t train loss : 0.6088921447138709; train accuracy : 0.9432664913434144; \n",
      " validation loss : 0.6862331771809156; validation accuracy : 0.8656716417910447\n",
      "Epoch 10:\t train loss : 0.6221766916066409; train accuracy : 0.9286810056040825; \n",
      " validation loss : 0.6827849419971316; validation accuracy : 0.8582089552238806\n",
      "Epoch 11:\t train loss : 0.6187067886322574; train accuracy : 0.9329310290848752; \n",
      " validation loss : 0.6992406613100044; validation accuracy : 0.8582089552238806\n",
      "Epoch 12:\t train loss : 0.6100076230464742; train accuracy : 0.9406562098869791; \n",
      " validation loss : 0.6866500863582242; validation accuracy : 0.8582089552238806\n",
      "Epoch 13:\t train loss : 0.6187747330119988; train accuracy : 0.9317491625183932; \n",
      " validation loss : 0.7641248458198411; validation accuracy : 0.7686567164179104\n",
      "Epoch 14:\t train loss : 0.6183065510373695; train accuracy : 0.9321992110453649; \n",
      " validation loss : 0.6609428605608018; validation accuracy : 0.8805970149253731\n",
      "Epoch 15:\t train loss : 0.5902408571387485; train accuracy : 0.9614836730221346; \n",
      " validation loss : 0.6582211557169901; validation accuracy : 0.8880597014925373\n",
      "Epoch 16:\t train loss : 0.5831556278402668; train accuracy : 0.967944804483266; \n",
      " validation loss : 0.6596541598996255; validation accuracy : 0.8880597014925373\n",
      "Epoch 17:\t train loss : 0.5954420146124243; train accuracy : 0.9555391190006575; \n",
      " validation loss : 0.6614601147315041; validation accuracy : 0.8880597014925373\n",
      "Epoch 18:\t train loss : 0.580208397732624; train accuracy : 0.9712321154628847; \n",
      " validation loss : 0.6217607049110146; validation accuracy : 0.9328358208955224\n",
      "Epoch 19:\t train loss : 0.601494904567181; train accuracy : 0.9490388528850068; \n",
      " validation loss : 0.677770858888618; validation accuracy : 0.8656716417910447\n",
      "Epoch 20:\t train loss : 0.6145539142493688; train accuracy : 0.9354826085595316; \n",
      " validation loss : 0.6420764600932382; validation accuracy : 0.8955223880597015\n",
      "Epoch 21:\t train loss : 0.5827357997118835; train accuracy : 0.9684652953883723; \n",
      " validation loss : 0.6520339964110006; validation accuracy : 0.9029850746268657\n",
      "Epoch 22:\t train loss : 0.5762466826967202; train accuracy : 0.9756465044926583; \n",
      " validation loss : 0.6234966725583089; validation accuracy : 0.9253731343283582\n",
      "Epoch 23:\t train loss : 0.5720362818835749; train accuracy : 0.9795599699445854; \n",
      " validation loss : 0.6225182652696333; validation accuracy : 0.9253731343283582\n",
      "Epoch 24:\t train loss : 0.585402771203204; train accuracy : 0.9657532638301869; \n",
      " validation loss : 0.6457172299068706; validation accuracy : 0.9029850746268657\n",
      "Epoch 25:\t train loss : 0.5779915899709487; train accuracy : 0.9734275695814157; \n",
      " validation loss : 0.6285171731608548; validation accuracy : 0.917910447761194\n",
      "Epoch 26:\t train loss : 0.567022146016831; train accuracy : 0.9844948498794652; \n",
      " validation loss : 0.6313027330162331; validation accuracy : 0.9104477611940298\n",
      "Epoch 27:\t train loss : 0.5679043753852719; train accuracy : 0.9836143201527817; \n",
      " validation loss : 0.6205885614882535; validation accuracy : 0.9328358208955224\n",
      "Epoch 28:\t train loss : 0.5714238298648529; train accuracy : 0.9799200087661626; \n",
      " validation loss : 0.6143075589047906; validation accuracy : 0.9328358208955224\n",
      "Epoch 29:\t train loss : 0.5697483734900336; train accuracy : 0.9817554240631163; \n",
      " validation loss : 0.6236289544065428; validation accuracy : 0.9253731343283582\n",
      "Epoch 30:\t train loss : 0.5636361067382809; train accuracy : 0.9880013149243918; \n",
      " validation loss : 0.6278457572326629; validation accuracy : 0.917910447761194\n",
      "Epoch 31:\t train loss : 0.5637673043170611; train accuracy : 0.987617795310103; \n",
      " validation loss : 0.6212936768734182; validation accuracy : 0.9328358208955224\n",
      "Epoch 32:\t train loss : 0.565219254023906; train accuracy : 0.9862206881437651; \n",
      " validation loss : 0.6261990769522804; validation accuracy : 0.9253731343283582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:\t train loss : 0.5681250544812845; train accuracy : 0.9832034062803293; \n",
      " validation loss : 0.6074433997643814; validation accuracy : 0.9402985074626866\n",
      "Epoch 34:\t train loss : 0.5682402100067234; train accuracy : 0.982796405873329; \n",
      " validation loss : 0.6086914239831441; validation accuracy : 0.9477611940298507\n",
      "Epoch 35:\t train loss : 0.5654504326990648; train accuracy : 0.9860289283366207; \n",
      " validation loss : 0.6209682588684737; validation accuracy : 0.9328358208955224\n",
      "Epoch 36:\t train loss : 0.5628633096742593; train accuracy : 0.9885178923640462; \n",
      " validation loss : 0.6270554047808297; validation accuracy : 0.9253731343283582\n",
      "Epoch 37:\t train loss : 0.5596460082604773; train accuracy : 0.9918091168091168; \n",
      " validation loss : 0.6294499500068121; validation accuracy : 0.917910447761194\n",
      "Epoch 38:\t train loss : 0.5651189359031378; train accuracy : 0.9864124479509094; \n",
      " validation loss : 0.6442809911921357; validation accuracy : 0.9029850746268657\n",
      "Epoch 39:\t train loss : 0.5632718499824452; train accuracy : 0.9880287091825554; \n",
      " validation loss : 0.6273275846053722; validation accuracy : 0.9253731343283582\n",
      "Epoch 40:\t train loss : 0.5633320709508781; train accuracy : 0.9881343727497574; \n",
      " validation loss : 0.6181072748580784; validation accuracy : 0.9328358208955224\n",
      "Epoch 41:\t train loss : 0.5732239013422584; train accuracy : 0.9780845934692088; \n",
      " validation loss : 0.6271078553597167; validation accuracy : 0.9253731343283582\n",
      "Epoch 42:\t train loss : 0.5657358289780243; train accuracy : 0.9858880435803513; \n",
      " validation loss : 0.64135104083772; validation accuracy : 0.9104477611940298\n",
      "Epoch 43:\t train loss : 0.564696182323902; train accuracy : 0.9863028709182555; \n",
      " validation loss : 0.6396247033152329; validation accuracy : 0.9104477611940298\n",
      "Epoch 44:\t train loss : 0.5819203965375354; train accuracy : 0.9688488150026612; \n",
      " validation loss : 0.7515455736918233; validation accuracy : 0.7835820895522388\n",
      "Epoch 45:\t train loss : 0.5975858212963956; train accuracy : 0.9534023668639053; \n",
      " validation loss : 0.6620882280197182; validation accuracy : 0.8805970149253731\n",
      "Epoch 46:\t train loss : 0.6259426043117245; train accuracy : 0.9237578660655583; \n",
      " validation loss : 0.6437443990875252; validation accuracy : 0.9104477611940298\n",
      "Epoch 47:\t train loss : 0.5818255110076987; train accuracy : 0.968962305500767; \n",
      " validation loss : 0.6273460687948876; validation accuracy : 0.917910447761194\n",
      "Epoch 48:\t train loss : 0.5686318857537913; train accuracy : 0.9824128862590401; \n",
      " validation loss : 0.5908604149159432; validation accuracy : 0.9552238805970149\n",
      "Epoch 49:\t train loss : 0.5720199648029654; train accuracy : 0.9791803637957485; \n",
      " validation loss : 0.6572765022399361; validation accuracy : 0.8805970149253731\n",
      "Epoch 50:\t train loss : 0.5756140292577473; train accuracy : 0.9752903791365329; \n",
      " validation loss : 0.6351683993299545; validation accuracy : 0.9104477611940298\n",
      "Epoch 51:\t train loss : 0.5650576471410189; train accuracy : 0.9860250148711687; \n",
      " validation loss : 0.6246850218355292; validation accuracy : 0.9253731343283582\n",
      "Epoch 52:\t train loss : 0.5909415886952066; train accuracy : 0.9601139601139601; \n",
      " validation loss : 0.6722700939375302; validation accuracy : 0.8805970149253731\n",
      "Epoch 53:\t train loss : 0.646782866866596; train accuracy : 0.9028286528286529; \n",
      " validation loss : 0.6828088214557575; validation accuracy : 0.8582089552238806\n",
      "Epoch 54:\t train loss : 0.5947277360325601; train accuracy : 0.9558091481168404; \n",
      " validation loss : 0.6357438398627666; validation accuracy : 0.917910447761194\n",
      "Epoch 55:\t train loss : 0.5754698956682238; train accuracy : 0.975399956169187; \n",
      " validation loss : 0.6509597354274625; validation accuracy : 0.8955223880597015\n",
      "Epoch 56:\t train loss : 0.5679724500343355; train accuracy : 0.9832855890548198; \n",
      " validation loss : 0.6502335031368323; validation accuracy : 0.9029850746268657\n",
      "Epoch 57:\t train loss : 0.56347307732249; train accuracy : 0.9878056416517955; \n",
      " validation loss : 0.641331317444268; validation accuracy : 0.9029850746268657\n",
      "Epoch 58:\t train loss : 0.5732739990382211; train accuracy : 0.9779671895056511; \n",
      " validation loss : 0.6230592041729517; validation accuracy : 0.9328358208955224\n",
      "Epoch 59:\t train loss : 0.5826116332874937; train accuracy : 0.9681913528067374; \n",
      " validation loss : 0.6329287898330161; validation accuracy : 0.917910447761194\n",
      "Epoch 60:\t train loss : 0.5660869152814456; train accuracy : 0.9851210043517736; \n",
      " validation loss : 0.6394856709045552; validation accuracy : 0.9104477611940298\n",
      "Epoch 61:\t train loss : 0.5655894802604737; train accuracy : 0.9854771297078989; \n",
      " validation loss : 0.589930222113735; validation accuracy : 0.9626865671641791\n",
      "Epoch 62:\t train loss : 0.5609627720142296; train accuracy : 0.9904394039009423; \n",
      " validation loss : 0.634381094575802; validation accuracy : 0.917910447761194\n",
      "Epoch 63:\t train loss : 0.5638534139798939; train accuracy : 0.9875864875864876; \n",
      " validation loss : 0.6189829756709763; validation accuracy : 0.9328358208955224\n",
      "Epoch 64:\t train loss : 0.5603791730231805; train accuracy : 0.9909872890642122; \n",
      " validation loss : 0.6108257408278939; validation accuracy : 0.9402985074626866\n",
      "Epoch 65:\t train loss : 0.5592187956794993; train accuracy : 0.9921926364234056; \n",
      " validation loss : 0.597221023538666; validation accuracy : 0.9552238805970149\n",
      "Epoch 66:\t train loss : 0.559956788606942; train accuracy : 0.991316020162174; \n",
      " validation loss : 0.5969151914101533; validation accuracy : 0.9552238805970149\n",
      "Epoch 67:\t train loss : 0.5594434440368496; train accuracy : 0.9919969631508093; \n",
      " validation loss : 0.6023011880397402; validation accuracy : 0.9477611940298507\n",
      "Epoch 68:\t train loss : 0.5589413448265332; train accuracy : 0.9925174540559156; \n",
      " validation loss : 0.6282880588476222; validation accuracy : 0.9253731343283582\n",
      "Epoch 69:\t train loss : 0.5584066376569291; train accuracy : 0.9930105507028584; \n",
      " validation loss : 0.6267968610750893; validation accuracy : 0.9253731343283582\n",
      "Epoch 70:\t train loss : 0.5620119811492574; train accuracy : 0.989010989010989; \n",
      " validation loss : 0.6264141337218198; validation accuracy : 0.9253731343283582\n",
      "Epoch 71:\t train loss : 0.6058967935166716; train accuracy : 0.9443857424626655; \n",
      " validation loss : 0.6488517748806802; validation accuracy : 0.8955223880597015\n",
      "Epoch 72:\t train loss : 0.574733984845254; train accuracy : 0.9764370245139475; \n",
      " validation loss : 0.6318894454390898; validation accuracy : 0.9253731343283582\n",
      "Epoch 73:\t train loss : 0.565811066922406; train accuracy : 0.9852853699007545; \n",
      " validation loss : 0.60632663584194; validation accuracy : 0.9477611940298507\n",
      "Epoch 74:\t train loss : 0.5631816805736903; train accuracy : 0.9881343727497574; \n",
      " validation loss : 0.6313044363889733; validation accuracy : 0.917910447761194\n",
      "Epoch 75:\t train loss : 0.5600263295551827; train accuracy : 0.9913081932312702; \n",
      " validation loss : 0.6460362434968971; validation accuracy : 0.9029850746268657\n",
      "Epoch 76:\t train loss : 0.5600268023648344; train accuracy : 0.991316020162174; \n",
      " validation loss : 0.6376009552911599; validation accuracy : 0.9104477611940298\n",
      "Epoch 77:\t train loss : 0.5586033038234549; train accuracy : 0.9927131273285119; \n",
      " validation loss : 0.6524525909074589; validation accuracy : 0.8955223880597015\n",
      "Epoch 78:\t train loss : 0.5562550612416283; train accuracy : 0.9952333990795529; \n",
      " validation loss : 0.6399775733036192; validation accuracy : 0.9104477611940298\n",
      "Epoch 79:\t train loss : 0.5563884768165747; train accuracy : 0.9949868507560815; \n",
      " validation loss : 0.6054563750648757; validation accuracy : 0.9477611940298507\n",
      "Epoch 80:\t train loss : 0.5561239667499059; train accuracy : 0.9953155818540433; \n",
      " validation loss : 0.629800851010684; validation accuracy : 0.917910447761194\n",
      "Epoch 81:\t train loss : 0.5569205518920788; train accuracy : 0.9944663598509752; \n",
      " validation loss : 0.610933979940409; validation accuracy : 0.9402985074626866\n",
      "Epoch 82:\t train loss : 0.5563457723704746; train accuracy : 0.994849879465264; \n",
      " validation loss : 0.6255045568363402; validation accuracy : 0.9253731343283582\n",
      "Epoch 83:\t train loss : 0.5579224091314403; train accuracy : 0.9934801665570896; \n",
      " validation loss : 0.6138676479750146; validation accuracy : 0.9402985074626866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84:\t train loss : 0.5584048544074082; train accuracy : 0.9927366081212234; \n",
      " validation loss : 0.6118706296938055; validation accuracy : 0.9402985074626866\n",
      "Epoch 85:\t train loss : 0.5905714735718572; train accuracy : 0.9602744121974891; \n",
      " validation loss : 0.6336855814019396; validation accuracy : 0.9104477611940298\n",
      "Epoch 86:\t train loss : 0.5687667836095093; train accuracy : 0.9821663379355687; \n",
      " validation loss : 0.6586379022903474; validation accuracy : 0.8880597014925373\n",
      "Epoch 87:\t train loss : 0.5602227745386766; train accuracy : 0.9911790488713565; \n",
      " validation loss : 0.6415666663406034; validation accuracy : 0.9029850746268657\n",
      "Epoch 88:\t train loss : 0.5606727084992437; train accuracy : 0.9907133464825773; \n",
      " validation loss : 0.6096953474708356; validation accuracy : 0.9328358208955224\n",
      "Epoch 89:\t train loss : 0.5656831479589728; train accuracy : 0.9855006105006106; \n",
      " validation loss : 0.6158398234582779; validation accuracy : 0.9253731343283582\n",
      "Epoch 90:\t train loss : 0.5665662597542217; train accuracy : 0.9847335712720328; \n",
      " validation loss : 0.638685379202064; validation accuracy : 0.9104477611940298\n",
      "Epoch 91:\t train loss : 0.5666010361739751; train accuracy : 0.9845731191885038; \n",
      " validation loss : 0.642662474837931; validation accuracy : 0.9104477611940298\n",
      "Epoch 92:\t train loss : 0.5611105258784108; train accuracy : 0.9903572211264519; \n",
      " validation loss : 0.6365493265985076; validation accuracy : 0.9104477611940298\n",
      "Epoch 93:\t train loss : 0.5991784476340203; train accuracy : 0.9513360571052879; \n",
      " validation loss : 0.6433374530274201; validation accuracy : 0.9104477611940298\n",
      "Epoch 94:\t train loss : 0.5710752565676106; train accuracy : 0.9798887010425472; \n",
      " validation loss : 0.629270921653406; validation accuracy : 0.917910447761194\n",
      "Epoch 95:\t train loss : 0.5613513143140986; train accuracy : 0.9900793650793651; \n",
      " validation loss : 0.6306565720007581; validation accuracy : 0.9253731343283582\n",
      "Epoch 96:\t train loss : 0.5586374125871385; train accuracy : 0.9928774928774928; \n",
      " validation loss : 0.6043129179596789; validation accuracy : 0.9477611940298507\n",
      "Epoch 97:\t train loss : 0.5573763396152422; train accuracy : 0.993891080429542; \n",
      " validation loss : 0.6276633043598306; validation accuracy : 0.9253731343283582\n",
      "Epoch 98:\t train loss : 0.5567967875238659; train accuracy : 0.9946542061926678; \n",
      " validation loss : 0.6225523030500436; validation accuracy : 0.9253731343283582\n",
      "Epoch 99:\t train loss : 0.5555680663125485; train accuracy : 0.9958634670173132; \n",
      " validation loss : 0.6181842109742621; validation accuracy : 0.9328358208955224\n",
      "Epoch 100:\t train loss : 0.5563344876309293; train accuracy : 0.9950964277887354; \n",
      " validation loss : 0.6526957510994472; validation accuracy : 0.8955223880597015\n",
      "Epoch 101:\t train loss : 0.5584591988759855; train accuracy : 0.9928227043611659; \n",
      " validation loss : 0.6396474202838148; validation accuracy : 0.917910447761194\n",
      "Epoch 102:\t train loss : 0.557117662243448; train accuracy : 0.9942198115275038; \n",
      " validation loss : 0.635782626028892; validation accuracy : 0.9104477611940298\n",
      "Epoch 103:\t train loss : 0.5592296902537611; train accuracy : 0.9921926364234056; \n",
      " validation loss : 0.6250896658567572; validation accuracy : 0.9253731343283582\n",
      "Epoch 104:\t train loss : 0.5578521923889516; train accuracy : 0.9936132243824551; \n",
      " validation loss : 0.599503498281321; validation accuracy : 0.9477611940298507\n",
      "Epoch 105:\t train loss : 0.5569037604055198; train accuracy : 0.9945485426254657; \n",
      " validation loss : 0.6426866991611347; validation accuracy : 0.9104477611940298\n",
      "Epoch 106:\t train loss : 0.557570455239004; train accuracy : 0.993781503396888; \n",
      " validation loss : 0.6347078587392165; validation accuracy : 0.9104477611940298\n",
      "Epoch 107:\t train loss : 0.5582791712141729; train accuracy : 0.9930692526846373; \n",
      " validation loss : 0.6528172397314439; validation accuracy : 0.8955223880597015\n",
      "Epoch 108:\t train loss : 0.5589755147206806; train accuracy : 0.9922748191978961; \n",
      " validation loss : 0.6215938900369684; validation accuracy : 0.9253731343283582\n",
      "Epoch 109:\t train loss : 0.5590302907821352; train accuracy : 0.9923022134560596; \n",
      " validation loss : 0.6354492276713936; validation accuracy : 0.9104477611940298\n",
      "Epoch 110:\t train loss : 0.5607042009677191; train accuracy : 0.9907133464825773; \n",
      " validation loss : 0.6001916975457178; validation accuracy : 0.9477611940298507\n",
      "Epoch 111:\t train loss : 0.5600250264380848; train accuracy : 0.9914803857111549; \n",
      " validation loss : 0.6337104844464366; validation accuracy : 0.917910447761194\n",
      "Early stopping at epoch 111\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5655894802604737; Train accuracy : 0.9854771297078989; \n",
      " Validation loss : 0.589930222113735; Validation accuracy : 0.9626865671641791\n",
      "------------------------------ Let's train model 32 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9154962376339232; train accuracy : 0.6136149975114749; \n",
      " validation loss : 0.8537473063254909; validation accuracy : 0.6691729323308271\n",
      "Epoch 2:\t train loss : 0.8167475214572374; train accuracy : 0.7224464967096168; \n",
      " validation loss : 0.756152733961757; validation accuracy : 0.8045112781954887\n",
      "Epoch 3:\t train loss : 0.7674766868426888; train accuracy : 0.7774567273129459; \n",
      " validation loss : 0.7123820112808684; validation accuracy : 0.849624060150376\n",
      "Epoch 4:\t train loss : 0.7299899125575775; train accuracy : 0.8163883205220372; \n",
      " validation loss : 0.7195067144798105; validation accuracy : 0.8345864661654135\n",
      "Epoch 5:\t train loss : 0.706736944410869; train accuracy : 0.8404164132057734; \n",
      " validation loss : 0.6707814811068228; validation accuracy : 0.8796992481203008\n",
      "Epoch 6:\t train loss : 0.6740353434452897; train accuracy : 0.8756566941326107; \n",
      " validation loss : 0.6824794124650737; validation accuracy : 0.8721804511278195\n",
      "Epoch 7:\t train loss : 0.6484557707461572; train accuracy : 0.9012470275949787; \n",
      " validation loss : 0.6674858962124393; validation accuracy : 0.8947368421052632\n",
      "Epoch 8:\t train loss : 0.6338326478117474; train accuracy : 0.9170629873361721; \n",
      " validation loss : 0.6619948674647452; validation accuracy : 0.8796992481203008\n",
      "Epoch 9:\t train loss : 0.6269732425220099; train accuracy : 0.9234916772659404; \n",
      " validation loss : 0.6862138584593825; validation accuracy : 0.8646616541353384\n",
      "Epoch 10:\t train loss : 0.6228931590712569; train accuracy : 0.9277636454128186; \n",
      " validation loss : 0.6591933698267577; validation accuracy : 0.8872180451127819\n",
      "Epoch 11:\t train loss : 0.607317660876655; train accuracy : 0.9440911353204667; \n",
      " validation loss : 0.6551819150624228; validation accuracy : 0.8872180451127819\n",
      "Epoch 12:\t train loss : 0.5970745917253777; train accuracy : 0.9542387878117569; \n",
      " validation loss : 0.64756981053806; validation accuracy : 0.8947368421052632\n",
      "Epoch 13:\t train loss : 0.5946305425067675; train accuracy : 0.9571282419952442; \n",
      " validation loss : 0.6465555266997914; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.5964984556822577; train accuracy : 0.9542940883702925; \n",
      " validation loss : 0.6455782364626942; validation accuracy : 0.9022556390977443\n",
      "Epoch 15:\t train loss : 0.5836390719523525; train accuracy : 0.9670823425316596; \n",
      " validation loss : 0.6360336946047653; validation accuracy : 0.9097744360902256\n",
      "Epoch 16:\t train loss : 0.5791052830377845; train accuracy : 0.9722805950340099; \n",
      " validation loss : 0.6003689641821914; validation accuracy : 0.9548872180451128\n",
      "Epoch 17:\t train loss : 0.5798819186128266; train accuracy : 0.9720179173809655; \n",
      " validation loss : 0.6286326376294489; validation accuracy : 0.9172932330827067\n",
      "Epoch 18:\t train loss : 0.5739375650516312; train accuracy : 0.9776862246308687; \n",
      " validation loss : 0.6512073433921242; validation accuracy : 0.8872180451127819\n",
      "Epoch 19:\t train loss : 0.5761899359706035; train accuracy : 0.9750041475418901; \n",
      " validation loss : 0.5932232179778062; validation accuracy : 0.9624060150375939\n",
      "Epoch 20:\t train loss : 0.5731684558236437; train accuracy : 0.9780318531217165; \n",
      " validation loss : 0.658163187925535; validation accuracy : 0.8796992481203008\n",
      "Epoch 21:\t train loss : 0.573966071710791; train accuracy : 0.9771332190455123; \n",
      " validation loss : 0.6315971592428684; validation accuracy : 0.9172932330827067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:\t train loss : 0.5755174478982262; train accuracy : 0.9759719073162639; \n",
      " validation loss : 0.6157864262414663; validation accuracy : 0.9398496240601504\n",
      "Epoch 23:\t train loss : 0.5710032928850639; train accuracy : 0.9802300503235083; \n",
      " validation loss : 0.610822017144006; validation accuracy : 0.9473684210526315\n",
      "Epoch 24:\t train loss : 0.5630087959761341; train accuracy : 0.9885113089642206; \n",
      " validation loss : 0.6032361220443034; validation accuracy : 0.9473684210526315\n",
      "Epoch 25:\t train loss : 0.5654794505028593; train accuracy : 0.9861886855057236; \n",
      " validation loss : 0.6016923525630712; validation accuracy : 0.9548872180451128\n",
      "Epoch 26:\t train loss : 0.563814200324982; train accuracy : 0.9878062268428911; \n",
      " validation loss : 0.6095494001003814; validation accuracy : 0.9398496240601504\n",
      "Epoch 27:\t train loss : 0.564095633873464; train accuracy : 0.9869767184648565; \n",
      " validation loss : 0.6248801918561245; validation accuracy : 0.9172932330827067\n",
      "Epoch 28:\t train loss : 0.5782034228694442; train accuracy : 0.9726262235248576; \n",
      " validation loss : 0.6590572556116457; validation accuracy : 0.8872180451127819\n",
      "Epoch 29:\t train loss : 0.5694475621636579; train accuracy : 0.9816816899850689; \n",
      " validation loss : 0.643276097259515; validation accuracy : 0.9097744360902256\n",
      "Epoch 30:\t train loss : 0.5622053336387165; train accuracy : 0.9894652435989604; \n",
      " validation loss : 0.6157765480309058; validation accuracy : 0.9323308270676691\n",
      "Epoch 31:\t train loss : 0.5602670475186559; train accuracy : 0.9912210363324669; \n",
      " validation loss : 0.6277218352009662; validation accuracy : 0.924812030075188\n",
      "Epoch 32:\t train loss : 0.5618553762333678; train accuracy : 0.989520544157496; \n",
      " validation loss : 0.6038605841994227; validation accuracy : 0.9473684210526315\n",
      "Epoch 33:\t train loss : 0.559315689782376; train accuracy : 0.9919537687330642; \n",
      " validation loss : 0.6244512884252773; validation accuracy : 0.924812030075188\n",
      "Epoch 34:\t train loss : 0.5581133165059938; train accuracy : 0.9931980313001161; \n",
      " validation loss : 0.6076372869450559; validation accuracy : 0.9398496240601504\n",
      "Epoch 35:\t train loss : 0.5624388228936718; train accuracy : 0.9888845877343361; \n",
      " validation loss : 0.6420437403854401; validation accuracy : 0.9022556390977443\n",
      "Epoch 36:\t train loss : 0.5649616353480753; train accuracy : 0.9864651882984018; \n",
      " validation loss : 0.6086246188587159; validation accuracy : 0.9398496240601504\n",
      "Epoch 37:\t train loss : 0.5606399395319918; train accuracy : 0.9905297793507715; \n",
      " validation loss : 0.6374241899356811; validation accuracy : 0.9022556390977443\n",
      "Epoch 38:\t train loss : 0.5644185878148591; train accuracy : 0.9869767184648565; \n",
      " validation loss : 0.6162664866978261; validation accuracy : 0.9398496240601504\n",
      "Epoch 39:\t train loss : 0.5603720653632333; train accuracy : 0.9911380854946635; \n",
      " validation loss : 0.6356905586206524; validation accuracy : 0.9097744360902256\n",
      "Epoch 40:\t train loss : 0.5616325213612533; train accuracy : 0.9895481944367638; \n",
      " validation loss : 0.6439044900284003; validation accuracy : 0.9022556390977443\n",
      "Epoch 41:\t train loss : 0.5621935270365143; train accuracy : 0.9894514184593265; \n",
      " validation loss : 0.6113348295412282; validation accuracy : 0.9398496240601504\n",
      "Epoch 42:\t train loss : 0.5648386162185624; train accuracy : 0.9862439860642592; \n",
      " validation loss : 0.6368122820973054; validation accuracy : 0.9172932330827067\n",
      "Epoch 43:\t train loss : 0.5799746464979517; train accuracy : 0.9706630536968424; \n",
      " validation loss : 0.6407812860838238; validation accuracy : 0.9097744360902256\n",
      "Epoch 44:\t train loss : 0.5600752117304243; train accuracy : 0.9911519106342974; \n",
      " validation loss : 0.6082984083825284; validation accuracy : 0.9398496240601504\n",
      "Epoch 45:\t train loss : 0.5590866342661559; train accuracy : 0.9923685229220816; \n",
      " validation loss : 0.614984195907736; validation accuracy : 0.9398496240601504\n",
      "Epoch 46:\t train loss : 0.5751621278461488; train accuracy : 0.9754742022894431; \n",
      " validation loss : 0.6397301291139551; validation accuracy : 0.9097744360902256\n",
      "Epoch 47:\t train loss : 0.5615312675978335; train accuracy : 0.9897140961123707; \n",
      " validation loss : 0.6370287883481563; validation accuracy : 0.9097744360902256\n",
      "Epoch 48:\t train loss : 0.5609011904550248; train accuracy : 0.9903224022562628; \n",
      " validation loss : 0.6320092287057871; validation accuracy : 0.9172932330827067\n",
      "Epoch 49:\t train loss : 0.5625615924719022; train accuracy : 0.9888845877343361; \n",
      " validation loss : 0.6099961121853756; validation accuracy : 0.9398496240601504\n",
      "Epoch 50:\t train loss : 0.5556250694011229; train accuracy : 0.9957971575512913; \n",
      " validation loss : 0.6152732624169672; validation accuracy : 0.9323308270676691\n",
      "Epoch 51:\t train loss : 0.5588780114021393; train accuracy : 0.9925759000165901; \n",
      " validation loss : 0.6333149341710662; validation accuracy : 0.9172932330827067\n",
      "Epoch 52:\t train loss : 0.5566151189736228; train accuracy : 0.9946911463805784; \n",
      " validation loss : 0.632576209361028; validation accuracy : 0.9172932330827067\n",
      "Epoch 53:\t train loss : 0.5581295610704124; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.620199121416509; validation accuracy : 0.9323308270676691\n",
      "Epoch 54:\t train loss : 0.5569446759724249; train accuracy : 0.9945252447049715; \n",
      " validation loss : 0.6280029933358925; validation accuracy : 0.924812030075188\n",
      "Epoch 55:\t train loss : 0.5658006766878855; train accuracy : 0.9856218547807333; \n",
      " validation loss : 0.6290613651646014; validation accuracy : 0.9172932330827067\n",
      "Epoch 56:\t train loss : 0.5809560477355225; train accuracy : 0.9699164961566111; \n",
      " validation loss : 0.6132827421810063; validation accuracy : 0.9398496240601504\n",
      "Epoch 57:\t train loss : 0.5654888632693496; train accuracy : 0.9856218547807333; \n",
      " validation loss : 0.6284269697860523; validation accuracy : 0.9172932330827067\n",
      "Epoch 58:\t train loss : 0.5613132137292751; train accuracy : 0.9898385223690759; \n",
      " validation loss : 0.636767564281477; validation accuracy : 0.9172932330827067\n",
      "Epoch 59:\t train loss : 0.5824436109185205; train accuracy : 0.9681468782834707; \n",
      " validation loss : 0.6246857740910698; validation accuracy : 0.924812030075188\n",
      "Epoch 60:\t train loss : 0.5629388524840202; train accuracy : 0.9882348061715424; \n",
      " validation loss : 0.6251726118788821; validation accuracy : 0.924812030075188\n",
      "Epoch 61:\t train loss : 0.5566855455282588; train accuracy : 0.9946634961013106; \n",
      " validation loss : 0.6385787652881186; validation accuracy : 0.9097744360902256\n",
      "Epoch 62:\t train loss : 0.5574862058011409; train accuracy : 0.9939169385610794; \n",
      " validation loss : 0.6115942022453782; validation accuracy : 0.9398496240601504\n",
      "Epoch 63:\t train loss : 0.5635342800849444; train accuracy : 0.987667975446552; \n",
      " validation loss : 0.6274914769233719; validation accuracy : 0.9172932330827067\n",
      "Epoch 64:\t train loss : 0.5638151745622378; train accuracy : 0.9877371011447216; \n",
      " validation loss : 0.6298813279787501; validation accuracy : 0.9172932330827067\n",
      "Epoch 65:\t train loss : 0.5548139299823558; train accuracy : 0.9966266659293259; \n",
      " validation loss : 0.6022906578601037; validation accuracy : 0.9473684210526315\n",
      "Epoch 66:\t train loss : 0.5547705792328815; train accuracy : 0.9967510921860311; \n",
      " validation loss : 0.6050916318656753; validation accuracy : 0.9473684210526315\n",
      "Epoch 67:\t train loss : 0.5544025303502659; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.6113836873500926; validation accuracy : 0.9398496240601504\n",
      "Epoch 68:\t train loss : 0.5538753046460254; train accuracy : 0.997539125145164; \n",
      " validation loss : 0.6115353473150705; validation accuracy : 0.9398496240601504\n",
      "Epoch 69:\t train loss : 0.557171370721316; train accuracy : 0.994290217331195; \n",
      " validation loss : 0.619103141642188; validation accuracy : 0.9323308270676691\n",
      "Early stopping at epoch 69\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5761899359706035; Train accuracy : 0.9750041475418901; \n",
      " Validation loss : 0.5932232179778062; Validation accuracy : 0.9624060150375939\n",
      "------------------------------ Let's train model 33 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8813029310499242; train accuracy : 0.641486479013438; \n",
      " validation loss : 0.7716213238089106; validation accuracy : 0.7744360902255639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\t train loss : 0.769955977320416; train accuracy : 0.774511972570923; \n",
      " validation loss : 0.7622258205050891; validation accuracy : 0.7744360902255639\n",
      "Epoch 3:\t train loss : 0.703063093078213; train accuracy : 0.8471769064867555; \n",
      " validation loss : 0.7219675207616261; validation accuracy : 0.8270676691729323\n",
      "Epoch 4:\t train loss : 0.6665667456969036; train accuracy : 0.8829978432782171; \n",
      " validation loss : 0.6908137166449627; validation accuracy : 0.8571428571428571\n",
      "Epoch 5:\t train loss : 0.6485692798743945; train accuracy : 0.9014682298291212; \n",
      " validation loss : 0.7149732332211916; validation accuracy : 0.8345864661654135\n",
      "Epoch 6:\t train loss : 0.6343787334713581; train accuracy : 0.9164961566111818; \n",
      " validation loss : 0.7103142975580097; validation accuracy : 0.8345864661654135\n",
      "Epoch 7:\t train loss : 0.6205494250255995; train accuracy : 0.931565558812144; \n",
      " validation loss : 0.7122096256404388; validation accuracy : 0.8270676691729323\n",
      "Epoch 8:\t train loss : 0.609116869767413; train accuracy : 0.9418376375601394; \n",
      " validation loss : 0.6524550936595428; validation accuracy : 0.9022556390977443\n",
      "Epoch 9:\t train loss : 0.6143229939450472; train accuracy : 0.9370541392468064; \n",
      " validation loss : 0.679369454626083; validation accuracy : 0.8646616541353384\n",
      "Epoch 10:\t train loss : 0.6058008715393588; train accuracy : 0.9455151247027594; \n",
      " validation loss : 0.6581085463872322; validation accuracy : 0.8872180451127819\n",
      "Epoch 11:\t train loss : 0.6003517009412938; train accuracy : 0.9503815738538959; \n",
      " validation loss : 0.6735691919661193; validation accuracy : 0.8796992481203008\n",
      "Epoch 12:\t train loss : 0.5963109053152104; train accuracy : 0.9550821213294254; \n",
      " validation loss : 0.6257241547924585; validation accuracy : 0.9323308270676691\n",
      "Epoch 13:\t train loss : 0.5869523503590577; train accuracy : 0.9644140905823149; \n",
      " validation loss : 0.665469347362244; validation accuracy : 0.8796992481203008\n",
      "Epoch 14:\t train loss : 0.5829163562188633; train accuracy : 0.9684233810761489; \n",
      " validation loss : 0.6915089469287847; validation accuracy : 0.8421052631578947\n",
      "Epoch 15:\t train loss : 0.5756656108322671; train accuracy : 0.9755433279876127; \n",
      " validation loss : 0.6440766460056371; validation accuracy : 0.9022556390977443\n",
      "Epoch 16:\t train loss : 0.5796162275103597; train accuracy : 0.9720593927998673; \n",
      " validation loss : 0.6388079473701823; validation accuracy : 0.9172932330827067\n",
      "Epoch 17:\t train loss : 0.5772782507984616; train accuracy : 0.9742714151412929; \n",
      " validation loss : 0.6682587211548763; validation accuracy : 0.8796992481203008\n",
      "Epoch 18:\t train loss : 0.576939583210187; train accuracy : 0.9744511419565337; \n",
      " validation loss : 0.6669144537968439; validation accuracy : 0.8796992481203008\n",
      "Epoch 19:\t train loss : 0.5722842788003893; train accuracy : 0.9791655145716972; \n",
      " validation loss : 0.6893780110699278; validation accuracy : 0.8571428571428571\n",
      "Epoch 20:\t train loss : 0.5795138639651846; train accuracy : 0.9714372615163414; \n",
      " validation loss : 0.6591002101887369; validation accuracy : 0.8872180451127819\n",
      "Epoch 21:\t train loss : 0.5688774288062883; train accuracy : 0.9826079743405408; \n",
      " validation loss : 0.6639182529240235; validation accuracy : 0.8872180451127819\n",
      "Epoch 22:\t train loss : 0.5782357363812821; train accuracy : 0.972405021290715; \n",
      " validation loss : 0.6404942313680093; validation accuracy : 0.9097744360902256\n",
      "Epoch 23:\t train loss : 0.568719461947605; train accuracy : 0.98274622573688; \n",
      " validation loss : 0.6387528483439201; validation accuracy : 0.9172932330827067\n",
      "Epoch 24:\t train loss : 0.5653901365923641; train accuracy : 0.9860642592490184; \n",
      " validation loss : 0.6300273620535525; validation accuracy : 0.9172932330827067\n",
      "Epoch 25:\t train loss : 0.5655980522318946; train accuracy : 0.9860642592490184; \n",
      " validation loss : 0.6545822224453532; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5719606331868304; train accuracy : 0.9792899408284024; \n",
      " validation loss : 0.6435865972161917; validation accuracy : 0.9022556390977443\n",
      "Epoch 27:\t train loss : 0.5618581910519516; train accuracy : 0.9896587955538351; \n",
      " validation loss : 0.6225895739210267; validation accuracy : 0.9323308270676691\n",
      "Epoch 28:\t train loss : 0.5796135314617062; train accuracy : 0.9713266603992701; \n",
      " validation loss : 0.6499781466838214; validation accuracy : 0.9022556390977443\n",
      "Epoch 29:\t train loss : 0.5690191580131623; train accuracy : 0.9825388486423713; \n",
      " validation loss : 0.6687361490760221; validation accuracy : 0.8796992481203008\n",
      "Epoch 30:\t train loss : 0.5664084512070386; train accuracy : 0.9847508709837969; \n",
      " validation loss : 0.6499769979584669; validation accuracy : 0.9022556390977443\n",
      "Epoch 31:\t train loss : 0.5651422837291316; train accuracy : 0.9862025106453576; \n",
      " validation loss : 0.6493339864036501; validation accuracy : 0.9022556390977443\n",
      "Epoch 32:\t train loss : 0.5602855757187909; train accuracy : 0.9912072111928331; \n",
      " validation loss : 0.6561395074874015; validation accuracy : 0.8947368421052632\n",
      "Epoch 33:\t train loss : 0.5610054435961015; train accuracy : 0.9906542056074766; \n",
      " validation loss : 0.6432458492763162; validation accuracy : 0.9022556390977443\n",
      "Epoch 34:\t train loss : 0.5743706428052107; train accuracy : 0.9769534922302715; \n",
      " validation loss : 0.6512558653590146; validation accuracy : 0.8947368421052632\n",
      "Epoch 35:\t train loss : 0.5795337631429883; train accuracy : 0.9712160592821988; \n",
      " validation loss : 0.6453587908493578; validation accuracy : 0.9097744360902256\n",
      "Epoch 36:\t train loss : 0.5732608488602657; train accuracy : 0.977492672675994; \n",
      " validation loss : 0.6368780466307876; validation accuracy : 0.9172932330827067\n",
      "Epoch 37:\t train loss : 0.5850972064404777; train accuracy : 0.9658795553835093; \n",
      " validation loss : 0.6353393238747093; validation accuracy : 0.9172932330827067\n",
      "Epoch 38:\t train loss : 0.5673646950559549; train accuracy : 0.9837139855112537; \n",
      " validation loss : 0.6827966447155824; validation accuracy : 0.8646616541353384\n",
      "Epoch 39:\t train loss : 0.5633596905799175; train accuracy : 0.9879168279599624; \n",
      " validation loss : 0.6650157808714879; validation accuracy : 0.8872180451127819\n",
      "Epoch 40:\t train loss : 0.5708675227726117; train accuracy : 0.9801609246253388; \n",
      " validation loss : 0.637483600229064; validation accuracy : 0.9097744360902256\n",
      "Epoch 41:\t train loss : 0.5610528712951576; train accuracy : 0.9903915279544323; \n",
      " validation loss : 0.6429629462948263; validation accuracy : 0.9097744360902256\n",
      "Epoch 42:\t train loss : 0.5731527329905509; train accuracy : 0.97811480395952; \n",
      " validation loss : 0.6345347170126318; validation accuracy : 0.9172932330827067\n",
      "Epoch 43:\t train loss : 0.6126427768022052; train accuracy : 0.9376209699717967; \n",
      " validation loss : 0.6838469943829237; validation accuracy : 0.8646616541353384\n",
      "Epoch 44:\t train loss : 0.6035557991642629; train accuracy : 0.9468838135265166; \n",
      " validation loss : 0.6613467841854276; validation accuracy : 0.8872180451127819\n",
      "Epoch 45:\t train loss : 0.565453783247318; train accuracy : 0.9858154067356081; \n",
      " validation loss : 0.6534791835800641; validation accuracy : 0.8947368421052632\n",
      "Epoch 46:\t train loss : 0.5594520582649565; train accuracy : 0.9922440966653763; \n",
      " validation loss : 0.6432453623002617; validation accuracy : 0.9097744360902256\n",
      "Epoch 47:\t train loss : 0.5601311094164094; train accuracy : 0.9912486866117348; \n",
      " validation loss : 0.6408755165915156; validation accuracy : 0.9097744360902256\n",
      "Epoch 48:\t train loss : 0.5572520672451206; train accuracy : 0.9941657910744899; \n",
      " validation loss : 0.6375864760162675; validation accuracy : 0.9097744360902256\n",
      "Epoch 49:\t train loss : 0.5584205818439607; train accuracy : 0.9929215285074379; \n",
      " validation loss : 0.6326006101964432; validation accuracy : 0.924812030075188\n",
      "Epoch 50:\t train loss : 0.557467191565881; train accuracy : 0.9939031134214455; \n",
      " validation loss : 0.5972522747695961; validation accuracy : 0.9548872180451128\n",
      "Epoch 51:\t train loss : 0.5629093240985846; train accuracy : 0.9881656804733727; \n",
      " validation loss : 0.6425919854560611; validation accuracy : 0.9097744360902256\n",
      "Epoch 52:\t train loss : 0.5620780952897892; train accuracy : 0.989368467621523; \n",
      " validation loss : 0.6243281374282086; validation accuracy : 0.924812030075188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53:\t train loss : 0.5652118590272011; train accuracy : 0.9862163357849915; \n",
      " validation loss : 0.6154939126664917; validation accuracy : 0.9398496240601504\n",
      "Epoch 54:\t train loss : 0.563889519575729; train accuracy : 0.9876265000276503; \n",
      " validation loss : 0.697169188041785; validation accuracy : 0.849624060150376\n",
      "Epoch 55:\t train loss : 0.559888097522944; train accuracy : 0.9914145882873417; \n",
      " validation loss : 0.6339713733825085; validation accuracy : 0.9172932330827067\n",
      "Epoch 56:\t train loss : 0.5596845727831024; train accuracy : 0.9918016921970911; \n",
      " validation loss : 0.6539336087211504; validation accuracy : 0.8947368421052632\n",
      "Epoch 57:\t train loss : 0.5563856607127496; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6548716919318358; validation accuracy : 0.8947368421052632\n",
      "Epoch 58:\t train loss : 0.5626491491198659; train accuracy : 0.9886357352209257; \n",
      " validation loss : 0.6410483236289308; validation accuracy : 0.9097744360902256\n",
      "Epoch 59:\t train loss : 0.5611621531682799; train accuracy : 0.990294751976995; \n",
      " validation loss : 0.6387822710659045; validation accuracy : 0.9097744360902256\n",
      "Epoch 60:\t train loss : 0.5642065839366538; train accuracy : 0.9868522922081513; \n",
      " validation loss : 0.6715153510178297; validation accuracy : 0.8796992481203008\n",
      "Epoch 61:\t train loss : 0.5715036403685755; train accuracy : 0.9795249682021788; \n",
      " validation loss : 0.6030442433999128; validation accuracy : 0.9473684210526315\n",
      "Epoch 62:\t train loss : 0.5591044722711684; train accuracy : 0.9920920201294033; \n",
      " validation loss : 0.6292467686806187; validation accuracy : 0.924812030075188\n",
      "Epoch 63:\t train loss : 0.5632335110943844; train accuracy : 0.9879997787977659; \n",
      " validation loss : 0.6560896629161465; validation accuracy : 0.8947368421052632\n",
      "Epoch 64:\t train loss : 0.576568170251593; train accuracy : 0.9744511419565338; \n",
      " validation loss : 0.6446254188783114; validation accuracy : 0.9022556390977443\n",
      "Epoch 65:\t train loss : 0.5597765714361562; train accuracy : 0.991677265940386; \n",
      " validation loss : 0.6819608995761799; validation accuracy : 0.8721804511278195\n",
      "Epoch 66:\t train loss : 0.5626117256409766; train accuracy : 0.9886772106398275; \n",
      " validation loss : 0.6401196348943387; validation accuracy : 0.9097744360902256\n",
      "Epoch 67:\t train loss : 0.5628899991708898; train accuracy : 0.9885251341038545; \n",
      " validation loss : 0.6489676017142649; validation accuracy : 0.8947368421052632\n",
      "Epoch 68:\t train loss : 0.562367577861194; train accuracy : 0.9889398882928717; \n",
      " validation loss : 0.634396567407365; validation accuracy : 0.9172932330827067\n",
      "Epoch 69:\t train loss : 0.5604456505369537; train accuracy : 0.9908201072830836; \n",
      " validation loss : 0.6561386680809382; validation accuracy : 0.8947368421052632\n",
      "Epoch 70:\t train loss : 0.5623266864244449; train accuracy : 0.9888292871758004; \n",
      " validation loss : 0.6111393464354317; validation accuracy : 0.9398496240601504\n",
      "Epoch 71:\t train loss : 0.5606169516849616; train accuracy : 0.9908477575623513; \n",
      " validation loss : 0.6668495816416368; validation accuracy : 0.8796992481203008\n",
      "Epoch 72:\t train loss : 0.5755352845302978; train accuracy : 0.9755156777083448; \n",
      " validation loss : 0.6182752836181922; validation accuracy : 0.9323308270676691\n",
      "Epoch 73:\t train loss : 0.5641665886746354; train accuracy : 0.9869767184648565; \n",
      " validation loss : 0.6612473746408214; validation accuracy : 0.8872180451127819\n",
      "Epoch 74:\t train loss : 0.5698154030200089; train accuracy : 0.9812807609356855; \n",
      " validation loss : 0.6156834864824317; validation accuracy : 0.9323308270676691\n",
      "Epoch 75:\t train loss : 0.5601609534174582; train accuracy : 0.9911380854946635; \n",
      " validation loss : 0.637153210792957; validation accuracy : 0.9097744360902256\n",
      "Epoch 76:\t train loss : 0.569019935753933; train accuracy : 0.9820549687551844; \n",
      " validation loss : 0.6205982449590766; validation accuracy : 0.9323308270676691\n",
      "Epoch 77:\t train loss : 0.5653982204875361; train accuracy : 0.9857324558978046; \n",
      " validation loss : 0.6451673950475451; validation accuracy : 0.9097744360902256\n",
      "Epoch 78:\t train loss : 0.5574152848254404; train accuracy : 0.9940690150970525; \n",
      " validation loss : 0.6386141174474019; validation accuracy : 0.9097744360902256\n",
      "Epoch 79:\t train loss : 0.5593302865041181; train accuracy : 0.9919675938726981; \n",
      " validation loss : 0.6481479470229107; validation accuracy : 0.8947368421052632\n",
      "Epoch 80:\t train loss : 0.5576005221383086; train accuracy : 0.9938478128629099; \n",
      " validation loss : 0.6638165166163018; validation accuracy : 0.8872180451127819\n",
      "Epoch 81:\t train loss : 0.5589427450869479; train accuracy : 0.9922164463861085; \n",
      " validation loss : 0.628916958499241; validation accuracy : 0.9172932330827067\n",
      "Epoch 82:\t train loss : 0.5709008592681705; train accuracy : 0.9801470994857048; \n",
      " validation loss : 0.6577483030825562; validation accuracy : 0.8872180451127819\n",
      "Epoch 83:\t train loss : 0.5682619618000835; train accuracy : 0.9828706519935851; \n",
      " validation loss : 0.650631850235048; validation accuracy : 0.8947368421052632\n",
      "Epoch 84:\t train loss : 0.5621429123580013; train accuracy : 0.9890781396892109; \n",
      " validation loss : 0.6258675477305151; validation accuracy : 0.9172932330827067\n",
      "Epoch 85:\t train loss : 0.5653227625332917; train accuracy : 0.9857324558978046; \n",
      " validation loss : 0.6369711959833884; validation accuracy : 0.9172932330827067\n",
      "Epoch 86:\t train loss : 0.5594696225461117; train accuracy : 0.9918431676159929; \n",
      " validation loss : 0.6083826869419141; validation accuracy : 0.9398496240601504\n",
      "Epoch 87:\t train loss : 0.5604555547288954; train accuracy : 0.9908754078416192; \n",
      " validation loss : 0.6327852477463547; validation accuracy : 0.9172932330827067\n",
      "Epoch 88:\t train loss : 0.5581499276598393; train accuracy : 0.993225681579384; \n",
      " validation loss : 0.6495109024050189; validation accuracy : 0.9022556390977443\n",
      "Epoch 89:\t train loss : 0.5550083207502241; train accuracy : 0.9964054636951833; \n",
      " validation loss : 0.6324202701169999; validation accuracy : 0.9172932330827067\n",
      "Epoch 90:\t train loss : 0.5546906394614981; train accuracy : 0.9967372670463972; \n",
      " validation loss : 0.6190722884932165; validation accuracy : 0.924812030075188\n",
      "Epoch 91:\t train loss : 0.5574795837961974; train accuracy : 0.9938754631421777; \n",
      " validation loss : 0.615674681469128; validation accuracy : 0.9323308270676691\n",
      "Epoch 92:\t train loss : 0.5672125817667725; train accuracy : 0.9838660620472267; \n",
      " validation loss : 0.6425704175754456; validation accuracy : 0.9022556390977443\n",
      "Epoch 93:\t train loss : 0.5577753047489119; train accuracy : 0.993681911187303; \n",
      " validation loss : 0.6431118359232066; validation accuracy : 0.9022556390977443\n",
      "Epoch 94:\t train loss : 0.556834483349334; train accuracy : 0.9945805452635071; \n",
      " validation loss : 0.6343665038118192; validation accuracy : 0.9172932330827067\n",
      "Epoch 95:\t train loss : 0.5660292975412688; train accuracy : 0.9851103246142786; \n",
      " validation loss : 0.673611990444194; validation accuracy : 0.8872180451127819\n",
      "Epoch 96:\t train loss : 0.6072834681253065; train accuracy : 0.9430542498479234; \n",
      " validation loss : 0.6240576033546186; validation accuracy : 0.924812030075188\n",
      "Epoch 97:\t train loss : 0.5957818696047404; train accuracy : 0.9547226676989438; \n",
      " validation loss : 0.6521482988279552; validation accuracy : 0.9022556390977443\n",
      "Epoch 98:\t train loss : 0.5792025888711338; train accuracy : 0.9715755129126804; \n",
      " validation loss : 0.657349589785315; validation accuracy : 0.8947368421052632\n",
      "Epoch 99:\t train loss : 0.6024620423586828; train accuracy : 0.9484184040258806; \n",
      " validation loss : 0.6726704503296058; validation accuracy : 0.8721804511278195\n",
      "Epoch 100:\t train loss : 0.5895620860678201; train accuracy : 0.9614693358402919; \n",
      " validation loss : 0.6636193196291494; validation accuracy : 0.8872180451127819\n",
      "Early stopping at epoch 100\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.557467191565881; Train accuracy : 0.9939031134214455; \n",
      " Validation loss : 0.5972522747695961; Validation accuracy : 0.9548872180451128\n",
      "------------------------------ Let's train model 34 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8991518912500528; train accuracy : 0.6301083890947299; \n",
      " validation loss : 0.8061683278047558; validation accuracy : 0.7593984962406015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\t train loss : 0.7778939228697099; train accuracy : 0.7661892385113089; \n",
      " validation loss : 0.7338102359800581; validation accuracy : 0.8045112781954887\n",
      "Epoch 3:\t train loss : 0.7336374481048806; train accuracy : 0.813512691478184; \n",
      " validation loss : 0.6996885012775336; validation accuracy : 0.849624060150376\n",
      "Epoch 4:\t train loss : 0.6925062385143573; train accuracy : 0.856190897528065; \n",
      " validation loss : 0.6825550685781014; validation accuracy : 0.8646616541353384\n",
      "Epoch 5:\t train loss : 0.6611846167545403; train accuracy : 0.8886385002488525; \n",
      " validation loss : 0.6413243239227372; validation accuracy : 0.9022556390977443\n",
      "Epoch 6:\t train loss : 0.6394547770442035; train accuracy : 0.9111043521539568; \n",
      " validation loss : 0.6825797675653629; validation accuracy : 0.8646616541353384\n",
      "Epoch 7:\t train loss : 0.6233419971193409; train accuracy : 0.9285516783719515; \n",
      " validation loss : 0.6608020656570238; validation accuracy : 0.8872180451127819\n",
      "Epoch 8:\t train loss : 0.6059211516238148; train accuracy : 0.9453215727478848; \n",
      " validation loss : 0.6844862872785634; validation accuracy : 0.8571428571428571\n",
      "Epoch 9:\t train loss : 0.600222156037958; train accuracy : 0.9514046341868053; \n",
      " validation loss : 0.6846550885269167; validation accuracy : 0.8646616541353384\n",
      "Epoch 10:\t train loss : 0.587891517519194; train accuracy : 0.9645246916993861; \n",
      " validation loss : 0.6595376103996957; validation accuracy : 0.8872180451127819\n",
      "Epoch 11:\t train loss : 0.5854395133344451; train accuracy : 0.9659763313609467; \n",
      " validation loss : 0.69096537513753; validation accuracy : 0.8721804511278195\n",
      "Epoch 12:\t train loss : 0.5926299954853143; train accuracy : 0.9584001548415639; \n",
      " validation loss : 0.6341855120470261; validation accuracy : 0.924812030075188\n",
      "Epoch 13:\t train loss : 0.5837728372023208; train accuracy : 0.9679533263285959; \n",
      " validation loss : 0.6624962899787423; validation accuracy : 0.8796992481203008\n",
      "Epoch 14:\t train loss : 0.5957775739318505; train accuracy : 0.9550268207708897; \n",
      " validation loss : 0.641146051705805; validation accuracy : 0.9097744360902256\n",
      "Epoch 15:\t train loss : 0.577525265145625; train accuracy : 0.9741469888845877; \n",
      " validation loss : 0.636177353349212; validation accuracy : 0.9172932330827067\n",
      "Epoch 16:\t train loss : 0.5718702630399249; train accuracy : 0.979801470994857; \n",
      " validation loss : 0.6474654886375251; validation accuracy : 0.9022556390977443\n",
      "Epoch 17:\t train loss : 0.5708321183636199; train accuracy : 0.9810872089808107; \n",
      " validation loss : 0.6238044482182763; validation accuracy : 0.924812030075188\n",
      "Epoch 18:\t train loss : 0.5728448067240693; train accuracy : 0.9789028369186529; \n",
      " validation loss : 0.6707025246244385; validation accuracy : 0.8721804511278195\n",
      "Epoch 19:\t train loss : 0.5687621654782452; train accuracy : 0.9828706519935851; \n",
      " validation loss : 0.6420596866455481; validation accuracy : 0.9097744360902256\n",
      "Epoch 20:\t train loss : 0.5650262303964663; train accuracy : 0.9866310899740087; \n",
      " validation loss : 0.6458705216061058; validation accuracy : 0.9022556390977443\n",
      "Epoch 21:\t train loss : 0.5684107462136145; train accuracy : 0.9832577559033346; \n",
      " validation loss : 0.6407772487701187; validation accuracy : 0.9172932330827067\n",
      "Epoch 22:\t train loss : 0.567178810958928; train accuracy : 0.9845296687496544; \n",
      " validation loss : 0.6576192696360815; validation accuracy : 0.8947368421052632\n",
      "Epoch 23:\t train loss : 0.5619523891144869; train accuracy : 0.9900735497428524; \n",
      " validation loss : 0.6403682628464811; validation accuracy : 0.9172932330827067\n",
      "Epoch 24:\t train loss : 0.5699639666533821; train accuracy : 0.9812392855167837; \n",
      " validation loss : 0.6401519670917845; validation accuracy : 0.9097744360902256\n",
      "Epoch 25:\t train loss : 0.5679074401929354; train accuracy : 0.9836310346734501; \n",
      " validation loss : 0.6073937849665483; validation accuracy : 0.9398496240601504\n",
      "Epoch 26:\t train loss : 0.560851948086531; train accuracy : 0.990903058120887; \n",
      " validation loss : 0.6434264097028652; validation accuracy : 0.9097744360902256\n",
      "Epoch 27:\t train loss : 0.5645804463328177; train accuracy : 0.9867831665099818; \n",
      " validation loss : 0.6472733701757342; validation accuracy : 0.9097744360902256\n",
      "Epoch 28:\t train loss : 0.5926760036503468; train accuracy : 0.9579301000940109; \n",
      " validation loss : 0.6822754236394021; validation accuracy : 0.8721804511278195\n",
      "Epoch 29:\t train loss : 0.5682963408730715; train accuracy : 0.9830227285295582; \n",
      " validation loss : 0.7133003720709692; validation accuracy : 0.8270676691729323\n",
      "Epoch 30:\t train loss : 0.5677007793742302; train accuracy : 0.9838384117679588; \n",
      " validation loss : 0.6694001211811405; validation accuracy : 0.8721804511278195\n",
      "Epoch 31:\t train loss : 0.5602136967731505; train accuracy : 0.9910827849361279; \n",
      " validation loss : 0.650561745916547; validation accuracy : 0.9022556390977443\n",
      "Epoch 32:\t train loss : 0.560327240293269; train accuracy : 0.9912901620306365; \n",
      " validation loss : 0.6457616343091396; validation accuracy : 0.9022556390977443\n",
      "Epoch 33:\t train loss : 0.5619285822690729; train accuracy : 0.9894928938782281; \n",
      " validation loss : 0.6424721317139199; validation accuracy : 0.9097744360902256\n",
      "Epoch 34:\t train loss : 0.5614117543470327; train accuracy : 0.9903085771166289; \n",
      " validation loss : 0.6586071379006025; validation accuracy : 0.8947368421052632\n",
      "Epoch 35:\t train loss : 0.5581944245550997; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.6458931341338384; validation accuracy : 0.9022556390977443\n",
      "Epoch 36:\t train loss : 0.5573085383542924; train accuracy : 0.9941796162141238; \n",
      " validation loss : 0.6587112541844191; validation accuracy : 0.9022556390977443\n",
      "Epoch 37:\t train loss : 0.5713637055403776; train accuracy : 0.9798152961344909; \n",
      " validation loss : 0.6728822574817043; validation accuracy : 0.8721804511278195\n",
      "Epoch 38:\t train loss : 0.5589592024400273; train accuracy : 0.9924652988995188; \n",
      " validation loss : 0.6396127591038838; validation accuracy : 0.9097744360902256\n",
      "Epoch 39:\t train loss : 0.5590247502716793; train accuracy : 0.9924238234806172; \n",
      " validation loss : 0.6606020577214677; validation accuracy : 0.8796992481203008\n",
      "Epoch 40:\t train loss : 0.5571035002250425; train accuracy : 0.9942210916330255; \n",
      " validation loss : 0.641592399068548; validation accuracy : 0.9022556390977443\n",
      "Epoch 41:\t train loss : 0.5838346279208108; train accuracy : 0.9668749654371509; \n",
      " validation loss : 0.6286892625455256; validation accuracy : 0.924812030075188\n",
      "Epoch 42:\t train loss : 0.5593526542112363; train accuracy : 0.991981419012332; \n",
      " validation loss : 0.6191382723097106; validation accuracy : 0.9323308270676691\n",
      "Epoch 43:\t train loss : 0.5547658101625454; train accuracy : 0.9966128407896919; \n",
      " validation loss : 0.6340693161277938; validation accuracy : 0.9097744360902256\n",
      "Epoch 44:\t train loss : 0.5835134358558774; train accuracy : 0.9674417961621412; \n",
      " validation loss : 0.6530321872764021; validation accuracy : 0.8947368421052632\n",
      "Epoch 45:\t train loss : 0.5651506229705462; train accuracy : 0.985967483271581; \n",
      " validation loss : 0.6308909218474945; validation accuracy : 0.924812030075188\n",
      "Epoch 46:\t train loss : 0.5559399132633328; train accuracy : 0.995534479898247; \n",
      " validation loss : 0.6367789938174745; validation accuracy : 0.9097744360902256\n",
      "Epoch 47:\t train loss : 0.5556934981474614; train accuracy : 0.9957003815738539; \n",
      " validation loss : 0.6569830612709207; validation accuracy : 0.8947368421052632\n",
      "Epoch 48:\t train loss : 0.5556793475238814; train accuracy : 0.9957556821323895; \n",
      " validation loss : 0.6449086533031858; validation accuracy : 0.9097744360902256\n",
      "Epoch 49:\t train loss : 0.5561096093901202; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6239020889828328; validation accuracy : 0.9172932330827067\n",
      "Epoch 50:\t train loss : 0.5552835826134843; train accuracy : 0.9961151357628711; \n",
      " validation loss : 0.648594105873552; validation accuracy : 0.8947368421052632\n",
      "Epoch 51:\t train loss : 0.6094134264143232; train accuracy : 0.9408422275064978; \n",
      " validation loss : 0.6809699125386379; validation accuracy : 0.8646616541353384\n",
      "Epoch 52:\t train loss : 0.5658221887900506; train accuracy : 0.9857601061770724; \n",
      " validation loss : 0.6566247775929404; validation accuracy : 0.9022556390977443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53:\t train loss : 0.5629735011278153; train accuracy : 0.9879583033788641; \n",
      " validation loss : 0.6660272003658941; validation accuracy : 0.8872180451127819\n",
      "Epoch 54:\t train loss : 0.5615359254161438; train accuracy : 0.9897693966709064; \n",
      " validation loss : 0.6730636078794219; validation accuracy : 0.8796992481203008\n",
      "Epoch 55:\t train loss : 0.557232923717679; train accuracy : 0.9941657910744899; \n",
      " validation loss : 0.6167163380242852; validation accuracy : 0.9398496240601504\n",
      "Epoch 56:\t train loss : 0.5610908533365835; train accuracy : 0.9902671016977271; \n",
      " validation loss : 0.6633466043084776; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5560759952354722; train accuracy : 0.995230326826301; \n",
      " validation loss : 0.6620584114272181; validation accuracy : 0.8872180451127819\n",
      "Epoch 58:\t train loss : 0.5559556510620309; train accuracy : 0.99536857822264; \n",
      " validation loss : 0.6470687423863136; validation accuracy : 0.9097744360902256\n",
      "Epoch 59:\t train loss : 0.5564237952188367; train accuracy : 0.9948985234750871; \n",
      " validation loss : 0.628716698777828; validation accuracy : 0.924812030075188\n",
      "Epoch 60:\t train loss : 0.5581584822217248; train accuracy : 0.9932809821379196; \n",
      " validation loss : 0.6720130654285252; validation accuracy : 0.8721804511278195\n",
      "Epoch 61:\t train loss : 0.5560992106025102; train accuracy : 0.9953409279433723; \n",
      " validation loss : 0.6655116442109895; validation accuracy : 0.8796992481203008\n",
      "Epoch 62:\t train loss : 0.5578820963928676; train accuracy : 0.9935021843720622; \n",
      " validation loss : 0.6572046339812838; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.5567177036759552; train accuracy : 0.9945667201238733; \n",
      " validation loss : 0.6718519862020851; validation accuracy : 0.8796992481203008\n",
      "Epoch 64:\t train loss : 0.562200252421519; train accuracy : 0.9891472653873804; \n",
      " validation loss : 0.6468523394436272; validation accuracy : 0.9022556390977443\n",
      "Epoch 65:\t train loss : 0.5554463680419031; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6465770856203257; validation accuracy : 0.9022556390977443\n",
      "Epoch 66:\t train loss : 0.5696582705475246; train accuracy : 0.9815987391472654; \n",
      " validation loss : 0.6476311147639454; validation accuracy : 0.9022556390977443\n",
      "Epoch 67:\t train loss : 0.5586764150469246; train accuracy : 0.9925897251562241; \n",
      " validation loss : 0.6635137130098904; validation accuracy : 0.8872180451127819\n",
      "Epoch 68:\t train loss : 0.5591198967220136; train accuracy : 0.9922026212464746; \n",
      " validation loss : 0.6086849310836747; validation accuracy : 0.9398496240601504\n",
      "Epoch 69:\t train loss : 0.5990829686888421; train accuracy : 0.951294033069734; \n",
      " validation loss : 0.7602792059884322; validation accuracy : 0.7894736842105263\n",
      "Epoch 70:\t train loss : 0.6211148595852153; train accuracy : 0.9288696565835315; \n",
      " validation loss : 0.6843832508311627; validation accuracy : 0.8646616541353384\n",
      "Epoch 71:\t train loss : 0.5656304262104238; train accuracy : 0.9856909804789028; \n",
      " validation loss : 0.661781604902325; validation accuracy : 0.8872180451127819\n",
      "Epoch 72:\t train loss : 0.5575008020589275; train accuracy : 0.9940551899574186; \n",
      " validation loss : 0.6314753754358662; validation accuracy : 0.9172932330827067\n",
      "Epoch 73:\t train loss : 0.5560793460195191; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.6485524714138247; validation accuracy : 0.9022556390977443\n",
      "Epoch 74:\t train loss : 0.5556698174719498; train accuracy : 0.9957280318531218; \n",
      " validation loss : 0.6551856943446208; validation accuracy : 0.8872180451127819\n",
      "Epoch 75:\t train loss : 0.5603757443801569; train accuracy : 0.9910274843775922; \n",
      " validation loss : 0.6522297880579871; validation accuracy : 0.8947368421052632\n",
      "Early stopping at epoch 75\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5679074401929354; Train accuracy : 0.9836310346734501; \n",
      " Validation loss : 0.6073937849665483; Validation accuracy : 0.9398496240601504\n",
      "------------------------------ Let's train model 35 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9123177982486059; train accuracy : 0.6188823757119947; \n",
      " validation loss : 0.8168851227083211; validation accuracy : 0.7368421052631579\n",
      "Epoch 2:\t train loss : 0.8036168390086557; train accuracy : 0.737833877122159; \n",
      " validation loss : 0.7635325667744994; validation accuracy : 0.7969924812030075\n",
      "Epoch 3:\t train loss : 0.757478964012798; train accuracy : 0.7883371122048333; \n",
      " validation loss : 0.7235551335746211; validation accuracy : 0.8270676691729323\n",
      "Epoch 4:\t train loss : 0.7108323546000793; train accuracy : 0.8370016037161976; \n",
      " validation loss : 0.6853828765533766; validation accuracy : 0.8721804511278195\n",
      "Epoch 5:\t train loss : 0.6686573772901359; train accuracy : 0.8816153293148261; \n",
      " validation loss : 0.6517649430808166; validation accuracy : 0.8947368421052632\n",
      "Epoch 6:\t train loss : 0.6427715576379763; train accuracy : 0.9095282862356909; \n",
      " validation loss : 0.6682072301774082; validation accuracy : 0.8796992481203008\n",
      "Epoch 7:\t train loss : 0.6306613740404953; train accuracy : 0.9207542996184261; \n",
      " validation loss : 0.6659830330227786; validation accuracy : 0.8872180451127819\n",
      "Epoch 8:\t train loss : 0.6106584862776814; train accuracy : 0.9403721727589449; \n",
      " validation loss : 0.6570183367405351; validation accuracy : 0.8947368421052632\n",
      "Epoch 9:\t train loss : 0.6126347097864385; train accuracy : 0.9384228280705635; \n",
      " validation loss : 0.69367071288494; validation accuracy : 0.849624060150376\n",
      "Epoch 10:\t train loss : 0.5910515698542359; train accuracy : 0.960999281092739; \n",
      " validation loss : 0.6619283237430353; validation accuracy : 0.8796992481203008\n",
      "Epoch 11:\t train loss : 0.5977089818013785; train accuracy : 0.9536304816678648; \n",
      " validation loss : 0.6685241396430657; validation accuracy : 0.8721804511278195\n",
      "Epoch 12:\t train loss : 0.5809207661807736; train accuracy : 0.9708842559309849; \n",
      " validation loss : 0.6610897470918972; validation accuracy : 0.8947368421052632\n",
      "Epoch 13:\t train loss : 0.5757260634035584; train accuracy : 0.9759995575955317; \n",
      " validation loss : 0.6494987752352924; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.582579416261213; train accuracy : 0.9685754576121219; \n",
      " validation loss : 0.7424867426593378; validation accuracy : 0.7969924812030075\n",
      "Epoch 15:\t train loss : 0.5911301403063512; train accuracy : 0.9597550185256871; \n",
      " validation loss : 0.6851172992966714; validation accuracy : 0.849624060150376\n",
      "Epoch 16:\t train loss : 0.5871628304438812; train accuracy : 0.9639716861140297; \n",
      " validation loss : 0.6388613229323659; validation accuracy : 0.9097744360902256\n",
      "Epoch 17:\t train loss : 0.5745688974522329; train accuracy : 0.9769258419510037; \n",
      " validation loss : 0.6592160697708356; validation accuracy : 0.8721804511278195\n",
      "Epoch 18:\t train loss : 0.5683596147341263; train accuracy : 0.9830780290880938; \n",
      " validation loss : 0.6422351861984924; validation accuracy : 0.9022556390977443\n",
      "Epoch 19:\t train loss : 0.562451329769754; train accuracy : 0.9894652435989604; \n",
      " validation loss : 0.6474478748383564; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5619710741657963; train accuracy : 0.9896173201349333; \n",
      " validation loss : 0.6192556400646866; validation accuracy : 0.924812030075188\n",
      "Epoch 21:\t train loss : 0.5591141461680705; train accuracy : 0.9928109273903666; \n",
      " validation loss : 0.6591021506912002; validation accuracy : 0.8947368421052632\n",
      "Epoch 22:\t train loss : 0.5975094948763819; train accuracy : 0.9526350716142233; \n",
      " validation loss : 0.7480050897434052; validation accuracy : 0.7894736842105263\n",
      "Epoch 23:\t train loss : 0.636734975356466; train accuracy : 0.9130536968423381; \n",
      " validation loss : 0.6742663606916212; validation accuracy : 0.8796992481203008\n",
      "Epoch 24:\t train loss : 0.5795880099534987; train accuracy : 0.9715478626334126; \n",
      " validation loss : 0.6482416483158343; validation accuracy : 0.9022556390977443\n",
      "Epoch 25:\t train loss : 0.5696437461513448; train accuracy : 0.981972017917381; \n",
      " validation loss : 0.6483214921293632; validation accuracy : 0.9097744360902256\n",
      "Epoch 26:\t train loss : 0.5650648884011861; train accuracy : 0.98674169109108; \n",
      " validation loss : 0.6415718656585693; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:\t train loss : 0.5626738745359562; train accuracy : 0.9889537134325057; \n",
      " validation loss : 0.6741154165744929; validation accuracy : 0.8872180451127819\n",
      "Epoch 28:\t train loss : 0.5612455197328934; train accuracy : 0.9903915279544323; \n",
      " validation loss : 0.6898795497800702; validation accuracy : 0.8646616541353384\n",
      "Epoch 29:\t train loss : 0.5590471235034207; train accuracy : 0.9926588508543936; \n",
      " validation loss : 0.690835535602851; validation accuracy : 0.8571428571428571\n",
      "Epoch 30:\t train loss : 0.5616072819925504; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.6589037449570484; validation accuracy : 0.8796992481203008\n",
      "Epoch 31:\t train loss : 0.5590940000814344; train accuracy : 0.9927279765525632; \n",
      " validation loss : 0.667727604360449; validation accuracy : 0.8796992481203008\n",
      "Epoch 32:\t train loss : 0.5622037826579148; train accuracy : 0.9893546424818891; \n",
      " validation loss : 0.6431117890559578; validation accuracy : 0.9022556390977443\n",
      "Epoch 33:\t train loss : 0.557996492533382; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.6420707377987352; validation accuracy : 0.9097744360902256\n",
      "Epoch 34:\t train loss : 0.5545803082600297; train accuracy : 0.996916993861638; \n",
      " validation loss : 0.6310721914663163; validation accuracy : 0.924812030075188\n",
      "Epoch 35:\t train loss : 0.5553195541744828; train accuracy : 0.9961704363214068; \n",
      " validation loss : 0.6462026291114396; validation accuracy : 0.9022556390977443\n",
      "Epoch 36:\t train loss : 0.5579026745367824; train accuracy : 0.9935851352098656; \n",
      " validation loss : 0.6643153365109182; validation accuracy : 0.8872180451127819\n",
      "Epoch 37:\t train loss : 0.5695769320419027; train accuracy : 0.9814466626112923; \n",
      " validation loss : 0.6802768447857375; validation accuracy : 0.8721804511278195\n",
      "Epoch 38:\t train loss : 0.5629977888798812; train accuracy : 0.9881795056130067; \n",
      " validation loss : 0.6371379738227131; validation accuracy : 0.9172932330827067\n",
      "Epoch 39:\t train loss : 0.5574246893263147; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6715997950953934; validation accuracy : 0.8721804511278195\n",
      "Epoch 40:\t train loss : 0.5568131162929629; train accuracy : 0.994608195542775; \n",
      " validation loss : 0.6549231357816301; validation accuracy : 0.8947368421052632\n",
      "Epoch 41:\t train loss : 0.5573125374341356; train accuracy : 0.9942072664933915; \n",
      " validation loss : 0.639444690643082; validation accuracy : 0.9097744360902256\n",
      "Epoch 42:\t train loss : 0.5721345898779425; train accuracy : 0.978889011779019; \n",
      " validation loss : 0.6316160127026835; validation accuracy : 0.924812030075188\n",
      "Epoch 43:\t train loss : 0.5606842203418362; train accuracy : 0.9904883039318697; \n",
      " validation loss : 0.6518554868255603; validation accuracy : 0.8947368421052632\n",
      "Epoch 44:\t train loss : 0.5585517378762193; train accuracy : 0.9928938782281701; \n",
      " validation loss : 0.680767679554811; validation accuracy : 0.8721804511278195\n",
      "Epoch 45:\t train loss : 0.5673308212067117; train accuracy : 0.9837139855112537; \n",
      " validation loss : 0.6726311727477486; validation accuracy : 0.8796992481203008\n",
      "Epoch 46:\t train loss : 0.5598068449412601; train accuracy : 0.9913454625891721; \n",
      " validation loss : 0.6825537094896739; validation accuracy : 0.8646616541353384\n",
      "Epoch 47:\t train loss : 0.5576327978028744; train accuracy : 0.9937786871647404; \n",
      " validation loss : 0.677521230841294; validation accuracy : 0.8721804511278195\n",
      "Epoch 48:\t train loss : 0.558109364359688; train accuracy : 0.9932671569982857; \n",
      " validation loss : 0.6486713964427047; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.5555288358204532; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6592299425734709; validation accuracy : 0.8872180451127819\n",
      "Epoch 50:\t train loss : 0.5552397668412277; train accuracy : 0.9962533871592103; \n",
      " validation loss : 0.6335332800518549; validation accuracy : 0.9172932330827067\n",
      "Epoch 51:\t train loss : 0.5548413352481334; train accuracy : 0.9964745893933529; \n",
      " validation loss : 0.6558378994226098; validation accuracy : 0.8947368421052632\n",
      "Epoch 52:\t train loss : 0.5553259657888897; train accuracy : 0.9960736603439695; \n",
      " validation loss : 0.6490877159931053; validation accuracy : 0.9022556390977443\n",
      "Epoch 53:\t train loss : 0.5536692407920077; train accuracy : 0.9977879776585743; \n",
      " validation loss : 0.6398887650725176; validation accuracy : 0.9097744360902256\n",
      "Epoch 54:\t train loss : 0.5525034788919376; train accuracy : 0.9990322402256263; \n",
      " validation loss : 0.6776098929341307; validation accuracy : 0.8721804511278195\n",
      "Epoch 55:\t train loss : 0.5540971853084357; train accuracy : 0.997373223469557; \n",
      " validation loss : 0.655304836291178; validation accuracy : 0.8947368421052632\n",
      "Epoch 56:\t train loss : 0.5543225065714571; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.6621583141910813; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5556058945721726; train accuracy : 0.9958109826909252; \n",
      " validation loss : 0.6757602266479316; validation accuracy : 0.8796992481203008\n",
      "Epoch 58:\t train loss : 0.5540129860604206; train accuracy : 0.9975114748658961; \n",
      " validation loss : 0.6773749745501644; validation accuracy : 0.8646616541353384\n",
      "Epoch 59:\t train loss : 0.5544516394832236; train accuracy : 0.9970690703976111; \n",
      " validation loss : 0.6536463693552902; validation accuracy : 0.9022556390977443\n",
      "Epoch 60:\t train loss : 0.5562743340207436; train accuracy : 0.99505060001106; \n",
      " validation loss : 0.6107700803287095; validation accuracy : 0.9323308270676691\n",
      "Epoch 61:\t train loss : 0.5535742168623105; train accuracy : 0.9979815296134491; \n",
      " validation loss : 0.6835821240171789; validation accuracy : 0.8721804511278195\n",
      "Epoch 62:\t train loss : 0.5567780534852358; train accuracy : 0.994594370403141; \n",
      " validation loss : 0.6679064713453485; validation accuracy : 0.8796992481203008\n",
      "Epoch 63:\t train loss : 0.5574038013411305; train accuracy : 0.9938616380025438; \n",
      " validation loss : 0.6535452057413739; validation accuracy : 0.8947368421052632\n",
      "Epoch 64:\t train loss : 0.5630130365523286; train accuracy : 0.9883730575678814; \n",
      " validation loss : 0.6637592693236362; validation accuracy : 0.8872180451127819\n",
      "Epoch 65:\t train loss : 0.5585272545177414; train accuracy : 0.9928385776696345; \n",
      " validation loss : 0.6612319532635258; validation accuracy : 0.8947368421052632\n",
      "Epoch 66:\t train loss : 0.558803451389386; train accuracy : 0.9925897251562241; \n",
      " validation loss : 0.6846210507263115; validation accuracy : 0.8571428571428571\n",
      "Epoch 67:\t train loss : 0.64492432341405; train accuracy : 0.9039844052424929; \n",
      " validation loss : 0.6951618151079855; validation accuracy : 0.8571428571428571\n",
      "Epoch 68:\t train loss : 0.5906875396515632; train accuracy : 0.9598379693634905; \n",
      " validation loss : 0.6505813620454433; validation accuracy : 0.9022556390977443\n",
      "Epoch 69:\t train loss : 0.571999495149934; train accuracy : 0.9788613614997511; \n",
      " validation loss : 0.6963507384550488; validation accuracy : 0.8421052631578947\n",
      "Epoch 70:\t train loss : 0.5654268906576924; train accuracy : 0.9858707072941437; \n",
      " validation loss : 0.6664834856428997; validation accuracy : 0.8872180451127819\n",
      "Epoch 71:\t train loss : 0.5608322195543927; train accuracy : 0.9904744787922358; \n",
      " validation loss : 0.6587083014682623; validation accuracy : 0.8872180451127819\n",
      "Epoch 72:\t train loss : 0.5591710581027478; train accuracy : 0.992133495548305; \n",
      " validation loss : 0.6855268067978423; validation accuracy : 0.8646616541353384\n",
      "Epoch 73:\t train loss : 0.5553216637446288; train accuracy : 0.9961980866006747; \n",
      " validation loss : 0.6606091889119471; validation accuracy : 0.8872180451127819\n",
      "Epoch 74:\t train loss : 0.5553269455721933; train accuracy : 0.996142786042139; \n",
      " validation loss : 0.6410279988612099; validation accuracy : 0.9097744360902256\n",
      "Epoch 75:\t train loss : 0.5542044380580425; train accuracy : 0.9972349720732179; \n",
      " validation loss : 0.6455765352096637; validation accuracy : 0.9022556390977443\n",
      "Epoch 76:\t train loss : 0.5548944615602408; train accuracy : 0.9964192888348172; \n",
      " validation loss : 0.6718914638536515; validation accuracy : 0.8796992481203008\n",
      "Epoch 77:\t train loss : 0.5536544187670576; train accuracy : 0.9976359011226014; \n",
      " validation loss : 0.6624216050870391; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78:\t train loss : 0.6546403138474037; train accuracy : 0.8944035834761931; \n",
      " validation loss : 0.6895596325005503; validation accuracy : 0.8571428571428571\n",
      "Epoch 79:\t train loss : 0.6024254728756178; train accuracy : 0.9481142509539346; \n",
      " validation loss : 0.6584990042893458; validation accuracy : 0.8947368421052632\n",
      "Epoch 80:\t train loss : 0.5767357466803271; train accuracy : 0.9739119615108113; \n",
      " validation loss : 0.6442971859267228; validation accuracy : 0.9022556390977443\n",
      "Epoch 81:\t train loss : 0.5744271065735638; train accuracy : 0.9766631642979594; \n",
      " validation loss : 0.6412880360947679; validation accuracy : 0.9097744360902256\n",
      "Epoch 82:\t train loss : 0.5678985929116032; train accuracy : 0.9832577559033346; \n",
      " validation loss : 0.6266450529151485; validation accuracy : 0.924812030075188\n",
      "Epoch 83:\t train loss : 0.563827259378857; train accuracy : 0.9872393961179008; \n",
      " validation loss : 0.6277588947197364; validation accuracy : 0.924812030075188\n",
      "Epoch 84:\t train loss : 0.5651002250465331; train accuracy : 0.9862163357849915; \n",
      " validation loss : 0.6765261885009559; validation accuracy : 0.8721804511278195\n",
      "Epoch 85:\t train loss : 0.562504384447914; train accuracy : 0.988746336337997; \n",
      " validation loss : 0.6343524386996304; validation accuracy : 0.9172932330827067\n",
      "Epoch 86:\t train loss : 0.561539364939759; train accuracy : 0.9897555715312725; \n",
      " validation loss : 0.6168178504872623; validation accuracy : 0.9323308270676691\n",
      "Epoch 87:\t train loss : 0.5591422463799383; train accuracy : 0.9921611458275729; \n",
      " validation loss : 0.6332200783309262; validation accuracy : 0.9097744360902256\n",
      "Epoch 88:\t train loss : 0.561402974390837; train accuracy : 0.9898799977879776; \n",
      " validation loss : 0.6395585623082777; validation accuracy : 0.9097744360902256\n",
      "Epoch 89:\t train loss : 0.5634860023130596; train accuracy : 0.987833877122159; \n",
      " validation loss : 0.649349868658727; validation accuracy : 0.9022556390977443\n",
      "Epoch 90:\t train loss : 0.5588661651425866; train accuracy : 0.992603550295858; \n",
      " validation loss : 0.6351074775713108; validation accuracy : 0.9172932330827067\n",
      "Epoch 91:\t train loss : 0.5603684442333495; train accuracy : 0.9908201072830836; \n",
      " validation loss : 0.625198440182418; validation accuracy : 0.924812030075188\n",
      "Epoch 92:\t train loss : 0.5600508481557953; train accuracy : 0.9912348614721008; \n",
      " validation loss : 0.6291490416004659; validation accuracy : 0.924812030075188\n",
      "Epoch 93:\t train loss : 0.5557922643838556; train accuracy : 0.9955483050378808; \n",
      " validation loss : 0.6415872399865308; validation accuracy : 0.9097744360902256\n",
      "Epoch 94:\t train loss : 0.5554489852321726; train accuracy : 0.9959354089476303; \n",
      " validation loss : 0.6263040280185167; validation accuracy : 0.924812030075188\n",
      "Epoch 95:\t train loss : 0.5548448943321508; train accuracy : 0.9966266659293259; \n",
      " validation loss : 0.6325476600758856; validation accuracy : 0.9172932330827067\n",
      "Epoch 96:\t train loss : 0.5591137074311509; train accuracy : 0.992147320687939; \n",
      " validation loss : 0.625196740870517; validation accuracy : 0.924812030075188\n",
      "Epoch 97:\t train loss : 0.5562076618505077; train accuracy : 0.9951612011281313; \n",
      " validation loss : 0.6178809471349214; validation accuracy : 0.9323308270676691\n",
      "Epoch 98:\t train loss : 0.5632688391462144; train accuracy : 0.9879997787977659; \n",
      " validation loss : 0.635363344153964; validation accuracy : 0.9172932330827067\n",
      "Epoch 99:\t train loss : 0.5566067250093065; train accuracy : 0.9947187966598462; \n",
      " validation loss : 0.6305376718202504; validation accuracy : 0.9172932330827067\n",
      "Epoch 100:\t train loss : 0.56250095110755; train accuracy : 0.9888154620361665; \n",
      " validation loss : 0.6077247744271997; validation accuracy : 0.9398496240601504\n",
      "Epoch 101:\t train loss : 0.556868207894481; train accuracy : 0.994594370403141; \n",
      " validation loss : 0.6081833119061483; validation accuracy : 0.9473684210526315\n",
      "Epoch 102:\t train loss : 0.555316648717393; train accuracy : 0.9960045346457999; \n",
      " validation loss : 0.6224339206541409; validation accuracy : 0.924812030075188\n",
      "Epoch 103:\t train loss : 0.5841573928199577; train accuracy : 0.9665708123652049; \n",
      " validation loss : 0.6279671925211274; validation accuracy : 0.924812030075188\n",
      "Epoch 104:\t train loss : 0.5694296755762004; train accuracy : 0.9814328374716584; \n",
      " validation loss : 0.6493361875195008; validation accuracy : 0.8947368421052632\n",
      "Epoch 105:\t train loss : 0.5955577321507339; train accuracy : 0.9548470939556489; \n",
      " validation loss : 0.6295537013243957; validation accuracy : 0.9172932330827067\n",
      "Epoch 106:\t train loss : 0.5664957975005501; train accuracy : 0.9845296687496544; \n",
      " validation loss : 0.6368186097404698; validation accuracy : 0.9097744360902256\n",
      "Epoch 107:\t train loss : 0.5605204628245497; train accuracy : 0.9907095061660123; \n",
      " validation loss : 0.6210759351501417; validation accuracy : 0.9323308270676691\n",
      "Epoch 108:\t train loss : 0.5580141643750827; train accuracy : 0.9934192335342586; \n",
      " validation loss : 0.6150393629819295; validation accuracy : 0.924812030075188\n",
      "Epoch 109:\t train loss : 0.5567003782261808; train accuracy : 0.9946634961013106; \n",
      " validation loss : 0.6325186590800618; validation accuracy : 0.9172932330827067\n",
      "Epoch 110:\t train loss : 0.5560203889935115; train accuracy : 0.9952856273848366; \n",
      " validation loss : 0.6313531201982717; validation accuracy : 0.9172932330827067\n",
      "Epoch 111:\t train loss : 0.5547379213478559; train accuracy : 0.9965851905104242; \n",
      " validation loss : 0.6199660418589212; validation accuracy : 0.9323308270676691\n",
      "Epoch 112:\t train loss : 0.554819314860687; train accuracy : 0.9966128407896919; \n",
      " validation loss : 0.578795600833412; validation accuracy : 0.9699248120300752\n",
      "Epoch 113:\t train loss : 0.5548011734619466; train accuracy : 0.9966128407896919; \n",
      " validation loss : 0.6122393281571379; validation accuracy : 0.9398496240601504\n",
      "Epoch 114:\t train loss : 0.5545800370473493; train accuracy : 0.9967925676049328; \n",
      " validation loss : 0.6037334400560271; validation accuracy : 0.9473684210526315\n",
      "Epoch 115:\t train loss : 0.5538622463863481; train accuracy : 0.9975806005640657; \n",
      " validation loss : 0.5977869490986942; validation accuracy : 0.9548872180451128\n",
      "Epoch 116:\t train loss : 0.5536573966396623; train accuracy : 0.9975944257036996; \n",
      " validation loss : 0.5981969907851407; validation accuracy : 0.9548872180451128\n",
      "Epoch 117:\t train loss : 0.5532869010784915; train accuracy : 0.9981197810097882; \n",
      " validation loss : 0.6484945104256367; validation accuracy : 0.9022556390977443\n",
      "Epoch 118:\t train loss : 0.5536985469894742; train accuracy : 0.997691201681137; \n",
      " validation loss : 0.6014324285150257; validation accuracy : 0.9548872180451128\n",
      "Epoch 119:\t train loss : 0.5540613278287521; train accuracy : 0.9972073217939501; \n",
      " validation loss : 0.5879212619628253; validation accuracy : 0.9624060150375939\n",
      "Epoch 120:\t train loss : 0.5573554666953533; train accuracy : 0.9940137145385168; \n",
      " validation loss : 0.6251161059218763; validation accuracy : 0.924812030075188\n",
      "Epoch 121:\t train loss : 0.5561417240261973; train accuracy : 0.9950782502903279; \n",
      " validation loss : 0.5930950879090838; validation accuracy : 0.9624060150375939\n",
      "Epoch 122:\t train loss : 0.556541550566108; train accuracy : 0.9947464469391141; \n",
      " validation loss : 0.6211256783442115; validation accuracy : 0.9323308270676691\n",
      "Epoch 123:\t train loss : 0.5580037111421007; train accuracy : 0.9932533318586517; \n",
      " validation loss : 0.6461308718794336; validation accuracy : 0.9022556390977443\n",
      "Epoch 124:\t train loss : 0.5567474975142535; train accuracy : 0.9946773212409445; \n",
      " validation loss : 0.6358578688888781; validation accuracy : 0.9172932330827067\n",
      "Epoch 125:\t train loss : 0.5545419345321243; train accuracy : 0.9969031687220041; \n",
      " validation loss : 0.5949913662194375; validation accuracy : 0.9548872180451128\n",
      "Epoch 126:\t train loss : 0.5538546349122068; train accuracy : 0.9976497262622352; \n",
      " validation loss : 0.6270334336773041; validation accuracy : 0.9172932330827067\n",
      "Epoch 127:\t train loss : 0.5542730718417607; train accuracy : 0.9971243709561467; \n",
      " validation loss : 0.6178324016848624; validation accuracy : 0.9323308270676691\n",
      "Epoch 128:\t train loss : 0.5548185518812669; train accuracy : 0.9965437150915224; \n",
      " validation loss : 0.6106581347368234; validation accuracy : 0.9398496240601504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129:\t train loss : 0.5843464675747062; train accuracy : 0.9665569872255709; \n",
      " validation loss : 0.639468267570857; validation accuracy : 0.9097744360902256\n",
      "Epoch 130:\t train loss : 0.5932206314764498; train accuracy : 0.9571697174141459; \n",
      " validation loss : 0.6264200258888803; validation accuracy : 0.924812030075188\n",
      "Epoch 131:\t train loss : 0.5855347569011048; train accuracy : 0.9648288447713321; \n",
      " validation loss : 0.6277503930844449; validation accuracy : 0.9172932330827067\n",
      "Epoch 132:\t train loss : 0.5704315881811374; train accuracy : 0.980741580489963; \n",
      " validation loss : 0.6244900865955302; validation accuracy : 0.924812030075188\n",
      "Epoch 133:\t train loss : 0.5637386162217985; train accuracy : 0.9876818005861859; \n",
      " validation loss : 0.6229103021136625; validation accuracy : 0.924812030075188\n",
      "Epoch 134:\t train loss : 0.5595202310706046; train accuracy : 0.9918431676159929; \n",
      " validation loss : 0.6098079421501187; validation accuracy : 0.9398496240601504\n",
      "Epoch 135:\t train loss : 0.5585492489119099; train accuracy : 0.9926588508543936; \n",
      " validation loss : 0.6356917130453771; validation accuracy : 0.9172932330827067\n",
      "Epoch 136:\t train loss : 0.5577066767325489; train accuracy : 0.9935989603494996; \n",
      " validation loss : 0.6476003411041596; validation accuracy : 0.9022556390977443\n",
      "Epoch 137:\t train loss : 0.5589500654271097; train accuracy : 0.9923546977824476; \n",
      " validation loss : 0.6165321445276004; validation accuracy : 0.9323308270676691\n",
      "Epoch 138:\t train loss : 0.5561527707133502; train accuracy : 0.9953547530830061; \n",
      " validation loss : 0.5999813581640777; validation accuracy : 0.9473684210526315\n",
      "Epoch 139:\t train loss : 0.5562686627379978; train accuracy : 0.9951059005695957; \n",
      " validation loss : 0.6474767767099125; validation accuracy : 0.9022556390977443\n",
      "Epoch 140:\t train loss : 0.5545017666061258; train accuracy : 0.9969308190012719; \n",
      " validation loss : 0.6438529173916426; validation accuracy : 0.9097744360902256\n",
      "Epoch 141:\t train loss : 0.5548763092962701; train accuracy : 0.9964884145329868; \n",
      " validation loss : 0.5904078506919778; validation accuracy : 0.9624060150375939\n",
      "Epoch 142:\t train loss : 0.5576743638322719; train accuracy : 0.9934468838135265; \n",
      " validation loss : 0.6104309951373394; validation accuracy : 0.9398496240601504\n",
      "Epoch 143:\t train loss : 0.5615533823345527; train accuracy : 0.9896449704142012; \n",
      " validation loss : 0.5956773569743974; validation accuracy : 0.9548872180451128\n",
      "Epoch 144:\t train loss : 0.5587933561336511; train accuracy : 0.9925620748769562; \n",
      " validation loss : 0.6268263441743422; validation accuracy : 0.924812030075188\n",
      "Epoch 145:\t train loss : 0.5547510206444362; train accuracy : 0.9966266659293259; \n",
      " validation loss : 0.624295980170773; validation accuracy : 0.9323308270676691\n",
      "Epoch 146:\t train loss : 0.5547540107743255; train accuracy : 0.9966957916274954; \n",
      " validation loss : 0.6036058240059149; validation accuracy : 0.9473684210526315\n",
      "Epoch 147:\t train loss : 0.5535033048396978; train accuracy : 0.9980091798927169; \n",
      " validation loss : 0.625136258705821; validation accuracy : 0.924812030075188\n",
      "Epoch 148:\t train loss : 0.5545649875986928; train accuracy : 0.9967925676049328; \n",
      " validation loss : 0.6373761102733712; validation accuracy : 0.9097744360902256\n",
      "Epoch 149:\t train loss : 0.5536638043927586; train accuracy : 0.997691201681137; \n",
      " validation loss : 0.6427725723571418; validation accuracy : 0.9097744360902256\n",
      "Epoch 150:\t train loss : 0.5542051411077987; train accuracy : 0.9973455731902892; \n",
      " validation loss : 0.6158436048864164; validation accuracy : 0.9323308270676691\n",
      "Epoch 151:\t train loss : 0.5542939678046332; train accuracy : 0.9971934966543162; \n",
      " validation loss : 0.6117252794804542; validation accuracy : 0.9398496240601504\n",
      "Epoch 152:\t train loss : 0.553762755847044; train accuracy : 0.9975806005640657; \n",
      " validation loss : 0.6044739576467686; validation accuracy : 0.9473684210526315\n",
      "Epoch 153:\t train loss : 0.553902925404261; train accuracy : 0.997539125145164; \n",
      " validation loss : 0.6066818454576169; validation accuracy : 0.9473684210526315\n",
      "Epoch 154:\t train loss : 0.5562688596316724; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.64052056835054; validation accuracy : 0.9097744360902256\n",
      "Epoch 155:\t train loss : 0.5549529904963703; train accuracy : 0.996446939114085; \n",
      " validation loss : 0.5941610485920608; validation accuracy : 0.9548872180451128\n",
      "Epoch 156:\t train loss : 0.5608277479680321; train accuracy : 0.9903500525355307; \n",
      " validation loss : 0.634370298452757; validation accuracy : 0.9172932330827067\n",
      "Epoch 157:\t train loss : 0.5545822072980869; train accuracy : 0.9967096167671293; \n",
      " validation loss : 0.6329654403783294; validation accuracy : 0.9172932330827067\n",
      "Epoch 158:\t train loss : 0.5540759005903817; train accuracy : 0.9972902726317535; \n",
      " validation loss : 0.5915556821229228; validation accuracy : 0.9624060150375939\n",
      "Epoch 159:\t train loss : 0.5539048781909727; train accuracy : 0.9975806005640657; \n",
      " validation loss : 0.6271273225337197; validation accuracy : 0.9172932330827067\n",
      "Epoch 160:\t train loss : 0.5528872532536839; train accuracy : 0.9985345351988055; \n",
      " validation loss : 0.6040719119228257; validation accuracy : 0.9473684210526315\n",
      "Epoch 161:\t train loss : 0.5530515335128985; train accuracy : 0.998313332964663; \n",
      " validation loss : 0.6299791892145545; validation accuracy : 0.924812030075188\n",
      "Epoch 162:\t train loss : 0.5529480295596596; train accuracy : 0.9985068849195377; \n",
      " validation loss : 0.6120850262195607; validation accuracy : 0.9398496240601504\n",
      "Early stopping at epoch 162\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.554819314860687; Train accuracy : 0.9966128407896919; \n",
      " Validation loss : 0.578795600833412; Validation accuracy : 0.9699248120300752\n",
      "------------------------------ Let's train model 36 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9037102201887479; train accuracy : 0.6177901896809158; \n",
      " validation loss : 0.8348496441178681; validation accuracy : 0.7218045112781954\n",
      "Epoch 2:\t train loss : 0.7841163784919944; train accuracy : 0.7607006580766466; \n",
      " validation loss : 0.7947568936328199; validation accuracy : 0.7443609022556391\n",
      "Epoch 3:\t train loss : 0.7333914576854872; train accuracy : 0.8140380467842725; \n",
      " validation loss : 0.7778559155225093; validation accuracy : 0.7669172932330827\n",
      "Epoch 4:\t train loss : 0.6968259731036839; train accuracy : 0.8523613338494719; \n",
      " validation loss : 0.8386363207712678; validation accuracy : 0.6917293233082706\n",
      "Epoch 5:\t train loss : 0.6576155152771319; train accuracy : 0.8930763700713377; \n",
      " validation loss : 0.7877463777225325; validation accuracy : 0.7669172932330827\n",
      "Epoch 6:\t train loss : 0.6337867128329806; train accuracy : 0.9173256649892164; \n",
      " validation loss : 0.7643951362828609; validation accuracy : 0.7744360902255639\n",
      "Epoch 7:\t train loss : 0.6233916488079465; train accuracy : 0.9281922247414699; \n",
      " validation loss : 0.7033380607973057; validation accuracy : 0.849624060150376\n",
      "Epoch 8:\t train loss : 0.6191154132925057; train accuracy : 0.9312061051816624; \n",
      " validation loss : 0.7301241808826281; validation accuracy : 0.8195488721804511\n",
      "Epoch 9:\t train loss : 0.6009216875214654; train accuracy : 0.9507272023447437; \n",
      " validation loss : 0.680421200007865; validation accuracy : 0.8646616541353384\n",
      "Epoch 10:\t train loss : 0.5972250966294167; train accuracy : 0.9540175855776143; \n",
      " validation loss : 0.704386560269817; validation accuracy : 0.8345864661654135\n",
      "Epoch 11:\t train loss : 0.5872343112905926; train accuracy : 0.9645661671182879; \n",
      " validation loss : 0.6919049866165906; validation accuracy : 0.849624060150376\n",
      "Epoch 12:\t train loss : 0.5886429650172963; train accuracy : 0.9623403196372283; \n",
      " validation loss : 0.7051985871389849; validation accuracy : 0.849624060150376\n",
      "Epoch 13:\t train loss : 0.5813760713132109; train accuracy : 0.9701653486700216; \n",
      " validation loss : 0.6592144834967301; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.5864242760638517; train accuracy : 0.9646214676768236; \n",
      " validation loss : 0.67369831000186; validation accuracy : 0.8721804511278195\n",
      "Epoch 15:\t train loss : 0.582971993945118; train accuracy : 0.9684786816346845; \n",
      " validation loss : 0.6583644797088635; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:\t train loss : 0.5773686878886832; train accuracy : 0.9740778631864182; \n",
      " validation loss : 0.7495390077768905; validation accuracy : 0.7894736842105263\n",
      "Epoch 17:\t train loss : 0.5861346896861672; train accuracy : 0.964552341978654; \n",
      " validation loss : 0.661189405857735; validation accuracy : 0.8872180451127819\n",
      "Epoch 18:\t train loss : 0.5780512618731704; train accuracy : 0.9732068793894818; \n",
      " validation loss : 0.6730123121431943; validation accuracy : 0.8721804511278195\n",
      "Epoch 19:\t train loss : 0.5880749170738038; train accuracy : 0.9631836531548968; \n",
      " validation loss : 0.7551027815581174; validation accuracy : 0.7969924812030075\n",
      "Epoch 20:\t train loss : 0.5705588444837032; train accuracy : 0.9812945860753194; \n",
      " validation loss : 0.7191852975149359; validation accuracy : 0.8270676691729323\n",
      "Epoch 21:\t train loss : 0.5724418580645825; train accuracy : 0.9788751866393851; \n",
      " validation loss : 0.7017004762165764; validation accuracy : 0.8421052631578947\n",
      "Epoch 22:\t train loss : 0.5700622436809121; train accuracy : 0.9812807609356855; \n",
      " validation loss : 0.7023055436479922; validation accuracy : 0.849624060150376\n",
      "Epoch 23:\t train loss : 0.5634563537591993; train accuracy : 0.9884974838245867; \n",
      " validation loss : 0.6682064719932004; validation accuracy : 0.8796992481203008\n",
      "Epoch 24:\t train loss : 0.5619430761255992; train accuracy : 0.9894237681800586; \n",
      " validation loss : 0.6778399183637287; validation accuracy : 0.8721804511278195\n",
      "Epoch 25:\t train loss : 0.5642693858893637; train accuracy : 0.9871702704197313; \n",
      " validation loss : 0.682397328085587; validation accuracy : 0.8646616541353384\n",
      "Epoch 26:\t train loss : 0.5639943887088446; train accuracy : 0.9872393961179008; \n",
      " validation loss : 0.7256240177540398; validation accuracy : 0.8270676691729323\n",
      "Epoch 27:\t train loss : 0.5623983693101214; train accuracy : 0.9889398882928717; \n",
      " validation loss : 0.6618512772198887; validation accuracy : 0.8872180451127819\n",
      "Epoch 28:\t train loss : 0.5681214797763177; train accuracy : 0.9833130564618703; \n",
      " validation loss : 0.7088218022453676; validation accuracy : 0.8421052631578947\n",
      "Epoch 29:\t train loss : 0.5721728236664557; train accuracy : 0.9792761156887685; \n",
      " validation loss : 0.6800033100151277; validation accuracy : 0.8721804511278195\n",
      "Epoch 30:\t train loss : 0.5769872817095081; train accuracy : 0.9740640380467843; \n",
      " validation loss : 0.6670273515447754; validation accuracy : 0.8872180451127819\n",
      "Epoch 31:\t train loss : 0.5654488133360077; train accuracy : 0.9858154067356081; \n",
      " validation loss : 0.6964647291667638; validation accuracy : 0.849624060150376\n",
      "Epoch 32:\t train loss : 0.56064479552211; train accuracy : 0.9909583586794226; \n",
      " validation loss : 0.6807377976961079; validation accuracy : 0.8721804511278195\n",
      "Epoch 33:\t train loss : 0.5618707089263206; train accuracy : 0.9893822927611569; \n",
      " validation loss : 0.7044551607484513; validation accuracy : 0.8421052631578947\n",
      "Epoch 34:\t train loss : 0.5609815999336625; train accuracy : 0.9902256262788254; \n",
      " validation loss : 0.6891241402617023; validation accuracy : 0.8646616541353384\n",
      "Epoch 35:\t train loss : 0.5578704764376877; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.68375960675341; validation accuracy : 0.8571428571428571\n",
      "Epoch 36:\t train loss : 0.5580114209395975; train accuracy : 0.9934883592324283; \n",
      " validation loss : 0.6601786726279588; validation accuracy : 0.8872180451127819\n",
      "Epoch 37:\t train loss : 0.5850793780991672; train accuracy : 0.9653542000774208; \n",
      " validation loss : 0.6575244927955328; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.5757178279880404; train accuracy : 0.9754189017309075; \n",
      " validation loss : 0.6947416063545704; validation accuracy : 0.8571428571428571\n",
      "Epoch 39:\t train loss : 0.5623376165183805; train accuracy : 0.9892163910855499; \n",
      " validation loss : 0.7131019254685276; validation accuracy : 0.8421052631578947\n",
      "Epoch 40:\t train loss : 0.5621669850876699; train accuracy : 0.9891334402477465; \n",
      " validation loss : 0.6996220724256699; validation accuracy : 0.849624060150376\n",
      "Epoch 41:\t train loss : 0.5589613717299047; train accuracy : 0.9924791240391528; \n",
      " validation loss : 0.6405987056662263; validation accuracy : 0.9172932330827067\n",
      "Epoch 42:\t train loss : 0.5569822443596483; train accuracy : 0.9945667201238733; \n",
      " validation loss : 0.6714394712575051; validation accuracy : 0.8796992481203008\n",
      "Epoch 43:\t train loss : 0.5858256787509191; train accuracy : 0.9651329978432782; \n",
      " validation loss : 0.73980657609098; validation accuracy : 0.8120300751879699\n",
      "Epoch 44:\t train loss : 0.5785853334513427; train accuracy : 0.9722805950340099; \n",
      " validation loss : 0.7256998754268891; validation accuracy : 0.8195488721804511\n",
      "Epoch 45:\t train loss : 0.5655412875726554; train accuracy : 0.9856771553392689; \n",
      " validation loss : 0.6936419636927946; validation accuracy : 0.849624060150376\n",
      "Epoch 46:\t train loss : 0.5619064800234504; train accuracy : 0.9894928938782281; \n",
      " validation loss : 0.6728887663954674; validation accuracy : 0.8796992481203008\n",
      "Epoch 47:\t train loss : 0.5725033377127371; train accuracy : 0.9784604324503677; \n",
      " validation loss : 0.7167060314826244; validation accuracy : 0.8270676691729323\n",
      "Epoch 48:\t train loss : 0.5660617952410971; train accuracy : 0.9850964994746447; \n",
      " validation loss : 0.6568716716617123; validation accuracy : 0.8947368421052632\n",
      "Epoch 49:\t train loss : 0.5650478788924643; train accuracy : 0.9863407620416966; \n",
      " validation loss : 0.7478086537516291; validation accuracy : 0.8045112781954887\n",
      "Epoch 50:\t train loss : 0.5667489850863822; train accuracy : 0.9844743681911188; \n",
      " validation loss : 0.7806830496267363; validation accuracy : 0.7669172932330827\n",
      "Epoch 51:\t train loss : 0.568505501643615; train accuracy : 0.9828015262954156; \n",
      " validation loss : 0.7159850262898213; validation accuracy : 0.8270676691729323\n",
      "Epoch 52:\t train loss : 0.5626697201459284; train accuracy : 0.9886080849416579; \n",
      " validation loss : 0.7439481792862781; validation accuracy : 0.8045112781954887\n",
      "Epoch 53:\t train loss : 0.5623132179725038; train accuracy : 0.9888292871758004; \n",
      " validation loss : 0.7413061084823898; validation accuracy : 0.8045112781954887\n",
      "Epoch 54:\t train loss : 0.5580378067867394; train accuracy : 0.993363932975723; \n",
      " validation loss : 0.6543417480773728; validation accuracy : 0.8947368421052632\n",
      "Epoch 55:\t train loss : 0.5580991111333129; train accuracy : 0.9933915832549909; \n",
      " validation loss : 0.7183838055351701; validation accuracy : 0.8345864661654135\n",
      "Epoch 56:\t train loss : 0.5560900928617177; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6493939627076649; validation accuracy : 0.8947368421052632\n",
      "Epoch 57:\t train loss : 0.5563592354017916; train accuracy : 0.9950782502903279; \n",
      " validation loss : 0.699014645185117; validation accuracy : 0.849624060150376\n",
      "Epoch 58:\t train loss : 0.5567474932657712; train accuracy : 0.9946496709616767; \n",
      " validation loss : 0.6731083508587842; validation accuracy : 0.8796992481203008\n",
      "Epoch 59:\t train loss : 0.55877342696883; train accuracy : 0.992589725156224; \n",
      " validation loss : 0.6820443614370887; validation accuracy : 0.8646616541353384\n",
      "Epoch 60:\t train loss : 0.5616676658289532; train accuracy : 0.9897279212520046; \n",
      " validation loss : 0.7315028253937175; validation accuracy : 0.8195488721804511\n",
      "Epoch 61:\t train loss : 0.5612945901889428; train accuracy : 0.9899491234861472; \n",
      " validation loss : 0.6984191681045556; validation accuracy : 0.8571428571428571\n",
      "Epoch 62:\t train loss : 0.5614333554952231; train accuracy : 0.989672620693469; \n",
      " validation loss : 0.7170268602171682; validation accuracy : 0.8345864661654135\n",
      "Epoch 63:\t train loss : 0.5584784651217327; train accuracy : 0.9928938782281701; \n",
      " validation loss : 0.709374768668566; validation accuracy : 0.8270676691729323\n",
      "Epoch 64:\t train loss : 0.5584671699048097; train accuracy : 0.9927694519714649; \n",
      " validation loss : 0.7456223667866434; validation accuracy : 0.7969924812030075\n",
      "Epoch 65:\t train loss : 0.5603289412216688; train accuracy : 0.99105513465686; \n",
      " validation loss : 0.633592704780527; validation accuracy : 0.9097744360902256\n",
      "Epoch 66:\t train loss : 0.5589912887111816; train accuracy : 0.9922164463861085; \n",
      " validation loss : 0.7039293258773828; validation accuracy : 0.8421052631578947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67:\t train loss : 0.556547922197991; train accuracy : 0.9948570480561854; \n",
      " validation loss : 0.6635524741747356; validation accuracy : 0.8872180451127819\n",
      "Epoch 68:\t train loss : 0.5637055963880426; train accuracy : 0.987363822374606; \n",
      " validation loss : 0.7136016880028333; validation accuracy : 0.8421052631578947\n",
      "Epoch 69:\t train loss : 0.5667004703626718; train accuracy : 0.9845158436100204; \n",
      " validation loss : 0.6842317414901224; validation accuracy : 0.8721804511278195\n",
      "Epoch 70:\t train loss : 0.559484474088362; train accuracy : 0.991829342476359; \n",
      " validation loss : 0.6997055614692006; validation accuracy : 0.849624060150376\n",
      "Epoch 71:\t train loss : 0.557303408171916; train accuracy : 0.9940966653763202; \n",
      " validation loss : 0.6890606708944604; validation accuracy : 0.8571428571428571\n",
      "Epoch 72:\t train loss : 0.584575208734428; train accuracy : 0.9660316319194824; \n",
      " validation loss : 0.8347959797197962; validation accuracy : 0.7142857142857143\n",
      "Epoch 73:\t train loss : 0.5646470806528471; train accuracy : 0.9867831665099818; \n",
      " validation loss : 0.7669867552888857; validation accuracy : 0.7894736842105263\n",
      "Epoch 74:\t train loss : 0.5589668885924144; train accuracy : 0.9922579218050103; \n",
      " validation loss : 0.7798913982914074; validation accuracy : 0.7744360902255639\n",
      "Epoch 75:\t train loss : 0.5574233452744719; train accuracy : 0.9939722391196151; \n",
      " validation loss : 0.7660419153361397; validation accuracy : 0.7819548872180451\n",
      "Epoch 76:\t train loss : 0.5628364013728636; train accuracy : 0.9883039318697119; \n",
      " validation loss : 0.7041556994292346; validation accuracy : 0.8421052631578947\n",
      "Epoch 77:\t train loss : 0.5585548851751705; train accuracy : 0.9927832771110988; \n",
      " validation loss : 0.7443498022603087; validation accuracy : 0.8120300751879699\n",
      "Epoch 78:\t train loss : 0.5572466806472076; train accuracy : 0.9940413648177846; \n",
      " validation loss : 0.7514189365583843; validation accuracy : 0.7969924812030075\n",
      "Epoch 79:\t train loss : 0.562968340304446; train accuracy : 0.988594259802024; \n",
      " validation loss : 0.771935114629745; validation accuracy : 0.7819548872180451\n",
      "Epoch 80:\t train loss : 0.5600417082792635; train accuracy : 0.9913869380080739; \n",
      " validation loss : 0.7226795208137122; validation accuracy : 0.8270676691729323\n",
      "Epoch 81:\t train loss : 0.5573620503161476; train accuracy : 0.9939169385610794; \n",
      " validation loss : 0.6853573657814306; validation accuracy : 0.8646616541353384\n",
      "Epoch 82:\t train loss : 0.5572525817719478; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.7308542196977755; validation accuracy : 0.8120300751879699\n",
      "Epoch 83:\t train loss : 0.5551821107760124; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.6617133271914424; validation accuracy : 0.8872180451127819\n",
      "Epoch 84:\t train loss : 0.5563412751204783; train accuracy : 0.9950367748714262; \n",
      " validation loss : 0.7210440021906818; validation accuracy : 0.8270676691729323\n",
      "Epoch 85:\t train loss : 0.5570861652820107; train accuracy : 0.9944422938671681; \n",
      " validation loss : 0.7223093949236667; validation accuracy : 0.8270676691729323\n",
      "Epoch 86:\t train loss : 0.5573382128271371; train accuracy : 0.9940690150970525; \n",
      " validation loss : 0.7238746660032179; validation accuracy : 0.8270676691729323\n",
      "Epoch 87:\t train loss : 0.560760620266078; train accuracy : 0.990598905048941; \n",
      " validation loss : 0.7188260001445527; validation accuracy : 0.8270676691729323\n",
      "Epoch 88:\t train loss : 0.5568823112177269; train accuracy : 0.9944975944257037; \n",
      " validation loss : 0.709775792456004; validation accuracy : 0.8421052631578947\n",
      "Epoch 89:\t train loss : 0.5590908543969112; train accuracy : 0.9923270475031798; \n",
      " validation loss : 0.6933472971936805; validation accuracy : 0.8571428571428571\n",
      "Epoch 90:\t train loss : 0.5782184220219128; train accuracy : 0.9729165514571697; \n",
      " validation loss : 0.7185755593611457; validation accuracy : 0.8270676691729323\n",
      "Epoch 91:\t train loss : 0.5673000391153897; train accuracy : 0.9837001603716198; \n",
      " validation loss : 0.7338951735997153; validation accuracy : 0.8195488721804511\n",
      "Epoch 92:\t train loss : 0.5595378298118168; train accuracy : 0.9918569927556268; \n",
      " validation loss : 0.7211769958601622; validation accuracy : 0.8270676691729323\n",
      "Epoch 93:\t train loss : 0.5582093007053449; train accuracy : 0.9933224575568214; \n",
      " validation loss : 0.7008476899185139; validation accuracy : 0.849624060150376\n",
      "Epoch 94:\t train loss : 0.5582814228343158; train accuracy : 0.9931150804623127; \n",
      " validation loss : 0.6943052476398299; validation accuracy : 0.8571428571428571\n",
      "Epoch 95:\t train loss : 0.5570570488427566; train accuracy : 0.9943178676104628; \n",
      " validation loss : 0.7190327790456776; validation accuracy : 0.8270676691729323\n",
      "Epoch 96:\t train loss : 0.5568343883146772; train accuracy : 0.9945667201238733; \n",
      " validation loss : 0.7175739184138769; validation accuracy : 0.8345864661654135\n",
      "Epoch 97:\t train loss : 0.5598479754303223; train accuracy : 0.9914284134269756; \n",
      " validation loss : 0.730743568791604; validation accuracy : 0.8195488721804511\n",
      "Epoch 98:\t train loss : 0.5671340944062273; train accuracy : 0.9841425648399049; \n",
      " validation loss : 0.7340789021717754; validation accuracy : 0.8195488721804511\n",
      "Epoch 99:\t train loss : 0.5572083804488529; train accuracy : 0.9941934413537576; \n",
      " validation loss : 0.7284393059697621; validation accuracy : 0.8195488721804511\n",
      "Epoch 100:\t train loss : 0.5581327033412592; train accuracy : 0.993225681579384; \n",
      " validation loss : 0.7018458823710826; validation accuracy : 0.849624060150376\n",
      "Epoch 101:\t train loss : 0.5566194646680477; train accuracy : 0.9948293977769175; \n",
      " validation loss : 0.7466714614068373; validation accuracy : 0.8045112781954887\n",
      "Epoch 102:\t train loss : 0.5546667300809057; train accuracy : 0.9968202178842006; \n",
      " validation loss : 0.7238989493682609; validation accuracy : 0.8270676691729323\n",
      "Epoch 103:\t train loss : 0.5555905424148428; train accuracy : 0.9957695072720234; \n",
      " validation loss : 0.737112622788925; validation accuracy : 0.8195488721804511\n",
      "Epoch 104:\t train loss : 0.5569541557726041; train accuracy : 0.9944008184482663; \n",
      " validation loss : 0.754194627438143; validation accuracy : 0.7969924812030075\n",
      "Epoch 105:\t train loss : 0.5632127347054194; train accuracy : 0.9879030028203285; \n",
      " validation loss : 0.6850593501541413; validation accuracy : 0.8646616541353384\n",
      "Epoch 106:\t train loss : 0.56158326715305; train accuracy : 0.9897417463916386; \n",
      " validation loss : 0.6718958122851443; validation accuracy : 0.8796992481203008\n",
      "Epoch 107:\t train loss : 0.5563692083630128; train accuracy : 0.9949399988939889; \n",
      " validation loss : 0.6868954002189442; validation accuracy : 0.8646616541353384\n",
      "Epoch 108:\t train loss : 0.555085730237039; train accuracy : 0.9963501631366477; \n",
      " validation loss : 0.7251585910906219; validation accuracy : 0.8270676691729323\n",
      "Epoch 109:\t train loss : 0.5601230596937398; train accuracy : 0.9912901620306365; \n",
      " validation loss : 0.7083493846779989; validation accuracy : 0.8421052631578947\n",
      "Epoch 110:\t train loss : 0.5581702841677062; train accuracy : 0.9930321296245092; \n",
      " validation loss : 0.7276507143956704; validation accuracy : 0.8195488721804511\n",
      "Epoch 111:\t train loss : 0.5545935711562819; train accuracy : 0.9968202178842006; \n",
      " validation loss : 0.7221161042274039; validation accuracy : 0.8270676691729323\n",
      "Epoch 112:\t train loss : 0.5540276170945291; train accuracy : 0.9974423491677266; \n",
      " validation loss : 0.6817710715990462; validation accuracy : 0.8721804511278195\n",
      "Epoch 113:\t train loss : 0.5559678786647624; train accuracy : 0.995534479898247; \n",
      " validation loss : 0.6792742586444104; validation accuracy : 0.8721804511278195\n",
      "Epoch 114:\t train loss : 0.5558513440513443; train accuracy : 0.9955621301775148; \n",
      " validation loss : 0.6867884706437639; validation accuracy : 0.8646616541353384\n",
      "Epoch 115:\t train loss : 0.5573645845638182; train accuracy : 0.9940413648177846; \n",
      " validation loss : 0.7273666287718313; validation accuracy : 0.8270676691729323\n",
      "Early stopping at epoch 115\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5603289412216688; Train accuracy : 0.99105513465686; \n",
      " Validation loss : 0.633592704780527; Validation accuracy : 0.9097744360902256\n",
      "------------------------------ Let's train model 37 ! ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t train loss : 0.899236530067961; train accuracy : 0.6278548913344025; \n",
      " validation loss : 0.802090170680442; validation accuracy : 0.7218045112781954\n",
      "Epoch 2:\t train loss : 0.7719358930154328; train accuracy : 0.773433611679478; \n",
      " validation loss : 0.7624040346330286; validation accuracy : 0.7894736842105263\n",
      "Epoch 3:\t train loss : 0.7284916588786213; train accuracy : 0.8194713266603992; \n",
      " validation loss : 0.7601051827717565; validation accuracy : 0.7894736842105263\n",
      "Epoch 4:\t train loss : 0.6920076936142788; train accuracy : 0.8583199690316872; \n",
      " validation loss : 0.7529557267048077; validation accuracy : 0.7894736842105263\n",
      "Epoch 5:\t train loss : 0.6592535884980111; train accuracy : 0.8914726538738041; \n",
      " validation loss : 0.6862377207104863; validation accuracy : 0.8646616541353384\n",
      "Epoch 6:\t train loss : 0.6307830936654538; train accuracy : 0.9206851739202566; \n",
      " validation loss : 0.6774116445552406; validation accuracy : 0.8796992481203008\n",
      "Epoch 7:\t train loss : 0.614128759413648; train accuracy : 0.9378698224852071; \n",
      " validation loss : 0.6812716710661849; validation accuracy : 0.8571428571428571\n",
      "Epoch 8:\t train loss : 0.604230912993905; train accuracy : 0.9472432671569982; \n",
      " validation loss : 0.6540743443057735; validation accuracy : 0.8872180451127819\n",
      "Epoch 9:\t train loss : 0.5935305730598263; train accuracy : 0.957460045346458; \n",
      " validation loss : 0.676334392756975; validation accuracy : 0.8721804511278195\n",
      "Epoch 10:\t train loss : 0.5903082080388262; train accuracy : 0.9612757838854172; \n",
      " validation loss : 0.6558445291480582; validation accuracy : 0.8872180451127819\n",
      "Epoch 11:\t train loss : 0.5783647973976718; train accuracy : 0.9733174805065531; \n",
      " validation loss : 0.6311361556071248; validation accuracy : 0.924812030075188\n",
      "Epoch 12:\t train loss : 0.5929728354067508; train accuracy : 0.9591743626610628; \n",
      " validation loss : 0.6605695727603407; validation accuracy : 0.8872180451127819\n",
      "Epoch 13:\t train loss : 0.5795601870950225; train accuracy : 0.9719349665431621; \n",
      " validation loss : 0.6642710749075813; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.5910476999302449; train accuracy : 0.9600591715976331; \n",
      " validation loss : 0.6693545158057611; validation accuracy : 0.8796992481203008\n",
      "Epoch 15:\t train loss : 0.5806033032071684; train accuracy : 0.970856605651717; \n",
      " validation loss : 0.6702934604469885; validation accuracy : 0.8796992481203008\n",
      "Epoch 16:\t train loss : 0.5817207994024356; train accuracy : 0.9699579715755129; \n",
      " validation loss : 0.6568491013134244; validation accuracy : 0.8947368421052632\n",
      "Epoch 17:\t train loss : 0.5808465290570567; train accuracy : 0.9708704307913509; \n",
      " validation loss : 0.6600838351665389; validation accuracy : 0.8872180451127819\n",
      "Epoch 18:\t train loss : 0.5730776974563128; train accuracy : 0.9783913067521982; \n",
      " validation loss : 0.6416870730399086; validation accuracy : 0.9097744360902256\n",
      "Epoch 19:\t train loss : 0.5686835358975807; train accuracy : 0.9828153514350495; \n",
      " validation loss : 0.660740841024905; validation accuracy : 0.8872180451127819\n",
      "Epoch 20:\t train loss : 0.563584342551432; train accuracy : 0.9881656804733728; \n",
      " validation loss : 0.6437274832717574; validation accuracy : 0.9097744360902256\n",
      "Epoch 21:\t train loss : 0.5611845118514156; train accuracy : 0.9906956810263784; \n",
      " validation loss : 0.6705523589960867; validation accuracy : 0.8796992481203008\n",
      "Epoch 22:\t train loss : 0.5617417532002857; train accuracy : 0.9896587955538351; \n",
      " validation loss : 0.6515738457350607; validation accuracy : 0.8947368421052632\n",
      "Epoch 23:\t train loss : 0.5585326648050007; train accuracy : 0.9930459547641431; \n",
      " validation loss : 0.6827980128334905; validation accuracy : 0.8571428571428571\n",
      "Epoch 24:\t train loss : 0.5578657207580136; train accuracy : 0.9937925123043743; \n",
      " validation loss : 0.6471659210974773; validation accuracy : 0.9022556390977443\n",
      "Epoch 25:\t train loss : 0.5607851511270305; train accuracy : 0.9908339324227174; \n",
      " validation loss : 0.6431146353483261; validation accuracy : 0.9097744360902256\n",
      "Epoch 26:\t train loss : 0.5621874313757189; train accuracy : 0.9893269922026212; \n",
      " validation loss : 0.67506759769339; validation accuracy : 0.8721804511278195\n",
      "Epoch 27:\t train loss : 0.5933070604315464; train accuracy : 0.9573217939501188; \n",
      " validation loss : 0.6636755939293499; validation accuracy : 0.8872180451127819\n",
      "Epoch 28:\t train loss : 0.5653044161322421; train accuracy : 0.9860227838301167; \n",
      " validation loss : 0.6523900414023586; validation accuracy : 0.9022556390977443\n",
      "Epoch 29:\t train loss : 0.5985790389256482; train accuracy : 0.9520405906099652; \n",
      " validation loss : 0.6879689755145947; validation accuracy : 0.8646616541353384\n",
      "Epoch 30:\t train loss : 0.5877960859561219; train accuracy : 0.9627827241055135; \n",
      " validation loss : 0.6653917547792181; validation accuracy : 0.8796992481203008\n",
      "Epoch 31:\t train loss : 0.5720555567322004; train accuracy : 0.9791655145716972; \n",
      " validation loss : 0.6766176372044772; validation accuracy : 0.8721804511278195\n",
      "Epoch 32:\t train loss : 0.5598875597090008; train accuracy : 0.9914975391251452; \n",
      " validation loss : 0.6492270117096943; validation accuracy : 0.9022556390977443\n",
      "Epoch 33:\t train loss : 0.5643024141031211; train accuracy : 0.9869767184648565; \n",
      " validation loss : 0.6599939070437918; validation accuracy : 0.8947368421052632\n",
      "Epoch 34:\t train loss : 0.5599772615260689; train accuracy : 0.9914422385666095; \n",
      " validation loss : 0.6717587798538247; validation accuracy : 0.8796992481203008\n",
      "Epoch 35:\t train loss : 0.5607832982474994; train accuracy : 0.9905712547696731; \n",
      " validation loss : 0.6454417257789479; validation accuracy : 0.9022556390977443\n",
      "Epoch 36:\t train loss : 0.5569163070545863; train accuracy : 0.9944975944257037; \n",
      " validation loss : 0.663896599825844; validation accuracy : 0.8796992481203008\n",
      "Epoch 37:\t train loss : 0.5585458877130326; train accuracy : 0.9929630039263396; \n",
      " validation loss : 0.6618135412165667; validation accuracy : 0.8872180451127819\n",
      "Epoch 38:\t train loss : 0.556128078310285; train accuracy : 0.9953547530830061; \n",
      " validation loss : 0.6623220267815522; validation accuracy : 0.8872180451127819\n",
      "Epoch 39:\t train loss : 0.5556414698156876; train accuracy : 0.99568655643422; \n",
      " validation loss : 0.6524953730924538; validation accuracy : 0.9022556390977443\n",
      "Epoch 40:\t train loss : 0.5558561222462405; train accuracy : 0.9957556821323895; \n",
      " validation loss : 0.6704945213503856; validation accuracy : 0.8721804511278195\n",
      "Epoch 41:\t train loss : 0.5673948556516564; train accuracy : 0.9835480838356467; \n",
      " validation loss : 0.6461915846746442; validation accuracy : 0.9022556390977443\n",
      "Epoch 42:\t train loss : 0.5583189396531073; train accuracy : 0.9932395067190178; \n",
      " validation loss : 0.669990458938196; validation accuracy : 0.8796992481203008\n",
      "Epoch 43:\t train loss : 0.5591931932166551; train accuracy : 0.9923132223635459; \n",
      " validation loss : 0.6819344762246269; validation accuracy : 0.8721804511278195\n",
      "Epoch 44:\t train loss : 0.5579141630960744; train accuracy : 0.9935989603494996; \n",
      " validation loss : 0.637971468536462; validation accuracy : 0.9097744360902256\n",
      "Epoch 45:\t train loss : 0.557964961808693; train accuracy : 0.9935436597909639; \n",
      " validation loss : 0.6516627875182333; validation accuracy : 0.8947368421052632\n",
      "Epoch 46:\t train loss : 0.559868449547631; train accuracy : 0.9912348614721008; \n",
      " validation loss : 0.6590807395791647; validation accuracy : 0.8872180451127819\n",
      "Epoch 47:\t train loss : 0.5656767173089204; train accuracy : 0.9854836033843942; \n",
      " validation loss : 0.6499788848236616; validation accuracy : 0.9022556390977443\n",
      "Epoch 48:\t train loss : 0.5580556641330245; train accuracy : 0.9933086324171874; \n",
      " validation loss : 0.6566399478388258; validation accuracy : 0.8947368421052632\n",
      "Epoch 49:\t train loss : 0.5573790097250516; train accuracy : 0.9940137145385168; \n",
      " validation loss : 0.6629422116977989; validation accuracy : 0.8872180451127819\n",
      "Epoch 50:\t train loss : 0.5664379610193525; train accuracy : 0.9848338218216004; \n",
      " validation loss : 0.6638763133021305; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5608998621694085; train accuracy : 0.9904883039318697; \n",
      " validation loss : 0.6625206635156343; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:\t train loss : 0.5593006065512742; train accuracy : 0.9918846430348947; \n",
      " validation loss : 0.6282180938717871; validation accuracy : 0.9172932330827067\n",
      "Epoch 53:\t train loss : 0.5571070501084909; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6396667481092894; validation accuracy : 0.9097744360902256\n",
      "Epoch 54:\t train loss : 0.5626623186284506; train accuracy : 0.9884698335453188; \n",
      " validation loss : 0.6982003301473095; validation accuracy : 0.849624060150376\n",
      "Epoch 55:\t train loss : 0.572330314838316; train accuracy : 0.9788337112204833; \n",
      " validation loss : 0.6596063489852076; validation accuracy : 0.8947368421052632\n",
      "Epoch 56:\t train loss : 0.5567083268727276; train accuracy : 0.9947326217994802; \n",
      " validation loss : 0.6385460505175239; validation accuracy : 0.9097744360902256\n",
      "Epoch 57:\t train loss : 0.5575420713475273; train accuracy : 0.9936266106287673; \n",
      " validation loss : 0.6639275855122158; validation accuracy : 0.8872180451127819\n",
      "Epoch 58:\t train loss : 0.5665740053265392; train accuracy : 0.9846264447270917; \n",
      " validation loss : 0.6637473294598706; validation accuracy : 0.8872180451127819\n",
      "Epoch 59:\t train loss : 0.575149902149651; train accuracy : 0.9759857324558978; \n",
      " validation loss : 0.6537123169914983; validation accuracy : 0.8947368421052632\n",
      "Epoch 60:\t train loss : 0.5594559234643683; train accuracy : 0.9918155173367251; \n",
      " validation loss : 0.6437901434281509; validation accuracy : 0.9097744360902256\n",
      "Epoch 61:\t train loss : 0.5573971892876345; train accuracy : 0.9939722391196151; \n",
      " validation loss : 0.6489022526223251; validation accuracy : 0.9022556390977443\n",
      "Epoch 62:\t train loss : 0.5682665886533459; train accuracy : 0.9829536028313886; \n",
      " validation loss : 0.6417990703984097; validation accuracy : 0.9097744360902256\n",
      "Epoch 63:\t train loss : 0.5660788910740571; train accuracy : 0.9851103246142786; \n",
      " validation loss : 0.6565969635953262; validation accuracy : 0.8947368421052632\n",
      "Epoch 64:\t train loss : 0.5566824647088402; train accuracy : 0.9946773212409445; \n",
      " validation loss : 0.6585822370909941; validation accuracy : 0.8872180451127819\n",
      "Epoch 65:\t train loss : 0.5569871481823854; train accuracy : 0.9942763921915612; \n",
      " validation loss : 0.6596612016025479; validation accuracy : 0.8947368421052632\n",
      "Epoch 66:\t train loss : 0.5559344349279067; train accuracy : 0.9954100536415418; \n",
      " validation loss : 0.6670132538859278; validation accuracy : 0.8796992481203008\n",
      "Epoch 67:\t train loss : 0.5820377819445116; train accuracy : 0.9686445833102915; \n",
      " validation loss : 0.6417443262470314; validation accuracy : 0.9097744360902256\n",
      "Epoch 68:\t train loss : 0.5574722253647716; train accuracy : 0.9939445888403473; \n",
      " validation loss : 0.6426875580195597; validation accuracy : 0.9097744360902256\n",
      "Epoch 69:\t train loss : 0.5549277548649874; train accuracy : 0.9964745893933529; \n",
      " validation loss : 0.6502702546202827; validation accuracy : 0.9022556390977443\n",
      "Epoch 70:\t train loss : 0.5540571852622719; train accuracy : 0.997373223469557; \n",
      " validation loss : 0.6522175248279117; validation accuracy : 0.9022556390977443\n",
      "Epoch 71:\t train loss : 0.5542749595975703; train accuracy : 0.9973040977713875; \n",
      " validation loss : 0.636146772464924; validation accuracy : 0.9172932330827067\n",
      "Epoch 72:\t train loss : 0.5741739960032929; train accuracy : 0.9770917436266107; \n",
      " validation loss : 0.6678394952618407; validation accuracy : 0.8796992481203008\n",
      "Epoch 73:\t train loss : 0.5610551647926808; train accuracy : 0.9901841508599237; \n",
      " validation loss : 0.6612875847566173; validation accuracy : 0.8872180451127819\n",
      "Epoch 74:\t train loss : 0.5776706681833421; train accuracy : 0.9729856771553392; \n",
      " validation loss : 0.6560615799096776; validation accuracy : 0.8947368421052632\n",
      "Epoch 75:\t train loss : 0.5580208457854956; train accuracy : 0.9932948072775535; \n",
      " validation loss : 0.6359540600036775; validation accuracy : 0.9172932330827067\n",
      "Epoch 76:\t train loss : 0.5545108884475699; train accuracy : 0.9969861195598075; \n",
      " validation loss : 0.6540979108439013; validation accuracy : 0.8947368421052632\n",
      "Epoch 77:\t train loss : 0.5556083344680184; train accuracy : 0.995824807830559; \n",
      " validation loss : 0.664886807654736; validation accuracy : 0.8872180451127819\n",
      "Epoch 78:\t train loss : 0.5579651895949732; train accuracy : 0.9934330586738926; \n",
      " validation loss : 0.6330712438609922; validation accuracy : 0.9172932330827067\n",
      "Epoch 79:\t train loss : 0.5535906109060178; train accuracy : 0.9978294530774761; \n",
      " validation loss : 0.6648138029261274; validation accuracy : 0.8872180451127819\n",
      "Epoch 80:\t train loss : 0.5587646509437142; train accuracy : 0.9926588508543936; \n",
      " validation loss : 0.6872807516994921; validation accuracy : 0.8646616541353384\n",
      "Epoch 81:\t train loss : 0.5764812805336639; train accuracy : 0.9743820162583642; \n",
      " validation loss : 0.6944231475989668; validation accuracy : 0.8571428571428571\n",
      "Epoch 82:\t train loss : 0.5561917422014248; train accuracy : 0.9951750262677653; \n",
      " validation loss : 0.6646277432159533; validation accuracy : 0.8872180451127819\n",
      "Epoch 83:\t train loss : 0.5541268366218611; train accuracy : 0.997373223469557; \n",
      " validation loss : 0.6691816210571034; validation accuracy : 0.8796992481203008\n",
      "Epoch 84:\t train loss : 0.5538704233985234; train accuracy : 0.9974423491677266; \n",
      " validation loss : 0.6713515908275658; validation accuracy : 0.8796992481203008\n",
      "Epoch 85:\t train loss : 0.5559691990559077; train accuracy : 0.9954377039208095; \n",
      " validation loss : 0.6607102839840813; validation accuracy : 0.8872180451127819\n",
      "Epoch 86:\t train loss : 0.5544294288832167; train accuracy : 0.9969446441409058; \n",
      " validation loss : 0.623365155047946; validation accuracy : 0.9323308270676691\n",
      "Epoch 87:\t train loss : 0.554491421335043; train accuracy : 0.9968893435823701; \n",
      " validation loss : 0.6202133785938255; validation accuracy : 0.9323308270676691\n",
      "Epoch 88:\t train loss : 0.5600413322305969; train accuracy : 0.9911795609135652; \n",
      " validation loss : 0.6501995234668936; validation accuracy : 0.9022556390977443\n",
      "Epoch 89:\t train loss : 0.5562724029835037; train accuracy : 0.995064425150694; \n",
      " validation loss : 0.6642885713652874; validation accuracy : 0.8872180451127819\n",
      "Epoch 90:\t train loss : 0.5558067510607749; train accuracy : 0.9956312558756844; \n",
      " validation loss : 0.6410587953852156; validation accuracy : 0.9097744360902256\n",
      "Epoch 91:\t train loss : 0.5645243649887585; train accuracy : 0.9864928385776697; \n",
      " validation loss : 0.6541666714025337; validation accuracy : 0.8947368421052632\n",
      "Epoch 92:\t train loss : 0.5762445775706637; train accuracy : 0.9743958413979982; \n",
      " validation loss : 0.6412794938578783; validation accuracy : 0.9097744360902256\n",
      "Epoch 93:\t train loss : 0.5678341896154802; train accuracy : 0.9830642039484598; \n",
      " validation loss : 0.6651842718999268; validation accuracy : 0.8872180451127819\n",
      "Epoch 94:\t train loss : 0.561177710805469; train accuracy : 0.9900182491843168; \n",
      " validation loss : 0.6665897284155542; validation accuracy : 0.8872180451127819\n",
      "Epoch 95:\t train loss : 0.5574226007789795; train accuracy : 0.993986064259249; \n",
      " validation loss : 0.6395360995383587; validation accuracy : 0.9097744360902256\n",
      "Epoch 96:\t train loss : 0.554979419019038; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.6527775458724294; validation accuracy : 0.9022556390977443\n",
      "Epoch 97:\t train loss : 0.5551299838495973; train accuracy : 0.9962395620195764; \n",
      " validation loss : 0.6446951936995098; validation accuracy : 0.9097744360902256\n",
      "Epoch 98:\t train loss : 0.580939347481282; train accuracy : 0.9698197201791738; \n",
      " validation loss : 0.6769910566678824; validation accuracy : 0.8721804511278195\n",
      "Epoch 99:\t train loss : 0.5611675097871378; train accuracy : 0.9898799977879776; \n",
      " validation loss : 0.6692267779588983; validation accuracy : 0.8796992481203008\n",
      "Epoch 100:\t train loss : 0.5755135133341701; train accuracy : 0.9756815793839517; \n",
      " validation loss : 0.6725486836337017; validation accuracy : 0.8796992481203008\n",
      "Epoch 101:\t train loss : 0.565763370980994; train accuracy : 0.9854697782447602; \n",
      " validation loss : 0.6281386069871575; validation accuracy : 0.924812030075188\n",
      "Epoch 102:\t train loss : 0.5554311499716408; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6681336785536349; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103:\t train loss : 0.5551548196624905; train accuracy : 0.9962395620195764; \n",
      " validation loss : 0.6397742787787575; validation accuracy : 0.9097744360902256\n",
      "Epoch 104:\t train loss : 0.5551623177467809; train accuracy : 0.9961566111817729; \n",
      " validation loss : 0.6491872654563278; validation accuracy : 0.9022556390977443\n",
      "Epoch 105:\t train loss : 0.5536197898284905; train accuracy : 0.9977465022396727; \n",
      " validation loss : 0.6743168182789802; validation accuracy : 0.8796992481203008\n",
      "Epoch 106:\t train loss : 0.5531365296048849; train accuracy : 0.9982856826853951; \n",
      " validation loss : 0.6505788428636166; validation accuracy : 0.9022556390977443\n",
      "Epoch 107:\t train loss : 0.5544029820888124; train accuracy : 0.9969446441409058; \n",
      " validation loss : 0.6481168104467815; validation accuracy : 0.9022556390977443\n",
      "Epoch 108:\t train loss : 0.5527008647940624; train accuracy : 0.9987142620140463; \n",
      " validation loss : 0.656703321774188; validation accuracy : 0.8947368421052632\n",
      "Epoch 109:\t train loss : 0.5528601563443698; train accuracy : 0.9985760106177072; \n",
      " validation loss : 0.6662404607844149; validation accuracy : 0.8872180451127819\n",
      "Epoch 110:\t train loss : 0.5533166148933861; train accuracy : 0.9981197810097882; \n",
      " validation loss : 0.6710012422540411; validation accuracy : 0.8796992481203008\n",
      "Epoch 111:\t train loss : 0.553696651572597; train accuracy : 0.9976359011226014; \n",
      " validation loss : 0.6771041336290835; validation accuracy : 0.8721804511278195\n",
      "Epoch 112:\t train loss : 0.5527792819803943; train accuracy : 0.9987004368744125; \n",
      " validation loss : 0.6439791471285766; validation accuracy : 0.9097744360902256\n",
      "Epoch 113:\t train loss : 0.5532090256531345; train accuracy : 0.9981889067079578; \n",
      " validation loss : 0.6686873351274997; validation accuracy : 0.8796992481203008\n",
      "Epoch 114:\t train loss : 0.5525784284687169; train accuracy : 0.9987833877122159; \n",
      " validation loss : 0.6588604607379281; validation accuracy : 0.8947368421052632\n",
      "Epoch 115:\t train loss : 0.5526153602242624; train accuracy : 0.9988663385500194; \n",
      " validation loss : 0.6493772087692827; validation accuracy : 0.9022556390977443\n",
      "Epoch 116:\t train loss : 0.5664374462443358; train accuracy : 0.9846540950063596; \n",
      " validation loss : 0.636379721115509; validation accuracy : 0.9172932330827067\n",
      "Epoch 117:\t train loss : 0.570025374573284; train accuracy : 0.980893657025936; \n",
      " validation loss : 0.6581567413067109; validation accuracy : 0.8872180451127819\n",
      "Epoch 118:\t train loss : 0.5557498087283232; train accuracy : 0.9955483050378808; \n",
      " validation loss : 0.6446229506598078; validation accuracy : 0.9097744360902256\n",
      "Epoch 119:\t train loss : 0.5560049830317495; train accuracy : 0.9953271028037383; \n",
      " validation loss : 0.6562040194938659; validation accuracy : 0.8947368421052632\n",
      "Epoch 120:\t train loss : 0.556281675530526; train accuracy : 0.9950367748714262; \n",
      " validation loss : 0.6713349196399401; validation accuracy : 0.8796992481203008\n",
      "Epoch 121:\t train loss : 0.5548621917289817; train accuracy : 0.9966543162085937; \n",
      " validation loss : 0.6325136086635832; validation accuracy : 0.9172932330827067\n",
      "Epoch 122:\t train loss : 0.5540232960748268; train accuracy : 0.9973593983299232; \n",
      " validation loss : 0.6701847398791007; validation accuracy : 0.8796992481203008\n",
      "Epoch 123:\t train loss : 0.5580214209236488; train accuracy : 0.9932118564397501; \n",
      " validation loss : 0.6630726199178825; validation accuracy : 0.8872180451127819\n",
      "Epoch 124:\t train loss : 0.5667651083391437; train accuracy : 0.9842531659569762; \n",
      " validation loss : 0.6496758489836268; validation accuracy : 0.9022556390977443\n",
      "Epoch 125:\t train loss : 0.5545953414064106; train accuracy : 0.9968478681634685; \n",
      " validation loss : 0.6682449587495644; validation accuracy : 0.8796992481203008\n",
      "Epoch 126:\t train loss : 0.553754146945331; train accuracy : 0.9976497262622352; \n",
      " validation loss : 0.6304858518028634; validation accuracy : 0.9172932330827067\n",
      "Epoch 127:\t train loss : 0.5550927005212112; train accuracy : 0.9962119117403085; \n",
      " validation loss : 0.6773717276974522; validation accuracy : 0.8721804511278195\n",
      "Epoch 128:\t train loss : 0.5535170015370123; train accuracy : 0.9978571033567439; \n",
      " validation loss : 0.6537454520078927; validation accuracy : 0.8947368421052632\n",
      "Epoch 129:\t train loss : 0.552973207987227; train accuracy : 0.9984930597799038; \n",
      " validation loss : 0.6597255791398488; validation accuracy : 0.8872180451127819\n",
      "Epoch 130:\t train loss : 0.5540369099314084; train accuracy : 0.997221146933584; \n",
      " validation loss : 0.6716469948440759; validation accuracy : 0.8796992481203008\n",
      "Epoch 131:\t train loss : 0.6163010232642178; train accuracy : 0.9336669800364984; \n",
      " validation loss : 0.7034754465969015; validation accuracy : 0.849624060150376\n",
      "Epoch 132:\t train loss : 0.582416259870671; train accuracy : 0.9685754576121219; \n",
      " validation loss : 0.6359253502916243; validation accuracy : 0.9172932330827067\n",
      "Epoch 133:\t train loss : 0.5691934222047662; train accuracy : 0.9818890670795775; \n",
      " validation loss : 0.7246301282995767; validation accuracy : 0.8195488721804511\n",
      "Epoch 134:\t train loss : 0.6080401145134863; train accuracy : 0.9423076923076923; \n",
      " validation loss : 0.7140621750311666; validation accuracy : 0.8345864661654135\n",
      "Epoch 135:\t train loss : 0.5792843126175955; train accuracy : 0.9718520157053586; \n",
      " validation loss : 0.6642025117104907; validation accuracy : 0.8872180451127819\n",
      "Epoch 136:\t train loss : 0.5673505778679103; train accuracy : 0.9837554609301554; \n",
      " validation loss : 0.679587035696003; validation accuracy : 0.8721804511278195\n",
      "Epoch 137:\t train loss : 0.5626716481971276; train accuracy : 0.9886495603605596; \n",
      " validation loss : 0.682187051752378; validation accuracy : 0.8646616541353384\n",
      "Early stopping at epoch 137\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.554491421335043; Train accuracy : 0.9968893435823701; \n",
      " Validation loss : 0.6202133785938255; Validation accuracy : 0.9323308270676691\n",
      "------------------------------ Let's train model 38 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9115624079008372; train accuracy : 0.618840900293093; \n",
      " validation loss : 0.8558268513995678; validation accuracy : 0.6842105263157895\n",
      "Epoch 2:\t train loss : 0.7908035010236688; train accuracy : 0.751548415638998; \n",
      " validation loss : 0.759131083485438; validation accuracy : 0.7969924812030075\n",
      "Epoch 3:\t train loss : 0.7305350442755726; train accuracy : 0.8167892495714206; \n",
      " validation loss : 0.7438294083138799; validation accuracy : 0.7969924812030075\n",
      "Epoch 4:\t train loss : 0.6816744192000923; train accuracy : 0.8683570204059061; \n",
      " validation loss : 0.6851464864961491; validation accuracy : 0.849624060150376\n",
      "Epoch 5:\t train loss : 0.6563946252540799; train accuracy : 0.8949012885030139; \n",
      " validation loss : 0.7004841490258407; validation accuracy : 0.8571428571428571\n",
      "Epoch 6:\t train loss : 0.6422644305230052; train accuracy : 0.9088508543936293; \n",
      " validation loss : 0.6794859114695541; validation accuracy : 0.8721804511278195\n",
      "Epoch 7:\t train loss : 0.6308080680384173; train accuracy : 0.9191229331416247; \n",
      " validation loss : 0.6699026432398157; validation accuracy : 0.8721804511278195\n",
      "Epoch 8:\t train loss : 0.6164154965936197; train accuracy : 0.9340540839462479; \n",
      " validation loss : 0.6944381605105503; validation accuracy : 0.849624060150376\n",
      "Epoch 9:\t train loss : 0.6098341235304545; train accuracy : 0.9415473096278273; \n",
      " validation loss : 0.642955472097932; validation accuracy : 0.9097744360902256\n",
      "Epoch 10:\t train loss : 0.601947727966663; train accuracy : 0.9496764917325665; \n",
      " validation loss : 0.6417929030028822; validation accuracy : 0.9097744360902256\n",
      "Epoch 11:\t train loss : 0.5984084694265123; train accuracy : 0.9529253995465354; \n",
      " validation loss : 0.6620301541363279; validation accuracy : 0.8721804511278195\n",
      "Epoch 12:\t train loss : 0.5935633181195574; train accuracy : 0.9581236520488857; \n",
      " validation loss : 0.6705029311941386; validation accuracy : 0.8796992481203008\n",
      "Epoch 13:\t train loss : 0.5882373857977803; train accuracy : 0.9634463308079412; \n",
      " validation loss : 0.6481829072986823; validation accuracy : 0.9022556390977443\n",
      "Epoch 14:\t train loss : 0.5840198671525989; train accuracy : 0.9677735995133551; \n",
      " validation loss : 0.6460555054721443; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\t train loss : 0.5898402645154495; train accuracy : 0.9615937620969972; \n",
      " validation loss : 0.6821906911675194; validation accuracy : 0.849624060150376\n",
      "Epoch 16:\t train loss : 0.6025204531426036; train accuracy : 0.948197201791738; \n",
      " validation loss : 0.6597172138878712; validation accuracy : 0.8947368421052632\n",
      "Epoch 17:\t train loss : 0.6016329009612741; train accuracy : 0.9492064369850135; \n",
      " validation loss : 0.6312427103418486; validation accuracy : 0.9172932330827067\n",
      "Epoch 18:\t train loss : 0.5868043478529416; train accuracy : 0.9645108665597523; \n",
      " validation loss : 0.656204239466596; validation accuracy : 0.8872180451127819\n",
      "Epoch 19:\t train loss : 0.5845557475207422; train accuracy : 0.9665155118066693; \n",
      " validation loss : 0.644947311739081; validation accuracy : 0.9097744360902256\n",
      "Epoch 20:\t train loss : 0.5776315837502105; train accuracy : 0.9737598849748382; \n",
      " validation loss : 0.6714776605467422; validation accuracy : 0.8796992481203008\n",
      "Epoch 21:\t train loss : 0.5733294030303722; train accuracy : 0.9782115799369574; \n",
      " validation loss : 0.6235653492064186; validation accuracy : 0.924812030075188\n",
      "Epoch 22:\t train loss : 0.5729793649507344; train accuracy : 0.978736935243046; \n",
      " validation loss : 0.6478033762725117; validation accuracy : 0.9022556390977443\n",
      "Epoch 23:\t train loss : 0.5756627778255752; train accuracy : 0.9757783553613891; \n",
      " validation loss : 0.6518228309274996; validation accuracy : 0.9022556390977443\n",
      "Epoch 24:\t train loss : 0.5718362938818059; train accuracy : 0.9792346402698667; \n",
      " validation loss : 0.6509693481183081; validation accuracy : 0.8947368421052632\n",
      "Epoch 25:\t train loss : 0.589858794243755; train accuracy : 0.9604186252281148; \n",
      " validation loss : 0.6428177954155093; validation accuracy : 0.9097744360902256\n",
      "Epoch 26:\t train loss : 0.5800733948850767; train accuracy : 0.9712022341425648; \n",
      " validation loss : 0.6363688030054873; validation accuracy : 0.9172932330827067\n",
      "Epoch 27:\t train loss : 0.5794825129047404; train accuracy : 0.971796715146823; \n",
      " validation loss : 0.629419022283007; validation accuracy : 0.9097744360902256\n",
      "Epoch 28:\t train loss : 0.5768881329315362; train accuracy : 0.9742161145827573; \n",
      " validation loss : 0.6243537989575317; validation accuracy : 0.9172932330827067\n",
      "Epoch 29:\t train loss : 0.5686724258693278; train accuracy : 0.9830089033899242; \n",
      " validation loss : 0.6232044805166728; validation accuracy : 0.924812030075188\n",
      "Epoch 30:\t train loss : 0.5701271616479318; train accuracy : 0.9810180832826412; \n",
      " validation loss : 0.6257425578134475; validation accuracy : 0.924812030075188\n",
      "Epoch 31:\t train loss : 0.5653585931736825; train accuracy : 0.9858707072941437; \n",
      " validation loss : 0.6380552447859399; validation accuracy : 0.9097744360902256\n",
      "Epoch 32:\t train loss : 0.5658138415370434; train accuracy : 0.9857324558978046; \n",
      " validation loss : 0.6687342685851051; validation accuracy : 0.8796992481203008\n",
      "Epoch 33:\t train loss : 0.5885251944804855; train accuracy : 0.961939390587845; \n",
      " validation loss : 0.6478637487956439; validation accuracy : 0.8947368421052632\n",
      "Epoch 34:\t train loss : 0.5682129667658848; train accuracy : 0.9827047503179782; \n",
      " validation loss : 0.6216101942508132; validation accuracy : 0.924812030075188\n",
      "Epoch 35:\t train loss : 0.5645122349972793; train accuracy : 0.9869490681855887; \n",
      " validation loss : 0.6344186125328491; validation accuracy : 0.9172932330827067\n",
      "Epoch 36:\t train loss : 0.5608705634188736; train accuracy : 0.990598905048941; \n",
      " validation loss : 0.651989512934781; validation accuracy : 0.8872180451127819\n",
      "Epoch 37:\t train loss : 0.5584736526133088; train accuracy : 0.9931427307415804; \n",
      " validation loss : 0.6322963714972104; validation accuracy : 0.924812030075188\n",
      "Epoch 38:\t train loss : 0.5601260293078687; train accuracy : 0.9914284134269756; \n",
      " validation loss : 0.6493996156857952; validation accuracy : 0.9022556390977443\n",
      "Epoch 39:\t train loss : 0.5623467292696492; train accuracy : 0.9892163910855499; \n",
      " validation loss : 0.6505275041382371; validation accuracy : 0.9022556390977443\n",
      "Epoch 40:\t train loss : 0.5600223159932356; train accuracy : 0.9912625117513687; \n",
      " validation loss : 0.6251703228665112; validation accuracy : 0.924812030075188\n",
      "Epoch 41:\t train loss : 0.5608856631913992; train accuracy : 0.9903777028147984; \n",
      " validation loss : 0.6442016888070622; validation accuracy : 0.9097744360902256\n",
      "Epoch 42:\t train loss : 0.5656850425267329; train accuracy : 0.9856356799203672; \n",
      " validation loss : 0.6590450816251134; validation accuracy : 0.8872180451127819\n",
      "Epoch 43:\t train loss : 0.5679899135340241; train accuracy : 0.9833683570204059; \n",
      " validation loss : 0.637190362671754; validation accuracy : 0.9097744360902256\n",
      "Epoch 44:\t train loss : 0.5650276946686192; train accuracy : 0.9863269369020627; \n",
      " validation loss : 0.6472438127202268; validation accuracy : 0.9022556390977443\n",
      "Epoch 45:\t train loss : 0.5717303173269918; train accuracy : 0.9793314162473041; \n",
      " validation loss : 0.6503330660545418; validation accuracy : 0.9022556390977443\n",
      "Epoch 46:\t train loss : 0.5626740508637914; train accuracy : 0.9888984128739701; \n",
      " validation loss : 0.631837707976443; validation accuracy : 0.9172932330827067\n",
      "Epoch 47:\t train loss : 0.5612303274094914; train accuracy : 0.9901565005806559; \n",
      " validation loss : 0.6362766519117026; validation accuracy : 0.9172932330827067\n",
      "Epoch 48:\t train loss : 0.5627567365027406; train accuracy : 0.9885251341038545; \n",
      " validation loss : 0.6405180152585963; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.6804248250015852; train accuracy : 0.8683155449870044; \n",
      " validation loss : 0.6645579943201193; validation accuracy : 0.8947368421052632\n",
      "Epoch 50:\t train loss : 0.5747234464438925; train accuracy : 0.9764972626223525; \n",
      " validation loss : 0.6430148161190347; validation accuracy : 0.9022556390977443\n",
      "Epoch 51:\t train loss : 0.5630432077817003; train accuracy : 0.9882071558922745; \n",
      " validation loss : 0.6371415831964082; validation accuracy : 0.9097744360902256\n",
      "Epoch 52:\t train loss : 0.559434976473174; train accuracy : 0.9918984681745285; \n",
      " validation loss : 0.6142218912574495; validation accuracy : 0.9323308270676691\n",
      "Epoch 53:\t train loss : 0.55862135177005; train accuracy : 0.9927832771110988; \n",
      " validation loss : 0.6240553207782663; validation accuracy : 0.9323308270676691\n",
      "Epoch 54:\t train loss : 0.56790682365091; train accuracy : 0.9831471547862634; \n",
      " validation loss : 0.6577485696148616; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5576408071773348; train accuracy : 0.9938063374440081; \n",
      " validation loss : 0.6104721278546588; validation accuracy : 0.9473684210526315\n",
      "Epoch 56:\t train loss : 0.5602192488391552; train accuracy : 0.9911657357739313; \n",
      " validation loss : 0.6283779300387327; validation accuracy : 0.9172932330827067\n",
      "Epoch 57:\t train loss : 0.5577164976486565; train accuracy : 0.9937233866062047; \n",
      " validation loss : 0.6170014549534466; validation accuracy : 0.9398496240601504\n",
      "Epoch 58:\t train loss : 0.5800614807811979; train accuracy : 0.9707736548139136; \n",
      " validation loss : 0.6673605084275109; validation accuracy : 0.8796992481203008\n",
      "Epoch 59:\t train loss : 0.5818464910220105; train accuracy : 0.9690593374993087; \n",
      " validation loss : 0.6860369231785749; validation accuracy : 0.8646616541353384\n",
      "Epoch 60:\t train loss : 0.5689784856708482; train accuracy : 0.9823176464082287; \n",
      " validation loss : 0.6671815985067298; validation accuracy : 0.8796992481203008\n",
      "Epoch 61:\t train loss : 0.5704182919450942; train accuracy : 0.9808383564674004; \n",
      " validation loss : 0.6246982940338077; validation accuracy : 0.924812030075188\n",
      "Epoch 62:\t train loss : 0.5844859283849191; train accuracy : 0.9665293369463032; \n",
      " validation loss : 0.648387329576421; validation accuracy : 0.9022556390977443\n",
      "Epoch 63:\t train loss : 0.569177759189357; train accuracy : 0.9820964441740861; \n",
      " validation loss : 0.6173217938292003; validation accuracy : 0.9323308270676691\n",
      "Epoch 64:\t train loss : 0.5636099958571233; train accuracy : 0.9876265000276503; \n",
      " validation loss : 0.6477222315489255; validation accuracy : 0.9022556390977443\n",
      "Epoch 65:\t train loss : 0.5601687148551037; train accuracy : 0.9909860089586905; \n",
      " validation loss : 0.608091730722586; validation accuracy : 0.9473684210526315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66:\t train loss : 0.5585543147254098; train accuracy : 0.9927141514129293; \n",
      " validation loss : 0.6380538271821046; validation accuracy : 0.9097744360902256\n",
      "Epoch 67:\t train loss : 0.5590695513304011; train accuracy : 0.9921749709672067; \n",
      " validation loss : 0.6481435936380697; validation accuracy : 0.9022556390977443\n",
      "Epoch 68:\t train loss : 0.5601980069953704; train accuracy : 0.9909998340983244; \n",
      " validation loss : 0.6463445050336339; validation accuracy : 0.9097744360902256\n",
      "Epoch 69:\t train loss : 0.5596892939343509; train accuracy : 0.9917740419178234; \n",
      " validation loss : 0.6303161195833951; validation accuracy : 0.9172932330827067\n",
      "Epoch 70:\t train loss : 0.5579420616440592; train accuracy : 0.9934054083946248; \n",
      " validation loss : 0.635232265245145; validation accuracy : 0.9172932330827067\n",
      "Epoch 71:\t train loss : 0.5565572196026368; train accuracy : 0.9946220206824089; \n",
      " validation loss : 0.6049324455455126; validation accuracy : 0.9473684210526315\n",
      "Epoch 72:\t train loss : 0.5570439484485354; train accuracy : 0.994456119006802; \n",
      " validation loss : 0.6416128866497459; validation accuracy : 0.9097744360902256\n",
      "Epoch 73:\t train loss : 0.5573113157404512; train accuracy : 0.9941104905159542; \n",
      " validation loss : 0.6399824388476515; validation accuracy : 0.9097744360902256\n",
      "Epoch 74:\t train loss : 0.5561223016838122; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.6088815772140119; validation accuracy : 0.9473684210526315\n",
      "Epoch 75:\t train loss : 0.5578370007145876; train accuracy : 0.9934745340927943; \n",
      " validation loss : 0.6268096192708252; validation accuracy : 0.924812030075188\n",
      "Epoch 76:\t train loss : 0.5585114375116109; train accuracy : 0.9927141514129293; \n",
      " validation loss : 0.6341357655939799; validation accuracy : 0.9172932330827067\n",
      "Epoch 77:\t train loss : 0.5627121570229523; train accuracy : 0.9885527843831222; \n",
      " validation loss : 0.6220238296306025; validation accuracy : 0.924812030075188\n",
      "Epoch 78:\t train loss : 0.5593444850137503; train accuracy : 0.9918846430348947; \n",
      " validation loss : 0.6221416115271063; validation accuracy : 0.9323308270676691\n",
      "Epoch 79:\t train loss : 0.5565391994942891; train accuracy : 0.9948017474976497; \n",
      " validation loss : 0.6249507323824773; validation accuracy : 0.924812030075188\n",
      "Epoch 80:\t train loss : 0.5572867657759482; train accuracy : 0.993999889398883; \n",
      " validation loss : 0.627469667959427; validation accuracy : 0.924812030075188\n",
      "Epoch 81:\t train loss : 0.5687267358940754; train accuracy : 0.9823867721063982; \n",
      " validation loss : 0.7436161710167434; validation accuracy : 0.8120300751879699\n",
      "Epoch 82:\t train loss : 0.6221587274049069; train accuracy : 0.928026323065863; \n",
      " validation loss : 0.6674149484651394; validation accuracy : 0.8872180451127819\n",
      "Epoch 83:\t train loss : 0.5799182383878275; train accuracy : 0.9707460045346458; \n",
      " validation loss : 0.621902630964125; validation accuracy : 0.924812030075188\n",
      "Epoch 84:\t train loss : 0.5692541921022977; train accuracy : 0.9819028922192115; \n",
      " validation loss : 0.6414277405187025; validation accuracy : 0.9022556390977443\n",
      "Epoch 85:\t train loss : 0.568309532153396; train accuracy : 0.9830365536691921; \n",
      " validation loss : 0.6216071347617658; validation accuracy : 0.9323308270676691\n",
      "Epoch 86:\t train loss : 0.5659635551640296; train accuracy : 0.9849997234972073; \n",
      " validation loss : 0.6547972833618179; validation accuracy : 0.8947368421052632\n",
      "Epoch 87:\t train loss : 0.5747999196891699; train accuracy : 0.9764557872034507; \n",
      " validation loss : 0.6389857293060242; validation accuracy : 0.9097744360902256\n",
      "Epoch 88:\t train loss : 0.5637551901051617; train accuracy : 0.9877371011447216; \n",
      " validation loss : 0.6696488271929678; validation accuracy : 0.8796992481203008\n",
      "Epoch 89:\t train loss : 0.559958412428998; train accuracy : 0.9914975391251452; \n",
      " validation loss : 0.6427435966262343; validation accuracy : 0.9097744360902256\n",
      "Epoch 90:\t train loss : 0.5707526002769596; train accuracy : 0.9803268263009457; \n",
      " validation loss : 0.6127035614678423; validation accuracy : 0.9398496240601504\n",
      "Epoch 91:\t train loss : 0.5613684029848072; train accuracy : 0.9899905989050489; \n",
      " validation loss : 0.6417875689296475; validation accuracy : 0.9097744360902256\n",
      "Epoch 92:\t train loss : 0.5661367360359254; train accuracy : 0.9851379748935465; \n",
      " validation loss : 0.6521948780367605; validation accuracy : 0.9022556390977443\n",
      "Epoch 93:\t train loss : 0.5609900319336054; train accuracy : 0.9902671016977271; \n",
      " validation loss : 0.6513703891720949; validation accuracy : 0.9022556390977443\n",
      "Epoch 94:\t train loss : 0.5588379778621523; train accuracy : 0.9924652988995188; \n",
      " validation loss : 0.6409065050812673; validation accuracy : 0.9097744360902256\n",
      "Epoch 95:\t train loss : 0.5596870092642022; train accuracy : 0.991677265940386; \n",
      " validation loss : 0.6651661465426184; validation accuracy : 0.8796992481203008\n",
      "Epoch 96:\t train loss : 0.5562088120129679; train accuracy : 0.995216501686667; \n",
      " validation loss : 0.6020020484331196; validation accuracy : 0.9473684210526315\n",
      "Epoch 97:\t train loss : 0.5579268259358431; train accuracy : 0.9935574849305978; \n",
      " validation loss : 0.6615612810593369; validation accuracy : 0.8872180451127819\n",
      "Epoch 98:\t train loss : 0.5622681309829669; train accuracy : 0.9891196151081126; \n",
      " validation loss : 0.6404494392182709; validation accuracy : 0.9172932330827067\n",
      "Epoch 99:\t train loss : 0.560234876920453; train accuracy : 0.9912072111928331; \n",
      " validation loss : 0.6736138856568116; validation accuracy : 0.8796992481203008\n",
      "Epoch 100:\t train loss : 0.6086514138729398; train accuracy : 0.9420173643753802; \n",
      " validation loss : 0.6571926464580157; validation accuracy : 0.8947368421052632\n",
      "Epoch 101:\t train loss : 0.5738008180189553; train accuracy : 0.977202344743682; \n",
      " validation loss : 0.6540383152810529; validation accuracy : 0.8947368421052632\n",
      "Epoch 102:\t train loss : 0.595063563692278; train accuracy : 0.955759553171487; \n",
      " validation loss : 0.656531263102992; validation accuracy : 0.8947368421052632\n",
      "Epoch 103:\t train loss : 0.5818733587709258; train accuracy : 0.9691975888956479; \n",
      " validation loss : 0.6586857465793576; validation accuracy : 0.8947368421052632\n",
      "Epoch 104:\t train loss : 0.5624651346663637; train accuracy : 0.9887739866172648; \n",
      " validation loss : 0.6229939522106273; validation accuracy : 0.9323308270676691\n",
      "Epoch 105:\t train loss : 0.5606950770287179; train accuracy : 0.9907786318641818; \n",
      " validation loss : 0.6312305781668605; validation accuracy : 0.9172932330827067\n",
      "Epoch 106:\t train loss : 0.560180478012067; train accuracy : 0.9911795609135652; \n",
      " validation loss : 0.6185488750666784; validation accuracy : 0.924812030075188\n",
      "Epoch 107:\t train loss : 0.5758333837903864; train accuracy : 0.9752668251949345; \n",
      " validation loss : 0.6978710365314195; validation accuracy : 0.849624060150376\n",
      "Epoch 108:\t train loss : 0.5676494365935457; train accuracy : 0.9838522369075927; \n",
      " validation loss : 0.6042186506347136; validation accuracy : 0.9473684210526315\n",
      "Epoch 109:\t train loss : 0.5591886350387408; train accuracy : 0.9922302715257424; \n",
      " validation loss : 0.6205830871213228; validation accuracy : 0.924812030075188\n",
      "Epoch 110:\t train loss : 0.5592463310374989; train accuracy : 0.9920367195708677; \n",
      " validation loss : 0.6338503107660224; validation accuracy : 0.9172932330827067\n",
      "Epoch 111:\t train loss : 0.5600274083414539; train accuracy : 0.9911933860531992; \n",
      " validation loss : 0.6294542799008171; validation accuracy : 0.9172932330827067\n",
      "Epoch 112:\t train loss : 0.5583870810969971; train accuracy : 0.9928800530885362; \n",
      " validation loss : 0.6203830736619227; validation accuracy : 0.9323308270676691\n",
      "Epoch 113:\t train loss : 0.5573223492876511; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.616658305217114; validation accuracy : 0.924812030075188\n",
      "Epoch 114:\t train loss : 0.5560272853858867; train accuracy : 0.9952856273848366; \n",
      " validation loss : 0.6361643837500399; validation accuracy : 0.9097744360902256\n",
      "Epoch 115:\t train loss : 0.5553859358604586; train accuracy : 0.9961151357628711; \n",
      " validation loss : 0.6487569666440818; validation accuracy : 0.9022556390977443\n",
      "Epoch 116:\t train loss : 0.5576685374010019; train accuracy : 0.9934607089531604; \n",
      " validation loss : 0.6135150640259373; validation accuracy : 0.9323308270676691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117:\t train loss : 0.5674477656279023; train accuracy : 0.9836310346734503; \n",
      " validation loss : 0.6583578130388746; validation accuracy : 0.8947368421052632\n",
      "Epoch 118:\t train loss : 0.5637362244819565; train accuracy : 0.9874329480727755; \n",
      " validation loss : 0.65700523935343; validation accuracy : 0.8947368421052632\n",
      "Epoch 119:\t train loss : 0.5660702763142793; train accuracy : 0.9851103246142786; \n",
      " validation loss : 0.6611246808401591; validation accuracy : 0.8947368421052632\n",
      "Epoch 120:\t train loss : 0.5731099641936177; train accuracy : 0.9780042028424487; \n",
      " validation loss : 0.6742779542011743; validation accuracy : 0.8796992481203008\n",
      "Epoch 121:\t train loss : 0.5597844874186393; train accuracy : 0.9914837139855113; \n",
      " validation loss : 0.6624849219294313; validation accuracy : 0.8872180451127819\n",
      "Epoch 122:\t train loss : 0.5576333156138561; train accuracy : 0.9937095614665707; \n",
      " validation loss : 0.629836351594307; validation accuracy : 0.9172932330827067\n",
      "Epoch 123:\t train loss : 0.555907911266263; train accuracy : 0.9954377039208095; \n",
      " validation loss : 0.6538691502615519; validation accuracy : 0.8947368421052632\n",
      "Epoch 124:\t train loss : 0.5615816119441939; train accuracy : 0.9897279212520046; \n",
      " validation loss : 0.6343791625894892; validation accuracy : 0.9172932330827067\n",
      "Epoch 125:\t train loss : 0.557616481581436; train accuracy : 0.9937648620251064; \n",
      " validation loss : 0.6292292279463717; validation accuracy : 0.9172932330827067\n",
      "Epoch 126:\t train loss : 0.5583861484105577; train accuracy : 0.9928385776696345; \n",
      " validation loss : 0.6424841075496569; validation accuracy : 0.9097744360902256\n",
      "Epoch 127:\t train loss : 0.5597623406634198; train accuracy : 0.9916081402422164; \n",
      " validation loss : 0.6206478679391979; validation accuracy : 0.9323308270676691\n",
      "Epoch 128:\t train loss : 0.5574468344026243; train accuracy : 0.9939169385610794; \n",
      " validation loss : 0.6569208163007242; validation accuracy : 0.8947368421052632\n",
      "Epoch 129:\t train loss : 0.5558809605554641; train accuracy : 0.9955483050378808; \n",
      " validation loss : 0.6340204994015133; validation accuracy : 0.9172932330827067\n",
      "Epoch 130:\t train loss : 0.5562084608134441; train accuracy : 0.9951059005695957; \n",
      " validation loss : 0.6470758397351999; validation accuracy : 0.9022556390977443\n",
      "Epoch 131:\t train loss : 0.5563690330222841; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6440069020435725; validation accuracy : 0.9097744360902256\n",
      "Epoch 132:\t train loss : 0.555455463145795; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6415570634543079; validation accuracy : 0.9097744360902256\n",
      "Epoch 133:\t train loss : 0.5562321706500917; train accuracy : 0.99505060001106; \n",
      " validation loss : 0.619832191807329; validation accuracy : 0.9323308270676691\n",
      "Epoch 134:\t train loss : 0.5564807385812774; train accuracy : 0.9948846983354531; \n",
      " validation loss : 0.6562726066652053; validation accuracy : 0.8947368421052632\n",
      "Epoch 135:\t train loss : 0.5553943274456462; train accuracy : 0.9960598352043355; \n",
      " validation loss : 0.6328280457940993; validation accuracy : 0.9172932330827067\n",
      "Epoch 136:\t train loss : 0.5563375794526324; train accuracy : 0.9948985234750871; \n",
      " validation loss : 0.6173921370623188; validation accuracy : 0.9323308270676691\n",
      "Epoch 137:\t train loss : 0.5550300106177104; train accuracy : 0.9963916385555494; \n",
      " validation loss : 0.6283797613477046; validation accuracy : 0.924812030075188\n",
      "Epoch 138:\t train loss : 0.5558064475787686; train accuracy : 0.9957280318531218; \n",
      " validation loss : 0.6260000058028256; validation accuracy : 0.9172932330827067\n",
      "Epoch 139:\t train loss : 0.558403585248783; train accuracy : 0.9929630039263396; \n",
      " validation loss : 0.6158311075757189; validation accuracy : 0.9398496240601504\n",
      "Epoch 140:\t train loss : 0.5574143659432775; train accuracy : 0.993999889398883; \n",
      " validation loss : 0.6676683875629846; validation accuracy : 0.8796992481203008\n",
      "Epoch 141:\t train loss : 0.5834598926816096; train accuracy : 0.9671929436487309; \n",
      " validation loss : 0.7141979949213991; validation accuracy : 0.8345864661654135\n",
      "Epoch 142:\t train loss : 0.5930116053811556; train accuracy : 0.9576259470220649; \n",
      " validation loss : 0.6394624324284129; validation accuracy : 0.9097744360902256\n",
      "Epoch 143:\t train loss : 0.5640543107119838; train accuracy : 0.9871426201404634; \n",
      " validation loss : 0.6462199037931777; validation accuracy : 0.9022556390977443\n",
      "Epoch 144:\t train loss : 0.5590729701507655; train accuracy : 0.9922302715257424; \n",
      " validation loss : 0.6382188018521513; validation accuracy : 0.9172932330827067\n",
      "Epoch 145:\t train loss : 0.5587144718665332; train accuracy : 0.9925205994580545; \n",
      " validation loss : 0.6416908248246418; validation accuracy : 0.9097744360902256\n",
      "Epoch 146:\t train loss : 0.5575481992195388; train accuracy : 0.9938754631421777; \n",
      " validation loss : 0.6465665297618856; validation accuracy : 0.9097744360902256\n",
      "Early stopping at epoch 146\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5562088120129679; Train accuracy : 0.995216501686667; \n",
      " Validation loss : 0.6020020484331196; Validation accuracy : 0.9473684210526315\n",
      "------------------------------ Let's train model 39 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9029454785493644; train accuracy : 0.6267350550240558; \n",
      " validation loss : 0.814724399625115; validation accuracy : 0.6992481203007519\n",
      "Epoch 2:\t train loss : 0.7715204082856422; train accuracy : 0.7734474368191119; \n",
      " validation loss : 0.7833624582977989; validation accuracy : 0.7593984962406015\n",
      "Epoch 3:\t train loss : 0.720131715993498; train accuracy : 0.8276143339047725; \n",
      " validation loss : 0.7547264851824877; validation accuracy : 0.7819548872180451\n",
      "Epoch 4:\t train loss : 0.6917098094262254; train accuracy : 0.8576701874688935; \n",
      " validation loss : 0.7439510135466688; validation accuracy : 0.8045112781954887\n",
      "Epoch 5:\t train loss : 0.6702646482144116; train accuracy : 0.8794309572526683; \n",
      " validation loss : 0.6857196048528681; validation accuracy : 0.8721804511278195\n",
      "Epoch 6:\t train loss : 0.6466327381956616; train accuracy : 0.90383232870652; \n",
      " validation loss : 0.6536369555857342; validation accuracy : 0.9097744360902256\n",
      "Epoch 7:\t train loss : 0.6299269296013725; train accuracy : 0.921390256041586; \n",
      " validation loss : 0.6411037631906233; validation accuracy : 0.9097744360902256\n",
      "Epoch 8:\t train loss : 0.6145277427836069; train accuracy : 0.9368744124315656; \n",
      " validation loss : 0.6506175856021527; validation accuracy : 0.8947368421052632\n",
      "Epoch 9:\t train loss : 0.6015052492965721; train accuracy : 0.9510175302770558; \n",
      " validation loss : 0.6604757509507024; validation accuracy : 0.8947368421052632\n",
      "Epoch 10:\t train loss : 0.5970738546765142; train accuracy : 0.9549162196538185; \n",
      " validation loss : 0.6439733054420446; validation accuracy : 0.9097744360902256\n",
      "Epoch 11:\t train loss : 0.6016140853367344; train accuracy : 0.9493170381020848; \n",
      " validation loss : 0.6517459454586022; validation accuracy : 0.9097744360902256\n",
      "Epoch 12:\t train loss : 0.5836133148821503; train accuracy : 0.9674694464414091; \n",
      " validation loss : 0.6770028006171513; validation accuracy : 0.8721804511278195\n",
      "Epoch 13:\t train loss : 0.5787834270719254; train accuracy : 0.9732068793894818; \n",
      " validation loss : 0.6950864029683168; validation accuracy : 0.849624060150376\n",
      "Epoch 14:\t train loss : 0.5857609891594276; train accuracy : 0.9660178067798485; \n",
      " validation loss : 0.6782323151381382; validation accuracy : 0.8721804511278195\n",
      "Epoch 15:\t train loss : 0.5788063379607727; train accuracy : 0.9728474257590002; \n",
      " validation loss : 0.7124878634328566; validation accuracy : 0.8421052631578947\n",
      "Epoch 16:\t train loss : 0.5871045876351164; train accuracy : 0.9640961123707349; \n",
      " validation loss : 0.6875509868505519; validation accuracy : 0.8571428571428571\n",
      "Epoch 17:\t train loss : 0.5758405393705962; train accuracy : 0.9758474810595587; \n",
      " validation loss : 0.6417006347895367; validation accuracy : 0.9022556390977443\n",
      "Epoch 18:\t train loss : 0.5745618945627481; train accuracy : 0.9765249129016204; \n",
      " validation loss : 0.6539296112835499; validation accuracy : 0.9022556390977443\n",
      "Epoch 19:\t train loss : 0.5969733927916623; train accuracy : 0.9538240336227396; \n",
      " validation loss : 0.6586153611053144; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:\t train loss : 0.5721732101460761; train accuracy : 0.9795940939003484; \n",
      " validation loss : 0.6618110096165603; validation accuracy : 0.8947368421052632\n",
      "Epoch 21:\t train loss : 0.5722723573144664; train accuracy : 0.9787645855223138; \n",
      " validation loss : 0.6838517797125327; validation accuracy : 0.8646616541353384\n",
      "Epoch 22:\t train loss : 0.5721003468481239; train accuracy : 0.979206989990599; \n",
      " validation loss : 0.6381027419300355; validation accuracy : 0.9172932330827067\n",
      "Epoch 23:\t train loss : 0.5635424326443927; train accuracy : 0.9879168279599624; \n",
      " validation loss : 0.6425743112375089; validation accuracy : 0.9097744360902256\n",
      "Epoch 24:\t train loss : 0.5638702835350213; train accuracy : 0.987515898910579; \n",
      " validation loss : 0.6775034260432715; validation accuracy : 0.8721804511278195\n",
      "Epoch 25:\t train loss : 0.5608255887950293; train accuracy : 0.9908892329812531; \n",
      " validation loss : 0.65576417790574; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5607914552160705; train accuracy : 0.9908062821434497; \n",
      " validation loss : 0.6732604170671517; validation accuracy : 0.8796992481203008\n",
      "Epoch 27:\t train loss : 0.5636469720761424; train accuracy : 0.9881518553337388; \n",
      " validation loss : 0.6462205786597011; validation accuracy : 0.9097744360902256\n",
      "Epoch 28:\t train loss : 0.5602258082315271; train accuracy : 0.9912763368910026; \n",
      " validation loss : 0.626871469662368; validation accuracy : 0.9172932330827067\n",
      "Epoch 29:\t train loss : 0.6000647589092792; train accuracy : 0.9501603716197533; \n",
      " validation loss : 0.6525887944971775; validation accuracy : 0.9022556390977443\n",
      "Epoch 30:\t train loss : 0.572934621436518; train accuracy : 0.9781977547973234; \n",
      " validation loss : 0.6591829024704184; validation accuracy : 0.8947368421052632\n",
      "Epoch 31:\t train loss : 0.563580747399865; train accuracy : 0.9877924017032572; \n",
      " validation loss : 0.6725406236436475; validation accuracy : 0.8796992481203008\n",
      "Epoch 32:\t train loss : 0.5578147101714516; train accuracy : 0.993820162583642; \n",
      " validation loss : 0.632153492510247; validation accuracy : 0.924812030075188\n",
      "Epoch 33:\t train loss : 0.557729090592379; train accuracy : 0.9938063374440081; \n",
      " validation loss : 0.676820846163667; validation accuracy : 0.8646616541353384\n",
      "Epoch 34:\t train loss : 0.5569053166296185; train accuracy : 0.9945252447049715; \n",
      " validation loss : 0.6302942647211429; validation accuracy : 0.924812030075188\n",
      "Epoch 35:\t train loss : 0.5684064051604716; train accuracy : 0.9826771000387103; \n",
      " validation loss : 0.6393075140529471; validation accuracy : 0.9172932330827067\n",
      "Epoch 36:\t train loss : 0.5735250687126261; train accuracy : 0.9777000497705027; \n",
      " validation loss : 0.6344992774292302; validation accuracy : 0.924812030075188\n",
      "Epoch 37:\t train loss : 0.5591589734481669; train accuracy : 0.9923132223635459; \n",
      " validation loss : 0.6804720898857177; validation accuracy : 0.8721804511278195\n",
      "Epoch 38:\t train loss : 0.5568492433562577; train accuracy : 0.994594370403141; \n",
      " validation loss : 0.6582062354324678; validation accuracy : 0.8947368421052632\n",
      "Epoch 39:\t train loss : 0.556804462856545; train accuracy : 0.9948017474976497; \n",
      " validation loss : 0.6550119143769266; validation accuracy : 0.8947368421052632\n",
      "Epoch 40:\t train loss : 0.5561716266354141; train accuracy : 0.9952856273848366; \n",
      " validation loss : 0.6253612716298994; validation accuracy : 0.9172932330827067\n",
      "Epoch 41:\t train loss : 0.5608984455574737; train accuracy : 0.9904744787922358; \n",
      " validation loss : 0.6712527557307203; validation accuracy : 0.8796992481203008\n",
      "Epoch 42:\t train loss : 0.5594864200125577; train accuracy : 0.9918155173367251; \n",
      " validation loss : 0.6121487569054033; validation accuracy : 0.9398496240601504\n",
      "Epoch 43:\t train loss : 0.5575429088683665; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.6027658235570815; validation accuracy : 0.9473684210526315\n",
      "Epoch 44:\t train loss : 0.5791776240793144; train accuracy : 0.9713543106785378; \n",
      " validation loss : 0.7140213680445674; validation accuracy : 0.8270676691729323\n",
      "Epoch 45:\t train loss : 0.602125079010025; train accuracy : 0.948376928606979; \n",
      " validation loss : 0.6647135705206147; validation accuracy : 0.8796992481203008\n",
      "Epoch 46:\t train loss : 0.5902158048994213; train accuracy : 0.9598241442238566; \n",
      " validation loss : 0.6487656495081942; validation accuracy : 0.9097744360902256\n",
      "Epoch 47:\t train loss : 0.5685450104595641; train accuracy : 0.9826494497594426; \n",
      " validation loss : 0.6640178167587902; validation accuracy : 0.8796992481203008\n",
      "Epoch 48:\t train loss : 0.5629334697825226; train accuracy : 0.9884974838245866; \n",
      " validation loss : 0.6849588615484119; validation accuracy : 0.8571428571428571\n",
      "Epoch 49:\t train loss : 0.5616688757132182; train accuracy : 0.9895896698556655; \n",
      " validation loss : 0.6565593057163324; validation accuracy : 0.9022556390977443\n",
      "Epoch 50:\t train loss : 0.5598742565084082; train accuracy : 0.9914698888458773; \n",
      " validation loss : 0.674317509785752; validation accuracy : 0.8721804511278195\n",
      "Epoch 51:\t train loss : 0.5664834344393687; train accuracy : 0.9845849693081901; \n",
      " validation loss : 0.6703235384850038; validation accuracy : 0.8872180451127819\n",
      "Epoch 52:\t train loss : 0.567369279070903; train accuracy : 0.9834374827185755; \n",
      " validation loss : 0.6714131915925667; validation accuracy : 0.8796992481203008\n",
      "Epoch 53:\t train loss : 0.5590074147228342; train accuracy : 0.9923546977824476; \n",
      " validation loss : 0.6643919430666769; validation accuracy : 0.8872180451127819\n",
      "Epoch 54:\t train loss : 0.5582691063390709; train accuracy : 0.9929353536470719; \n",
      " validation loss : 0.660714521781329; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5566840750355154; train accuracy : 0.9947326217994802; \n",
      " validation loss : 0.6868540558188646; validation accuracy : 0.849624060150376\n",
      "Epoch 56:\t train loss : 0.5555191466969583; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6672364878165143; validation accuracy : 0.8721804511278195\n",
      "Epoch 57:\t train loss : 0.5577755561073388; train accuracy : 0.993377758115357; \n",
      " validation loss : 0.6379277757278743; validation accuracy : 0.9172932330827067\n",
      "Epoch 58:\t train loss : 0.5613980738330492; train accuracy : 0.9897140961123707; \n",
      " validation loss : 0.7126552560151539; validation accuracy : 0.8345864661654135\n",
      "Epoch 59:\t train loss : 0.5790575607846569; train accuracy : 0.9717828900071891; \n",
      " validation loss : 0.6854986981952824; validation accuracy : 0.8646616541353384\n",
      "Epoch 60:\t train loss : 0.5574631641053647; train accuracy : 0.9938892882818117; \n",
      " validation loss : 0.6814807689098658; validation accuracy : 0.8721804511278195\n",
      "Epoch 61:\t train loss : 0.6236918664012027; train accuracy : 0.9263396560305259; \n",
      " validation loss : 0.676369280360747; validation accuracy : 0.8721804511278195\n",
      "Epoch 62:\t train loss : 0.5670988708109028; train accuracy : 0.9841840402588066; \n",
      " validation loss : 0.6357446085768014; validation accuracy : 0.9097744360902256\n",
      "Epoch 63:\t train loss : 0.5593359068874985; train accuracy : 0.9921058452690372; \n",
      " validation loss : 0.6417668175391593; validation accuracy : 0.9097744360902256\n",
      "Epoch 64:\t train loss : 0.5570144279358581; train accuracy : 0.9943869933086324; \n",
      " validation loss : 0.6455352649354922; validation accuracy : 0.9022556390977443\n",
      "Epoch 65:\t train loss : 0.5559157588337437; train accuracy : 0.9955621301775148; \n",
      " validation loss : 0.6694255838775498; validation accuracy : 0.8872180451127819\n",
      "Epoch 66:\t train loss : 0.554601812220462; train accuracy : 0.9968063927445667; \n",
      " validation loss : 0.6457432602127298; validation accuracy : 0.9022556390977443\n",
      "Epoch 67:\t train loss : 0.5542134246187994; train accuracy : 0.9972073217939501; \n",
      " validation loss : 0.6498737417776965; validation accuracy : 0.9022556390977443\n",
      "Epoch 68:\t train loss : 0.5547431184754775; train accuracy : 0.9966404910689598; \n",
      " validation loss : 0.6719358674956488; validation accuracy : 0.8721804511278195\n",
      "Epoch 69:\t train loss : 0.5574413377825198; train accuracy : 0.993999889398883; \n",
      " validation loss : 0.613177792820089; validation accuracy : 0.9398496240601504\n",
      "Epoch 70:\t train loss : 0.55440130181284; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.6081926886242766; validation accuracy : 0.9473684210526315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71:\t train loss : 0.556880985421384; train accuracy : 0.9943869933086324; \n",
      " validation loss : 0.6139309856700398; validation accuracy : 0.9398496240601504\n",
      "Epoch 72:\t train loss : 0.5571517687474399; train accuracy : 0.9939584139799812; \n",
      " validation loss : 0.6310972540130133; validation accuracy : 0.9172932330827067\n",
      "Epoch 73:\t train loss : 0.5566859914021475; train accuracy : 0.994594370403141; \n",
      " validation loss : 0.6237352495828118; validation accuracy : 0.924812030075188\n",
      "Epoch 74:\t train loss : 0.5538887888402446; train accuracy : 0.9975944257036996; \n",
      " validation loss : 0.6731970749336602; validation accuracy : 0.8721804511278195\n",
      "Epoch 75:\t train loss : 0.5565600074779835; train accuracy : 0.994760272078748; \n",
      " validation loss : 0.654210829725088; validation accuracy : 0.8947368421052632\n",
      "Epoch 76:\t train loss : 0.5587611699295593; train accuracy : 0.992603550295858; \n",
      " validation loss : 0.6496559636612944; validation accuracy : 0.9022556390977443\n",
      "Epoch 77:\t train loss : 0.5635409251248521; train accuracy : 0.9876403251672842; \n",
      " validation loss : 0.6472420471533105; validation accuracy : 0.9022556390977443\n",
      "Epoch 78:\t train loss : 0.5567247967019445; train accuracy : 0.9946773212409445; \n",
      " validation loss : 0.6728770315330131; validation accuracy : 0.8796992481203008\n",
      "Epoch 79:\t train loss : 0.553894859382988; train accuracy : 0.9973593983299232; \n",
      " validation loss : 0.6349899679943376; validation accuracy : 0.9172932330827067\n",
      "Epoch 80:\t train loss : 0.5582282326010319; train accuracy : 0.9931565558812144; \n",
      " validation loss : 0.6897295713872797; validation accuracy : 0.849624060150376\n",
      "Epoch 81:\t train loss : 0.5546049414812485; train accuracy : 0.9968340430238345; \n",
      " validation loss : 0.6307068784715422; validation accuracy : 0.9172932330827067\n",
      "Epoch 82:\t train loss : 0.5526971830673097; train accuracy : 0.9987557374329481; \n",
      " validation loss : 0.6292765091498664; validation accuracy : 0.924812030075188\n",
      "Epoch 83:\t train loss : 0.5529681923213849; train accuracy : 0.9985068849195377; \n",
      " validation loss : 0.6566353971470065; validation accuracy : 0.8947368421052632\n",
      "Epoch 84:\t train loss : 0.553385461643465; train accuracy : 0.9981197810097882; \n",
      " validation loss : 0.6707144979988002; validation accuracy : 0.8796992481203008\n",
      "Epoch 85:\t train loss : 0.553542044192245; train accuracy : 0.9978847536360117; \n",
      " validation loss : 0.6434073967337693; validation accuracy : 0.9097744360902256\n",
      "Epoch 86:\t train loss : 0.5599287248929555; train accuracy : 0.9912072111928331; \n",
      " validation loss : 0.6520950792763022; validation accuracy : 0.9022556390977443\n",
      "Epoch 87:\t train loss : 0.5542192529453175; train accuracy : 0.9971934966543162; \n",
      " validation loss : 0.6614167599333786; validation accuracy : 0.8872180451127819\n",
      "Epoch 88:\t train loss : 0.5533366447809511; train accuracy : 0.9979400541945473; \n",
      " validation loss : 0.6620939001324424; validation accuracy : 0.8872180451127819\n",
      "Epoch 89:\t train loss : 0.5544506198389413; train accuracy : 0.9968893435823701; \n",
      " validation loss : 0.6782819099135949; validation accuracy : 0.8721804511278195\n",
      "Epoch 90:\t train loss : 0.5572867301414212; train accuracy : 0.9940413648177846; \n",
      " validation loss : 0.6470637871775539; validation accuracy : 0.9022556390977443\n",
      "Epoch 91:\t train loss : 0.5607735937365058; train accuracy : 0.9905159542111375; \n",
      " validation loss : 0.6139593590941926; validation accuracy : 0.9398496240601504\n",
      "Epoch 92:\t train loss : 0.5564196063616175; train accuracy : 0.994912348614721; \n",
      " validation loss : 0.6176230604737507; validation accuracy : 0.9323308270676691\n",
      "Epoch 93:\t train loss : 0.5555990142758352; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.6416819449279495; validation accuracy : 0.9097744360902256\n",
      "Early stopping at epoch 93\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5575429088683665; Train accuracy : 0.9936404357684012; \n",
      " Validation loss : 0.6027658235570815; Validation accuracy : 0.9473684210526315\n",
      "------------------------------ Let's train model 40 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9108983062325335; train accuracy : 0.6161173477852127; \n",
      " validation loss : 0.8514237674299631; validation accuracy : 0.6917293233082706\n",
      "Epoch 2:\t train loss : 0.8017518669856594; train accuracy : 0.7390919648288448; \n",
      " validation loss : 0.7315352650204078; validation accuracy : 0.8345864661654135\n",
      "Epoch 3:\t train loss : 0.7569656656626867; train accuracy : 0.7884062379030028; \n",
      " validation loss : 0.7543762954819386; validation accuracy : 0.7819548872180451\n",
      "Epoch 4:\t train loss : 0.727250061175726; train accuracy : 0.8200243322457557; \n",
      " validation loss : 0.6990845812403398; validation accuracy : 0.8421052631578947\n",
      "Epoch 5:\t train loss : 0.7106401030941589; train accuracy : 0.8379555383509374; \n",
      " validation loss : 0.7111418894284921; validation accuracy : 0.8345864661654135\n",
      "Epoch 6:\t train loss : 0.6753344124915596; train accuracy : 0.8748686611734778; \n",
      " validation loss : 0.7281389359700406; validation accuracy : 0.8195488721804511\n",
      "Epoch 7:\t train loss : 0.6521088349002265; train accuracy : 0.8989382292761157; \n",
      " validation loss : 0.7361105429863097; validation accuracy : 0.8195488721804511\n",
      "Epoch 8:\t train loss : 0.6357195377334215; train accuracy : 0.9146988884587735; \n",
      " validation loss : 0.6961890320423195; validation accuracy : 0.8421052631578947\n",
      "Epoch 9:\t train loss : 0.6185051939009899; train accuracy : 0.932795996239562; \n",
      " validation loss : 0.6793456054598527; validation accuracy : 0.8796992481203008\n",
      "Epoch 10:\t train loss : 0.6092754842769312; train accuracy : 0.9422109163302549; \n",
      " validation loss : 0.6755075168950961; validation accuracy : 0.8872180451127819\n",
      "Epoch 11:\t train loss : 0.6021641480899239; train accuracy : 0.9495658906154952; \n",
      " validation loss : 0.7380329322411099; validation accuracy : 0.8195488721804511\n",
      "Epoch 12:\t train loss : 0.5967245574381571; train accuracy : 0.9549023945141846; \n",
      " validation loss : 0.6562212573979578; validation accuracy : 0.9022556390977443\n",
      "Epoch 13:\t train loss : 0.5954082723479234; train accuracy : 0.9554830503788089; \n",
      " validation loss : 0.7071729606634697; validation accuracy : 0.8421052631578947\n",
      "Epoch 14:\t train loss : 0.5916329610625186; train accuracy : 0.9600591715976331; \n",
      " validation loss : 0.7364043463765596; validation accuracy : 0.8120300751879699\n",
      "Epoch 15:\t train loss : 0.5806940922004803; train accuracy : 0.9711331084443953; \n",
      " validation loss : 0.739413004982126; validation accuracy : 0.8120300751879699\n",
      "Epoch 16:\t train loss : 0.5828633790025339; train accuracy : 0.9687966598462644; \n",
      " validation loss : 0.6879010720307676; validation accuracy : 0.8646616541353384\n",
      "Epoch 17:\t train loss : 0.5756129926331206; train accuracy : 0.9758336559199248; \n",
      " validation loss : 0.6767711757091912; validation accuracy : 0.8796992481203008\n",
      "Epoch 18:\t train loss : 0.5760683643133206; train accuracy : 0.975183874357131; \n",
      " validation loss : 0.6726769333744503; validation accuracy : 0.8872180451127819\n",
      "Epoch 19:\t train loss : 0.5738652502126546; train accuracy : 0.9778797765857435; \n",
      " validation loss : 0.7182764982272459; validation accuracy : 0.8270676691729323\n",
      "Epoch 20:\t train loss : 0.5703889252135151; train accuracy : 0.9811563346789802; \n",
      " validation loss : 0.6612766392266755; validation accuracy : 0.8872180451127819\n",
      "Epoch 21:\t train loss : 0.5654854048443474; train accuracy : 0.9861333849471879; \n",
      " validation loss : 0.6847690881520164; validation accuracy : 0.8646616541353384\n",
      "Epoch 22:\t train loss : 0.567360276132437; train accuracy : 0.9841563899795388; \n",
      " validation loss : 0.6504523315297984; validation accuracy : 0.9022556390977443\n",
      "Epoch 23:\t train loss : 0.5733894690802401; train accuracy : 0.9775064978156279; \n",
      " validation loss : 0.6879140832041154; validation accuracy : 0.8646616541353384\n",
      "Epoch 24:\t train loss : 0.5628841910393194; train accuracy : 0.9887601614776309; \n",
      " validation loss : 0.6815412337790842; validation accuracy : 0.8721804511278195\n",
      "Epoch 25:\t train loss : 0.5641825966177612; train accuracy : 0.9874329480727755; \n",
      " validation loss : 0.7962722213420365; validation accuracy : 0.7518796992481203\n",
      "Epoch 26:\t train loss : 0.5627470995998375; train accuracy : 0.9888707625947022; \n",
      " validation loss : 0.7244459555183702; validation accuracy : 0.8270676691729323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:\t train loss : 0.5628154138505467; train accuracy : 0.9884836586849527; \n",
      " validation loss : 0.7023614910868826; validation accuracy : 0.849624060150376\n",
      "Epoch 28:\t train loss : 0.5767341561505435; train accuracy : 0.9743543659790964; \n",
      " validation loss : 0.7421123394965745; validation accuracy : 0.8120300751879699\n",
      "Epoch 29:\t train loss : 0.5794577543234568; train accuracy : 0.9717275894486535; \n",
      " validation loss : 0.6974116604667988; validation accuracy : 0.8421052631578947\n",
      "Epoch 30:\t train loss : 0.5644795124374509; train accuracy : 0.987211745838633; \n",
      " validation loss : 0.6621608469565604; validation accuracy : 0.8872180451127819\n",
      "Epoch 31:\t train loss : 0.5629986031969288; train accuracy : 0.9884974838245866; \n",
      " validation loss : 0.6608814358936623; validation accuracy : 0.8872180451127819\n",
      "Epoch 32:\t train loss : 0.5615027788270337; train accuracy : 0.9903224022562628; \n",
      " validation loss : 0.6778125098845529; validation accuracy : 0.8721804511278195\n",
      "Epoch 33:\t train loss : 0.590626253670602; train accuracy : 0.9600591715976331; \n",
      " validation loss : 0.7461333875892112; validation accuracy : 0.8045112781954887\n",
      "Epoch 34:\t train loss : 0.571547257989799; train accuracy : 0.9799535475308301; \n",
      " validation loss : 0.7185582638036523; validation accuracy : 0.8270676691729323\n",
      "Epoch 35:\t train loss : 0.5668643232812719; train accuracy : 0.9844467179118509; \n",
      " validation loss : 0.7234597822881612; validation accuracy : 0.8345864661654135\n",
      "Epoch 36:\t train loss : 0.5665014406790603; train accuracy : 0.984737045844163; \n",
      " validation loss : 0.7400835054581669; validation accuracy : 0.8045112781954887\n",
      "Epoch 37:\t train loss : 0.5625172520455576; train accuracy : 0.9888845877343361; \n",
      " validation loss : 0.7446134220687382; validation accuracy : 0.8045112781954887\n",
      "Epoch 38:\t train loss : 0.5657818631161164; train accuracy : 0.9856495050600012; \n",
      " validation loss : 0.6873856416429834; validation accuracy : 0.8646616541353384\n",
      "Epoch 39:\t train loss : 0.5598487003341658; train accuracy : 0.9916081402422164; \n",
      " validation loss : 0.7437225879964261; validation accuracy : 0.7969924812030075\n",
      "Epoch 40:\t train loss : 0.5622379573069556; train accuracy : 0.9894514184593264; \n",
      " validation loss : 0.7015800845907729; validation accuracy : 0.849624060150376\n",
      "Epoch 41:\t train loss : 0.5624068144027088; train accuracy : 0.9890228391306752; \n",
      " validation loss : 0.6634647366914191; validation accuracy : 0.8872180451127819\n",
      "Epoch 42:\t train loss : 0.5598089058687835; train accuracy : 0.9917602167781895; \n",
      " validation loss : 0.6997259473763618; validation accuracy : 0.849624060150376\n",
      "Epoch 43:\t train loss : 0.5611005135953585; train accuracy : 0.9901841508599237; \n",
      " validation loss : 0.6880654114541762; validation accuracy : 0.8646616541353384\n",
      "Epoch 44:\t train loss : 0.5600392497428129; train accuracy : 0.9913316374495382; \n",
      " validation loss : 0.7117518129163578; validation accuracy : 0.8421052631578947\n",
      "Epoch 45:\t train loss : 0.5568813245919464; train accuracy : 0.9944284687275341; \n",
      " validation loss : 0.6829641346451603; validation accuracy : 0.8646616541353384\n",
      "Epoch 46:\t train loss : 0.5633828615969343; train accuracy : 0.9878062268428911; \n",
      " validation loss : 0.6954134572957891; validation accuracy : 0.8571428571428571\n",
      "Epoch 47:\t train loss : 0.5595225068319687; train accuracy : 0.9917878670574573; \n",
      " validation loss : 0.6724665427054201; validation accuracy : 0.8796992481203008\n",
      "Epoch 48:\t train loss : 0.5637163810431275; train accuracy : 0.9874191229331416; \n",
      " validation loss : 0.6873769817787638; validation accuracy : 0.8646616541353384\n",
      "Epoch 49:\t train loss : 0.5658658128327404; train accuracy : 0.9851241497539125; \n",
      " validation loss : 0.6800100056493309; validation accuracy : 0.8721804511278195\n",
      "Epoch 50:\t train loss : 0.5567339692187124; train accuracy : 0.9948017474976497; \n",
      " validation loss : 0.6805236448458375; validation accuracy : 0.8721804511278195\n",
      "Epoch 51:\t train loss : 0.5554833633447168; train accuracy : 0.9958662832494608; \n",
      " validation loss : 0.6754084945889592; validation accuracy : 0.8646616541353384\n",
      "Epoch 52:\t train loss : 0.555969166644763; train accuracy : 0.9954100536415418; \n",
      " validation loss : 0.6726249512111733; validation accuracy : 0.8721804511278195\n",
      "Epoch 53:\t train loss : 0.555624666165781; train accuracy : 0.9959768843665321; \n",
      " validation loss : 0.6730073690774578; validation accuracy : 0.8796992481203008\n",
      "Epoch 54:\t train loss : 0.5582667487081511; train accuracy : 0.9931150804623127; \n",
      " validation loss : 0.7003229094153076; validation accuracy : 0.849624060150376\n",
      "Epoch 55:\t train loss : 0.5881941228481149; train accuracy : 0.9625891721506388; \n",
      " validation loss : 0.7527243113375508; validation accuracy : 0.7969924812030075\n",
      "Epoch 56:\t train loss : 0.5781089447635447; train accuracy : 0.9726953492230271; \n",
      " validation loss : 0.7136486297644192; validation accuracy : 0.8345864661654135\n",
      "Epoch 57:\t train loss : 0.5602217867045225; train accuracy : 0.9911242603550295; \n",
      " validation loss : 0.6889795350628022; validation accuracy : 0.8646616541353384\n",
      "Epoch 58:\t train loss : 0.563652607906866; train accuracy : 0.9873085218160703; \n",
      " validation loss : 0.7478524623168563; validation accuracy : 0.8045112781954887\n",
      "Epoch 59:\t train loss : 0.5573056087608919; train accuracy : 0.9942349167726594; \n",
      " validation loss : 0.7616344809805986; validation accuracy : 0.7894736842105263\n",
      "Epoch 60:\t train loss : 0.5773410351223052; train accuracy : 0.97348338218216; \n",
      " validation loss : 0.7375307606964517; validation accuracy : 0.8120300751879699\n",
      "Epoch 61:\t train loss : 0.5736551531930227; train accuracy : 0.9772852955814854; \n",
      " validation loss : 0.6877532531148475; validation accuracy : 0.8646616541353384\n",
      "Epoch 62:\t train loss : 0.5637358358747323; train accuracy : 0.9873776475142398; \n",
      " validation loss : 0.70898525622808; validation accuracy : 0.8421052631578947\n",
      "Epoch 63:\t train loss : 0.5686449925744459; train accuracy : 0.98274622573688; \n",
      " validation loss : 0.7358369308769954; validation accuracy : 0.8120300751879699\n",
      "Epoch 64:\t train loss : 0.5669172377480866; train accuracy : 0.9841702151191727; \n",
      " validation loss : 0.8782142709661978; validation accuracy : 0.6691729323308271\n",
      "Epoch 65:\t train loss : 0.5633917477534557; train accuracy : 0.9878753525410606; \n",
      " validation loss : 0.7995251296593915; validation accuracy : 0.7518796992481203\n",
      "Epoch 66:\t train loss : 0.5577885254865788; train accuracy : 0.9935298346513299; \n",
      " validation loss : 0.8428413750333433; validation accuracy : 0.706766917293233\n",
      "Epoch 67:\t train loss : 0.5584174748131657; train accuracy : 0.9929768290659735; \n",
      " validation loss : 0.723277448666824; validation accuracy : 0.8270676691729323\n",
      "Epoch 68:\t train loss : 0.5573314258720529; train accuracy : 0.9940690150970525; \n",
      " validation loss : 0.7988940682533117; validation accuracy : 0.7518796992481203\n",
      "Epoch 69:\t train loss : 0.5571163783076464; train accuracy : 0.9942072664933915; \n",
      " validation loss : 0.7858723215353423; validation accuracy : 0.7669172932330827\n",
      "Epoch 70:\t train loss : 0.5552511497074288; train accuracy : 0.9962119117403085; \n",
      " validation loss : 0.7720989892053621; validation accuracy : 0.7744360902255639\n",
      "Epoch 71:\t train loss : 0.5603848251295825; train accuracy : 0.9909860089586905; \n",
      " validation loss : 0.7531461983545455; validation accuracy : 0.7969924812030075\n",
      "Epoch 72:\t train loss : 0.5546976506485747; train accuracy : 0.9966543162085937; \n",
      " validation loss : 0.7320839178861208; validation accuracy : 0.8195488721804511\n",
      "Early stopping at epoch 72\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.567360276132437; Train accuracy : 0.9841563899795388; \n",
      " Validation loss : 0.6504523315297984; Validation accuracy : 0.9022556390977443\n",
      "------------------------------ Let's train model 41 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8964871603956498; train accuracy : 0.6318503566886026; \n",
      " validation loss : 0.8777732053736104; validation accuracy : 0.6766917293233082\n",
      "Epoch 2:\t train loss : 0.7788317594251567; train accuracy : 0.7682630094563955; \n",
      " validation loss : 0.8107354974169624; validation accuracy : 0.7293233082706767\n",
      "Epoch 3:\t train loss : 0.7189838324346176; train accuracy : 0.8309323674169109; \n",
      " validation loss : 0.8032697272747765; validation accuracy : 0.7293233082706767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\t train loss : 0.6980349806965263; train accuracy : 0.8516562517281424; \n",
      " validation loss : 0.7484690291724667; validation accuracy : 0.8195488721804511\n",
      "Epoch 5:\t train loss : 0.6630540233956486; train accuracy : 0.8869933086324172; \n",
      " validation loss : 0.7507469019224186; validation accuracy : 0.7969924812030075\n",
      "Epoch 6:\t train loss : 0.6407733031158187; train accuracy : 0.909680362771664; \n",
      " validation loss : 0.7129389465995571; validation accuracy : 0.8270676691729323\n",
      "Epoch 7:\t train loss : 0.6204500975243341; train accuracy : 0.930487197920699; \n",
      " validation loss : 0.7764525263695715; validation accuracy : 0.7669172932330827\n",
      "Epoch 8:\t train loss : 0.6076096837540488; train accuracy : 0.9442432118564398; \n",
      " validation loss : 0.6956846722335898; validation accuracy : 0.8571428571428571\n",
      "Epoch 9:\t train loss : 0.5984421782278814; train accuracy : 0.9536304816678648; \n",
      " validation loss : 0.7224755056653597; validation accuracy : 0.8270676691729323\n",
      "Epoch 10:\t train loss : 0.5876448493783236; train accuracy : 0.9644417408615827; \n",
      " validation loss : 0.7143106754473668; validation accuracy : 0.8270676691729323\n",
      "Epoch 11:\t train loss : 0.579499992553033; train accuracy : 0.9728612508986341; \n",
      " validation loss : 0.7038977378295757; validation accuracy : 0.849624060150376\n",
      "Epoch 12:\t train loss : 0.585438190433422; train accuracy : 0.9660316319194824; \n",
      " validation loss : 0.7224209609177483; validation accuracy : 0.8345864661654135\n",
      "Epoch 13:\t train loss : 0.5748815235484172; train accuracy : 0.9768981916717359; \n",
      " validation loss : 0.6580640866015346; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.5719946051656991; train accuracy : 0.9798291212741249; \n",
      " validation loss : 0.6882272714261006; validation accuracy : 0.8571428571428571\n",
      "Epoch 15:\t train loss : 0.5659165151117973; train accuracy : 0.9859536581319471; \n",
      " validation loss : 0.7086716649023683; validation accuracy : 0.8345864661654135\n",
      "Epoch 16:\t train loss : 0.5749019183583838; train accuracy : 0.976580213460156; \n",
      " validation loss : 0.6980618434619874; validation accuracy : 0.849624060150376\n",
      "Epoch 17:\t train loss : 0.5716722665719189; train accuracy : 0.9800917989271691; \n",
      " validation loss : 0.749366278692726; validation accuracy : 0.7894736842105263\n",
      "Epoch 18:\t train loss : 0.5885169364831749; train accuracy : 0.9618011391915058; \n",
      " validation loss : 0.678175565370942; validation accuracy : 0.8721804511278195\n",
      "Epoch 19:\t train loss : 0.5713714011095088; train accuracy : 0.9799120721119283; \n",
      " validation loss : 0.7247037388204131; validation accuracy : 0.8195488721804511\n",
      "Epoch 20:\t train loss : 0.5714403312774288; train accuracy : 0.9799811978100978; \n",
      " validation loss : 0.7110337209228714; validation accuracy : 0.8421052631578947\n",
      "Epoch 21:\t train loss : 0.563099356470121; train accuracy : 0.9887186860587291; \n",
      " validation loss : 0.6898134562211341; validation accuracy : 0.8646616541353384\n",
      "Epoch 22:\t train loss : 0.5884728877445022; train accuracy : 0.9622711939390588; \n",
      " validation loss : 0.7104533616391204; validation accuracy : 0.8421052631578947\n",
      "Epoch 23:\t train loss : 0.5641667749736243; train accuracy : 0.9875297240502129; \n",
      " validation loss : 0.7186721794897729; validation accuracy : 0.8270676691729323\n",
      "Epoch 24:\t train loss : 0.5650812524782826; train accuracy : 0.9862301609246253; \n",
      " validation loss : 0.6926814084159205; validation accuracy : 0.8571428571428571\n",
      "Epoch 25:\t train loss : 0.5620483072093665; train accuracy : 0.9897140961123707; \n",
      " validation loss : 0.7012870845577079; validation accuracy : 0.849624060150376\n",
      "Epoch 26:\t train loss : 0.5696357886519112; train accuracy : 0.981501963169828; \n",
      " validation loss : 0.7132199775423721; validation accuracy : 0.8345864661654135\n",
      "Epoch 27:\t train loss : 0.5604459480225271; train accuracy : 0.990916883260521; \n",
      " validation loss : 0.7227273025635395; validation accuracy : 0.8195488721804511\n",
      "Epoch 28:\t train loss : 0.5590052837350905; train accuracy : 0.9926312005751258; \n",
      " validation loss : 0.7317871213371517; validation accuracy : 0.8120300751879699\n",
      "Epoch 29:\t train loss : 0.5653345731012904; train accuracy : 0.9860780843886523; \n",
      " validation loss : 0.6901184966473506; validation accuracy : 0.8646616541353384\n",
      "Epoch 30:\t train loss : 0.5594600258107922; train accuracy : 0.9918708178952608; \n",
      " validation loss : 0.7148905871522631; validation accuracy : 0.8421052631578947\n",
      "Epoch 31:\t train loss : 0.56961126476097; train accuracy : 0.9816816899850689; \n",
      " validation loss : 0.674950185688656; validation accuracy : 0.8796992481203008\n",
      "Epoch 32:\t train loss : 0.5613004800409152; train accuracy : 0.9900873748824863; \n",
      " validation loss : 0.733155424388329; validation accuracy : 0.8195488721804511\n",
      "Epoch 33:\t train loss : 0.5618037549388072; train accuracy : 0.9897002709727368; \n",
      " validation loss : 0.7102530359364395; validation accuracy : 0.8345864661654135\n",
      "Epoch 34:\t train loss : 0.5667296772469623; train accuracy : 0.9841840402588066; \n",
      " validation loss : 0.7073306547654564; validation accuracy : 0.8421052631578947\n",
      "Epoch 35:\t train loss : 0.5647719444726987; train accuracy : 0.9865343139965713; \n",
      " validation loss : 0.742227738690447; validation accuracy : 0.8045112781954887\n",
      "Epoch 36:\t train loss : 0.562338055074665; train accuracy : 0.9892163910855499; \n",
      " validation loss : 0.6832944931245487; validation accuracy : 0.8721804511278195\n",
      "Epoch 37:\t train loss : 0.5578797903514908; train accuracy : 0.9935436597909638; \n",
      " validation loss : 0.7255625014203778; validation accuracy : 0.8195488721804511\n",
      "Epoch 38:\t train loss : 0.5574615235824615; train accuracy : 0.9940690150970525; \n",
      " validation loss : 0.6872822705959342; validation accuracy : 0.8571428571428571\n",
      "Epoch 39:\t train loss : 0.5571972812147586; train accuracy : 0.9944008184482663; \n",
      " validation loss : 0.7030636248661685; validation accuracy : 0.8421052631578947\n",
      "Epoch 40:\t train loss : 0.5589698790258173; train accuracy : 0.9926588508543936; \n",
      " validation loss : 0.6684569800086066; validation accuracy : 0.8872180451127819\n",
      "Epoch 41:\t train loss : 0.5571976169763513; train accuracy : 0.9944699441464359; \n",
      " validation loss : 0.708641010762919; validation accuracy : 0.8421052631578947\n",
      "Epoch 42:\t train loss : 0.6039356505067494; train accuracy : 0.9458469280539733; \n",
      " validation loss : 0.7890559827186834; validation accuracy : 0.7518796992481203\n",
      "Epoch 43:\t train loss : 0.5728509530034929; train accuracy : 0.9785433832881713; \n",
      " validation loss : 0.7252317583731909; validation accuracy : 0.8270676691729323\n",
      "Epoch 44:\t train loss : 0.5819969677405646; train accuracy : 0.9693496654316208; \n",
      " validation loss : 0.7579258849412597; validation accuracy : 0.7894736842105263\n",
      "Epoch 45:\t train loss : 0.5632800821563825; train accuracy : 0.9879997787977659; \n",
      " validation loss : 0.6612380448747026; validation accuracy : 0.8947368421052632\n",
      "Epoch 46:\t train loss : 0.5659716628349907; train accuracy : 0.9852762262898855; \n",
      " validation loss : 0.7805404827421192; validation accuracy : 0.7744360902255639\n",
      "Epoch 47:\t train loss : 0.5672595096330395; train accuracy : 0.9841287397002709; \n",
      " validation loss : 0.704208512565053; validation accuracy : 0.849624060150376\n",
      "Epoch 48:\t train loss : 0.5666506164645608; train accuracy : 0.9846817452856274; \n",
      " validation loss : 0.6948248021892796; validation accuracy : 0.849624060150376\n",
      "Epoch 49:\t train loss : 0.5599437214920381; train accuracy : 0.9913454625891721; \n",
      " validation loss : 0.7056851940685503; validation accuracy : 0.8421052631578947\n",
      "Epoch 50:\t train loss : 0.5576813761553189; train accuracy : 0.9938616380025438; \n",
      " validation loss : 0.6638199426421914; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5591090930181448; train accuracy : 0.9922026212464746; \n",
      " validation loss : 0.6924259361548948; validation accuracy : 0.8571428571428571\n",
      "Epoch 52:\t train loss : 0.6990115162872904; train accuracy : 0.8494027539678151; \n",
      " validation loss : 0.787648624038798; validation accuracy : 0.7593984962406015\n",
      "Epoch 53:\t train loss : 0.6270843522290496; train accuracy : 0.922316540397058; \n",
      " validation loss : 0.7495817757602152; validation accuracy : 0.7894736842105263\n",
      "Epoch 54:\t train loss : 0.599221905532712; train accuracy : 0.9510590056959575; \n",
      " validation loss : 0.7104170062297842; validation accuracy : 0.8421052631578947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55:\t train loss : 0.580144011611197; train accuracy : 0.9709948570480562; \n",
      " validation loss : 0.7681879800331213; validation accuracy : 0.7819548872180451\n",
      "Epoch 56:\t train loss : 0.5642883074528832; train accuracy : 0.9873223469557042; \n",
      " validation loss : 0.7261679234986423; validation accuracy : 0.8270676691729323\n",
      "Epoch 57:\t train loss : 0.5627716719293893; train accuracy : 0.9885389592434883; \n",
      " validation loss : 0.6720642510165905; validation accuracy : 0.8796992481203008\n",
      "Epoch 58:\t train loss : 0.5586180543761335; train accuracy : 0.9930044793452414; \n",
      " validation loss : 0.6951285251988628; validation accuracy : 0.8571428571428571\n",
      "Epoch 59:\t train loss : 0.5629941804414428; train accuracy : 0.9882624564508101; \n",
      " validation loss : 0.7262934388521265; validation accuracy : 0.8195488721804511\n",
      "Epoch 60:\t train loss : 0.5608970371938765; train accuracy : 0.990446828512968; \n",
      " validation loss : 0.704447932229789; validation accuracy : 0.8421052631578947\n",
      "Epoch 61:\t train loss : 0.5582272187405689; train accuracy : 0.9931012553226788; \n",
      " validation loss : 0.7016247400490381; validation accuracy : 0.849624060150376\n",
      "Epoch 62:\t train loss : 0.5637058965416666; train accuracy : 0.987820051982525; \n",
      " validation loss : 0.7227378799614013; validation accuracy : 0.8270676691729323\n",
      "Epoch 63:\t train loss : 0.5575623840792053; train accuracy : 0.9938478128629099; \n",
      " validation loss : 0.6784361304870126; validation accuracy : 0.8721804511278195\n",
      "Early stopping at epoch 63\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5748815235484172; Train accuracy : 0.9768981916717359; \n",
      " Validation loss : 0.6580640866015346; Validation accuracy : 0.8947368421052632\n",
      "------------------------------ Let's train model 42 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8925596518929921; train accuracy : 0.6435879002377924; \n",
      " validation loss : 0.8225016823570361; validation accuracy : 0.706766917293233\n",
      "Epoch 2:\t train loss : 0.773883239463802; train accuracy : 0.7711524636398828; \n",
      " validation loss : 0.778370206794962; validation accuracy : 0.7744360902255639\n",
      "Epoch 3:\t train loss : 0.7367399190691954; train accuracy : 0.8107476635514018; \n",
      " validation loss : 0.7336600915794155; validation accuracy : 0.8045112781954887\n",
      "Epoch 4:\t train loss : 0.6856226454967752; train accuracy : 0.863753248907814; \n",
      " validation loss : 0.7573220698094739; validation accuracy : 0.7969924812030075\n",
      "Epoch 5:\t train loss : 0.6628466227168245; train accuracy : 0.8876430901952109; \n",
      " validation loss : 0.764865458296947; validation accuracy : 0.7744360902255639\n",
      "Epoch 6:\t train loss : 0.6305976849031142; train accuracy : 0.9200768677763645; \n",
      " validation loss : 0.6981094461638909; validation accuracy : 0.849624060150376\n",
      "Epoch 7:\t train loss : 0.6238633734715018; train accuracy : 0.9268511861969806; \n",
      " validation loss : 0.6856933910769729; validation accuracy : 0.8571428571428571\n",
      "Epoch 8:\t train loss : 0.6037165638770924; train accuracy : 0.948058950395399; \n",
      " validation loss : 0.6871854389261457; validation accuracy : 0.8646616541353384\n",
      "Epoch 9:\t train loss : 0.5961679784922895; train accuracy : 0.955759553171487; \n",
      " validation loss : 0.6614494787830776; validation accuracy : 0.8872180451127819\n",
      "Epoch 10:\t train loss : 0.5964830730530275; train accuracy : 0.9554830503788088; \n",
      " validation loss : 0.6601324629465979; validation accuracy : 0.8796992481203008\n",
      "Epoch 11:\t train loss : 0.581485666368579; train accuracy : 0.9698197201791738; \n",
      " validation loss : 0.6541193197659496; validation accuracy : 0.8872180451127819\n",
      "Epoch 12:\t train loss : 0.5762297937988644; train accuracy : 0.9762484101089421; \n",
      " validation loss : 0.661902474730007; validation accuracy : 0.8721804511278195\n",
      "Epoch 13:\t train loss : 0.5761825047009452; train accuracy : 0.9756124536857822; \n",
      " validation loss : 0.6559463015174262; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.58277710956048; train accuracy : 0.9686445833102915; \n",
      " validation loss : 0.6486216233294538; validation accuracy : 0.9022556390977443\n",
      "Epoch 15:\t train loss : 0.5818948940649682; train accuracy : 0.9698888458773434; \n",
      " validation loss : 0.6436815507710542; validation accuracy : 0.9022556390977443\n",
      "Epoch 16:\t train loss : 0.5781808155315222; train accuracy : 0.9734142564839905; \n",
      " validation loss : 0.6638559409840722; validation accuracy : 0.8872180451127819\n",
      "Epoch 17:\t train loss : 0.5691962256692075; train accuracy : 0.9823176464082287; \n",
      " validation loss : 0.6558531913842065; validation accuracy : 0.8872180451127819\n",
      "Epoch 18:\t train loss : 0.5672389914541972; train accuracy : 0.9845987944478239; \n",
      " validation loss : 0.6575729472506773; validation accuracy : 0.8872180451127819\n",
      "Epoch 19:\t train loss : 0.5663785383720702; train accuracy : 0.985193275452082; \n",
      " validation loss : 0.6485625309954094; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5857499546683081; train accuracy : 0.9653542000774208; \n",
      " validation loss : 0.6460784937650794; validation accuracy : 0.9097744360902256\n",
      "Epoch 21:\t train loss : 0.5758057018610903; train accuracy : 0.9757645302217552; \n",
      " validation loss : 0.6729209042571446; validation accuracy : 0.8721804511278195\n",
      "Epoch 22:\t train loss : 0.5754306341288267; train accuracy : 0.9752530000553006; \n",
      " validation loss : 0.6445914694500089; validation accuracy : 0.9097744360902256\n",
      "Epoch 23:\t train loss : 0.5631794520383148; train accuracy : 0.9882071558922745; \n",
      " validation loss : 0.630108077030742; validation accuracy : 0.9172932330827067\n",
      "Epoch 24:\t train loss : 0.5627636638540461; train accuracy : 0.9888845877343361; \n",
      " validation loss : 0.6890365283730314; validation accuracy : 0.8571428571428571\n",
      "Epoch 25:\t train loss : 0.5643538366632925; train accuracy : 0.9868522922081513; \n",
      " validation loss : 0.6512703250503457; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5675565158789603; train accuracy : 0.983824586628325; \n",
      " validation loss : 0.6595060649879998; validation accuracy : 0.8872180451127819\n",
      "Epoch 27:\t train loss : 0.559364138036401; train accuracy : 0.9922164463861085; \n",
      " validation loss : 0.6654217641027247; validation accuracy : 0.8796992481203008\n",
      "Epoch 28:\t train loss : 0.5759586605076614; train accuracy : 0.9751562240778632; \n",
      " validation loss : 0.7195346769438021; validation accuracy : 0.8270676691729323\n",
      "Epoch 29:\t train loss : 0.5806592883846361; train accuracy : 0.9701791738096555; \n",
      " validation loss : 0.6718972078130387; validation accuracy : 0.8721804511278195\n",
      "Epoch 30:\t train loss : 0.5630061265207287; train accuracy : 0.988594259802024; \n",
      " validation loss : 0.6377529415662083; validation accuracy : 0.9172932330827067\n",
      "Epoch 31:\t train loss : 0.5609255469319248; train accuracy : 0.9907648067245479; \n",
      " validation loss : 0.6700871525667523; validation accuracy : 0.8721804511278195\n",
      "Epoch 32:\t train loss : 0.5599518048133345; train accuracy : 0.9915251894044129; \n",
      " validation loss : 0.6545455813969993; validation accuracy : 0.9022556390977443\n",
      "Epoch 33:\t train loss : 0.5601818733915098; train accuracy : 0.9911657357739313; \n",
      " validation loss : 0.6651598868673433; validation accuracy : 0.8721804511278195\n",
      "Epoch 34:\t train loss : 0.5585640715276317; train accuracy : 0.9929215285074379; \n",
      " validation loss : 0.6540998635517816; validation accuracy : 0.8947368421052632\n",
      "Epoch 35:\t train loss : 0.5612050886306119; train accuracy : 0.990142675441022; \n",
      " validation loss : 0.646080090374733; validation accuracy : 0.9022556390977443\n",
      "Epoch 36:\t train loss : 0.564827894032435; train accuracy : 0.9866310899740087; \n",
      " validation loss : 0.6403936213704102; validation accuracy : 0.9097744360902256\n",
      "Epoch 37:\t train loss : 0.5583070731994022; train accuracy : 0.9931012553226788; \n",
      " validation loss : 0.6583559936071914; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.5561694008724525; train accuracy : 0.9953132776641044; \n",
      " validation loss : 0.6046450005204269; validation accuracy : 0.9473684210526315\n",
      "Epoch 39:\t train loss : 0.5554538549962981; train accuracy : 0.9960183597854338; \n",
      " validation loss : 0.61462625562263; validation accuracy : 0.9398496240601504\n",
      "Epoch 40:\t train loss : 0.5717447412077254; train accuracy : 0.9790134380357242; \n",
      " validation loss : 0.6520321168902596; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41:\t train loss : 0.560794996529098; train accuracy : 0.9908615827019853; \n",
      " validation loss : 0.6608441625956221; validation accuracy : 0.8947368421052632\n",
      "Epoch 42:\t train loss : 0.565470183980757; train accuracy : 0.9857601061770724; \n",
      " validation loss : 0.6408161885855618; validation accuracy : 0.9097744360902256\n",
      "Epoch 43:\t train loss : 0.5689690294567185; train accuracy : 0.9822623458496931; \n",
      " validation loss : 0.6503343741256497; validation accuracy : 0.9022556390977443\n",
      "Epoch 44:\t train loss : 0.5608627631696534; train accuracy : 0.990446828512968; \n",
      " validation loss : 0.6851582436503812; validation accuracy : 0.8571428571428571\n",
      "Epoch 45:\t train loss : 0.6076762808073551; train accuracy : 0.9422109163302549; \n",
      " validation loss : 0.6887289351009251; validation accuracy : 0.8646616541353384\n",
      "Epoch 46:\t train loss : 0.5716056334605017; train accuracy : 0.9792899408284024; \n",
      " validation loss : 0.6775704498024551; validation accuracy : 0.8721804511278195\n",
      "Epoch 47:\t train loss : 0.5652092598487408; train accuracy : 0.9858568821545097; \n",
      " validation loss : 0.682373290664302; validation accuracy : 0.8721804511278195\n",
      "Epoch 48:\t train loss : 0.586788277474729; train accuracy : 0.9640269866725654; \n",
      " validation loss : 0.6897635237223353; validation accuracy : 0.8571428571428571\n",
      "Epoch 49:\t train loss : 0.5617328438546806; train accuracy : 0.989686445833103; \n",
      " validation loss : 0.6971165780665451; validation accuracy : 0.8571428571428571\n",
      "Epoch 50:\t train loss : 0.5604694111169689; train accuracy : 0.9908892329812531; \n",
      " validation loss : 0.673317016441542; validation accuracy : 0.8721804511278195\n",
      "Epoch 51:\t train loss : 0.5582769292779898; train accuracy : 0.993225681579384; \n",
      " validation loss : 0.6371517107361566; validation accuracy : 0.9172932330827067\n",
      "Epoch 52:\t train loss : 0.5984593189148099; train accuracy : 0.9516534867002157; \n",
      " validation loss : 0.664339184407202; validation accuracy : 0.8872180451127819\n",
      "Epoch 53:\t train loss : 0.5764470416769368; train accuracy : 0.974561743073605; \n",
      " validation loss : 0.688935132820132; validation accuracy : 0.8571428571428571\n",
      "Epoch 54:\t train loss : 0.5702307936499491; train accuracy : 0.980423602278383; \n",
      " validation loss : 0.6397215446575512; validation accuracy : 0.9172932330827067\n",
      "Epoch 55:\t train loss : 0.5619918478103744; train accuracy : 0.989368467621523; \n",
      " validation loss : 0.6388112229767365; validation accuracy : 0.9097744360902256\n",
      "Epoch 56:\t train loss : 0.560841036866663; train accuracy : 0.9905850799093071; \n",
      " validation loss : 0.6464119531911713; validation accuracy : 0.9022556390977443\n",
      "Epoch 57:\t train loss : 0.5586232192664582; train accuracy : 0.9928524028092683; \n",
      " validation loss : 0.6791496528740274; validation accuracy : 0.8721804511278195\n",
      "Epoch 58:\t train loss : 0.5599453631705257; train accuracy : 0.99137311286844; \n",
      " validation loss : 0.6603249604175717; validation accuracy : 0.8872180451127819\n",
      "Epoch 59:\t train loss : 0.5560568812114114; train accuracy : 0.9954653542000774; \n",
      " validation loss : 0.6524014725173403; validation accuracy : 0.8947368421052632\n",
      "Epoch 60:\t train loss : 0.5563634407687913; train accuracy : 0.9951473759884975; \n",
      " validation loss : 0.6419379772446128; validation accuracy : 0.9097744360902256\n",
      "Epoch 61:\t train loss : 0.5547499228136531; train accuracy : 0.9967096167671293; \n",
      " validation loss : 0.6506627173871924; validation accuracy : 0.9022556390977443\n",
      "Epoch 62:\t train loss : 0.5547232155650663; train accuracy : 0.9967096167671293; \n",
      " validation loss : 0.6647734087945646; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.554780036349398; train accuracy : 0.9965298899518885; \n",
      " validation loss : 0.6266713987168088; validation accuracy : 0.924812030075188\n",
      "Epoch 64:\t train loss : 0.55394015440148; train accuracy : 0.9974699994469944; \n",
      " validation loss : 0.6472713594247955; validation accuracy : 0.9022556390977443\n",
      "Epoch 65:\t train loss : 0.556022190275801; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6970020419050683; validation accuracy : 0.849624060150376\n",
      "Epoch 66:\t train loss : 0.6744787868837465; train accuracy : 0.8745921583807996; \n",
      " validation loss : 0.7126765547831351; validation accuracy : 0.8345864661654135\n",
      "Epoch 67:\t train loss : 0.6153879793788324; train accuracy : 0.9348421169053808; \n",
      " validation loss : 0.7013174937328917; validation accuracy : 0.849624060150376\n",
      "Epoch 68:\t train loss : 0.6291522672731162; train accuracy : 0.9203810208483105; \n",
      " validation loss : 0.7671848264667167; validation accuracy : 0.7819548872180451\n",
      "Epoch 69:\t train loss : 0.6431646985091367; train accuracy : 0.9061134767461151; \n",
      " validation loss : 0.6829859485528288; validation accuracy : 0.8646616541353384\n",
      "Epoch 70:\t train loss : 0.6169736814632873; train accuracy : 0.933570204059061; \n",
      " validation loss : 0.7548934540826545; validation accuracy : 0.7969924812030075\n",
      "Epoch 71:\t train loss : 0.5987243746251487; train accuracy : 0.9514737598849748; \n",
      " validation loss : 0.642569902889741; validation accuracy : 0.9097744360902256\n",
      "Epoch 72:\t train loss : 0.580839029424379; train accuracy : 0.9703036000663606; \n",
      " validation loss : 0.6791362159390268; validation accuracy : 0.8721804511278195\n",
      "Epoch 73:\t train loss : 0.5722805636961924; train accuracy : 0.9788751866393851; \n",
      " validation loss : 0.7014971385920568; validation accuracy : 0.849624060150376\n",
      "Epoch 74:\t train loss : 0.5673324821058101; train accuracy : 0.9839490128850301; \n",
      " validation loss : 0.6512373587208303; validation accuracy : 0.9022556390977443\n",
      "Epoch 75:\t train loss : 0.5632294994812235; train accuracy : 0.9883177570093458; \n",
      " validation loss : 0.665326720072207; validation accuracy : 0.8872180451127819\n",
      "Epoch 76:\t train loss : 0.5617563283539387; train accuracy : 0.9897555715312725; \n",
      " validation loss : 0.6418539998710244; validation accuracy : 0.9097744360902256\n",
      "Epoch 77:\t train loss : 0.5862713295618864; train accuracy : 0.9638610849969584; \n",
      " validation loss : 0.6474721105349325; validation accuracy : 0.9097744360902256\n",
      "Epoch 78:\t train loss : 0.5727879139176691; train accuracy : 0.9783083559143947; \n",
      " validation loss : 0.6634825245929541; validation accuracy : 0.8796992481203008\n",
      "Epoch 79:\t train loss : 0.562006558864036; train accuracy : 0.9892716916440856; \n",
      " validation loss : 0.6283560913631865; validation accuracy : 0.9172932330827067\n",
      "Epoch 80:\t train loss : 0.5608426585300634; train accuracy : 0.9902394514184594; \n",
      " validation loss : 0.6377696509212268; validation accuracy : 0.9097744360902256\n",
      "Epoch 81:\t train loss : 0.5606154431563075; train accuracy : 0.9908754078416192; \n",
      " validation loss : 0.6123252185697808; validation accuracy : 0.9398496240601504\n",
      "Epoch 82:\t train loss : 0.5598149434146014; train accuracy : 0.9917325664989216; \n",
      " validation loss : 0.6194906539459889; validation accuracy : 0.9323308270676691\n",
      "Epoch 83:\t train loss : 0.5579588853123566; train accuracy : 0.9934607089531604; \n",
      " validation loss : 0.6340617144347152; validation accuracy : 0.9172932330827067\n",
      "Epoch 84:\t train loss : 0.5612307913407498; train accuracy : 0.9901979759995576; \n",
      " validation loss : 0.6492929585321447; validation accuracy : 0.9022556390977443\n",
      "Epoch 85:\t train loss : 0.5590273557819703; train accuracy : 0.9923546977824476; \n",
      " validation loss : 0.63534411414674; validation accuracy : 0.9172932330827067\n",
      "Epoch 86:\t train loss : 0.5629066912271303; train accuracy : 0.9884974838245866; \n",
      " validation loss : 0.6038828576335302; validation accuracy : 0.9473684210526315\n",
      "Epoch 87:\t train loss : 0.5647264280237329; train accuracy : 0.9864098877398662; \n",
      " validation loss : 0.6451163268255297; validation accuracy : 0.9022556390977443\n",
      "Epoch 88:\t train loss : 0.5620669863201156; train accuracy : 0.9891887408062822; \n",
      " validation loss : 0.6170943378277709; validation accuracy : 0.9323308270676691\n",
      "Epoch 89:\t train loss : 0.5588667415015948; train accuracy : 0.9924099983409832; \n",
      " validation loss : 0.6302969888279354; validation accuracy : 0.9172932330827067\n",
      "Epoch 90:\t train loss : 0.5592277325611075; train accuracy : 0.9920228944312337; \n",
      " validation loss : 0.6346474020849828; validation accuracy : 0.9172932330827067\n",
      "Epoch 91:\t train loss : 0.5588191496043146; train accuracy : 0.992451473759885; \n",
      " validation loss : 0.6115979323734183; validation accuracy : 0.9398496240601504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:\t train loss : 0.5745186554904492; train accuracy : 0.9764696123430847; \n",
      " validation loss : 0.6487978583168005; validation accuracy : 0.9022556390977443\n",
      "Epoch 93:\t train loss : 0.5602298650104474; train accuracy : 0.9910827849361279; \n",
      " validation loss : 0.6329160023418954; validation accuracy : 0.9172932330827067\n",
      "Epoch 94:\t train loss : 0.5593729174330174; train accuracy : 0.9920228944312337; \n",
      " validation loss : 0.6121325130481411; validation accuracy : 0.9398496240601504\n",
      "Epoch 95:\t train loss : 0.5571620143459147; train accuracy : 0.9940690150970525; \n",
      " validation loss : 0.6448650983772655; validation accuracy : 0.9022556390977443\n",
      "Epoch 96:\t train loss : 0.55626867375551; train accuracy : 0.9951059005695957; \n",
      " validation loss : 0.6398617656193147; validation accuracy : 0.9097744360902256\n",
      "Epoch 97:\t train loss : 0.5569598600728314; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6433612086567004; validation accuracy : 0.9022556390977443\n",
      "Epoch 98:\t train loss : 0.5563415900528339; train accuracy : 0.9950367748714262; \n",
      " validation loss : 0.6407392510085334; validation accuracy : 0.9097744360902256\n",
      "Epoch 99:\t train loss : 0.5559867405153375; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.6339128096859955; validation accuracy : 0.9172932330827067\n",
      "Epoch 100:\t train loss : 0.5571139607195895; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6562965123669372; validation accuracy : 0.8947368421052632\n",
      "Epoch 101:\t train loss : 0.5595192967789595; train accuracy : 0.9917463916385555; \n",
      " validation loss : 0.6265211041532015; validation accuracy : 0.924812030075188\n",
      "Epoch 102:\t train loss : 0.556345389197419; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6466142585132342; validation accuracy : 0.9097744360902256\n",
      "Epoch 103:\t train loss : 0.5616866250729681; train accuracy : 0.9895620195763978; \n",
      " validation loss : 0.6464600999280518; validation accuracy : 0.9022556390977443\n",
      "Epoch 104:\t train loss : 0.5572793290878543; train accuracy : 0.9942210916330255; \n",
      " validation loss : 0.6568296494578719; validation accuracy : 0.8947368421052632\n",
      "Epoch 105:\t train loss : 0.5611749215363758; train accuracy : 0.9900735497428524; \n",
      " validation loss : 0.6251400668879943; validation accuracy : 0.924812030075188\n",
      "Epoch 106:\t train loss : 0.5565055251279094; train accuracy : 0.994912348614721; \n",
      " validation loss : 0.6418271862469096; validation accuracy : 0.9097744360902256\n",
      "Epoch 107:\t train loss : 0.5559916298541281; train accuracy : 0.9954791793397113; \n",
      " validation loss : 0.6359820553780113; validation accuracy : 0.9172932330827067\n",
      "Epoch 108:\t train loss : 0.5566605312842924; train accuracy : 0.9948432229165515; \n",
      " validation loss : 0.6471065869338015; validation accuracy : 0.9022556390977443\n",
      "Epoch 109:\t train loss : 0.5613343407384511; train accuracy : 0.9898385223690759; \n",
      " validation loss : 0.6254238384327324; validation accuracy : 0.9323308270676691\n",
      "Epoch 110:\t train loss : 0.5701663835923491; train accuracy : 0.980423602278383; \n",
      " validation loss : 0.7051739959920271; validation accuracy : 0.8421052631578947\n",
      "Epoch 111:\t train loss : 0.5653625694106726; train accuracy : 0.9855527290825637; \n",
      " validation loss : 0.648688994653428; validation accuracy : 0.8947368421052632\n",
      "Epoch 112:\t train loss : 0.5640484894961377; train accuracy : 0.9869352430459547; \n",
      " validation loss : 0.6961408012374305; validation accuracy : 0.8571428571428571\n",
      "Epoch 113:\t train loss : 0.6054114002350267; train accuracy : 0.9451833213515457; \n",
      " validation loss : 0.6376047339062321; validation accuracy : 0.9097744360902256\n",
      "Epoch 114:\t train loss : 0.5673128339960837; train accuracy : 0.9839213626057624; \n",
      " validation loss : 0.6601119513862933; validation accuracy : 0.8872180451127819\n",
      "Epoch 115:\t train loss : 0.5566915014619667; train accuracy : 0.9946496709616767; \n",
      " validation loss : 0.656579803162043; validation accuracy : 0.8947368421052632\n",
      "Epoch 116:\t train loss : 0.5566715765615041; train accuracy : 0.9947326217994802; \n",
      " validation loss : 0.6260338702834122; validation accuracy : 0.924812030075188\n",
      "Epoch 117:\t train loss : 0.55575621397083; train accuracy : 0.9957142067134878; \n",
      " validation loss : 0.6271521751363257; validation accuracy : 0.9172932330827067\n",
      "Epoch 118:\t train loss : 0.5566808633287301; train accuracy : 0.9946911463805784; \n",
      " validation loss : 0.6561803205693355; validation accuracy : 0.8947368421052632\n",
      "Epoch 119:\t train loss : 0.5578760139526527; train accuracy : 0.9933915832549909; \n",
      " validation loss : 0.6215129615521158; validation accuracy : 0.9323308270676691\n",
      "Epoch 120:\t train loss : 0.5564863690278461; train accuracy : 0.9949538240336228; \n",
      " validation loss : 0.6363652426233046; validation accuracy : 0.9172932330827067\n",
      "Epoch 121:\t train loss : 0.5559356442769083; train accuracy : 0.9953547530830061; \n",
      " validation loss : 0.6232894062213162; validation accuracy : 0.924812030075188\n",
      "Epoch 122:\t train loss : 0.5563122795716328; train accuracy : 0.9951750262677653; \n",
      " validation loss : 0.630382709754198; validation accuracy : 0.9172932330827067\n",
      "Epoch 123:\t train loss : 0.5562886480786599; train accuracy : 0.99505060001106; \n",
      " validation loss : 0.6111490295208839; validation accuracy : 0.9323308270676691\n",
      "Epoch 124:\t train loss : 0.5627332035830891; train accuracy : 0.9886633855001935; \n",
      " validation loss : 0.6697512012017623; validation accuracy : 0.8796992481203008\n",
      "Epoch 125:\t train loss : 0.5626146855477673; train accuracy : 0.9885113089642206; \n",
      " validation loss : 0.6679444090752606; validation accuracy : 0.8796992481203008\n",
      "Epoch 126:\t train loss : 0.5594920989383461; train accuracy : 0.9919261184537964; \n",
      " validation loss : 0.6490252208737967; validation accuracy : 0.9022556390977443\n",
      "Epoch 127:\t train loss : 0.5613029210377373; train accuracy : 0.9899352983465133; \n",
      " validation loss : 0.628559469015153; validation accuracy : 0.924812030075188\n",
      "Epoch 128:\t train loss : 0.555829047863872; train accuracy : 0.99568655643422; \n",
      " validation loss : 0.6301981227366976; validation accuracy : 0.9172932330827067\n",
      "Epoch 129:\t train loss : 0.5552562183114095; train accuracy : 0.9960874854836034; \n",
      " validation loss : 0.6422097784778438; validation accuracy : 0.9097744360902256\n",
      "Epoch 130:\t train loss : 0.55509285966066; train accuracy : 0.9962395620195764; \n",
      " validation loss : 0.640467837419922; validation accuracy : 0.9097744360902256\n",
      "Epoch 131:\t train loss : 0.5545838408198015; train accuracy : 0.9968755184427363; \n",
      " validation loss : 0.6230403587862938; validation accuracy : 0.924812030075188\n",
      "Epoch 132:\t train loss : 0.5556280710898003; train accuracy : 0.9958801083890947; \n",
      " validation loss : 0.6230613300613252; validation accuracy : 0.924812030075188\n",
      "Epoch 133:\t train loss : 0.5555139917161729; train accuracy : 0.9959077586683626; \n",
      " validation loss : 0.6265265889784797; validation accuracy : 0.924812030075188\n",
      "Epoch 134:\t train loss : 0.5548591009600474; train accuracy : 0.9966404910689598; \n",
      " validation loss : 0.6146619845743865; validation accuracy : 0.9323308270676691\n",
      "Epoch 135:\t train loss : 0.5612282419554946; train accuracy : 0.9899629486257812; \n",
      " validation loss : 0.6621695420561922; validation accuracy : 0.8872180451127819\n",
      "Epoch 136:\t train loss : 0.5580339469624394; train accuracy : 0.9932671569982857; \n",
      " validation loss : 0.6340818266682046; validation accuracy : 0.9172932330827067\n",
      "Early stopping at epoch 136\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5629066912271303; Train accuracy : 0.9884974838245866; \n",
      " Validation loss : 0.6038828576335302; Validation accuracy : 0.9473684210526315\n",
      "------------------------------ Let's train model 43 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8945827024716366; train accuracy : 0.6368135818171764; \n",
      " validation loss : 0.8820284656460933; validation accuracy : 0.6466165413533834\n",
      "Epoch 2:\t train loss : 0.7819699053785816; train accuracy : 0.7632859591881878; \n",
      " validation loss : 0.8198952293076841; validation accuracy : 0.7142857142857143\n",
      "Epoch 3:\t train loss : 0.7420936019806414; train accuracy : 0.803945694851518; \n",
      " validation loss : 0.7796952459648476; validation accuracy : 0.7819548872180451\n",
      "Epoch 4:\t train loss : 0.7154354601647628; train accuracy : 0.8336697450644251; \n",
      " validation loss : 0.7588862049667989; validation accuracy : 0.7894736842105263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\t train loss : 0.688885489603221; train accuracy : 0.8611955980755406; \n",
      " validation loss : 0.7775129643739739; validation accuracy : 0.7819548872180451\n",
      "Epoch 6:\t train loss : 0.6729306004574979; train accuracy : 0.8771359840734392; \n",
      " validation loss : 0.7498744202315148; validation accuracy : 0.7969924812030075\n",
      "Epoch 7:\t train loss : 0.6506997750461048; train accuracy : 0.8997124370956147; \n",
      " validation loss : 0.686968918534583; validation accuracy : 0.8721804511278195\n",
      "Epoch 8:\t train loss : 0.6347441596901472; train accuracy : 0.9164270309130123; \n",
      " validation loss : 0.6804840413488814; validation accuracy : 0.8646616541353384\n",
      "Epoch 9:\t train loss : 0.625036037161892; train accuracy : 0.9264087817286955; \n",
      " validation loss : 0.6746711996896698; validation accuracy : 0.8721804511278195\n",
      "Epoch 10:\t train loss : 0.6154605501293016; train accuracy : 0.9357960515401206; \n",
      " validation loss : 0.6958593697481046; validation accuracy : 0.849624060150376\n",
      "Epoch 11:\t train loss : 0.6078909572376744; train accuracy : 0.9435519548747442; \n",
      " validation loss : 0.6721569383631805; validation accuracy : 0.8721804511278195\n",
      "Epoch 12:\t train loss : 0.60155787307952; train accuracy : 0.9495382403362274; \n",
      " validation loss : 0.7018881040939875; validation accuracy : 0.849624060150376\n",
      "Epoch 13:\t train loss : 0.5933580284761064; train accuracy : 0.9577780235580379; \n",
      " validation loss : 0.6988088874061485; validation accuracy : 0.849624060150376\n",
      "Epoch 14:\t train loss : 0.5961464071604216; train accuracy : 0.9553309738428358; \n",
      " validation loss : 0.6598313132701709; validation accuracy : 0.8947368421052632\n",
      "Epoch 15:\t train loss : 0.586737086729474; train accuracy : 0.9644970414201184; \n",
      " validation loss : 0.6317553003793984; validation accuracy : 0.9172932330827067\n",
      "Epoch 16:\t train loss : 0.6205962451478559; train accuracy : 0.9303904219432616; \n",
      " validation loss : 0.682143453199446; validation accuracy : 0.8646616541353384\n",
      "Epoch 17:\t train loss : 0.5829946509648481; train accuracy : 0.968395730796881; \n",
      " validation loss : 0.6979219282518502; validation accuracy : 0.849624060150376\n",
      "Epoch 18:\t train loss : 0.590027931238411; train accuracy : 0.9605292263451861; \n",
      " validation loss : 0.649958146828161; validation accuracy : 0.8947368421052632\n",
      "Epoch 19:\t train loss : 0.5761868719132388; train accuracy : 0.9752391749156667; \n",
      " validation loss : 0.6946547613191708; validation accuracy : 0.8646616541353384\n",
      "Epoch 20:\t train loss : 0.5788959974563905; train accuracy : 0.9725294475474202; \n",
      " validation loss : 0.6469747591585796; validation accuracy : 0.9022556390977443\n",
      "Epoch 21:\t train loss : 0.5722971715286445; train accuracy : 0.9793728916662058; \n",
      " validation loss : 0.6933083955555346; validation accuracy : 0.8571428571428571\n",
      "Epoch 22:\t train loss : 0.5827835973077113; train accuracy : 0.9678427252115246; \n",
      " validation loss : 0.6367415056509974; validation accuracy : 0.9097744360902256\n",
      "Epoch 23:\t train loss : 0.5745008798534595; train accuracy : 0.9768152408339325; \n",
      " validation loss : 0.6760414604454911; validation accuracy : 0.8796992481203008\n",
      "Epoch 24:\t train loss : 0.573243986555349; train accuracy : 0.9778659514461097; \n",
      " validation loss : 0.6633915087151673; validation accuracy : 0.8947368421052632\n",
      "Epoch 25:\t train loss : 0.5719075017655106; train accuracy : 0.9801609246253388; \n",
      " validation loss : 0.649334674582298; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5681451772831293; train accuracy : 0.9832715810429685; \n",
      " validation loss : 0.6575765022325945; validation accuracy : 0.8872180451127819\n",
      "Epoch 27:\t train loss : 0.5714512994756337; train accuracy : 0.9798844218326606; \n",
      " validation loss : 0.6649653434984654; validation accuracy : 0.8872180451127819\n",
      "Epoch 28:\t train loss : 0.5653908295503173; train accuracy : 0.9860780843886523; \n",
      " validation loss : 0.6545502633113301; validation accuracy : 0.8947368421052632\n",
      "Epoch 29:\t train loss : 0.5683701606930892; train accuracy : 0.9831886302051651; \n",
      " validation loss : 0.6774451318594217; validation accuracy : 0.8721804511278195\n",
      "Epoch 30:\t train loss : 0.5676418604201801; train accuracy : 0.9837692860697893; \n",
      " validation loss : 0.6463994069980789; validation accuracy : 0.9022556390977443\n",
      "Epoch 31:\t train loss : 0.5650845932556925; train accuracy : 0.9863684123209644; \n",
      " validation loss : 0.6666909585240824; validation accuracy : 0.8721804511278195\n",
      "Epoch 32:\t train loss : 0.57541381309982; train accuracy : 0.9757645302217552; \n",
      " validation loss : 0.6501392148417121; validation accuracy : 0.9022556390977443\n",
      "Epoch 33:\t train loss : 0.5761150732615767; train accuracy : 0.9748244207266493; \n",
      " validation loss : 0.6726196575287372; validation accuracy : 0.8796992481203008\n",
      "Epoch 34:\t train loss : 0.5655854373165835; train accuracy : 0.9855527290825637; \n",
      " validation loss : 0.6417359606067737; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.5637190102463161; train accuracy : 0.9878891776806946; \n",
      " validation loss : 0.6956093382263047; validation accuracy : 0.8571428571428571\n",
      "Epoch 36:\t train loss : 0.5737249433220295; train accuracy : 0.9774235469778245; \n",
      " validation loss : 0.6581714081692269; validation accuracy : 0.8796992481203008\n",
      "Epoch 37:\t train loss : 0.5670314643553657; train accuracy : 0.9841840402588066; \n",
      " validation loss : 0.6292390169740727; validation accuracy : 0.924812030075188\n",
      "Epoch 38:\t train loss : 0.572934402882903; train accuracy : 0.97811480395952; \n",
      " validation loss : 0.7239032766418627; validation accuracy : 0.8270676691729323\n",
      "Epoch 39:\t train loss : 0.5902814122869691; train accuracy : 0.9606260023226234; \n",
      " validation loss : 0.6904640249391629; validation accuracy : 0.8646616541353384\n",
      "Epoch 40:\t train loss : 0.5718628740686006; train accuracy : 0.9793314162473041; \n",
      " validation loss : 0.6538653799432369; validation accuracy : 0.9022556390977443\n",
      "Epoch 41:\t train loss : 0.5627218751614412; train accuracy : 0.9886772106398275; \n",
      " validation loss : 0.6400950300416334; validation accuracy : 0.9097744360902256\n",
      "Epoch 42:\t train loss : 0.6275258021388117; train accuracy : 0.9219570867665764; \n",
      " validation loss : 0.6903600818530287; validation accuracy : 0.8571428571428571\n",
      "Epoch 43:\t train loss : 0.5755541288064245; train accuracy : 0.9754327268705414; \n",
      " validation loss : 0.6633906237732404; validation accuracy : 0.8947368421052632\n",
      "Epoch 44:\t train loss : 0.5778040678243506; train accuracy : 0.9729303765968036; \n",
      " validation loss : 0.6439568599022166; validation accuracy : 0.9097744360902256\n",
      "Epoch 45:\t train loss : 0.5682704308391652; train accuracy : 0.9831748050655311; \n",
      " validation loss : 0.6537321593337274; validation accuracy : 0.8947368421052632\n",
      "Epoch 46:\t train loss : 0.5678017495459157; train accuracy : 0.9836725100923519; \n",
      " validation loss : 0.6471339995442418; validation accuracy : 0.8947368421052632\n",
      "Epoch 47:\t train loss : 0.5647478361535907; train accuracy : 0.9865481391362053; \n",
      " validation loss : 0.6275357612912742; validation accuracy : 0.924812030075188\n",
      "Epoch 48:\t train loss : 0.5634067030503127; train accuracy : 0.9880412542166676; \n",
      " validation loss : 0.635151267818831; validation accuracy : 0.9172932330827067\n",
      "Epoch 49:\t train loss : 0.5705324946798773; train accuracy : 0.9804374274180169; \n",
      " validation loss : 0.6406387157378892; validation accuracy : 0.9097744360902256\n",
      "Epoch 50:\t train loss : 0.5622736065810061; train accuracy : 0.9890919648288448; \n",
      " validation loss : 0.6410180101247841; validation accuracy : 0.9097744360902256\n",
      "Epoch 51:\t train loss : 0.5660229252475292; train accuracy : 0.9852485760106177; \n",
      " validation loss : 0.6383315790337095; validation accuracy : 0.9097744360902256\n",
      "Epoch 52:\t train loss : 0.5635416990497955; train accuracy : 0.9876403251672842; \n",
      " validation loss : 0.653553877735381; validation accuracy : 0.8947368421052632\n",
      "Epoch 53:\t train loss : 0.6047390961923194; train accuracy : 0.9455842504009291; \n",
      " validation loss : 0.7395907524561184; validation accuracy : 0.8045112781954887\n",
      "Epoch 54:\t train loss : 0.5726836083691305; train accuracy : 0.9783360061936626; \n",
      " validation loss : 0.6391994947544344; validation accuracy : 0.9097744360902256\n",
      "Epoch 55:\t train loss : 0.5624344235133615; train accuracy : 0.9886633855001935; \n",
      " validation loss : 0.6270781523268586; validation accuracy : 0.924812030075188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56:\t train loss : 0.5617797968231232; train accuracy : 0.9894514184593264; \n",
      " validation loss : 0.6605320644161894; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5670580319698258; train accuracy : 0.9840319637228336; \n",
      " validation loss : 0.6186113553334055; validation accuracy : 0.9323308270676691\n",
      "Epoch 58:\t train loss : 0.561709923019002; train accuracy : 0.9895620195763977; \n",
      " validation loss : 0.6407515692277426; validation accuracy : 0.9097744360902256\n",
      "Epoch 59:\t train loss : 0.5630163608129672; train accuracy : 0.9881933307526406; \n",
      " validation loss : 0.6617112648226402; validation accuracy : 0.8947368421052632\n",
      "Epoch 60:\t train loss : 0.5601070587119265; train accuracy : 0.9911933860531992; \n",
      " validation loss : 0.6745540543135679; validation accuracy : 0.8721804511278195\n",
      "Epoch 61:\t train loss : 0.5649070589236704; train accuracy : 0.9863960626002323; \n",
      " validation loss : 0.6235555420274325; validation accuracy : 0.924812030075188\n",
      "Epoch 62:\t train loss : 0.5613934268717627; train accuracy : 0.9900597246032184; \n",
      " validation loss : 0.6541891830932627; validation accuracy : 0.8947368421052632\n",
      "Epoch 63:\t train loss : 0.5601504378454895; train accuracy : 0.9911795609135652; \n",
      " validation loss : 0.6424251331732868; validation accuracy : 0.9097744360902256\n",
      "Epoch 64:\t train loss : 0.5707534822787184; train accuracy : 0.9803130011613117; \n",
      " validation loss : 0.6366900830343616; validation accuracy : 0.9097744360902256\n",
      "Epoch 65:\t train loss : 0.563556196629505; train accuracy : 0.9877509262843555; \n",
      " validation loss : 0.6525334346373743; validation accuracy : 0.8947368421052632\n",
      "Epoch 66:\t train loss : 0.557781631395588; train accuracy : 0.9935851352098656; \n",
      " validation loss : 0.6170538334036496; validation accuracy : 0.9323308270676691\n",
      "Epoch 67:\t train loss : 0.5581711818237017; train accuracy : 0.9934192335342586; \n",
      " validation loss : 0.6478963072806561; validation accuracy : 0.9022556390977443\n",
      "Epoch 68:\t train loss : 0.5823367681337616; train accuracy : 0.9685339821932202; \n",
      " validation loss : 0.7098523635135924; validation accuracy : 0.8421052631578947\n",
      "Epoch 69:\t train loss : 0.6027854810373133; train accuracy : 0.9479759995575955; \n",
      " validation loss : 0.6073159063486826; validation accuracy : 0.9398496240601504\n",
      "Epoch 70:\t train loss : 0.5819116096465982; train accuracy : 0.9689487363822374; \n",
      " validation loss : 0.6415904169508964; validation accuracy : 0.9022556390977443\n",
      "Epoch 71:\t train loss : 0.5733379005415766; train accuracy : 0.9776723994912349; \n",
      " validation loss : 0.6149617116843756; validation accuracy : 0.9323308270676691\n",
      "Epoch 72:\t train loss : 0.5720186665566989; train accuracy : 0.9790687385942598; \n",
      " validation loss : 0.658872141540217; validation accuracy : 0.8872180451127819\n",
      "Epoch 73:\t train loss : 0.5688234716347765; train accuracy : 0.9824697229442018; \n",
      " validation loss : 0.6109917563928592; validation accuracy : 0.9398496240601504\n",
      "Epoch 74:\t train loss : 0.5613716428029565; train accuracy : 0.9901150251617541; \n",
      " validation loss : 0.6062806089581747; validation accuracy : 0.9473684210526315\n",
      "Epoch 75:\t train loss : 0.5577427978317789; train accuracy : 0.9934607089531604; \n",
      " validation loss : 0.6193400297029062; validation accuracy : 0.9323308270676691\n",
      "Epoch 76:\t train loss : 0.556458136685211; train accuracy : 0.9950091245921584; \n",
      " validation loss : 0.6465936738081718; validation accuracy : 0.9022556390977443\n",
      "Epoch 77:\t train loss : 0.5563445216250925; train accuracy : 0.9950782502903279; \n",
      " validation loss : 0.6184514511409702; validation accuracy : 0.9323308270676691\n",
      "Epoch 78:\t train loss : 0.5570266508165407; train accuracy : 0.9943455178897307; \n",
      " validation loss : 0.6178912876489819; validation accuracy : 0.9323308270676691\n",
      "Epoch 79:\t train loss : 0.5629621578212556; train accuracy : 0.9884145329867832; \n",
      " validation loss : 0.6424647221802953; validation accuracy : 0.9022556390977443\n",
      "Epoch 80:\t train loss : 0.5639184780409883; train accuracy : 0.9874052977935077; \n",
      " validation loss : 0.6841661812140799; validation accuracy : 0.8721804511278195\n",
      "Epoch 81:\t train loss : 0.5590437051594371; train accuracy : 0.9922302715257424; \n",
      " validation loss : 0.6630641165205841; validation accuracy : 0.8796992481203008\n",
      "Epoch 82:\t train loss : 0.5575073136555347; train accuracy : 0.993820162583642; \n",
      " validation loss : 0.6195445995382847; validation accuracy : 0.924812030075188\n",
      "Epoch 83:\t train loss : 0.5674895633787496; train accuracy : 0.9836310346734501; \n",
      " validation loss : 0.6406975117676805; validation accuracy : 0.9097744360902256\n",
      "Epoch 84:\t train loss : 0.55707284255616; train accuracy : 0.9943316927500968; \n",
      " validation loss : 0.6109411388067264; validation accuracy : 0.9398496240601504\n",
      "Epoch 85:\t train loss : 0.5621690936143975; train accuracy : 0.989064314549577; \n",
      " validation loss : 0.6559444565331776; validation accuracy : 0.8947368421052632\n",
      "Epoch 86:\t train loss : 0.5655991900376954; train accuracy : 0.9856495050600012; \n",
      " validation loss : 0.6346765634326663; validation accuracy : 0.9172932330827067\n",
      "Epoch 87:\t train loss : 0.5603935237071958; train accuracy : 0.9907786318641818; \n",
      " validation loss : 0.6821591037554945; validation accuracy : 0.8646616541353384\n",
      "Epoch 88:\t train loss : 0.6059366637831628; train accuracy : 0.9441602610186363; \n",
      " validation loss : 0.6775955033566003; validation accuracy : 0.8721804511278195\n",
      "Epoch 89:\t train loss : 0.5662670474726542; train accuracy : 0.9849167726594038; \n",
      " validation loss : 0.6572000293451964; validation accuracy : 0.8947368421052632\n",
      "Epoch 90:\t train loss : 0.5733724346594802; train accuracy : 0.9777830006083061; \n",
      " validation loss : 0.6637049751182917; validation accuracy : 0.8872180451127819\n",
      "Epoch 91:\t train loss : 0.5608905322021869; train accuracy : 0.9904053530940663; \n",
      " validation loss : 0.6314252473239299; validation accuracy : 0.9172932330827067\n",
      "Epoch 92:\t train loss : 0.5637733040007724; train accuracy : 0.9874744234916772; \n",
      " validation loss : 0.6183613236000656; validation accuracy : 0.9323308270676691\n",
      "Epoch 93:\t train loss : 0.5677105992106749; train accuracy : 0.9833130564618703; \n",
      " validation loss : 0.6919867491231271; validation accuracy : 0.8571428571428571\n",
      "Epoch 94:\t train loss : 0.5593596895647273; train accuracy : 0.9920920201294033; \n",
      " validation loss : 0.614069155389127; validation accuracy : 0.9398496240601504\n",
      "Epoch 95:\t train loss : 0.5561795783256973; train accuracy : 0.9951612011281313; \n",
      " validation loss : 0.5958723869666249; validation accuracy : 0.9548872180451128\n",
      "Epoch 96:\t train loss : 0.5617743675630889; train accuracy : 0.9894928938782281; \n",
      " validation loss : 0.6380184628695217; validation accuracy : 0.9172932330827067\n",
      "Epoch 97:\t train loss : 0.5577368490972128; train accuracy : 0.9935298346513299; \n",
      " validation loss : 0.6382973796388888; validation accuracy : 0.9097744360902256\n",
      "Epoch 98:\t train loss : 0.5599480056613075; train accuracy : 0.9914698888458774; \n",
      " validation loss : 0.6587342875380546; validation accuracy : 0.8872180451127819\n",
      "Epoch 99:\t train loss : 0.5621866664724341; train accuracy : 0.9891196151081125; \n",
      " validation loss : 0.649320142956211; validation accuracy : 0.9022556390977443\n",
      "Epoch 100:\t train loss : 0.569007340681707; train accuracy : 0.9820411436155505; \n",
      " validation loss : 0.6503305822456592; validation accuracy : 0.9022556390977443\n",
      "Epoch 101:\t train loss : 0.5632212455807482; train accuracy : 0.9880136039373998; \n",
      " validation loss : 0.6452108946869096; validation accuracy : 0.8947368421052632\n",
      "Epoch 102:\t train loss : 0.5594755439435524; train accuracy : 0.9918155173367251; \n",
      " validation loss : 0.8887911031779488; validation accuracy : 0.6616541353383458\n",
      "Epoch 103:\t train loss : 0.6802428964623799; train accuracy : 0.8687579494552895; \n",
      " validation loss : 0.6633658032258793; validation accuracy : 0.8872180451127819\n",
      "Epoch 104:\t train loss : 0.5942981197005269; train accuracy : 0.9561881325001382; \n",
      " validation loss : 0.6342198441932408; validation accuracy : 0.9172932330827067\n",
      "Epoch 105:\t train loss : 0.5919712593998143; train accuracy : 0.9584001548415639; \n",
      " validation loss : 0.6047373337294437; validation accuracy : 0.9473684210526315\n",
      "Epoch 106:\t train loss : 0.5976750318781979; train accuracy : 0.9527180224520267; \n",
      " validation loss : 0.6202027450818844; validation accuracy : 0.9323308270676691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107:\t train loss : 0.5744962817375174; train accuracy : 0.9768290659735663; \n",
      " validation loss : 0.6145270319355297; validation accuracy : 0.9398496240601504\n",
      "Epoch 108:\t train loss : 0.5696144716444568; train accuracy : 0.9817369905436045; \n",
      " validation loss : 0.6166498608988533; validation accuracy : 0.9323308270676691\n",
      "Epoch 109:\t train loss : 0.5751096359535873; train accuracy : 0.9757368799424875; \n",
      " validation loss : 0.634071398476998; validation accuracy : 0.9172932330827067\n",
      "Epoch 110:\t train loss : 0.572344232572802; train accuracy : 0.9789028369186529; \n",
      " validation loss : 0.6229775639499053; validation accuracy : 0.924812030075188\n",
      "Epoch 111:\t train loss : 0.568483724933037; train accuracy : 0.9827877011557816; \n",
      " validation loss : 0.6263282647697369; validation accuracy : 0.924812030075188\n",
      "Epoch 112:\t train loss : 0.5640749717951727; train accuracy : 0.9869075927666869; \n",
      " validation loss : 0.6124911049582946; validation accuracy : 0.9398496240601504\n",
      "Epoch 113:\t train loss : 0.5630432366603975; train accuracy : 0.9882348061715424; \n",
      " validation loss : 0.6263680427958846; validation accuracy : 0.924812030075188\n",
      "Epoch 114:\t train loss : 0.7310521304236768; train accuracy : 0.8171072277830006; \n",
      " validation loss : 0.6617302804236581; validation accuracy : 0.8947368421052632\n",
      "Epoch 115:\t train loss : 0.6147385617225234; train accuracy : 0.9351600951169606; \n",
      " validation loss : 0.6678797000476606; validation accuracy : 0.8872180451127819\n",
      "Epoch 116:\t train loss : 0.5908915499819413; train accuracy : 0.9600315213183653; \n",
      " validation loss : 0.6346522774127475; validation accuracy : 0.9172932330827067\n",
      "Epoch 117:\t train loss : 0.5836246177519384; train accuracy : 0.9672620693469004; \n",
      " validation loss : 0.6509903925926517; validation accuracy : 0.9022556390977443\n",
      "Epoch 118:\t train loss : 0.5740223992746749; train accuracy : 0.9772299950229497; \n",
      " validation loss : 0.6290692231694099; validation accuracy : 0.9172932330827067\n",
      "Epoch 119:\t train loss : 0.5717802500987067; train accuracy : 0.9798291212741249; \n",
      " validation loss : 0.6270274369155899; validation accuracy : 0.924812030075188\n",
      "Epoch 120:\t train loss : 0.5851507278387881; train accuracy : 0.9658933805231433; \n",
      " validation loss : 0.6085697404990862; validation accuracy : 0.9398496240601504\n",
      "Epoch 121:\t train loss : 0.5683298332519651; train accuracy : 0.9831748050655311; \n",
      " validation loss : 0.598277187983375; validation accuracy : 0.9548872180451128\n",
      "Epoch 122:\t train loss : 0.5670850567952606; train accuracy : 0.9840596140021014; \n",
      " validation loss : 0.613246524407248; validation accuracy : 0.9398496240601504\n",
      "Epoch 123:\t train loss : 0.5674862937535853; train accuracy : 0.9838660620472267; \n",
      " validation loss : 0.627770550974679; validation accuracy : 0.924812030075188\n",
      "Epoch 124:\t train loss : 0.5650378860020051; train accuracy : 0.9865619642758392; \n",
      " validation loss : 0.5973766806650321; validation accuracy : 0.9548872180451128\n",
      "Epoch 125:\t train loss : 0.5627426175985352; train accuracy : 0.9886357352209257; \n",
      " validation loss : 0.636694115015807; validation accuracy : 0.9097744360902256\n",
      "Epoch 126:\t train loss : 0.5650383975611872; train accuracy : 0.9862992866227949; \n",
      " validation loss : 0.6051199041608409; validation accuracy : 0.9473684210526315\n",
      "Epoch 127:\t train loss : 0.5647210973321979; train accuracy : 0.986589614555107; \n",
      " validation loss : 0.5843872375142927; validation accuracy : 0.9699248120300752\n",
      "Epoch 128:\t train loss : 0.5608636614993004; train accuracy : 0.9904883039318697; \n",
      " validation loss : 0.6127500881850131; validation accuracy : 0.9323308270676691\n",
      "Epoch 129:\t train loss : 0.5615076232965409; train accuracy : 0.9897417463916386; \n",
      " validation loss : 0.619300695213994; validation accuracy : 0.9323308270676691\n",
      "Epoch 130:\t train loss : 0.5729540774839286; train accuracy : 0.9781424542387879; \n",
      " validation loss : 0.5958377796877387; validation accuracy : 0.9624060150375939\n",
      "Epoch 131:\t train loss : 0.5675153261564676; train accuracy : 0.9834789581374772; \n",
      " validation loss : 0.6312257226843707; validation accuracy : 0.9172932330827067\n",
      "Epoch 132:\t train loss : 0.5679660774863241; train accuracy : 0.9834236575789416; \n",
      " validation loss : 0.6194263399867784; validation accuracy : 0.924812030075188\n",
      "Epoch 133:\t train loss : 0.5624452669186707; train accuracy : 0.9888845877343361; \n",
      " validation loss : 0.6032762248012732; validation accuracy : 0.9473684210526315\n",
      "Epoch 134:\t train loss : 0.5666877678128304; train accuracy : 0.9846679201459935; \n",
      " validation loss : 0.5978685833586155; validation accuracy : 0.9548872180451128\n",
      "Epoch 135:\t train loss : 0.5600991469623153; train accuracy : 0.9912625117513687; \n",
      " validation loss : 0.6025243075941384; validation accuracy : 0.9473684210526315\n",
      "Epoch 136:\t train loss : 0.5594334181416762; train accuracy : 0.9920090692915998; \n",
      " validation loss : 0.6098707033774019; validation accuracy : 0.9398496240601504\n",
      "Epoch 137:\t train loss : 0.5597738728486035; train accuracy : 0.9915943151025826; \n",
      " validation loss : 0.5853844029884572; validation accuracy : 0.9624060150375939\n",
      "Epoch 138:\t train loss : 0.5597929757562465; train accuracy : 0.9915390145440469; \n",
      " validation loss : 0.6022790758563993; validation accuracy : 0.9473684210526315\n",
      "Epoch 139:\t train loss : 0.5589665812731016; train accuracy : 0.9923270475031798; \n",
      " validation loss : 0.5871137056003619; validation accuracy : 0.9699248120300752\n",
      "Epoch 140:\t train loss : 0.5607867452866173; train accuracy : 0.9906127301885749; \n",
      " validation loss : 0.612829217173445; validation accuracy : 0.9398496240601504\n",
      "Epoch 141:\t train loss : 0.56118829714107; train accuracy : 0.9901565005806559; \n",
      " validation loss : 0.6039964892000617; validation accuracy : 0.9398496240601504\n",
      "Epoch 142:\t train loss : 0.5595908889001706; train accuracy : 0.9919261184537964; \n",
      " validation loss : 0.5836651363273878; validation accuracy : 0.9699248120300752\n",
      "Epoch 143:\t train loss : 0.5702735373950529; train accuracy : 0.9808245313277664; \n",
      " validation loss : 0.6093582232345023; validation accuracy : 0.9398496240601504\n",
      "Epoch 144:\t train loss : 0.565847365324584; train accuracy : 0.9856218547807333; \n",
      " validation loss : 0.6653799473254701; validation accuracy : 0.8872180451127819\n",
      "Epoch 145:\t train loss : 0.5635139839595882; train accuracy : 0.9877232760050877; \n",
      " validation loss : 0.642271494636687; validation accuracy : 0.9097744360902256\n",
      "Epoch 146:\t train loss : 0.559596862145717; train accuracy : 0.9915390145440469; \n",
      " validation loss : 0.6423769162148067; validation accuracy : 0.9097744360902256\n",
      "Epoch 147:\t train loss : 0.5625722492493299; train accuracy : 0.9888569374550683; \n",
      " validation loss : 0.619588697111218; validation accuracy : 0.9323308270676691\n",
      "Epoch 148:\t train loss : 0.5598343377093855; train accuracy : 0.9914975391251452; \n",
      " validation loss : 0.6238207835048526; validation accuracy : 0.924812030075188\n",
      "Epoch 149:\t train loss : 0.5584951022628714; train accuracy : 0.9927832771110988; \n",
      " validation loss : 0.5954908453931571; validation accuracy : 0.9548872180451128\n",
      "Epoch 150:\t train loss : 0.558579983564592; train accuracy : 0.9927556268318309; \n",
      " validation loss : 0.6304255736354094; validation accuracy : 0.9172932330827067\n",
      "Epoch 151:\t train loss : 0.5686009796946834; train accuracy : 0.982580324061273; \n",
      " validation loss : 0.6116294929855877; validation accuracy : 0.9398496240601504\n",
      "Epoch 152:\t train loss : 0.569600922303472; train accuracy : 0.9813637117734889; \n",
      " validation loss : 0.5981220830071565; validation accuracy : 0.9548872180451128\n",
      "Epoch 153:\t train loss : 0.5599706941868564; train accuracy : 0.9913178123099043; \n",
      " validation loss : 0.6477202919777809; validation accuracy : 0.9022556390977443\n",
      "Epoch 154:\t train loss : 0.559327550695865; train accuracy : 0.9919675938726981; \n",
      " validation loss : 0.6138215630226632; validation accuracy : 0.9398496240601504\n",
      "Epoch 155:\t train loss : 0.5586547264376963; train accuracy : 0.9926173754354919; \n",
      " validation loss : 0.6007002228179114; validation accuracy : 0.9473684210526315\n",
      "Epoch 156:\t train loss : 0.5579212980735974; train accuracy : 0.9933224575568214; \n",
      " validation loss : 0.6051657290308737; validation accuracy : 0.9473684210526315\n",
      "Epoch 157:\t train loss : 0.5606027950873899; train accuracy : 0.9907233313056462; \n",
      " validation loss : 0.613546535427618; validation accuracy : 0.9323308270676691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158:\t train loss : 0.5818115841653181; train accuracy : 0.9691837637560139; \n",
      " validation loss : 0.6393015030314627; validation accuracy : 0.9097744360902256\n",
      "Epoch 159:\t train loss : 0.5633172100625241; train accuracy : 0.9879444782392303; \n",
      " validation loss : 0.6416615382169271; validation accuracy : 0.9097744360902256\n",
      "Epoch 160:\t train loss : 0.5620965321207926; train accuracy : 0.9891749156666482; \n",
      " validation loss : 0.6157402309095819; validation accuracy : 0.9323308270676691\n",
      "Epoch 161:\t train loss : 0.5630549716962356; train accuracy : 0.9883868827075153; \n",
      " validation loss : 0.6306639889025561; validation accuracy : 0.9172932330827067\n",
      "Epoch 162:\t train loss : 0.5596440278561544; train accuracy : 0.991677265940386; \n",
      " validation loss : 0.6368108593394577; validation accuracy : 0.9097744360902256\n",
      "Epoch 163:\t train loss : 0.5577188607589002; train accuracy : 0.9935851352098656; \n",
      " validation loss : 0.6318725612260053; validation accuracy : 0.9172932330827067\n",
      "Epoch 164:\t train loss : 0.5591303359896348; train accuracy : 0.9923408726428137; \n",
      " validation loss : 0.5981239117129435; validation accuracy : 0.9548872180451128\n",
      "Epoch 165:\t train loss : 0.560474759318227; train accuracy : 0.9909860089586905; \n",
      " validation loss : 0.6044089820487704; validation accuracy : 0.9473684210526315\n",
      "Epoch 166:\t train loss : 0.5574241861376211; train accuracy : 0.9938616380025438; \n",
      " validation loss : 0.578781832371527; validation accuracy : 0.9699248120300752\n",
      "Epoch 167:\t train loss : 0.558248637982503; train accuracy : 0.9930459547641431; \n",
      " validation loss : 0.6564283000057798; validation accuracy : 0.8947368421052632\n",
      "Epoch 168:\t train loss : 0.5571189683667265; train accuracy : 0.994290217331195; \n",
      " validation loss : 0.6266287749610733; validation accuracy : 0.924812030075188\n",
      "Epoch 169:\t train loss : 0.5576193526001143; train accuracy : 0.993681911187303; \n",
      " validation loss : 0.6056397684511946; validation accuracy : 0.9473684210526315\n",
      "Epoch 170:\t train loss : 0.574708273670017; train accuracy : 0.9761654592711386; \n",
      " validation loss : 0.5936670315942401; validation accuracy : 0.9548872180451128\n",
      "Epoch 171:\t train loss : 0.5598899136099657; train accuracy : 0.991511364264779; \n",
      " validation loss : 0.6250174287529803; validation accuracy : 0.924812030075188\n",
      "Epoch 172:\t train loss : 0.5579726838011485; train accuracy : 0.9932533318586517; \n",
      " validation loss : 0.6420536234292032; validation accuracy : 0.9097744360902256\n",
      "Epoch 173:\t train loss : 0.5602170539657614; train accuracy : 0.9911657357739313; \n",
      " validation loss : 0.6266131359728959; validation accuracy : 0.924812030075188\n",
      "Epoch 174:\t train loss : 0.5582942033468421; train accuracy : 0.9929353536470719; \n",
      " validation loss : 0.6427338414393134; validation accuracy : 0.9097744360902256\n",
      "Epoch 175:\t train loss : 0.5606836013156244; train accuracy : 0.9905021290715036; \n",
      " validation loss : 0.6068450597020351; validation accuracy : 0.9398496240601504\n",
      "Epoch 176:\t train loss : 0.5604612044289986; train accuracy : 0.9908615827019853; \n",
      " validation loss : 0.6339284251535657; validation accuracy : 0.9172932330827067\n",
      "Epoch 177:\t train loss : 0.5949274780350767; train accuracy : 0.9559254548470939; \n",
      " validation loss : 0.6343168087660983; validation accuracy : 0.9172932330827067\n",
      "Epoch 178:\t train loss : 0.5711167386760431; train accuracy : 0.9801332743460709; \n",
      " validation loss : 0.650695960478312; validation accuracy : 0.9022556390977443\n",
      "Epoch 179:\t train loss : 0.5604765202475961; train accuracy : 0.9907095061660123; \n",
      " validation loss : 0.642096046765829; validation accuracy : 0.9097744360902256\n",
      "Epoch 180:\t train loss : 0.55885731695336; train accuracy : 0.9925620748769562; \n",
      " validation loss : 0.6221258835415079; validation accuracy : 0.924812030075188\n",
      "Epoch 181:\t train loss : 0.5585234957429993; train accuracy : 0.9928800530885362; \n",
      " validation loss : 0.6268732565120343; validation accuracy : 0.924812030075188\n",
      "Epoch 182:\t train loss : 0.5573386137743068; train accuracy : 0.9940551899574186; \n",
      " validation loss : 0.6350268912693976; validation accuracy : 0.9172932330827067\n",
      "Epoch 183:\t train loss : 0.5579856241345529; train accuracy : 0.9934054083946248; \n",
      " validation loss : 0.6121978324351778; validation accuracy : 0.9398496240601504\n",
      "Epoch 184:\t train loss : 0.5568115133669883; train accuracy : 0.9945805452635071; \n",
      " validation loss : 0.6115649083503962; validation accuracy : 0.9398496240601504\n",
      "Epoch 185:\t train loss : 0.5552603112352584; train accuracy : 0.9963363379970137; \n",
      " validation loss : 0.6032475153182272; validation accuracy : 0.9473684210526315\n",
      "Epoch 186:\t train loss : 0.5597533810187233; train accuracy : 0.9914975391251452; \n",
      " validation loss : 0.6189765971033189; validation accuracy : 0.9323308270676691\n",
      "Epoch 187:\t train loss : 0.5571076884425934; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6265648827203681; validation accuracy : 0.924812030075188\n",
      "Epoch 188:\t train loss : 0.5613616988593194; train accuracy : 0.9898523475087099; \n",
      " validation loss : 0.6270719813409968; validation accuracy : 0.924812030075188\n",
      "Epoch 189:\t train loss : 0.5581948653725911; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.6353281816275432; validation accuracy : 0.9172932330827067\n",
      "Epoch 190:\t train loss : 0.5599048884752942; train accuracy : 0.9914698888458773; \n",
      " validation loss : 0.6414857797750164; validation accuracy : 0.9097744360902256\n",
      "Epoch 191:\t train loss : 0.5576738850302887; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.6575058286506185; validation accuracy : 0.8947368421052632\n",
      "Epoch 192:\t train loss : 0.5571002343713697; train accuracy : 0.9943178676104628; \n",
      " validation loss : 0.6430117086358447; validation accuracy : 0.9097744360902256\n",
      "Epoch 193:\t train loss : 0.5571748205556006; train accuracy : 0.9941796162141238; \n",
      " validation loss : 0.6192995913442509; validation accuracy : 0.9323308270676691\n",
      "Epoch 194:\t train loss : 0.5566102631292587; train accuracy : 0.994760272078748; \n",
      " validation loss : 0.6164048964676441; validation accuracy : 0.9323308270676691\n",
      "Epoch 195:\t train loss : 0.5571971989683167; train accuracy : 0.9942487419122933; \n",
      " validation loss : 0.5972399817047105; validation accuracy : 0.9548872180451128\n",
      "Epoch 196:\t train loss : 0.5584403069509167; train accuracy : 0.9928800530885362; \n",
      " validation loss : 0.6122631825594702; validation accuracy : 0.9398496240601504\n",
      "Epoch 197:\t train loss : 0.5561400946062205; train accuracy : 0.9953409279433723; \n",
      " validation loss : 0.6567773677776303; validation accuracy : 0.8947368421052632\n",
      "Epoch 198:\t train loss : 0.5564128307420027; train accuracy : 0.9949538240336228; \n",
      " validation loss : 0.6330959145179458; validation accuracy : 0.9172932330827067\n",
      "Epoch 199:\t train loss : 0.5569199194618003; train accuracy : 0.9944422938671681; \n",
      " validation loss : 0.6146586252660862; validation accuracy : 0.9323308270676691\n",
      "Epoch 200:\t train loss : 0.5608074638091416; train accuracy : 0.9905436044904053; \n",
      " validation loss : 0.6397599644659554; validation accuracy : 0.9097744360902256\n",
      "Epoch 201:\t train loss : 0.5611919688039565; train accuracy : 0.9901150251617541; \n",
      " validation loss : 0.6053143072608933; validation accuracy : 0.9473684210526315\n",
      "Epoch 202:\t train loss : 0.559277059293258; train accuracy : 0.992133495548305; \n",
      " validation loss : 0.6184333349614889; validation accuracy : 0.9323308270676691\n",
      "Epoch 203:\t train loss : 0.5565026461261144; train accuracy : 0.9949261737543549; \n",
      " validation loss : 0.5890429047243047; validation accuracy : 0.9624060150375939\n",
      "Epoch 204:\t train loss : 0.5566901540203237; train accuracy : 0.9946773212409445; \n",
      " validation loss : 0.619078985916802; validation accuracy : 0.9323308270676691\n",
      "Epoch 205:\t train loss : 0.5569008690783439; train accuracy : 0.9944975944257037; \n",
      " validation loss : 0.6040912322121581; validation accuracy : 0.9473684210526315\n",
      "Epoch 206:\t train loss : 0.5575193255019909; train accuracy : 0.9937786871647404; \n",
      " validation loss : 0.6005995599929584; validation accuracy : 0.9548872180451128\n",
      "Epoch 207:\t train loss : 0.5559082857252494; train accuracy : 0.9954930044793452; \n",
      " validation loss : 0.6360272143643508; validation accuracy : 0.9172932330827067\n",
      "Epoch 208:\t train loss : 0.5638130481506308; train accuracy : 0.9874329480727755; \n",
      " validation loss : 0.636522838652343; validation accuracy : 0.9172932330827067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209:\t train loss : 0.5600852714326391; train accuracy : 0.9912901620306365; \n",
      " validation loss : 0.6120513940720996; validation accuracy : 0.9398496240601504\n",
      "Epoch 210:\t train loss : 0.5586504062039901; train accuracy : 0.9927141514129293; \n",
      " validation loss : 0.6493550078833507; validation accuracy : 0.9022556390977443\n",
      "Epoch 211:\t train loss : 0.5660239051286196; train accuracy : 0.9852762262898855; \n",
      " validation loss : 0.6787254721516106; validation accuracy : 0.8721804511278195\n",
      "Epoch 212:\t train loss : 0.5610411338454904; train accuracy : 0.9902671016977271; \n",
      " validation loss : 0.6515207205471997; validation accuracy : 0.9022556390977443\n",
      "Epoch 213:\t train loss : 0.5613881600757404; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.6483555515085547; validation accuracy : 0.9022556390977443\n",
      "Epoch 214:\t train loss : 0.5604779874088401; train accuracy : 0.9908615827019853; \n",
      " validation loss : 0.6403880697330668; validation accuracy : 0.9097744360902256\n",
      "Epoch 215:\t train loss : 0.5594880268109258; train accuracy : 0.9917878670574573; \n",
      " validation loss : 0.6119355009992888; validation accuracy : 0.9398496240601504\n",
      "Epoch 216:\t train loss : 0.5573045123180651; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.6147823761543553; validation accuracy : 0.9323308270676691\n",
      "Early stopping at epoch 216\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5574241861376211; Train accuracy : 0.9938616380025438; \n",
      " Validation loss : 0.578781832371527; Validation accuracy : 0.9699248120300752\n",
      "------------------------------ Let's train model 44 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8821066271578681; train accuracy : 0.6507907979870596; \n",
      " validation loss : 0.7895134078840208; validation accuracy : 0.7593984962406015\n",
      "Epoch 2:\t train loss : 0.7787254061205302; train accuracy : 0.7664104407454515; \n",
      " validation loss : 0.7556469145086061; validation accuracy : 0.7969924812030075\n",
      "Epoch 3:\t train loss : 0.73984584474324; train accuracy : 0.8069872255709782; \n",
      " validation loss : 0.7037723687502674; validation accuracy : 0.849624060150376\n",
      "Epoch 4:\t train loss : 0.7109626776651202; train accuracy : 0.8369186528783941; \n",
      " validation loss : 0.6863026073790625; validation accuracy : 0.8721804511278195\n",
      "Epoch 5:\t train loss : 0.6876028614618801; train accuracy : 0.8610158712602998; \n",
      " validation loss : 0.6798884154137215; validation accuracy : 0.8646616541353384\n",
      "Epoch 6:\t train loss : 0.660337822485728; train accuracy : 0.8897168611402975; \n",
      " validation loss : 0.6860182425138284; validation accuracy : 0.8646616541353384\n",
      "Epoch 7:\t train loss : 0.6475108938777057; train accuracy : 0.9030166454681192; \n",
      " validation loss : 0.6693217045879933; validation accuracy : 0.8872180451127819\n",
      "Epoch 8:\t train loss : 0.6461473028159788; train accuracy : 0.9046618370845546; \n",
      " validation loss : 0.6567880127596643; validation accuracy : 0.8872180451127819\n",
      "Epoch 9:\t train loss : 0.6290811332331945; train accuracy : 0.9214593817397556; \n",
      " validation loss : 0.6867256566795236; validation accuracy : 0.8571428571428571\n",
      "Epoch 10:\t train loss : 0.6364150934231403; train accuracy : 0.9141182325941491; \n",
      " validation loss : 0.6994051909225981; validation accuracy : 0.8421052631578947\n",
      "Epoch 11:\t train loss : 0.6323074093746045; train accuracy : 0.9175883426422606; \n",
      " validation loss : 0.6435889227890406; validation accuracy : 0.9097744360902256\n",
      "Epoch 12:\t train loss : 0.6125123718524286; train accuracy : 0.9381325001382514; \n",
      " validation loss : 0.6473346947437392; validation accuracy : 0.9022556390977443\n",
      "Epoch 13:\t train loss : 0.6056791644828996; train accuracy : 0.9453353978875186; \n",
      " validation loss : 0.6733605806487346; validation accuracy : 0.8721804511278195\n",
      "Epoch 14:\t train loss : 0.5971877324350356; train accuracy : 0.9542802632306586; \n",
      " validation loss : 0.6667500681405709; validation accuracy : 0.8721804511278195\n",
      "Epoch 15:\t train loss : 0.5934858421984038; train accuracy : 0.957916274954377; \n",
      " validation loss : 0.6623314530917314; validation accuracy : 0.8796992481203008\n",
      "Epoch 16:\t train loss : 0.5948962925634602; train accuracy : 0.9564922855720843; \n",
      " validation loss : 0.7104312348836244; validation accuracy : 0.8345864661654135\n",
      "Epoch 17:\t train loss : 0.5930463473290657; train accuracy : 0.9584692805397335; \n",
      " validation loss : 0.6294659598126574; validation accuracy : 0.924812030075188\n",
      "Epoch 18:\t train loss : 0.5932693082617249; train accuracy : 0.957916274954377; \n",
      " validation loss : 0.6502484508455153; validation accuracy : 0.9022556390977443\n",
      "Epoch 19:\t train loss : 0.5873146182489678; train accuracy : 0.9636122324835481; \n",
      " validation loss : 0.6471465813746287; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5841022998084133; train accuracy : 0.9666537632030083; \n",
      " validation loss : 0.6616604722187481; validation accuracy : 0.8872180451127819\n",
      "Epoch 21:\t train loss : 0.5890925466472321; train accuracy : 0.9615937620969972; \n",
      " validation loss : 0.6394717087255279; validation accuracy : 0.9097744360902256\n",
      "Epoch 22:\t train loss : 0.5833287997140558; train accuracy : 0.9674279710225073; \n",
      " validation loss : 0.6335811563131611; validation accuracy : 0.9172932330827067\n",
      "Epoch 23:\t train loss : 0.5836322875961699; train accuracy : 0.9677459492340873; \n",
      " validation loss : 0.6314183519649366; validation accuracy : 0.924812030075188\n",
      "Epoch 24:\t train loss : 0.6096678235605082; train accuracy : 0.9403859978985788; \n",
      " validation loss : 0.6559015360736346; validation accuracy : 0.8947368421052632\n",
      "Epoch 25:\t train loss : 0.5832770666416575; train accuracy : 0.9678012497926229; \n",
      " validation loss : 0.6266359086933107; validation accuracy : 0.924812030075188\n",
      "Epoch 26:\t train loss : 0.5728709125281817; train accuracy : 0.9786678095448764; \n",
      " validation loss : 0.6144994667703977; validation accuracy : 0.9398496240601504\n",
      "Epoch 27:\t train loss : 0.5721566348173174; train accuracy : 0.9792622905491346; \n",
      " validation loss : 0.6446344630427173; validation accuracy : 0.9097744360902256\n",
      "Epoch 28:\t train loss : 0.5789732049218832; train accuracy : 0.9722805950340099; \n",
      " validation loss : 0.690865189903819; validation accuracy : 0.8421052631578947\n",
      "Epoch 29:\t train loss : 0.6007268601974637; train accuracy : 0.9493446883813527; \n",
      " validation loss : 0.6422644710787847; validation accuracy : 0.9022556390977443\n",
      "Epoch 30:\t train loss : 0.5832973417396389; train accuracy : 0.9677597743737212; \n",
      " validation loss : 0.6361012058267925; validation accuracy : 0.9172932330827067\n",
      "Epoch 31:\t train loss : 0.573463933234455; train accuracy : 0.9778244760272079; \n",
      " validation loss : 0.7007531372063106; validation accuracy : 0.8421052631578947\n",
      "Epoch 32:\t train loss : 0.5772949977789432; train accuracy : 0.9735110324614279; \n",
      " validation loss : 0.6349514036451427; validation accuracy : 0.9172932330827067\n",
      "Epoch 33:\t train loss : 0.5699088502040076; train accuracy : 0.9810872089808107; \n",
      " validation loss : 0.6502085665648447; validation accuracy : 0.9022556390977443\n",
      "Epoch 34:\t train loss : 0.5692836497798281; train accuracy : 0.9820134933362827; \n",
      " validation loss : 0.6283661661991954; validation accuracy : 0.9172932330827067\n",
      "Epoch 35:\t train loss : 0.5665721406470088; train accuracy : 0.9847232207045291; \n",
      " validation loss : 0.6749672744918618; validation accuracy : 0.8796992481203008\n",
      "Epoch 36:\t train loss : 0.6041096678736276; train accuracy : 0.9466349610131062; \n",
      " validation loss : 0.6543458132770645; validation accuracy : 0.8947368421052632\n",
      "Epoch 37:\t train loss : 0.5828986865758031; train accuracy : 0.9680224520267655; \n",
      " validation loss : 0.6401622333941404; validation accuracy : 0.9022556390977443\n",
      "Epoch 38:\t train loss : 0.5741609400253497; train accuracy : 0.9771608693247802; \n",
      " validation loss : 0.5873702855342624; validation accuracy : 0.9699248120300752\n",
      "Epoch 39:\t train loss : 0.577806919652123; train accuracy : 0.97316540397058; \n",
      " validation loss : 0.6145574632975671; validation accuracy : 0.9323308270676691\n",
      "Epoch 40:\t train loss : 0.575288447794845; train accuracy : 0.9755709782668804; \n",
      " validation loss : 0.6420746353090239; validation accuracy : 0.9172932330827067\n",
      "Epoch 41:\t train loss : 0.5702919048355032; train accuracy : 0.9810733838411768; \n",
      " validation loss : 0.6009965979933293; validation accuracy : 0.9473684210526315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:\t train loss : 0.5668409272941823; train accuracy : 0.9842255156777083; \n",
      " validation loss : 0.6123601032598711; validation accuracy : 0.9398496240601504\n",
      "Epoch 43:\t train loss : 0.5703549015309397; train accuracy : 0.9810595587015429; \n",
      " validation loss : 0.639263625092216; validation accuracy : 0.9097744360902256\n",
      "Epoch 44:\t train loss : 0.5811648074008461; train accuracy : 0.9695155671072277; \n",
      " validation loss : 0.6380105510645663; validation accuracy : 0.9097744360902256\n",
      "Epoch 45:\t train loss : 0.5763684536163055; train accuracy : 0.9742714151412929; \n",
      " validation loss : 0.6442186766572193; validation accuracy : 0.9022556390977443\n",
      "Epoch 46:\t train loss : 0.5735501434558932; train accuracy : 0.9779074268650113; \n",
      " validation loss : 0.6337259671484802; validation accuracy : 0.9172932330827067\n",
      "Epoch 47:\t train loss : 0.5619036586819935; train accuracy : 0.9894375933196925; \n",
      " validation loss : 0.6372611730637519; validation accuracy : 0.9097744360902256\n",
      "Epoch 48:\t train loss : 0.5636890077245479; train accuracy : 0.9876265000276503; \n",
      " validation loss : 0.6416756937030015; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.5627316080539414; train accuracy : 0.9886772106398275; \n",
      " validation loss : 0.6496458406285044; validation accuracy : 0.9022556390977443\n",
      "Epoch 50:\t train loss : 0.5616774276105305; train accuracy : 0.9897832218105402; \n",
      " validation loss : 0.6530504223602629; validation accuracy : 0.8947368421052632\n",
      "Epoch 51:\t train loss : 0.5702513587996283; train accuracy : 0.9809351324448377; \n",
      " validation loss : 0.6524827665765119; validation accuracy : 0.9022556390977443\n",
      "Epoch 52:\t train loss : 0.5659207613571388; train accuracy : 0.985207100591716; \n",
      " validation loss : 0.6377003231762458; validation accuracy : 0.9097744360902256\n",
      "Epoch 53:\t train loss : 0.5622919704105107; train accuracy : 0.9889260631532378; \n",
      " validation loss : 0.622835259463703; validation accuracy : 0.924812030075188\n",
      "Epoch 54:\t train loss : 0.5608951169367886; train accuracy : 0.9904744787922358; \n",
      " validation loss : 0.6324190031380759; validation accuracy : 0.9172932330827067\n",
      "Epoch 55:\t train loss : 0.560792632617619; train accuracy : 0.9905712547696731; \n",
      " validation loss : 0.6415566435508581; validation accuracy : 0.9097744360902256\n",
      "Epoch 56:\t train loss : 0.5610923480009304; train accuracy : 0.9902671016977271; \n",
      " validation loss : 0.649704267467408; validation accuracy : 0.9022556390977443\n",
      "Epoch 57:\t train loss : 0.5645396236657049; train accuracy : 0.9865481391362053; \n",
      " validation loss : 0.6276987740418906; validation accuracy : 0.924812030075188\n",
      "Epoch 58:\t train loss : 0.5810837621900053; train accuracy : 0.9693220151523531; \n",
      " validation loss : 0.6677923884343534; validation accuracy : 0.8872180451127819\n",
      "Epoch 59:\t train loss : 0.5682687449138814; train accuracy : 0.9829674279710225; \n",
      " validation loss : 0.6501473644235513; validation accuracy : 0.9022556390977443\n",
      "Epoch 60:\t train loss : 0.5651638840736422; train accuracy : 0.9858983575734115; \n",
      " validation loss : 0.6389073570109725; validation accuracy : 0.9097744360902256\n",
      "Epoch 61:\t train loss : 0.5667741710401873; train accuracy : 0.9842946413758779; \n",
      " validation loss : 0.646614184496337; validation accuracy : 0.8947368421052632\n",
      "Epoch 62:\t train loss : 0.5626310604537188; train accuracy : 0.9886633855001935; \n",
      " validation loss : 0.6647242760906378; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.5755544901121705; train accuracy : 0.9755848034065144; \n",
      " validation loss : 0.6466201392586538; validation accuracy : 0.9022556390977443\n",
      "Epoch 64:\t train loss : 0.560976481427436; train accuracy : 0.9904883039318697; \n",
      " validation loss : 0.6457979980643564; validation accuracy : 0.9097744360902256\n",
      "Epoch 65:\t train loss : 0.564530512989793; train accuracy : 0.9865619642758392; \n",
      " validation loss : 0.6705473769443535; validation accuracy : 0.8796992481203008\n",
      "Epoch 66:\t train loss : 0.5644114368523032; train accuracy : 0.9868246419288835; \n",
      " validation loss : 0.6514624650711935; validation accuracy : 0.8947368421052632\n",
      "Epoch 67:\t train loss : 0.5762618298847638; train accuracy : 0.9750870983796937; \n",
      " validation loss : 0.6197899477668318; validation accuracy : 0.9323308270676691\n",
      "Epoch 68:\t train loss : 0.5654860089546938; train accuracy : 0.9856909804789028; \n",
      " validation loss : 0.6336661504077036; validation accuracy : 0.9172932330827067\n",
      "Epoch 69:\t train loss : 0.5614868881942937; train accuracy : 0.9898108720898081; \n",
      " validation loss : 0.6647488482673254; validation accuracy : 0.8872180451127819\n",
      "Epoch 70:\t train loss : 0.5788413593089753; train accuracy : 0.971796715146823; \n",
      " validation loss : 0.6413430840854776; validation accuracy : 0.9097744360902256\n",
      "Epoch 71:\t train loss : 0.5692245420423417; train accuracy : 0.9816402145661671; \n",
      " validation loss : 0.6195980685501096; validation accuracy : 0.9323308270676691\n",
      "Epoch 72:\t train loss : 0.5697709580211073; train accuracy : 0.9811563346789802; \n",
      " validation loss : 0.6537454406510218; validation accuracy : 0.8947368421052632\n",
      "Epoch 73:\t train loss : 0.564682995566186; train accuracy : 0.9865619642758392; \n",
      " validation loss : 0.6100962459420927; validation accuracy : 0.9398496240601504\n",
      "Epoch 74:\t train loss : 0.558563848836652; train accuracy : 0.992755626831831; \n",
      " validation loss : 0.6065252920646848; validation accuracy : 0.9398496240601504\n",
      "Epoch 75:\t train loss : 0.5609615802233354; train accuracy : 0.9901565005806559; \n",
      " validation loss : 0.6206010156408326; validation accuracy : 0.9323308270676691\n",
      "Epoch 76:\t train loss : 0.5569199702734446; train accuracy : 0.9944837692860697; \n",
      " validation loss : 0.635100865013032; validation accuracy : 0.9172932330827067\n",
      "Epoch 77:\t train loss : 0.5581941634115608; train accuracy : 0.9932809821379196; \n",
      " validation loss : 0.6382785847419818; validation accuracy : 0.9097744360902256\n",
      "Epoch 78:\t train loss : 0.5628671255643848; train accuracy : 0.9884145329867832; \n",
      " validation loss : 0.6477510125764326; validation accuracy : 0.9022556390977443\n",
      "Epoch 79:\t train loss : 0.5555830569754238; train accuracy : 0.9958939335287287; \n",
      " validation loss : 0.649624676503939; validation accuracy : 0.8947368421052632\n",
      "Epoch 80:\t train loss : 0.5562099680407276; train accuracy : 0.9951059005695957; \n",
      " validation loss : 0.651608442069628; validation accuracy : 0.9022556390977443\n",
      "Epoch 81:\t train loss : 0.5562024705336825; train accuracy : 0.9952026765470331; \n",
      " validation loss : 0.626686330040443; validation accuracy : 0.924812030075188\n",
      "Epoch 82:\t train loss : 0.5534427152335698; train accuracy : 0.9979262290549135; \n",
      " validation loss : 0.6314350712434058; validation accuracy : 0.9172932330827067\n",
      "Epoch 83:\t train loss : 0.5579714926056984; train accuracy : 0.9933362826964552; \n",
      " validation loss : 0.6344284504833302; validation accuracy : 0.9172932330827067\n",
      "Epoch 84:\t train loss : 0.5577141611742087; train accuracy : 0.9935851352098656; \n",
      " validation loss : 0.6306030989279464; validation accuracy : 0.924812030075188\n",
      "Epoch 85:\t train loss : 0.5659534330980436; train accuracy : 0.9850688491953768; \n",
      " validation loss : 0.6418504149987919; validation accuracy : 0.9022556390977443\n",
      "Epoch 86:\t train loss : 0.5550483306947893; train accuracy : 0.9962810374384781; \n",
      " validation loss : 0.6415819482151764; validation accuracy : 0.9097744360902256\n",
      "Epoch 87:\t train loss : 0.5554232866055093; train accuracy : 0.9959354089476303; \n",
      " validation loss : 0.6272736667362958; validation accuracy : 0.924812030075188\n",
      "Epoch 88:\t train loss : 0.562891947618219; train accuracy : 0.9884836586849527; \n",
      " validation loss : 0.6266898499145289; validation accuracy : 0.9172932330827067\n",
      "Early stopping at epoch 88\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5741609400253497; Train accuracy : 0.9771608693247802; \n",
      " Validation loss : 0.5873702855342624; Validation accuracy : 0.9699248120300752\n",
      "------------------------------ Let's train model 45 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8754403909453822; train accuracy : 0.6668889928959014; \n",
      " validation loss : 0.7914343250400319; validation accuracy : 0.7443609022556391\n",
      "Epoch 2:\t train loss : 0.7650006864954928; train accuracy : 0.7801789310267155; \n",
      " validation loss : 0.7802104578809121; validation accuracy : 0.7744360902255639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\t train loss : 0.7340765833221047; train accuracy : 0.8143196075548655; \n",
      " validation loss : 0.7991833410195376; validation accuracy : 0.7368421052631579\n",
      "Epoch 4:\t train loss : 0.7100382633628122; train accuracy : 0.839198114925351; \n",
      " validation loss : 0.8074213413049169; validation accuracy : 0.7293233082706767\n",
      "Epoch 5:\t train loss : 0.6882836138703721; train accuracy : 0.8614491713683381; \n",
      " validation loss : 0.7778498995168485; validation accuracy : 0.7593984962406015\n",
      "Epoch 6:\t train loss : 0.665326615830634; train accuracy : 0.8851070200687076; \n",
      " validation loss : 0.7446985196996723; validation accuracy : 0.7894736842105263\n",
      "Epoch 7:\t train loss : 0.6481460058536; train accuracy : 0.9027094576094243; \n",
      " validation loss : 0.7576845711991316; validation accuracy : 0.7669172932330827\n",
      "Epoch 8:\t train loss : 0.6186011318665763; train accuracy : 0.9340547583433032; \n",
      " validation loss : 0.734357628268594; validation accuracy : 0.8195488721804511\n",
      "Epoch 9:\t train loss : 0.6187407918028999; train accuracy : 0.9326688723946356; \n",
      " validation loss : 0.7119883899828171; validation accuracy : 0.8345864661654135\n",
      "Epoch 10:\t train loss : 0.6248866613568773; train accuracy : 0.9260914779141708; \n",
      " validation loss : 0.7276987571203511; validation accuracy : 0.8270676691729323\n",
      "Epoch 11:\t train loss : 0.606698927382784; train accuracy : 0.9450595694918957; \n",
      " validation loss : 0.7243597029225396; validation accuracy : 0.8120300751879699\n",
      "Epoch 12:\t train loss : 0.6044476976897495; train accuracy : 0.9469674387613753; \n",
      " validation loss : 0.70334133865132; validation accuracy : 0.8421052631578947\n",
      "Epoch 13:\t train loss : 0.5932834547589381; train accuracy : 0.9578339985136289; \n",
      " validation loss : 0.686576922492099; validation accuracy : 0.8646616541353384\n",
      "Epoch 14:\t train loss : 0.5818936533227272; train accuracy : 0.9703009024781394; \n",
      " validation loss : 0.6983993199225865; validation accuracy : 0.8421052631578947\n",
      "Epoch 15:\t train loss : 0.5805450446011647; train accuracy : 0.9708572800487724; \n",
      " validation loss : 0.6818331926902936; validation accuracy : 0.8646616541353384\n",
      "Epoch 16:\t train loss : 0.5779641059733971; train accuracy : 0.9735804953581251; \n",
      " validation loss : 0.7039812562832387; validation accuracy : 0.8421052631578947\n",
      "Epoch 17:\t train loss : 0.5826608393361065; train accuracy : 0.9685623068695433; \n",
      " validation loss : 0.7033756574902262; validation accuracy : 0.8421052631578947\n",
      "Epoch 18:\t train loss : 0.5824432389588439; train accuracy : 0.9687693467655243; \n",
      " validation loss : 0.6918026067989647; validation accuracy : 0.849624060150376\n",
      "Epoch 19:\t train loss : 0.5730726038557135; train accuracy : 0.9787268192872163; \n",
      " validation loss : 0.6542779718627458; validation accuracy : 0.8947368421052632\n",
      "Epoch 20:\t train loss : 0.5895610924899591; train accuracy : 0.9612349828635708; \n",
      " validation loss : 0.680478270784519; validation accuracy : 0.8571428571428571\n",
      "Epoch 21:\t train loss : 0.573069016838551; train accuracy : 0.9784745947885293; \n",
      " validation loss : 0.6932051154373201; validation accuracy : 0.8571428571428571\n",
      "Epoch 22:\t train loss : 0.566425287674086; train accuracy : 0.9852799354736897; \n",
      " validation loss : 0.6773908444740422; validation accuracy : 0.8721804511278195\n",
      "Epoch 23:\t train loss : 0.5667713458202545; train accuracy : 0.9848894595786637; \n",
      " validation loss : 0.6958646759412559; validation accuracy : 0.849624060150376\n",
      "Epoch 24:\t train loss : 0.5722870321544279; train accuracy : 0.9789446495360823; \n",
      " validation loss : 0.6892948834924597; validation accuracy : 0.8421052631578947\n",
      "Epoch 25:\t train loss : 0.5688620658058768; train accuracy : 0.9824596069883721; \n",
      " validation loss : 0.673113249395691; validation accuracy : 0.8721804511278195\n",
      "Epoch 26:\t train loss : 0.5699530797434865; train accuracy : 0.9817063054775877; \n",
      " validation loss : 0.6815322608464807; validation accuracy : 0.8571428571428571\n",
      "Epoch 27:\t train loss : 0.5668340548968619; train accuracy : 0.9847168139325037; \n",
      " validation loss : 0.670384219587574; validation accuracy : 0.8721804511278195\n",
      "Epoch 28:\t train loss : 0.5750033596452434; train accuracy : 0.9758997468313454; \n",
      " validation loss : 0.6743095001421886; validation accuracy : 0.8721804511278195\n",
      "Epoch 29:\t train loss : 0.5682984425697701; train accuracy : 0.9832479771460326; \n",
      " validation loss : 0.7023038870285226; validation accuracy : 0.8421052631578947\n",
      "Epoch 30:\t train loss : 0.5666550689775961; train accuracy : 0.9846992796090656; \n",
      " validation loss : 0.6599605179449873; validation accuracy : 0.8947368421052632\n",
      "Epoch 31:\t train loss : 0.5620362292388017; train accuracy : 0.9893654328347741; \n",
      " validation loss : 0.657139154052362; validation accuracy : 0.8872180451127819\n",
      "Epoch 32:\t train loss : 0.5638256841431164; train accuracy : 0.9875782806381954; \n",
      " validation loss : 0.6833829469686; validation accuracy : 0.8646616541353384\n",
      "Epoch 33:\t train loss : 0.5622844627446055; train accuracy : 0.9892858539822472; \n",
      " validation loss : 0.6553296727852196; validation accuracy : 0.8947368421052632\n",
      "Epoch 34:\t train loss : 0.5652612138183974; train accuracy : 0.9862787175126079; \n",
      " validation loss : 0.6568417062379518; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.5626333654228537; train accuracy : 0.9888953780872212; \n",
      " validation loss : 0.6912139007422651; validation accuracy : 0.849624060150376\n",
      "Epoch 36:\t train loss : 0.5591145312351946; train accuracy : 0.9921372047321092; \n",
      " validation loss : 0.6349459032436227; validation accuracy : 0.9097744360902256\n",
      "Epoch 37:\t train loss : 0.563160022625344; train accuracy : 0.9881245422529987; \n",
      " validation loss : 0.6532636607556711; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.5664332830635154; train accuracy : 0.9848962035492168; \n",
      " validation loss : 0.6649246775528402; validation accuracy : 0.8872180451127819\n",
      "Epoch 39:\t train loss : 0.5594797867430562; train accuracy : 0.9921372047321092; \n",
      " validation loss : 0.6908048011748399; validation accuracy : 0.849624060150376\n",
      "Epoch 40:\t train loss : 0.590177204011025; train accuracy : 0.960508657234999; \n",
      " validation loss : 0.6601728438163146; validation accuracy : 0.8872180451127819\n",
      "Epoch 41:\t train loss : 0.5648859983531493; train accuracy : 0.986209929012966; \n",
      " validation loss : 0.678228886183388; validation accuracy : 0.8721804511278195\n",
      "Epoch 42:\t train loss : 0.5592557715911598; train accuracy : 0.9921614830261005; \n",
      " validation loss : 0.6247657538289673; validation accuracy : 0.924812030075188\n",
      "Epoch 43:\t train loss : 0.5579683223834675; train accuracy : 0.9935264626660534; \n",
      " validation loss : 0.6935686973468516; validation accuracy : 0.8571428571428571\n",
      "Epoch 44:\t train loss : 0.560537935695797; train accuracy : 0.9907513187834417; \n",
      " validation loss : 0.6421565507203459; validation accuracy : 0.9097744360902256\n",
      "Epoch 45:\t train loss : 0.5577603181721329; train accuracy : 0.9936889923563837; \n",
      " validation loss : 0.6789825893721441; validation accuracy : 0.8721804511278195\n",
      "Epoch 46:\t train loss : 0.5574872255524905; train accuracy : 0.9938582660172672; \n",
      " validation loss : 0.7004368601171544; validation accuracy : 0.8421052631578947\n",
      "Epoch 47:\t train loss : 0.5735789877532143; train accuracy : 0.9772923767505661; \n",
      " validation loss : 0.6659684139765678; validation accuracy : 0.8796992481203008\n",
      "Epoch 48:\t train loss : 0.5650298704184346; train accuracy : 0.9860750496019034; \n",
      " validation loss : 0.6454257299863391; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.5581852636430159; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.6276916466158966; validation accuracy : 0.9323308270676691\n",
      "Epoch 50:\t train loss : 0.5570975094100719; train accuracy : 0.9942972985002758; \n",
      " validation loss : 0.6396242797654933; validation accuracy : 0.9097744360902256\n",
      "Epoch 51:\t train loss : 0.5712973034076251; train accuracy : 0.9797741579141169; \n",
      " validation loss : 0.6504457258323659; validation accuracy : 0.9022556390977443\n",
      "Epoch 52:\t train loss : 0.5711372446657038; train accuracy : 0.9795563276652509; \n",
      " validation loss : 0.6688101797152187; validation accuracy : 0.8796992481203008\n",
      "Epoch 53:\t train loss : 0.5562337807557065; train accuracy : 0.9951268068783105; \n",
      " validation loss : 0.6604183561957775; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54:\t train loss : 0.5572973095662412; train accuracy : 0.9941866973832045; \n",
      " validation loss : 0.6637421807787421; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5561985361664149; train accuracy : 0.995175363466293; \n",
      " validation loss : 0.6412559599253422; validation accuracy : 0.9097744360902256\n",
      "Epoch 56:\t train loss : 0.5688468192555652; train accuracy : 0.9821972665338554; \n",
      " validation loss : 0.6749704912496097; validation accuracy : 0.8721804511278195\n",
      "Epoch 57:\t train loss : 0.5617787006386674; train accuracy : 0.9893755487906037; \n",
      " validation loss : 0.6535932358087294; validation accuracy : 0.8947368421052632\n",
      "Epoch 58:\t train loss : 0.5562035722109046; train accuracy : 0.9951854794221227; \n",
      " validation loss : 0.6499622078302372; validation accuracy : 0.9022556390977443\n",
      "Epoch 59:\t train loss : 0.5551054413954586; train accuracy : 0.996208539755032; \n",
      " validation loss : 0.6688674810363694; validation accuracy : 0.8796992481203008\n",
      "Epoch 60:\t train loss : 0.5586286922908639; train accuracy : 0.9926416537294831; \n",
      " validation loss : 0.6397361177711427; validation accuracy : 0.9097744360902256\n",
      "Epoch 61:\t train loss : 0.5597145994626137; train accuracy : 0.9916084774407441; \n",
      " validation loss : 0.6450126197289905; validation accuracy : 0.9022556390977443\n",
      "Epoch 62:\t train loss : 0.5569549721889331; train accuracy : 0.9943458550882583; \n",
      " validation loss : 0.6488636466467285; validation accuracy : 0.9022556390977443\n",
      "Epoch 63:\t train loss : 0.5546043460692452; train accuracy : 0.9968654024869066; \n",
      " validation loss : 0.6781081986730011; validation accuracy : 0.8796992481203008\n",
      "Epoch 64:\t train loss : 0.5569170838342586; train accuracy : 0.9944598281906062; \n",
      " validation loss : 0.6678770857191659; validation accuracy : 0.8796992481203008\n",
      "Epoch 65:\t train loss : 0.5581841322449653; train accuracy : 0.993243215902822; \n",
      " validation loss : 0.6441300763002166; validation accuracy : 0.9022556390977443\n",
      "Epoch 66:\t train loss : 0.5940227150137396; train accuracy : 0.9560542646846587; \n",
      " validation loss : 0.6957504402817413; validation accuracy : 0.8421052631578947\n",
      "Epoch 67:\t train loss : 0.5767023344336697; train accuracy : 0.9744895825886866; \n",
      " validation loss : 0.6454209093899403; validation accuracy : 0.9097744360902256\n",
      "Epoch 68:\t train loss : 0.5634734845486602; train accuracy : 0.9878514114455971; \n",
      " validation loss : 0.6556807241509961; validation accuracy : 0.9022556390977443\n",
      "Epoch 69:\t train loss : 0.5564610862743256; train accuracy : 0.9949642771879801; \n",
      " validation loss : 0.6430442258892097; validation accuracy : 0.9097744360902256\n",
      "Epoch 70:\t train loss : 0.5546100316231598; train accuracy : 0.996764917325665; \n",
      " validation loss : 0.6539831918766175; validation accuracy : 0.8947368421052632\n",
      "Epoch 71:\t train loss : 0.5544592633830677; train accuracy : 0.9968755184427363; \n",
      " validation loss : 0.6282262861491194; validation accuracy : 0.9172932330827067\n",
      "Epoch 72:\t train loss : 0.554385464018605; train accuracy : 0.9969517253099865; \n",
      " validation loss : 0.6636599987881452; validation accuracy : 0.8872180451127819\n",
      "Epoch 73:\t train loss : 0.5547058347857816; train accuracy : 0.9967096167671293; \n",
      " validation loss : 0.6414477985081919; validation accuracy : 0.9097744360902256\n",
      "Epoch 74:\t train loss : 0.5584232052856423; train accuracy : 0.9929491787867057; \n",
      " validation loss : 0.6241364415007329; validation accuracy : 0.924812030075188\n",
      "Epoch 75:\t train loss : 0.5564002205925256; train accuracy : 0.9949332549234357; \n",
      " validation loss : 0.6341663244588605; validation accuracy : 0.9172932330827067\n",
      "Epoch 76:\t train loss : 0.5538622926733848; train accuracy : 0.9976396103064056; \n",
      " validation loss : 0.6558221915677753; validation accuracy : 0.8947368421052632\n",
      "Epoch 77:\t train loss : 0.555412431746906; train accuracy : 0.996001499859051; \n",
      " validation loss : 0.6487427656999718; validation accuracy : 0.9022556390977443\n",
      "Epoch 78:\t train loss : 0.5584582426271114; train accuracy : 0.9929808754483054; \n",
      " validation loss : 0.6060197277071573; validation accuracy : 0.9473684210526315\n",
      "Epoch 79:\t train loss : 0.5552148547327433; train accuracy : 0.9961842614610408; \n",
      " validation loss : 0.6517235687281117; validation accuracy : 0.8947368421052632\n",
      "Epoch 80:\t train loss : 0.5547849796516503; train accuracy : 0.9965437150915224; \n",
      " validation loss : 0.6415185073003413; validation accuracy : 0.9097744360902256\n",
      "Epoch 81:\t train loss : 0.5549643705497066; train accuracy : 0.9965403431062458; \n",
      " validation loss : 0.6532462792297047; validation accuracy : 0.8947368421052632\n",
      "Epoch 82:\t train loss : 0.5539628773123119; train accuracy : 0.9974838245866283; \n",
      " validation loss : 0.6284984498409043; validation accuracy : 0.924812030075188\n",
      "Epoch 83:\t train loss : 0.5839881825443843; train accuracy : 0.9666126249826342; \n",
      " validation loss : 0.6892636217322299; validation accuracy : 0.849624060150376\n",
      "Epoch 84:\t train loss : 0.5941042660079591; train accuracy : 0.9565479233291476; \n",
      " validation loss : 0.6567221739640183; validation accuracy : 0.8947368421052632\n",
      "Epoch 85:\t train loss : 0.5837810876366316; train accuracy : 0.9668479895549384; \n",
      " validation loss : 0.6589576912331923; validation accuracy : 0.8872180451127819\n",
      "Epoch 86:\t train loss : 0.5705857877727049; train accuracy : 0.9803237915141967; \n",
      " validation loss : 0.6277260938883847; validation accuracy : 0.924812030075188\n",
      "Epoch 87:\t train loss : 0.5582266977772323; train accuracy : 0.993243215902822; \n",
      " validation loss : 0.6264810396420366; validation accuracy : 0.924812030075188\n",
      "Epoch 88:\t train loss : 0.5586924380476975; train accuracy : 0.9926969542880187; \n",
      " validation loss : 0.6278904027404297; validation accuracy : 0.9172932330827067\n",
      "Epoch 89:\t train loss : 0.5564640608811994; train accuracy : 0.9945947076016687; \n",
      " validation loss : 0.6517642645279106; validation accuracy : 0.8947368421052632\n",
      "Epoch 90:\t train loss : 0.5693144234820244; train accuracy : 0.9816820271835965; \n",
      " validation loss : 0.6162734981475302; validation accuracy : 0.9323308270676691\n",
      "Epoch 91:\t train loss : 0.5637579899449212; train accuracy : 0.9875263520649363; \n",
      " validation loss : 0.635886982435904; validation accuracy : 0.9097744360902256\n",
      "Epoch 92:\t train loss : 0.5564900481932681; train accuracy : 0.9949541612321504; \n",
      " validation loss : 0.6415190891368178; validation accuracy : 0.9097744360902256\n",
      "Epoch 93:\t train loss : 0.5555591757669409; train accuracy : 0.9956764404783903; \n",
      " validation loss : 0.6581052628898877; validation accuracy : 0.8872180451127819\n",
      "Epoch 94:\t train loss : 0.5544848301595015; train accuracy : 0.99694835332471; \n",
      " validation loss : 0.6145098567174224; validation accuracy : 0.9398496240601504\n",
      "Epoch 95:\t train loss : 0.5554506064505151; train accuracy : 0.9959873375208894; \n",
      " validation loss : 0.6487396824536801; validation accuracy : 0.9022556390977443\n",
      "Epoch 96:\t train loss : 0.5728490988501052; train accuracy : 0.9781185131433242; \n",
      " validation loss : 0.6366955819429444; validation accuracy : 0.9172932330827067\n",
      "Epoch 97:\t train loss : 0.5614579604246639; train accuracy : 0.9897248864652557; \n",
      " validation loss : 0.6170930854334042; validation accuracy : 0.9323308270676691\n",
      "Epoch 98:\t train loss : 0.557629799181483; train accuracy : 0.9937166426356516; \n",
      " validation loss : 0.6707722643613163; validation accuracy : 0.8796992481203008\n",
      "Epoch 99:\t train loss : 0.5543739128301731; train accuracy : 0.9970899767063257; \n",
      " validation loss : 0.6339368545657548; validation accuracy : 0.9172932330827067\n",
      "Epoch 100:\t train loss : 0.557744505525953; train accuracy : 0.9937719431941873; \n",
      " validation loss : 0.6309229140688011; validation accuracy : 0.924812030075188\n",
      "Epoch 101:\t train loss : 0.5569884773240656; train accuracy : 0.9942419979417402; \n",
      " validation loss : 0.6634618298562637; validation accuracy : 0.8872180451127819\n",
      "Epoch 102:\t train loss : 0.5542289651529206; train accuracy : 0.9972073217939501; \n",
      " validation loss : 0.6420028778495585; validation accuracy : 0.9022556390977443\n",
      "Epoch 103:\t train loss : 0.55407692556505; train accuracy : 0.997338829219736; \n",
      " validation loss : 0.6404618115494511; validation accuracy : 0.9097744360902256\n",
      "Epoch 104:\t train loss : 0.5557426539572913; train accuracy : 0.9956487901991224; \n",
      " validation loss : 0.6393892269821666; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105:\t train loss : 0.5570593062147056; train accuracy : 0.9943006704855524; \n",
      " validation loss : 0.6476182620391768; validation accuracy : 0.9022556390977443\n",
      "Epoch 106:\t train loss : 0.5549397288415648; train accuracy : 0.9965612494149605; \n",
      " validation loss : 0.6406433451437017; validation accuracy : 0.9097744360902256\n",
      "Epoch 107:\t train loss : 0.5549528305578516; train accuracy : 0.9964020917099068; \n",
      " validation loss : 0.6499817852950953; validation accuracy : 0.9022556390977443\n",
      "Epoch 108:\t train loss : 0.5557190050459585; train accuracy : 0.9956211399198547; \n",
      " validation loss : 0.6079019231881994; validation accuracy : 0.9473684210526315\n",
      "Epoch 109:\t train loss : 0.5553995722626156; train accuracy : 0.9959839655356129; \n",
      " validation loss : 0.626726846631998; validation accuracy : 0.924812030075188\n",
      "Epoch 110:\t train loss : 0.5579157299097318; train accuracy : 0.9933848392844378; \n",
      " validation loss : 0.6097562910768214; validation accuracy : 0.9398496240601504\n",
      "Epoch 111:\t train loss : 0.5566105986707901; train accuracy : 0.9947262150274547; \n",
      " validation loss : 0.6238421370473979; validation accuracy : 0.924812030075188\n",
      "Epoch 112:\t train loss : 0.5543547959540387; train accuracy : 0.9969517253099865; \n",
      " validation loss : 0.6265822436306807; validation accuracy : 0.9323308270676691\n",
      "Epoch 113:\t train loss : 0.5557652716307167; train accuracy : 0.995652162184399; \n",
      " validation loss : 0.6516300278928485; validation accuracy : 0.9022556390977443\n",
      "Epoch 114:\t train loss : 0.5941485656436692; train accuracy : 0.9565897359465769; \n",
      " validation loss : 0.679659799232077; validation accuracy : 0.8646616541353384\n",
      "Epoch 115:\t train loss : 0.5862372414613485; train accuracy : 0.9644700655379058; \n",
      " validation loss : 0.6405551390726292; validation accuracy : 0.9097744360902256\n",
      "Epoch 116:\t train loss : 0.5720775188352824; train accuracy : 0.9790383907267707; \n",
      " validation loss : 0.6496065037385929; validation accuracy : 0.9022556390977443\n",
      "Epoch 117:\t train loss : 0.5648003055945627; train accuracy : 0.9865417323641799; \n",
      " validation loss : 0.6390007070765642; validation accuracy : 0.9022556390977443\n",
      "Epoch 118:\t train loss : 0.5637111342348649; train accuracy : 0.9875162361091067; \n",
      " validation loss : 0.6323456800448766; validation accuracy : 0.9097744360902256\n",
      "Epoch 119:\t train loss : 0.5639668968727495; train accuracy : 0.9870670876702684; \n",
      " validation loss : 0.65655789373361; validation accuracy : 0.8947368421052632\n",
      "Epoch 120:\t train loss : 0.5594164583232067; train accuracy : 0.9919160024979666; \n",
      " validation loss : 0.6493886370475058; validation accuracy : 0.9022556390977443\n",
      "Epoch 121:\t train loss : 0.5583822496286618; train accuracy : 0.9930186416834029; \n",
      " validation loss : 0.6312684361935337; validation accuracy : 0.9172932330827067\n",
      "Epoch 122:\t train loss : 0.5580544425410047; train accuracy : 0.9932674941968134; \n",
      " validation loss : 0.6667377894900844; validation accuracy : 0.8796992481203008\n",
      "Epoch 123:\t train loss : 0.5564362108746805; train accuracy : 0.9949507892468739; \n",
      " validation loss : 0.6773374215760772; validation accuracy : 0.8646616541353384\n",
      "Epoch 124:\t train loss : 0.5555370087688136; train accuracy : 0.9960116158148807; \n",
      " validation loss : 0.6408185012200857; validation accuracy : 0.9097744360902256\n",
      "Epoch 125:\t train loss : 0.5563216594932239; train accuracy : 0.9951443412017486; \n",
      " validation loss : 0.6542972135433137; validation accuracy : 0.8947368421052632\n",
      "Epoch 126:\t train loss : 0.5572282640868345; train accuracy : 0.9941003745601245; \n",
      " validation loss : 0.6280623189040425; validation accuracy : 0.924812030075188\n",
      "Epoch 127:\t train loss : 0.555214579748711; train accuracy : 0.9961431232406667; \n",
      " validation loss : 0.6358562687629905; validation accuracy : 0.9172932330827067\n",
      "Epoch 128:\t train loss : 0.5588887559903749; train accuracy : 0.9923617789515283; \n",
      " validation loss : 0.6364015435820662; validation accuracy : 0.9172932330827067\n",
      "Early stopping at epoch 128\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5584582426271114; Train accuracy : 0.9929808754483054; \n",
      " Validation loss : 0.6060197277071573; Validation accuracy : 0.9473684210526315\n",
      "------------------------------ Let's train model 46 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9156243103827325; train accuracy : 0.6125919371785655; \n",
      " validation loss : 0.8593533316805186; validation accuracy : 0.6691729323308271\n",
      "Epoch 2:\t train loss : 0.7950695915594125; train accuracy : 0.7469308190012719; \n",
      " validation loss : 0.7709474977981409; validation accuracy : 0.7819548872180451\n",
      "Epoch 3:\t train loss : 0.7395073440531352; train accuracy : 0.8086877177459493; \n",
      " validation loss : 0.7348226469307043; validation accuracy : 0.7894736842105263\n",
      "Epoch 4:\t train loss : 0.69416173549357; train accuracy : 0.8536470718354255; \n",
      " validation loss : 0.7440221919858598; validation accuracy : 0.8120300751879699\n",
      "Epoch 5:\t train loss : 0.6651888726974623; train accuracy : 0.8843250566830725; \n",
      " validation loss : 0.7191150835576217; validation accuracy : 0.8270676691729323\n",
      "Epoch 6:\t train loss : 0.6377872004265758; train accuracy : 0.9122380136039374; \n",
      " validation loss : 0.7613241327415511; validation accuracy : 0.7819548872180451\n",
      "Epoch 7:\t train loss : 0.6398946604231665; train accuracy : 0.9100951169606813; \n",
      " validation loss : 0.7359595649977189; validation accuracy : 0.7969924812030075\n",
      "Epoch 8:\t train loss : 0.6158366902389237; train accuracy : 0.9351324448376929; \n",
      " validation loss : 0.6980580659241056; validation accuracy : 0.849624060150376\n",
      "Epoch 9:\t train loss : 0.6060749642487692; train accuracy : 0.9459437040314107; \n",
      " validation loss : 0.6766110183326879; validation accuracy : 0.8721804511278195\n",
      "Epoch 10:\t train loss : 0.6023393044986209; train accuracy : 0.9493446883813527; \n",
      " validation loss : 0.6612025867943283; validation accuracy : 0.8947368421052632\n",
      "Epoch 11:\t train loss : 0.5991201947081449; train accuracy : 0.9517779129569208; \n",
      " validation loss : 0.6617853667901348; validation accuracy : 0.8872180451127819\n",
      "Epoch 12:\t train loss : 0.5916799120442708; train accuracy : 0.9602112481336061; \n",
      " validation loss : 0.6674153425475019; validation accuracy : 0.8872180451127819\n",
      "Epoch 13:\t train loss : 0.5968303185747775; train accuracy : 0.9540867112757839; \n",
      " validation loss : 0.6809405515387512; validation accuracy : 0.8646616541353384\n",
      "Epoch 14:\t train loss : 0.5967343874246934; train accuracy : 0.9542802632306586; \n",
      " validation loss : 0.6935616681598972; validation accuracy : 0.849624060150376\n",
      "Epoch 15:\t train loss : 0.5922987683480493; train accuracy : 0.9591743626610629; \n",
      " validation loss : 0.7581636225625435; validation accuracy : 0.7819548872180451\n",
      "Epoch 16:\t train loss : 0.5922266444460935; train accuracy : 0.9592434883592325; \n",
      " validation loss : 0.6554232614337709; validation accuracy : 0.9022556390977443\n",
      "Epoch 17:\t train loss : 0.5842038747799442; train accuracy : 0.9672067687883648; \n",
      " validation loss : 0.6643914935629275; validation accuracy : 0.8796992481203008\n",
      "Epoch 18:\t train loss : 0.5812469535757518; train accuracy : 0.9704695017419676; \n",
      " validation loss : 0.716958543718046; validation accuracy : 0.8195488721804511\n",
      "Epoch 19:\t train loss : 0.5936809436991034; train accuracy : 0.9569208649007355; \n",
      " validation loss : 0.6758701244474437; validation accuracy : 0.8796992481203008\n",
      "Epoch 20:\t train loss : 0.5814309257824127; train accuracy : 0.9695846928053973; \n",
      " validation loss : 0.6757500897509966; validation accuracy : 0.8721804511278195\n",
      "Epoch 21:\t train loss : 0.5776988216585297; train accuracy : 0.9739949123486147; \n",
      " validation loss : 0.7185301176519752; validation accuracy : 0.8270676691729323\n",
      "Epoch 22:\t train loss : 0.5778417283402073; train accuracy : 0.9734419067632583; \n",
      " validation loss : 0.6966397585995193; validation accuracy : 0.8646616541353384\n",
      "Epoch 23:\t train loss : 0.590326277649126; train accuracy : 0.9611513576287121; \n",
      " validation loss : 0.7469715528759273; validation accuracy : 0.8045112781954887\n",
      "Epoch 24:\t train loss : 0.6008882383060218; train accuracy : 0.9499391693856107; \n",
      " validation loss : 0.691035266370857; validation accuracy : 0.8571428571428571\n",
      "Epoch 25:\t train loss : 0.5776616450756334; train accuracy : 0.973345130785821; \n",
      " validation loss : 0.6643479067994807; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:\t train loss : 0.5722665958913755; train accuracy : 0.9794696676436432; \n",
      " validation loss : 0.654372603258305; validation accuracy : 0.9022556390977443\n",
      "Epoch 27:\t train loss : 0.568270749560605; train accuracy : 0.982884477133219; \n",
      " validation loss : 0.671281195885479; validation accuracy : 0.8796992481203008\n",
      "Epoch 28:\t train loss : 0.5706021353270218; train accuracy : 0.9808383564674004; \n",
      " validation loss : 0.6838246769435742; validation accuracy : 0.8646616541353384\n",
      "Epoch 29:\t train loss : 0.5672357611251807; train accuracy : 0.9841563899795388; \n",
      " validation loss : 0.6561080056861454; validation accuracy : 0.8872180451127819\n",
      "Epoch 30:\t train loss : 0.5689310953326094; train accuracy : 0.9822485207100592; \n",
      " validation loss : 0.6640041571141149; validation accuracy : 0.8872180451127819\n",
      "Epoch 31:\t train loss : 0.5709685866282842; train accuracy : 0.9801470994857048; \n",
      " validation loss : 0.6749522091817604; validation accuracy : 0.8646616541353384\n",
      "Epoch 32:\t train loss : 0.5657479513596041; train accuracy : 0.9855389039429299; \n",
      " validation loss : 0.6343976601111765; validation accuracy : 0.9172932330827067\n",
      "Epoch 33:\t train loss : 0.5636752396938804; train accuracy : 0.9880827296355693; \n",
      " validation loss : 0.6961609441252256; validation accuracy : 0.8571428571428571\n",
      "Epoch 34:\t train loss : 0.5621533007136976; train accuracy : 0.989506719017862; \n",
      " validation loss : 0.6607412596253279; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.5643426250229872; train accuracy : 0.9871011447215617; \n",
      " validation loss : 0.6654786863428489; validation accuracy : 0.8872180451127819\n",
      "Epoch 36:\t train loss : 0.5714369816515744; train accuracy : 0.9795111430625449; \n",
      " validation loss : 0.6642152449897567; validation accuracy : 0.8796992481203008\n",
      "Epoch 37:\t train loss : 0.5684174011563341; train accuracy : 0.9828568268539513; \n",
      " validation loss : 0.6745054112243883; validation accuracy : 0.8796992481203008\n",
      "Epoch 38:\t train loss : 0.5729973922233088; train accuracy : 0.9781701045180556; \n",
      " validation loss : 0.7070697144862049; validation accuracy : 0.8421052631578947\n",
      "Epoch 39:\t train loss : 0.5966510999518573; train accuracy : 0.9537272576453022; \n",
      " validation loss : 0.693597456490111; validation accuracy : 0.849624060150376\n",
      "Epoch 40:\t train loss : 0.617780386002289; train accuracy : 0.9325194934468838; \n",
      " validation loss : 0.7250826909975346; validation accuracy : 0.8270676691729323\n",
      "Epoch 41:\t train loss : 0.5911890467550143; train accuracy : 0.9594370403141071; \n",
      " validation loss : 0.6683874894826912; validation accuracy : 0.8872180451127819\n",
      "Epoch 42:\t train loss : 0.5734563551008243; train accuracy : 0.9776309240723331; \n",
      " validation loss : 0.6707171950769519; validation accuracy : 0.8796992481203008\n",
      "Epoch 43:\t train loss : 0.566987976671975; train accuracy : 0.9841010894210032; \n",
      " validation loss : 0.6790576982619732; validation accuracy : 0.8721804511278195\n",
      "Epoch 44:\t train loss : 0.5651782857822032; train accuracy : 0.9861748603660897; \n",
      " validation loss : 0.7103626752195011; validation accuracy : 0.8421052631578947\n",
      "Epoch 45:\t train loss : 0.5616171329408286; train accuracy : 0.9897417463916386; \n",
      " validation loss : 0.6869203203272146; validation accuracy : 0.8646616541353384\n",
      "Epoch 46:\t train loss : 0.5608033969747445; train accuracy : 0.9905850799093071; \n",
      " validation loss : 0.683844507801207; validation accuracy : 0.8721804511278195\n",
      "Epoch 47:\t train loss : 0.5622013599836367; train accuracy : 0.9890366642703091; \n",
      " validation loss : 0.7096916897990196; validation accuracy : 0.8345864661654135\n",
      "Epoch 48:\t train loss : 0.5599873118419928; train accuracy : 0.9913039871702705; \n",
      " validation loss : 0.6879049791741719; validation accuracy : 0.8646616541353384\n",
      "Epoch 49:\t train loss : 0.5679518150609136; train accuracy : 0.9831056793673616; \n",
      " validation loss : 0.6523751727263216; validation accuracy : 0.9022556390977443\n",
      "Epoch 50:\t train loss : 0.5623181946649993; train accuracy : 0.9888569374550683; \n",
      " validation loss : 0.7105768596741809; validation accuracy : 0.8421052631578947\n",
      "Epoch 51:\t train loss : 0.5717743369475358; train accuracy : 0.9790825637338937; \n",
      " validation loss : 0.6843374718851276; validation accuracy : 0.8646616541353384\n",
      "Epoch 52:\t train loss : 0.5732141985549163; train accuracy : 0.9778659514461095; \n",
      " validation loss : 0.649306877149074; validation accuracy : 0.8947368421052632\n",
      "Epoch 53:\t train loss : 0.5621897731813411; train accuracy : 0.9893961179007909; \n",
      " validation loss : 0.6447050613885706; validation accuracy : 0.9022556390977443\n",
      "Epoch 54:\t train loss : 0.5613607476966294; train accuracy : 0.9901012000221202; \n",
      " validation loss : 0.6978478277170029; validation accuracy : 0.8571428571428571\n",
      "Epoch 55:\t train loss : 0.5718013372275245; train accuracy : 0.9795526184814467; \n",
      " validation loss : 0.7210850466640901; validation accuracy : 0.8195488721804511\n",
      "Epoch 56:\t train loss : 0.5843013588244861; train accuracy : 0.9666814134822762; \n",
      " validation loss : 0.7120422679135288; validation accuracy : 0.8345864661654135\n",
      "Epoch 57:\t train loss : 0.5674751987126818; train accuracy : 0.9837554609301554; \n",
      " validation loss : 0.6770140083967373; validation accuracy : 0.8721804511278195\n",
      "Epoch 58:\t train loss : 0.5637210703041208; train accuracy : 0.9875297240502129; \n",
      " validation loss : 0.6720425863555153; validation accuracy : 0.8796992481203008\n",
      "Epoch 59:\t train loss : 0.5572002051303847; train accuracy : 0.9942487419122933; \n",
      " validation loss : 0.6498252392015008; validation accuracy : 0.9022556390977443\n",
      "Epoch 60:\t train loss : 0.5698004367619726; train accuracy : 0.9813913620527568; \n",
      " validation loss : 0.6993853862565866; validation accuracy : 0.849624060150376\n",
      "Epoch 61:\t train loss : 0.5728016236659684; train accuracy : 0.9783221810540287; \n",
      " validation loss : 0.6731580245363888; validation accuracy : 0.8796992481203008\n",
      "Epoch 62:\t train loss : 0.5616757205484232; train accuracy : 0.9895896698556655; \n",
      " validation loss : 0.660945714594642; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.5560715652154726; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6486165635101029; validation accuracy : 0.9022556390977443\n",
      "Epoch 64:\t train loss : 0.5555297771493007; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6715693035872751; validation accuracy : 0.8796992481203008\n",
      "Epoch 65:\t train loss : 0.5568899931288812; train accuracy : 0.9944146435879002; \n",
      " validation loss : 0.6370833566743679; validation accuracy : 0.9097744360902256\n",
      "Epoch 66:\t train loss : 0.5572264697221908; train accuracy : 0.9941657910744899; \n",
      " validation loss : 0.6704955289955903; validation accuracy : 0.8796992481203008\n",
      "Epoch 67:\t train loss : 0.556263529479369; train accuracy : 0.995216501686667; \n",
      " validation loss : 0.6472033814757628; validation accuracy : 0.9097744360902256\n",
      "Epoch 68:\t train loss : 0.5586284934524918; train accuracy : 0.9927971022507327; \n",
      " validation loss : 0.7033573270411005; validation accuracy : 0.8421052631578947\n",
      "Epoch 69:\t train loss : 0.58283638962977; train accuracy : 0.9678012497926229; \n",
      " validation loss : 0.6816456613238788; validation accuracy : 0.8721804511278195\n",
      "Epoch 70:\t train loss : 0.5681798156909426; train accuracy : 0.9830780290880938; \n",
      " validation loss : 0.6761137732495331; validation accuracy : 0.8796992481203008\n",
      "Epoch 71:\t train loss : 0.5618589903528427; train accuracy : 0.9892716916440856; \n",
      " validation loss : 0.6957064021879614; validation accuracy : 0.849624060150376\n",
      "Epoch 72:\t train loss : 0.5625662407962453; train accuracy : 0.9888016368965327; \n",
      " validation loss : 0.673378709627258; validation accuracy : 0.8796992481203008\n",
      "Epoch 73:\t train loss : 0.5576386489879221; train accuracy : 0.9937648620251064; \n",
      " validation loss : 0.6571213107797421; validation accuracy : 0.8947368421052632\n",
      "Epoch 74:\t train loss : 0.5648677166604736; train accuracy : 0.9864098877398662; \n",
      " validation loss : 0.6655992604051102; validation accuracy : 0.8872180451127819\n",
      "Epoch 75:\t train loss : 0.5835826756439003; train accuracy : 0.9672482442072665; \n",
      " validation loss : 0.6902664563984403; validation accuracy : 0.849624060150376\n",
      "Epoch 76:\t train loss : 0.5656717271552272; train accuracy : 0.9854974285240281; \n",
      " validation loss : 0.6425842813132375; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77:\t train loss : 0.5610893029707184; train accuracy : 0.9901288503013881; \n",
      " validation loss : 0.6562462231802151; validation accuracy : 0.8947368421052632\n",
      "Epoch 78:\t train loss : 0.557431378869727; train accuracy : 0.9939722391196151; \n",
      " validation loss : 0.6419076873582654; validation accuracy : 0.9097744360902256\n",
      "Epoch 79:\t train loss : 0.5578108390703767; train accuracy : 0.9935851352098656; \n",
      " validation loss : 0.6382849791485573; validation accuracy : 0.9172932330827067\n",
      "Epoch 80:\t train loss : 0.5601259888574034; train accuracy : 0.9911795609135652; \n",
      " validation loss : 0.6670792338060799; validation accuracy : 0.8796992481203008\n",
      "Epoch 81:\t train loss : 0.5558292162465092; train accuracy : 0.9955068296189792; \n",
      " validation loss : 0.6482035161676261; validation accuracy : 0.9022556390977443\n",
      "Epoch 82:\t train loss : 0.555490720712101; train accuracy : 0.9958801083890947; \n",
      " validation loss : 0.6566758378809507; validation accuracy : 0.8947368421052632\n",
      "Early stopping at epoch 82\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5657479513596041; Train accuracy : 0.9855389039429299; \n",
      " Validation loss : 0.6343976601111765; Validation accuracy : 0.9172932330827067\n",
      "------------------------------ Let's train model 47 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8848077049598553; train accuracy : 0.6532378477022618; \n",
      " validation loss : 0.8096412628669601; validation accuracy : 0.7368421052631579\n",
      "Epoch 2:\t train loss : 0.7775395590897441; train accuracy : 0.7647099485704806; \n",
      " validation loss : 0.7745126294181685; validation accuracy : 0.7669172932330827\n",
      "Epoch 3:\t train loss : 0.7179500820317323; train accuracy : 0.8306143892053309; \n",
      " validation loss : 0.7202519349378561; validation accuracy : 0.8045112781954887\n",
      "Epoch 4:\t train loss : 0.6758886096335242; train accuracy : 0.8738179505613006; \n",
      " validation loss : 0.7275332450167497; validation accuracy : 0.8195488721804511\n",
      "Epoch 5:\t train loss : 0.6454146570618134; train accuracy : 0.9058784493723386; \n",
      " validation loss : 0.6632354871144279; validation accuracy : 0.9097744360902256\n",
      "Epoch 6:\t train loss : 0.6252092364014922; train accuracy : 0.9257590001659017; \n",
      " validation loss : 0.6359790274424566; validation accuracy : 0.9172932330827067\n",
      "Epoch 7:\t train loss : 0.6241815823194798; train accuracy : 0.9265470331250346; \n",
      " validation loss : 0.6472469172502489; validation accuracy : 0.9022556390977443\n",
      "Epoch 8:\t train loss : 0.6100197769243305; train accuracy : 0.9409804789028369; \n",
      " validation loss : 0.6627211694878811; validation accuracy : 0.8721804511278195\n",
      "Epoch 9:\t train loss : 0.59356855228024; train accuracy : 0.9582480783055909; \n",
      " validation loss : 0.6426281692745502; validation accuracy : 0.9022556390977443\n",
      "Epoch 10:\t train loss : 0.5925978023491304; train accuracy : 0.9588149090305812; \n",
      " validation loss : 0.6341161093100223; validation accuracy : 0.9172932330827067\n",
      "Epoch 11:\t train loss : 0.5861442687364146; train accuracy : 0.9653680252170547; \n",
      " validation loss : 0.6567704049233769; validation accuracy : 0.8646616541353384\n",
      "Epoch 12:\t train loss : 0.5890602624168322; train accuracy : 0.9619117403085771; \n",
      " validation loss : 0.629100974431855; validation accuracy : 0.9172932330827067\n",
      "Epoch 13:\t train loss : 0.57919994324973; train accuracy : 0.972570922966322; \n",
      " validation loss : 0.6257458350246594; validation accuracy : 0.924812030075188\n",
      "Epoch 14:\t train loss : 0.5826831674548931; train accuracy : 0.9690455123596748; \n",
      " validation loss : 0.6187173274868264; validation accuracy : 0.9323308270676691\n",
      "Epoch 15:\t train loss : 0.5783665779401467; train accuracy : 0.9728612508986341; \n",
      " validation loss : 0.6151544972551699; validation accuracy : 0.9323308270676691\n",
      "Epoch 16:\t train loss : 0.5679007935046299; train accuracy : 0.9838798871868606; \n",
      " validation loss : 0.6215265325970221; validation accuracy : 0.924812030075188\n",
      "Epoch 17:\t train loss : 0.5643631915599486; train accuracy : 0.9873914726538738; \n",
      " validation loss : 0.6153827246701278; validation accuracy : 0.9323308270676691\n",
      "Epoch 18:\t train loss : 0.5622584384549515; train accuracy : 0.9896034949952994; \n",
      " validation loss : 0.6355595835675972; validation accuracy : 0.9172932330827067\n",
      "Epoch 19:\t train loss : 0.5660512032389118; train accuracy : 0.9852762262898855; \n",
      " validation loss : 0.609561137776109; validation accuracy : 0.9398496240601504\n",
      "Epoch 20:\t train loss : 0.5675220475889312; train accuracy : 0.9841010894210032; \n",
      " validation loss : 0.6183240877019968; validation accuracy : 0.924812030075188\n",
      "Epoch 21:\t train loss : 0.5700938218071029; train accuracy : 0.9811701598186142; \n",
      " validation loss : 0.6096580664307355; validation accuracy : 0.9398496240601504\n",
      "Epoch 22:\t train loss : 0.5727253137035998; train accuracy : 0.9787231101034121; \n",
      " validation loss : 0.6233508404127545; validation accuracy : 0.9172932330827067\n",
      "Epoch 23:\t train loss : 0.5682002720960722; train accuracy : 0.9830642039484598; \n",
      " validation loss : 0.6430314838086474; validation accuracy : 0.9022556390977443\n",
      "Epoch 24:\t train loss : 0.5721284665464258; train accuracy : 0.9792346402698667; \n",
      " validation loss : 0.6452712141346777; validation accuracy : 0.9022556390977443\n",
      "Epoch 25:\t train loss : 0.5691697628389744; train accuracy : 0.9823038212685948; \n",
      " validation loss : 0.5992785862659789; validation accuracy : 0.9548872180451128\n",
      "Epoch 26:\t train loss : 0.566435773987684; train accuracy : 0.9849858983575734; \n",
      " validation loss : 0.6332580829643643; validation accuracy : 0.924812030075188\n",
      "Epoch 27:\t train loss : 0.5613788841895143; train accuracy : 0.9901012000221202; \n",
      " validation loss : 0.6300467538391304; validation accuracy : 0.924812030075188\n",
      "Epoch 28:\t train loss : 0.5628398752578554; train accuracy : 0.9883868827075153; \n",
      " validation loss : 0.6496703469529878; validation accuracy : 0.9022556390977443\n",
      "Epoch 29:\t train loss : 0.55962806462535; train accuracy : 0.9920367195708677; \n",
      " validation loss : 0.6127261030661163; validation accuracy : 0.9398496240601504\n",
      "Epoch 30:\t train loss : 0.5585960430478892; train accuracy : 0.9927694519714649; \n",
      " validation loss : 0.6377262672727136; validation accuracy : 0.9097744360902256\n",
      "Epoch 31:\t train loss : 0.566132449176011; train accuracy : 0.9854283028258586; \n",
      " validation loss : 0.6221870562085057; validation accuracy : 0.9323308270676691\n",
      "Epoch 32:\t train loss : 0.5617700635888978; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.6182735146319623; validation accuracy : 0.9323308270676691\n",
      "Epoch 33:\t train loss : 0.5614201868519302; train accuracy : 0.9898523475087099; \n",
      " validation loss : 0.6095629046477272; validation accuracy : 0.9398496240601504\n",
      "Epoch 34:\t train loss : 0.5691988595510225; train accuracy : 0.9817231654039705; \n",
      " validation loss : 0.6450193409557209; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.5624791145740533; train accuracy : 0.9888292871758004; \n",
      " validation loss : 0.6270026942683696; validation accuracy : 0.924812030075188\n",
      "Epoch 36:\t train loss : 0.5607428053515897; train accuracy : 0.990750981584914; \n",
      " validation loss : 0.6084194719843292; validation accuracy : 0.9473684210526315\n",
      "Epoch 37:\t train loss : 0.5684659364894936; train accuracy : 0.9823452966874965; \n",
      " validation loss : 0.601969166213353; validation accuracy : 0.9473684210526315\n",
      "Epoch 38:\t train loss : 0.561278533219913; train accuracy : 0.9901565005806559; \n",
      " validation loss : 0.6169909969557414; validation accuracy : 0.9323308270676691\n",
      "Epoch 39:\t train loss : 0.55846075581909; train accuracy : 0.9928938782281701; \n",
      " validation loss : 0.6383290992605256; validation accuracy : 0.9097744360902256\n",
      "Epoch 40:\t train loss : 0.5611218791690007; train accuracy : 0.9904606536526018; \n",
      " validation loss : 0.6175125412665353; validation accuracy : 0.9323308270676691\n",
      "Epoch 41:\t train loss : 0.565535551508829; train accuracy : 0.9856218547807333; \n",
      " validation loss : 0.5922887849842431; validation accuracy : 0.9624060150375939\n",
      "Epoch 42:\t train loss : 0.5707420653150624; train accuracy : 0.9803959519991152; \n",
      " validation loss : 0.6543086888560524; validation accuracy : 0.8872180451127819\n",
      "Epoch 43:\t train loss : 0.5698576485614975; train accuracy : 0.9810042581430073; \n",
      " validation loss : 0.6645372831634755; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:\t train loss : 0.5675546488038394; train accuracy : 0.9837554609301554; \n",
      " validation loss : 0.6311361892982188; validation accuracy : 0.9172932330827067\n",
      "Epoch 45:\t train loss : 0.5626853465575636; train accuracy : 0.9886495603605596; \n",
      " validation loss : 0.6219950922060089; validation accuracy : 0.924812030075188\n",
      "Epoch 46:\t train loss : 0.5711377722149894; train accuracy : 0.9801470994857048; \n",
      " validation loss : 0.6372453132472768; validation accuracy : 0.9172932330827067\n",
      "Epoch 47:\t train loss : 0.564294573308267; train accuracy : 0.9867693413703479; \n",
      " validation loss : 0.6296199219843376; validation accuracy : 0.924812030075188\n",
      "Epoch 48:\t train loss : 0.5592319778958397; train accuracy : 0.9920090692915998; \n",
      " validation loss : 0.6444761769131633; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.5577536436193766; train accuracy : 0.9934745340927943; \n",
      " validation loss : 0.6223733282695347; validation accuracy : 0.924812030075188\n",
      "Epoch 50:\t train loss : 0.5573099826105269; train accuracy : 0.9940413648177846; \n",
      " validation loss : 0.6031350379564026; validation accuracy : 0.9473684210526315\n",
      "Epoch 51:\t train loss : 0.5641258036097287; train accuracy : 0.9869767184648565; \n",
      " validation loss : 0.6508104018314265; validation accuracy : 0.8947368421052632\n",
      "Epoch 52:\t train loss : 0.5613425215376773; train accuracy : 0.9901012000221202; \n",
      " validation loss : 0.5986951942763201; validation accuracy : 0.9548872180451128\n",
      "Epoch 53:\t train loss : 0.5570134146498433; train accuracy : 0.9943593430293646; \n",
      " validation loss : 0.6233397933716791; validation accuracy : 0.9323308270676691\n",
      "Epoch 54:\t train loss : 0.5605978518987719; train accuracy : 0.9904330033733341; \n",
      " validation loss : 0.6332990195067083; validation accuracy : 0.9172932330827067\n",
      "Epoch 55:\t train loss : 0.558885933722867; train accuracy : 0.9923132223635459; \n",
      " validation loss : 0.6041554689950527; validation accuracy : 0.9473684210526315\n",
      "Epoch 56:\t train loss : 0.5604265500734313; train accuracy : 0.9909998340983244; \n",
      " validation loss : 0.5969239981056176; validation accuracy : 0.9548872180451128\n",
      "Epoch 57:\t train loss : 0.5558511614355272; train accuracy : 0.9955483050378808; \n",
      " validation loss : 0.6237217407166652; validation accuracy : 0.924812030075188\n",
      "Epoch 58:\t train loss : 0.5559364879657506; train accuracy : 0.9954377039208095; \n",
      " validation loss : 0.6324466364850011; validation accuracy : 0.9172932330827067\n",
      "Epoch 59:\t train loss : 0.5561416517444201; train accuracy : 0.9951612011281313; \n",
      " validation loss : 0.6317462785292309; validation accuracy : 0.9172932330827067\n",
      "Epoch 60:\t train loss : 0.5569026899619376; train accuracy : 0.9943316927500968; \n",
      " validation loss : 0.6241984585034424; validation accuracy : 0.924812030075188\n",
      "Epoch 61:\t train loss : 0.5551898421700998; train accuracy : 0.9962672122988442; \n",
      " validation loss : 0.6319238927566161; validation accuracy : 0.9097744360902256\n",
      "Epoch 62:\t train loss : 0.5552773514862936; train accuracy : 0.9961842614610408; \n",
      " validation loss : 0.6143328381774485; validation accuracy : 0.9398496240601504\n",
      "Epoch 63:\t train loss : 0.563686126338069; train accuracy : 0.9876126748880164; \n",
      " validation loss : 0.6046349143071867; validation accuracy : 0.9473684210526315\n",
      "Epoch 64:\t train loss : 0.5657771517509265; train accuracy : 0.9852900514295194; \n",
      " validation loss : 0.5994244845958528; validation accuracy : 0.9473684210526315\n",
      "Epoch 65:\t train loss : 0.5613737536554984; train accuracy : 0.9898385223690759; \n",
      " validation loss : 0.6161594846000943; validation accuracy : 0.9323308270676691\n",
      "Epoch 66:\t train loss : 0.5587191966990379; train accuracy : 0.9926450257147597; \n",
      " validation loss : 0.6269343184899286; validation accuracy : 0.924812030075188\n",
      "Epoch 67:\t train loss : 0.55673739146869; train accuracy : 0.9947049715202123; \n",
      " validation loss : 0.6289429651896945; validation accuracy : 0.9172932330827067\n",
      "Epoch 68:\t train loss : 0.5560944759835137; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.6543545427886525; validation accuracy : 0.8947368421052632\n",
      "Epoch 69:\t train loss : 0.5629267003103579; train accuracy : 0.9883868827075153; \n",
      " validation loss : 0.6229526886003228; validation accuracy : 0.924812030075188\n",
      "Epoch 70:\t train loss : 0.5607899179655332; train accuracy : 0.9905159542111375; \n",
      " validation loss : 0.6326206925366914; validation accuracy : 0.9172932330827067\n",
      "Epoch 71:\t train loss : 0.5619375330495552; train accuracy : 0.9891472653873804; \n",
      " validation loss : 0.6385973321285487; validation accuracy : 0.9172932330827067\n",
      "Epoch 72:\t train loss : 0.5619107317203144; train accuracy : 0.989202565945916; \n",
      " validation loss : 0.6059963429047452; validation accuracy : 0.9473684210526315\n",
      "Epoch 73:\t train loss : 0.5592436219992183; train accuracy : 0.9920920201294033; \n",
      " validation loss : 0.6117797172042824; validation accuracy : 0.9398496240601504\n",
      "Epoch 74:\t train loss : 0.5706323704516262; train accuracy : 0.9806309793728917; \n",
      " validation loss : 0.6620532928124145; validation accuracy : 0.8872180451127819\n",
      "Epoch 75:\t train loss : 0.5902967012542673; train accuracy : 0.9601835978543384; \n",
      " validation loss : 0.6368753515355168; validation accuracy : 0.9097744360902256\n",
      "Epoch 76:\t train loss : 0.5755481160969774; train accuracy : 0.9755571531272466; \n",
      " validation loss : 0.6711813807671125; validation accuracy : 0.8872180451127819\n",
      "Epoch 77:\t train loss : 0.5775571798995848; train accuracy : 0.9732345296687497; \n",
      " validation loss : 0.6385078666003162; validation accuracy : 0.9097744360902256\n",
      "Epoch 78:\t train loss : 0.5598999657964336; train accuracy : 0.991511364264779; \n",
      " validation loss : 0.5960194670920359; validation accuracy : 0.9548872180451128\n",
      "Epoch 79:\t train loss : 0.5566501447631271; train accuracy : 0.9946911463805784; \n",
      " validation loss : 0.5992321682885331; validation accuracy : 0.9548872180451128\n",
      "Epoch 80:\t train loss : 0.559818512953444; train accuracy : 0.991677265940386; \n",
      " validation loss : 0.6104675783240636; validation accuracy : 0.9398496240601504\n",
      "Epoch 81:\t train loss : 0.5579705330061719; train accuracy : 0.9933362826964552; \n",
      " validation loss : 0.6336019727798963; validation accuracy : 0.9097744360902256\n",
      "Epoch 82:\t train loss : 0.5573407004260494; train accuracy : 0.9938892882818117; \n",
      " validation loss : 0.6162720145595639; validation accuracy : 0.9398496240601504\n",
      "Epoch 83:\t train loss : 0.5573023000340435; train accuracy : 0.9940551899574186; \n",
      " validation loss : 0.635908161058309; validation accuracy : 0.9172932330827067\n",
      "Epoch 84:\t train loss : 0.5571946780368058; train accuracy : 0.9942763921915612; \n",
      " validation loss : 0.5994903522920414; validation accuracy : 0.9548872180451128\n",
      "Epoch 85:\t train loss : 0.5561942386933787; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6069107438568836; validation accuracy : 0.9473684210526315\n",
      "Epoch 86:\t train loss : 0.556527511082967; train accuracy : 0.9948017474976497; \n",
      " validation loss : 0.6156242721308882; validation accuracy : 0.9323308270676691\n",
      "Epoch 87:\t train loss : 0.5553623664669973; train accuracy : 0.9960874854836034; \n",
      " validation loss : 0.6051394362810008; validation accuracy : 0.9473684210526315\n",
      "Epoch 88:\t train loss : 0.5545995473196117; train accuracy : 0.9967787424652989; \n",
      " validation loss : 0.6569665073315684; validation accuracy : 0.8872180451127819\n",
      "Epoch 89:\t train loss : 0.5630804847534084; train accuracy : 0.9880827296355693; \n",
      " validation loss : 0.6224487668058197; validation accuracy : 0.9323308270676691\n",
      "Epoch 90:\t train loss : 0.5547333132397658; train accuracy : 0.9966266659293259; \n",
      " validation loss : 0.6214166075080374; validation accuracy : 0.924812030075188\n",
      "Epoch 91:\t train loss : 0.5555588379994177; train accuracy : 0.9957971575512913; \n",
      " validation loss : 0.6307532714638608; validation accuracy : 0.924812030075188\n",
      "Early stopping at epoch 91\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.565535551508829; Train accuracy : 0.9856218547807333; \n",
      " Validation loss : 0.5922887849842431; Validation accuracy : 0.9624060150375939\n",
      "------------------------------ Let's train model 48 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8757540544434685; train accuracy : 0.6608140242216446; \n",
      " validation loss : 0.8393855700765532; validation accuracy : 0.706766917293233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\t train loss : 0.771278875289731; train accuracy : 0.7741801692197091; \n",
      " validation loss : 0.7963190909200305; validation accuracy : 0.7518796992481203\n",
      "Epoch 3:\t train loss : 0.7548418389152457; train accuracy : 0.7913924680639275; \n",
      " validation loss : 0.7887237382603214; validation accuracy : 0.7669172932330827\n",
      "Epoch 4:\t train loss : 0.7309673746639457; train accuracy : 0.8177017087872588; \n",
      " validation loss : 0.6991483030495632; validation accuracy : 0.8646616541353384\n",
      "Epoch 5:\t train loss : 0.6876050995959118; train accuracy : 0.862370734944423; \n",
      " validation loss : 0.6914197172965669; validation accuracy : 0.8571428571428571\n",
      "Epoch 6:\t train loss : 0.6560609327564014; train accuracy : 0.8944035834761931; \n",
      " validation loss : 0.674611786292145; validation accuracy : 0.8796992481203008\n",
      "Epoch 7:\t train loss : 0.638002359561553; train accuracy : 0.912002986230161; \n",
      " validation loss : 0.682869819468929; validation accuracy : 0.8796992481203008\n",
      "Epoch 8:\t train loss : 0.6180095337859641; train accuracy : 0.9329065973566333; \n",
      " validation loss : 0.823356530100258; validation accuracy : 0.7218045112781954\n",
      "Epoch 9:\t train loss : 0.6113311140810963; train accuracy : 0.9399988939888293; \n",
      " validation loss : 0.6904733169853177; validation accuracy : 0.8571428571428571\n",
      "Epoch 10:\t train loss : 0.5980071353869593; train accuracy : 0.9534092794337222; \n",
      " validation loss : 0.6554304359810735; validation accuracy : 0.8872180451127819\n",
      "Epoch 11:\t train loss : 0.5836950284057507; train accuracy : 0.9677459492340873; \n",
      " validation loss : 0.6726976884038015; validation accuracy : 0.8721804511278195\n",
      "Epoch 12:\t train loss : 0.5776428975029213; train accuracy : 0.9746585190510424; \n",
      " validation loss : 0.679272995004605; validation accuracy : 0.8646616541353384\n",
      "Epoch 13:\t train loss : 0.5757645924746048; train accuracy : 0.975792180501023; \n",
      " validation loss : 0.685087294254682; validation accuracy : 0.8721804511278195\n",
      "Epoch 14:\t train loss : 0.5986604146850154; train accuracy : 0.9526627218934911; \n",
      " validation loss : 0.6488313237014022; validation accuracy : 0.9022556390977443\n",
      "Epoch 15:\t train loss : 0.5686432996058789; train accuracy : 0.9830227285295582; \n",
      " validation loss : 0.6620825623356993; validation accuracy : 0.8872180451127819\n",
      "Epoch 16:\t train loss : 0.5668831695107982; train accuracy : 0.9849444229386717; \n",
      " validation loss : 0.6770939826888215; validation accuracy : 0.8721804511278195\n",
      "Epoch 17:\t train loss : 0.5710301786486774; train accuracy : 0.9805480285350882; \n",
      " validation loss : 0.6783462817629399; validation accuracy : 0.8721804511278195\n",
      "Epoch 18:\t train loss : 0.5767026995753547; train accuracy : 0.9747276447492119; \n",
      " validation loss : 0.6994209587213402; validation accuracy : 0.8345864661654135\n",
      "Epoch 19:\t train loss : 0.566550957840024; train accuracy : 0.9849582480783056; \n",
      " validation loss : 0.6593684896158081; validation accuracy : 0.8947368421052632\n",
      "Epoch 20:\t train loss : 0.5657163764962672; train accuracy : 0.9858707072941437; \n",
      " validation loss : 0.6673657130665684; validation accuracy : 0.8796992481203008\n",
      "Epoch 21:\t train loss : 0.5624869387245247; train accuracy : 0.9889260631532378; \n",
      " validation loss : 0.6734122074916994; validation accuracy : 0.8796992481203008\n",
      "Epoch 22:\t train loss : 0.5599297203758038; train accuracy : 0.9916081402422164; \n",
      " validation loss : 0.6544871993329683; validation accuracy : 0.8947368421052632\n",
      "Epoch 23:\t train loss : 0.5645773404385447; train accuracy : 0.9873361720953382; \n",
      " validation loss : 0.6512637030418837; validation accuracy : 0.9022556390977443\n",
      "Epoch 24:\t train loss : 0.5658527800100067; train accuracy : 0.9859121827130454; \n",
      " validation loss : 0.6828902641864559; validation accuracy : 0.8646616541353384\n",
      "Epoch 25:\t train loss : 0.566149417469932; train accuracy : 0.9849582480783056; \n",
      " validation loss : 0.6899107530900512; validation accuracy : 0.8571428571428571\n",
      "Epoch 26:\t train loss : 0.5718048815870844; train accuracy : 0.9796908698777858; \n",
      " validation loss : 0.6639729854702124; validation accuracy : 0.8796992481203008\n",
      "Epoch 27:\t train loss : 0.5623809062555787; train accuracy : 0.9891472653873804; \n",
      " validation loss : 0.6711978456193889; validation accuracy : 0.8796992481203008\n",
      "Epoch 28:\t train loss : 0.5678499470910391; train accuracy : 0.9835480838356467; \n",
      " validation loss : 0.6638830134203371; validation accuracy : 0.8872180451127819\n",
      "Epoch 29:\t train loss : 0.5764926611895178; train accuracy : 0.9740225626278826; \n",
      " validation loss : 0.7848801551601559; validation accuracy : 0.7593984962406015\n",
      "Epoch 30:\t train loss : 0.5797693383143895; train accuracy : 0.9712437095614666; \n",
      " validation loss : 0.6650148765419636; validation accuracy : 0.8872180451127819\n",
      "Epoch 31:\t train loss : 0.5708539533469081; train accuracy : 0.9805203782558204; \n",
      " validation loss : 0.6486987377997492; validation accuracy : 0.9022556390977443\n",
      "Epoch 32:\t train loss : 0.5619527336439786; train accuracy : 0.9896034949952994; \n",
      " validation loss : 0.6804138664556649; validation accuracy : 0.8646616541353384\n",
      "Epoch 33:\t train loss : 0.5600623026318281; train accuracy : 0.9914975391251452; \n",
      " validation loss : 0.6413328182687111; validation accuracy : 0.9172932330827067\n",
      "Epoch 34:\t train loss : 0.5598176531941894; train accuracy : 0.9914837139855113; \n",
      " validation loss : 0.6805881551671912; validation accuracy : 0.8721804511278195\n",
      "Epoch 35:\t train loss : 0.5596217635014146; train accuracy : 0.9916081402422164; \n",
      " validation loss : 0.7095133721914701; validation accuracy : 0.8421052631578947\n",
      "Epoch 36:\t train loss : 0.5662266118300057; train accuracy : 0.9849029475197699; \n",
      " validation loss : 0.6552670026218655; validation accuracy : 0.8947368421052632\n",
      "Epoch 37:\t train loss : 0.5798234739558228; train accuracy : 0.9706630536968424; \n",
      " validation loss : 0.6919299104330534; validation accuracy : 0.8646616541353384\n",
      "Epoch 38:\t train loss : 0.5618573100017541; train accuracy : 0.9894652435989604; \n",
      " validation loss : 0.695218945332889; validation accuracy : 0.849624060150376\n",
      "Epoch 39:\t train loss : 0.5615679256302639; train accuracy : 0.9899076480672455; \n",
      " validation loss : 0.6450974805099656; validation accuracy : 0.9022556390977443\n",
      "Epoch 40:\t train loss : 0.5580194230433511; train accuracy : 0.9934054083946248; \n",
      " validation loss : 0.671419610245207; validation accuracy : 0.8796992481203008\n",
      "Epoch 41:\t train loss : 0.5561238881659277; train accuracy : 0.9953271028037383; \n",
      " validation loss : 0.633606199246588; validation accuracy : 0.924812030075188\n",
      "Epoch 42:\t train loss : 0.5623794800926639; train accuracy : 0.9889675385721396; \n",
      " validation loss : 0.6970437789125985; validation accuracy : 0.849624060150376\n",
      "Epoch 43:\t train loss : 0.6251262818137472; train accuracy : 0.9247221146933584; \n",
      " validation loss : 0.6851737440150648; validation accuracy : 0.8646616541353384\n",
      "Epoch 44:\t train loss : 0.6014476355003096; train accuracy : 0.9488884587734336; \n",
      " validation loss : 0.7181465817822902; validation accuracy : 0.8270676691729323\n",
      "Epoch 45:\t train loss : 0.5766747741406654; train accuracy : 0.974561743073605; \n",
      " validation loss : 0.6760570230629516; validation accuracy : 0.8721804511278195\n",
      "Epoch 46:\t train loss : 0.5640902226450363; train accuracy : 0.9870873195819277; \n",
      " validation loss : 0.6474395849576902; validation accuracy : 0.8947368421052632\n",
      "Epoch 47:\t train loss : 0.5570939869879247; train accuracy : 0.9944284687275341; \n",
      " validation loss : 0.6505062938263042; validation accuracy : 0.9022556390977443\n",
      "Epoch 48:\t train loss : 0.5559768471372897; train accuracy : 0.9955483050378808; \n",
      " validation loss : 0.6819923432665161; validation accuracy : 0.8721804511278195\n",
      "Epoch 49:\t train loss : 0.592106742589835; train accuracy : 0.9582480783055909; \n",
      " validation loss : 0.6801069046561098; validation accuracy : 0.8721804511278195\n",
      "Epoch 50:\t train loss : 0.593599172371977; train accuracy : 0.9566581872476912; \n",
      " validation loss : 0.6941986926177075; validation accuracy : 0.849624060150376\n",
      "Epoch 51:\t train loss : 0.5718386439563395; train accuracy : 0.9794420173643754; \n",
      " validation loss : 0.6835796290949094; validation accuracy : 0.8721804511278195\n",
      "Epoch 52:\t train loss : 0.5639340099620316; train accuracy : 0.9873499972349721; \n",
      " validation loss : 0.6815546478962106; validation accuracy : 0.8721804511278195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53:\t train loss : 0.5786417189845801; train accuracy : 0.972114693358403; \n",
      " validation loss : 0.6456429935262302; validation accuracy : 0.9022556390977443\n",
      "Epoch 54:\t train loss : 0.5633971399649323; train accuracy : 0.9877924017032572; \n",
      " validation loss : 0.6695448264195637; validation accuracy : 0.8796992481203008\n",
      "Epoch 55:\t train loss : 0.5585843465503255; train accuracy : 0.992589725156224; \n",
      " validation loss : 0.6408822501312471; validation accuracy : 0.9097744360902256\n",
      "Epoch 56:\t train loss : 0.5572540040713496; train accuracy : 0.9942210916330255; \n",
      " validation loss : 0.6256158460307296; validation accuracy : 0.924812030075188\n",
      "Epoch 57:\t train loss : 0.5552795259004394; train accuracy : 0.9961289609025051; \n",
      " validation loss : 0.6138734986800567; validation accuracy : 0.9398496240601504\n",
      "Epoch 58:\t train loss : 0.5554882026757505; train accuracy : 0.9960736603439695; \n",
      " validation loss : 0.6123696827473543; validation accuracy : 0.9398496240601504\n",
      "Epoch 59:\t train loss : 0.554619305570801; train accuracy : 0.9968202178842006; \n",
      " validation loss : 0.6320784993257482; validation accuracy : 0.9172932330827067\n",
      "Epoch 60:\t train loss : 0.5553638976056133; train accuracy : 0.9960874854836034; \n",
      " validation loss : 0.6534956397383715; validation accuracy : 0.8947368421052632\n",
      "Epoch 61:\t train loss : 0.5563418596737063; train accuracy : 0.9949261737543549; \n",
      " validation loss : 0.6650850039289874; validation accuracy : 0.8872180451127819\n",
      "Epoch 62:\t train loss : 0.5600173041730554; train accuracy : 0.9911657357739313; \n",
      " validation loss : 0.6254945419859037; validation accuracy : 0.924812030075188\n",
      "Epoch 63:\t train loss : 0.5552094616610839; train accuracy : 0.9961704363214068; \n",
      " validation loss : 0.6346316097346537; validation accuracy : 0.9172932330827067\n",
      "Epoch 64:\t train loss : 0.568406048115404; train accuracy : 0.9827047503179782; \n",
      " validation loss : 0.6451230009148448; validation accuracy : 0.9022556390977443\n",
      "Epoch 65:\t train loss : 0.5565377877451024; train accuracy : 0.9948846983354531; \n",
      " validation loss : 0.6498590148938108; validation accuracy : 0.9022556390977443\n",
      "Epoch 66:\t train loss : 0.55422007603163; train accuracy : 0.997234972073218; \n",
      " validation loss : 0.639162189160215; validation accuracy : 0.9097744360902256\n",
      "Epoch 67:\t train loss : 0.5536038948175716; train accuracy : 0.9978432782171099; \n",
      " validation loss : 0.6491050705891744; validation accuracy : 0.9022556390977443\n",
      "Epoch 68:\t train loss : 0.5541569598453561; train accuracy : 0.9972626223524858; \n",
      " validation loss : 0.6720300264031043; validation accuracy : 0.8796992481203008\n",
      "Epoch 69:\t train loss : 0.5541237932238493; train accuracy : 0.9973179229110214; \n",
      " validation loss : 0.6452401602404712; validation accuracy : 0.9097744360902256\n",
      "Epoch 70:\t train loss : 0.6447371966359332; train accuracy : 0.9047586130619919; \n",
      " validation loss : 0.7222406378454275; validation accuracy : 0.8270676691729323\n",
      "Epoch 71:\t train loss : 0.6436732603043164; train accuracy : 0.9057816733949012; \n",
      " validation loss : 0.7082225737889146; validation accuracy : 0.849624060150376\n",
      "Epoch 72:\t train loss : 0.6223787835325699; train accuracy : 0.9271553392689266; \n",
      " validation loss : 0.6957575240089231; validation accuracy : 0.8646616541353384\n",
      "Epoch 73:\t train loss : 0.6199805861346288; train accuracy : 0.9298235912182713; \n",
      " validation loss : 0.6893403876635367; validation accuracy : 0.8571428571428571\n",
      "Epoch 74:\t train loss : 0.5934246908183568; train accuracy : 0.9570867665763424; \n",
      " validation loss : 0.6626141026336475; validation accuracy : 0.8796992481203008\n",
      "Epoch 75:\t train loss : 0.5821810678733658; train accuracy : 0.9688934358237018; \n",
      " validation loss : 0.6582549300452466; validation accuracy : 0.8872180451127819\n",
      "Epoch 76:\t train loss : 0.5867579623717184; train accuracy : 0.9643449648841453; \n",
      " validation loss : 0.6889118491083779; validation accuracy : 0.8646616541353384\n",
      "Epoch 77:\t train loss : 0.5773834679799461; train accuracy : 0.9736354587181331; \n",
      " validation loss : 0.6985102147437949; validation accuracy : 0.8571428571428571\n",
      "Epoch 78:\t train loss : 0.5691115281089676; train accuracy : 0.9822070452911574; \n",
      " validation loss : 0.664803940398427; validation accuracy : 0.8947368421052632\n",
      "Epoch 79:\t train loss : 0.566828060473895; train accuracy : 0.9846126195874578; \n",
      " validation loss : 0.6403430486740364; validation accuracy : 0.9172932330827067\n",
      "Epoch 80:\t train loss : 0.565717207070652; train accuracy : 0.9858430570148758; \n",
      " validation loss : 0.6811032531011759; validation accuracy : 0.8646616541353384\n",
      "Epoch 81:\t train loss : 0.5631494682783356; train accuracy : 0.9880550793563015; \n",
      " validation loss : 0.657316155459197; validation accuracy : 0.8872180451127819\n",
      "Epoch 82:\t train loss : 0.5645132456323588; train accuracy : 0.9869075927666869; \n",
      " validation loss : 0.633923646219405; validation accuracy : 0.9172932330827067\n",
      "Epoch 83:\t train loss : 0.5638344009911941; train accuracy : 0.9873499972349721; \n",
      " validation loss : 0.6727780354748073; validation accuracy : 0.8796992481203008\n",
      "Epoch 84:\t train loss : 0.5646862519323943; train accuracy : 0.9866725653929105; \n",
      " validation loss : 0.6537925247532613; validation accuracy : 0.8947368421052632\n",
      "Epoch 85:\t train loss : 0.5608011765225738; train accuracy : 0.9905159542111375; \n",
      " validation loss : 0.6429710491023166; validation accuracy : 0.9022556390977443\n",
      "Epoch 86:\t train loss : 0.5621372415493626; train accuracy : 0.9893131670629873; \n",
      " validation loss : 0.662636544356861; validation accuracy : 0.8796992481203008\n",
      "Epoch 87:\t train loss : 0.5657892890748837; train accuracy : 0.9854421279654925; \n",
      " validation loss : 0.6562868416283679; validation accuracy : 0.8947368421052632\n",
      "Epoch 88:\t train loss : 0.5620880454929772; train accuracy : 0.9891610905270143; \n",
      " validation loss : 0.6585828492406139; validation accuracy : 0.8872180451127819\n",
      "Epoch 89:\t train loss : 0.5824191938288411; train accuracy : 0.9686169330310236; \n",
      " validation loss : 0.6854374814292891; validation accuracy : 0.8646616541353384\n",
      "Epoch 90:\t train loss : 0.561797303267887; train accuracy : 0.9897140961123707; \n",
      " validation loss : 0.6603363477158352; validation accuracy : 0.8872180451127819\n",
      "Epoch 91:\t train loss : 0.5608197360693745; train accuracy : 0.9905021290715036; \n",
      " validation loss : 0.6435094366655566; validation accuracy : 0.9097744360902256\n",
      "Epoch 92:\t train loss : 0.557556019214238; train accuracy : 0.9939445888403473; \n",
      " validation loss : 0.6633492961996151; validation accuracy : 0.8872180451127819\n",
      "Epoch 93:\t train loss : 0.5615224427285269; train accuracy : 0.9900182491843168; \n",
      " validation loss : 0.671659633175153; validation accuracy : 0.8796992481203008\n",
      "Epoch 94:\t train loss : 0.5675182560034253; train accuracy : 0.983658684952718; \n",
      " validation loss : 0.6640320888728245; validation accuracy : 0.8872180451127819\n",
      "Epoch 95:\t train loss : 0.5651082301352683; train accuracy : 0.985967483271581; \n",
      " validation loss : 0.6283995558261589; validation accuracy : 0.924812030075188\n",
      "Epoch 96:\t train loss : 0.558942074022745; train accuracy : 0.9927003262732953; \n",
      " validation loss : 0.6517032464158555; validation accuracy : 0.9022556390977443\n",
      "Epoch 97:\t train loss : 0.5577796123307396; train accuracy : 0.9935436597909639; \n",
      " validation loss : 0.6384573396413714; validation accuracy : 0.9097744360902256\n",
      "Epoch 98:\t train loss : 0.5568445626804739; train accuracy : 0.9946358458220428; \n",
      " validation loss : 0.6265786539806315; validation accuracy : 0.924812030075188\n",
      "Epoch 99:\t train loss : 0.5587552823735115; train accuracy : 0.9923685229220816; \n",
      " validation loss : 0.6190745588708375; validation accuracy : 0.924812030075188\n",
      "Epoch 100:\t train loss : 0.5664001380898531; train accuracy : 0.9847646961234309; \n",
      " validation loss : 0.6546611372882727; validation accuracy : 0.8947368421052632\n",
      "Epoch 101:\t train loss : 0.5630478250091943; train accuracy : 0.9880965547752032; \n",
      " validation loss : 0.6191324335386713; validation accuracy : 0.9323308270676691\n",
      "Epoch 102:\t train loss : 0.5560543703155684; train accuracy : 0.9954377039208095; \n",
      " validation loss : 0.6256583531297869; validation accuracy : 0.924812030075188\n",
      "Epoch 103:\t train loss : 0.5581188373661609; train accuracy : 0.993225681579384; \n",
      " validation loss : 0.6314251683749538; validation accuracy : 0.924812030075188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104:\t train loss : 0.5569259176955225; train accuracy : 0.9944284687275341; \n",
      " validation loss : 0.6129137206363626; validation accuracy : 0.9398496240601504\n",
      "Epoch 105:\t train loss : 0.5576349906335237; train accuracy : 0.9936127854891335; \n",
      " validation loss : 0.660552125672797; validation accuracy : 0.8872180451127819\n",
      "Epoch 106:\t train loss : 0.5579073142183395; train accuracy : 0.9933362826964552; \n",
      " validation loss : 0.6359731233078497; validation accuracy : 0.9172932330827067\n",
      "Epoch 107:\t train loss : 0.5664880647076427; train accuracy : 0.9845296687496544; \n",
      " validation loss : 0.7028115069826607; validation accuracy : 0.8421052631578947\n",
      "Epoch 108:\t train loss : 0.5699030594363014; train accuracy : 0.9811286843997125; \n",
      " validation loss : 0.6976729625858764; validation accuracy : 0.849624060150376\n",
      "Early stopping at epoch 108\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5554882026757505; Train accuracy : 0.9960736603439695; \n",
      " Validation loss : 0.6123696827473543; Validation accuracy : 0.9398496240601504\n",
      "------------------------------ Let's train model 49 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8853624038762572; train accuracy : 0.6525189404412984; \n",
      " validation loss : 0.7620526715377061; validation accuracy : 0.7744360902255639\n",
      "Epoch 2:\t train loss : 0.7616716781463668; train accuracy : 0.7828900071890726; \n",
      " validation loss : 0.7662188979494845; validation accuracy : 0.7819548872180451\n",
      "Epoch 3:\t train loss : 0.7441783246767576; train accuracy : 0.8025078803295913; \n",
      " validation loss : 0.7619883477689444; validation accuracy : 0.7819548872180451\n",
      "Epoch 4:\t train loss : 0.7033801116737862; train accuracy : 0.8447160316319194; \n",
      " validation loss : 0.7311109341451125; validation accuracy : 0.7894736842105263\n",
      "Epoch 5:\t train loss : 0.6750575362798406; train accuracy : 0.8744400818448266; \n",
      " validation loss : 0.7106069146151374; validation accuracy : 0.8345864661654135\n",
      "Epoch 6:\t train loss : 0.6458475498598829; train accuracy : 0.9046480119449206; \n",
      " validation loss : 0.7028738959744707; validation accuracy : 0.8345864661654135\n",
      "Epoch 7:\t train loss : 0.6235031611592354; train accuracy : 0.927722169993917; \n",
      " validation loss : 0.6581881710838448; validation accuracy : 0.8947368421052632\n",
      "Epoch 8:\t train loss : 0.6051822098624421; train accuracy : 0.9467455621301775; \n",
      " validation loss : 0.6858236024866342; validation accuracy : 0.8571428571428571\n",
      "Epoch 9:\t train loss : 0.6211400908881187; train accuracy : 0.9299894928938782; \n",
      " validation loss : 0.6331312930171702; validation accuracy : 0.9172932330827067\n",
      "Epoch 10:\t train loss : 0.6121084429386888; train accuracy : 0.9388928828181164; \n",
      " validation loss : 0.6505988973666785; validation accuracy : 0.9022556390977443\n",
      "Epoch 11:\t train loss : 0.6063926700938311; train accuracy : 0.9439667090637616; \n",
      " validation loss : 0.6656136945939882; validation accuracy : 0.8721804511278195\n",
      "Epoch 12:\t train loss : 0.5843740297216045; train accuracy : 0.9673864956036056; \n",
      " validation loss : 0.6669039384537678; validation accuracy : 0.8796992481203008\n",
      "Epoch 13:\t train loss : 0.5923229984297943; train accuracy : 0.9590499364043577; \n",
      " validation loss : 0.6453869512470138; validation accuracy : 0.9097744360902256\n",
      "Epoch 14:\t train loss : 0.5929942568450955; train accuracy : 0.9579024498147432; \n",
      " validation loss : 0.693014536552838; validation accuracy : 0.849624060150376\n",
      "Epoch 15:\t train loss : 0.5783099851444865; train accuracy : 0.9732760050876513; \n",
      " validation loss : 0.643449334171035; validation accuracy : 0.9022556390977443\n",
      "Epoch 16:\t train loss : 0.5837053441098508; train accuracy : 0.9675523972792125; \n",
      " validation loss : 0.6590059606183059; validation accuracy : 0.8872180451127819\n",
      "Epoch 17:\t train loss : 0.5752813276832015; train accuracy : 0.9763590112260134; \n",
      " validation loss : 0.6667281688875131; validation accuracy : 0.8872180451127819\n",
      "Epoch 18:\t train loss : 0.567904024059374; train accuracy : 0.9837969363490572; \n",
      " validation loss : 0.6426827572834978; validation accuracy : 0.9097744360902256\n",
      "Epoch 19:\t train loss : 0.5663803735240006; train accuracy : 0.985663330199635; \n",
      " validation loss : 0.6507224241343572; validation accuracy : 0.9022556390977443\n",
      "Epoch 20:\t train loss : 0.5642235237155342; train accuracy : 0.9875297240502129; \n",
      " validation loss : 0.6258757075416602; validation accuracy : 0.9323308270676691\n",
      "Epoch 21:\t train loss : 0.567856918430278; train accuracy : 0.983506608416745; \n",
      " validation loss : 0.6337764209643618; validation accuracy : 0.9172932330827067\n",
      "Epoch 22:\t train loss : 0.562955897130297; train accuracy : 0.9886357352209257; \n",
      " validation loss : 0.6423074987392424; validation accuracy : 0.9022556390977443\n",
      "Epoch 23:\t train loss : 0.5668013934138596; train accuracy : 0.9845020184703865; \n",
      " validation loss : 0.6374986045452681; validation accuracy : 0.9172932330827067\n",
      "Epoch 24:\t train loss : 0.5801733176068005; train accuracy : 0.9708289553724493; \n",
      " validation loss : 0.6304266207650501; validation accuracy : 0.924812030075188\n",
      "Epoch 25:\t train loss : 0.5731155617926758; train accuracy : 0.9785986838467069; \n",
      " validation loss : 0.6416868405599887; validation accuracy : 0.9022556390977443\n",
      "Epoch 26:\t train loss : 0.5684051311780636; train accuracy : 0.98274622573688; \n",
      " validation loss : 0.628823230880619; validation accuracy : 0.924812030075188\n",
      "Epoch 27:\t train loss : 0.5910847327727593; train accuracy : 0.9595752917104463; \n",
      " validation loss : 0.6515510132745338; validation accuracy : 0.9022556390977443\n",
      "Epoch 28:\t train loss : 0.5763955078179881; train accuracy : 0.974561743073605; \n",
      " validation loss : 0.6232835827577129; validation accuracy : 0.9323308270676691\n",
      "Epoch 29:\t train loss : 0.5662673772068487; train accuracy : 0.984737045844163; \n",
      " validation loss : 0.6458802774042453; validation accuracy : 0.9022556390977443\n",
      "Epoch 30:\t train loss : 0.5615065167007806; train accuracy : 0.9899491234861472; \n",
      " validation loss : 0.6543522974978574; validation accuracy : 0.8947368421052632\n",
      "Epoch 31:\t train loss : 0.5690218341893294; train accuracy : 0.982276170989327; \n",
      " validation loss : 0.6296477988662755; validation accuracy : 0.924812030075188\n",
      "Epoch 32:\t train loss : 0.5612181465129877; train accuracy : 0.9902118011391915; \n",
      " validation loss : 0.6582501572268384; validation accuracy : 0.8872180451127819\n",
      "Epoch 33:\t train loss : 0.5590194851102885; train accuracy : 0.9922993972239119; \n",
      " validation loss : 0.6193274577749579; validation accuracy : 0.924812030075188\n",
      "Epoch 34:\t train loss : 0.5581257873068729; train accuracy : 0.9934192335342586; \n",
      " validation loss : 0.6354120156443134; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.558026146953685; train accuracy : 0.9933224575568214; \n",
      " validation loss : 0.6699834485967034; validation accuracy : 0.8796992481203008\n",
      "Epoch 36:\t train loss : 0.5693833576763299; train accuracy : 0.9817369905436045; \n",
      " validation loss : 0.6573406116060513; validation accuracy : 0.8947368421052632\n",
      "Epoch 37:\t train loss : 0.5723327523287061; train accuracy : 0.9789028369186529; \n",
      " validation loss : 0.6488515320867242; validation accuracy : 0.9022556390977443\n",
      "Epoch 38:\t train loss : 0.5789010680469293; train accuracy : 0.9720040922413317; \n",
      " validation loss : 0.6913419615153735; validation accuracy : 0.8571428571428571\n",
      "Epoch 39:\t train loss : 0.6052539736454551; train accuracy : 0.9450035945363048; \n",
      " validation loss : 0.6496158393939848; validation accuracy : 0.9022556390977443\n",
      "Epoch 40:\t train loss : 0.573097005190426; train accuracy : 0.9781701045180556; \n",
      " validation loss : 0.6525365760895416; validation accuracy : 0.8947368421052632\n",
      "Epoch 41:\t train loss : 0.5757046804619087; train accuracy : 0.9751009235193275; \n",
      " validation loss : 0.6210420575308205; validation accuracy : 0.9323308270676691\n",
      "Epoch 42:\t train loss : 0.5686546373651075; train accuracy : 0.9823176464082287; \n",
      " validation loss : 0.6535076816905708; validation accuracy : 0.9022556390977443\n",
      "Epoch 43:\t train loss : 0.5631021364532427; train accuracy : 0.9883454072886136; \n",
      " validation loss : 0.6337834077369996; validation accuracy : 0.9172932330827067\n",
      "Epoch 44:\t train loss : 0.5600053498821155; train accuracy : 0.9914422385666095; \n",
      " validation loss : 0.6220404633740355; validation accuracy : 0.924812030075188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:\t train loss : 0.578833978981934; train accuracy : 0.9721008682187691; \n",
      " validation loss : 0.6375017649718744; validation accuracy : 0.9172932330827067\n",
      "Epoch 46:\t train loss : 0.5605217113384523; train accuracy : 0.9908754078416192; \n",
      " validation loss : 0.6540226931403179; validation accuracy : 0.8947368421052632\n",
      "Epoch 47:\t train loss : 0.5632229180583975; train accuracy : 0.9881933307526406; \n",
      " validation loss : 0.6494557804954697; validation accuracy : 0.8947368421052632\n",
      "Epoch 48:\t train loss : 0.5590258688746174; train accuracy : 0.9925205994580545; \n",
      " validation loss : 0.6386050935813133; validation accuracy : 0.9172932330827067\n",
      "Epoch 49:\t train loss : 0.5582700924768539; train accuracy : 0.9931427307415804; \n",
      " validation loss : 0.663441330383757; validation accuracy : 0.8872180451127819\n",
      "Epoch 50:\t train loss : 0.5604965074224927; train accuracy : 0.9908754078416192; \n",
      " validation loss : 0.6606853307216713; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5638130449583353; train accuracy : 0.9875020737709451; \n",
      " validation loss : 0.6346510669667839; validation accuracy : 0.9172932330827067\n",
      "Epoch 52:\t train loss : 0.5565493459990768; train accuracy : 0.9948017474976497; \n",
      " validation loss : 0.6326263575734993; validation accuracy : 0.9172932330827067\n",
      "Epoch 53:\t train loss : 0.561984852131587; train accuracy : 0.9894099430404247; \n",
      " validation loss : 0.6898166479058098; validation accuracy : 0.8571428571428571\n",
      "Epoch 54:\t train loss : 0.5890971954499928; train accuracy : 0.9614140352817564; \n",
      " validation loss : 0.7340878138023076; validation accuracy : 0.8120300751879699\n",
      "Epoch 55:\t train loss : 0.5984058554704298; train accuracy : 0.95223414256484; \n",
      " validation loss : 0.6565378027107637; validation accuracy : 0.8947368421052632\n",
      "Epoch 56:\t train loss : 0.5749440287252546; train accuracy : 0.9759995575955317; \n",
      " validation loss : 0.6586881297285581; validation accuracy : 0.8872180451127819\n",
      "Epoch 57:\t train loss : 0.5623991115658691; train accuracy : 0.989064314549577; \n",
      " validation loss : 0.6392468764959133; validation accuracy : 0.9172932330827067\n",
      "Epoch 58:\t train loss : 0.6929553177133093; train accuracy : 0.8558176187579495; \n",
      " validation loss : 0.7261216491312255; validation accuracy : 0.8195488721804511\n",
      "Epoch 59:\t train loss : 0.6332126066870074; train accuracy : 0.9161228778410662; \n",
      " validation loss : 0.6729199059277761; validation accuracy : 0.8721804511278195\n",
      "Epoch 60:\t train loss : 0.6128417924116311; train accuracy : 0.9374135928772881; \n",
      " validation loss : 0.693292571089047; validation accuracy : 0.8571428571428571\n",
      "Epoch 61:\t train loss : 0.5958191208328729; train accuracy : 0.9545014654648012; \n",
      " validation loss : 0.6407456640264269; validation accuracy : 0.9097744360902256\n",
      "Epoch 62:\t train loss : 0.5864545956492352; train accuracy : 0.9645108665597523; \n",
      " validation loss : 0.66590509942434; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.582407149123571; train accuracy : 0.9687275341480949; \n",
      " validation loss : 0.6593320496265164; validation accuracy : 0.8872180451127819\n",
      "Epoch 64:\t train loss : 0.5737907138046078; train accuracy : 0.9777138749101366; \n",
      " validation loss : 0.6818028416139953; validation accuracy : 0.8646616541353384\n",
      "Epoch 65:\t train loss : 0.5707051079508744; train accuracy : 0.9807001050710612; \n",
      " validation loss : 0.666404270328487; validation accuracy : 0.8872180451127819\n",
      "Epoch 66:\t train loss : 0.5672071519848781; train accuracy : 0.9842669910966101; \n",
      " validation loss : 0.6803262393841397; validation accuracy : 0.8721804511278195\n",
      "Epoch 67:\t train loss : 0.566743103588856; train accuracy : 0.9845434938892883; \n",
      " validation loss : 0.6440981075308685; validation accuracy : 0.9022556390977443\n",
      "Epoch 68:\t train loss : 0.5760833563056353; train accuracy : 0.9750594481004258; \n",
      " validation loss : 0.6609259442844452; validation accuracy : 0.8872180451127819\n",
      "Epoch 69:\t train loss : 0.5812281961216829; train accuracy : 0.969944146435879; \n",
      " validation loss : 0.6705518131306484; validation accuracy : 0.8721804511278195\n",
      "Epoch 70:\t train loss : 0.5743877191922263; train accuracy : 0.9765525631808881; \n",
      " validation loss : 0.657620380000596; validation accuracy : 0.8796992481203008\n",
      "Epoch 71:\t train loss : 0.5746580284115421; train accuracy : 0.9762898855278438; \n",
      " validation loss : 0.6647882221721373; validation accuracy : 0.8796992481203008\n",
      "Epoch 72:\t train loss : 0.5701224992069677; train accuracy : 0.9809904330033733; \n",
      " validation loss : 0.6645890550676652; validation accuracy : 0.8947368421052632\n",
      "Epoch 73:\t train loss : 0.563950053186018; train accuracy : 0.9873361720953382; \n",
      " validation loss : 0.6705316723911894; validation accuracy : 0.8796992481203008\n",
      "Epoch 74:\t train loss : 0.5616850328201243; train accuracy : 0.9894790687385943; \n",
      " validation loss : 0.6638328036769778; validation accuracy : 0.8872180451127819\n",
      "Epoch 75:\t train loss : 0.5617970172869303; train accuracy : 0.9895620195763977; \n",
      " validation loss : 0.6579837811682235; validation accuracy : 0.8872180451127819\n",
      "Epoch 76:\t train loss : 0.5608022502709796; train accuracy : 0.990280926837361; \n",
      " validation loss : 0.6540299958964709; validation accuracy : 0.9022556390977443\n",
      "Epoch 77:\t train loss : 0.5605475704906074; train accuracy : 0.9910274843775922; \n",
      " validation loss : 0.6546717702139145; validation accuracy : 0.8947368421052632\n",
      "Epoch 78:\t train loss : 0.5637701750775211; train accuracy : 0.9873914726538738; \n",
      " validation loss : 0.6641846584119964; validation accuracy : 0.8796992481203008\n",
      "Epoch 79:\t train loss : 0.561339751438766; train accuracy : 0.9899076480672455; \n",
      " validation loss : 0.6512541219438589; validation accuracy : 0.9022556390977443\n",
      "Epoch 80:\t train loss : 0.5594381961121789; train accuracy : 0.9919399435934303; \n",
      " validation loss : 0.6394347446061728; validation accuracy : 0.9097744360902256\n",
      "Epoch 81:\t train loss : 0.5591901496169288; train accuracy : 0.9921058452690372; \n",
      " validation loss : 0.6543071118752464; validation accuracy : 0.8947368421052632\n",
      "Epoch 82:\t train loss : 0.5572762322283498; train accuracy : 0.9940137145385168; \n",
      " validation loss : 0.6590812711901702; validation accuracy : 0.8947368421052632\n",
      "Epoch 83:\t train loss : 0.5571809245140307; train accuracy : 0.9939584139799812; \n",
      " validation loss : 0.6352416646372775; validation accuracy : 0.9172932330827067\n",
      "Early stopping at epoch 83\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5590194851102885; Train accuracy : 0.9922993972239119; \n",
      " Validation loss : 0.6193274577749579; Validation accuracy : 0.924812030075188\n",
      "------------------------------ Let's train model 50 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8940128084160506; train accuracy : 0.6333019963501632; \n",
      " validation loss : 0.8848500120221893; validation accuracy : 0.6466165413533834\n",
      "Epoch 2:\t train loss : 0.7792027050984703; train accuracy : 0.7663274899076481; \n",
      " validation loss : 0.8197183937772349; validation accuracy : 0.7368421052631579\n",
      "Epoch 3:\t train loss : 0.7260512669514803; train accuracy : 0.8212685948128076; \n",
      " validation loss : 0.7654695216478951; validation accuracy : 0.7819548872180451\n",
      "Epoch 4:\t train loss : 0.6953182368081192; train accuracy : 0.8539235746281038; \n",
      " validation loss : 0.7179404036932673; validation accuracy : 0.8270676691729323\n",
      "Epoch 5:\t train loss : 0.6674498210191218; train accuracy : 0.8815047281977548; \n",
      " validation loss : 0.7597714602759384; validation accuracy : 0.7819548872180451\n",
      "Epoch 6:\t train loss : 0.6484270398644786; train accuracy : 0.902435989603495; \n",
      " validation loss : 0.7214108813386074; validation accuracy : 0.8120300751879699\n",
      "Epoch 7:\t train loss : 0.6209480135837351; train accuracy : 0.9306807498755737; \n",
      " validation loss : 0.6912268465782868; validation accuracy : 0.849624060150376\n",
      "Epoch 8:\t train loss : 0.6161556517236094; train accuracy : 0.9349665431620859; \n",
      " validation loss : 0.6677143806062555; validation accuracy : 0.8796992481203008\n",
      "Epoch 9:\t train loss : 0.611395370178237; train accuracy : 0.9399021180113919; \n",
      " validation loss : 0.7209068757104546; validation accuracy : 0.8195488721804511\n",
      "Epoch 10:\t train loss : 0.596494623825132; train accuracy : 0.9554830503788089; \n",
      " validation loss : 0.6691050078164009; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\t train loss : 0.5850191722393054; train accuracy : 0.9666675883426422; \n",
      " validation loss : 0.6504627253716294; validation accuracy : 0.8947368421052632\n",
      "Epoch 12:\t train loss : 0.5859628158631223; train accuracy : 0.9653956754963225; \n",
      " validation loss : 0.6951790552914958; validation accuracy : 0.8421052631578947\n",
      "Epoch 13:\t train loss : 0.5799611643686782; train accuracy : 0.9719626168224299; \n",
      " validation loss : 0.6537908127757632; validation accuracy : 0.8947368421052632\n",
      "Epoch 14:\t train loss : 0.5742240181797807; train accuracy : 0.9775203229552618; \n",
      " validation loss : 0.6812306367748552; validation accuracy : 0.8571428571428571\n",
      "Epoch 15:\t train loss : 0.5751462982164199; train accuracy : 0.9768567162528341; \n",
      " validation loss : 0.6367508234251036; validation accuracy : 0.9022556390977443\n",
      "Epoch 16:\t train loss : 0.5716872319481057; train accuracy : 0.9797876458552232; \n",
      " validation loss : 0.6589280942006462; validation accuracy : 0.8872180451127819\n",
      "Epoch 17:\t train loss : 0.5721159928155819; train accuracy : 0.979345241386938; \n",
      " validation loss : 0.6820627681612361; validation accuracy : 0.8721804511278195\n",
      "Epoch 18:\t train loss : 0.572737897976778; train accuracy : 0.9787645855223138; \n",
      " validation loss : 0.6856137714291356; validation accuracy : 0.849624060150376\n",
      "Epoch 19:\t train loss : 0.5735861767919918; train accuracy : 0.9777415251894044; \n",
      " validation loss : 0.6646965321487838; validation accuracy : 0.8872180451127819\n",
      "Epoch 20:\t train loss : 0.5767185568296518; train accuracy : 0.974575568213239; \n",
      " validation loss : 0.6788382788261641; validation accuracy : 0.8721804511278195\n",
      "Epoch 21:\t train loss : 0.5677228530587107; train accuracy : 0.9837831112094232; \n",
      " validation loss : 0.66202448724843; validation accuracy : 0.8872180451127819\n",
      "Epoch 22:\t train loss : 0.5689764145847221; train accuracy : 0.9821379195929879; \n",
      " validation loss : 0.6933095458492229; validation accuracy : 0.8571428571428571\n",
      "Epoch 23:\t train loss : 0.571186967100473; train accuracy : 0.9799535475308301; \n",
      " validation loss : 0.6518736559949919; validation accuracy : 0.9022556390977443\n",
      "Epoch 24:\t train loss : 0.5654197203898462; train accuracy : 0.9860919095282863; \n",
      " validation loss : 0.6606919245947432; validation accuracy : 0.8872180451127819\n",
      "Epoch 25:\t train loss : 0.5831133063127281; train accuracy : 0.9676076978377481; \n",
      " validation loss : 0.7187454038383619; validation accuracy : 0.8270676691729323\n",
      "Epoch 26:\t train loss : 0.5720588000854735; train accuracy : 0.9790549134546259; \n",
      " validation loss : 0.7869837086000857; validation accuracy : 0.7669172932330827\n",
      "Epoch 27:\t train loss : 0.5735472618746503; train accuracy : 0.9777138749101366; \n",
      " validation loss : 0.6570709078692395; validation accuracy : 0.8947368421052632\n",
      "Epoch 28:\t train loss : 0.5622304048091991; train accuracy : 0.9892440413648178; \n",
      " validation loss : 0.6217320504812236; validation accuracy : 0.9323308270676691\n",
      "Epoch 29:\t train loss : 0.5587869564407032; train accuracy : 0.9928938782281701; \n",
      " validation loss : 0.6615498399588476; validation accuracy : 0.8872180451127819\n",
      "Epoch 30:\t train loss : 0.5593311349104543; train accuracy : 0.9920781949897693; \n",
      " validation loss : 0.6476611435480194; validation accuracy : 0.9022556390977443\n",
      "Epoch 31:\t train loss : 0.5606432807138944; train accuracy : 0.9908615827019853; \n",
      " validation loss : 0.6392672826266347; validation accuracy : 0.9097744360902256\n",
      "Epoch 32:\t train loss : 0.562869928322658; train accuracy : 0.9885527843831222; \n",
      " validation loss : 0.6659827430092369; validation accuracy : 0.8872180451127819\n",
      "Epoch 33:\t train loss : 0.5596341822685929; train accuracy : 0.9915390145440469; \n",
      " validation loss : 0.6498435509054882; validation accuracy : 0.9022556390977443\n",
      "Epoch 34:\t train loss : 0.5609423250330063; train accuracy : 0.99073715644528; \n",
      " validation loss : 0.6423775118068934; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.5615807559466092; train accuracy : 0.9898661726483438; \n",
      " validation loss : 0.6455069879397483; validation accuracy : 0.9022556390977443\n",
      "Epoch 36:\t train loss : 0.5717179736944353; train accuracy : 0.9797185201570536; \n",
      " validation loss : 0.6747709546419458; validation accuracy : 0.8721804511278195\n",
      "Epoch 37:\t train loss : 0.565153781067717; train accuracy : 0.9863407620416966; \n",
      " validation loss : 0.640553372551043; validation accuracy : 0.9172932330827067\n",
      "Epoch 38:\t train loss : 0.5643755056898925; train accuracy : 0.9867831665099818; \n",
      " validation loss : 0.6279013175969365; validation accuracy : 0.9172932330827067\n",
      "Epoch 39:\t train loss : 0.5738430582320726; train accuracy : 0.9774235469778245; \n",
      " validation loss : 0.6897181067666678; validation accuracy : 0.8646616541353384\n",
      "Epoch 40:\t train loss : 0.5720538861749614; train accuracy : 0.9792069899905989; \n",
      " validation loss : 0.6677162924521015; validation accuracy : 0.8872180451127819\n",
      "Epoch 41:\t train loss : 0.5582701782453838; train accuracy : 0.9931703810208483; \n",
      " validation loss : 0.6678290974550098; validation accuracy : 0.8721804511278195\n",
      "Epoch 42:\t train loss : 0.5616042272975617; train accuracy : 0.9899491234861472; \n",
      " validation loss : 0.6285453164693724; validation accuracy : 0.9172932330827067\n",
      "Epoch 43:\t train loss : 0.5731886228813111; train accuracy : 0.9779074268650113; \n",
      " validation loss : 0.6510523851158623; validation accuracy : 0.8947368421052632\n",
      "Epoch 44:\t train loss : 0.5643754282857439; train accuracy : 0.9870320190233921; \n",
      " validation loss : 0.6742733879928807; validation accuracy : 0.8796992481203008\n",
      "Epoch 45:\t train loss : 0.5582064224835704; train accuracy : 0.9931565558812144; \n",
      " validation loss : 0.6491614014785758; validation accuracy : 0.9022556390977443\n",
      "Epoch 46:\t train loss : 0.557107821905744; train accuracy : 0.9942763921915612; \n",
      " validation loss : 0.6409208518643701; validation accuracy : 0.9097744360902256\n",
      "Epoch 47:\t train loss : 0.5559268507685308; train accuracy : 0.9954515290604435; \n",
      " validation loss : 0.6593684216553084; validation accuracy : 0.8872180451127819\n",
      "Epoch 48:\t train loss : 0.5565628551028294; train accuracy : 0.9947049715202123; \n",
      " validation loss : 0.6313114454417323; validation accuracy : 0.9172932330827067\n",
      "Epoch 49:\t train loss : 0.5573800548098674; train accuracy : 0.993820162583642; \n",
      " validation loss : 0.7060941309058378; validation accuracy : 0.8345864661654135\n",
      "Epoch 50:\t train loss : 0.5556245449977344; train accuracy : 0.9957695072720234; \n",
      " validation loss : 0.6611752797515025; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5633407637337261; train accuracy : 0.9880550793563015; \n",
      " validation loss : 0.6477143050107029; validation accuracy : 0.9022556390977443\n",
      "Epoch 52:\t train loss : 0.5828552143716346; train accuracy : 0.9678012497926229; \n",
      " validation loss : 0.6397878253992207; validation accuracy : 0.9172932330827067\n",
      "Epoch 53:\t train loss : 0.5822512836756889; train accuracy : 0.9687551844273627; \n",
      " validation loss : 0.6407082173682923; validation accuracy : 0.9097744360902256\n",
      "Epoch 54:\t train loss : 0.5730077321315302; train accuracy : 0.9781009788198861; \n",
      " validation loss : 0.6338434551209726; validation accuracy : 0.9172932330827067\n",
      "Epoch 55:\t train loss : 0.5676872900135758; train accuracy : 0.9835757341149146; \n",
      " validation loss : 0.6508954755820675; validation accuracy : 0.8947368421052632\n",
      "Epoch 56:\t train loss : 0.5757026770835277; train accuracy : 0.975349776032738; \n",
      " validation loss : 0.649540379941352; validation accuracy : 0.8947368421052632\n",
      "Epoch 57:\t train loss : 0.5723120117546331; train accuracy : 0.9787922358015816; \n",
      " validation loss : 0.6455990115033423; validation accuracy : 0.9022556390977443\n",
      "Epoch 58:\t train loss : 0.5657137922441939; train accuracy : 0.9855389039429299; \n",
      " validation loss : 0.6532285956844404; validation accuracy : 0.8947368421052632\n",
      "Epoch 59:\t train loss : 0.5596908400934706; train accuracy : 0.9917602167781895; \n",
      " validation loss : 0.670375856876462; validation accuracy : 0.8872180451127819\n",
      "Epoch 60:\t train loss : 0.5603636389284092; train accuracy : 0.9911104352153957; \n",
      " validation loss : 0.659909670421924; validation accuracy : 0.8872180451127819\n",
      "Epoch 61:\t train loss : 0.5634308700899587; train accuracy : 0.9878753525410606; \n",
      " validation loss : 0.7003461038278709; validation accuracy : 0.849624060150376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62:\t train loss : 0.5655472875694295; train accuracy : 0.9857739313167063; \n",
      " validation loss : 0.6732878534147901; validation accuracy : 0.8796992481203008\n",
      "Epoch 63:\t train loss : 0.605457660906096; train accuracy : 0.9445335397887519; \n",
      " validation loss : 0.6368518980293664; validation accuracy : 0.9097744360902256\n",
      "Epoch 64:\t train loss : 0.5683289078979477; train accuracy : 0.9826771000387103; \n",
      " validation loss : 0.6576512414999428; validation accuracy : 0.8947368421052632\n",
      "Epoch 65:\t train loss : 0.5648313220474007; train accuracy : 0.9863407620416966; \n",
      " validation loss : 0.6534325802635526; validation accuracy : 0.8947368421052632\n",
      "Epoch 66:\t train loss : 0.5586515916873477; train accuracy : 0.9926865011336614; \n",
      " validation loss : 0.6441449484503302; validation accuracy : 0.9022556390977443\n",
      "Epoch 67:\t train loss : 0.561596801480565; train accuracy : 0.9897970469501742; \n",
      " validation loss : 0.6555719612078992; validation accuracy : 0.8872180451127819\n",
      "Epoch 68:\t train loss : 0.56369956256854; train accuracy : 0.9876403251672842; \n",
      " validation loss : 0.670694374058624; validation accuracy : 0.8796992481203008\n",
      "Epoch 69:\t train loss : 0.5570690483488601; train accuracy : 0.9941657910744899; \n",
      " validation loss : 0.6745877733685428; validation accuracy : 0.8721804511278195\n",
      "Epoch 70:\t train loss : 0.5583198177855624; train accuracy : 0.9928247525300006; \n",
      " validation loss : 0.6479537401750048; validation accuracy : 0.9022556390977443\n",
      "Epoch 71:\t train loss : 0.5611590536701809; train accuracy : 0.9900458994635846; \n",
      " validation loss : 0.6357706198155738; validation accuracy : 0.9172932330827067\n",
      "Epoch 72:\t train loss : 0.5626751517922212; train accuracy : 0.9884145329867832; \n",
      " validation loss : 0.6307703605124533; validation accuracy : 0.924812030075188\n",
      "Epoch 73:\t train loss : 0.565469586850986; train accuracy : 0.9858430570148758; \n",
      " validation loss : 0.6639105500814212; validation accuracy : 0.8796992481203008\n",
      "Epoch 74:\t train loss : 0.565263366925358; train accuracy : 0.9857739313167063; \n",
      " validation loss : 0.6152708258746725; validation accuracy : 0.9323308270676691\n",
      "Epoch 75:\t train loss : 0.5631530233004837; train accuracy : 0.9880965547752032; \n",
      " validation loss : 0.6664292728005661; validation accuracy : 0.8872180451127819\n",
      "Epoch 76:\t train loss : 0.5598232494270119; train accuracy : 0.9914698888458773; \n",
      " validation loss : 0.670764326283478; validation accuracy : 0.8721804511278195\n",
      "Epoch 77:\t train loss : 0.5565138755354412; train accuracy : 0.9948846983354531; \n",
      " validation loss : 0.6350616228635261; validation accuracy : 0.9172932330827067\n",
      "Epoch 78:\t train loss : 0.5554837907300909; train accuracy : 0.9960183597854338; \n",
      " validation loss : 0.6717475560112433; validation accuracy : 0.8796992481203008\n",
      "Epoch 79:\t train loss : 0.5555888660179606; train accuracy : 0.9958524581098269; \n",
      " validation loss : 0.649604967520629; validation accuracy : 0.9022556390977443\n",
      "Epoch 80:\t train loss : 0.5609970141379572; train accuracy : 0.9902394514184594; \n",
      " validation loss : 0.6545107506027573; validation accuracy : 0.8947368421052632\n",
      "Epoch 81:\t train loss : 0.5630216083272561; train accuracy : 0.9878891776806946; \n",
      " validation loss : 0.6722417276472791; validation accuracy : 0.8796992481203008\n",
      "Epoch 82:\t train loss : 0.5594921948187765; train accuracy : 0.9917878670574573; \n",
      " validation loss : 0.6270237459674924; validation accuracy : 0.924812030075188\n",
      "Epoch 83:\t train loss : 0.5573764657832759; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.6407844625728325; validation accuracy : 0.9097744360902256\n",
      "Epoch 84:\t train loss : 0.5550334295371785; train accuracy : 0.9962672122988442; \n",
      " validation loss : 0.6688829760443294; validation accuracy : 0.8796992481203008\n",
      "Epoch 85:\t train loss : 0.5664184327989124; train accuracy : 0.984737045844163; \n",
      " validation loss : 0.6902477376159644; validation accuracy : 0.8571428571428571\n",
      "Epoch 86:\t train loss : 0.6092970451880175; train accuracy : 0.941284631974783; \n",
      " validation loss : 0.6572191360927815; validation accuracy : 0.8947368421052632\n",
      "Epoch 87:\t train loss : 0.5705041629399162; train accuracy : 0.9805895039539899; \n",
      " validation loss : 0.6701104371039961; validation accuracy : 0.8796992481203008\n",
      "Epoch 88:\t train loss : 0.5717542954129087; train accuracy : 0.979345241386938; \n",
      " validation loss : 0.6419505375050221; validation accuracy : 0.9097744360902256\n",
      "Epoch 89:\t train loss : 0.5619242679697134; train accuracy : 0.9894790687385943; \n",
      " validation loss : 0.6592811692384015; validation accuracy : 0.8947368421052632\n",
      "Epoch 90:\t train loss : 0.5592896723098227; train accuracy : 0.9919675938726981; \n",
      " validation loss : 0.6750058312865899; validation accuracy : 0.8721804511278195\n",
      "Epoch 91:\t train loss : 0.5867667424804633; train accuracy : 0.9640546369518332; \n",
      " validation loss : 0.6456226737816653; validation accuracy : 0.9022556390977443\n",
      "Epoch 92:\t train loss : 0.5749307910856606; train accuracy : 0.975792180501023; \n",
      " validation loss : 0.6371574419249285; validation accuracy : 0.9172932330827067\n",
      "Epoch 93:\t train loss : 0.5620435651138332; train accuracy : 0.9891749156666483; \n",
      " validation loss : 0.6447590738198314; validation accuracy : 0.9022556390977443\n",
      "Epoch 94:\t train loss : 0.5597189459022104; train accuracy : 0.9916496156611182; \n",
      " validation loss : 0.6009467635414862; validation accuracy : 0.9473684210526315\n",
      "Epoch 95:\t train loss : 0.5589050086828368; train accuracy : 0.9923685229220816; \n",
      " validation loss : 0.6218190357178894; validation accuracy : 0.924812030075188\n",
      "Epoch 96:\t train loss : 0.5612789088132162; train accuracy : 0.9901288503013881; \n",
      " validation loss : 0.6434231379605762; validation accuracy : 0.9097744360902256\n",
      "Epoch 97:\t train loss : 0.5570617918172974; train accuracy : 0.9943593430293646; \n",
      " validation loss : 0.6512036241571814; validation accuracy : 0.9022556390977443\n",
      "Epoch 98:\t train loss : 0.5589945844912263; train accuracy : 0.9921749709672067; \n",
      " validation loss : 0.6540639446851354; validation accuracy : 0.8947368421052632\n",
      "Epoch 99:\t train loss : 0.5590516940865466; train accuracy : 0.9922026212464746; \n",
      " validation loss : 0.6439799100460485; validation accuracy : 0.9097744360902256\n",
      "Epoch 100:\t train loss : 0.5607727779515385; train accuracy : 0.9905297793507715; \n",
      " validation loss : 0.6423970774088034; validation accuracy : 0.9022556390977443\n",
      "Epoch 101:\t train loss : 0.5579290545836061; train accuracy : 0.9933362826964552; \n",
      " validation loss : 0.6348957731556298; validation accuracy : 0.9097744360902256\n",
      "Epoch 102:\t train loss : 0.5596434735249457; train accuracy : 0.9916910910800198; \n",
      " validation loss : 0.6703626713934213; validation accuracy : 0.8796992481203008\n",
      "Epoch 103:\t train loss : 0.5632667925212027; train accuracy : 0.9879583033788641; \n",
      " validation loss : 0.6756791478637192; validation accuracy : 0.8721804511278195\n",
      "Epoch 104:\t train loss : 0.560112770567482; train accuracy : 0.9910413095172261; \n",
      " validation loss : 0.6492932214610548; validation accuracy : 0.9022556390977443\n",
      "Epoch 105:\t train loss : 0.5582764704882571; train accuracy : 0.9931150804623127; \n",
      " validation loss : 0.6516959090828044; validation accuracy : 0.8947368421052632\n",
      "Epoch 106:\t train loss : 0.5623161932959289; train accuracy : 0.9889675385721396; \n",
      " validation loss : 0.6570487750282392; validation accuracy : 0.8947368421052632\n",
      "Epoch 107:\t train loss : 0.5584896097545823; train accuracy : 0.9929491787867057; \n",
      " validation loss : 0.6572576907151064; validation accuracy : 0.8947368421052632\n",
      "Epoch 108:\t train loss : 0.5605328706484635; train accuracy : 0.9906680307471105; \n",
      " validation loss : 0.6491769193100111; validation accuracy : 0.9022556390977443\n",
      "Epoch 109:\t train loss : 0.5623417616117093; train accuracy : 0.9890228391306752; \n",
      " validation loss : 0.6435862247019456; validation accuracy : 0.9022556390977443\n",
      "Epoch 110:\t train loss : 0.5680301360436277; train accuracy : 0.9829950782502903; \n",
      " validation loss : 0.6826464905341818; validation accuracy : 0.8646616541353384\n",
      "Epoch 111:\t train loss : 0.5658391151975171; train accuracy : 0.9853868274069568; \n",
      " validation loss : 0.6458683503923249; validation accuracy : 0.9022556390977443\n",
      "Epoch 112:\t train loss : 0.5570762283780695; train accuracy : 0.994290217331195; \n",
      " validation loss : 0.6552353411618029; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113:\t train loss : 0.5575231911810969; train accuracy : 0.9938754631421777; \n",
      " validation loss : 0.624568390016945; validation accuracy : 0.924812030075188\n",
      "Epoch 114:\t train loss : 0.5559254868462878; train accuracy : 0.9953824033622739; \n",
      " validation loss : 0.627429862656252; validation accuracy : 0.924812030075188\n",
      "Epoch 115:\t train loss : 0.5561317373957532; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6284162057872091; validation accuracy : 0.924812030075188\n",
      "Epoch 116:\t train loss : 0.5543974358043788; train accuracy : 0.9970275949787093; \n",
      " validation loss : 0.6416388389525308; validation accuracy : 0.9097744360902256\n",
      "Epoch 117:\t train loss : 0.554930985272112; train accuracy : 0.996460764253719; \n",
      " validation loss : 0.6381863510939564; validation accuracy : 0.9097744360902256\n",
      "Epoch 118:\t train loss : 0.554542270337416; train accuracy : 0.9970137698390754; \n",
      " validation loss : 0.638639041421033; validation accuracy : 0.9097744360902256\n",
      "Epoch 119:\t train loss : 0.55540016350915; train accuracy : 0.9960598352043356; \n",
      " validation loss : 0.5890403969723232; validation accuracy : 0.9624060150375939\n",
      "Epoch 120:\t train loss : 0.5622158382411013; train accuracy : 0.9891334402477465; \n",
      " validation loss : 0.6848370228824581; validation accuracy : 0.8646616541353384\n",
      "Epoch 121:\t train loss : 0.565608732012265; train accuracy : 0.9855389039429299; \n",
      " validation loss : 0.6508106926407052; validation accuracy : 0.8947368421052632\n",
      "Epoch 122:\t train loss : 0.5653093345611848; train accuracy : 0.9859951335508489; \n",
      " validation loss : 0.6731917379720113; validation accuracy : 0.8721804511278195\n",
      "Epoch 123:\t train loss : 0.5602967608019336; train accuracy : 0.9908477575623513; \n",
      " validation loss : 0.6124177754679262; validation accuracy : 0.9398496240601504\n",
      "Epoch 124:\t train loss : 0.5583704029572911; train accuracy : 0.9930459547641431; \n",
      " validation loss : 0.6487049812213195; validation accuracy : 0.9022556390977443\n",
      "Epoch 125:\t train loss : 0.5610585484290133; train accuracy : 0.9902118011391915; \n",
      " validation loss : 0.6453682230187112; validation accuracy : 0.9022556390977443\n",
      "Epoch 126:\t train loss : 0.5585402416826504; train accuracy : 0.9926588508543936; \n",
      " validation loss : 0.6518736818329336; validation accuracy : 0.9022556390977443\n",
      "Epoch 127:\t train loss : 0.5652261341882762; train accuracy : 0.9860780843886523; \n",
      " validation loss : 0.6640376218501138; validation accuracy : 0.8947368421052632\n",
      "Epoch 128:\t train loss : 0.5631773798574439; train accuracy : 0.9880550793563015; \n",
      " validation loss : 0.7226224664605181; validation accuracy : 0.8270676691729323\n",
      "Epoch 129:\t train loss : 0.5663017501375819; train accuracy : 0.9849167726594038; \n",
      " validation loss : 0.642217819521688; validation accuracy : 0.9097744360902256\n",
      "Epoch 130:\t train loss : 0.5592496917046421; train accuracy : 0.991981419012332; \n",
      " validation loss : 0.6728971043653307; validation accuracy : 0.8721804511278195\n",
      "Epoch 131:\t train loss : 0.5562847151129671; train accuracy : 0.9951059005695957; \n",
      " validation loss : 0.6266735388668079; validation accuracy : 0.924812030075188\n",
      "Epoch 132:\t train loss : 0.5574987616946155; train accuracy : 0.9937372117458386; \n",
      " validation loss : 0.661550304425542; validation accuracy : 0.8872180451127819\n",
      "Epoch 133:\t train loss : 0.5620673976129741; train accuracy : 0.989202565945916; \n",
      " validation loss : 0.7909217014938335; validation accuracy : 0.7443609022556391\n",
      "Epoch 134:\t train loss : 0.5721814235678431; train accuracy : 0.9789304871979206; \n",
      " validation loss : 0.8740221870910144; validation accuracy : 0.6766917293233082\n",
      "Epoch 135:\t train loss : 0.8149473551458296; train accuracy : 0.7323591218271305; \n",
      " validation loss : 0.7918490128446152; validation accuracy : 0.7518796992481203\n",
      "Epoch 136:\t train loss : 0.7701978466995556; train accuracy : 0.7782309351324448; \n",
      " validation loss : 0.8449708141252473; validation accuracy : 0.706766917293233\n",
      "Epoch 137:\t train loss : 0.7178452776871878; train accuracy : 0.8312641707681248; \n",
      " validation loss : 0.7899131484602547; validation accuracy : 0.7518796992481203\n",
      "Epoch 138:\t train loss : 0.6693815319984726; train accuracy : 0.8794447823923022; \n",
      " validation loss : 0.7027461591404771; validation accuracy : 0.849624060150376\n",
      "Epoch 139:\t train loss : 0.6184096746207252; train accuracy : 0.9318973621633578; \n",
      " validation loss : 0.6748516631161242; validation accuracy : 0.8721804511278195\n",
      "Epoch 140:\t train loss : 0.5994639287133251; train accuracy : 0.9510451805563236; \n",
      " validation loss : 0.6613927351449105; validation accuracy : 0.8947368421052632\n",
      "Epoch 141:\t train loss : 0.5862169579325823; train accuracy : 0.9643173146048775; \n",
      " validation loss : 0.6656399521578796; validation accuracy : 0.8796992481203008\n",
      "Epoch 142:\t train loss : 0.5780783769561085; train accuracy : 0.9729856771553392; \n",
      " validation loss : 0.6924570358191291; validation accuracy : 0.8571428571428571\n",
      "Epoch 143:\t train loss : 0.5779632247246916; train accuracy : 0.9731101034120445; \n",
      " validation loss : 0.680378698884424; validation accuracy : 0.8646616541353384\n",
      "Epoch 144:\t train loss : 0.5702056575740311; train accuracy : 0.980893657025936; \n",
      " validation loss : 0.6645573465513704; validation accuracy : 0.8872180451127819\n",
      "Epoch 145:\t train loss : 0.5683683889184555; train accuracy : 0.9828291765746834; \n",
      " validation loss : 0.6305060290977564; validation accuracy : 0.924812030075188\n",
      "Epoch 146:\t train loss : 0.5667072963831289; train accuracy : 0.9845711441685561; \n",
      " validation loss : 0.6676656446665945; validation accuracy : 0.8796992481203008\n",
      "Epoch 147:\t train loss : 0.566983497255807; train accuracy : 0.9841702151191727; \n",
      " validation loss : 0.6735067868733132; validation accuracy : 0.8721804511278195\n",
      "Epoch 148:\t train loss : 0.5716888987568504; train accuracy : 0.9792484654095006; \n",
      " validation loss : 0.6602487290496596; validation accuracy : 0.8872180451127819\n",
      "Epoch 149:\t train loss : 0.5660027554242486; train accuracy : 0.9852900514295194; \n",
      " validation loss : 0.6563520376554413; validation accuracy : 0.9022556390977443\n",
      "Epoch 150:\t train loss : 0.5657826850257367; train accuracy : 0.9857462810374384; \n",
      " validation loss : 0.6195224528642878; validation accuracy : 0.924812030075188\n",
      "Epoch 151:\t train loss : 0.5679878319239667; train accuracy : 0.9830089033899242; \n",
      " validation loss : 0.6202062620241752; validation accuracy : 0.924812030075188\n",
      "Epoch 152:\t train loss : 0.5632609137822575; train accuracy : 0.9881933307526406; \n",
      " validation loss : 0.6429525202118611; validation accuracy : 0.9097744360902256\n",
      "Epoch 153:\t train loss : 0.5596996540924006; train accuracy : 0.9916910910800198; \n",
      " validation loss : 0.6477133241252846; validation accuracy : 0.9022556390977443\n",
      "Epoch 154:\t train loss : 0.5595446433248731; train accuracy : 0.9919399435934303; \n",
      " validation loss : 0.6236820836864198; validation accuracy : 0.924812030075188\n",
      "Epoch 155:\t train loss : 0.5639652716400706; train accuracy : 0.9872946966764364; \n",
      " validation loss : 0.6347999379491243; validation accuracy : 0.9172932330827067\n",
      "Epoch 156:\t train loss : 0.5632416858505291; train accuracy : 0.9879168279599624; \n",
      " validation loss : 0.6842149890137378; validation accuracy : 0.8646616541353384\n",
      "Epoch 157:\t train loss : 0.5581416523015671; train accuracy : 0.9930044793452414; \n",
      " validation loss : 0.6542634232364198; validation accuracy : 0.8947368421052632\n",
      "Epoch 158:\t train loss : 0.5627496329097845; train accuracy : 0.9885251341038545; \n",
      " validation loss : 0.6697971424452924; validation accuracy : 0.8721804511278195\n",
      "Epoch 159:\t train loss : 0.5861431133884728; train accuracy : 0.964400265442681; \n",
      " validation loss : 0.6539428526476948; validation accuracy : 0.8947368421052632\n",
      "Epoch 160:\t train loss : 0.5736409270684988; train accuracy : 0.9773682464192889; \n",
      " validation loss : 0.637499423052024; validation accuracy : 0.9172932330827067\n",
      "Epoch 161:\t train loss : 0.5744973930827049; train accuracy : 0.9766216888790576; \n",
      " validation loss : 0.6725908107620936; validation accuracy : 0.8721804511278195\n",
      "Epoch 162:\t train loss : 0.5712411382075534; train accuracy : 0.9798152961344909; \n",
      " validation loss : 0.6596620942298109; validation accuracy : 0.8947368421052632\n",
      "Epoch 163:\t train loss : 0.5616487399203883; train accuracy : 0.9897279212520046; \n",
      " validation loss : 0.6836402599723235; validation accuracy : 0.8646616541353384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164:\t train loss : 0.5618798922879731; train accuracy : 0.9894928938782281; \n",
      " validation loss : 0.6325482807500595; validation accuracy : 0.9172932330827067\n",
      "Epoch 165:\t train loss : 0.558588409378395; train accuracy : 0.9928385776696345; \n",
      " validation loss : 0.6563869484341557; validation accuracy : 0.8947368421052632\n",
      "Epoch 166:\t train loss : 0.5565674336603267; train accuracy : 0.9947879223580158; \n",
      " validation loss : 0.6552939189798793; validation accuracy : 0.8947368421052632\n",
      "Epoch 167:\t train loss : 0.559864659068167; train accuracy : 0.99137311286844; \n",
      " validation loss : 0.6448378034911528; validation accuracy : 0.9022556390977443\n",
      "Epoch 168:\t train loss : 0.5609812594651016; train accuracy : 0.9901841508599237; \n",
      " validation loss : 0.6315958940215538; validation accuracy : 0.9172932330827067\n",
      "Epoch 169:\t train loss : 0.5617132385451032; train accuracy : 0.9896587955538351; \n",
      " validation loss : 0.6338604711725622; validation accuracy : 0.9172932330827067\n",
      "Early stopping at epoch 169\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.55540016350915; Train accuracy : 0.9960598352043356; \n",
      " Validation loss : 0.5890403969723232; Validation accuracy : 0.9624060150375939\n",
      "------------------------------ Let's train model 51 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8831834368329947; train accuracy : 0.6470856605651717; \n",
      " validation loss : 0.7654577174029602; validation accuracy : 0.7669172932330827\n",
      "Epoch 2:\t train loss : 0.768025117946192; train accuracy : 0.7748299507825029; \n",
      " validation loss : 0.7177948474404723; validation accuracy : 0.8270676691729323\n",
      "Epoch 3:\t train loss : 0.6981409528495478; train accuracy : 0.8503566886025549; \n",
      " validation loss : 0.700045229728151; validation accuracy : 0.8345864661654135\n",
      "Epoch 4:\t train loss : 0.6555364789206368; train accuracy : 0.895343692971299; \n",
      " validation loss : 0.7027920263834985; validation accuracy : 0.8571428571428571\n",
      "Epoch 5:\t train loss : 0.6315163751741304; train accuracy : 0.9197727147044185; \n",
      " validation loss : 0.6568832918288668; validation accuracy : 0.8947368421052632\n",
      "Epoch 6:\t train loss : 0.6191147785851657; train accuracy : 0.9319941381407952; \n",
      " validation loss : 0.6427660264444873; validation accuracy : 0.9097744360902256\n",
      "Epoch 7:\t train loss : 0.6122955001732716; train accuracy : 0.9389481833766521; \n",
      " validation loss : 0.6203472759195066; validation accuracy : 0.9323308270676691\n",
      "Epoch 8:\t train loss : 0.6093685807697957; train accuracy : 0.9425703699607366; \n",
      " validation loss : 0.6417823348408841; validation accuracy : 0.9097744360902256\n",
      "Epoch 9:\t train loss : 0.5959230523536685; train accuracy : 0.9557042526129513; \n",
      " validation loss : 0.6418268646053467; validation accuracy : 0.9172932330827067\n",
      "Epoch 10:\t train loss : 0.5954427916014293; train accuracy : 0.9558286788696566; \n",
      " validation loss : 0.6413542657993159; validation accuracy : 0.9172932330827067\n",
      "Epoch 11:\t train loss : 0.5866563086697396; train accuracy : 0.9654233257755903; \n",
      " validation loss : 0.6444510752931063; validation accuracy : 0.9022556390977443\n",
      "Epoch 12:\t train loss : 0.5846449448443987; train accuracy : 0.9672897196261682; \n",
      " validation loss : 0.6835440531033976; validation accuracy : 0.8646616541353384\n",
      "Epoch 13:\t train loss : 0.589594385885249; train accuracy : 0.9616628877951667; \n",
      " validation loss : 0.6291402004623186; validation accuracy : 0.924812030075188\n",
      "Epoch 14:\t train loss : 0.5768937777368706; train accuracy : 0.9749350218437206; \n",
      " validation loss : 0.6272572877202004; validation accuracy : 0.924812030075188\n",
      "Epoch 15:\t train loss : 0.5721558255250732; train accuracy : 0.9793037659680363; \n",
      " validation loss : 0.6326638239152397; validation accuracy : 0.9172932330827067\n",
      "Epoch 16:\t train loss : 0.5804145040908298; train accuracy : 0.9709257313498867; \n",
      " validation loss : 0.6821154032703773; validation accuracy : 0.8646616541353384\n",
      "Epoch 17:\t train loss : 0.5835850605424561; train accuracy : 0.9680501023060333; \n",
      " validation loss : 0.6123500942460497; validation accuracy : 0.9398496240601504\n",
      "Epoch 18:\t train loss : 0.5781248592698368; train accuracy : 0.9731377536913123; \n",
      " validation loss : 0.6343909501062426; validation accuracy : 0.9097744360902256\n",
      "Epoch 19:\t train loss : 0.5748849136511662; train accuracy : 0.9763451860863794; \n",
      " validation loss : 0.6267142932145809; validation accuracy : 0.9172932330827067\n",
      "Epoch 20:\t train loss : 0.572188870184099; train accuracy : 0.9790549134546259; \n",
      " validation loss : 0.6507034946461292; validation accuracy : 0.9022556390977443\n",
      "Epoch 21:\t train loss : 0.57725939122677; train accuracy : 0.97380136039374; \n",
      " validation loss : 0.6248685564542427; validation accuracy : 0.924812030075188\n",
      "Epoch 22:\t train loss : 0.5732678305787297; train accuracy : 0.9784604324503677; \n",
      " validation loss : 0.6712912111217427; validation accuracy : 0.8721804511278195\n",
      "Epoch 23:\t train loss : 0.5669822631363216; train accuracy : 0.9846264447270917; \n",
      " validation loss : 0.7366104848532264; validation accuracy : 0.8120300751879699\n",
      "Epoch 24:\t train loss : 0.6944579292245082; train accuracy : 0.8529972902726317; \n",
      " validation loss : 0.6797502134962249; validation accuracy : 0.8796992481203008\n",
      "Epoch 25:\t train loss : 0.6150314400802819; train accuracy : 0.9351462699773267; \n",
      " validation loss : 0.6482384643187674; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.5888882693604278; train accuracy : 0.9624509207542996; \n",
      " validation loss : 0.693025287979192; validation accuracy : 0.8571428571428571\n",
      "Epoch 27:\t train loss : 0.5746050214134742; train accuracy : 0.9766908145772272; \n",
      " validation loss : 0.6432959244166692; validation accuracy : 0.9097744360902256\n",
      "Epoch 28:\t train loss : 0.5669766907343684; train accuracy : 0.9844052424929491; \n",
      " validation loss : 0.6479223115120096; validation accuracy : 0.9022556390977443\n",
      "Epoch 29:\t train loss : 0.5674155945829763; train accuracy : 0.9838798871868606; \n",
      " validation loss : 0.6175321094827206; validation accuracy : 0.9323308270676691\n",
      "Epoch 30:\t train loss : 0.5617969502614908; train accuracy : 0.9897002709727368; \n",
      " validation loss : 0.6264035306780075; validation accuracy : 0.924812030075188\n",
      "Epoch 31:\t train loss : 0.5602712614102716; train accuracy : 0.9910966100757618; \n",
      " validation loss : 0.6274204535555483; validation accuracy : 0.924812030075188\n",
      "Epoch 32:\t train loss : 0.5596151257979218; train accuracy : 0.9918846430348947; \n",
      " validation loss : 0.6425115092122042; validation accuracy : 0.9097744360902256\n",
      "Epoch 33:\t train loss : 0.5593236779336728; train accuracy : 0.9920367195708677; \n",
      " validation loss : 0.6319424389073219; validation accuracy : 0.9097744360902256\n",
      "Epoch 34:\t train loss : 0.5624901133276768; train accuracy : 0.9888569374550683; \n",
      " validation loss : 0.6590600912137902; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.559137227331087; train accuracy : 0.9921887961068406; \n",
      " validation loss : 0.6287303689776113; validation accuracy : 0.924812030075188\n",
      "Epoch 36:\t train loss : 0.5743612425719364; train accuracy : 0.9767737654150307; \n",
      " validation loss : 0.6962013903553779; validation accuracy : 0.8421052631578947\n",
      "Epoch 37:\t train loss : 0.5850090823766895; train accuracy : 0.965934855942045; \n",
      " validation loss : 0.6529770084162525; validation accuracy : 0.9022556390977443\n",
      "Epoch 38:\t train loss : 0.5698227231156425; train accuracy : 0.9813637117734889; \n",
      " validation loss : 0.6296950245808812; validation accuracy : 0.924812030075188\n",
      "Epoch 39:\t train loss : 0.5635406518019902; train accuracy : 0.9878062268428911; \n",
      " validation loss : 0.6511246199174204; validation accuracy : 0.9022556390977443\n",
      "Epoch 40:\t train loss : 0.5585948260137017; train accuracy : 0.9929353536470719; \n",
      " validation loss : 0.6315140971473334; validation accuracy : 0.924812030075188\n",
      "Epoch 41:\t train loss : 0.5574906118621341; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.6345497452424502; validation accuracy : 0.9172932330827067\n",
      "Epoch 42:\t train loss : 0.5592354803334069; train accuracy : 0.9919537687330642; \n",
      " validation loss : 0.6476867062488559; validation accuracy : 0.9022556390977443\n",
      "Epoch 43:\t train loss : 0.5591711805990832; train accuracy : 0.9922717469446442; \n",
      " validation loss : 0.6519590915927136; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:\t train loss : 0.5708660244074042; train accuracy : 0.9800503235082675; \n",
      " validation loss : 0.634787403538821; validation accuracy : 0.9172932330827067\n",
      "Epoch 45:\t train loss : 0.5577615727915425; train accuracy : 0.993516009511696; \n",
      " validation loss : 0.6417180253256226; validation accuracy : 0.9097744360902256\n",
      "Epoch 46:\t train loss : 0.5577001810234111; train accuracy : 0.9936404357684012; \n",
      " validation loss : 0.64522348638833; validation accuracy : 0.9022556390977443\n",
      "Epoch 47:\t train loss : 0.5626514874813001; train accuracy : 0.9885527843831222; \n",
      " validation loss : 0.6433561988589905; validation accuracy : 0.9172932330827067\n",
      "Epoch 48:\t train loss : 0.5611001418095637; train accuracy : 0.9903085771166289; \n",
      " validation loss : 0.648670047044295; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.557881954732944; train accuracy : 0.9936680860476691; \n",
      " validation loss : 0.6735224813868522; validation accuracy : 0.8721804511278195\n",
      "Epoch 50:\t train loss : 0.5639541815230448; train accuracy : 0.987363822374606; \n",
      " validation loss : 0.6699331833229004; validation accuracy : 0.8796992481203008\n",
      "Epoch 51:\t train loss : 0.5676990922667268; train accuracy : 0.9836863352319858; \n",
      " validation loss : 0.6839353655222071; validation accuracy : 0.8646616541353384\n",
      "Epoch 52:\t train loss : 0.562062399628056; train accuracy : 0.9890919648288448; \n",
      " validation loss : 0.625764475792128; validation accuracy : 0.924812030075188\n",
      "Epoch 53:\t train loss : 0.5558254188631546; train accuracy : 0.9956174307360505; \n",
      " validation loss : 0.624839192504416; validation accuracy : 0.924812030075188\n",
      "Epoch 54:\t train loss : 0.5580235158957239; train accuracy : 0.9933915832549909; \n",
      " validation loss : 0.6603302738727891; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5553576858572542; train accuracy : 0.9960874854836034; \n",
      " validation loss : 0.6341664411411235; validation accuracy : 0.9172932330827067\n",
      "Epoch 56:\t train loss : 0.5558295593081278; train accuracy : 0.9956312558756844; \n",
      " validation loss : 0.6373305704726938; validation accuracy : 0.9097744360902256\n",
      "Epoch 57:\t train loss : 0.5549167672891892; train accuracy : 0.9965575402311563; \n",
      " validation loss : 0.6191499146701509; validation accuracy : 0.9323308270676691\n",
      "Epoch 58:\t train loss : 0.5639780304036179; train accuracy : 0.987197920698999; \n",
      " validation loss : 0.6095585311912869; validation accuracy : 0.9398496240601504\n",
      "Epoch 59:\t train loss : 0.5570253345391918; train accuracy : 0.9942210916330255; \n",
      " validation loss : 0.6199012312241263; validation accuracy : 0.9323308270676691\n",
      "Epoch 60:\t train loss : 0.5610414883878666; train accuracy : 0.9902532765580933; \n",
      " validation loss : 0.6893736849223655; validation accuracy : 0.8571428571428571\n",
      "Epoch 61:\t train loss : 0.638919910275218; train accuracy : 0.9105651717082343; \n",
      " validation loss : 0.6376980388203793; validation accuracy : 0.9172932330827067\n",
      "Epoch 62:\t train loss : 0.578985843181392; train accuracy : 0.9718658408449925; \n",
      " validation loss : 0.6604874864715198; validation accuracy : 0.8947368421052632\n",
      "Epoch 63:\t train loss : 0.5723988716816182; train accuracy : 0.9784604324503677; \n",
      " validation loss : 0.6941056474838163; validation accuracy : 0.8571428571428571\n",
      "Epoch 64:\t train loss : 0.5669667052091406; train accuracy : 0.984114914560637; \n",
      " validation loss : 0.6604180960415955; validation accuracy : 0.8872180451127819\n",
      "Epoch 65:\t train loss : 0.5618040500512863; train accuracy : 0.989506719017862; \n",
      " validation loss : 0.6421300451135924; validation accuracy : 0.9097744360902256\n",
      "Epoch 66:\t train loss : 0.5609586481960528; train accuracy : 0.9903777028147984; \n",
      " validation loss : 0.6881652568934791; validation accuracy : 0.8646616541353384\n",
      "Epoch 67:\t train loss : 0.5634873493343934; train accuracy : 0.987833877122159; \n",
      " validation loss : 0.625843688465663; validation accuracy : 0.924812030075188\n",
      "Epoch 68:\t train loss : 0.5606003333624704; train accuracy : 0.990598905048941; \n",
      " validation loss : 0.6770979775045958; validation accuracy : 0.8721804511278195\n",
      "Epoch 69:\t train loss : 0.557366107515009; train accuracy : 0.9940137145385168; \n",
      " validation loss : 0.6419004923476984; validation accuracy : 0.9097744360902256\n",
      "Epoch 70:\t train loss : 0.5566366027169757; train accuracy : 0.9947879223580158; \n",
      " validation loss : 0.6466149702834483; validation accuracy : 0.9022556390977443\n",
      "Epoch 71:\t train loss : 0.5569485861800586; train accuracy : 0.9943869933086324; \n",
      " validation loss : 0.6492097773750447; validation accuracy : 0.9022556390977443\n",
      "Epoch 72:\t train loss : 0.5537347882630513; train accuracy : 0.9977188519604048; \n",
      " validation loss : 0.6338759771021335; validation accuracy : 0.9172932330827067\n",
      "Epoch 73:\t train loss : 0.5562061577494601; train accuracy : 0.9951059005695957; \n",
      " validation loss : 0.6499211276210144; validation accuracy : 0.9022556390977443\n",
      "Epoch 74:\t train loss : 0.5561019448331799; train accuracy : 0.9952026765470331; \n",
      " validation loss : 0.642217216955356; validation accuracy : 0.9097744360902256\n",
      "Epoch 75:\t train loss : 0.5576381238373398; train accuracy : 0.9934607089531604; \n",
      " validation loss : 0.6246090035437298; validation accuracy : 0.924812030075188\n",
      "Epoch 76:\t train loss : 0.5581536697115518; train accuracy : 0.9932809821379196; \n",
      " validation loss : 0.651296469397963; validation accuracy : 0.9022556390977443\n",
      "Epoch 77:\t train loss : 0.5562968855618458; train accuracy : 0.9950920754299618; \n",
      " validation loss : 0.8156640119189988; validation accuracy : 0.7293233082706767\n",
      "Epoch 78:\t train loss : 0.7679713700411693; train accuracy : 0.7808715368025217; \n",
      " validation loss : 0.7459832306531214; validation accuracy : 0.8045112781954887\n",
      "Epoch 79:\t train loss : 0.6668328122130334; train accuracy : 0.8823342365757895; \n",
      " validation loss : 0.6671831104433364; validation accuracy : 0.8872180451127819\n",
      "Epoch 80:\t train loss : 0.6031648195036928; train accuracy : 0.9474782945307747; \n",
      " validation loss : 0.6424596593804158; validation accuracy : 0.9097744360902256\n",
      "Epoch 81:\t train loss : 0.5930847499862575; train accuracy : 0.9575015207653598; \n",
      " validation loss : 0.6568054393087929; validation accuracy : 0.8872180451127819\n",
      "Epoch 82:\t train loss : 0.5746117453283522; train accuracy : 0.9763175358071117; \n",
      " validation loss : 0.6485707697961056; validation accuracy : 0.9022556390977443\n",
      "Epoch 83:\t train loss : 0.5688520507333781; train accuracy : 0.9820549687551844; \n",
      " validation loss : 0.6699014560151648; validation accuracy : 0.8796992481203008\n",
      "Epoch 84:\t train loss : 0.5619416396529892; train accuracy : 0.9893961179007909; \n",
      " validation loss : 0.6394584438422057; validation accuracy : 0.9097744360902256\n",
      "Epoch 85:\t train loss : 0.5612276754032162; train accuracy : 0.9900458994635846; \n",
      " validation loss : 0.604920173550395; validation accuracy : 0.9398496240601504\n",
      "Epoch 86:\t train loss : 0.5614573684465191; train accuracy : 0.9900044240446828; \n",
      " validation loss : 0.6432552365474672; validation accuracy : 0.9097744360902256\n",
      "Epoch 87:\t train loss : 0.5574144397502225; train accuracy : 0.9940966653763202; \n",
      " validation loss : 0.6444262530664236; validation accuracy : 0.9097744360902256\n",
      "Epoch 88:\t train loss : 0.5574785738100931; train accuracy : 0.9939031134214455; \n",
      " validation loss : 0.6340803281532176; validation accuracy : 0.9172932330827067\n",
      "Epoch 89:\t train loss : 0.5611574626948715; train accuracy : 0.9903224022562628; \n",
      " validation loss : 0.6416770257996953; validation accuracy : 0.9022556390977443\n",
      "Epoch 90:\t train loss : 0.5637336707572678; train accuracy : 0.987515898910579; \n",
      " validation loss : 0.675194113193281; validation accuracy : 0.8721804511278195\n",
      "Epoch 91:\t train loss : 0.5565689198580746; train accuracy : 0.9949399988939888; \n",
      " validation loss : 0.6576421147499374; validation accuracy : 0.8872180451127819\n",
      "Epoch 92:\t train loss : 0.5572224015007656; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.6330921077247027; validation accuracy : 0.9172932330827067\n",
      "Epoch 93:\t train loss : 0.55842020126532; train accuracy : 0.9930321296245092; \n",
      " validation loss : 0.6552022489679622; validation accuracy : 0.8947368421052632\n",
      "Epoch 94:\t train loss : 0.555969334186194; train accuracy : 0.9955621301775148; \n",
      " validation loss : 0.6191391969832302; validation accuracy : 0.9323308270676691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95:\t train loss : 0.5577146767661242; train accuracy : 0.9935989603494996; \n",
      " validation loss : 0.6627364851938847; validation accuracy : 0.8872180451127819\n",
      "Epoch 96:\t train loss : 0.5611321926567633; train accuracy : 0.9900873748824863; \n",
      " validation loss : 0.6626969499353202; validation accuracy : 0.8872180451127819\n",
      "Epoch 97:\t train loss : 0.5959189482464334; train accuracy : 0.9549300447934524; \n",
      " validation loss : 0.6372514960420684; validation accuracy : 0.9172932330827067\n",
      "Epoch 98:\t train loss : 0.5736780706311595; train accuracy : 0.977202344743682; \n",
      " validation loss : 0.6579744640110328; validation accuracy : 0.8947368421052632\n",
      "Epoch 99:\t train loss : 0.5632517327568394; train accuracy : 0.987833877122159; \n",
      " validation loss : 0.6797443398225911; validation accuracy : 0.8721804511278195\n",
      "Epoch 100:\t train loss : 0.5633329564424305; train accuracy : 0.9879444782392303; \n",
      " validation loss : 0.6152006795196686; validation accuracy : 0.9398496240601504\n",
      "Epoch 101:\t train loss : 0.5603899318206985; train accuracy : 0.9907786318641818; \n",
      " validation loss : 0.6694475063105286; validation accuracy : 0.8796992481203008\n",
      "Epoch 102:\t train loss : 0.5697453984685993; train accuracy : 0.981501963169828; \n",
      " validation loss : 0.6218709260764599; validation accuracy : 0.9323308270676691\n",
      "Epoch 103:\t train loss : 0.5714120004764607; train accuracy : 0.9798567715533927; \n",
      " validation loss : 0.620901988399401; validation accuracy : 0.9323308270676691\n",
      "Epoch 104:\t train loss : 0.5579047671501847; train accuracy : 0.9934745340927943; \n",
      " validation loss : 0.6719205434597605; validation accuracy : 0.8796992481203008\n",
      "Epoch 105:\t train loss : 0.5717665626860436; train accuracy : 0.9790687385942598; \n",
      " validation loss : 0.6371525250658415; validation accuracy : 0.9097744360902256\n",
      "Epoch 106:\t train loss : 0.5637582192311111; train accuracy : 0.9876126748880164; \n",
      " validation loss : 0.6505840739121646; validation accuracy : 0.9022556390977443\n",
      "Epoch 107:\t train loss : 0.5662474987913139; train accuracy : 0.9849444229386717; \n",
      " validation loss : 0.6802395182204468; validation accuracy : 0.8646616541353384\n",
      "Epoch 108:\t train loss : 0.5649192719844848; train accuracy : 0.9862578112038931; \n",
      " validation loss : 0.6449269882061522; validation accuracy : 0.9022556390977443\n",
      "Epoch 109:\t train loss : 0.5582779738295309; train accuracy : 0.9931150804623127; \n",
      " validation loss : 0.6566822765602665; validation accuracy : 0.8947368421052632\n",
      "Epoch 110:\t train loss : 0.5561647185678683; train accuracy : 0.995216501686667; \n",
      " validation loss : 0.6439882776238635; validation accuracy : 0.9097744360902256\n",
      "Epoch 111:\t train loss : 0.5572852381944928; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.6566402581975396; validation accuracy : 0.8947368421052632\n",
      "Epoch 112:\t train loss : 0.556735696255286; train accuracy : 0.9944975944257037; \n",
      " validation loss : 0.6036813132540572; validation accuracy : 0.9473684210526315\n",
      "Epoch 113:\t train loss : 0.5573241214767709; train accuracy : 0.9941104905159542; \n",
      " validation loss : 0.6192546421250289; validation accuracy : 0.9323308270676691\n",
      "Epoch 114:\t train loss : 0.5593744103996869; train accuracy : 0.9918984681745285; \n",
      " validation loss : 0.6426114546846151; validation accuracy : 0.9097744360902256\n",
      "Epoch 115:\t train loss : 0.5557752365774056; train accuracy : 0.9956450810153182; \n",
      " validation loss : 0.6269986435911867; validation accuracy : 0.924812030075188\n",
      "Epoch 116:\t train loss : 0.5551173094700151; train accuracy : 0.9962810374384781; \n",
      " validation loss : 0.6539580161577703; validation accuracy : 0.8947368421052632\n",
      "Epoch 117:\t train loss : 0.556080384560158; train accuracy : 0.9952441519659349; \n",
      " validation loss : 0.6312418619995745; validation accuracy : 0.9172932330827067\n",
      "Epoch 118:\t train loss : 0.5569579736263764; train accuracy : 0.994290217331195; \n",
      " validation loss : 0.6457076614234812; validation accuracy : 0.9022556390977443\n",
      "Epoch 119:\t train loss : 0.5546695187210309; train accuracy : 0.9966957916274954; \n",
      " validation loss : 0.6464170672509633; validation accuracy : 0.9022556390977443\n",
      "Epoch 120:\t train loss : 0.554539578485138; train accuracy : 0.9968893435823701; \n",
      " validation loss : 0.644156956574294; validation accuracy : 0.9097744360902256\n",
      "Epoch 121:\t train loss : 0.5552662925016386; train accuracy : 0.9961566111817729; \n",
      " validation loss : 0.6522584205318543; validation accuracy : 0.8947368421052632\n",
      "Epoch 122:\t train loss : 0.5575442977212968; train accuracy : 0.9938063374440081; \n",
      " validation loss : 0.6341542197439182; validation accuracy : 0.9172932330827067\n",
      "Epoch 123:\t train loss : 0.5569677343797969; train accuracy : 0.9943316927500968; \n",
      " validation loss : 0.6320395363392562; validation accuracy : 0.9172932330827067\n",
      "Epoch 124:\t train loss : 0.5573219214750739; train accuracy : 0.9939722391196151; \n",
      " validation loss : 0.6603108399183037; validation accuracy : 0.8872180451127819\n",
      "Epoch 125:\t train loss : 0.5569801843725372; train accuracy : 0.994290217331195; \n",
      " validation loss : 0.6422913170869641; validation accuracy : 0.9097744360902256\n",
      "Epoch 126:\t train loss : 0.5572423419998067; train accuracy : 0.9941519659348559; \n",
      " validation loss : 0.649676835089127; validation accuracy : 0.9022556390977443\n",
      "Epoch 127:\t train loss : 0.556350987068904; train accuracy : 0.9949952994525244; \n",
      " validation loss : 0.6572165909869049; validation accuracy : 0.8872180451127819\n",
      "Epoch 128:\t train loss : 0.5562887894967679; train accuracy : 0.9950091245921584; \n",
      " validation loss : 0.6364554720193192; validation accuracy : 0.9172932330827067\n",
      "Epoch 129:\t train loss : 0.5687303720822467; train accuracy : 0.9824282475253; \n",
      " validation loss : 0.6432357810626076; validation accuracy : 0.9022556390977443\n",
      "Epoch 130:\t train loss : 0.5603757603086138; train accuracy : 0.9909583586794226; \n",
      " validation loss : 0.651539904084332; validation accuracy : 0.8947368421052632\n",
      "Epoch 131:\t train loss : 0.5566584787652675; train accuracy : 0.9946773212409445; \n",
      " validation loss : 0.670528489716581; validation accuracy : 0.8796992481203008\n",
      "Epoch 132:\t train loss : 0.565786233863951; train accuracy : 0.9853730022673229; \n",
      " validation loss : 0.6379048083354385; validation accuracy : 0.9172932330827067\n",
      "Epoch 133:\t train loss : 0.5616772657634914; train accuracy : 0.9893961179007907; \n",
      " validation loss : 0.6409893700120888; validation accuracy : 0.9097744360902256\n",
      "Epoch 134:\t train loss : 0.5574164149180859; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.6693367037023537; validation accuracy : 0.8796992481203008\n",
      "Epoch 135:\t train loss : 0.5604237389631014; train accuracy : 0.9908892329812531; \n",
      " validation loss : 0.6432617835648263; validation accuracy : 0.9097744360902256\n",
      "Epoch 136:\t train loss : 0.5565000365522491; train accuracy : 0.9948293977769176; \n",
      " validation loss : 0.6220883522015472; validation accuracy : 0.9323308270676691\n",
      "Epoch 137:\t train loss : 0.5608493836567452; train accuracy : 0.9904883039318697; \n",
      " validation loss : 0.6428020332678158; validation accuracy : 0.9097744360902256\n",
      "Epoch 138:\t train loss : 0.5553565304539643; train accuracy : 0.996142786042139; \n",
      " validation loss : 0.6698229880960379; validation accuracy : 0.8796992481203008\n",
      "Epoch 139:\t train loss : 0.5556957151725876; train accuracy : 0.9957003815738539; \n",
      " validation loss : 0.6422669661023209; validation accuracy : 0.9097744360902256\n",
      "Epoch 140:\t train loss : 0.5557000040946957; train accuracy : 0.9957142067134878; \n",
      " validation loss : 0.6493339358270058; validation accuracy : 0.9022556390977443\n",
      "Epoch 141:\t train loss : 0.5541379145392861; train accuracy : 0.9973317480506553; \n",
      " validation loss : 0.6485065078819985; validation accuracy : 0.9022556390977443\n",
      "Epoch 142:\t train loss : 0.5602950226303431; train accuracy : 0.990916883260521; \n",
      " validation loss : 0.62520792684641; validation accuracy : 0.924812030075188\n",
      "Epoch 143:\t train loss : 0.5582438480520887; train accuracy : 0.9931150804623127; \n",
      " validation loss : 0.6486723256043376; validation accuracy : 0.9022556390977443\n",
      "Epoch 144:\t train loss : 0.5608815299481097; train accuracy : 0.9905297793507715; \n",
      " validation loss : 0.6497533219700565; validation accuracy : 0.8947368421052632\n",
      "Epoch 145:\t train loss : 0.5714777704505046; train accuracy : 0.9795664436210806; \n",
      " validation loss : 0.6407222075027619; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146:\t train loss : 0.5606818589057966; train accuracy : 0.9905574296300392; \n",
      " validation loss : 0.6569747981620125; validation accuracy : 0.8947368421052632\n",
      "Epoch 147:\t train loss : 0.5602869984079764; train accuracy : 0.9909445335397887; \n",
      " validation loss : 0.6369234953866801; validation accuracy : 0.9172932330827067\n",
      "Epoch 148:\t train loss : 0.5574999526330918; train accuracy : 0.9939169385610794; \n",
      " validation loss : 0.6776259409277975; validation accuracy : 0.8721804511278195\n",
      "Epoch 149:\t train loss : 0.5558101774434011; train accuracy : 0.9955897804567826; \n",
      " validation loss : 0.6509672769246472; validation accuracy : 0.9022556390977443\n",
      "Epoch 150:\t train loss : 0.5704173192498712; train accuracy : 0.9807692307692307; \n",
      " validation loss : 0.6497565877075908; validation accuracy : 0.9022556390977443\n",
      "Epoch 151:\t train loss : 0.559527870689637; train accuracy : 0.9917463916385555; \n",
      " validation loss : 0.6205058962867538; validation accuracy : 0.9323308270676691\n",
      "Epoch 152:\t train loss : 0.5578585062264488; train accuracy : 0.9935021843720622; \n",
      " validation loss : 0.655359900332652; validation accuracy : 0.8947368421052632\n",
      "Epoch 153:\t train loss : 0.5577623926835591; train accuracy : 0.9935436597909639; \n",
      " validation loss : 0.647902511649402; validation accuracy : 0.9022556390977443\n",
      "Epoch 154:\t train loss : 0.5574023035218042; train accuracy : 0.9938478128629099; \n",
      " validation loss : 0.6653036325455175; validation accuracy : 0.8872180451127819\n",
      "Epoch 155:\t train loss : 0.5549274303398377; train accuracy : 0.9963778134159155; \n",
      " validation loss : 0.6446442802417508; validation accuracy : 0.9022556390977443\n",
      "Epoch 156:\t train loss : 0.5559373361881609; train accuracy : 0.9954238787811757; \n",
      " validation loss : 0.6379248313494146; validation accuracy : 0.9097744360902256\n",
      "Epoch 157:\t train loss : 0.5557257641391362; train accuracy : 0.9955897804567826; \n",
      " validation loss : 0.6628188086209328; validation accuracy : 0.8872180451127819\n",
      "Epoch 158:\t train loss : 0.5580396881576969; train accuracy : 0.9932948072775535; \n",
      " validation loss : 0.6404882550755067; validation accuracy : 0.9097744360902256\n",
      "Epoch 159:\t train loss : 0.5929902211154926; train accuracy : 0.9576674224409667; \n",
      " validation loss : 0.6645858513813568; validation accuracy : 0.8872180451127819\n",
      "Epoch 160:\t train loss : 0.5886088773949213; train accuracy : 0.9620499917049162; \n",
      " validation loss : 0.6544934172038659; validation accuracy : 0.8947368421052632\n",
      "Epoch 161:\t train loss : 0.5749706702661475; train accuracy : 0.9760410330144335; \n",
      " validation loss : 0.6329003128883827; validation accuracy : 0.9172932330827067\n",
      "Epoch 162:\t train loss : 0.5599206264908481; train accuracy : 0.9913592877288061; \n",
      " validation loss : 0.6242801046717033; validation accuracy : 0.924812030075188\n",
      "Early stopping at epoch 162\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.556735696255286; Train accuracy : 0.9944975944257037; \n",
      " Validation loss : 0.6036813132540572; Validation accuracy : 0.9473684210526315\n",
      "------------------------------ Let's train model 52 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8906044096822132; train accuracy : 0.6410717248244208; \n",
      " validation loss : 0.7988158810600848; validation accuracy : 0.7518796992481203\n",
      "Epoch 2:\t train loss : 0.7743600617854032; train accuracy : 0.7710418625228115; \n",
      " validation loss : 0.7691990445940058; validation accuracy : 0.7669172932330827\n",
      "Epoch 3:\t train loss : 0.7243194771619342; train accuracy : 0.8232870651993586; \n",
      " validation loss : 0.7344543473794146; validation accuracy : 0.8195488721804511\n",
      "Epoch 4:\t train loss : 0.6937804707766587; train accuracy : 0.8541447768622463; \n",
      " validation loss : 0.7298107259895686; validation accuracy : 0.8120300751879699\n",
      "Epoch 5:\t train loss : 0.658371804788088; train accuracy : 0.8926616158823204; \n",
      " validation loss : 0.7012796020839055; validation accuracy : 0.8421052631578947\n",
      "Epoch 6:\t train loss : 0.637353887211968; train accuracy : 0.9137034784051319; \n",
      " validation loss : 0.6768000353899525; validation accuracy : 0.8796992481203008\n",
      "Epoch 7:\t train loss : 0.6220386982650374; train accuracy : 0.9290908588176741; \n",
      " validation loss : 0.6794564923055991; validation accuracy : 0.8646616541353384\n",
      "Epoch 8:\t train loss : 0.6016321900608034; train accuracy : 0.9493723386606204; \n",
      " validation loss : 0.6505057494090967; validation accuracy : 0.8872180451127819\n",
      "Epoch 9:\t train loss : 0.6090931369511645; train accuracy : 0.9413814079522204; \n",
      " validation loss : 0.6346284422554889; validation accuracy : 0.924812030075188\n",
      "Epoch 10:\t train loss : 0.5962490423307962; train accuracy : 0.9556489520544157; \n",
      " validation loss : 0.6443687722113924; validation accuracy : 0.9022556390977443\n",
      "Epoch 11:\t train loss : 0.5941272075502888; train accuracy : 0.9566028866891556; \n",
      " validation loss : 0.7099387576603239; validation accuracy : 0.8345864661654135\n",
      "Epoch 12:\t train loss : 0.5895360423551447; train accuracy : 0.9614831609799259; \n",
      " validation loss : 0.6660247742642802; validation accuracy : 0.8796992481203008\n",
      "Epoch 13:\t train loss : 0.5755426892635439; train accuracy : 0.977036443068075; \n",
      " validation loss : 0.6421313416501135; validation accuracy : 0.9097744360902256\n",
      "Epoch 14:\t train loss : 0.57349242785107; train accuracy : 0.9780595034009844; \n",
      " validation loss : 0.645695807216433; validation accuracy : 0.9097744360902256\n",
      "Epoch 15:\t train loss : 0.5659442278206277; train accuracy : 0.985359177127689; \n",
      " validation loss : 0.6170544529593199; validation accuracy : 0.9323308270676691\n",
      "Epoch 16:\t train loss : 0.5635893279266282; train accuracy : 0.9884698335453188; \n",
      " validation loss : 0.6389428134910086; validation accuracy : 0.9097744360902256\n",
      "Epoch 17:\t train loss : 0.563282962334685; train accuracy : 0.9885527843831222; \n",
      " validation loss : 0.6396104231712237; validation accuracy : 0.9097744360902256\n",
      "Epoch 18:\t train loss : 0.5627664721530188; train accuracy : 0.9889675385721396; \n",
      " validation loss : 0.6500590915380856; validation accuracy : 0.9022556390977443\n",
      "Epoch 19:\t train loss : 0.5689940597990837; train accuracy : 0.9822208704307913; \n",
      " validation loss : 0.6226915586756697; validation accuracy : 0.9323308270676691\n",
      "Epoch 20:\t train loss : 0.5645319698184426; train accuracy : 0.9875020737709451; \n",
      " validation loss : 0.6372522713024832; validation accuracy : 0.9097744360902256\n",
      "Epoch 21:\t train loss : 0.5598860136474195; train accuracy : 0.9915943151025826; \n",
      " validation loss : 0.6196620923588096; validation accuracy : 0.924812030075188\n",
      "Epoch 22:\t train loss : 0.5590108156672057; train accuracy : 0.992603550295858; \n",
      " validation loss : 0.6312883435782416; validation accuracy : 0.9172932330827067\n",
      "Epoch 23:\t train loss : 0.5719802019308743; train accuracy : 0.9792899408284024; \n",
      " validation loss : 0.6956363498729335; validation accuracy : 0.849624060150376\n",
      "Epoch 24:\t train loss : 0.5839195744344198; train accuracy : 0.9667920145993475; \n",
      " validation loss : 0.6713128375356189; validation accuracy : 0.8721804511278195\n",
      "Epoch 25:\t train loss : 0.565361246161357; train accuracy : 0.9864928385776697; \n",
      " validation loss : 0.6657602048354472; validation accuracy : 0.8872180451127819\n",
      "Epoch 26:\t train loss : 0.5608770698504503; train accuracy : 0.9908615827019853; \n",
      " validation loss : 0.6463436026396198; validation accuracy : 0.9022556390977443\n",
      "Epoch 27:\t train loss : 0.5606145912366476; train accuracy : 0.9908339324227174; \n",
      " validation loss : 0.6745484981575476; validation accuracy : 0.8646616541353384\n",
      "Epoch 28:\t train loss : 0.5598745602463531; train accuracy : 0.9914837139855113; \n",
      " validation loss : 0.6420371991016874; validation accuracy : 0.9097744360902256\n",
      "Epoch 29:\t train loss : 0.5595620198974607; train accuracy : 0.9919261184537964; \n",
      " validation loss : 0.6665460013728227; validation accuracy : 0.8796992481203008\n",
      "Epoch 30:\t train loss : 0.5567055093581303; train accuracy : 0.994760272078748; \n",
      " validation loss : 0.6445344372524459; validation accuracy : 0.9022556390977443\n",
      "Epoch 31:\t train loss : 0.5574026026947091; train accuracy : 0.9940966653763202; \n",
      " validation loss : 0.655029274901202; validation accuracy : 0.9022556390977443\n",
      "Epoch 32:\t train loss : 0.5613589126902906; train accuracy : 0.9900597246032184; \n",
      " validation loss : 0.6800662534772486; validation accuracy : 0.8646616541353384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:\t train loss : 0.5611792641531179; train accuracy : 0.9900458994635846; \n",
      " validation loss : 0.635334397910979; validation accuracy : 0.9172932330827067\n",
      "Epoch 34:\t train loss : 0.5727412169104933; train accuracy : 0.977962727423547; \n",
      " validation loss : 0.6649207051728151; validation accuracy : 0.8872180451127819\n",
      "Epoch 35:\t train loss : 0.5702081643959556; train accuracy : 0.9809351324448377; \n",
      " validation loss : 0.6592151854296895; validation accuracy : 0.8947368421052632\n",
      "Epoch 36:\t train loss : 0.5858890809546349; train accuracy : 0.9648288447713322; \n",
      " validation loss : 0.6711843490728976; validation accuracy : 0.8796992481203008\n",
      "Epoch 37:\t train loss : 0.5746577851183164; train accuracy : 0.9763866615052812; \n",
      " validation loss : 0.6497266662804152; validation accuracy : 0.9022556390977443\n",
      "Epoch 38:\t train loss : 0.5606047769988406; train accuracy : 0.9907233313056462; \n",
      " validation loss : 0.6696098228095078; validation accuracy : 0.8796992481203008\n",
      "Epoch 39:\t train loss : 0.5562226917618989; train accuracy : 0.99536857822264; \n",
      " validation loss : 0.6723174679099305; validation accuracy : 0.8796992481203008\n",
      "Epoch 40:\t train loss : 0.5550730551997034; train accuracy : 0.996446939114085; \n",
      " validation loss : 0.6536128042108645; validation accuracy : 0.8947368421052632\n",
      "Epoch 41:\t train loss : 0.5618065611355423; train accuracy : 0.9893546424818891; \n",
      " validation loss : 0.629300553401544; validation accuracy : 0.924812030075188\n",
      "Epoch 42:\t train loss : 0.5577877938531048; train accuracy : 0.9935713100702317; \n",
      " validation loss : 0.6197438053083815; validation accuracy : 0.9323308270676691\n",
      "Epoch 43:\t train loss : 0.5568174348807943; train accuracy : 0.9946358458220428; \n",
      " validation loss : 0.6486131382217946; validation accuracy : 0.9022556390977443\n",
      "Epoch 44:\t train loss : 0.5552385840039031; train accuracy : 0.9962810374384781; \n",
      " validation loss : 0.6398251009652519; validation accuracy : 0.9097744360902256\n",
      "Epoch 45:\t train loss : 0.5577919446751654; train accuracy : 0.9935989603494996; \n",
      " validation loss : 0.6632532316454324; validation accuracy : 0.8872180451127819\n",
      "Epoch 46:\t train loss : 0.5541655500607873; train accuracy : 0.9971796715146822; \n",
      " validation loss : 0.6357767597904622; validation accuracy : 0.9172932330827067\n",
      "Epoch 47:\t train loss : 0.5543361868645538; train accuracy : 0.9971934966543162; \n",
      " validation loss : 0.6445878660978803; validation accuracy : 0.9097744360902256\n",
      "Epoch 48:\t train loss : 0.554057399890078; train accuracy : 0.9973455731902893; \n",
      " validation loss : 0.6497001017037469; validation accuracy : 0.9022556390977443\n",
      "Epoch 49:\t train loss : 0.5559663667004784; train accuracy : 0.9956312558756844; \n",
      " validation loss : 0.6554537437334469; validation accuracy : 0.8947368421052632\n",
      "Epoch 50:\t train loss : 0.5571614644198344; train accuracy : 0.9943040424708289; \n",
      " validation loss : 0.6330659931765282; validation accuracy : 0.9172932330827067\n",
      "Epoch 51:\t train loss : 0.5571936952373452; train accuracy : 0.9941657910744899; \n",
      " validation loss : 0.6608160191923099; validation accuracy : 0.8947368421052632\n",
      "Epoch 52:\t train loss : 0.5595382662533449; train accuracy : 0.9915666648233147; \n",
      " validation loss : 0.6759296994126073; validation accuracy : 0.8721804511278195\n",
      "Epoch 53:\t train loss : 0.5895894252851295; train accuracy : 0.9608610296964; \n",
      " validation loss : 0.6291920836921335; validation accuracy : 0.924812030075188\n",
      "Epoch 54:\t train loss : 0.583184808942707; train accuracy : 0.9676906486755517; \n",
      " validation loss : 0.665266517466953; validation accuracy : 0.8872180451127819\n",
      "Epoch 55:\t train loss : 0.5705076435338006; train accuracy : 0.9805895039539899; \n",
      " validation loss : 0.6630630234714573; validation accuracy : 0.8872180451127819\n",
      "Epoch 56:\t train loss : 0.5627004035561458; train accuracy : 0.9885251341038545; \n",
      " validation loss : 0.6358335586355506; validation accuracy : 0.9172932330827067\n",
      "Epoch 57:\t train loss : 0.5573182492202639; train accuracy : 0.9941104905159542; \n",
      " validation loss : 0.6376764030661363; validation accuracy : 0.9097744360902256\n",
      "Epoch 58:\t train loss : 0.558834854919882; train accuracy : 0.9923132223635459; \n",
      " validation loss : 0.6579587130469134; validation accuracy : 0.8947368421052632\n",
      "Epoch 59:\t train loss : 0.5564665522935128; train accuracy : 0.9949261737543549; \n",
      " validation loss : 0.6908610090469088; validation accuracy : 0.8646616541353384\n",
      "Epoch 60:\t train loss : 0.555009264715454; train accuracy : 0.996599015650058; \n",
      " validation loss : 0.6643532049965265; validation accuracy : 0.8872180451127819\n",
      "Epoch 61:\t train loss : 0.5557975930813933; train accuracy : 0.9957003815738539; \n",
      " validation loss : 0.6396537869556533; validation accuracy : 0.9097744360902256\n",
      "Epoch 62:\t train loss : 0.5552528479628951; train accuracy : 0.9960183597854338; \n",
      " validation loss : 0.6638802774957676; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.5548885966894203; train accuracy : 0.9964745893933529; \n",
      " validation loss : 0.6703558326120849; validation accuracy : 0.8796992481203008\n",
      "Epoch 64:\t train loss : 0.5567603399201068; train accuracy : 0.9946220206824089; \n",
      " validation loss : 0.6577969297254588; validation accuracy : 0.8947368421052632\n",
      "Epoch 65:\t train loss : 0.5557372023636141; train accuracy : 0.9957418569927556; \n",
      " validation loss : 0.6519108005560339; validation accuracy : 0.9022556390977443\n",
      "Early stopping at epoch 65\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5659442278206277; Train accuracy : 0.985359177127689; \n",
      " Validation loss : 0.6170544529593199; Validation accuracy : 0.9323308270676691\n",
      "------------------------------ Let's train model 53 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9162904274758024; train accuracy : 0.5914947740972184; \n",
      " validation loss : 0.8711755888997841; validation accuracy : 0.6616541353383458\n",
      "Epoch 2:\t train loss : 0.7894847537890405; train accuracy : 0.7551982525023503; \n",
      " validation loss : 0.7952989140321214; validation accuracy : 0.7368421052631579\n",
      "Epoch 3:\t train loss : 0.7375572582424909; train accuracy : 0.8073605043410939; \n",
      " validation loss : 0.7708074921639845; validation accuracy : 0.7819548872180451\n",
      "Epoch 4:\t train loss : 0.706942671337952; train accuracy : 0.8409970690703976; \n",
      " validation loss : 0.8502274812376361; validation accuracy : 0.6691729323308271\n",
      "Epoch 5:\t train loss : 0.6880360690506502; train accuracy : 0.8602831388597025; \n",
      " validation loss : 0.7287936395380904; validation accuracy : 0.8195488721804511\n",
      "Epoch 6:\t train loss : 0.656247231379821; train accuracy : 0.8940164795664436; \n",
      " validation loss : 0.7127242294369974; validation accuracy : 0.8421052631578947\n",
      "Epoch 7:\t train loss : 0.6430390703580187; train accuracy : 0.9071918376375602; \n",
      " validation loss : 0.7081914073270543; validation accuracy : 0.8421052631578947\n",
      "Epoch 8:\t train loss : 0.6265173787506804; train accuracy : 0.9250400929049384; \n",
      " validation loss : 0.7148312841098522; validation accuracy : 0.8421052631578947\n",
      "Epoch 9:\t train loss : 0.6173124697260721; train accuracy : 0.9338052314328374; \n",
      " validation loss : 0.716805964504934; validation accuracy : 0.8270676691729323\n",
      "Epoch 10:\t train loss : 0.6077573812735128; train accuracy : 0.9432478018027982; \n",
      " validation loss : 0.694313387465096; validation accuracy : 0.8646616541353384\n",
      "Epoch 11:\t train loss : 0.60113211453442; train accuracy : 0.950063595642316; \n",
      " validation loss : 0.6588283358000601; validation accuracy : 0.8872180451127819\n",
      "Epoch 12:\t train loss : 0.5968902591704649; train accuracy : 0.954377039208096; \n",
      " validation loss : 0.6849356885181751; validation accuracy : 0.8646616541353384\n",
      "Epoch 13:\t train loss : 0.6048684572531473; train accuracy : 0.9460404800088481; \n",
      " validation loss : 0.6939457100227647; validation accuracy : 0.8571428571428571\n",
      "Epoch 14:\t train loss : 0.5929729012783711; train accuracy : 0.9585798816568047; \n",
      " validation loss : 0.735217990947051; validation accuracy : 0.8195488721804511\n",
      "Epoch 15:\t train loss : 0.5916313663144889; train accuracy : 0.9593955648952054; \n",
      " validation loss : 0.6817087160442942; validation accuracy : 0.8646616541353384\n",
      "Epoch 16:\t train loss : 0.5818957803518967; train accuracy : 0.969792069899906; \n",
      " validation loss : 0.6824188526834905; validation accuracy : 0.8646616541353384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:\t train loss : 0.5937550903996556; train accuracy : 0.9568932146214677; \n",
      " validation loss : 0.6905342711615107; validation accuracy : 0.8571428571428571\n",
      "Epoch 18:\t train loss : 0.5871038738840283; train accuracy : 0.9639578609743958; \n",
      " validation loss : 0.661088301578489; validation accuracy : 0.8947368421052632\n",
      "Epoch 19:\t train loss : 0.5783436794002627; train accuracy : 0.9733174805065531; \n",
      " validation loss : 0.6841737552069881; validation accuracy : 0.8646616541353384\n",
      "Epoch 20:\t train loss : 0.5734533456257769; train accuracy : 0.9776723994912349; \n",
      " validation loss : 0.6597664049797077; validation accuracy : 0.8947368421052632\n",
      "Epoch 21:\t train loss : 0.572379964174905; train accuracy : 0.9794281922247414; \n",
      " validation loss : 0.6847638056435941; validation accuracy : 0.8646616541353384\n",
      "Epoch 22:\t train loss : 0.5710030916690058; train accuracy : 0.9803268263009457; \n",
      " validation loss : 0.7046597211669801; validation accuracy : 0.8421052631578947\n",
      "Epoch 23:\t train loss : 0.5689174688018688; train accuracy : 0.9825941492009069; \n",
      " validation loss : 0.6895974332591235; validation accuracy : 0.8571428571428571\n",
      "Epoch 24:\t train loss : 0.5709180429778667; train accuracy : 0.9805618536747222; \n",
      " validation loss : 0.689096374388463; validation accuracy : 0.8571428571428571\n",
      "Epoch 25:\t train loss : 0.5741492168128909; train accuracy : 0.9770917436266107; \n",
      " validation loss : 0.686588488332519; validation accuracy : 0.8571428571428571\n",
      "Epoch 26:\t train loss : 0.5719366261930952; train accuracy : 0.9794834927832771; \n",
      " validation loss : 0.6677653609308327; validation accuracy : 0.8872180451127819\n",
      "Epoch 27:\t train loss : 0.5808159722958871; train accuracy : 0.9701376983907537; \n",
      " validation loss : 0.6666079709243445; validation accuracy : 0.8796992481203008\n",
      "Epoch 28:\t train loss : 0.5777736011804757; train accuracy : 0.9731377536913123; \n",
      " validation loss : 0.6885883072494906; validation accuracy : 0.8571428571428571\n",
      "Epoch 29:\t train loss : 0.5748701947870462; train accuracy : 0.9760825084333352; \n",
      " validation loss : 0.6498631635991998; validation accuracy : 0.9022556390977443\n",
      "Epoch 30:\t train loss : 0.5629786379526358; train accuracy : 0.9885666095227562; \n",
      " validation loss : 0.6965740483380458; validation accuracy : 0.8571428571428571\n",
      "Epoch 31:\t train loss : 0.6079331886671612; train accuracy : 0.942515069402201; \n",
      " validation loss : 0.6563102989312715; validation accuracy : 0.8872180451127819\n",
      "Epoch 32:\t train loss : 0.5693119953746154; train accuracy : 0.9820411436155505; \n",
      " validation loss : 0.6691397371439802; validation accuracy : 0.8721804511278195\n",
      "Epoch 33:\t train loss : 0.5752083790140377; train accuracy : 0.9758474810595587; \n",
      " validation loss : 0.6693785473482057; validation accuracy : 0.8796992481203008\n",
      "Epoch 34:\t train loss : 0.5607406648271493; train accuracy : 0.9908892329812531; \n",
      " validation loss : 0.6985323278608382; validation accuracy : 0.8421052631578947\n",
      "Epoch 35:\t train loss : 0.5677595971211002; train accuracy : 0.9837139855112537; \n",
      " validation loss : 0.7023278047946072; validation accuracy : 0.8421052631578947\n",
      "Epoch 36:\t train loss : 0.5615424046308873; train accuracy : 0.9898661726483438; \n",
      " validation loss : 0.6502002736454422; validation accuracy : 0.9022556390977443\n",
      "Epoch 37:\t train loss : 0.5607034295521344; train accuracy : 0.9905574296300392; \n",
      " validation loss : 0.7176812016018269; validation accuracy : 0.8345864661654135\n",
      "Epoch 38:\t train loss : 0.5680163897146299; train accuracy : 0.9834236575789416; \n",
      " validation loss : 0.6766301292395759; validation accuracy : 0.8721804511278195\n",
      "Epoch 39:\t train loss : 0.562458501163024; train accuracy : 0.9888569374550683; \n",
      " validation loss : 0.6943990741484978; validation accuracy : 0.8571428571428571\n",
      "Epoch 40:\t train loss : 0.5698286742385101; train accuracy : 0.9813360614942211; \n",
      " validation loss : 0.674675422604237; validation accuracy : 0.8796992481203008\n",
      "Epoch 41:\t train loss : 0.56090509304392; train accuracy : 0.9905712547696731; \n",
      " validation loss : 0.6887894307241185; validation accuracy : 0.8571428571428571\n",
      "Epoch 42:\t train loss : 0.5598046496226723; train accuracy : 0.9914975391251452; \n",
      " validation loss : 0.7065084581013019; validation accuracy : 0.8421052631578947\n",
      "Epoch 43:\t train loss : 0.5721522444871163; train accuracy : 0.9791240391527954; \n",
      " validation loss : 0.724776739108268; validation accuracy : 0.8270676691729323\n",
      "Epoch 44:\t train loss : 0.5779946171044653; train accuracy : 0.972875076038268; \n",
      " validation loss : 0.693892934346601; validation accuracy : 0.849624060150376\n",
      "Epoch 45:\t train loss : 0.5733934711664401; train accuracy : 0.9779074268650113; \n",
      " validation loss : 0.6674701710315282; validation accuracy : 0.8872180451127819\n",
      "Epoch 46:\t train loss : 0.5600716060742871; train accuracy : 0.9914284134269756; \n",
      " validation loss : 0.6637731873391004; validation accuracy : 0.8796992481203008\n",
      "Epoch 47:\t train loss : 0.5609732191947931; train accuracy : 0.9903362273958967; \n",
      " validation loss : 0.6720474082458029; validation accuracy : 0.8721804511278195\n",
      "Epoch 48:\t train loss : 0.5687269355863485; train accuracy : 0.9824558978045678; \n",
      " validation loss : 0.7242761040744973; validation accuracy : 0.8270676691729323\n",
      "Epoch 49:\t train loss : 0.5678589076311937; train accuracy : 0.9833130564618703; \n",
      " validation loss : 0.6998848496448584; validation accuracy : 0.849624060150376\n",
      "Epoch 50:\t train loss : 0.5643266445476215; train accuracy : 0.9871564452800973; \n",
      " validation loss : 0.6636410828056187; validation accuracy : 0.8872180451127819\n",
      "Epoch 51:\t train loss : 0.5589478268010034; train accuracy : 0.9924929491787867; \n",
      " validation loss : 0.6548163451022423; validation accuracy : 0.8947368421052632\n",
      "Epoch 52:\t train loss : 0.5587152101522637; train accuracy : 0.9926588508543936; \n",
      " validation loss : 0.6843354911513421; validation accuracy : 0.8646616541353384\n",
      "Epoch 53:\t train loss : 0.5557337157033279; train accuracy : 0.9957556821323895; \n",
      " validation loss : 0.6849197261653028; validation accuracy : 0.8646616541353384\n",
      "Epoch 54:\t train loss : 0.5563038877012654; train accuracy : 0.995230326826301; \n",
      " validation loss : 0.7243645468345408; validation accuracy : 0.8270676691729323\n",
      "Epoch 55:\t train loss : 0.5567058861391967; train accuracy : 0.9947187966598463; \n",
      " validation loss : 0.6880124040852097; validation accuracy : 0.8571428571428571\n",
      "Epoch 56:\t train loss : 0.5596930043613229; train accuracy : 0.9917602167781895; \n",
      " validation loss : 0.6945104845364459; validation accuracy : 0.8571428571428571\n",
      "Epoch 57:\t train loss : 0.5596160672303564; train accuracy : 0.9918984681745285; \n",
      " validation loss : 0.6808142291068165; validation accuracy : 0.8721804511278195\n",
      "Epoch 58:\t train loss : 0.5600247930240566; train accuracy : 0.9912486866117348; \n",
      " validation loss : 0.6743251628004368; validation accuracy : 0.8796992481203008\n",
      "Epoch 59:\t train loss : 0.5707842245671659; train accuracy : 0.9803544765802135; \n",
      " validation loss : 0.6849179254405855; validation accuracy : 0.8646616541353384\n",
      "Epoch 60:\t train loss : 0.559707581655715; train accuracy : 0.9917049162196538; \n",
      " validation loss : 0.6828643680474339; validation accuracy : 0.8721804511278195\n",
      "Epoch 61:\t train loss : 0.5627017208704148; train accuracy : 0.9887325111983631; \n",
      " validation loss : 0.6521224566158331; validation accuracy : 0.9022556390977443\n",
      "Epoch 62:\t train loss : 0.5583256098293171; train accuracy : 0.9929215285074379; \n",
      " validation loss : 0.6972172936849484; validation accuracy : 0.8571428571428571\n",
      "Epoch 63:\t train loss : 0.5564590938575756; train accuracy : 0.9949814743128905; \n",
      " validation loss : 0.6800453338500511; validation accuracy : 0.8721804511278195\n",
      "Epoch 64:\t train loss : 0.5676247250093626; train accuracy : 0.9833821821600398; \n",
      " validation loss : 0.6533092598369841; validation accuracy : 0.8947368421052632\n",
      "Epoch 65:\t train loss : 0.5697219579413584; train accuracy : 0.9812254603771499; \n",
      " validation loss : 0.6803864183033626; validation accuracy : 0.8721804511278195\n",
      "Epoch 66:\t train loss : 0.5610841671279; train accuracy : 0.9900597246032184; \n",
      " validation loss : 0.6784607283304315; validation accuracy : 0.8646616541353384\n",
      "Epoch 67:\t train loss : 0.5602803375649057; train accuracy : 0.99105513465686; \n",
      " validation loss : 0.6660720260626367; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68:\t train loss : 0.5622856686601821; train accuracy : 0.9889675385721396; \n",
      " validation loss : 0.6730013683571862; validation accuracy : 0.8796992481203008\n",
      "Epoch 69:\t train loss : 0.5551385034451032; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.7026474876452372; validation accuracy : 0.849624060150376\n",
      "Epoch 70:\t train loss : 0.5625352691119229; train accuracy : 0.9886910357794614; \n",
      " validation loss : 0.7278359388100792; validation accuracy : 0.8195488721804511\n",
      "Epoch 71:\t train loss : 0.5690395681833589; train accuracy : 0.9822623458496931; \n",
      " validation loss : 0.7912322197410722; validation accuracy : 0.7593984962406015\n",
      "Epoch 72:\t train loss : 0.5834474426150016; train accuracy : 0.9674417961621412; \n",
      " validation loss : 0.6991184118359733; validation accuracy : 0.8421052631578947\n",
      "Epoch 73:\t train loss : 0.5648103398714327; train accuracy : 0.986437538019134; \n",
      " validation loss : 0.6865739826372242; validation accuracy : 0.8646616541353384\n",
      "Epoch 74:\t train loss : 0.557164584253108; train accuracy : 0.9941934413537576; \n",
      " validation loss : 0.6884698838528711; validation accuracy : 0.8646616541353384\n",
      "Epoch 75:\t train loss : 0.5683346719634562; train accuracy : 0.9826771000387103; \n",
      " validation loss : 0.6812559917057489; validation accuracy : 0.8721804511278195\n",
      "Epoch 76:\t train loss : 0.6084712664290358; train accuracy : 0.9415058342089255; \n",
      " validation loss : 0.6932152308008216; validation accuracy : 0.8571428571428571\n",
      "Epoch 77:\t train loss : 0.5822277712960874; train accuracy : 0.9685616324724879; \n",
      " validation loss : 0.6612661859824949; validation accuracy : 0.8796992481203008\n",
      "Epoch 78:\t train loss : 0.5598750072089625; train accuracy : 0.9914837139855113; \n",
      " validation loss : 0.6795152724936596; validation accuracy : 0.8721804511278195\n",
      "Epoch 79:\t train loss : 0.5560078219717693; train accuracy : 0.9954100536415418; \n",
      " validation loss : 0.6661764685716934; validation accuracy : 0.8872180451127819\n",
      "Early stopping at epoch 79\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5748701947870462; Train accuracy : 0.9760825084333352; \n",
      " Validation loss : 0.6498631635991998; Validation accuracy : 0.9022556390977443\n",
      "------------------------------ Let's train model 54 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9103859192561743; train accuracy : 0.6166703533705691; \n",
      " validation loss : 0.8112334901591324; validation accuracy : 0.7593984962406015\n",
      "Epoch 2:\t train loss : 0.7962678917962773; train accuracy : 0.7477050268207709; \n",
      " validation loss : 0.7443376641953515; validation accuracy : 0.7969924812030075\n",
      "Epoch 3:\t train loss : 0.746102665748482; train accuracy : 0.8008488635735221; \n",
      " validation loss : 0.7090825788658461; validation accuracy : 0.8421052631578947\n",
      "Epoch 4:\t train loss : 0.7225483827445376; train accuracy : 0.8252778853066416; \n",
      " validation loss : 0.6894022938446888; validation accuracy : 0.8571428571428571\n",
      "Epoch 5:\t train loss : 0.6965042994499473; train accuracy : 0.8520433556378919; \n",
      " validation loss : 0.6882891915163472; validation accuracy : 0.849624060150376\n",
      "Epoch 6:\t train loss : 0.678933746133766; train accuracy : 0.8708178952607422; \n",
      " validation loss : 0.6621028225283196; validation accuracy : 0.8872180451127819\n",
      "Epoch 7:\t train loss : 0.6650266613500777; train accuracy : 0.8856107946690261; \n",
      " validation loss : 0.6380775044364021; validation accuracy : 0.9097744360902256\n",
      "Epoch 8:\t train loss : 0.6430287186122641; train accuracy : 0.9073439141735331; \n",
      " validation loss : 0.625765755282889; validation accuracy : 0.9172932330827067\n",
      "Epoch 9:\t train loss : 0.6278267469403277; train accuracy : 0.9229801470994857; \n",
      " validation loss : 0.6338810183364979; validation accuracy : 0.9097744360902256\n",
      "Epoch 10:\t train loss : 0.6180784857947874; train accuracy : 0.932795996239562; \n",
      " validation loss : 0.6187256759412141; validation accuracy : 0.9398496240601504\n",
      "Epoch 11:\t train loss : 0.6095600782421159; train accuracy : 0.9416993861638002; \n",
      " validation loss : 0.5980949919341304; validation accuracy : 0.9548872180451128\n",
      "Epoch 12:\t train loss : 0.5995024162614578; train accuracy : 0.952068240889233; \n",
      " validation loss : 0.6080251563039248; validation accuracy : 0.9473684210526315\n",
      "Epoch 13:\t train loss : 0.5947373925489062; train accuracy : 0.9568932146214677; \n",
      " validation loss : 0.6167186885165384; validation accuracy : 0.9323308270676691\n",
      "Epoch 14:\t train loss : 0.5858265313365141; train accuracy : 0.9657413039871703; \n",
      " validation loss : 0.6054232055263401; validation accuracy : 0.9473684210526315\n",
      "Epoch 15:\t train loss : 0.5876667399835579; train accuracy : 0.9640131615329315; \n",
      " validation loss : 0.5869462201129594; validation accuracy : 0.9699248120300752\n",
      "Epoch 16:\t train loss : 0.5778397601312816; train accuracy : 0.9738428358126417; \n",
      " validation loss : 0.5949358316062481; validation accuracy : 0.9548872180451128\n",
      "Epoch 17:\t train loss : 0.5828281022329049; train accuracy : 0.9688796106840679; \n",
      " validation loss : 0.5828350456462917; validation accuracy : 0.9699248120300752\n",
      "Epoch 18:\t train loss : 0.5741831478411846; train accuracy : 0.9775479732345297; \n",
      " validation loss : 0.6076089669892774; validation accuracy : 0.9473684210526315\n",
      "Epoch 19:\t train loss : 0.5754991431694513; train accuracy : 0.9761931095504065; \n",
      " validation loss : 0.5971060616545302; validation accuracy : 0.9548872180451128\n",
      "Epoch 20:\t train loss : 0.5748825404349341; train accuracy : 0.9769120168113697; \n",
      " validation loss : 0.588177001182651; validation accuracy : 0.9624060150375939\n",
      "Epoch 21:\t train loss : 0.5716785335047296; train accuracy : 0.9798567715533927; \n",
      " validation loss : 0.5988517891277942; validation accuracy : 0.9548872180451128\n",
      "Epoch 22:\t train loss : 0.5714291532576471; train accuracy : 0.9800917989271691; \n",
      " validation loss : 0.6132994511764811; validation accuracy : 0.9398496240601504\n",
      "Epoch 23:\t train loss : 0.5683664208935455; train accuracy : 0.9831195045069955; \n",
      " validation loss : 0.5877643004327268; validation accuracy : 0.9624060150375939\n",
      "Epoch 24:\t train loss : 0.5666424217136219; train accuracy : 0.9848614721008683; \n",
      " validation loss : 0.5967274650319045; validation accuracy : 0.9548872180451128\n",
      "Epoch 25:\t train loss : 0.5883784346830052; train accuracy : 0.9622435436597909; \n",
      " validation loss : 0.6496102282529644; validation accuracy : 0.9022556390977443\n",
      "Epoch 26:\t train loss : 0.5938627563494877; train accuracy : 0.9569485151800033; \n",
      " validation loss : 0.5918719439678771; validation accuracy : 0.9548872180451128\n",
      "Epoch 27:\t train loss : 0.5711474012914475; train accuracy : 0.9802853508820439; \n",
      " validation loss : 0.6003933810856672; validation accuracy : 0.9548872180451128\n",
      "Epoch 28:\t train loss : 0.565738266938516; train accuracy : 0.9857186307581707; \n",
      " validation loss : 0.6003083528233555; validation accuracy : 0.9548872180451128\n",
      "Epoch 29:\t train loss : 0.5779381365992137; train accuracy : 0.9734419067632583; \n",
      " validation loss : 0.5911093879435102; validation accuracy : 0.9548872180451128\n",
      "Epoch 30:\t train loss : 0.5698867810140785; train accuracy : 0.9814743128905602; \n",
      " validation loss : 0.6043916987757051; validation accuracy : 0.9398496240601504\n",
      "Epoch 31:\t train loss : 0.5743362526054427; train accuracy : 0.9765525631808881; \n",
      " validation loss : 0.6246884237446013; validation accuracy : 0.924812030075188\n",
      "Epoch 32:\t train loss : 0.5774715426295416; train accuracy : 0.9738428358126417; \n",
      " validation loss : 0.6221292423303549; validation accuracy : 0.9172932330827067\n",
      "Epoch 33:\t train loss : 0.7072590642591058; train accuracy : 0.8405823148813804; \n",
      " validation loss : 0.6551517046749815; validation accuracy : 0.8947368421052632\n",
      "Epoch 34:\t train loss : 0.6591382325152774; train accuracy : 0.889343582370182; \n",
      " validation loss : 0.6318940506379002; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.614256278444152; train accuracy : 0.9362661062876735; \n",
      " validation loss : 0.6217516875909311; validation accuracy : 0.924812030075188\n",
      "Epoch 36:\t train loss : 0.5957365696945308; train accuracy : 0.9551650721672289; \n",
      " validation loss : 0.6164157265020218; validation accuracy : 0.9323308270676691\n",
      "Epoch 37:\t train loss : 0.5833729854425495; train accuracy : 0.967939501188962; \n",
      " validation loss : 0.5946723018101671; validation accuracy : 0.9624060150375939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38:\t train loss : 0.5855775526623707; train accuracy : 0.9659210308024111; \n",
      " validation loss : 0.6389224816699355; validation accuracy : 0.9172932330827067\n",
      "Epoch 39:\t train loss : 0.5784650439257334; train accuracy : 0.9726815240833933; \n",
      " validation loss : 0.6133055822973199; validation accuracy : 0.9323308270676691\n",
      "Epoch 40:\t train loss : 0.5763266441046949; train accuracy : 0.9749211967040867; \n",
      " validation loss : 0.6099041861550467; validation accuracy : 0.9398496240601504\n",
      "Epoch 41:\t train loss : 0.5764314413819785; train accuracy : 0.9746446939114085; \n",
      " validation loss : 0.5936785996426747; validation accuracy : 0.9548872180451128\n",
      "Epoch 42:\t train loss : 0.5761778743332847; train accuracy : 0.9753912514516396; \n",
      " validation loss : 0.5963050372349216; validation accuracy : 0.9473684210526315\n",
      "Epoch 43:\t train loss : 0.5703210117607069; train accuracy : 0.9808521816070342; \n",
      " validation loss : 0.5897963365517453; validation accuracy : 0.9624060150375939\n",
      "Epoch 44:\t train loss : 0.5754218597659787; train accuracy : 0.9758198307802909; \n",
      " validation loss : 0.6177845883897475; validation accuracy : 0.9323308270676691\n",
      "Epoch 45:\t train loss : 0.5689702161288919; train accuracy : 0.9823729469667644; \n",
      " validation loss : 0.6184092198253262; validation accuracy : 0.9323308270676691\n",
      "Epoch 46:\t train loss : 0.5643051241867911; train accuracy : 0.9869214179063208; \n",
      " validation loss : 0.6002181276926716; validation accuracy : 0.9548872180451128\n",
      "Epoch 47:\t train loss : 0.5642294932054581; train accuracy : 0.9870734944422939; \n",
      " validation loss : 0.6095829375252325; validation accuracy : 0.9398496240601504\n",
      "Epoch 48:\t train loss : 0.5634513984463011; train accuracy : 0.9879997787977659; \n",
      " validation loss : 0.6052143431038054; validation accuracy : 0.9398496240601504\n",
      "Epoch 49:\t train loss : 0.5636410874696349; train accuracy : 0.987654150306918; \n",
      " validation loss : 0.6101995425775395; validation accuracy : 0.9473684210526315\n",
      "Epoch 50:\t train loss : 0.5613189624221363; train accuracy : 0.9903085771166289; \n",
      " validation loss : 0.6178061561883286; validation accuracy : 0.9323308270676691\n",
      "Epoch 51:\t train loss : 0.565776211951978; train accuracy : 0.9854697782447602; \n",
      " validation loss : 0.6069317144746764; validation accuracy : 0.9473684210526315\n",
      "Epoch 52:\t train loss : 0.5775775865025046; train accuracy : 0.9734695570425261; \n",
      " validation loss : 0.6023933156630352; validation accuracy : 0.9548872180451128\n",
      "Epoch 53:\t train loss : 0.5732840892092137; train accuracy : 0.9778797765857435; \n",
      " validation loss : 0.6137285285638351; validation accuracy : 0.9398496240601504\n",
      "Epoch 54:\t train loss : 0.560354714181682; train accuracy : 0.9910966100757618; \n",
      " validation loss : 0.6142701324408183; validation accuracy : 0.9398496240601504\n",
      "Epoch 55:\t train loss : 0.562133701249844; train accuracy : 0.9892855167837196; \n",
      " validation loss : 0.6197134226234443; validation accuracy : 0.9323308270676691\n",
      "Epoch 56:\t train loss : 0.5590520738250664; train accuracy : 0.9923132223635459; \n",
      " validation loss : 0.642781760205442; validation accuracy : 0.9022556390977443\n",
      "Epoch 57:\t train loss : 0.5676529468876924; train accuracy : 0.9833821821600398; \n",
      " validation loss : 0.6147625847467988; validation accuracy : 0.9398496240601504\n",
      "Epoch 58:\t train loss : 0.5637969590874804; train accuracy : 0.9872532212575347; \n",
      " validation loss : 0.5903991842627847; validation accuracy : 0.9624060150375939\n",
      "Epoch 59:\t train loss : 0.5627516135876415; train accuracy : 0.9885113089642206; \n",
      " validation loss : 0.6345077329845298; validation accuracy : 0.9097744360902256\n",
      "Epoch 60:\t train loss : 0.5600515709808451; train accuracy : 0.9913039871702705; \n",
      " validation loss : 0.5975677960342892; validation accuracy : 0.9548872180451128\n",
      "Epoch 61:\t train loss : 0.5673435840888923; train accuracy : 0.9837001603716198; \n",
      " validation loss : 0.616849647363643; validation accuracy : 0.9398496240601504\n",
      "Epoch 62:\t train loss : 0.5609748828525729; train accuracy : 0.9904191782337002; \n",
      " validation loss : 0.6156243911844826; validation accuracy : 0.9398496240601504\n",
      "Epoch 63:\t train loss : 0.5590658442729531; train accuracy : 0.9923685229220816; \n",
      " validation loss : 0.6092957277673463; validation accuracy : 0.9398496240601504\n",
      "Epoch 64:\t train loss : 0.5602604152553754; train accuracy : 0.9911104352153957; \n",
      " validation loss : 0.6182706862300756; validation accuracy : 0.9323308270676691\n",
      "Epoch 65:\t train loss : 0.5632099762698564; train accuracy : 0.9877509262843555; \n",
      " validation loss : 0.6053535769681031; validation accuracy : 0.9473684210526315\n",
      "Epoch 66:\t train loss : 0.5971493985960037; train accuracy : 0.9536581319471327; \n",
      " validation loss : 0.6200239680687124; validation accuracy : 0.9323308270676691\n",
      "Epoch 67:\t train loss : 0.5867973365364372; train accuracy : 0.9636951833213515; \n",
      " validation loss : 0.6287071173455859; validation accuracy : 0.924812030075188\n",
      "Early stopping at epoch 67\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5828281022329049; Train accuracy : 0.9688796106840679; \n",
      " Validation loss : 0.5828350456462917; Validation accuracy : 0.9699248120300752\n",
      "------------------------------ Let's train model 55 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.9149798010530603; train accuracy : 0.6039788751866394; \n",
      " validation loss : 0.9101042514305996; validation accuracy : 0.5939849624060151\n",
      "Epoch 2:\t train loss : 0.8094208458131794; train accuracy : 0.732580324061273; \n",
      " validation loss : 0.8024656780925304; validation accuracy : 0.7518796992481203\n",
      "Epoch 3:\t train loss : 0.7493874876958251; train accuracy : 0.7962589172150639; \n",
      " validation loss : 0.7490845941152025; validation accuracy : 0.7894736842105263\n",
      "Epoch 4:\t train loss : 0.6902759305955348; train accuracy : 0.858195542774982; \n",
      " validation loss : 0.7378182939619221; validation accuracy : 0.8120300751879699\n",
      "Epoch 5:\t train loss : 0.666380830114225; train accuracy : 0.8828457667422441; \n",
      " validation loss : 0.6802461708677091; validation accuracy : 0.8646616541353384\n",
      "Epoch 6:\t train loss : 0.6446738567717342; train accuracy : 0.9054913454625891; \n",
      " validation loss : 0.6492255908931418; validation accuracy : 0.8947368421052632\n",
      "Epoch 7:\t train loss : 0.6274593124534552; train accuracy : 0.9239479068738594; \n",
      " validation loss : 0.6233183495377846; validation accuracy : 0.9323308270676691\n",
      "Epoch 8:\t train loss : 0.6137634257756716; train accuracy : 0.9384090029309295; \n",
      " validation loss : 0.6488827895520992; validation accuracy : 0.9097744360902256\n",
      "Epoch 9:\t train loss : 0.6052895183600304; train accuracy : 0.9457916274954377; \n",
      " validation loss : 0.6644705855229818; validation accuracy : 0.8872180451127819\n",
      "Epoch 10:\t train loss : 0.6037974865188067; train accuracy : 0.9477824476027208; \n",
      " validation loss : 0.6789096725462337; validation accuracy : 0.8646616541353384\n",
      "Epoch 11:\t train loss : 0.6039747399477067; train accuracy : 0.9474644693911408; \n",
      " validation loss : 0.6496294499816898; validation accuracy : 0.8947368421052632\n",
      "Epoch 12:\t train loss : 0.5982364232122875; train accuracy : 0.9526212464745893; \n",
      " validation loss : 0.6284091522461015; validation accuracy : 0.9172932330827067\n",
      "Epoch 13:\t train loss : 0.6028427391582535; train accuracy : 0.9485566554222198; \n",
      " validation loss : 0.629829740506099; validation accuracy : 0.924812030075188\n",
      "Epoch 14:\t train loss : 0.5932090026331054; train accuracy : 0.9579439252336448; \n",
      " validation loss : 0.6607117196825707; validation accuracy : 0.8872180451127819\n",
      "Epoch 15:\t train loss : 0.5824166703981986; train accuracy : 0.9687828347066305; \n",
      " validation loss : 0.6261785451950999; validation accuracy : 0.924812030075188\n",
      "Epoch 16:\t train loss : 0.5754271673767446; train accuracy : 0.9761378089918709; \n",
      " validation loss : 0.6542183327298542; validation accuracy : 0.8947368421052632\n",
      "Epoch 17:\t train loss : 0.576930035848055; train accuracy : 0.9745340927943372; \n",
      " validation loss : 0.6606520797026494; validation accuracy : 0.8872180451127819\n",
      "Epoch 18:\t train loss : 0.5817623589365987; train accuracy : 0.9692252391749157; \n",
      " validation loss : 0.6444086337335204; validation accuracy : 0.9022556390977443\n",
      "Epoch 19:\t train loss : 0.5771948622459911; train accuracy : 0.974257590001659; \n",
      " validation loss : 0.670279336909767; validation accuracy : 0.8721804511278195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:\t train loss : 0.5788899204431537; train accuracy : 0.9720870430791351; \n",
      " validation loss : 0.633312172322941; validation accuracy : 0.9172932330827067\n",
      "Epoch 21:\t train loss : 0.5695466087162753; train accuracy : 0.9824282475253; \n",
      " validation loss : 0.6464488534541826; validation accuracy : 0.8947368421052632\n",
      "Epoch 22:\t train loss : 0.5670412132762568; train accuracy : 0.9846126195874578; \n",
      " validation loss : 0.6419979329274871; validation accuracy : 0.9172932330827067\n",
      "Epoch 23:\t train loss : 0.563862599084706; train accuracy : 0.9877371011447216; \n",
      " validation loss : 0.6288625771693378; validation accuracy : 0.924812030075188\n",
      "Epoch 24:\t train loss : 0.5789512649087035; train accuracy : 0.9720040922413317; \n",
      " validation loss : 0.6317781567098876; validation accuracy : 0.924812030075188\n",
      "Epoch 25:\t train loss : 0.5742019817589079; train accuracy : 0.9773544212796549; \n",
      " validation loss : 0.6586162612890868; validation accuracy : 0.8947368421052632\n",
      "Epoch 26:\t train loss : 0.567576014233957; train accuracy : 0.9836172095338163; \n",
      " validation loss : 0.6673010416892002; validation accuracy : 0.8796992481203008\n",
      "Epoch 27:\t train loss : 0.5645249156155184; train accuracy : 0.9871426201404634; \n",
      " validation loss : 0.6504790556785476; validation accuracy : 0.9022556390977443\n",
      "Epoch 28:\t train loss : 0.5700471309861914; train accuracy : 0.9812116352375159; \n",
      " validation loss : 0.6409998523810129; validation accuracy : 0.9097744360902256\n",
      "Epoch 29:\t train loss : 0.561720226167735; train accuracy : 0.9899491234861472; \n",
      " validation loss : 0.6022877273463669; validation accuracy : 0.9548872180451128\n",
      "Epoch 30:\t train loss : 0.5651124882032538; train accuracy : 0.9861886855057236; \n",
      " validation loss : 0.6181081188829033; validation accuracy : 0.9323308270676691\n",
      "Epoch 31:\t train loss : 0.5805347637735413; train accuracy : 0.9705386274401372; \n",
      " validation loss : 0.6248031587177331; validation accuracy : 0.924812030075188\n",
      "Epoch 32:\t train loss : 0.5633972074414321; train accuracy : 0.9879030028203285; \n",
      " validation loss : 0.6569058563165343; validation accuracy : 0.8796992481203008\n",
      "Epoch 33:\t train loss : 0.5700419468008295; train accuracy : 0.9812531106564176; \n",
      " validation loss : 0.6195587637315819; validation accuracy : 0.9172932330827067\n",
      "Epoch 34:\t train loss : 0.5639977353764373; train accuracy : 0.9871840955593651; \n",
      " validation loss : 0.6369479963133449; validation accuracy : 0.9097744360902256\n",
      "Epoch 35:\t train loss : 0.559459301931883; train accuracy : 0.9917740419178234; \n",
      " validation loss : 0.6287238417141405; validation accuracy : 0.9172932330827067\n",
      "Epoch 36:\t train loss : 0.5644343472760138; train accuracy : 0.9867969916496157; \n",
      " validation loss : 0.6409007327335559; validation accuracy : 0.9097744360902256\n",
      "Epoch 37:\t train loss : 0.561933536022561; train accuracy : 0.989686445833103; \n",
      " validation loss : 0.6139762693753593; validation accuracy : 0.9398496240601504\n",
      "Epoch 38:\t train loss : 0.5737729301786627; train accuracy : 0.9771193939058784; \n",
      " validation loss : 0.62962486697776; validation accuracy : 0.924812030075188\n",
      "Epoch 39:\t train loss : 0.5734106806021718; train accuracy : 0.9776170989326992; \n",
      " validation loss : 0.6537001262356498; validation accuracy : 0.8947368421052632\n",
      "Epoch 40:\t train loss : 0.5697989426378924; train accuracy : 0.9810319084222751; \n",
      " validation loss : 0.6077560357297551; validation accuracy : 0.9473684210526315\n",
      "Epoch 41:\t train loss : 0.5609796352967353; train accuracy : 0.9905850799093071; \n",
      " validation loss : 0.6583339116848227; validation accuracy : 0.8947368421052632\n",
      "Epoch 42:\t train loss : 0.5606389714308035; train accuracy : 0.9907648067245479; \n",
      " validation loss : 0.6414340155654392; validation accuracy : 0.9097744360902256\n",
      "Epoch 43:\t train loss : 0.5610168195791907; train accuracy : 0.9904744787922358; \n",
      " validation loss : 0.6115233184567073; validation accuracy : 0.9398496240601504\n",
      "Epoch 44:\t train loss : 0.5629372527977063; train accuracy : 0.9885804346623901; \n",
      " validation loss : 0.621638173263443; validation accuracy : 0.9323308270676691\n",
      "Epoch 45:\t train loss : 0.560315853041764; train accuracy : 0.9910274843775922; \n",
      " validation loss : 0.6382948399148788; validation accuracy : 0.9097744360902256\n",
      "Epoch 46:\t train loss : 0.5709693328021505; train accuracy : 0.98027152574241; \n",
      " validation loss : 0.6553379254095172; validation accuracy : 0.8947368421052632\n",
      "Epoch 47:\t train loss : 0.5600876204380636; train accuracy : 0.9912072111928331; \n",
      " validation loss : 0.6072859772602172; validation accuracy : 0.9323308270676691\n",
      "Epoch 48:\t train loss : 0.557827448119598; train accuracy : 0.9933915832549909; \n",
      " validation loss : 0.6393007688838509; validation accuracy : 0.9097744360902256\n",
      "Epoch 49:\t train loss : 0.5583698170143152; train accuracy : 0.9930736050434109; \n",
      " validation loss : 0.6185882050535365; validation accuracy : 0.9323308270676691\n",
      "Epoch 50:\t train loss : 0.557877028841812; train accuracy : 0.9936957363269369; \n",
      " validation loss : 0.6234366638557796; validation accuracy : 0.9323308270676691\n",
      "Epoch 51:\t train loss : 0.557228933021836; train accuracy : 0.9940275396781507; \n",
      " validation loss : 0.6004515345801771; validation accuracy : 0.9398496240601504\n",
      "Epoch 52:\t train loss : 0.5606784814686342; train accuracy : 0.9907924570038157; \n",
      " validation loss : 0.625753370138762; validation accuracy : 0.924812030075188\n",
      "Epoch 53:\t train loss : 0.5617633807873696; train accuracy : 0.9896311452745673; \n",
      " validation loss : 0.6189200010516144; validation accuracy : 0.9323308270676691\n",
      "Epoch 54:\t train loss : 0.5586324419618407; train accuracy : 0.9928247525300006; \n",
      " validation loss : 0.6363638934204315; validation accuracy : 0.9172932330827067\n",
      "Epoch 55:\t train loss : 0.5595271727377771; train accuracy : 0.991981419012332; \n",
      " validation loss : 0.6425611089353366; validation accuracy : 0.9097744360902256\n",
      "Epoch 56:\t train loss : 0.5551830406817241; train accuracy : 0.9962533871592103; \n",
      " validation loss : 0.630665657444576; validation accuracy : 0.9172932330827067\n",
      "Epoch 57:\t train loss : 0.555525675404207; train accuracy : 0.9960045346457999; \n",
      " validation loss : 0.6198994049644464; validation accuracy : 0.9323308270676691\n",
      "Epoch 58:\t train loss : 0.5573455076163728; train accuracy : 0.9940551899574186; \n",
      " validation loss : 0.6238881759903432; validation accuracy : 0.924812030075188\n",
      "Epoch 59:\t train loss : 0.5553976417251638; train accuracy : 0.9960045346457999; \n",
      " validation loss : 0.619617898921151; validation accuracy : 0.9323308270676691\n",
      "Epoch 60:\t train loss : 0.5567814217349681; train accuracy : 0.9946358458220428; \n",
      " validation loss : 0.6725274188461873; validation accuracy : 0.8721804511278195\n",
      "Epoch 61:\t train loss : 0.5547425929073398; train accuracy : 0.9968202178842006; \n",
      " validation loss : 0.6561017858757021; validation accuracy : 0.8796992481203008\n",
      "Epoch 62:\t train loss : 0.5557077007989252; train accuracy : 0.9956727312945861; \n",
      " validation loss : 0.6327835796241367; validation accuracy : 0.9097744360902256\n",
      "Epoch 63:\t train loss : 0.5556983343910866; train accuracy : 0.995824807830559; \n",
      " validation loss : 0.6700588139834466; validation accuracy : 0.8646616541353384\n",
      "Epoch 64:\t train loss : 0.5630369368758544; train accuracy : 0.9883454072886136; \n",
      " validation loss : 0.6688518201049148; validation accuracy : 0.8721804511278195\n",
      "Epoch 65:\t train loss : 0.5680421263584955; train accuracy : 0.9829674279710225; \n",
      " validation loss : 0.6693504680378238; validation accuracy : 0.8796992481203008\n",
      "Epoch 66:\t train loss : 0.5712066802023292; train accuracy : 0.9800917989271691; \n",
      " validation loss : 0.6926843867597698; validation accuracy : 0.8571428571428571\n",
      "Epoch 67:\t train loss : 0.5866798624097008; train accuracy : 0.9640408118121992; \n",
      " validation loss : 0.6863007487053823; validation accuracy : 0.8646616541353384\n",
      "Epoch 68:\t train loss : 0.5666603649067564; train accuracy : 0.9845849693081901; \n",
      " validation loss : 0.6629138677621852; validation accuracy : 0.8872180451127819\n",
      "Epoch 69:\t train loss : 0.5596196833415893; train accuracy : 0.9917878670574573; \n",
      " validation loss : 0.6710621233165047; validation accuracy : 0.8796992481203008\n",
      "Epoch 70:\t train loss : 0.5696924632776714; train accuracy : 0.9814881380301941; \n",
      " validation loss : 0.644921341253324; validation accuracy : 0.9097744360902256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71:\t train loss : 0.5626981614859362; train accuracy : 0.9887186860587291; \n",
      " validation loss : 0.6562594315957493; validation accuracy : 0.8947368421052632\n",
      "Epoch 72:\t train loss : 0.5588970041195429; train accuracy : 0.9922993972239119; \n",
      " validation loss : 0.6527490941693551; validation accuracy : 0.8872180451127819\n",
      "Epoch 73:\t train loss : 0.556347661285787; train accuracy : 0.9948846983354531; \n",
      " validation loss : 0.6341770715542956; validation accuracy : 0.9172932330827067\n",
      "Epoch 74:\t train loss : 0.5644883340363278; train accuracy : 0.9865619642758392; \n",
      " validation loss : 0.6202636197031861; validation accuracy : 0.9323308270676691\n",
      "Epoch 75:\t train loss : 0.5625468643496314; train accuracy : 0.9886910357794614; \n",
      " validation loss : 0.6320917985856938; validation accuracy : 0.9097744360902256\n",
      "Epoch 76:\t train loss : 0.557069087005518; train accuracy : 0.9944975944257037; \n",
      " validation loss : 0.6440295947468404; validation accuracy : 0.9097744360902256\n",
      "Epoch 77:\t train loss : 0.6296158750093731; train accuracy : 0.9203257202897749; \n",
      " validation loss : 0.7311382847875965; validation accuracy : 0.8270676691729323\n",
      "Epoch 78:\t train loss : 0.5851392205284003; train accuracy : 0.9655754023115634; \n",
      " validation loss : 0.6748160916170829; validation accuracy : 0.8721804511278195\n",
      "Epoch 79:\t train loss : 0.5694200148082545; train accuracy : 0.9816125642868992; \n",
      " validation loss : 0.6659184254534608; validation accuracy : 0.8872180451127819\n",
      "Epoch 80:\t train loss : 0.5583082919210992; train accuracy : 0.9928800530885362; \n",
      " validation loss : 0.62563861608282; validation accuracy : 0.924812030075188\n",
      "Epoch 81:\t train loss : 0.5601769669915773; train accuracy : 0.9912210363324669; \n",
      " validation loss : 0.6029632847548576; validation accuracy : 0.9473684210526315\n",
      "Epoch 82:\t train loss : 0.5567929459217879; train accuracy : 0.9945667201238733; \n",
      " validation loss : 0.6394148018609952; validation accuracy : 0.9097744360902256\n",
      "Epoch 83:\t train loss : 0.5553049040737419; train accuracy : 0.9962119117403085; \n",
      " validation loss : 0.6157854105673554; validation accuracy : 0.9323308270676691\n",
      "Epoch 84:\t train loss : 0.5539924009618592; train accuracy : 0.9973179229110214; \n",
      " validation loss : 0.6224234184135785; validation accuracy : 0.9323308270676691\n",
      "Epoch 85:\t train loss : 0.556788696001833; train accuracy : 0.9946496709616767; \n",
      " validation loss : 0.6253883991372278; validation accuracy : 0.924812030075188\n",
      "Epoch 86:\t train loss : 0.5634004288296277; train accuracy : 0.9878753525410606; \n",
      " validation loss : 0.622221392666592; validation accuracy : 0.924812030075188\n",
      "Epoch 87:\t train loss : 0.5572264318739752; train accuracy : 0.994138140795222; \n",
      " validation loss : 0.613635549279812; validation accuracy : 0.9323308270676691\n",
      "Epoch 88:\t train loss : 0.5606629970713524; train accuracy : 0.9904744787922358; \n",
      " validation loss : 0.6158308181231494; validation accuracy : 0.9323308270676691\n",
      "Epoch 89:\t train loss : 0.5562984844707266; train accuracy : 0.9951197257092297; \n",
      " validation loss : 0.6179736099575078; validation accuracy : 0.924812030075188\n",
      "Epoch 90:\t train loss : 0.5551975376671537; train accuracy : 0.9961704363214068; \n",
      " validation loss : 0.6429426759270395; validation accuracy : 0.9097744360902256\n",
      "Epoch 91:\t train loss : 0.5580718690763139; train accuracy : 0.9934192335342586; \n",
      " validation loss : 0.6367843122163699; validation accuracy : 0.9097744360902256\n",
      "Epoch 92:\t train loss : 0.5558456342496862; train accuracy : 0.9954100536415418; \n",
      " validation loss : 0.6338992612285196; validation accuracy : 0.9172932330827067\n",
      "Epoch 93:\t train loss : 0.5550535478679949; train accuracy : 0.996446939114085; \n",
      " validation loss : 0.6254496743150388; validation accuracy : 0.924812030075188\n",
      "Epoch 94:\t train loss : 0.5540322793009099; train accuracy : 0.9973455731902892; \n",
      " validation loss : 0.6249614952495953; validation accuracy : 0.924812030075188\n",
      "Epoch 95:\t train loss : 0.5548246964410702; train accuracy : 0.9966266659293259; \n",
      " validation loss : 0.6204126582264801; validation accuracy : 0.924812030075188\n",
      "Epoch 96:\t train loss : 0.5541320765302541; train accuracy : 0.9973870486091909; \n",
      " validation loss : 0.6374288070894955; validation accuracy : 0.9172932330827067\n",
      "Epoch 97:\t train loss : 0.5552892268002879; train accuracy : 0.9961566111817729; \n",
      " validation loss : 0.6304615646593271; validation accuracy : 0.924812030075188\n",
      "Epoch 98:\t train loss : 0.5545084068271902; train accuracy : 0.9969031687220041; \n",
      " validation loss : 0.6527106722813559; validation accuracy : 0.8947368421052632\n",
      "Epoch 99:\t train loss : 0.5536902526565012; train accuracy : 0.9977050268207709; \n",
      " validation loss : 0.6307066045904952; validation accuracy : 0.9172932330827067\n",
      "Epoch 100:\t train loss : 0.5539692764832208; train accuracy : 0.9974285240280927; \n",
      " validation loss : 0.6249710170612189; validation accuracy : 0.924812030075188\n",
      "Epoch 101:\t train loss : 0.5556698766636669; train accuracy : 0.9957556821323895; \n",
      " validation loss : 0.6236466764313858; validation accuracy : 0.924812030075188\n",
      "Early stopping at epoch 101\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.557228933021836; Train accuracy : 0.9940275396781507; \n",
      " Validation loss : 0.6004515345801771; Validation accuracy : 0.9398496240601504\n",
      "------------------------------ Let's train model 56 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.897137712522879; train accuracy : 0.6339932533318586; \n",
      " validation loss : 0.8292042581989805; validation accuracy : 0.7368421052631579\n",
      "Epoch 2:\t train loss : 0.7812429809346941; train accuracy : 0.761709893269922; \n",
      " validation loss : 0.7792994262094737; validation accuracy : 0.7593984962406015\n",
      "Epoch 3:\t train loss : 0.745006191406493; train accuracy : 0.8011530166454681; \n",
      " validation loss : 0.7451511881130999; validation accuracy : 0.7969924812030075\n",
      "Epoch 4:\t train loss : 0.7000341559271452; train accuracy : 0.8488912238013604; \n",
      " validation loss : 0.6945990686631784; validation accuracy : 0.849624060150376\n",
      "Epoch 5:\t train loss : 0.6888981888253268; train accuracy : 0.85974395841398; \n",
      " validation loss : 0.7052172429459883; validation accuracy : 0.8421052631578947\n",
      "Epoch 6:\t train loss : 0.6683982747540027; train accuracy : 0.8807443455178897; \n",
      " validation loss : 0.7248852184949343; validation accuracy : 0.8120300751879699\n",
      "Epoch 7:\t train loss : 0.6382543767238428; train accuracy : 0.912597467234419; \n",
      " validation loss : 0.7288311087209436; validation accuracy : 0.8270676691729323\n",
      "Epoch 8:\t train loss : 0.6336805978629463; train accuracy : 0.9162749543770392; \n",
      " validation loss : 0.6743904845415831; validation accuracy : 0.8721804511278195\n",
      "Epoch 9:\t train loss : 0.6214332296710524; train accuracy : 0.9295056130066913; \n",
      " validation loss : 0.7084142944811032; validation accuracy : 0.8421052631578947\n",
      "Epoch 10:\t train loss : 0.6104261402214765; train accuracy : 0.9408145772272299; \n",
      " validation loss : 0.6807515070947698; validation accuracy : 0.8571428571428571\n",
      "Epoch 11:\t train loss : 0.5991512920671439; train accuracy : 0.9528009732898303; \n",
      " validation loss : 0.7071364619109086; validation accuracy : 0.8421052631578947\n",
      "Epoch 12:\t train loss : 0.6071813186210191; train accuracy : 0.9438146325277885; \n",
      " validation loss : 0.6771485906005009; validation accuracy : 0.8721804511278195\n",
      "Epoch 13:\t train loss : 0.5900550239416879; train accuracy : 0.961455510700658; \n",
      " validation loss : 0.686112617685627; validation accuracy : 0.8721804511278195\n",
      "Epoch 14:\t train loss : 0.586788218936747; train accuracy : 0.9649809213073052; \n",
      " validation loss : 0.6627608942440009; validation accuracy : 0.8796992481203008\n",
      "Epoch 15:\t train loss : 0.5945491687418367; train accuracy : 0.9566720123873251; \n",
      " validation loss : 0.678145291356062; validation accuracy : 0.8721804511278195\n",
      "Epoch 16:\t train loss : 0.5908441718962322; train accuracy : 0.9600315213183653; \n",
      " validation loss : 0.7158435886846444; validation accuracy : 0.8345864661654135\n",
      "Epoch 17:\t train loss : 0.5795621883937393; train accuracy : 0.9716999391693856; \n",
      " validation loss : 0.6717273292446178; validation accuracy : 0.8721804511278195\n",
      "Epoch 18:\t train loss : 0.5704806442795775; train accuracy : 0.9813913620527568; \n",
      " validation loss : 0.6688783987620541; validation accuracy : 0.8796992481203008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:\t train loss : 0.569141211084139; train accuracy : 0.9825250235027374; \n",
      " validation loss : 0.6647574124385263; validation accuracy : 0.8872180451127819\n",
      "Epoch 20:\t train loss : 0.5778060866312129; train accuracy : 0.9733866062047226; \n",
      " validation loss : 0.6696300333767194; validation accuracy : 0.8872180451127819\n",
      "Epoch 21:\t train loss : 0.5713857498748052; train accuracy : 0.9800088480893657; \n",
      " validation loss : 0.6677689436684908; validation accuracy : 0.8872180451127819\n",
      "Epoch 22:\t train loss : 0.5711917690785615; train accuracy : 0.9797876458552232; \n",
      " validation loss : 0.6827966205459234; validation accuracy : 0.8646616541353384\n",
      "Epoch 23:\t train loss : 0.5665005179800519; train accuracy : 0.984750870983797; \n",
      " validation loss : 0.6826607191008559; validation accuracy : 0.8721804511278195\n",
      "Epoch 24:\t train loss : 0.5628555917560176; train accuracy : 0.9886772106398275; \n",
      " validation loss : 0.6606649759952999; validation accuracy : 0.8947368421052632\n",
      "Epoch 25:\t train loss : 0.5933592905422913; train accuracy : 0.9571005917159763; \n",
      " validation loss : 0.7016415237368077; validation accuracy : 0.849624060150376\n",
      "Epoch 26:\t train loss : 0.5666409862601786; train accuracy : 0.9845573190289222; \n",
      " validation loss : 0.6661465876658401; validation accuracy : 0.8872180451127819\n",
      "Epoch 27:\t train loss : 0.566043437706941; train accuracy : 0.9854559531051263; \n",
      " validation loss : 0.6837500140425099; validation accuracy : 0.8646616541353384\n",
      "Epoch 28:\t train loss : 0.5820876219348511; train accuracy : 0.9686031078913897; \n",
      " validation loss : 0.6960778171786793; validation accuracy : 0.8421052631578947\n",
      "Epoch 29:\t train loss : 0.56879659312769; train accuracy : 0.9826632748990765; \n",
      " validation loss : 0.6743849792411786; validation accuracy : 0.8721804511278195\n",
      "Epoch 30:\t train loss : 0.5671910854549611; train accuracy : 0.9840734391417353; \n",
      " validation loss : 0.7298152806074831; validation accuracy : 0.8195488721804511\n",
      "Epoch 31:\t train loss : 0.5755280186248513; train accuracy : 0.9754189017309075; \n",
      " validation loss : 0.6764773249174502; validation accuracy : 0.8721804511278195\n",
      "Epoch 32:\t train loss : 0.5618769032829546; train accuracy : 0.9894237681800586; \n",
      " validation loss : 0.681580577999344; validation accuracy : 0.8721804511278195\n",
      "Epoch 33:\t train loss : 0.5597352758218542; train accuracy : 0.9916219653818503; \n",
      " validation loss : 0.6663955511453994; validation accuracy : 0.8872180451127819\n",
      "Epoch 34:\t train loss : 0.5684081609215355; train accuracy : 0.9830089033899242; \n",
      " validation loss : 0.6822411197830267; validation accuracy : 0.8646616541353384\n",
      "Epoch 35:\t train loss : 0.5643068414214172; train accuracy : 0.9870320190233921; \n",
      " validation loss : 0.6916231352023509; validation accuracy : 0.8571428571428571\n",
      "Epoch 36:\t train loss : 0.5615881074888391; train accuracy : 0.9899629486257812; \n",
      " validation loss : 0.6671064663934742; validation accuracy : 0.8872180451127819\n",
      "Epoch 37:\t train loss : 0.5602475542324016; train accuracy : 0.9913316374495382; \n",
      " validation loss : 0.6564163668007124; validation accuracy : 0.8947368421052632\n",
      "Epoch 38:\t train loss : 0.5653004892991796; train accuracy : 0.9861748603660897; \n",
      " validation loss : 0.7156287970911258; validation accuracy : 0.8421052631578947\n",
      "Epoch 39:\t train loss : 0.5856972593773709; train accuracy : 0.9649670961676713; \n",
      " validation loss : 0.6886179970541999; validation accuracy : 0.8646616541353384\n",
      "Epoch 40:\t train loss : 0.5597089139987528; train accuracy : 0.991677265940386; \n",
      " validation loss : 0.6535841556289248; validation accuracy : 0.9022556390977443\n",
      "Epoch 41:\t train loss : 0.5622194055448474; train accuracy : 0.9890781396892109; \n",
      " validation loss : 0.677300056031879; validation accuracy : 0.8721804511278195\n",
      "Epoch 42:\t train loss : 0.5592998493828555; train accuracy : 0.9917602167781895; \n",
      " validation loss : 0.6523887408931855; validation accuracy : 0.9022556390977443\n",
      "Epoch 43:\t train loss : 0.5597065179219105; train accuracy : 0.9916219653818503; \n",
      " validation loss : 0.6714544212425789; validation accuracy : 0.8796992481203008\n",
      "Epoch 44:\t train loss : 0.5608770921939455; train accuracy : 0.9904053530940663; \n",
      " validation loss : 0.6860012629131279; validation accuracy : 0.8646616541353384\n",
      "Epoch 45:\t train loss : 0.5591657339538462; train accuracy : 0.9921749709672067; \n",
      " validation loss : 0.673895652454361; validation accuracy : 0.8796992481203008\n",
      "Epoch 46:\t train loss : 0.5561645675302832; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.6630422312898376; validation accuracy : 0.8872180451127819\n",
      "Epoch 47:\t train loss : 0.5559071964339639; train accuracy : 0.9954791793397113; \n",
      " validation loss : 0.6791307487162412; validation accuracy : 0.8721804511278195\n",
      "Epoch 48:\t train loss : 0.556553684407186; train accuracy : 0.9948708731958192; \n",
      " validation loss : 0.6581139685267323; validation accuracy : 0.8947368421052632\n",
      "Epoch 49:\t train loss : 0.5687812863283935; train accuracy : 0.9820826190344523; \n",
      " validation loss : 0.7474206377008894; validation accuracy : 0.7969924812030075\n",
      "Epoch 50:\t train loss : 0.6097186084656891; train accuracy : 0.9405933749930874; \n",
      " validation loss : 0.6954828366105726; validation accuracy : 0.8571428571428571\n",
      "Epoch 51:\t train loss : 0.5755946935368084; train accuracy : 0.9753497760327379; \n",
      " validation loss : 0.6737989866260221; validation accuracy : 0.8796992481203008\n",
      "Epoch 52:\t train loss : 0.5631793183138849; train accuracy : 0.9882486313111762; \n",
      " validation loss : 0.6512424144626097; validation accuracy : 0.8947368421052632\n",
      "Epoch 53:\t train loss : 0.5560686664118457; train accuracy : 0.9954100536415418; \n",
      " validation loss : 0.6759881616156718; validation accuracy : 0.8721804511278195\n",
      "Epoch 54:\t train loss : 0.5554053275453503; train accuracy : 0.9961013106232373; \n",
      " validation loss : 0.6355592360870915; validation accuracy : 0.9172932330827067\n",
      "Epoch 55:\t train loss : 0.5569888881210046; train accuracy : 0.9944699441464359; \n",
      " validation loss : 0.6513725389725155; validation accuracy : 0.8947368421052632\n",
      "Epoch 56:\t train loss : 0.5581128039551915; train accuracy : 0.9931427307415804; \n",
      " validation loss : 0.6649970243168106; validation accuracy : 0.8796992481203008\n",
      "Epoch 57:\t train loss : 0.5583834448240751; train accuracy : 0.9928662279489022; \n",
      " validation loss : 0.6552319279377509; validation accuracy : 0.8947368421052632\n",
      "Epoch 58:\t train loss : 0.5551434554365282; train accuracy : 0.9962257368799424; \n",
      " validation loss : 0.6865996685335085; validation accuracy : 0.8571428571428571\n",
      "Epoch 59:\t train loss : 0.5595984640677545; train accuracy : 0.9918846430348947; \n",
      " validation loss : 0.6810528069466183; validation accuracy : 0.8646616541353384\n",
      "Epoch 60:\t train loss : 0.5674777632891057; train accuracy : 0.9837278106508875; \n",
      " validation loss : 0.6642669999687238; validation accuracy : 0.8872180451127819\n",
      "Epoch 61:\t train loss : 0.557492365137246; train accuracy : 0.9937786871647404; \n",
      " validation loss : 0.6354778909649944; validation accuracy : 0.9172932330827067\n",
      "Epoch 62:\t train loss : 0.5581847536877166; train accuracy : 0.9931427307415804; \n",
      " validation loss : 0.6611704883753476; validation accuracy : 0.8872180451127819\n",
      "Epoch 63:\t train loss : 0.5546359446068055; train accuracy : 0.996764917325665; \n",
      " validation loss : 0.6543224158679977; validation accuracy : 0.8947368421052632\n",
      "Epoch 64:\t train loss : 0.5610895683747242; train accuracy : 0.9902118011391915; \n",
      " validation loss : 0.6895945926456508; validation accuracy : 0.8571428571428571\n",
      "Epoch 65:\t train loss : 0.560691346907766; train accuracy : 0.9905712547696731; \n",
      " validation loss : 0.6644632207981043; validation accuracy : 0.8872180451127819\n",
      "Epoch 66:\t train loss : 0.5591768906736425; train accuracy : 0.9920920201294033; \n",
      " validation loss : 0.699999656242433; validation accuracy : 0.8421052631578947\n",
      "Epoch 67:\t train loss : 0.5587434520918496; train accuracy : 0.9926865011336614; \n",
      " validation loss : 0.6413653603777938; validation accuracy : 0.9097744360902256\n",
      "Epoch 68:\t train loss : 0.5552568269221445; train accuracy : 0.9961842614610408; \n",
      " validation loss : 0.6582755155593029; validation accuracy : 0.8947368421052632\n",
      "Epoch 69:\t train loss : 0.5555343486748354; train accuracy : 0.9957695072720234; \n",
      " validation loss : 0.6644489597165656; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70:\t train loss : 0.5568239922554028; train accuracy : 0.994608195542775; \n",
      " validation loss : 0.6942233553990639; validation accuracy : 0.8571428571428571\n",
      "Epoch 71:\t train loss : 0.5611802800177366; train accuracy : 0.9900182491843168; \n",
      " validation loss : 0.6736068868075612; validation accuracy : 0.8721804511278195\n",
      "Epoch 72:\t train loss : 0.5580889036242613; train accuracy : 0.9931565558812144; \n",
      " validation loss : 0.641831603575281; validation accuracy : 0.9097744360902256\n",
      "Epoch 73:\t train loss : 0.5586222380107388; train accuracy : 0.9928109273903666; \n",
      " validation loss : 0.6561957168495828; validation accuracy : 0.8947368421052632\n",
      "Epoch 74:\t train loss : 0.5570263426619635; train accuracy : 0.9942763921915612; \n",
      " validation loss : 0.6598209008649764; validation accuracy : 0.8872180451127819\n",
      "Epoch 75:\t train loss : 0.5593524531700851; train accuracy : 0.9918984681745285; \n",
      " validation loss : 0.65753119945616; validation accuracy : 0.8947368421052632\n",
      "Epoch 76:\t train loss : 0.5549902085053784; train accuracy : 0.9964192888348172; \n",
      " validation loss : 0.6317106820387001; validation accuracy : 0.924812030075188\n",
      "Epoch 77:\t train loss : 0.5550705593510196; train accuracy : 0.9962948625781121; \n",
      " validation loss : 0.6717795189436222; validation accuracy : 0.8796992481203008\n",
      "Epoch 78:\t train loss : 0.5575315385415601; train accuracy : 0.9937648620251064; \n",
      " validation loss : 0.6544904720350854; validation accuracy : 0.9022556390977443\n",
      "Epoch 79:\t train loss : 0.5799464370219419; train accuracy : 0.9711607587236631; \n",
      " validation loss : 0.6544651722840058; validation accuracy : 0.8947368421052632\n",
      "Epoch 80:\t train loss : 0.5649741890631504; train accuracy : 0.9860089586904828; \n",
      " validation loss : 0.6641139055870328; validation accuracy : 0.8872180451127819\n",
      "Epoch 81:\t train loss : 0.6021788259996809; train accuracy : 0.9479898246972295; \n",
      " validation loss : 0.6848968584589158; validation accuracy : 0.8646616541353384\n",
      "Epoch 82:\t train loss : 0.5677687629191948; train accuracy : 0.983354531880772; \n",
      " validation loss : 0.6571452419361508; validation accuracy : 0.8947368421052632\n",
      "Epoch 83:\t train loss : 0.5680847562183354; train accuracy : 0.9831471547862634; \n",
      " validation loss : 0.6707861066777489; validation accuracy : 0.8796992481203008\n",
      "Epoch 84:\t train loss : 0.5586928632359446; train accuracy : 0.9925205994580545; \n",
      " validation loss : 0.6332640641816477; validation accuracy : 0.9172932330827067\n",
      "Epoch 85:\t train loss : 0.5561525443474465; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.6785141388192685; validation accuracy : 0.8721804511278195\n",
      "Epoch 86:\t train loss : 0.55519883523373; train accuracy : 0.9961566111817729; \n",
      " validation loss : 0.6614669059548758; validation accuracy : 0.8872180451127819\n",
      "Epoch 87:\t train loss : 0.5568948893762229; train accuracy : 0.9944975944257037; \n",
      " validation loss : 0.6564452308372238; validation accuracy : 0.8947368421052632\n",
      "Epoch 88:\t train loss : 0.5614588874645614; train accuracy : 0.9895896698556655; \n",
      " validation loss : 0.6384683748231658; validation accuracy : 0.9097744360902256\n",
      "Epoch 89:\t train loss : 0.5559820171708538; train accuracy : 0.9952579771055687; \n",
      " validation loss : 0.6362277072389423; validation accuracy : 0.9172932330827067\n",
      "Epoch 90:\t train loss : 0.5688768472784932; train accuracy : 0.9821932201515235; \n",
      " validation loss : 0.6287772329168082; validation accuracy : 0.924812030075188\n",
      "Epoch 91:\t train loss : 0.5581781179013318; train accuracy : 0.9933501078360891; \n",
      " validation loss : 0.6516419392065512; validation accuracy : 0.9022556390977443\n",
      "Epoch 92:\t train loss : 0.5556825498689444; train accuracy : 0.9957418569927556; \n",
      " validation loss : 0.6638375371043631; validation accuracy : 0.8872180451127819\n",
      "Epoch 93:\t train loss : 0.5541905815014023; train accuracy : 0.9971796715146823; \n",
      " validation loss : 0.6501769942318114; validation accuracy : 0.9022556390977443\n",
      "Epoch 94:\t train loss : 0.5533080674056048; train accuracy : 0.9981612564286899; \n",
      " validation loss : 0.6640379114337241; validation accuracy : 0.8872180451127819\n",
      "Epoch 95:\t train loss : 0.5536364707715434; train accuracy : 0.9977603273793065; \n",
      " validation loss : 0.6270164763164544; validation accuracy : 0.924812030075188\n",
      "Epoch 96:\t train loss : 0.5535487540432142; train accuracy : 0.9979538793341812; \n",
      " validation loss : 0.645517485196771; validation accuracy : 0.9097744360902256\n",
      "Epoch 97:\t train loss : 0.5542881244146858; train accuracy : 0.9970552452579771; \n",
      " validation loss : 0.663156172448455; validation accuracy : 0.8796992481203008\n",
      "Epoch 98:\t train loss : 0.5556272021866063; train accuracy : 0.9957418569927556; \n",
      " validation loss : 0.6548994561670163; validation accuracy : 0.8947368421052632\n",
      "Epoch 99:\t train loss : 0.5591250643745033; train accuracy : 0.9920920201294033; \n",
      " validation loss : 0.6699527530141383; validation accuracy : 0.8796992481203008\n",
      "Epoch 100:\t train loss : 0.5547962348632056; train accuracy : 0.9966266659293259; \n",
      " validation loss : 0.6484030410381194; validation accuracy : 0.9022556390977443\n",
      "Epoch 101:\t train loss : 0.5560544946908722; train accuracy : 0.9952718022452026; \n",
      " validation loss : 0.6335307657578958; validation accuracy : 0.9097744360902256\n",
      "Epoch 102:\t train loss : 0.5567153043431768; train accuracy : 0.994594370403141; \n",
      " validation loss : 0.6500954595765888; validation accuracy : 0.9022556390977443\n",
      "Epoch 103:\t train loss : 0.5561803446893693; train accuracy : 0.9949952994525245; \n",
      " validation loss : 0.6534097219586729; validation accuracy : 0.9022556390977443\n",
      "Epoch 104:\t train loss : 0.59477812991595; train accuracy : 0.9554830503788089; \n",
      " validation loss : 0.6595829472795071; validation accuracy : 0.8947368421052632\n",
      "Epoch 105:\t train loss : 0.5604749704240958; train accuracy : 0.990903058120887; \n",
      " validation loss : 0.6523178477285556; validation accuracy : 0.9022556390977443\n",
      "Epoch 106:\t train loss : 0.5536943007014083; train accuracy : 0.9977465022396727; \n",
      " validation loss : 0.6356202814202662; validation accuracy : 0.9172932330827067\n",
      "Epoch 107:\t train loss : 0.5554186649563551; train accuracy : 0.9960045346458; \n",
      " validation loss : 0.6660389667009625; validation accuracy : 0.8796992481203008\n",
      "Epoch 108:\t train loss : 0.5531720086517092; train accuracy : 0.9982303821268594; \n",
      " validation loss : 0.6302303797316928; validation accuracy : 0.924812030075188\n",
      "Epoch 109:\t train loss : 0.5544441792315616; train accuracy : 0.9969584692805398; \n",
      " validation loss : 0.6396656988009698; validation accuracy : 0.9097744360902256\n",
      "Epoch 110:\t train loss : 0.5593892359060232; train accuracy : 0.9920090692915998; \n",
      " validation loss : 0.6426044542558508; validation accuracy : 0.9097744360902256\n",
      "Epoch 111:\t train loss : 0.5595731977076294; train accuracy : 0.9918708178952608; \n",
      " validation loss : 0.6163819112539829; validation accuracy : 0.9398496240601504\n",
      "Epoch 112:\t train loss : 0.5570372914774394; train accuracy : 0.9943869933086324; \n",
      " validation loss : 0.6603126136055777; validation accuracy : 0.8872180451127819\n",
      "Epoch 113:\t train loss : 0.5549955471021201; train accuracy : 0.9962810374384781; \n",
      " validation loss : 0.6695634087799323; validation accuracy : 0.8796992481203008\n",
      "Epoch 114:\t train loss : 0.5604491254871656; train accuracy : 0.9910413095172261; \n",
      " validation loss : 0.6777830044428793; validation accuracy : 0.8721804511278195\n",
      "Epoch 115:\t train loss : 0.5659743695794341; train accuracy : 0.9852624011502517; \n",
      " validation loss : 0.6716713582288039; validation accuracy : 0.8796992481203008\n",
      "Epoch 116:\t train loss : 0.6064583439608334; train accuracy : 0.9441464358790024; \n",
      " validation loss : 0.6679228945542881; validation accuracy : 0.8872180451127819\n",
      "Epoch 117:\t train loss : 0.5815686521597265; train accuracy : 0.9689072609633357; \n",
      " validation loss : 0.657354275081387; validation accuracy : 0.8947368421052632\n",
      "Epoch 118:\t train loss : 0.5610471025491767; train accuracy : 0.9901979759995576; \n",
      " validation loss : 0.6741193488611833; validation accuracy : 0.8796992481203008\n",
      "Epoch 119:\t train loss : 0.5543926789980561; train accuracy : 0.9970137698390754; \n",
      " validation loss : 0.6642497199540858; validation accuracy : 0.8872180451127819\n",
      "Epoch 120:\t train loss : 0.5534845828936874; train accuracy : 0.9979538793341812; \n",
      " validation loss : 0.6604715532381039; validation accuracy : 0.8872180451127819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121:\t train loss : 0.553233474446748; train accuracy : 0.9982442072664934; \n",
      " validation loss : 0.6553890245537672; validation accuracy : 0.8947368421052632\n",
      "Epoch 122:\t train loss : 0.5539635649715253; train accuracy : 0.9974008737488248; \n",
      " validation loss : 0.656573234375819; validation accuracy : 0.8947368421052632\n",
      "Epoch 123:\t train loss : 0.5541008804092061; train accuracy : 0.9973179229110214; \n",
      " validation loss : 0.6504100619588803; validation accuracy : 0.9022556390977443\n",
      "Epoch 124:\t train loss : 0.5531111594532305; train accuracy : 0.9982995078250291; \n",
      " validation loss : 0.6492797098641709; validation accuracy : 0.9022556390977443\n",
      "Epoch 125:\t train loss : 0.5683874369757945; train accuracy : 0.9828983022728529; \n",
      " validation loss : 0.6582669771569134; validation accuracy : 0.8947368421052632\n",
      "Epoch 126:\t train loss : 0.5545221704119252; train accuracy : 0.9969584692805398; \n",
      " validation loss : 0.6441155548548132; validation accuracy : 0.9097744360902256\n",
      "Epoch 127:\t train loss : 0.5531372106609073; train accuracy : 0.9983409832439307; \n",
      " validation loss : 0.6485505372590096; validation accuracy : 0.9022556390977443\n",
      "Epoch 128:\t train loss : 0.5531424341918926; train accuracy : 0.9982303821268594; \n",
      " validation loss : 0.6634563820449095; validation accuracy : 0.8872180451127819\n",
      "Epoch 129:\t train loss : 0.5530304907376021; train accuracy : 0.9984101089421004; \n",
      " validation loss : 0.6491587730001768; validation accuracy : 0.9022556390977443\n",
      "Epoch 130:\t train loss : 0.5554455362024461; train accuracy : 0.9959215838079964; \n",
      " validation loss : 0.6718685841582214; validation accuracy : 0.8796992481203008\n",
      "Epoch 131:\t train loss : 0.5611775516867495; train accuracy : 0.990142675441022; \n",
      " validation loss : 0.6491803867791373; validation accuracy : 0.9022556390977443\n",
      "Epoch 132:\t train loss : 0.556043127616822; train accuracy : 0.9952579771055687; \n",
      " validation loss : 0.6482889542629802; validation accuracy : 0.9022556390977443\n",
      "Epoch 133:\t train loss : 0.5553865292806566; train accuracy : 0.9960183597854338; \n",
      " validation loss : 0.6370557242060407; validation accuracy : 0.9097744360902256\n",
      "Epoch 134:\t train loss : 0.5541374290392346; train accuracy : 0.9972073217939501; \n",
      " validation loss : 0.638196443835695; validation accuracy : 0.9097744360902256\n",
      "Epoch 135:\t train loss : 0.5536372818773838; train accuracy : 0.9978432782171099; \n",
      " validation loss : 0.6498810397620729; validation accuracy : 0.9022556390977443\n",
      "Epoch 136:\t train loss : 0.5532472917795375; train accuracy : 0.9981612564286899; \n",
      " validation loss : 0.655023210254804; validation accuracy : 0.8947368421052632\n",
      "Epoch 137:\t train loss : 0.5537540304086281; train accuracy : 0.9976635514018691; \n",
      " validation loss : 0.6503149177721662; validation accuracy : 0.9022556390977443\n",
      "Epoch 138:\t train loss : 0.5549140714566368; train accuracy : 0.9965713653707903; \n",
      " validation loss : 0.6736514125771184; validation accuracy : 0.8721804511278195\n",
      "Epoch 139:\t train loss : 0.5534124738593011; train accuracy : 0.9980091798927169; \n",
      " validation loss : 0.6478914797140053; validation accuracy : 0.9022556390977443\n",
      "Epoch 140:\t train loss : 0.5534900514033991; train accuracy : 0.9978571033567439; \n",
      " validation loss : 0.6426725634982083; validation accuracy : 0.9097744360902256\n",
      "Epoch 141:\t train loss : 0.5596028635907735; train accuracy : 0.9916496156611182; \n",
      " validation loss : 0.6579363542647102; validation accuracy : 0.8947368421052632\n",
      "Epoch 142:\t train loss : 0.5565681132377966; train accuracy : 0.9947464469391141; \n",
      " validation loss : 0.6416844724408698; validation accuracy : 0.9097744360902256\n",
      "Epoch 143:\t train loss : 0.5824425206481191; train accuracy : 0.9683404302383454; \n",
      " validation loss : 0.6718629103998806; validation accuracy : 0.8796992481203008\n",
      "Epoch 144:\t train loss : 0.616722573704497; train accuracy : 0.9333490018249184; \n",
      " validation loss : 0.6855250981130376; validation accuracy : 0.8646616541353384\n",
      "Epoch 145:\t train loss : 0.5900235903965966; train accuracy : 0.9603633246695792; \n",
      " validation loss : 0.6749674832667345; validation accuracy : 0.8796992481203008\n",
      "Epoch 146:\t train loss : 0.5735886258134791; train accuracy : 0.9774373721174584; \n",
      " validation loss : 0.6325326906816319; validation accuracy : 0.9172932330827067\n",
      "Epoch 147:\t train loss : 0.5669027829295352; train accuracy : 0.984114914560637; \n",
      " validation loss : 0.6397429799616206; validation accuracy : 0.9097744360902256\n",
      "Epoch 148:\t train loss : 0.5628812727103365; train accuracy : 0.988428358126417; \n",
      " validation loss : 0.6739430120721985; validation accuracy : 0.8721804511278195\n",
      "Epoch 149:\t train loss : 0.5638730964535248; train accuracy : 0.9874191229331416; \n",
      " validation loss : 0.6418387475469297; validation accuracy : 0.9097744360902256\n",
      "Epoch 150:\t train loss : 0.5572109859929255; train accuracy : 0.9940413648177846; \n",
      " validation loss : 0.6158631021956664; validation accuracy : 0.9323308270676691\n",
      "Epoch 151:\t train loss : 0.5556351535854976; train accuracy : 0.9955759553171487; \n",
      " validation loss : 0.6554756981921647; validation accuracy : 0.8947368421052632\n",
      "Epoch 152:\t train loss : 0.5534236894817341; train accuracy : 0.9980091798927169; \n",
      " validation loss : 0.6601066753961732; validation accuracy : 0.8947368421052632\n",
      "Epoch 153:\t train loss : 0.5528215311862843; train accuracy : 0.9985898357573412; \n",
      " validation loss : 0.668470779412309; validation accuracy : 0.8796992481203008\n",
      "Epoch 154:\t train loss : 0.5521800373040532; train accuracy : 0.9992810927390366; \n",
      " validation loss : 0.6338231543585816; validation accuracy : 0.924812030075188\n",
      "Epoch 155:\t train loss : 0.5524653806922285; train accuracy : 0.9988939888292871; \n",
      " validation loss : 0.6404211207125902; validation accuracy : 0.9097744360902256\n",
      "Epoch 156:\t train loss : 0.5526970327128835; train accuracy : 0.9987004368744125; \n",
      " validation loss : 0.6497723290525412; validation accuracy : 0.8947368421052632\n",
      "Epoch 157:\t train loss : 0.5521188031891261; train accuracy : 0.9993363932975723; \n",
      " validation loss : 0.6566514799122275; validation accuracy : 0.8947368421052632\n",
      "Epoch 158:\t train loss : 0.5524985527400396; train accuracy : 0.9989354642481889; \n",
      " validation loss : 0.6438021481363493; validation accuracy : 0.9097744360902256\n",
      "Epoch 159:\t train loss : 0.5523078568496476; train accuracy : 0.9991566664823315; \n",
      " validation loss : 0.6483857264166515; validation accuracy : 0.9022556390977443\n",
      "Epoch 160:\t train loss : 0.5529863797823298; train accuracy : 0.9984239340817342; \n",
      " validation loss : 0.6568269665983766; validation accuracy : 0.8947368421052632\n",
      "Epoch 161:\t train loss : 0.5540691684160145; train accuracy : 0.9972626223524858; \n",
      " validation loss : 0.6626019086542009; validation accuracy : 0.8872180451127819\n",
      "Epoch 162:\t train loss : 0.5528213212415487; train accuracy : 0.9985068849195377; \n",
      " validation loss : 0.6340664817973509; validation accuracy : 0.9172932330827067\n",
      "Epoch 163:\t train loss : 0.5530434299004353; train accuracy : 0.998451584361002; \n",
      " validation loss : 0.6657007733260186; validation accuracy : 0.8796992481203008\n",
      "Epoch 164:\t train loss : 0.5537612770320398; train accuracy : 0.9976635514018691; \n",
      " validation loss : 0.6528404601633299; validation accuracy : 0.8947368421052632\n",
      "Epoch 165:\t train loss : 0.5547919481638243; train accuracy : 0.9966819664878616; \n",
      " validation loss : 0.6562073299207561; validation accuracy : 0.8947368421052632\n",
      "Epoch 166:\t train loss : 0.5530632079576647; train accuracy : 0.998313332964663; \n",
      " validation loss : 0.664208459739335; validation accuracy : 0.8872180451127819\n",
      "Epoch 167:\t train loss : 0.5532396349775767; train accuracy : 0.9982580324061273; \n",
      " validation loss : 0.6568484742844265; validation accuracy : 0.8947368421052632\n",
      "Epoch 168:\t train loss : 0.5524697054828372; train accuracy : 0.9990184150859923; \n",
      " validation loss : 0.6415722597844583; validation accuracy : 0.9097744360902256\n",
      "Epoch 169:\t train loss : 0.5522508772873479; train accuracy : 0.9991704916219654; \n",
      " validation loss : 0.6416386382217014; validation accuracy : 0.9097744360902256\n",
      "Epoch 170:\t train loss : 0.7036185843609681; train accuracy : 0.8454349388928828; \n",
      " validation loss : 0.7350587972913658; validation accuracy : 0.8195488721804511\n",
      "Epoch 171:\t train loss : 0.6981864156134914; train accuracy : 0.8492230271525743; \n",
      " validation loss : 0.6719890072809847; validation accuracy : 0.8721804511278195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172:\t train loss : 0.6001475291434383; train accuracy : 0.950519825250235; \n",
      " validation loss : 0.6511103757401961; validation accuracy : 0.9022556390977443\n",
      "Epoch 173:\t train loss : 0.5884947113219323; train accuracy : 0.9622158933805232; \n",
      " validation loss : 0.6319450236607581; validation accuracy : 0.924812030075188\n",
      "Epoch 174:\t train loss : 0.5785736816686622; train accuracy : 0.9723358955925455; \n",
      " validation loss : 0.6302768921517033; validation accuracy : 0.9172932330827067\n",
      "Epoch 175:\t train loss : 0.5751873079628472; train accuracy : 0.9757783553613891; \n",
      " validation loss : 0.6455595802205051; validation accuracy : 0.9022556390977443\n",
      "Epoch 176:\t train loss : 0.5715749698971375; train accuracy : 0.9797461704363214; \n",
      " validation loss : 0.6267933494030515; validation accuracy : 0.924812030075188\n",
      "Epoch 177:\t train loss : 0.5737971987057531; train accuracy : 0.9772714704418515; \n",
      " validation loss : 0.6635608193361353; validation accuracy : 0.8872180451127819\n",
      "Epoch 178:\t train loss : 0.5680879734159762; train accuracy : 0.9829121274124869; \n",
      " validation loss : 0.6398097096786591; validation accuracy : 0.9097744360902256\n",
      "Epoch 179:\t train loss : 0.5639060816511289; train accuracy : 0.9874329480727755; \n",
      " validation loss : 0.6205526363417808; validation accuracy : 0.9323308270676691\n",
      "Epoch 180:\t train loss : 0.5629730553054276; train accuracy : 0.988290106730078; \n",
      " validation loss : 0.6266454615268242; validation accuracy : 0.924812030075188\n",
      "Epoch 181:\t train loss : 0.574911015548834; train accuracy : 0.9758889564784604; \n",
      " validation loss : 0.6180757555439749; validation accuracy : 0.9323308270676691\n",
      "Epoch 182:\t train loss : 0.5616155776372843; train accuracy : 0.989686445833103; \n",
      " validation loss : 0.6288319126502073; validation accuracy : 0.924812030075188\n",
      "Epoch 183:\t train loss : 0.5601689259825973; train accuracy : 0.9910274843775922; \n",
      " validation loss : 0.6044006055509125; validation accuracy : 0.9473684210526315\n",
      "Epoch 184:\t train loss : 0.561402428093362; train accuracy : 0.9897279212520046; \n",
      " validation loss : 0.6569034560374724; validation accuracy : 0.8872180451127819\n",
      "Epoch 185:\t train loss : 0.5683901915987496; train accuracy : 0.9829121274124869; \n",
      " validation loss : 0.639309529074467; validation accuracy : 0.9097744360902256\n",
      "Epoch 186:\t train loss : 0.5627056908533495; train accuracy : 0.9887739866172648; \n",
      " validation loss : 0.6231816687349188; validation accuracy : 0.924812030075188\n",
      "Epoch 187:\t train loss : 0.5603606004475226; train accuracy : 0.9909307084001548; \n",
      " validation loss : 0.6283411187480162; validation accuracy : 0.924812030075188\n",
      "Epoch 188:\t train loss : 0.5574199926144199; train accuracy : 0.993986064259249; \n",
      " validation loss : 0.621801303624214; validation accuracy : 0.9323308270676691\n",
      "Epoch 189:\t train loss : 0.5838676692495038; train accuracy : 0.9668334900182491; \n",
      " validation loss : 0.6293746056650704; validation accuracy : 0.924812030075188\n",
      "Epoch 190:\t train loss : 0.5619687870171632; train accuracy : 0.9891610905270143; \n",
      " validation loss : 0.6540988902496733; validation accuracy : 0.8947368421052632\n",
      "Epoch 191:\t train loss : 0.5582500124862084; train accuracy : 0.9930874301830448; \n",
      " validation loss : 0.6424719573492216; validation accuracy : 0.9097744360902256\n",
      "Epoch 192:\t train loss : 0.5571386313095398; train accuracy : 0.993986064259249; \n",
      " validation loss : 0.6301697604911932; validation accuracy : 0.9172932330827067\n",
      "Epoch 193:\t train loss : 0.5600465171394077; train accuracy : 0.9909583586794226; \n",
      " validation loss : 0.6539400520314801; validation accuracy : 0.8947368421052632\n",
      "Epoch 194:\t train loss : 0.5588527424019732; train accuracy : 0.9925205994580545; \n",
      " validation loss : 0.6195913415228673; validation accuracy : 0.9323308270676691\n",
      "Epoch 195:\t train loss : 0.5563788715874398; train accuracy : 0.9950229497317923; \n",
      " validation loss : 0.6226037483200709; validation accuracy : 0.9323308270676691\n",
      "Epoch 196:\t train loss : 0.5575082517669817; train accuracy : 0.9937233866062047; \n",
      " validation loss : 0.6405220908406154; validation accuracy : 0.9097744360902256\n",
      "Epoch 197:\t train loss : 0.5643453770594049; train accuracy : 0.9870873195819277; \n",
      " validation loss : 0.657293051566718; validation accuracy : 0.8947368421052632\n",
      "Epoch 198:\t train loss : 0.5571830614351866; train accuracy : 0.9940551899574186; \n",
      " validation loss : 0.626669427310571; validation accuracy : 0.924812030075188\n",
      "Epoch 199:\t train loss : 0.5584131268443628; train accuracy : 0.9930044793452414; \n",
      " validation loss : 0.6412508293058463; validation accuracy : 0.9097744360902256\n",
      "Epoch 200:\t train loss : 0.5599453577267699; train accuracy : 0.9913454625891721; \n",
      " validation loss : 0.6591694074643434; validation accuracy : 0.8947368421052632\n",
      "Epoch 201:\t train loss : 0.5585329349783099; train accuracy : 0.9927832771110988; \n",
      " validation loss : 0.656936024926168; validation accuracy : 0.9022556390977443\n",
      "Epoch 202:\t train loss : 0.5561460086666994; train accuracy : 0.9951888514073992; \n",
      " validation loss : 0.6515410434132403; validation accuracy : 0.8947368421052632\n",
      "Epoch 203:\t train loss : 0.5567197302654066; train accuracy : 0.9945667201238733; \n",
      " validation loss : 0.6349747960118128; validation accuracy : 0.9172932330827067\n",
      "Epoch 204:\t train loss : 0.5550503143554304; train accuracy : 0.9961842614610408; \n",
      " validation loss : 0.6474783530785132; validation accuracy : 0.9022556390977443\n",
      "Epoch 205:\t train loss : 0.554601405045566; train accuracy : 0.9968202178842006; \n",
      " validation loss : 0.6435671909541159; validation accuracy : 0.9097744360902256\n",
      "Epoch 206:\t train loss : 0.5550277105882458; train accuracy : 0.9963778134159155; \n",
      " validation loss : 0.6400396818623161; validation accuracy : 0.9097744360902256\n",
      "Epoch 207:\t train loss : 0.553874999048863; train accuracy : 0.9974838245866283; \n",
      " validation loss : 0.64083268643417; validation accuracy : 0.9097744360902256\n",
      "Epoch 208:\t train loss : 0.5546771846738765; train accuracy : 0.9967372670463972; \n",
      " validation loss : 0.656110288626131; validation accuracy : 0.8947368421052632\n",
      "Epoch 209:\t train loss : 0.5570570959014247; train accuracy : 0.9942763921915612; \n",
      " validation loss : 0.6610092451359939; validation accuracy : 0.8947368421052632\n",
      "Epoch 210:\t train loss : 0.555362543008728; train accuracy : 0.9960183597854338; \n",
      " validation loss : 0.6314079301081725; validation accuracy : 0.9172932330827067\n",
      "Epoch 211:\t train loss : 0.5555216965292594; train accuracy : 0.9957971575512913; \n",
      " validation loss : 0.6215719779909775; validation accuracy : 0.9323308270676691\n",
      "Epoch 212:\t train loss : 0.5536853055589008; train accuracy : 0.9977050268207709; \n",
      " validation loss : 0.6520627435269731; validation accuracy : 0.8872180451127819\n",
      "Epoch 213:\t train loss : 0.5545292814133558; train accuracy : 0.9967234419067632; \n",
      " validation loss : 0.6115357218312873; validation accuracy : 0.9398496240601504\n",
      "Epoch 214:\t train loss : 0.553507321877262; train accuracy : 0.9979262290549135; \n",
      " validation loss : 0.6343470378185184; validation accuracy : 0.9172932330827067\n",
      "Epoch 215:\t train loss : 0.5527697598187387; train accuracy : 0.9987557374329481; \n",
      " validation loss : 0.633822780021013; validation accuracy : 0.9172932330827067\n",
      "Epoch 216:\t train loss : 0.5534997855241193; train accuracy : 0.9979262290549135; \n",
      " validation loss : 0.6491943415480774; validation accuracy : 0.9022556390977443\n",
      "Epoch 217:\t train loss : 0.5561588360314208; train accuracy : 0.9953409279433723; \n",
      " validation loss : 0.6528066422348743; validation accuracy : 0.8947368421052632\n",
      "Epoch 218:\t train loss : 0.5642498135483267; train accuracy : 0.9869214179063208; \n",
      " validation loss : 0.6509842168784039; validation accuracy : 0.8947368421052632\n",
      "Epoch 219:\t train loss : 0.5684214681881529; train accuracy : 0.9827600508765139; \n",
      " validation loss : 0.6458753006263743; validation accuracy : 0.9022556390977443\n",
      "Epoch 220:\t train loss : 0.5593483011182782; train accuracy : 0.9919261184537964; \n",
      " validation loss : 0.6565454828037938; validation accuracy : 0.8947368421052632\n",
      "Epoch 221:\t train loss : 0.5546487742066317; train accuracy : 0.9967925676049328; \n",
      " validation loss : 0.6440511048918444; validation accuracy : 0.9022556390977443\n",
      "Epoch 222:\t train loss : 0.5552042412044209; train accuracy : 0.9961704363214068; \n",
      " validation loss : 0.6580303707201823; validation accuracy : 0.8947368421052632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223:\t train loss : 0.554683729392136; train accuracy : 0.9966404910689598; \n",
      " validation loss : 0.6318074909165386; validation accuracy : 0.9172932330827067\n",
      "Epoch 224:\t train loss : 0.5577808267616728; train accuracy : 0.993516009511696; \n",
      " validation loss : 0.6252189556320028; validation accuracy : 0.924812030075188\n",
      "Epoch 225:\t train loss : 0.5564465949868294; train accuracy : 0.9948846983354531; \n",
      " validation loss : 0.6491918307487381; validation accuracy : 0.9022556390977443\n",
      "Epoch 226:\t train loss : 0.5554277202728646; train accuracy : 0.9959077586683626; \n",
      " validation loss : 0.6451330572318161; validation accuracy : 0.9022556390977443\n",
      "Epoch 227:\t train loss : 0.5548091601230205; train accuracy : 0.9965160648122546; \n",
      " validation loss : 0.6357308276942386; validation accuracy : 0.9172932330827067\n",
      "Epoch 228:\t train loss : 0.5555557323553758; train accuracy : 0.9958662832494608; \n",
      " validation loss : 0.6574304633347382; validation accuracy : 0.8947368421052632\n",
      "Epoch 229:\t train loss : 0.5548132329943164; train accuracy : 0.9965713653707903; \n",
      " validation loss : 0.6200889265941285; validation accuracy : 0.9323308270676691\n",
      "Epoch 230:\t train loss : 0.5547250926179581; train accuracy : 0.9966957916274954; \n",
      " validation loss : 0.6305255495822254; validation accuracy : 0.9172932330827067\n",
      "Epoch 231:\t train loss : 0.5548461800310501; train accuracy : 0.9965160648122546; \n",
      " validation loss : 0.6488963212767507; validation accuracy : 0.9022556390977443\n",
      "Epoch 232:\t train loss : 0.556533854562778; train accuracy : 0.9948155726372836; \n",
      " validation loss : 0.6499122570631223; validation accuracy : 0.9022556390977443\n",
      "Epoch 233:\t train loss : 0.5553046244202752; train accuracy : 0.995990709506166; \n",
      " validation loss : 0.6510457106520501; validation accuracy : 0.9022556390977443\n",
      "Early stopping at epoch 233\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5601689259825973; Train accuracy : 0.9910274843775922; \n",
      " Validation loss : 0.6044006055509125; Validation accuracy : 0.9473684210526315\n",
      "------------------------------ Let's train model 57 ! ------------------------------\n",
      "Epoch 1:\t train loss : 0.8718247850543698; train accuracy : 0.6532675812217484; \n",
      " validation loss : 0.8029592958147379; validation accuracy : 0.7313432835820896\n",
      "Epoch 2:\t train loss : 0.7645271520921215; train accuracy : 0.7812402703212508; \n",
      " validation loss : 0.77137325134294; validation accuracy : 0.7761194029850746\n",
      "Epoch 3:\t train loss : 0.7359164829435022; train accuracy : 0.811699136174974; \n",
      " validation loss : 0.7268753442366455; validation accuracy : 0.8283582089552238\n",
      "Epoch 4:\t train loss : 0.7069090906212481; train accuracy : 0.8409749109698884; \n",
      " validation loss : 0.7056300905558845; validation accuracy : 0.835820895522388\n",
      "Epoch 5:\t train loss : 0.6726336728231713; train accuracy : 0.8774338874247287; \n",
      " validation loss : 0.676004859996201; validation accuracy : 0.8880597014925373\n",
      "Epoch 6:\t train loss : 0.636702774025418; train accuracy : 0.9143047772864697; \n",
      " validation loss : 0.6348313434987448; validation accuracy : 0.9104477611940298\n",
      "Epoch 7:\t train loss : 0.6150543297938734; train accuracy : 0.936007216344118; \n",
      " validation loss : 0.6295622969080523; validation accuracy : 0.917910447761194\n",
      "Epoch 8:\t train loss : 0.6053465831404732; train accuracy : 0.9464270157621743; \n",
      " validation loss : 0.6053295412555982; validation accuracy : 0.9477611940298507\n",
      "Epoch 9:\t train loss : 0.5974449972154086; train accuracy : 0.9539609593207576; \n",
      " validation loss : 0.6302602151151804; validation accuracy : 0.917910447761194\n",
      "Epoch 10:\t train loss : 0.6068978901331268; train accuracy : 0.9445890297327619; \n",
      " validation loss : 0.6414509555395639; validation accuracy : 0.917910447761194\n",
      "Epoch 11:\t train loss : 0.5947253822814825; train accuracy : 0.9563970246784425; \n",
      " validation loss : 0.6076708383140274; validation accuracy : 0.9402985074626866\n",
      "Epoch 12:\t train loss : 0.5831701345752109; train accuracy : 0.9687566995111582; \n",
      " validation loss : 0.6227727292022666; validation accuracy : 0.9253731343283582\n",
      "Epoch 13:\t train loss : 0.5863129448837449; train accuracy : 0.9652261754967013; \n",
      " validation loss : 0.623656456259318; validation accuracy : 0.917910447761194\n",
      "Epoch 14:\t train loss : 0.5735200775039615; train accuracy : 0.978185444741485; \n",
      " validation loss : 0.5982906660844323; validation accuracy : 0.9477611940298507\n",
      "Epoch 15:\t train loss : 0.5729257423919748; train accuracy : 0.9789844620581353; \n",
      " validation loss : 0.6252916617086753; validation accuracy : 0.9328358208955224\n",
      "Epoch 16:\t train loss : 0.5957535557054945; train accuracy : 0.9549417866928676; \n",
      " validation loss : 0.6166397944432476; validation accuracy : 0.9253731343283582\n",
      "Epoch 17:\t train loss : 0.5747525419543468; train accuracy : 0.9764478330135244; \n",
      " validation loss : 0.6195594996895448; validation accuracy : 0.9253731343283582\n",
      "Epoch 18:\t train loss : 0.5862446974533763; train accuracy : 0.9647635067826513; \n",
      " validation loss : 0.6577323221766174; validation accuracy : 0.9029850746268657\n",
      "Epoch 19:\t train loss : 0.5973811955576737; train accuracy : 0.9535490459138569; \n",
      " validation loss : 0.6136951494094821; validation accuracy : 0.9402985074626866\n",
      "Epoch 20:\t train loss : 0.5781130818733173; train accuracy : 0.9734063022940641; \n",
      " validation loss : 0.6122425380339467; validation accuracy : 0.9402985074626866\n",
      "Epoch 21:\t train loss : 0.5863878451406744; train accuracy : 0.964604801755073; \n",
      " validation loss : 0.5939112388047081; validation accuracy : 0.9552238805970149\n",
      "Epoch 22:\t train loss : 0.5762494036413243; train accuracy : 0.9750653190501334; \n",
      " validation loss : 0.6144748003417432; validation accuracy : 0.9328358208955224\n",
      "Epoch 23:\t train loss : 0.5843276836616828; train accuracy : 0.9669783699061936; \n",
      " validation loss : 0.5958560042390217; validation accuracy : 0.9477611940298507\n",
      "Epoch 24:\t train loss : 0.5749627891977578; train accuracy : 0.9765671458624198; \n",
      " validation loss : 0.5940436033753581; validation accuracy : 0.9552238805970149\n",
      "Epoch 25:\t train loss : 0.5728826832795634; train accuracy : 0.9784430089867195; \n",
      " validation loss : 0.6144363883669395; validation accuracy : 0.9402985074626866\n",
      "Epoch 26:\t train loss : 0.5644846698375994; train accuracy : 0.9870829637160158; \n",
      " validation loss : 0.6144636154403099; validation accuracy : 0.9328358208955224\n",
      "Epoch 27:\t train loss : 0.5711873999872137; train accuracy : 0.9801150933405249; \n",
      " validation loss : 0.6311099749254862; validation accuracy : 0.9253731343283582\n",
      "Epoch 28:\t train loss : 0.5682487791459307; train accuracy : 0.983309458137856; \n",
      " validation loss : 0.5938797491673053; validation accuracy : 0.9552238805970149\n",
      "Epoch 29:\t train loss : 0.5633330717974048; train accuracy : 0.9883418089645993; \n",
      " validation loss : 0.6190155060202253; validation accuracy : 0.9328358208955224\n",
      "Epoch 30:\t train loss : 0.5739931376787986; train accuracy : 0.9773879425086303; \n",
      " validation loss : 0.6888818217263898; validation accuracy : 0.8582089552238806\n",
      "Epoch 31:\t train loss : 0.585103791255467; train accuracy : 0.9655390403004714; \n",
      " validation loss : 0.6235544969821621; validation accuracy : 0.9328358208955224\n",
      "Epoch 32:\t train loss : 0.5780474306177841; train accuracy : 0.9728548117925032; \n",
      " validation loss : 0.6108562708040365; validation accuracy : 0.9402985074626866\n",
      "Epoch 33:\t train loss : 0.588608827952092; train accuracy : 0.9621526386320611; \n",
      " validation loss : 0.620684023658921; validation accuracy : 0.9253731343283582\n",
      "Epoch 34:\t train loss : 0.5696314339768551; train accuracy : 0.9816780916610546; \n",
      " validation loss : 0.5977631501723186; validation accuracy : 0.9552238805970149\n",
      "Epoch 35:\t train loss : 0.5632582584369906; train accuracy : 0.988101668183013; \n",
      " validation loss : 0.5975659386620419; validation accuracy : 0.9477611940298507\n",
      "Epoch 36:\t train loss : 0.5603652453149321; train accuracy : 0.9909860089586905; \n",
      " validation loss : 0.6147064535382447; validation accuracy : 0.9328358208955224\n",
      "Epoch 37:\t train loss : 0.5671345152435698; train accuracy : 0.9841709726610705; \n",
      " validation loss : 0.6263169637016613; validation accuracy : 0.917910447761194\n",
      "Epoch 38:\t train loss : 0.5617230738330197; train accuracy : 0.9897693966709064; \n",
      " validation loss : 0.6187282073888941; validation accuracy : 0.9328358208955224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39:\t train loss : 0.562924461183018; train accuracy : 0.9882166251659964; \n",
      " validation loss : 0.6085330987761962; validation accuracy : 0.9477611940298507\n",
      "Epoch 40:\t train loss : 0.5757223034747876; train accuracy : 0.9755063978200974; \n",
      " validation loss : 0.601794150655133; validation accuracy : 0.9477611940298507\n",
      "Epoch 41:\t train loss : 0.5677793650806767; train accuracy : 0.9833778262941277; \n",
      " validation loss : 0.6045821482268064; validation accuracy : 0.9402985074626866\n",
      "Epoch 42:\t train loss : 0.5627717147903041; train accuracy : 0.988397109523135; \n",
      " validation loss : 0.6415499949501159; validation accuracy : 0.9029850746268657\n",
      "Epoch 43:\t train loss : 0.5593568852076574; train accuracy : 0.9920978910791108; \n",
      " validation loss : 0.5909572683540791; validation accuracy : 0.9552238805970149\n",
      "Epoch 44:\t train loss : 0.5579587844647472; train accuracy : 0.9934701782268822; \n",
      " validation loss : 0.6073525235436806; validation accuracy : 0.9477611940298507\n",
      "Epoch 45:\t train loss : 0.5579258508152446; train accuracy : 0.9934760491765898; \n",
      " validation loss : 0.6119801873283776; validation accuracy : 0.9402985074626866\n",
      "Epoch 46:\t train loss : 0.5592342358027506; train accuracy : 0.9922026212464746; \n",
      " validation loss : 0.6099995744148489; validation accuracy : 0.9402985074626866\n",
      "Epoch 47:\t train loss : 0.5624911997676437; train accuracy : 0.9886546737683695; \n",
      " validation loss : 0.6025556162258436; validation accuracy : 0.9477611940298507\n",
      "Epoch 48:\t train loss : 0.561532952154217; train accuracy : 0.989654439687923; \n",
      " validation loss : 0.6109750619619368; validation accuracy : 0.9402985074626866\n",
      "Epoch 49:\t train loss : 0.5612175188239178; train accuracy : 0.9901012000221202; \n",
      " validation loss : 0.6223643691995917; validation accuracy : 0.9253731343283582\n",
      "Epoch 50:\t train loss : 0.5574165644065441; train accuracy : 0.9941104905159542; \n",
      " validation loss : 0.5812846489682804; validation accuracy : 0.9701492537313433\n",
      "Epoch 51:\t train loss : 0.5624337990129467; train accuracy : 0.9887478514217924; \n",
      " validation loss : 0.6055074801233623; validation accuracy : 0.9477611940298507\n",
      "Epoch 52:\t train loss : 0.5591538956519271; train accuracy : 0.9921749709672067; \n",
      " validation loss : 0.6004065132048465; validation accuracy : 0.9477611940298507\n",
      "Epoch 53:\t train loss : 0.5604536045915369; train accuracy : 0.990866696109795; \n",
      " validation loss : 0.6161801862280865; validation accuracy : 0.9402985074626866\n",
      "Epoch 54:\t train loss : 0.5688192304010502; train accuracy : 0.9822587475256788; \n",
      " validation loss : 0.6267395189477534; validation accuracy : 0.9253731343283582\n",
      "Epoch 55:\t train loss : 0.5635992397832273; train accuracy : 0.987667975446552; \n",
      " validation loss : 0.6170285351480781; validation accuracy : 0.9328358208955224\n",
      "Epoch 56:\t train loss : 0.5580481842502687; train accuracy : 0.9933785156572547; \n",
      " validation loss : 0.6104206311497188; validation accuracy : 0.9402985074626866\n",
      "Epoch 57:\t train loss : 0.558971304687886; train accuracy : 0.9922681486206298; \n",
      " validation loss : 0.5911681597724247; validation accuracy : 0.9626865671641791\n",
      "Epoch 58:\t train loss : 0.5581703716701087; train accuracy : 0.99318496370238; \n",
      " validation loss : 0.6000550424538056; validation accuracy : 0.9552238805970149\n",
      "Epoch 59:\t train loss : 0.5619498653045728; train accuracy : 0.9895394827049397; \n",
      " validation loss : 0.610519432146927; validation accuracy : 0.9402985074626866\n",
      "Epoch 60:\t train loss : 0.5595839140666052; train accuracy : 0.9915085234826625; \n",
      " validation loss : 0.6134966263706432; validation accuracy : 0.9402985074626866\n",
      "Epoch 61:\t train loss : 0.5661488598259365; train accuracy : 0.9850411989161091; \n",
      " validation loss : 0.6102566086971682; validation accuracy : 0.9402985074626866\n",
      "Epoch 62:\t train loss : 0.5609708494907907; train accuracy : 0.9905072424793134; \n",
      " validation loss : 0.6005229606643957; validation accuracy : 0.9552238805970149\n",
      "Epoch 63:\t train loss : 0.5641710147906593; train accuracy : 0.9869767184648565; \n",
      " validation loss : 0.6236127447890886; validation accuracy : 0.9328358208955224\n",
      "Epoch 64:\t train loss : 0.5594390694316459; train accuracy : 0.9918621061634366; \n",
      " validation loss : 0.6395973885370037; validation accuracy : 0.9104477611940298\n",
      "Epoch 65:\t train loss : 0.5570825771770105; train accuracy : 0.9942443860463812; \n",
      " validation loss : 0.6089901096063813; validation accuracy : 0.9402985074626866\n",
      "Epoch 66:\t train loss : 0.5591835104122881; train accuracy : 0.9922259156598303; \n",
      " validation loss : 0.6150510621456734; validation accuracy : 0.9402985074626866\n",
      "Epoch 67:\t train loss : 0.5615127969712898; train accuracy : 0.9897563290731702; \n",
      " validation loss : 0.603657596923186; validation accuracy : 0.9477611940298507\n",
      "Epoch 68:\t train loss : 0.5608749967082595; train accuracy : 0.990302138010498; \n",
      " validation loss : 0.6001908461706629; validation accuracy : 0.9552238805970149\n",
      "Epoch 69:\t train loss : 0.5689827539618061; train accuracy : 0.9820739073026281; \n",
      " validation loss : 0.6016324154744805; validation accuracy : 0.9477611940298507\n",
      "Epoch 70:\t train loss : 0.5800927997766774; train accuracy : 0.9706456302331942; \n",
      " validation loss : 0.6469328418755874; validation accuracy : 0.9029850746268657\n",
      "Epoch 71:\t train loss : 0.5674898164457755; train accuracy : 0.9838857581365681; \n",
      " validation loss : 0.6362801527356243; validation accuracy : 0.9104477611940298\n",
      "Epoch 72:\t train loss : 0.5614517797857398; train accuracy : 0.989824697229442; \n",
      " validation loss : 0.6067063962918242; validation accuracy : 0.9477611940298507\n",
      "Epoch 73:\t train loss : 0.5590907172789734; train accuracy : 0.9923918173354372; \n",
      " validation loss : 0.5864666713193705; validation accuracy : 0.9626865671641791\n",
      "Epoch 74:\t train loss : 0.5587203606019637; train accuracy : 0.9926406698488477; \n",
      " validation loss : 0.6226951945396054; validation accuracy : 0.9253731343283582\n",
      "Epoch 75:\t train loss : 0.5592735565286843; train accuracy : 0.991811161470813; \n",
      " validation loss : 0.5810727380812266; validation accuracy : 0.9701492537313433\n",
      "Epoch 76:\t train loss : 0.5613735234921947; train accuracy : 0.9899048072851289; \n",
      " validation loss : 0.647773892967714; validation accuracy : 0.8955223880597015\n",
      "Epoch 77:\t train loss : 0.5689415949515289; train accuracy : 0.9821888642856115; \n",
      " validation loss : 0.6240950971218286; validation accuracy : 0.9253731343283582\n",
      "Epoch 78:\t train loss : 0.5592413590497891; train accuracy : 0.992244854207274; \n",
      " validation loss : 0.6097359370063439; validation accuracy : 0.9402985074626866\n",
      "Epoch 79:\t train loss : 0.5607519618833721; train accuracy : 0.9902220279548111; \n",
      " validation loss : 0.6008469104838444; validation accuracy : 0.9552238805970149\n",
      "Epoch 80:\t train loss : 0.5685944456228711; train accuracy : 0.9824930173575575; \n",
      " validation loss : 0.6085859334933962; validation accuracy : 0.9402985074626866\n",
      "Epoch 81:\t train loss : 0.556101500499632; train accuracy : 0.9953547530830061; \n",
      " validation loss : 0.6021973083331325; validation accuracy : 0.9477611940298507\n",
      "Epoch 82:\t train loss : 0.5586390757058602; train accuracy : 0.9925679458266637; \n",
      " validation loss : 0.6000094412317708; validation accuracy : 0.9552238805970149\n",
      "Epoch 83:\t train loss : 0.6437760721635332; train accuracy : 0.9057593259089177; \n",
      " validation loss : 0.6775786326143199; validation accuracy : 0.8731343283582089\n",
      "Epoch 84:\t train loss : 0.5947727068309734; train accuracy : 0.9556911850152152; \n",
      " validation loss : 0.6089115154829443; validation accuracy : 0.9402985074626866\n",
      "Epoch 85:\t train loss : 0.5694296058118924; train accuracy : 0.9817421039514143; \n",
      " validation loss : 0.6208721582248222; validation accuracy : 0.9328358208955224\n",
      "Epoch 86:\t train loss : 0.5606615104377485; train accuracy : 0.9907328005793681; \n",
      " validation loss : 0.5964827945583775; validation accuracy : 0.9552238805970149\n",
      "Epoch 87:\t train loss : 0.557629783866444; train accuracy : 0.9937190307402927; \n",
      " validation loss : 0.6109485871488651; validation accuracy : 0.9477611940298507\n",
      "Epoch 88:\t train loss : 0.5582224103629533; train accuracy : 0.9931296631438443; \n",
      " validation loss : 0.6210371933304573; validation accuracy : 0.9328358208955224\n",
      "Epoch 89:\t train loss : 0.5578968365900586; train accuracy : 0.9934061659365225; \n",
      " validation loss : 0.6054649885419359; validation accuracy : 0.9402985074626866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90:\t train loss : 0.557855991252335; train accuracy : 0.9935807793439535; \n",
      " validation loss : 0.6160620420880698; validation accuracy : 0.9328358208955224\n",
      "Epoch 91:\t train loss : 0.5574145265997928; train accuracy : 0.9939445888403473; \n",
      " validation loss : 0.606152356638845; validation accuracy : 0.9477611940298507\n",
      "Epoch 92:\t train loss : 0.5561952963392747; train accuracy : 0.9951335508488636; \n",
      " validation loss : 0.6207593717407218; validation accuracy : 0.9328358208955224\n",
      "Epoch 93:\t train loss : 0.5590157947996122; train accuracy : 0.9922535659390982; \n",
      " validation loss : 0.6198142927109694; validation accuracy : 0.9253731343283582\n",
      "Epoch 94:\t train loss : 0.5623789452808714; train accuracy : 0.9889864771195833; \n",
      " validation loss : 0.6518205142262326; validation accuracy : 0.9029850746268657\n",
      "Epoch 95:\t train loss : 0.5634495207709675; train accuracy : 0.9878848218147825; \n",
      " validation loss : 0.6072748134516092; validation accuracy : 0.9477611940298507\n",
      "Epoch 96:\t train loss : 0.5556500265036586; train accuracy : 0.9957418569927556; \n",
      " validation loss : 0.6182021237234966; validation accuracy : 0.9328358208955224\n",
      "Epoch 97:\t train loss : 0.5553265102712607; train accuracy : 0.9961289609025051; \n",
      " validation loss : 0.6021549999122334; validation accuracy : 0.9477611940298507\n",
      "Epoch 98:\t train loss : 0.554611943689775; train accuracy : 0.9968478681634685; \n",
      " validation loss : 0.6118246476110928; validation accuracy : 0.9402985074626866\n",
      "Epoch 99:\t train loss : 0.5554527399144573; train accuracy : 0.9957884458194671; \n",
      " validation loss : 0.616648575150529; validation accuracy : 0.9328358208955224\n",
      "Epoch 100:\t train loss : 0.5549182961876465; train accuracy : 0.9965160648122546; \n",
      " validation loss : 0.621855568130708; validation accuracy : 0.9253731343283582\n",
      "Epoch 101:\t train loss : 0.5539349916599753; train accuracy : 0.9975217016815158; \n",
      " validation loss : 0.5952159562108705; validation accuracy : 0.9626865671641791\n",
      "Epoch 102:\t train loss : 0.5611634606963228; train accuracy : 0.9902106648263449; \n",
      " validation loss : 0.6821714694765668; validation accuracy : 0.8656716417910447\n",
      "Epoch 103:\t train loss : 0.6652382622436702; train accuracy : 0.8844322488616039; \n",
      " validation loss : 0.673694460115758; validation accuracy : 0.8731343283582089\n",
      "Epoch 104:\t train loss : 0.6239316893228042; train accuracy : 0.9262336001648411; \n",
      " validation loss : 0.6287848538877197; validation accuracy : 0.917910447761194\n",
      "Epoch 105:\t train loss : 0.6027916708963531; train accuracy : 0.9474995057039117; \n",
      " validation loss : 0.6050648064684174; validation accuracy : 0.9477611940298507\n",
      "Epoch 106:\t train loss : 0.5910317362592887; train accuracy : 0.9596482051181046; \n",
      " validation loss : 0.6271599206603956; validation accuracy : 0.9253731343283582\n",
      "Epoch 107:\t train loss : 0.5897460311593344; train accuracy : 0.9606377442220385; \n",
      " validation loss : 0.6099310733273701; validation accuracy : 0.9402985074626866\n",
      "Epoch 108:\t train loss : 0.5817079659662883; train accuracy : 0.969120509007552; \n",
      " validation loss : 0.5918823581797208; validation accuracy : 0.9626865671641791\n",
      "Epoch 109:\t train loss : 0.5693702913767347; train accuracy : 0.9818862262974609; \n",
      " validation loss : 0.6068035841564062; validation accuracy : 0.9477611940298507\n",
      "Epoch 110:\t train loss : 0.5694797972658681; train accuracy : 0.9815951408232511; \n",
      " validation loss : 0.616411548285453; validation accuracy : 0.9328358208955224\n",
      "Epoch 111:\t train loss : 0.574005898712982; train accuracy : 0.9767883480965623; \n",
      " validation loss : 0.6111474461272717; validation accuracy : 0.9402985074626866\n",
      "Epoch 112:\t train loss : 0.5652690476917006; train accuracy : 0.9859784676290984; \n",
      " validation loss : 0.6120654649312856; validation accuracy : 0.9402985074626866\n",
      "Epoch 113:\t train loss : 0.5651379737342432; train accuracy : 0.9862680380195128; \n",
      " validation loss : 0.6155769055170651; validation accuracy : 0.9328358208955224\n",
      "Epoch 114:\t train loss : 0.5651499875771747; train accuracy : 0.9861705045001776; \n",
      " validation loss : 0.5772915116155493; validation accuracy : 0.9701492537313433\n",
      "Epoch 115:\t train loss : 0.5621083820121596; train accuracy : 0.9893415748841529; \n",
      " validation loss : 0.6021930898346755; validation accuracy : 0.9477611940298507\n",
      "Epoch 116:\t train loss : 0.5614620285008969; train accuracy : 0.9899731754414007; \n",
      " validation loss : 0.6121798793263734; validation accuracy : 0.9402985074626866\n",
      "Epoch 117:\t train loss : 0.5702552057591153; train accuracy : 0.980941760936443; \n",
      " validation loss : 0.6153772400011521; validation accuracy : 0.9328358208955224\n",
      "Epoch 118:\t train loss : 0.568057557885541; train accuracy : 0.9831333296466295; \n",
      " validation loss : 0.5887351271313793; validation accuracy : 0.9626865671641791\n",
      "Epoch 119:\t train loss : 0.5611966515809322; train accuracy : 0.9898815128717732; \n",
      " validation loss : 0.6116931828886435; validation accuracy : 0.9328358208955224\n",
      "Epoch 120:\t train loss : 0.559974181010555; train accuracy : 0.9915623089574026; \n",
      " validation loss : 0.5983183660604455; validation accuracy : 0.9552238805970149\n",
      "Epoch 121:\t train loss : 0.5587736366202531; train accuracy : 0.9924704123073287; \n",
      " validation loss : 0.6037227260137534; validation accuracy : 0.9477611940298507\n",
      "Epoch 122:\t train loss : 0.5596942411294957; train accuracy : 0.9917049162196538; \n",
      " validation loss : 0.5883953779795579; validation accuracy : 0.9552238805970149\n",
      "Epoch 123:\t train loss : 0.5585459494543902; train accuracy : 0.9926086637036677; \n",
      " validation loss : 0.5897493888328126; validation accuracy : 0.9626865671641791\n",
      "Epoch 124:\t train loss : 0.5601473705558129; train accuracy : 0.9910966100757618; \n",
      " validation loss : 0.5893019365741256; validation accuracy : 0.9626865671641791\n",
      "Epoch 125:\t train loss : 0.558742574549167; train accuracy : 0.9926173754354919; \n",
      " validation loss : 0.6006185831778664; validation accuracy : 0.9477611940298507\n",
      "Epoch 126:\t train loss : 0.5600085865922206; train accuracy : 0.9911388430365612; \n",
      " validation loss : 0.6109582584370549; validation accuracy : 0.9402985074626866\n",
      "Epoch 127:\t train loss : 0.5622585020346462; train accuracy : 0.9889078821476919; \n",
      " validation loss : 0.5998250829764428; validation accuracy : 0.9477611940298507\n",
      "Epoch 128:\t train loss : 0.5588949830578606; train accuracy : 0.9924704123073287; \n",
      " validation loss : 0.5920400027086449; validation accuracy : 0.9626865671641791\n",
      "Epoch 129:\t train loss : 0.5595103971850338; train accuracy : 0.9918388117500808; \n",
      " validation loss : 0.5932963738317454; validation accuracy : 0.9552238805970149\n",
      "Epoch 130:\t train loss : 0.5563978837246195; train accuracy : 0.9949909435866124; \n",
      " validation loss : 0.6108862947961817; validation accuracy : 0.9477611940298507\n",
      "Epoch 131:\t train loss : 0.5585800774247701; train accuracy : 0.992844448619342; \n",
      " validation loss : 0.5861217625021405; validation accuracy : 0.9626865671641791\n",
      "Epoch 132:\t train loss : 0.5597586448940778; train accuracy : 0.9915623089574026; \n",
      " validation loss : 0.5920889702687491; validation accuracy : 0.9552238805970149\n",
      "Epoch 133:\t train loss : 0.5586445350423689; train accuracy : 0.9927789212451867; \n",
      " validation loss : 0.6010717293334135; validation accuracy : 0.9477611940298507\n",
      "Epoch 134:\t train loss : 0.5574083425920947; train accuracy : 0.9939955335329709; \n",
      " validation loss : 0.603731735684435; validation accuracy : 0.9477611940298507\n",
      "Epoch 135:\t train loss : 0.5588976480354668; train accuracy : 0.9922579218050103; \n",
      " validation loss : 0.6089379990367393; validation accuracy : 0.9402985074626866\n",
      "Epoch 136:\t train loss : 0.5602932426328031; train accuracy : 0.9909772972268663; \n",
      " validation loss : 0.6166091847093176; validation accuracy : 0.9328358208955224\n",
      "Epoch 137:\t train loss : 0.5593973753402939; train accuracy : 0.9919217625878843; \n",
      " validation loss : 0.6136643624078922; validation accuracy : 0.9402985074626866\n",
      "Epoch 138:\t train loss : 0.558554036793916; train accuracy : 0.9927832771110988; \n",
      " validation loss : 0.6054762954199946; validation accuracy : 0.9477611940298507\n",
      "Epoch 139:\t train loss : 0.5573233031644088; train accuracy : 0.9941061346500422; \n",
      " validation loss : 0.5813101794286313; validation accuracy : 0.9701492537313433\n",
      "Epoch 140:\t train loss : 0.5559022551176829; train accuracy : 0.9954566424682533; \n",
      " validation loss : 0.600218906144165; validation accuracy : 0.9477611940298507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141:\t train loss : 0.5549327072473523; train accuracy : 0.9964331139744511; \n",
      " validation loss : 0.6108758735659368; validation accuracy : 0.9402985074626866\n",
      "Epoch 142:\t train loss : 0.5582903986123448; train accuracy : 0.9930277737585972; \n",
      " validation loss : 0.5816196921942083; validation accuracy : 0.9701492537313433\n",
      "Epoch 143:\t train loss : 0.5576603786862824; train accuracy : 0.9937976257121841; \n",
      " validation loss : 0.5672063448838244; validation accuracy : 0.9850746268656716\n",
      "Epoch 144:\t train loss : 0.5576213323694622; train accuracy : 0.9937466810195604; \n",
      " validation loss : 0.5919609581068569; validation accuracy : 0.9552238805970149\n",
      "Epoch 145:\t train loss : 0.559373297252607; train accuracy : 0.9918941123086165; \n",
      " validation loss : 0.6169133375494593; validation accuracy : 0.9328358208955224\n",
      "Epoch 146:\t train loss : 0.5554547005040831; train accuracy : 0.9959310530817183; \n",
      " validation loss : 0.5972247433154177; validation accuracy : 0.9552238805970149\n",
      "Epoch 147:\t train loss : 0.5589975780965415; train accuracy : 0.9922259156598303; \n",
      " validation loss : 0.6258798639470804; validation accuracy : 0.9253731343283582\n",
      "Epoch 148:\t train loss : 0.5585253255153856; train accuracy : 0.9928211542059863; \n",
      " validation loss : 0.5966163555081653; validation accuracy : 0.9552238805970149\n",
      "Epoch 149:\t train loss : 0.5560853447931179; train accuracy : 0.9952994525244705; \n",
      " validation loss : 0.5917047247148625; validation accuracy : 0.9552238805970149\n",
      "Epoch 150:\t train loss : 0.5561661429491066; train accuracy : 0.9951612011281313; \n",
      " validation loss : 0.5831855518586853; validation accuracy : 0.9701492537313433\n",
      "Epoch 151:\t train loss : 0.5554972657386089; train accuracy : 0.9959077586683626; \n",
      " validation loss : 0.5812912241818017; validation accuracy : 0.9701492537313433\n",
      "Epoch 152:\t train loss : 0.5538604101084227; train accuracy : 0.9976497262622352; \n",
      " validation loss : 0.6061601808133358; validation accuracy : 0.9477611940298507\n",
      "Epoch 153:\t train loss : 0.5600675346435494; train accuracy : 0.9910922542098497; \n",
      " validation loss : 0.598610714382635; validation accuracy : 0.9552238805970149\n",
      "Epoch 154:\t train loss : 0.5628194152728233; train accuracy : 0.9885484285172103; \n",
      " validation loss : 0.6029808316165416; validation accuracy : 0.9477611940298507\n",
      "Epoch 155:\t train loss : 0.5658154701414445; train accuracy : 0.9851402475192397; \n",
      " validation loss : 0.6125562946115847; validation accuracy : 0.9402985074626866\n",
      "Epoch 156:\t train loss : 0.564698986889282; train accuracy : 0.9866449151136426; \n",
      " validation loss : 0.6114667852067431; validation accuracy : 0.9402985074626866\n",
      "Epoch 157:\t train loss : 0.5613197662755368; train accuracy : 0.9900182491843168; \n",
      " validation loss : 0.6157294598554104; validation accuracy : 0.9328358208955224\n",
      "Epoch 158:\t train loss : 0.5567054328118916; train accuracy : 0.9946824346487543; \n",
      " validation loss : 0.6111407120705662; validation accuracy : 0.9402985074626866\n",
      "Epoch 159:\t train loss : 0.5558805590179752; train accuracy : 0.995516298892701; \n",
      " validation loss : 0.5890109011324737; validation accuracy : 0.9626865671641791\n",
      "Epoch 160:\t train loss : 0.5558594197649243; train accuracy : 0.9955395933060568; \n",
      " validation loss : 0.5986409226266746; validation accuracy : 0.9552238805970149\n",
      "Epoch 161:\t train loss : 0.5567514481142236; train accuracy : 0.9945208888390594; \n",
      " validation loss : 0.5899552159009646; validation accuracy : 0.9626865671641791\n",
      "Epoch 162:\t train loss : 0.5755913275476799; train accuracy : 0.9751177788265525; \n",
      " validation loss : 0.6376251969119765; validation accuracy : 0.9104477611940298\n",
      "Epoch 163:\t train loss : 0.5586420270883588; train accuracy : 0.9927279765525632; \n",
      " validation loss : 0.6124304807269202; validation accuracy : 0.9402985074626866\n",
      "Epoch 164:\t train loss : 0.5580696974983949; train accuracy : 0.9933872273890788; \n",
      " validation loss : 0.597363356537066; validation accuracy : 0.9552238805970149\n",
      "Epoch 165:\t train loss : 0.5557114612427414; train accuracy : 0.9956036055964165; \n",
      " validation loss : 0.5963373886759051; validation accuracy : 0.9477611940298507\n",
      "Epoch 166:\t train loss : 0.5557033376934976; train accuracy : 0.9955905379986804; \n",
      " validation loss : 0.6027453116959303; validation accuracy : 0.9477611940298507\n",
      "Epoch 167:\t train loss : 0.5558259329066981; train accuracy : 0.9956036055964165; \n",
      " validation loss : 0.5782744731350803; validation accuracy : 0.9701492537313433\n",
      "Epoch 168:\t train loss : 0.5562042637552395; train accuracy : 0.9951801396755751; \n",
      " validation loss : 0.5792301080958238; validation accuracy : 0.9701492537313433\n",
      "Epoch 169:\t train loss : 0.5564881772271354; train accuracy : 0.9949079927488089; \n",
      " validation loss : 0.6112357174966769; validation accuracy : 0.9402985074626866\n",
      "Epoch 170:\t train loss : 0.5565772320603694; train accuracy : 0.9948526921902733; \n",
      " validation loss : 0.6380595501577031; validation accuracy : 0.9104477611940298\n",
      "Epoch 171:\t train loss : 0.5554294682057742; train accuracy : 0.9959630592268982; \n",
      " validation loss : 0.6036376244411892; validation accuracy : 0.9477611940298507\n",
      "Epoch 172:\t train loss : 0.5552477067419642; train accuracy : 0.996120249170681; \n",
      " validation loss : 0.5875369556436781; validation accuracy : 0.9552238805970149\n",
      "Epoch 173:\t train loss : 0.5618296316335254; train accuracy : 0.9893226363367091; \n",
      " validation loss : 0.6068357118053074; validation accuracy : 0.9477611940298507\n",
      "Epoch 174:\t train loss : 0.5579898119569543; train accuracy : 0.993359577109811; \n",
      " validation loss : 0.6296252782379907; validation accuracy : 0.917910447761194\n",
      "Epoch 175:\t train loss : 0.5563970603392541; train accuracy : 0.9948163301791814; \n",
      " validation loss : 0.6068638316175621; validation accuracy : 0.9477611940298507\n",
      "Epoch 176:\t train loss : 0.555101826604961; train accuracy : 0.9962948625781121; \n",
      " validation loss : 0.6111067086771527; validation accuracy : 0.9402985074626866\n",
      "Epoch 177:\t train loss : 0.5554015321059944; train accuracy : 0.9960183597854338; \n",
      " validation loss : 0.6034031358028676; validation accuracy : 0.9477611940298507\n",
      "Epoch 178:\t train loss : 0.556248328826975; train accuracy : 0.9951248391170394; \n",
      " validation loss : 0.6014113844263301; validation accuracy : 0.9477611940298507\n",
      "Epoch 179:\t train loss : 0.5555399299427655; train accuracy : 0.995824807830559; \n",
      " validation loss : 0.6169182997713256; validation accuracy : 0.9328358208955224\n",
      "Epoch 180:\t train loss : 0.5552147868991563; train accuracy : 0.9962075558743965; \n",
      " validation loss : 0.596250261332999; validation accuracy : 0.9552238805970149\n",
      "Epoch 181:\t train loss : 0.555161764193496; train accuracy : 0.9962672122988442; \n",
      " validation loss : 0.5991876962185712; validation accuracy : 0.9477611940298507\n",
      "Epoch 182:\t train loss : 0.5559417676734755; train accuracy : 0.9953547530830061; \n",
      " validation loss : 0.5953087507091775; validation accuracy : 0.9552238805970149\n",
      "Epoch 183:\t train loss : 0.5550917993904416; train accuracy : 0.9963225128573798; \n",
      " validation loss : 0.5851897209986601; validation accuracy : 0.9701492537313433\n",
      "Epoch 184:\t train loss : 0.5543205950662907; train accuracy : 0.9970690703976111; \n",
      " validation loss : 0.6052609747858886; validation accuracy : 0.9402985074626866\n",
      "Epoch 185:\t train loss : 0.5541028434867836; train accuracy : 0.9972306162073059; \n",
      " validation loss : 0.6110500781229637; validation accuracy : 0.9402985074626866\n",
      "Epoch 186:\t train loss : 0.554320685988632; train accuracy : 0.9969817636938955; \n",
      " validation loss : 0.6029507849803188; validation accuracy : 0.9552238805970149\n",
      "Epoch 187:\t train loss : 0.5546395322788175; train accuracy : 0.9967925676049328; \n",
      " validation loss : 0.6018189819129282; validation accuracy : 0.9477611940298507\n",
      "Epoch 188:\t train loss : 0.5551000123779458; train accuracy : 0.9962774391144638; \n",
      " validation loss : 0.5974384105597975; validation accuracy : 0.9552238805970149\n",
      "Epoch 189:\t train loss : 0.5555213934173003; train accuracy : 0.995820451964647; \n",
      " validation loss : 0.6060415429494516; validation accuracy : 0.9402985074626866\n",
      "Epoch 190:\t train loss : 0.5534092161331635; train accuracy : 0.9980091798927169; \n",
      " validation loss : 0.6238056224974624; validation accuracy : 0.9253731343283582\n",
      "Epoch 191:\t train loss : 0.5536649902590844; train accuracy : 0.9977879776585743; \n",
      " validation loss : 0.6176337533563797; validation accuracy : 0.9328358208955224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192:\t train loss : 0.5553599693835425; train accuracy : 0.9960693044780574; \n",
      " validation loss : 0.5781411308052483; validation accuracy : 0.9776119402985075\n",
      "Epoch 193:\t train loss : 0.5538349408669148; train accuracy : 0.9975944257036996; \n",
      " validation loss : 0.6037274769374654; validation accuracy : 0.9477611940298507\n",
      "Early stopping at epoch 193\n",
      "------------------------------ Final result of the model ! ------------------------------\n",
      "Train loss : 0.5576603786862824; Train accuracy : 0.9937976257121841; \n",
      " Validation loss : 0.5672063448838244; Validation accuracy : 0.9850746268656716\n",
      "------------------------------ Total time of training 7.0 h 49.0 m and 51.990206480026245 s ------------------------------\n"
     ]
    }
   ],
   "source": [
    "numEpochs = 273\n",
    "patience = 50\n",
    "directoryToSaveModel = \"../saved_models/pd_RAW\"\n",
    "models_list, devices = trainingLoop(gpus_list, numEpochs, patience, train_dataset, validation_dataset, directoryToSaveModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-verification",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "taken-trade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Let's predict with model 1 ! ------------------------------\n",
      "------------------------------ Model 1 predict with 0.9285714285714286 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9285714285714286\n",
      "------------------------------ Let's predict with model 2 ! ------------------------------\n",
      "------------------------------ Model 2 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9642857142857143\n",
      "------------------------------ Let's predict with model 3 ! ------------------------------\n",
      "------------------------------ Model 3 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9761904761904763\n",
      "------------------------------ Let's predict with model 4 ! ------------------------------\n",
      "------------------------------ Model 4 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9821428571428572\n",
      "------------------------------ Let's predict with model 5 ! ------------------------------\n",
      "------------------------------ Model 5 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9857142857142858\n",
      "------------------------------ Let's predict with model 6 ! ------------------------------\n",
      "------------------------------ Model 6 predict with 0.7 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9380952380952382\n",
      "------------------------------ Let's predict with model 7 ! ------------------------------\n",
      "------------------------------ Model 7 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9469387755102041\n",
      "------------------------------ Let's predict with model 8 ! ------------------------------\n",
      "------------------------------ Model 8 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9535714285714286\n",
      "------------------------------ Let's predict with model 9 ! ------------------------------\n",
      "------------------------------ Model 9 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9587301587301589\n",
      "------------------------------ Let's predict with model 10 ! ------------------------------\n",
      "------------------------------ Model 10 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.962857142857143\n",
      "------------------------------ Let's predict with model 11 ! ------------------------------\n",
      "------------------------------ Model 11 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9662337662337663\n",
      "------------------------------ Let's predict with model 12 ! ------------------------------\n",
      "------------------------------ Model 12 predict with 0.64 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9390476190476192\n",
      "------------------------------ Let's predict with model 13 ! ------------------------------\n",
      "------------------------------ Model 13 predict with 0.875 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9341208791208793\n",
      "------------------------------ Let's predict with model 14 ! ------------------------------\n",
      "------------------------------ Model 14 predict with 0.92 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9331122448979593\n",
      "------------------------------ Let's predict with model 15 ! ------------------------------\n",
      "------------------------------ Model 15 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9375714285714287\n",
      "------------------------------ Let's predict with model 16 ! ------------------------------\n",
      "------------------------------ Model 16 predict with 0.8 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9289732142857144\n",
      "------------------------------ Let's predict with model 17 ! ------------------------------\n",
      "------------------------------ Model 17 predict with 0.92 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9284453781512606\n",
      "------------------------------ Let's predict with model 18 ! ------------------------------\n",
      "------------------------------ Model 18 predict with 0.92 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9279761904761907\n",
      "------------------------------ Let's predict with model 19 ! ------------------------------\n",
      "------------------------------ Model 19 predict with 0.96 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9296616541353386\n",
      "------------------------------ Let's predict with model 20 ! ------------------------------\n",
      "------------------------------ Model 20 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9331785714285716\n",
      "------------------------------ Let's predict with model 21 ! ------------------------------\n",
      "------------------------------ Model 21 predict with 0.48 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9115986394557826\n",
      "------------------------------ Let's predict with model 22 ! ------------------------------\n",
      "------------------------------ Model 22 predict with 0.96 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9137987012987016\n",
      "------------------------------ Let's predict with model 23 ! ------------------------------\n",
      "------------------------------ Model 23 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9175465838509319\n",
      "------------------------------ Let's predict with model 24 ! ------------------------------\n",
      "------------------------------ Model 24 predict with 0.64 of accuracy ------------------------------\n",
      "The mean accuracy is 0.9059821428571432\n",
      "------------------------------ Let's predict with model 25 ! ------------------------------\n",
      "------------------------------ Model 25 predict with 0.68 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8969428571428574\n",
      "------------------------------ Let's predict with model 26 ! ------------------------------\n",
      "------------------------------ Model 26 predict with 0.56 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8839835164835167\n",
      "------------------------------ Let's predict with model 27 ! ------------------------------\n",
      "------------------------------ Model 27 predict with 0.56 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8719841269841271\n",
      "------------------------------ Let's predict with model 28 ! ------------------------------\n",
      "------------------------------ Model 28 predict with 0.68 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8651275510204083\n",
      "------------------------------ Let's predict with model 29 ! ------------------------------\n",
      "------------------------------ Model 29 predict with 0.5217391304347826 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8532865710002142\n",
      "------------------------------ Let's predict with model 30 ! ------------------------------\n",
      "------------------------------ Model 30 predict with 0.9565217391304348 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8567277432712216\n",
      "------------------------------ Let's predict with model 31 ! ------------------------------\n",
      "------------------------------ Model 31 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8613494289721499\n",
      "------------------------------ Let's predict with model 32 ! ------------------------------\n",
      "------------------------------ Model 32 predict with 0.48 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8494322593167702\n",
      "------------------------------ Let's predict with model 33 ! ------------------------------\n",
      "------------------------------ Model 33 predict with 0.96 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8527827969132318\n",
      "------------------------------ Let's predict with model 34 ! ------------------------------\n",
      "------------------------------ Model 34 predict with 0.76 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8500538911216662\n",
      "------------------------------ Let's predict with model 35 ! ------------------------------\n",
      "------------------------------ Model 35 predict with 0.88 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8509094942324756\n",
      "------------------------------ Let's predict with model 36 ! ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Model 36 predict with 0.48 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8406064527260181\n",
      "------------------------------ Let's predict with model 37 ! ------------------------------\n",
      "------------------------------ Model 37 predict with 0.68 of accuracy ------------------------------\n",
      "The mean accuracy is 0.836265737787477\n",
      "------------------------------ Let's predict with model 38 ! ------------------------------\n",
      "------------------------------ Model 38 predict with 0.36 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8237324288983329\n",
      "------------------------------ Let's predict with model 39 ! ------------------------------\n",
      "------------------------------ Model 39 predict with 0.76 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8220982640547859\n",
      "------------------------------ Let's predict with model 40 ! ------------------------------\n",
      "------------------------------ Model 40 predict with 0.6 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8165458074534163\n",
      "------------------------------ Let's predict with model 41 ! ------------------------------\n",
      "------------------------------ Model 41 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8210202999545525\n",
      "------------------------------ Let's predict with model 42 ! ------------------------------\n",
      "------------------------------ Model 42 predict with 0.76 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8195674356699202\n",
      "------------------------------ Let's predict with model 43 ! ------------------------------\n",
      "------------------------------ Model 43 predict with 0.56 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8135309836775966\n",
      "------------------------------ Let's predict with model 44 ! ------------------------------\n",
      "------------------------------ Model 44 predict with 0.32 of accuracy ------------------------------\n",
      "The mean accuracy is 0.8023143704121967\n",
      "------------------------------ Let's predict with model 45 ! ------------------------------\n",
      "------------------------------ Model 45 predict with 0.20833333333333334 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7891147918104442\n",
      "------------------------------ Let's predict with model 46 ! ------------------------------\n",
      "------------------------------ Model 46 predict with 0.76 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7884818615536954\n",
      "------------------------------ Let's predict with model 47 ! ------------------------------\n",
      "------------------------------ Model 47 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7929822474780848\n",
      "------------------------------ Let's predict with model 48 ! ------------------------------\n",
      "------------------------------ Model 48 predict with 0.36 of accuracy ------------------------------\n",
      "The mean accuracy is 0.783961783988958\n",
      "------------------------------ Let's predict with model 49 ! ------------------------------\n",
      "------------------------------ Model 49 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7883707271728568\n",
      "------------------------------ Let's predict with model 50 ! ------------------------------\n",
      "------------------------------ Model 50 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7926033126293998\n",
      "------------------------------ Let's predict with model 51 ! ------------------------------\n",
      "------------------------------ Model 51 predict with 0.48 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7864738359111761\n",
      "------------------------------ Let's predict with model 52 ! ------------------------------\n",
      "------------------------------ Model 52 predict with 0.16 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7744262621436534\n",
      "------------------------------ Let's predict with model 53 ! ------------------------------\n",
      "------------------------------ Model 53 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7786823704050939\n",
      "------------------------------ Let's predict with model 54 ! ------------------------------\n",
      "------------------------------ Model 54 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7827808450272218\n",
      "------------------------------ Let's predict with model 55 ! ------------------------------\n",
      "------------------------------ Model 55 predict with 0.44 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7765484660267269\n",
      "------------------------------ Let's predict with model 56 ! ------------------------------\n",
      "------------------------------ Model 56 predict with 1.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7805386719905353\n",
      "------------------------------ Let's predict with model 57 ! ------------------------------\n",
      "------------------------------ Model 57 predict with 0.0 of accuracy ------------------------------\n",
      "The mean accuracy is 0.7668450110784206\n"
     ]
    }
   ],
   "source": [
    "testLoop(models_list, test_dataset, devices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
