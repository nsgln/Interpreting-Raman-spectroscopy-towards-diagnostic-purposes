{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "specialized-atlantic",
   "metadata": {},
   "source": [
    "# Raman model in Pytorch \n",
    "This notebook as the purpose to transpose the CNN model created by Dario Bertazioli in the Pytorch librairie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-arctic",
   "metadata": {},
   "source": [
    "## Librairies\n",
    "Here, we will find the librairies needed for this work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "agricultural-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utils librairies ---\n",
    "#Generics librairies\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Measure librairies\n",
    "import time\n",
    "\n",
    "#Dataset librairies\n",
    "import pandas as pd\n",
    "\n",
    "# --- DL librairies ---\n",
    "#Pytorch librairies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Sklearn librairies\n",
    "from sklearn.model_selection import LeaveOneGroupOut, train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-consortium",
   "metadata": {},
   "source": [
    "## Set up the GPU environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collaborative-archives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3,4\";\n",
    "gpus_list = [0, 1, 2, 3]\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-weekend",
   "metadata": {},
   "source": [
    "## Data\n",
    "In this part, we will find all the methods regarding the data (loading, data augmentation...). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-youth",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, labels, names = pd.read_pickle(\"../data/dataset_COVID_RAW.pkl\")\n",
    "df = pd.DataFrame(df)\n",
    "labels = pd.Series(labels, name = 'label')\n",
    "names = pd.Series(names, name = 'names')\n",
    "df = pd.concat((df, labels, names), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "isolated-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set = df.drop(columns = ['label', \"names\"]).values\n",
    "Y_set = df.label.values\n",
    "groups = df.names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "streaming-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(LeaveOneGroupOut().split(X_set, Y_set, groups = groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-salon",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "republican-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataAugment(signal, betashift = 0.24039033704204857, slopeshift = 0.5640435054299953, multishift = 0.0013960388613510225):\n",
    "    #baseline shift\n",
    "    beta = np.random.random(size=(signal.shape[0],1))*2*betashift-betashift\n",
    "    slope = np.random.random(size=(signal.shape[0],1))*2*slopeshift-slopeshift + 1\n",
    "    #relative positions\n",
    "    axis = np.array(range(signal.shape[1]))/float(signal.shape[1])\n",
    "    #offset\n",
    "    offset = slope*(axis) + beta - axis - slope/2. + 0.5\n",
    "\n",
    "    #multiplicative coefficient\n",
    "    multi = np.random.random(size=(signal.shape[0],1))*2*multishift-multishift + 1\n",
    "    augmented_signal = multi*signal + offset\n",
    "\n",
    "    return augmented_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-right",
   "metadata": {},
   "source": [
    "### Creation of train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pointed-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RamanDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        super(RamanDataset).__init__()\n",
    "        x = torch.from_numpy(X)\n",
    "        self.raman_spectra = x\n",
    "        y = torch.from_numpy(Y)\n",
    "        self.labels = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.raman_spectra)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        spectrum = self.raman_spectra[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return spectrum, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunset-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(Dataset):\n",
    "    def __init__(self, ramanDatasets):\n",
    "        super(Datasets).__init__()\n",
    "        self.datasets = ramanDatasets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datasets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.datasets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "clinical-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setsCreation(pathToFile, X_set, Y_set, folds):\n",
    "    if not path.exists(pathToFile):\n",
    "        train_set = []\n",
    "        validation_set = []\n",
    "        test_set = []\n",
    "        X_train = []\n",
    "        X_val = []\n",
    "        X_test = []\n",
    "        Y_train = []\n",
    "        Y_val = []\n",
    "        Y_test = []\n",
    "        \n",
    "        for i, (train_idx, test_idx) in enumerate(folds):\n",
    "            X_train_tmp = X_set[train_idx]\n",
    "            Y_train_tmp = Y_set[train_idx]\n",
    "            \n",
    "            X_test_tmp = X_set[test_idx]\n",
    "            Y_test_tmp = Y_set[test_idx]\n",
    "            \n",
    "            X_train_tmp, X_val_tmp, Y_train_tmp, Y_val_tmp = train_test_split(X_train_tmp, Y_train_tmp, test_size = .1,\n",
    "                                                                              stratify = Y_train_tmp)\n",
    "            augment = 30\n",
    "            augmented_data = []\n",
    "            Y_list = copy.copy(Y_train_tmp)\n",
    "            for i in range(augment):\n",
    "                augmented_data.append(dataAugment(X_train_tmp))\n",
    "            for i in range(augment-1):\n",
    "                Y_list = np.concatenate((Y_list, Y_train_tmp), axis=0)\n",
    "                \n",
    "            X_train_tmp = np.vstack(augmented_data)\n",
    "            Y_train_tmp = copy.copy(Y_list)\n",
    "            train_set_tmp = RamanDataset(X_train_tmp, Y_train_tmp)\n",
    "            train_set.append(train_set_tmp)\n",
    "            val_set_tmp = RamanDataset(X_val_tmp, Y_val_tmp)\n",
    "            validation_set.append(val_set_tmp)\n",
    "            test_set_tmp = RamanDataset(X_test_tmp, Y_test_tmp)\n",
    "            test_set.append(test_set_tmp)\n",
    "        \n",
    "        train_dataset = Datasets(train_set)\n",
    "        validation_dataset = Datasets(validation_set)\n",
    "        test_dataset = Datasets(test_set)\n",
    "        training_settings = (train_dataset, validation_dataset, test_dataset)\n",
    "        \n",
    "        with open(pathToFile, \"wb\") as outf:\n",
    "            pickle.dump(training_settings, outf)\n",
    "        \n",
    "    else:\n",
    "        with open(pathToFile, \"rb\") as inf:\n",
    "            train_dataset, validation_dataset, test_dataset = pickle.load(inf)\n",
    "            \n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artistic-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset, test_dataset = setsCreation(\"../train_settings/training_settings_cov_raw.pckl\", X_set, Y_set, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-version",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-grace",
   "metadata": {},
   "source": [
    "### Utility class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extended-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv1d(1, 100, kernel_size=100,\n",
    "                     stride=1, padding_mode='replicate'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100, eps=0.001, momentum=0.99),\n",
    "            nn.Conv1d(100, 102, kernel_size=5,\n",
    "                     stride=2, padding_mode='replicate'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(6, stride=3),\n",
    "            nn.BatchNorm1d(102, eps=0.001, momentum=0.99),\n",
    "            nn.Conv1d(102, 25, kernel_size=9,\n",
    "                     stride=5, padding_mode='replicate'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(325, 732),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.7000000000000001),\n",
    "            nn.Linear(732, 152),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(152,189),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(189, 3),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.resize_(x.shape[0],  1, x.shape[1])\n",
    "        x = self.cnn_layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dense_layers(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sought-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCNN(gpu_ids):\n",
    "    model = ConvNet()\n",
    "    model = model.double()\n",
    "    optimizer = Adam(model.parameters(), lr=0.00020441990333108206)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        cuda='cuda:'+str(gpu_ids[0])\n",
    "        model = nn.DataParallel(model, device_ids=gpu_ids)\n",
    "        loss.cuda()\n",
    "    device = torch.device(cuda if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    return model, loss, optimizer, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "superior-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, model, loss, optimizer, train_dataset, validation_dataset, epochs, patience, path, verbose=0, batch_size=338):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    min_val_loss = np.Inf\n",
    "    max_val_acc = np.NINF\n",
    "    epochs_no_improve_loss = 0\n",
    "    epochs_no_improve_acc = 0\n",
    "    if verbose == 1:\n",
    "        verbScheduler = True\n",
    "    else:\n",
    "        verbScheduler = False\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=80, cooldown=10, verbose=verbScheduler)\n",
    "    training_generator = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    validation_generator = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        loss_train_epoch = []\n",
    "        acc_train_epoch = []\n",
    "        for i, (ramanSpectraTrain, labelTrain) in enumerate(training_generator):\n",
    "            ramanSpectraTrain = ramanSpectraTrain.to(device)\n",
    "            labelTrain = labelTrain.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            output_train = model(ramanSpectraTrain)\n",
    "            \n",
    "            loss_train = loss(output_train, labelTrain)\n",
    "            loss_train_epoch.append(loss_train.cpu().item())\n",
    "            \n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            output_label = torch.argmax(output_train, dim=1)\n",
    "            acc_train = accuracy_score(labelTrain.cpu().detach().numpy(), output_label.cpu().detach().numpy())\n",
    "            acc_train_epoch.append(acc_train)\n",
    "        \n",
    "        loss_train = mean(loss_train_epoch)\n",
    "        acc_train = mean(acc_train_epoch)\n",
    "        train_losses.append(loss_train)\n",
    "        train_acc.append(acc_train)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss_val_epoch = []\n",
    "            acc_val_epoch = []\n",
    "            for j, (ramanSpectraVal, labelVal) in enumerate(validation_generator):\n",
    "                ramanSpectraVal = ramanSpectraVal.to(device)\n",
    "                labelVal = labelVal.to(device)\n",
    "                    \n",
    "                output_val = model(ramanSpectraVal)\n",
    "                    \n",
    "                loss_val = loss(output_val, labelVal)\n",
    "                loss_val_epoch.append(loss_val.cpu().item())\n",
    "                \n",
    "                val_label = torch.argmax(output_val, dim=1)\n",
    "                acc_val = accuracy_score(labelVal.cpu().detach().numpy(), val_label.cpu().detach().numpy())\n",
    "                acc_val_epoch.append(acc_val)\n",
    "            \n",
    "            loss_val = mean(loss_val_epoch)\n",
    "            acc_val = mean(acc_val_epoch)\n",
    "        val_losses.append(loss_val)\n",
    "        val_acc.append(acc_val)\n",
    "        scheduler.step(loss_val)\n",
    "        if acc_val > max_val_acc:\n",
    "            epochs_no_improve_acc = 0\n",
    "            max_val_acc = acc_val\n",
    "            torch.save({'model_state_dict' : model.state_dict(),\n",
    "                       'optimizer_state_dict' : optimizer.state_dict(),\n",
    "                       'train_loss' : train_losses,\n",
    "                       'train_acc' : train_acc,\n",
    "                       'val_loss' : val_losses,\n",
    "                       'val_acc' : val_acc}, path)\n",
    "        else:\n",
    "            epochs_no_improve_acc += 1\n",
    "        \n",
    "        if loss_val < min_val_loss:\n",
    "            epochs_no_improve_loss = 0\n",
    "            min_val_loss = loss_val\n",
    "            torch.save({'model_state_dict' : model.state_dict(),\n",
    "                       'optimizer_state_dict' : optimizer.state_dict(),\n",
    "                       'train_loss' : train_losses,\n",
    "                       'train_acc' : train_acc,\n",
    "                       'val_loss' : val_losses,\n",
    "                       'val_acc' : val_acc}, path)\n",
    "        else:\n",
    "            epochs_no_improve_loss += 1\n",
    "            \n",
    "        if verbose == 1:\n",
    "            print(\"Epoch {}:\\t train loss : {}; train accuracy : {}; \\n validation loss : {}; validation accuracy : {}\".format(epoch+1, loss_train, acc_train, loss_val, acc_val))\n",
    "            \n",
    "        if epochs_no_improve_loss >= patience and epochs_no_improve_acc >= patience:\n",
    "            print(\"Early stopping at epoch {}\".format(epoch+1))\n",
    "            break\n",
    "    \n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    train_losses = checkpoint['train_loss']\n",
    "    train_acc = checkpoint['train_acc']\n",
    "    val_losses = checkpoint['val_loss']\n",
    "    val_acc = checkpoint['val_acc']\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print(\"----- Final result of the model ! -----\")\n",
    "        print(\"Train loss : {}; Train accuracy : {}; \\n Validation loss : {}; Validation accuracy : {}\".format(train_losses[-1], train_acc[-1], val_losses[-1], val_acc[-1]))\n",
    "        \n",
    "    return train_losses, val_losses, train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "copyrighted-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTrain(modelName, train_loss, val_loss, train_acc, val_acc):\n",
    "    plt.plot(train_acc, 'c-')\n",
    "    plt.plot(train_loss, 'c--')\n",
    "    plt.plot(val_acc, 'r-')\n",
    "    plt.plot(val_loss, 'r--')\n",
    "    plt.title(modelName)\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['trainning accuracy', 'training loss', 'validation accuracy', 'validation loss'], loc='upper left')\n",
    "    plt.savefig('../train_results/'+modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-joshua",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "realistic-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Let's train model 1 ! ---\n",
      "Epoch 1:\t train loss : 0.9127732905389903; train accuracy : 0.6237105920341032; \n",
      " validation loss : 0.8144422509313127; validation accuracy : 0.7333333333333333\n",
      "Epoch 2:\t train loss : 0.7396704536950462; train accuracy : 0.8109232837055418; \n",
      " validation loss : 0.7636383142179974; validation accuracy : 0.7875\n",
      "Epoch 3:\t train loss : 0.7067314401292997; train accuracy : 0.842295066647579; \n",
      " validation loss : 0.7482756314645039; validation accuracy : 0.8041666666666667\n",
      "Epoch 4:\t train loss : 0.6839379570276491; train accuracy : 0.8664622701533371; \n",
      " validation loss : 0.7043889664236868; validation accuracy : 0.8458333333333333\n",
      "Epoch 5:\t train loss : 0.6669917595757693; train accuracy : 0.8834432859324298; \n",
      " validation loss : 0.7362373754505993; validation accuracy : 0.8083333333333333\n",
      "Epoch 6:\t train loss : 0.6501803635393667; train accuracy : 0.9001007070369663; \n",
      " validation loss : 0.7081266940935269; validation accuracy : 0.8416666666666667\n",
      "Epoch 7:\t train loss : 0.6430731565350625; train accuracy : 0.9075712206527964; \n",
      " validation loss : 0.7085484686541524; validation accuracy : 0.8375\n",
      "Epoch 8:\t train loss : 0.6310069485513522; train accuracy : 0.9193369440732965; \n",
      " validation loss : 0.6922919207536533; validation accuracy : 0.85\n",
      "Epoch 9:\t train loss : 0.6183232838765651; train accuracy : 0.9328031550232233; \n",
      " validation loss : 0.6595315476585725; validation accuracy : 0.8875\n",
      "Epoch 10:\t train loss : 0.6070192566224786; train accuracy : 0.944276102309601; \n",
      " validation loss : 0.6782262245886373; validation accuracy : 0.8708333333333333\n",
      "Epoch 11:\t train loss : 0.6102558163736969; train accuracy : 0.940608695997964; \n",
      " validation loss : 0.640468709072474; validation accuracy : 0.9125\n",
      "Epoch 12:\t train loss : 0.5959203338880567; train accuracy : 0.9555611559139785; \n",
      " validation loss : 0.6368099655112573; validation accuracy : 0.9125\n",
      "Epoch 13:\t train loss : 0.5936160718653689; train accuracy : 0.9577507635044856; \n",
      " validation loss : 0.6512871800578852; validation accuracy : 0.9\n",
      "Epoch 14:\t train loss : 0.5957620341336693; train accuracy : 0.955386186136031; \n",
      " validation loss : 0.6381225714062764; validation accuracy : 0.9166666666666666\n",
      "Epoch 15:\t train loss : 0.5976480248112092; train accuracy : 0.9531448829293122; \n",
      " validation loss : 0.6480819610386006; validation accuracy : 0.9041666666666667\n",
      "Epoch 16:\t train loss : 0.5941178120129532; train accuracy : 0.9568137804606477; \n",
      " validation loss : 0.623410004074605; validation accuracy : 0.9291666666666667\n",
      "Epoch 17:\t train loss : 0.6031345779567318; train accuracy : 0.9479042398358465; \n",
      " validation loss : 0.6340932088118064; validation accuracy : 0.9166666666666666\n",
      "Epoch 18:\t train loss : 0.5911542846493891; train accuracy : 0.9597161910669976; \n",
      " validation loss : 0.635314816766695; validation accuracy : 0.9083333333333333\n",
      "Epoch 19:\t train loss : 0.5868187620708903; train accuracy : 0.9645238833746899; \n",
      " validation loss : 0.6631710565188577; validation accuracy : 0.8833333333333333\n",
      "Epoch 20:\t train loss : 0.5896665943930935; train accuracy : 0.9613495737099955; \n",
      " validation loss : 0.6690146691646621; validation accuracy : 0.8791666666666667\n",
      "Epoch 21:\t train loss : 0.5804691189169873; train accuracy : 0.970725369027168; \n",
      " validation loss : 0.6663868675487842; validation accuracy : 0.8875\n",
      "Epoch 22:\t train loss : 0.6007081178097813; train accuracy : 0.9499074449640517; \n",
      " validation loss : 0.6352174228787114; validation accuracy : 0.9125\n",
      "Epoch 23:\t train loss : 0.5889871421074324; train accuracy : 0.9621786918623146; \n",
      " validation loss : 0.6153872732082607; validation accuracy : 0.9291666666666667\n",
      "Epoch 24:\t train loss : 0.5822433415664611; train accuracy : 0.9690611678437361; \n",
      " validation loss : 0.612283206271218; validation accuracy : 0.9416666666666667\n",
      "Epoch 25:\t train loss : 0.5875139829277467; train accuracy : 0.9635799413055927; \n",
      " validation loss : 0.6796311112743286; validation accuracy : 0.8666666666666667\n",
      "Epoch 26:\t train loss : 0.6037371712487718; train accuracy : 0.9469250055672203; \n",
      " validation loss : 0.6174810929610548; validation accuracy : 0.9375\n",
      "Epoch 27:\t train loss : 0.5789935228844608; train accuracy : 0.9720674667557422; \n",
      " validation loss : 0.6468174475305511; validation accuracy : 0.9041666666666667\n",
      "Epoch 28:\t train loss : 0.5896082684881374; train accuracy : 0.9609698097601324; \n",
      " validation loss : 0.6298067864502872; validation accuracy : 0.9166666666666666\n",
      "Epoch 29:\t train loss : 0.5775685847010066; train accuracy : 0.97356614255265; \n",
      " validation loss : 0.6403092869471995; validation accuracy : 0.9125\n",
      "Epoch 30:\t train loss : 0.5732946899266467; train accuracy : 0.9781456782464847; \n",
      " validation loss : 0.628067752183617; validation accuracy : 0.925\n",
      "Epoch 31:\t train loss : 0.5774373609141538; train accuracy : 0.9737177498886556; \n",
      " validation loss : 0.6664887397016077; validation accuracy : 0.8833333333333333\n",
      "Epoch 32:\t train loss : 0.5957239280224051; train accuracy : 0.9547822421581726; \n",
      " validation loss : 0.6228908443605649; validation accuracy : 0.9291666666666667\n",
      "Epoch 33:\t train loss : 0.572396807999086; train accuracy : 0.9786750612394223; \n",
      " validation loss : 0.6145926617003692; validation accuracy : 0.9375\n",
      "Epoch 34:\t train loss : 0.567170309010386; train accuracy : 0.9841692116816186; \n",
      " validation loss : 0.6035087884914488; validation accuracy : 0.95\n",
      "Epoch 35:\t train loss : 0.5769361405323727; train accuracy : 0.9743604655786727; \n",
      " validation loss : 0.6365635825546085; validation accuracy : 0.9125\n",
      "Epoch 36:\t train loss : 0.5690722638574895; train accuracy : 0.9821267377680218; \n",
      " validation loss : 0.6456984991654394; validation accuracy : 0.9041666666666667\n",
      "Epoch 37:\t train loss : 0.5861905550496377; train accuracy : 0.9642211657759114; \n",
      " validation loss : 0.6241210192853457; validation accuracy : 0.925\n",
      "Epoch 38:\t train loss : 0.5658027426059176; train accuracy : 0.9856007825920977; \n",
      " validation loss : 0.6281987920113121; validation accuracy : 0.9166666666666666\n",
      "Epoch 39:\t train loss : 0.5659959241637929; train accuracy : 0.9855252274607114; \n",
      " validation loss : 0.6177475155101504; validation accuracy : 0.925\n",
      "Epoch 40:\t train loss : 0.6040925254486669; train accuracy : 0.9463578450085894; \n",
      " validation loss : 0.6640166718064309; validation accuracy : 0.8833333333333333\n",
      "Epoch 41:\t train loss : 0.5785335702455896; train accuracy : 0.9724889848571611; \n",
      " validation loss : 0.6148918672140249; validation accuracy : 0.9375\n",
      "Epoch 42:\t train loss : 0.5739236876774314; train accuracy : 0.9774214425462875; \n",
      " validation loss : 0.6774550816528161; validation accuracy : 0.8791666666666667\n",
      "Epoch 43:\t train loss : 0.5750724609886297; train accuracy : 0.9760639355474964; \n",
      " validation loss : 0.6210040002231613; validation accuracy : 0.925\n",
      "Epoch 44:\t train loss : 0.5698559924050459; train accuracy : 0.9814109523127823; \n",
      " validation loss : 0.5932567757130259; validation accuracy : 0.9583333333333334\n",
      "Epoch 45:\t train loss : 0.5700785035567514; train accuracy : 0.9811574449640517; \n",
      " validation loss : 0.6142821952326578; validation accuracy : 0.9333333333333333\n",
      "Epoch 46:\t train loss : 0.5746348862292794; train accuracy : 0.9765277048737037; \n",
      " validation loss : 0.6148863124698304; validation accuracy : 0.9416666666666667\n",
      "Epoch 47:\t train loss : 0.5780342768299025; train accuracy : 0.9728394214862888; \n",
      " validation loss : 0.7181309729375044; validation accuracy : 0.8291666666666667\n",
      "Epoch 48:\t train loss : 0.5950837087587537; train accuracy : 0.9555025012725075; \n",
      " validation loss : 0.6652672458013185; validation accuracy : 0.875\n",
      "Epoch 49:\t train loss : 0.5799684224134601; train accuracy : 0.970855602214163; \n",
      " validation loss : 0.5913426282374956; validation accuracy : 0.9625\n",
      "Epoch 50:\t train loss : 0.5674297251481267; train accuracy : 0.9836776062543743; \n",
      " validation loss : 0.6363042175234287; validation accuracy : 0.9083333333333333\n",
      "Epoch 51:\t train loss : 0.5716847213522586; train accuracy : 0.9794763432907043; \n",
      " validation loss : 0.6129424639331137; validation accuracy : 0.9333333333333333\n",
      "Epoch 52:\t train loss : 0.5663251315267013; train accuracy : 0.9848541785964242; \n",
      " validation loss : 0.6139530413509209; validation accuracy : 0.9416666666666667\n",
      "Epoch 53:\t train loss : 0.5657612829809671; train accuracy : 0.9854705494051028; \n",
      " validation loss : 0.6037795201307432; validation accuracy : 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54:\t train loss : 0.5653755565153494; train accuracy : 0.9857424484634473; \n",
      " validation loss : 0.6172914761821893; validation accuracy : 0.9375\n",
      "Epoch 55:\t train loss : 0.5652867710694145; train accuracy : 0.9858865997009607; \n",
      " validation loss : 0.6490915313665597; validation accuracy : 0.8958333333333334\n",
      "Epoch 56:\t train loss : 0.566217192671704; train accuracy : 0.984800991760514; \n",
      " validation loss : 0.5973221995232386; validation accuracy : 0.9541666666666667\n",
      "Epoch 57:\t train loss : 0.5715168694607639; train accuracy : 0.9794470159699689; \n",
      " validation loss : 0.5925923064148128; validation accuracy : 0.9583333333333334\n",
      "Epoch 58:\t train loss : 0.5653893725382054; train accuracy : 0.9859666284914423; \n",
      " validation loss : 0.614841915603518; validation accuracy : 0.9375\n",
      "Epoch 59:\t train loss : 0.5693992094118282; train accuracy : 0.9818185523636827; \n",
      " validation loss : 0.6146968016767612; validation accuracy : 0.9333333333333333\n",
      "Epoch 60:\t train loss : 0.5641996344979239; train accuracy : 0.9869821491060635; \n",
      " validation loss : 0.6185381595486477; validation accuracy : 0.9333333333333333\n",
      "Epoch 61:\t train loss : 0.5620002381485316; train accuracy : 0.9892766391486925; \n",
      " validation loss : 0.5886452079670192; validation accuracy : 0.9625\n",
      "Epoch 62:\t train loss : 0.5651906927699584; train accuracy : 0.9859189094610931; \n",
      " validation loss : 0.6115342562659428; validation accuracy : 0.9333333333333333\n",
      "Epoch 63:\t train loss : 0.5643151533684636; train accuracy : 0.9870969730228415; \n",
      " validation loss : 0.5974654623711143; validation accuracy : 0.95\n",
      "Epoch 64:\t train loss : 0.5640498892059468; train accuracy : 0.9872888432907043; \n",
      " validation loss : 0.6062377797066467; validation accuracy : 0.9458333333333333\n",
      "Epoch 65:\t train loss : 0.5640155441150942; train accuracy : 0.9872117969396195; \n",
      " validation loss : 0.6081382824478483; validation accuracy : 0.9416666666666667\n",
      "Epoch 66:\t train loss : 0.5651334542673638; train accuracy : 0.9861709255901253; \n",
      " validation loss : 0.5925742941258698; validation accuracy : 0.9625\n",
      "Epoch 67:\t train loss : 0.5612590109917367; train accuracy : 0.9900933304701915; \n",
      " validation loss : 0.6118708187760716; validation accuracy : 0.9375\n",
      "Epoch 68:\t train loss : 0.5749293790290596; train accuracy : 0.9759630296812368; \n",
      " validation loss : 0.6053332948898148; validation accuracy : 0.9458333333333333\n",
      "Epoch 69:\t train loss : 0.5613502290247286; train accuracy : 0.990007833874149; \n",
      " validation loss : 0.6050933747339274; validation accuracy : 0.9416666666666667\n",
      "Epoch 70:\t train loss : 0.5621910436659527; train accuracy : 0.9890231317999618; \n",
      " validation loss : 0.6277414983982618; validation accuracy : 0.925\n",
      "Epoch 71:\t train loss : 0.5655574044531076; train accuracy : 0.9857563665139658; \n",
      " validation loss : 0.6116836301448357; validation accuracy : 0.9375\n",
      "Epoch 72:\t train loss : 0.5642580566530263; train accuracy : 0.9870591954571483; \n",
      " validation loss : 0.5964245527456008; validation accuracy : 0.9541666666666667\n",
      "Epoch 73:\t train loss : 0.559238728113543; train accuracy : 0.9921651317045237; \n",
      " validation loss : 0.6159631060724563; validation accuracy : 0.9375\n",
      "Epoch 74:\t train loss : 0.5598357561131089; train accuracy : 0.991411568683591; \n",
      " validation loss : 0.6143623315289857; validation accuracy : 0.9333333333333333\n",
      "Epoch 75:\t train loss : 0.559185728664523; train accuracy : 0.9921203951135713; \n",
      " validation loss : 0.6098834925999868; validation accuracy : 0.9416666666666667\n",
      "Epoch 76:\t train loss : 0.56720877648468; train accuracy : 0.9839296223834065; \n",
      " validation loss : 0.6151342647517196; validation accuracy : 0.9333333333333333\n",
      "Epoch 77:\t train loss : 0.5609943595245305; train accuracy : 0.9903190017178851; \n",
      " validation loss : 0.6355607224953296; validation accuracy : 0.9125\n",
      "Epoch 78:\t train loss : 0.5638987920698169; train accuracy : 0.9872341652350958; \n",
      " validation loss : 0.5911055808016752; validation accuracy : 0.9583333333333334\n",
      "Epoch 79:\t train loss : 0.5613647329779945; train accuracy : 0.9898104958007253; \n",
      " validation loss : 0.6146934052056567; validation accuracy : 0.9333333333333333\n",
      "Epoch 80:\t train loss : 0.5623663436545363; train accuracy : 0.9888297703124006; \n",
      " validation loss : 0.6012571017661873; validation accuracy : 0.9458333333333333\n",
      "Epoch 81:\t train loss : 0.5600746222024616; train accuracy : 0.9913022125723738; \n",
      " validation loss : 0.5937034829999153; validation accuracy : 0.9583333333333334\n",
      "Epoch 82:\t train loss : 0.5629082714488473; train accuracy : 0.9882511770694152; \n",
      " validation loss : 0.6068737224316142; validation accuracy : 0.9458333333333333\n",
      "Epoch 83:\t train loss : 0.558958988792888; train accuracy : 0.9923053063561749; \n",
      " validation loss : 0.6096799764397759; validation accuracy : 0.9375\n",
      "Epoch 84:\t train loss : 0.5619230233608187; train accuracy : 0.989362135744735; \n",
      " validation loss : 0.6156753662273936; validation accuracy : 0.9375\n",
      "Epoch 85:\t train loss : 0.5595417143894165; train accuracy : 0.9918653965451422; \n",
      " validation loss : 0.5831159922848775; validation accuracy : 0.9666666666666667\n",
      "Epoch 86:\t train loss : 0.5615091701942789; train accuracy : 0.9896842391995928; \n",
      " validation loss : 0.6052317831518683; validation accuracy : 0.9458333333333333\n",
      "Epoch 87:\t train loss : 0.5605769124461861; train accuracy : 0.9907320695743462; \n",
      " validation loss : 0.5919168939050992; validation accuracy : 0.9583333333333334\n",
      "Epoch 88:\t train loss : 0.5579883223844799; train accuracy : 0.993305417700579; \n",
      " validation loss : 0.625135323210101; validation accuracy : 0.925\n",
      "Epoch 89:\t train loss : 0.5615283615054377; train accuracy : 0.9896772801743335; \n",
      " validation loss : 0.6085817975006498; validation accuracy : 0.9416666666666667\n",
      "Epoch 90:\t train loss : 0.5622461516526582; train accuracy : 0.9889560269135331; \n",
      " validation loss : 0.612017176253232; validation accuracy : 0.9375\n",
      "Epoch 91:\t train loss : 0.5605236267360071; train accuracy : 0.9906719237131768; \n",
      " validation loss : 0.5952451654767882; validation accuracy : 0.9583333333333334\n",
      "Epoch 92:\t train loss : 0.5611380669266813; train accuracy : 0.9901002894954508; \n",
      " validation loss : 0.5899363007249847; validation accuracy : 0.9625\n",
      "Epoch 93:\t train loss : 0.559997318318316; train accuracy : 0.9913106628173315; \n",
      " validation loss : 0.6057489130856631; validation accuracy : 0.9458333333333333\n",
      "Epoch 94:\t train loss : 0.5586083445561028; train accuracy : 0.9927984030031176; \n",
      " validation loss : 0.6128083558781775; validation accuracy : 0.9375\n",
      "Epoch 95:\t train loss : 0.5600335435306608; train accuracy : 0.9910949330342941; \n",
      " validation loss : 0.6082704724221079; validation accuracy : 0.9375\n",
      "Epoch 96:\t train loss : 0.5587178256207633; train accuracy : 0.9926512693262073; \n",
      " validation loss : 0.5881764329586564; validation accuracy : 0.9625\n",
      "Epoch 97:\t train loss : 0.5646607702752914; train accuracy : 0.9865646075905071; \n",
      " validation loss : 0.5830915312319865; validation accuracy : 0.9666666666666667\n",
      "Epoch 98:\t train loss : 0.5609363590785206; train accuracy : 0.99040847489979; \n",
      " validation loss : 0.6001321153396818; validation accuracy : 0.95\n",
      "Epoch 99:\t train loss : 0.5585640882828634; train accuracy : 0.9926736376216835; \n",
      " validation loss : 0.5977929839205439; validation accuracy : 0.9541666666666667\n",
      "Epoch 100:\t train loss : 0.5596862304523176; train accuracy : 0.9915517433352421; \n",
      " validation loss : 0.6086649399943312; validation accuracy : 0.9416666666666667\n",
      "Epoch 101:\t train loss : 0.5599754157088263; train accuracy : 0.9912182071960298; \n",
      " validation loss : 0.5821935549510183; validation accuracy : 0.9666666666666667\n",
      "Epoch 102:\t train loss : 0.5575505405334907; train accuracy : 0.9937691870267863; \n",
      " validation loss : 0.606052288075876; validation accuracy : 0.9375\n",
      "Epoch 103:\t train loss : 0.5599953415681822; train accuracy : 0.9914031184386333; \n",
      " validation loss : 0.5800916515810358; validation accuracy : 0.9708333333333333\n",
      "Epoch 104:\t train loss : 0.559016420383287; train accuracy : 0.9922814468410002; \n",
      " validation loss : 0.6076678790502821; validation accuracy : 0.9458333333333333\n",
      "Epoch 105:\t train loss : 0.5582520009057386; train accuracy : 0.9930434601068906; \n",
      " validation loss : 0.5939932939172663; validation accuracy : 0.9583333333333334\n",
      "Epoch 106:\t train loss : 0.5681300330410775; train accuracy : 0.9830373759305211; \n",
      " validation loss : 0.6280523693764436; validation accuracy : 0.9208333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107:\t train loss : 0.5596396420209336; train accuracy : 0.9915109833301521; \n",
      " validation loss : 0.6074576168906768; validation accuracy : 0.9416666666666667\n",
      "Epoch 108:\t train loss : 0.5599173023023318; train accuracy : 0.9915025330851943; \n",
      " validation loss : 0.6103239255302854; validation accuracy : 0.9416666666666667\n",
      "Epoch 109:\t train loss : 0.5597583933204872; train accuracy : 0.9915040243048928; \n",
      " validation loss : 0.654022816895369; validation accuracy : 0.8958333333333334\n",
      "Epoch 110:\t train loss : 0.5626151263992661; train accuracy : 0.9885538946681937; \n",
      " validation loss : 0.6050395855515458; validation accuracy : 0.9458333333333333\n",
      "Epoch 111:\t train loss : 0.5636996205363577; train accuracy : 0.987427526722657; \n",
      " validation loss : 0.6123105096082582; validation accuracy : 0.9375\n",
      "Epoch 112:\t train loss : 0.5590804277460508; train accuracy : 0.9922898970859578; \n",
      " validation loss : 0.5934815796662353; validation accuracy : 0.9583333333333334\n",
      "Epoch 113:\t train loss : 0.5600710462497964; train accuracy : 0.9911789384106382; \n",
      " validation loss : 0.6184158291388012; validation accuracy : 0.9333333333333333\n",
      "Epoch 114:\t train loss : 0.5585854551150217; train accuracy : 0.9927352747025514; \n",
      " validation loss : 0.6062387202762666; validation accuracy : 0.9416666666666667\n",
      "Epoch 115:\t train loss : 0.5613308901962066; train accuracy : 0.9898244138512439; \n",
      " validation loss : 0.6371696914675149; validation accuracy : 0.9125\n",
      "Epoch 116:\t train loss : 0.5628293479046471; train accuracy : 0.9883983107463257; \n",
      " validation loss : 0.594804726445213; validation accuracy : 0.9583333333333334\n",
      "Epoch 117:\t train loss : 0.5585951251572052; train accuracy : 0.992644310300948; \n",
      " validation loss : 0.600906317136479; validation accuracy : 0.95\n",
      "Epoch 118:\t train loss : 0.585570534745236; train accuracy : 0.965362942991665; \n",
      " validation loss : 0.6020529349795144; validation accuracy : 0.95\n",
      "Epoch 119:\t train loss : 0.561177533664869; train accuracy : 0.9901703768212763; \n",
      " validation loss : 0.5833152235838477; validation accuracy : 0.9708333333333333\n",
      "Epoch 120:\t train loss : 0.5593584330686713; train accuracy : 0.9918962150855761; \n",
      " validation loss : 0.5967707705995872; validation accuracy : 0.9583333333333334\n",
      "Epoch 121:\t train loss : 0.5569715883616729; train accuracy : 0.994423335401158; \n",
      " validation loss : 0.5876557237373166; validation accuracy : 0.9625\n",
      "Epoch 122:\t train loss : 0.555768896163959; train accuracy : 0.995656077018515; \n",
      " validation loss : 0.5776624938434677; validation accuracy : 0.975\n",
      "Epoch 123:\t train loss : 0.5559622193385174; train accuracy : 0.9954010784500859; \n",
      " validation loss : 0.6120505472435008; validation accuracy : 0.9333333333333333\n",
      "Epoch 124:\t train loss : 0.5559526445007629; train accuracy : 0.9955397618820385; \n",
      " validation loss : 0.5850308456386935; validation accuracy : 0.9666666666666667\n",
      "Epoch 125:\t train loss : 0.5558238496799928; train accuracy : 0.9956028901826048; \n",
      " validation loss : 0.6121935727840065; validation accuracy : 0.9375\n",
      "Epoch 126:\t train loss : 0.555184872144929; train accuracy : 0.9962639975822358; \n",
      " validation loss : 0.5855024042772655; validation accuracy : 0.9666666666666667\n",
      "Epoch 127:\t train loss : 0.5572395258465564; train accuracy : 0.9941027231659986; \n",
      " validation loss : 0.6063820639452346; validation accuracy : 0.9458333333333333\n",
      "Epoch 128:\t train loss : 0.5559605452051833; train accuracy : 0.9954965165107845; \n",
      " validation loss : 0.5843570011336099; validation accuracy : 0.9666666666666667\n",
      "Epoch 129:\t train loss : 0.5564189427231409; train accuracy : 0.9950004374244449; \n",
      " validation loss : 0.5918097802465699; validation accuracy : 0.9583333333333334\n",
      "Epoch 130:\t train loss : 0.5588552677650934; train accuracy : 0.9924817673538207; \n",
      " validation loss : 0.5805701113340878; validation accuracy : 0.9708333333333333\n",
      "Epoch 131:\t train loss : 0.5578386336036789; train accuracy : 0.9934595104027486; \n",
      " validation loss : 0.5928752472454036; validation accuracy : 0.9583333333333334\n",
      "Epoch 132:\t train loss : 0.5596965711999358; train accuracy : 0.9916735262772793; \n",
      " validation loss : 0.6340805535641347; validation accuracy : 0.9125\n",
      "Epoch 133:\t train loss : 0.5620090047590031; train accuracy : 0.9891856747470892; \n",
      " validation loss : 0.5884790138444945; validation accuracy : 0.9625\n",
      "Epoch 134:\t train loss : 0.5585058501484476; train accuracy : 0.9927437249475091; \n",
      " validation loss : 0.6138393771807428; validation accuracy : 0.9375\n",
      "Epoch 135:\t train loss : 0.5582489565607709; train accuracy : 0.9931289567029331; \n",
      " validation loss : 0.5875053835887439; validation accuracy : 0.9625\n",
      "Epoch 136:\t train loss : 0.5565072149791209; train accuracy : 0.994823976426799; \n",
      " validation loss : 0.593559284903037; validation accuracy : 0.9583333333333334\n",
      "Epoch 137:\t train loss : 0.5585822325026893; train accuracy : 0.9927760347076414; \n",
      " validation loss : 0.6018095001365306; validation accuracy : 0.95\n",
      "Epoch 138:\t train loss : 0.5592020036094627; train accuracy : 0.9921427634090475; \n",
      " validation loss : 0.5950056351880686; validation accuracy : 0.9583333333333334\n",
      "Epoch 139:\t train loss : 0.5614160844316897; train accuracy : 0.9898159636062862; \n",
      " validation loss : 0.6226724459668823; validation accuracy : 0.9291666666666667\n",
      "Epoch 140:\t train loss : 0.5626083778580299; train accuracy : 0.9886309410192785; \n",
      " validation loss : 0.5907606610445109; validation accuracy : 0.9625\n",
      "Epoch 141:\t train loss : 0.5611593368316945; train accuracy : 0.990225054876885; \n",
      " validation loss : 0.602738781245366; validation accuracy : 0.95\n",
      "Epoch 142:\t train loss : 0.5616210876893459; train accuracy : 0.989607192848508; \n",
      " validation loss : 0.5938058839044086; validation accuracy : 0.9583333333333334\n",
      "Epoch 143:\t train loss : 0.5584699499828377; train accuracy : 0.9928824083794617; \n",
      " validation loss : 0.6152179046704951; validation accuracy : 0.9333333333333333\n",
      "Epoch 144:\t train loss : 0.5599618648471058; train accuracy : 0.9913583818476809; \n",
      " validation loss : 0.6327258535542016; validation accuracy : 0.9166666666666666\n",
      "Epoch 145:\t train loss : 0.5574712620502115; train accuracy : 0.9939217885092575; \n",
      " validation loss : 0.6011122094279127; validation accuracy : 0.95\n",
      "Epoch 146:\t train loss : 0.5593129421311236; train accuracy : 0.9920125302220525; \n",
      " validation loss : 0.6013361844192264; validation accuracy : 0.95\n",
      "Epoch 147:\t train loss : 0.5561468178318578; train accuracy : 0.9952554359928739; \n",
      " validation loss : 0.6047684317383083; validation accuracy : 0.9458333333333333\n",
      "Epoch 148:\t train loss : 0.5585174505446402; train accuracy : 0.9928824083794617; \n",
      " validation loss : 0.5892233177836662; validation accuracy : 0.9625\n",
      "Epoch 149:\t train loss : 0.5583235184075913; train accuracy : 0.9930126415664567; \n",
      " validation loss : 0.5804258613374749; validation accuracy : 0.9708333333333333\n",
      "Epoch 150:\t train loss : 0.5575592981850578; train accuracy : 0.9937299182413947; \n",
      " validation loss : 0.5924555542628142; validation accuracy : 0.9583333333333334\n",
      "Epoch 151:\t train loss : 0.5735439483504176; train accuracy : 0.977450769867023; \n",
      " validation loss : 0.5933360341023862; validation accuracy : 0.9541666666666667\n",
      "Epoch 152:\t train loss : 0.5614533622153215; train accuracy : 0.9898552323916778; \n",
      " validation loss : 0.6001753901374924; validation accuracy : 0.95\n",
      "Epoch 153:\t train loss : 0.5599649839318338; train accuracy : 0.9913022125723738; \n",
      " validation loss : 0.617758664143409; validation accuracy : 0.9291666666666667\n",
      "Epoch 154:\t train loss : 0.5625769458445143; train accuracy : 0.9886995371254056; \n",
      " validation loss : 0.5924823992848509; validation accuracy : 0.9583333333333334\n",
      "Epoch 155:\t train loss : 0.5589136937009382; train accuracy : 0.9923654522173443; \n",
      " validation loss : 0.5949589229422675; validation accuracy : 0.9541666666666667\n",
      "Epoch 156:\t train loss : 0.5595107476175485; train accuracy : 0.9917729409238404; \n",
      " validation loss : 0.5966931003708169; validation accuracy : 0.9541666666666667\n",
      "Epoch 157:\t train loss : 0.5596983151028412; train accuracy : 0.9916496667621048; \n",
      " validation loss : 0.6097679593874816; validation accuracy : 0.9416666666666667\n",
      "Epoch 158:\t train loss : 0.5573698699045582; train accuracy : 0.9939148294839982; \n",
      " validation loss : 0.6015730464340202; validation accuracy : 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159:\t train loss : 0.5576104254403764; train accuracy : 0.9936752401857861; \n",
      " validation loss : 0.5894914732776508; validation accuracy : 0.9625\n",
      "Epoch 160:\t train loss : 0.5598345088822153; train accuracy : 0.9914801647897181; \n",
      " validation loss : 0.5787324696732973; validation accuracy : 0.975\n",
      "Epoch 161:\t train loss : 0.5589632950381567; train accuracy : 0.9923823527072596; \n",
      " validation loss : 0.5865104428266006; validation accuracy : 0.9666666666666667\n",
      "Epoch 162:\t train loss : 0.5575042522923386; train accuracy : 0.9938392743526118; \n",
      " validation loss : 0.6180044060272166; validation accuracy : 0.9291666666666667\n",
      "Epoch 163:\t train loss : 0.5603477283977033; train accuracy : 0.9908891447159127; \n",
      " validation loss : 0.6294212573994427; validation accuracy : 0.9208333333333333\n",
      "Epoch 164:\t train loss : 0.5620361486596549; train accuracy : 0.9892304113380416; \n",
      " validation loss : 0.6169256828032298; validation accuracy : 0.9333333333333333\n",
      "Epoch 165:\t train loss : 0.5588172545294502; train accuracy : 0.9924887263790799; \n",
      " validation loss : 0.6009110326002584; validation accuracy : 0.95\n",
      "Epoch 166:\t train loss : 0.5562531534635653; train accuracy : 0.9951783896417892; \n",
      " validation loss : 0.6197029304668308; validation accuracy : 0.9291666666666667\n",
      "Epoch 167:\t train loss : 0.563175124390825; train accuracy : 0.9880593068015524; \n",
      " validation loss : 0.6329360201139071; validation accuracy : 0.9166666666666666\n",
      "Epoch 168:\t train loss : 0.5616217449496459; train accuracy : 0.9896857304192912; \n",
      " validation loss : 0.5846961269327327; validation accuracy : 0.9666666666666667\n",
      "Epoch 169:\t train loss : 0.5587452891897935; train accuracy : 0.9926627020105618; \n",
      " validation loss : 0.6428034297217983; validation accuracy : 0.9083333333333333\n",
      "Epoch 170:\t train loss : 0.56097166501691; train accuracy : 0.990293650983012; \n",
      " validation loss : 0.6123364175652525; validation accuracy : 0.9375\n",
      "Epoch 171:\t train loss : 0.5589857706750939; train accuracy : 0.9923276746516511; \n",
      " validation loss : 0.5920005587562762; validation accuracy : 0.9583333333333334\n",
      "Epoch 172:\t train loss : 0.5558990071068795; train accuracy : 0.9954473062607367; \n",
      " validation loss : 0.6095315717721377; validation accuracy : 0.9416666666666667\n",
      "Early stopping at epoch 172\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.555768896163959; Train accuracy : 0.995656077018515; \n",
      " Validation loss : 0.5776624938434677; Validation accuracy : 0.975\n",
      "--- Let's train model 2 ! ---\n",
      "Epoch 1:\t train loss : 0.9720855873654096; train accuracy : 0.550203909662629; \n",
      " validation loss : 0.8434757059847277; validation accuracy : 0.6820083682008368\n",
      "Epoch 2:\t train loss : 0.7805692083426503; train accuracy : 0.7676205582576907; \n",
      " validation loss : 0.7511415265833665; validation accuracy : 0.799163179916318\n",
      "Epoch 3:\t train loss : 0.7093641441698465; train accuracy : 0.8411722791908052; \n",
      " validation loss : 0.6761276692571546; validation accuracy : 0.8786610878661087\n",
      "Epoch 4:\t train loss : 0.6785818249128099; train accuracy : 0.8716361721242913; \n",
      " validation loss : 0.6746926318545362; validation accuracy : 0.8828451882845189\n",
      "Epoch 5:\t train loss : 0.6567080748885582; train accuracy : 0.893452337433006; \n",
      " validation loss : 0.6433979273139648; validation accuracy : 0.9079497907949791\n",
      "Epoch 6:\t train loss : 0.6498925208184314; train accuracy : 0.9004391709780353; \n",
      " validation loss : 0.6533184212262543; validation accuracy : 0.895397489539749\n",
      "Epoch 7:\t train loss : 0.6276586289155675; train accuracy : 0.9227091297747761; \n",
      " validation loss : 0.6544133088774036; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6190013609935241; train accuracy : 0.9316841290002789; \n",
      " validation loss : 0.6318901767828389; validation accuracy : 0.9121338912133892\n",
      "Epoch 9:\t train loss : 0.615315659172776; train accuracy : 0.935415471359088; \n",
      " validation loss : 0.6246487939842795; validation accuracy : 0.9330543933054394\n",
      "Epoch 10:\t train loss : 0.6050177901422918; train accuracy : 0.9464460485145141; \n",
      " validation loss : 0.611984190580646; validation accuracy : 0.9288702928870293\n",
      "Epoch 11:\t train loss : 0.6003522403327317; train accuracy : 0.9508523808048577; \n",
      " validation loss : 0.6131984918186102; validation accuracy : 0.9330543933054394\n",
      "Epoch 12:\t train loss : 0.5959072873695267; train accuracy : 0.9552799033427306; \n",
      " validation loss : 0.6223196149840111; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.5960512763046716; train accuracy : 0.9552024536076087; \n",
      " validation loss : 0.6508982368243493; validation accuracy : 0.899581589958159\n",
      "Epoch 14:\t train loss : 0.5934988701076405; train accuracy : 0.9576361101645032; \n",
      " validation loss : 0.6084307931884676; validation accuracy : 0.9414225941422594\n",
      "Epoch 15:\t train loss : 0.5893901021109434; train accuracy : 0.961849375755135; \n",
      " validation loss : 0.6053690526985149; validation accuracy : 0.9456066945606695\n",
      "Epoch 16:\t train loss : 0.591273284862541; train accuracy : 0.9598620775116949; \n",
      " validation loss : 0.6230114693536803; validation accuracy : 0.9246861924686193\n",
      "Epoch 17:\t train loss : 0.5853990651878614; train accuracy : 0.965681712568543; \n",
      " validation loss : 0.6147056941214057; validation accuracy : 0.9372384937238494\n",
      "Epoch 18:\t train loss : 0.5878934097912044; train accuracy : 0.962970104402243; \n",
      " validation loss : 0.6230075306787238; validation accuracy : 0.9246861924686193\n",
      "Epoch 19:\t train loss : 0.5838751628097089; train accuracy : 0.9673072895690696; \n",
      " validation loss : 0.6127070523589991; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.5854903920675283; train accuracy : 0.9659278168468663; \n",
      " validation loss : 0.633606759492029; validation accuracy : 0.9163179916317992\n",
      "Epoch 21:\t train loss : 0.5874031036672869; train accuracy : 0.963348183029214; \n",
      " validation loss : 0.6261887748769185; validation accuracy : 0.9246861924686193\n",
      "Epoch 22:\t train loss : 0.5833967023619765; train accuracy : 0.9680608445119118; \n",
      " validation loss : 0.6099448132748396; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5797885505118519; train accuracy : 0.9712882059543356; \n",
      " validation loss : 0.6112349658596206; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5839521566217261; train accuracy : 0.9671678800458502; \n",
      " validation loss : 0.6286613717512782; validation accuracy : 0.9205020920502092\n",
      "Epoch 25:\t train loss : 0.5765619086220045; train accuracy : 0.9746713343040366; \n",
      " validation loss : 0.5989365957323957; validation accuracy : 0.9539748953974896\n",
      "Epoch 26:\t train loss : 0.579369045128284; train accuracy : 0.972069890640974; \n",
      " validation loss : 0.6183278553894935; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.58175761649371; train accuracy : 0.9692489854084699; \n",
      " validation loss : 0.6146652567814759; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5952703825358635; train accuracy : 0.9553963877443539; \n",
      " validation loss : 0.6205543845169156; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.5757240403192438; train accuracy : 0.9752808946993401; \n",
      " validation loss : 0.6283539965339816; validation accuracy : 0.9205020920502092\n",
      "Epoch 30:\t train loss : 0.5766964625884072; train accuracy : 0.9745537346262276; \n",
      " validation loss : 0.6265517990146963; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5728429640273904; train accuracy : 0.9783688466185446; \n",
      " validation loss : 0.6085137745784018; validation accuracy : 0.9456066945606695\n",
      "Epoch 32:\t train loss : 0.5753964113622855; train accuracy : 0.9757702531057344; \n",
      " validation loss : 0.6273455395764551; validation accuracy : 0.9246861924686193\n",
      "Epoch 33:\t train loss : 0.5933371584175184; train accuracy : 0.9573409337340066; \n",
      " validation loss : 0.6382953763144343; validation accuracy : 0.9163179916317992\n",
      "Epoch 34:\t train loss : 0.580566587754754; train accuracy : 0.9702265869450727; \n",
      " validation loss : 0.5998158763209345; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.5755452129074248; train accuracy : 0.9756936708076458; \n",
      " validation loss : 0.6074807771780578; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.5706331194315373; train accuracy : 0.9805073267449426; \n",
      " validation loss : 0.6037986238610772; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:\t train loss : 0.569812571118144; train accuracy : 0.9815242107871991; \n",
      " validation loss : 0.6107253472397869; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5681321680972203; train accuracy : 0.9830732054896373; \n",
      " validation loss : 0.5915035171264559; validation accuracy : 0.9623430962343096\n",
      "Epoch 39:\t train loss : 0.574008844980458; train accuracy : 0.9773054927352148; \n",
      " validation loss : 0.6011137058316454; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5693369089183801; train accuracy : 0.981968834226587; \n",
      " validation loss : 0.6061332634318014; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5650946803943973; train accuracy : 0.9862021747885622; \n",
      " validation loss : 0.5907994303924375; validation accuracy : 0.9623430962343096\n",
      "Epoch 42:\t train loss : 0.5658275441522916; train accuracy : 0.9856763840267666; \n",
      " validation loss : 0.6239862409665978; validation accuracy : 0.9246861924686193\n",
      "Epoch 43:\t train loss : 0.5694751148768845; train accuracy : 0.9818193872176957; \n",
      " validation loss : 0.6111299939279408; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5675354829449636; train accuracy : 0.9835542612844264; \n",
      " validation loss : 0.5855731217414836; validation accuracy : 0.9623430962343096\n",
      "Epoch 45:\t train loss : 0.5648778721772969; train accuracy : 0.9863980916385267; \n",
      " validation loss : 0.5954412052150828; validation accuracy : 0.9581589958158996\n",
      "Epoch 46:\t train loss : 0.5887062408092082; train accuracy : 0.9620415750178134; \n",
      " validation loss : 0.6202790308960963; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.5675322207125131; train accuracy : 0.983733820750333; \n",
      " validation loss : 0.6052727613485755; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5657970100292833; train accuracy : 0.9853966975432944; \n",
      " validation loss : 0.6078456800489563; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.5649146785658615; train accuracy : 0.9864864462963536; \n",
      " validation loss : 0.6069173650330575; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5755654658818964; train accuracy : 0.9753118745933889; \n",
      " validation loss : 0.6021486379007386; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5650683585975489; train accuracy : 0.9861511199231698; \n",
      " validation loss : 0.6157470463071489; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5645665685560989; train accuracy : 0.9867506428328016; \n",
      " validation loss : 0.5770134390115155; validation accuracy : 0.9748953974895398\n",
      "Epoch 53:\t train loss : 0.5624607208269217; train accuracy : 0.9890067226370086; \n",
      " validation loss : 0.6217191381576118; validation accuracy : 0.9246861924686193\n",
      "Epoch 54:\t train loss : 0.5623489344132014; train accuracy : 0.9887689209702902; \n",
      " validation loss : 0.594917576012071; validation accuracy : 0.9581589958158996\n",
      "Epoch 55:\t train loss : 0.5686522315121036; train accuracy : 0.9824280801759658; \n",
      " validation loss : 0.5984494748444628; validation accuracy : 0.9497907949790795\n",
      "Epoch 56:\t train loss : 0.5664131850985485; train accuracy : 0.984716007311255; \n",
      " validation loss : 0.5887124543377196; validation accuracy : 0.9623430962343096\n",
      "Epoch 57:\t train loss : 0.5670311598811261; train accuracy : 0.9842923262802441; \n",
      " validation loss : 0.6212440570634143; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.5624346847058427; train accuracy : 0.9887333560519223; \n",
      " validation loss : 0.603500660896575; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5598215708069479; train accuracy : 0.9914177019114595; \n",
      " validation loss : 0.6031268558875674; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5670145035702756; train accuracy : 0.9841939341367453; \n",
      " validation loss : 0.5930031872039514; validation accuracy : 0.9581589958158996\n",
      "Epoch 61:\t train loss : 0.562865255642885; train accuracy : 0.988329749992255; \n",
      " validation loss : 0.6176530168474411; validation accuracy : 0.9330543933054394\n",
      "Epoch 62:\t train loss : 0.5619219530034192; train accuracy : 0.9892901267077666; \n",
      " validation loss : 0.6145545466660151; validation accuracy : 0.9330543933054394\n",
      "Epoch 63:\t train loss : 0.5649707278930073; train accuracy : 0.9863889215898881; \n",
      " validation loss : 0.6152758633872111; validation accuracy : 0.9288702928870293\n",
      "Epoch 64:\t train loss : 0.5658248578488736; train accuracy : 0.9854130549273521; \n",
      " validation loss : 0.5915997915258743; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.5657533983694064; train accuracy : 0.9854222249759906; \n",
      " validation loss : 0.5959564449566593; validation accuracy : 0.9581589958158996\n",
      "Epoch 66:\t train loss : 0.5628296985056417; train accuracy : 0.9883917097803525; \n",
      " validation loss : 0.5852897520761207; validation accuracy : 0.9665271966527197\n",
      "Epoch 67:\t train loss : 0.5635409716157064; train accuracy : 0.9877365469810093; \n",
      " validation loss : 0.6049745399190641; validation accuracy : 0.9456066945606695\n",
      "Epoch 68:\t train loss : 0.5601569439203883; train accuracy : 0.9909484184764088; \n",
      " validation loss : 0.5908559857500113; validation accuracy : 0.9581589958158996\n",
      "Epoch 69:\t train loss : 0.5600318550683462; train accuracy : 0.991263669878249; \n",
      " validation loss : 0.5806428478908298; validation accuracy : 0.9665271966527197\n",
      "Epoch 70:\t train loss : 0.5588640666606386; train accuracy : 0.9925593729669444; \n",
      " validation loss : 0.5898964695945499; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5644109134182059; train accuracy : 0.9866777781219989; \n",
      " validation loss : 0.5938507656162325; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5606034727516779; train accuracy : 0.9907370116794201; \n",
      " validation loss : 0.5858781088017415; validation accuracy : 0.9623430962343096\n",
      "Epoch 73:\t train loss : 0.5653729409744427; train accuracy : 0.9858568109297067; \n",
      " validation loss : 0.6196611693547213; validation accuracy : 0.9288702928870293\n",
      "Epoch 74:\t train loss : 0.5660737573745102; train accuracy : 0.9849420366182348; \n",
      " validation loss : 0.6406618378985999; validation accuracy : 0.9079497907949791\n",
      "Epoch 75:\t train loss : 0.5643031036887861; train accuracy : 0.9870595743362558; \n",
      " validation loss : 0.5866952592840827; validation accuracy : 0.9665271966527197\n",
      "Epoch 76:\t train loss : 0.5585874586375472; train accuracy : 0.9928227020663589; \n",
      " validation loss : 0.5826821098174543; validation accuracy : 0.9665271966527197\n",
      "Epoch 77:\t train loss : 0.5577249148256095; train accuracy : 0.9935452771151523; \n",
      " validation loss : 0.5852708833924509; validation accuracy : 0.9665271966527197\n",
      "Epoch 78:\t train loss : 0.5657941830490804; train accuracy : 0.9854431673843675; \n",
      " validation loss : 0.6192400212323576; validation accuracy : 0.9288702928870293\n",
      "Epoch 79:\t train loss : 0.5746702755085058; train accuracy : 0.9764845255429226; \n",
      " validation loss : 0.6328743644447875; validation accuracy : 0.9163179916317992\n",
      "Epoch 80:\t train loss : 0.5672307243868628; train accuracy : 0.9839314724743642; \n",
      " validation loss : 0.5924536739056857; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.5643046704844344; train accuracy : 0.9868992224046593; \n",
      " validation loss : 0.6073870823248363; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5576173914434668; train accuracy : 0.9937056290467486; \n",
      " validation loss : 0.5955763924065353; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5680411407790563; train accuracy : 0.9831856005452462; \n",
      " validation loss : 0.6515871348491263; validation accuracy : 0.899581589958159\n",
      "Epoch 84:\t train loss : 0.5684371034338199; train accuracy : 0.9827898014188792; \n",
      " validation loss : 0.6111446417076957; validation accuracy : 0.9372384937238494\n",
      "Epoch 85:\t train loss : 0.5612713923997854; train accuracy : 0.9900500015489947; \n",
      " validation loss : 0.5929098540426591; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5723901228363463; train accuracy : 0.9783396015985625; \n",
      " validation loss : 0.6055687510424902; validation accuracy : 0.9414225941422594\n",
      "Epoch 87:\t train loss : 0.5605249467448267; train accuracy : 0.9907880665448124; \n",
      " validation loss : 0.5756392286217917; validation accuracy : 0.9748953974895398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88:\t train loss : 0.5580221865202273; train accuracy : 0.9932199882276402; \n",
      " validation loss : 0.5998656140319648; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.5587195897830595; train accuracy : 0.992579447938288; \n",
      " validation loss : 0.6087559685034695; validation accuracy : 0.9372384937238494\n",
      "Epoch 90:\t train loss : 0.5628549832392893; train accuracy : 0.9882531676941665; \n",
      " validation loss : 0.6051943478062303; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5608946231032739; train accuracy : 0.9902668608073361; \n",
      " validation loss : 0.5774945823072829; validation accuracy : 0.9748953974895398\n",
      "Epoch 92:\t train loss : 0.5590016996641582; train accuracy : 0.9923014963288825; \n",
      " validation loss : 0.5892365365959383; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5563401728824319; train accuracy : 0.995043216952198; \n",
      " validation loss : 0.5915025462906481; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5593820770302683; train accuracy : 0.991804950587069; \n",
      " validation loss : 0.6108025161418259; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.5590621958277551; train accuracy : 0.99229604386753; \n",
      " validation loss : 0.5872806232238906; validation accuracy : 0.9623430962343096\n",
      "Epoch 96:\t train loss : 0.5581999006036047; train accuracy : 0.9931161436227888; \n",
      " validation loss : 0.6007065804880283; validation accuracy : 0.9497907949790795\n",
      "Epoch 97:\t train loss : 0.5610615078495941; train accuracy : 0.990352613154063; \n",
      " validation loss : 0.6192602895335624; validation accuracy : 0.9288702928870293\n",
      "Epoch 98:\t train loss : 0.560933745377; train accuracy : 0.9903497630038105; \n",
      " validation loss : 0.5838786148860838; validation accuracy : 0.9623430962343096\n",
      "Epoch 99:\t train loss : 0.5712926094406918; train accuracy : 0.9797537718021004; \n",
      " validation loss : 0.603260049974226; validation accuracy : 0.9497907949790795\n",
      "Epoch 100:\t train loss : 0.5663200848604668; train accuracy : 0.9850157687660708; \n",
      " validation loss : 0.6063606139219654; validation accuracy : 0.9414225941422594\n",
      "Epoch 101:\t train loss : 0.5622377292099998; train accuracy : 0.9889711577186406; \n",
      " validation loss : 0.6059254431918585; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5624505332328869; train accuracy : 0.9889602527959355; \n",
      " validation loss : 0.5723244801475166; validation accuracy : 0.9790794979079498\n",
      "Epoch 103:\t train loss : 0.5595794388427259; train accuracy : 0.9916609560395303; \n",
      " validation loss : 0.6069302489024081; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.5620928975408465; train accuracy : 0.9890377025310574; \n",
      " validation loss : 0.5810189150743691; validation accuracy : 0.9707112970711297\n",
      "Epoch 105:\t train loss : 0.5582448818126098; train accuracy : 0.9930650887573964; \n",
      " validation loss : 0.5716382353622669; validation accuracy : 0.9832635983263598\n",
      "Epoch 106:\t train loss : 0.5588350939073112; train accuracy : 0.992615012856656; \n",
      " validation loss : 0.5862210093657618; validation accuracy : 0.9665271966527197\n",
      "Epoch 107:\t train loss : 0.5579994598687996; train accuracy : 0.9933493602651878; \n",
      " validation loss : 0.5710469936847891; validation accuracy : 0.9790794979079498\n",
      "Epoch 108:\t train loss : 0.5558847276402165; train accuracy : 0.9954769354688807; \n",
      " validation loss : 0.6014172629153752; validation accuracy : 0.9497907949790795\n",
      "Epoch 109:\t train loss : 0.5576557815855292; train accuracy : 0.9936491217200037; \n",
      " validation loss : 0.6041795929903905; validation accuracy : 0.9456066945606695\n",
      "Epoch 110:\t train loss : 0.5565684427998574; train accuracy : 0.9947899253384553; \n",
      " validation loss : 0.5889163971296045; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5583795529020279; train accuracy : 0.9929566591282257; \n",
      " validation loss : 0.5919671550775486; validation accuracy : 0.9581589958158996\n",
      "Epoch 112:\t train loss : 0.5667024310611074; train accuracy : 0.9844007559094148; \n",
      " validation loss : 0.6052065341954482; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.557340963921787; train accuracy : 0.9939379782521144; \n",
      " validation loss : 0.5846324038963899; validation accuracy : 0.9665271966527197\n",
      "Epoch 114:\t train loss : 0.5563404334560523; train accuracy : 0.995043216952198; \n",
      " validation loss : 0.5784924969056905; validation accuracy : 0.9707112970711297\n",
      "Epoch 115:\t train loss : 0.5577930168693; train accuracy : 0.9934887697884073; \n",
      " validation loss : 0.5963848967342491; validation accuracy : 0.9581589958158996\n",
      "Epoch 116:\t train loss : 0.5573983942542695; train accuracy : 0.9938806034883361; \n",
      " validation loss : 0.5954015785132443; validation accuracy : 0.9497907949790795\n",
      "Epoch 117:\t train loss : 0.5585337632344006; train accuracy : 0.9927243099228601; \n",
      " validation loss : 0.5945547791826552; validation accuracy : 0.9581589958158996\n",
      "Epoch 118:\t train loss : 0.5603120562824978; train accuracy : 0.9909639084234332; \n",
      " validation loss : 0.5847840909155217; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.5566757593434799; train accuracy : 0.9946915331949565; \n",
      " validation loss : 0.5809699975312714; validation accuracy : 0.9707112970711297\n",
      "Epoch 120:\t train loss : 0.5609445533467889; train accuracy : 0.9902823507543604; \n",
      " validation loss : 0.6002412694284271; validation accuracy : 0.9497907949790795\n",
      "Epoch 121:\t train loss : 0.5611197356284645; train accuracy : 0.9902149385049103; \n",
      " validation loss : 0.5946389481364343; validation accuracy : 0.9581589958158996\n",
      "Epoch 122:\t train loss : 0.5583289060490418; train accuracy : 0.9930186189163233; \n",
      " validation loss : 0.5932270505541049; validation accuracy : 0.9539748953974896\n",
      "Epoch 123:\t train loss : 0.561353594656218; train accuracy : 0.9899880417608972; \n",
      " validation loss : 0.5853610798665734; validation accuracy : 0.9665271966527197\n",
      "Epoch 124:\t train loss : 0.5597236608023717; train accuracy : 0.9916081663000712; \n",
      " validation loss : 0.5811002293388762; validation accuracy : 0.9707112970711297\n",
      "Epoch 125:\t train loss : 0.5571550755040741; train accuracy : 0.994247777192602; \n",
      " validation loss : 0.5800242929236722; validation accuracy : 0.9707112970711297\n",
      "Epoch 126:\t train loss : 0.557664200926576; train accuracy : 0.9936281793116267; \n",
      " validation loss : 0.5810105368241156; validation accuracy : 0.9665271966527197\n",
      "Epoch 127:\t train loss : 0.5574575781653506; train accuracy : 0.9938350010842962; \n",
      " validation loss : 0.599891164355275; validation accuracy : 0.9497907949790795\n",
      "Epoch 128:\t train loss : 0.5577757236807943; train accuracy : 0.9936327643359459; \n",
      " validation loss : 0.5904052188715976; validation accuracy : 0.9623430962343096\n",
      "Epoch 129:\t train loss : 0.5613819785101085; train accuracy : 0.9898796121317265; \n",
      " validation loss : 0.5866437403112726; validation accuracy : 0.9623430962343096\n",
      "Epoch 130:\t train loss : 0.5607008977401147; train accuracy : 0.9904883050899966; \n",
      " validation loss : 0.5953891330566231; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5571543867391626; train accuracy : 0.9941858174045045; \n",
      " validation loss : 0.5932234077822367; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.5594310010282174; train accuracy : 0.9918058180241024; \n",
      " validation loss : 0.5888812587737005; validation accuracy : 0.9623430962343096\n",
      "Epoch 133:\t train loss : 0.558016416883087; train accuracy : 0.9934012825676136; \n",
      " validation loss : 0.6033238409198307; validation accuracy : 0.9456066945606695\n",
      "Epoch 134:\t train loss : 0.5586182895519737; train accuracy : 0.9926933300288113; \n",
      " validation loss : 0.5751309503522797; validation accuracy : 0.9748953974895398\n",
      "Epoch 135:\t train loss : 0.5564557912355492; train accuracy : 0.9949038074289785; \n",
      " validation loss : 0.5709973011038195; validation accuracy : 0.9790794979079498\n",
      "Epoch 136:\t train loss : 0.5556164820498236; train accuracy : 0.9957402645682951; \n",
      " validation loss : 0.60219379519115; validation accuracy : 0.9497907949790795\n",
      "Epoch 137:\t train loss : 0.5567124159253714; train accuracy : 0.9947279655503578; \n",
      " validation loss : 0.5882642897609176; validation accuracy : 0.9581589958158996\n",
      "Epoch 138:\t train loss : 0.5562895167073555; train accuracy : 0.9950741968462468; \n",
      " validation loss : 0.5816459807687071; validation accuracy : 0.9707112970711297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139:\t train loss : 0.5557415464391487; train accuracy : 0.9957712444623439; \n",
      " validation loss : 0.5868974327018138; validation accuracy : 0.9665271966527197\n",
      "Epoch 140:\t train loss : 0.5547652531384392; train accuracy : 0.9966587564670528; \n",
      " validation loss : 0.5830129146308312; validation accuracy : 0.9665271966527197\n",
      "Epoch 141:\t train loss : 0.5580044628033884; train accuracy : 0.9932974379627622; \n",
      " validation loss : 0.573455423551298; validation accuracy : 0.9790794979079498\n",
      "Epoch 142:\t train loss : 0.555875928623216; train accuracy : 0.9954714830075281; \n",
      " validation loss : 0.5895125450296232; validation accuracy : 0.9581589958158996\n",
      "Epoch 143:\t train loss : 0.5580375208497975; train accuracy : 0.9932874004770904; \n",
      " validation loss : 0.5909145506619584; validation accuracy : 0.9623430962343096\n",
      "Epoch 144:\t train loss : 0.5575017907524294; train accuracy : 0.9938140586759193; \n",
      " validation loss : 0.5808608430422061; validation accuracy : 0.9707112970711297\n",
      "Epoch 145:\t train loss : 0.5609980105679755; train accuracy : 0.9903342730567861; \n",
      " validation loss : 0.5810666038293363; validation accuracy : 0.9707112970711297\n",
      "Epoch 146:\t train loss : 0.5568677784781642; train accuracy : 0.9945475386474179; \n",
      " validation loss : 0.5807252844520778; validation accuracy : 0.9707112970711297\n",
      "Epoch 147:\t train loss : 0.5582283026293059; train accuracy : 0.9931634809008953; \n",
      " validation loss : 0.603294534327054; validation accuracy : 0.9456066945606695\n",
      "Epoch 148:\t train loss : 0.5555191342098987; train accuracy : 0.9959881037206852; \n",
      " validation loss : 0.576793261540108; validation accuracy : 0.9707112970711297\n",
      "Epoch 149:\t train loss : 0.5556593978649189; train accuracy : 0.9957712444623439; \n",
      " validation loss : 0.5918405277117952; validation accuracy : 0.9581589958158996\n",
      "Epoch 150:\t train loss : 0.5586074607124313; train accuracy : 0.9926924625917779; \n",
      " validation loss : 0.5814110172520504; validation accuracy : 0.9707112970711297\n",
      "Epoch 151:\t train loss : 0.5590796848543406; train accuracy : 0.9922185941324081; \n",
      " validation loss : 0.573195649471551; validation accuracy : 0.9790794979079498\n",
      "Epoch 152:\t train loss : 0.5629188813770023; train accuracy : 0.9882924501998203; \n",
      " validation loss : 0.599625971398057; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.5673512700211211; train accuracy : 0.9838723628365191; \n",
      " validation loss : 0.5913138363449418; validation accuracy : 0.9581589958158996\n",
      "Epoch 154:\t train loss : 0.5591506135964418; train accuracy : 0.9920172248210911; \n",
      " validation loss : 0.5893736843409328; validation accuracy : 0.9623430962343096\n",
      "Epoch 155:\t train loss : 0.5553227757142128; train accuracy : 0.9961275132439047; \n",
      " validation loss : 0.6186899316847736; validation accuracy : 0.9330543933054394\n",
      "Epoch 156:\t train loss : 0.5557194488655707; train accuracy : 0.9956008550450758; \n",
      " validation loss : 0.5706372804056777; validation accuracy : 0.9790794979079498\n",
      "Epoch 157:\t train loss : 0.555531346105507; train accuracy : 0.9959052015242108; \n",
      " validation loss : 0.5906030499376154; validation accuracy : 0.9581589958158996\n",
      "Epoch 158:\t train loss : 0.5576848258009381; train accuracy : 0.9937110815081013; \n",
      " validation loss : 0.5864805700612634; validation accuracy : 0.9623430962343096\n",
      "Epoch 159:\t train loss : 0.5566238054313717; train accuracy : 0.9947643979057591; \n",
      " validation loss : 0.5855552834739599; validation accuracy : 0.9665271966527197\n",
      "Epoch 160:\t train loss : 0.5553122284071262; train accuracy : 0.9961011183741751; \n",
      " validation loss : 0.602078068533795; validation accuracy : 0.9497907949790795\n",
      "Epoch 161:\t train loss : 0.5585495479171159; train accuracy : 0.9928117971436538; \n",
      " validation loss : 0.5975225237364818; validation accuracy : 0.9539748953974896\n",
      "Epoch 162:\t train loss : 0.5582381832646438; train accuracy : 0.993070541218749; \n",
      " validation loss : 0.5917270764386112; validation accuracy : 0.9581589958158996\n",
      "Epoch 163:\t train loss : 0.5586716830573255; train accuracy : 0.9927544223798754; \n",
      " validation loss : 0.6134358899708129; validation accuracy : 0.9372384937238494\n",
      "Epoch 164:\t train loss : 0.5850104761663929; train accuracy : 0.9656470150872084; \n",
      " validation loss : 0.6223590907214345; validation accuracy : 0.9288702928870293\n",
      "Epoch 165:\t train loss : 0.5613702082058729; train accuracy : 0.9899461569441432; \n",
      " validation loss : 0.6124165181383174; validation accuracy : 0.9372384937238494\n",
      "Epoch 166:\t train loss : 0.5572296152143683; train accuracy : 0.9940564453669568; \n",
      " validation loss : 0.5755419407491463; validation accuracy : 0.9790794979079498\n",
      "Epoch 167:\t train loss : 0.5543385834430977; train accuracy : 0.997072400012392; \n",
      " validation loss : 0.5792632621067804; validation accuracy : 0.9748953974895398\n",
      "Epoch 168:\t train loss : 0.5550422706065992; train accuracy : 0.9964373121843924; \n",
      " validation loss : 0.6000045852938617; validation accuracy : 0.9497907949790795\n",
      "Epoch 169:\t train loss : 0.5546639478297826; train accuracy : 0.996726168716503; \n",
      " validation loss : 0.589167605130197; validation accuracy : 0.9623430962343096\n",
      "Epoch 170:\t train loss : 0.554087786250744; train accuracy : 0.9973448991604449; \n",
      " validation loss : 0.5862857699855135; validation accuracy : 0.9665271966527197\n",
      "Epoch 171:\t train loss : 0.554681861131124; train accuracy : 0.9966796988754298; \n",
      " validation loss : 0.5952990679025695; validation accuracy : 0.9581589958158996\n",
      "Epoch 172:\t train loss : 0.5569768045736642; train accuracy : 0.9943616592831253; \n",
      " validation loss : 0.5941937588624379; validation accuracy : 0.9581589958158996\n",
      "Epoch 173:\t train loss : 0.5569157332892003; train accuracy : 0.9945056538306639; \n",
      " validation loss : 0.5900708700928022; validation accuracy : 0.9623430962343096\n",
      "Epoch 174:\t train loss : 0.5582132371936939; train accuracy : 0.9932044982806159; \n",
      " validation loss : 0.5993459976454965; validation accuracy : 0.9497907949790795\n",
      "Epoch 175:\t train loss : 0.5590059614887511; train accuracy : 0.9922650639734812; \n",
      " validation loss : 0.6024870936275687; validation accuracy : 0.9497907949790795\n",
      "Epoch 176:\t train loss : 0.5565337896473723; train accuracy : 0.9948619226122246; \n",
      " validation loss : 0.5996040088315772; validation accuracy : 0.9497907949790795\n",
      "Epoch 177:\t train loss : 0.5615632977322271; train accuracy : 0.9897711825025558; \n",
      " validation loss : 0.58089113491232; validation accuracy : 0.9707112970711297\n",
      "Epoch 178:\t train loss : 0.5579266213976565; train accuracy : 0.9934368474859816; \n",
      " validation loss : 0.6044417643701603; validation accuracy : 0.9497907949790795\n",
      "Epoch 179:\t train loss : 0.5608048265619132; train accuracy : 0.9905821122091762; \n",
      " validation loss : 0.5736238562859247; validation accuracy : 0.9790794979079498\n",
      "Epoch 180:\t train loss : 0.5603860924668755; train accuracy : 0.9907525016264445; \n",
      " validation loss : 0.5980477896515448; validation accuracy : 0.9539748953974896\n",
      "Epoch 181:\t train loss : 0.5561569180442076; train accuracy : 0.995223643855138; \n",
      " validation loss : 0.5758860054075984; validation accuracy : 0.9748953974895398\n",
      "Epoch 182:\t train loss : 0.5550027130184417; train accuracy : 0.9963698999349422; \n",
      " validation loss : 0.5886952325602819; validation accuracy : 0.9623430962343096\n",
      "Epoch 183:\t train loss : 0.5543455462460825; train accuracy : 0.9970049877629419; \n",
      " validation loss : 0.5769682787727712; validation accuracy : 0.9748953974895398\n",
      "Epoch 184:\t train loss : 0.5546514395305465; train accuracy : 0.9967106787694786; \n",
      " validation loss : 0.588991241649598; validation accuracy : 0.9581589958158996\n",
      "Epoch 185:\t train loss : 0.555003612298079; train accuracy : 0.9964473496700641; \n",
      " validation loss : 0.583695274928778; validation accuracy : 0.9665271966527197\n",
      "Epoch 186:\t train loss : 0.5596412244695415; train accuracy : 0.9916509185538586; \n",
      " validation loss : 0.5772829565091703; validation accuracy : 0.9748953974895398\n",
      "Epoch 187:\t train loss : 0.5686469694320749; train accuracy : 0.9826004523064531; \n",
      " validation loss : 0.6138843515372491; validation accuracy : 0.9372384937238494\n",
      "Epoch 188:\t train loss : 0.5601186336612751; train accuracy : 0.991118807893677; \n",
      " validation loss : 0.5927783574141496; validation accuracy : 0.9581589958158996\n",
      "Epoch 189:\t train loss : 0.5551603882460526; train accuracy : 0.9962459803587471; \n",
      " validation loss : 0.5803312731342539; validation accuracy : 0.9707112970711297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190:\t train loss : 0.5562366719749652; train accuracy : 0.9951206666873199; \n",
      " validation loss : 0.5774398473552338; validation accuracy : 0.9748953974895398\n",
      "Epoch 191:\t train loss : 0.5578110102076479; train accuracy : 0.9933949626692277; \n",
      " validation loss : 0.6011448481217603; validation accuracy : 0.9456066945606695\n",
      "Epoch 192:\t train loss : 0.5565958769579094; train accuracy : 0.9947434554973822; \n",
      " validation loss : 0.5907903146526572; validation accuracy : 0.9623430962343096\n",
      "Epoch 193:\t train loss : 0.5554154020623208; train accuracy : 0.996019083614734; \n",
      " validation loss : 0.5956888723559294; validation accuracy : 0.9539748953974896\n",
      "Epoch 194:\t train loss : 0.5544220966703802; train accuracy : 0.9969894978159175; \n",
      " validation loss : 0.5765112417014712; validation accuracy : 0.9748953974895398\n",
      "Epoch 195:\t train loss : 0.5543717409434561; train accuracy : 0.9970150252486136; \n",
      " validation loss : 0.5758886544640325; validation accuracy : 0.9748953974895398\n",
      "Epoch 196:\t train loss : 0.5541420232312788; train accuracy : 0.9972892592707333; \n",
      " validation loss : 0.5887160704133818; validation accuracy : 0.9623430962343096\n",
      "Epoch 197:\t train loss : 0.5616368468124607; train accuracy : 0.9896573004120326; \n",
      " validation loss : 0.6137467232639807; validation accuracy : 0.9372384937238494\n",
      "Epoch 198:\t train loss : 0.5582722872049818; train accuracy : 0.9930860311657734; \n",
      " validation loss : 0.5837807606833533; validation accuracy : 0.9665271966527197\n",
      "Epoch 199:\t train loss : 0.5547012952819895; train accuracy : 0.9966796988754298; \n",
      " validation loss : 0.5853367958178273; validation accuracy : 0.9665271966527197\n",
      "Epoch 200:\t train loss : 0.5554730400784481; train accuracy : 0.9959152390098825; \n",
      " validation loss : 0.5859348022558194; validation accuracy : 0.9665271966527197\n",
      "Epoch 201:\t train loss : 0.556543959297522; train accuracy : 0.9948108677468323; \n",
      " validation loss : 0.5943227394586267; validation accuracy : 0.9581589958158996\n",
      "Epoch 202:\t train loss : 0.5564000753579086; train accuracy : 0.9949758047027479; \n",
      " validation loss : 0.5739680330118145; validation accuracy : 0.9748953974895398\n",
      "Epoch 203:\t train loss : 0.5547334573162802; train accuracy : 0.9966432665200284; \n",
      " validation loss : 0.5897108242385847; validation accuracy : 0.9623430962343096\n",
      "Epoch 204:\t train loss : 0.5555595554859962; train accuracy : 0.9957657920009914; \n",
      " validation loss : 0.5778484866624366; validation accuracy : 0.9748953974895398\n",
      "Epoch 205:\t train loss : 0.5549824127387102; train accuracy : 0.9963753523962948; \n",
      " validation loss : 0.5849875122391726; validation accuracy : 0.9665271966527197\n",
      "Epoch 206:\t train loss : 0.5593044173220874; train accuracy : 0.9919753400043372; \n",
      " validation loss : 0.5865450305544392; validation accuracy : 0.9665271966527197\n",
      "Early stopping at epoch 206\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5557194488655707; Train accuracy : 0.9956008550450758; \n",
      " Validation loss : 0.5706372804056777; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 3 ! ---\n",
      "Epoch 1:\t train loss : 0.9653949368873377; train accuracy : 0.5665293224697171; \n",
      " validation loss : 0.8410410915328159; validation accuracy : 0.702928870292887\n",
      "Epoch 2:\t train loss : 0.76573272923703; train accuracy : 0.7829362743579417; \n",
      " validation loss : 0.7368056068653555; validation accuracy : 0.803347280334728\n",
      "Epoch 3:\t train loss : 0.7013235442850193; train accuracy : 0.8494717928064686; \n",
      " validation loss : 0.7038940790623622; validation accuracy : 0.8451882845188284\n",
      "Epoch 4:\t train loss : 0.6746730786030782; train accuracy : 0.8757055670869606; \n",
      " validation loss : 0.6779829024974485; validation accuracy : 0.8744769874476988\n",
      "Epoch 5:\t train loss : 0.6575401576280255; train accuracy : 0.893692493571672; \n",
      " validation loss : 0.6598328026120698; validation accuracy : 0.891213389121339\n",
      "Epoch 6:\t train loss : 0.6475378266543468; train accuracy : 0.9029492859134421; \n",
      " validation loss : 0.6611893472048361; validation accuracy : 0.8828451882845189\n",
      "Epoch 7:\t train loss : 0.6307054119062587; train accuracy : 0.9201772049939589; \n",
      " validation loss : 0.6315122387567701; validation accuracy : 0.9246861924686193\n",
      "Epoch 8:\t train loss : 0.6260552426880985; train accuracy : 0.9241271414851762; \n",
      " validation loss : 0.684966418904604; validation accuracy : 0.8619246861924686\n",
      "Epoch 9:\t train loss : 0.6191282130453354; train accuracy : 0.9317512934105765; \n",
      " validation loss : 0.6297118866948713; validation accuracy : 0.9288702928870293\n",
      "Epoch 10:\t train loss : 0.6063364379153569; train accuracy : 0.9448402986461786; \n",
      " validation loss : 0.6628178376251886; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.6013529920652864; train accuracy : 0.9494810867746832; \n",
      " validation loss : 0.6454430003114981; validation accuracy : 0.9037656903765691\n",
      "Epoch 12:\t train loss : 0.6032758517599468; train accuracy : 0.9477709966231915; \n",
      " validation loss : 0.6607205419085758; validation accuracy : 0.8828451882845189\n",
      "Epoch 13:\t train loss : 0.6090791424343023; train accuracy : 0.9416245856439172; \n",
      " validation loss : 0.6320025100482652; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.6090472669813733; train accuracy : 0.9417423092413024; \n",
      " validation loss : 0.6098654431010562; validation accuracy : 0.9456066945606695\n",
      "Epoch 15:\t train loss : 0.5909070845632742; train accuracy : 0.9605471049289012; \n",
      " validation loss : 0.6427292071352956; validation accuracy : 0.9037656903765691\n",
      "Epoch 16:\t train loss : 0.5937914003539697; train accuracy : 0.9571641004987763; \n",
      " validation loss : 0.6036806845842922; validation accuracy : 0.9414225941422594\n",
      "Epoch 17:\t train loss : 0.5874709743853277; train accuracy : 0.9637163480900895; \n",
      " validation loss : 0.6088169689708617; validation accuracy : 0.9414225941422594\n",
      "Epoch 18:\t train loss : 0.5871419125214237; train accuracy : 0.9640199510517674; \n",
      " validation loss : 0.6183455584362105; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5885807148739949; train accuracy : 0.9622943709532513; \n",
      " validation loss : 0.632752849013937; validation accuracy : 0.9163179916317992\n",
      "Epoch 20:\t train loss : 0.5852659880429468; train accuracy : 0.9661265838470833; \n",
      " validation loss : 0.6197051214498269; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5819433707218229; train accuracy : 0.9693206109235106; \n",
      " validation loss : 0.6070033491176253; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5929394405974683; train accuracy : 0.9576597788035565; \n",
      " validation loss : 0.6345675076396807; validation accuracy : 0.9163179916317992\n",
      "Epoch 23:\t train loss : 0.584532662629463; train accuracy : 0.966331051147805; \n",
      " validation loss : 0.6225869478725309; validation accuracy : 0.9205020920502092\n",
      "Epoch 24:\t train loss : 0.5815311483900032; train accuracy : 0.9697636234084079; \n",
      " validation loss : 0.6173216904834412; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5814926234322818; train accuracy : 0.9694879023513739; \n",
      " validation loss : 0.5994915170143574; validation accuracy : 0.9497907949790795\n",
      "Epoch 26:\t train loss : 0.5775859384458009; train accuracy : 0.9739366151367762; \n",
      " validation loss : 0.6277139086681656; validation accuracy : 0.9205020920502092\n",
      "Epoch 27:\t train loss : 0.5789038144867541; train accuracy : 0.9721583692183773; \n",
      " validation loss : 0.5844504786275765; validation accuracy : 0.9623430962343096\n",
      "Epoch 28:\t train loss : 0.582650673376036; train accuracy : 0.968310666377521; \n",
      " validation loss : 0.6190896443844097; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5839152299469172; train accuracy : 0.9669754329440193; \n",
      " validation loss : 0.6052303558258741; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5759386335899438; train accuracy : 0.9753740822206388; \n",
      " validation loss : 0.6108513169902513; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5817179743218917; train accuracy : 0.9692400631989838; \n",
      " validation loss : 0.6719280603543073; validation accuracy : 0.8744769874476988\n",
      "Epoch 32:\t train loss : 0.5846881519006022; train accuracy : 0.9662443074444685; \n",
      " validation loss : 0.594629108184291; validation accuracy : 0.9497907949790795\n",
      "Epoch 33:\t train loss : 0.5709388057411404; train accuracy : 0.9803680411412993; \n",
      " validation loss : 0.6262316587520355; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:\t train loss : 0.5726865638556692; train accuracy : 0.9784194058056321; \n",
      " validation loss : 0.6031430423429974; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.5815531863300888; train accuracy : 0.9691316335698131; \n",
      " validation loss : 0.5958263300753299; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5773904066427817; train accuracy : 0.9736608940797422; \n",
      " validation loss : 0.6177364474042368; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5731143243553036; train accuracy : 0.9778803556491836; \n",
      " validation loss : 0.6089690058620034; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5696558677215344; train accuracy : 0.9815514730939621; \n",
      " validation loss : 0.6040483614215475; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5687448979041885; train accuracy : 0.9825304377459029; \n",
      " validation loss : 0.6104404461466442; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5680936000694464; train accuracy : 0.983202701446761; \n",
      " validation loss : 0.610650446668992; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5715181411116973; train accuracy : 0.979398370457573; \n",
      " validation loss : 0.615572765156253; validation accuracy : 0.9330543933054394\n",
      "Epoch 42:\t train loss : 0.5680933086417246; train accuracy : 0.983078781870566; \n",
      " validation loss : 0.5697711825058485; validation accuracy : 0.9832635983263598\n",
      "Epoch 43:\t train loss : 0.5683043337746309; train accuracy : 0.9828092567923418; \n",
      " validation loss : 0.6190964615193973; validation accuracy : 0.9246861924686193\n",
      "Epoch 44:\t train loss : 0.5735832882714001; train accuracy : 0.9774497351219059; \n",
      " validation loss : 0.5860230406328536; validation accuracy : 0.9623430962343096\n",
      "Epoch 45:\t train loss : 0.5691798607838703; train accuracy : 0.9821493850491031; \n",
      " validation loss : 0.6120659427008388; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5676094142691037; train accuracy : 0.9835682641965364; \n",
      " validation loss : 0.5993967381710174; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5769875884559935; train accuracy : 0.9741720623315469; \n",
      " validation loss : 0.651239481812464; validation accuracy : 0.895397489539749\n",
      "Epoch 48:\t train loss : 0.5763256790212259; train accuracy : 0.9746088788376344; \n",
      " validation loss : 0.6110453181702244; validation accuracy : 0.9372384937238494\n",
      "Epoch 49:\t train loss : 0.5656902740426016; train accuracy : 0.9856748969918523; \n",
      " validation loss : 0.608886871502747; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5654386748645459; train accuracy : 0.9859351281018619; \n",
      " validation loss : 0.6034141550118994; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5768062481108818; train accuracy : 0.9742247281514297; \n",
      " validation loss : 0.5923002713651914; validation accuracy : 0.9581589958158996\n",
      "Epoch 52:\t train loss : 0.5654275112282389; train accuracy : 0.9855974472567304; \n",
      " validation loss : 0.5824472699203552; validation accuracy : 0.9665271966527197\n",
      "Epoch 53:\t train loss : 0.5639951736137444; train accuracy : 0.9873447132810805; \n",
      " validation loss : 0.5841837241620362; validation accuracy : 0.9707112970711297\n",
      "Epoch 54:\t train loss : 0.5658992796076869; train accuracy : 0.9851451408036185; \n",
      " validation loss : 0.6041225414264353; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.565774944156253; train accuracy : 0.9855447814368475; \n",
      " validation loss : 0.6012958866708842; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5633690049021332; train accuracy : 0.9877164720096657; \n",
      " validation loss : 0.6276344058951725; validation accuracy : 0.9205020920502092\n",
      "Epoch 57:\t train loss : 0.5626954254158977; train accuracy : 0.9884475975092165; \n",
      " validation loss : 0.6015441057963284; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.5777445518937787; train accuracy : 0.9732147836054401; \n",
      " validation loss : 0.6049380477114015; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5633678713993109; train accuracy : 0.987784627776573; \n",
      " validation loss : 0.5957212764632306; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5622990787195531; train accuracy : 0.9890981752842405; \n",
      " validation loss : 0.5873861400501886; validation accuracy : 0.9623430962343096\n",
      "Epoch 61:\t train loss : 0.5704441351859074; train accuracy : 0.9807181139440503; \n",
      " validation loss : 0.6062241466280974; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5695759975556579; train accuracy : 0.98135320177205; \n",
      " validation loss : 0.6184965722693117; validation accuracy : 0.9330543933054394\n",
      "Epoch 63:\t train loss : 0.5644648109911604; train accuracy : 0.9867994671458223; \n",
      " validation loss : 0.6048753086243637; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5652134245312036; train accuracy : 0.9859475200594814; \n",
      " validation loss : 0.609076895019527; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.5626020255782475; train accuracy : 0.9886303788841042; \n",
      " validation loss : 0.5785757878565656; validation accuracy : 0.9748953974895398\n",
      "Epoch 66:\t train loss : 0.5709288422093015; train accuracy : 0.9801449859041482; \n",
      " validation loss : 0.5914175571251746; validation accuracy : 0.9623430962343096\n",
      "Epoch 67:\t train loss : 0.5591372357355249; train accuracy : 0.992189968710307; \n",
      " validation loss : 0.5778103086612698; validation accuracy : 0.9748953974895398\n",
      "Epoch 68:\t train loss : 0.5593142027152317; train accuracy : 0.992016481303634; \n",
      " validation loss : 0.6037608197023742; validation accuracy : 0.9497907949790795\n",
      "Epoch 69:\t train loss : 0.5618743066563612; train accuracy : 0.9894265621611574; \n",
      " validation loss : 0.5973512723777515; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5605576497635671; train accuracy : 0.990761795594659; \n",
      " validation loss : 0.5907285580058218; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5743599181801198; train accuracy : 0.9765761021097308; \n",
      " validation loss : 0.5764781138821364; validation accuracy : 0.9748953974895398\n",
      "Epoch 72:\t train loss : 0.5646848667809192; train accuracy : 0.9864215124384275; \n",
      " validation loss : 0.6025645213454515; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5727693946563491; train accuracy : 0.9780507450664518; \n",
      " validation loss : 0.6020246723506741; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5615143218594556; train accuracy : 0.9898478887202206; \n",
      " validation loss : 0.6008397178145911; validation accuracy : 0.9497907949790795\n",
      "Epoch 75:\t train loss : 0.5593665531971557; train accuracy : 0.9919235416214877; \n",
      " validation loss : 0.5988802836100832; validation accuracy : 0.9539748953974896\n",
      "Epoch 76:\t train loss : 0.5605626051623241; train accuracy : 0.9907432076582298; \n",
      " validation loss : 0.6198084162375244; validation accuracy : 0.9288702928870293\n",
      "Epoch 77:\t train loss : 0.5582500168198979; train accuracy : 0.9930078379131944; \n",
      " validation loss : 0.5866835091341469; validation accuracy : 0.9665271966527197\n",
      "Epoch 78:\t train loss : 0.5596198710847463; train accuracy : 0.9917438582360049; \n",
      " validation loss : 0.6043977030472568; validation accuracy : 0.9414225941422594\n",
      "Epoch 79:\t train loss : 0.5641018789388751; train accuracy : 0.9871898138108368; \n",
      " validation loss : 0.6029146491185817; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5613872150072198; train accuracy : 0.9898447907308157; \n",
      " validation loss : 0.5847618096574111; validation accuracy : 0.9665271966527197\n",
      "Epoch 81:\t train loss : 0.563232544514436; train accuracy : 0.987883763437529; \n",
      " validation loss : 0.6251505526376979; validation accuracy : 0.9205020920502092\n",
      "Epoch 82:\t train loss : 0.5675190837884335; train accuracy : 0.9834319526627219; \n",
      " validation loss : 0.6050422549997077; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5587662999544103; train accuracy : 0.9925927073329409; \n",
      " validation loss : 0.5959903676365974; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.5627277517216336; train accuracy : 0.9884011276681434; \n",
      " validation loss : 0.5990260505815219; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85:\t train loss : 0.561289286206991; train accuracy : 0.9899315344341523; \n",
      " validation loss : 0.5960906990817504; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5619949259805931; train accuracy : 0.9892933486167477; \n",
      " validation loss : 0.6057777810099026; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.5588098433289994; train accuracy : 0.9925617274388921; \n",
      " validation loss : 0.5899724084306293; validation accuracy : 0.9623430962343096\n",
      "Epoch 88:\t train loss : 0.5629989106449962; train accuracy : 0.988385637721119; \n",
      " validation loss : 0.5929169246117345; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.566240602514802; train accuracy : 0.9849592614393259; \n",
      " validation loss : 0.5875414739156251; validation accuracy : 0.9623430962343096\n",
      "Epoch 90:\t train loss : 0.5743545572640112; train accuracy : 0.9764614765017504; \n",
      " validation loss : 0.6551486406586282; validation accuracy : 0.895397489539749\n",
      "Epoch 91:\t train loss : 0.6068743457235714; train accuracy : 0.9438737259518573; \n",
      " validation loss : 0.6163805329730997; validation accuracy : 0.9330543933054394\n",
      "Epoch 92:\t train loss : 0.5764381080240759; train accuracy : 0.974568604975371; \n",
      " validation loss : 0.6050273116128085; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 92\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5680933086417246; Train accuracy : 0.983078781870566; \n",
      " Validation loss : 0.5697711825058485; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 4 ! ---\n",
      "Epoch 1:\t train loss : 0.9807646076330343; train accuracy : 0.53916613742681; \n",
      " validation loss : 0.9084908038198816; validation accuracy : 0.6359832635983264\n",
      "Epoch 2:\t train loss : 0.7840126767243131; train accuracy : 0.7629687645218254; \n",
      " validation loss : 0.7653046658575802; validation accuracy : 0.7866108786610879\n",
      "Epoch 3:\t train loss : 0.7102497088655205; train accuracy : 0.8392981892251928; \n",
      " validation loss : 0.7294218760441484; validation accuracy : 0.8158995815899581\n",
      "Epoch 4:\t train loss : 0.6652648644003346; train accuracy : 0.8851554028935221; \n",
      " validation loss : 0.7137060346347732; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.649773230563132; train accuracy : 0.9006265683571362; \n",
      " validation loss : 0.6768238081197839; validation accuracy : 0.8744769874476988\n",
      "Epoch 6:\t train loss : 0.6355539154167384; train accuracy : 0.9152990334273057; \n",
      " validation loss : 0.6623861822186451; validation accuracy : 0.895397489539749\n",
      "Epoch 7:\t train loss : 0.6210521172012355; train accuracy : 0.9292140400879829; \n",
      " validation loss : 0.653361687689942; validation accuracy : 0.891213389121339\n",
      "Epoch 8:\t train loss : 0.6148822995668551; train accuracy : 0.9360073499798631; \n",
      " validation loss : 0.66918849906417; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.605324814835512; train accuracy : 0.9455526425849624; \n",
      " validation loss : 0.6705951107700198; validation accuracy : 0.8744769874476988\n",
      "Epoch 10:\t train loss : 0.6000263807920575; train accuracy : 0.9513234223488956; \n",
      " validation loss : 0.6546546884797657; validation accuracy : 0.899581589958159\n",
      "Epoch 11:\t train loss : 0.5963361613755533; train accuracy : 0.9547519284984045; \n",
      " validation loss : 0.639283498502829; validation accuracy : 0.9163179916317992\n",
      "Epoch 12:\t train loss : 0.5964159863691173; train accuracy : 0.954748443260324; \n",
      " validation loss : 0.6509624527507308; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.5901834589013824; train accuracy : 0.9610770547414728; \n",
      " validation loss : 0.6343979253083852; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5892537859433378; train accuracy : 0.9620409166950649; \n",
      " validation loss : 0.6513717718570222; validation accuracy : 0.899581589958159\n",
      "Epoch 15:\t train loss : 0.5842258126466954; train accuracy : 0.9671766086309985; \n",
      " validation loss : 0.6352730846386162; validation accuracy : 0.9163179916317992\n",
      "Epoch 16:\t train loss : 0.5900949199509414; train accuracy : 0.9610425896093435; \n",
      " validation loss : 0.6307360030315801; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.5829202093136321; train accuracy : 0.9681249806375662; \n",
      " validation loss : 0.609582207468953; validation accuracy : 0.9414225941422594\n",
      "Epoch 18:\t train loss : 0.580682041143441; train accuracy : 0.9707462669227671; \n",
      " validation loss : 0.6328453100977102; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.5825296262779056; train accuracy : 0.9685449518262648; \n",
      " validation loss : 0.6336852265800343; validation accuracy : 0.9205020920502092\n",
      "Epoch 20:\t train loss : 0.5907960339676958; train accuracy : 0.9600547182378636; \n",
      " validation loss : 0.6489017429093572; validation accuracy : 0.895397489539749\n",
      "Epoch 21:\t train loss : 0.5828700700739484; train accuracy : 0.9682678753988662; \n",
      " validation loss : 0.6401606253266899; validation accuracy : 0.9163179916317992\n",
      "Epoch 22:\t train loss : 0.5903903511268519; train accuracy : 0.9602680922581245; \n",
      " validation loss : 0.6449276430470922; validation accuracy : 0.9037656903765691\n",
      "Epoch 23:\t train loss : 0.5802132667296651; train accuracy : 0.9708787059698256; \n",
      " validation loss : 0.6525079192492037; validation accuracy : 0.891213389121339\n",
      "Epoch 24:\t train loss : 0.5785565541830211; train accuracy : 0.9726892871526379; \n",
      " validation loss : 0.6624480203247552; validation accuracy : 0.895397489539749\n",
      "Epoch 25:\t train loss : 0.5784347834899856; train accuracy : 0.9725705954335636; \n",
      " validation loss : 0.6720601595921835; validation accuracy : 0.8786610878661087\n",
      "Epoch 26:\t train loss : 0.5746879067281603; train accuracy : 0.9766461941200161; \n",
      " validation loss : 0.6374846728326208; validation accuracy : 0.9121338912133892\n",
      "Epoch 27:\t train loss : 0.5725013014238646; train accuracy : 0.9789834335016574; \n",
      " validation loss : 0.6123371683410831; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5746516816181757; train accuracy : 0.9764740620837077; \n",
      " validation loss : 0.6371069491576612; validation accuracy : 0.9121338912133892\n",
      "Epoch 29:\t train loss : 0.5816380164870018; train accuracy : 0.9691300845751107; \n",
      " validation loss : 0.6252518411521085; validation accuracy : 0.9205020920502092\n",
      "Epoch 30:\t train loss : 0.5733664912331332; train accuracy : 0.9780402893522104; \n",
      " validation loss : 0.623138837248577; validation accuracy : 0.9330543933054394\n",
      "Epoch 31:\t train loss : 0.5759972917385211; train accuracy : 0.9750422101056414; \n",
      " validation loss : 0.6604281365485408; validation accuracy : 0.891213389121339\n",
      "Epoch 32:\t train loss : 0.5700029336141871; train accuracy : 0.9812002385451842; \n",
      " validation loss : 0.6326111241812201; validation accuracy : 0.9163179916317992\n",
      "Epoch 33:\t train loss : 0.5667323095919631; train accuracy : 0.9846924471018309; \n",
      " validation loss : 0.6109232367524187; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5662082359512334; train accuracy : 0.9853068171256855; \n",
      " validation loss : 0.6259090039432474; validation accuracy : 0.9246861924686193\n",
      "Epoch 35:\t train loss : 0.5661171503468101; train accuracy : 0.9852121348244989; \n",
      " validation loss : 0.6301985155939468; validation accuracy : 0.9205020920502092\n",
      "Epoch 36:\t train loss : 0.5727754099478856; train accuracy : 0.9784103054617553; \n",
      " validation loss : 0.6202952102531256; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5732239749804415; train accuracy : 0.9777012531367143; \n",
      " validation loss : 0.6283154196648927; validation accuracy : 0.9246861924686193\n",
      "Epoch 38:\t train loss : 0.5659241888242715; train accuracy : 0.9854479692679451; \n",
      " validation loss : 0.6367731565813594; validation accuracy : 0.9163179916317992\n",
      "Epoch 39:\t train loss : 0.5730701419247649; train accuracy : 0.9780160863099848; \n",
      " validation loss : 0.7937943092255215; validation accuracy : 0.7573221757322176\n",
      "Epoch 40:\t train loss : 0.5870966342220496; train accuracy : 0.9638222606028687; \n",
      " validation loss : 0.627860864596933; validation accuracy : 0.9246861924686193\n",
      "Epoch 41:\t train loss : 0.5732265897952872; train accuracy : 0.9778269153319495; \n",
      " validation loss : 0.6362248451097218; validation accuracy : 0.9163179916317992\n",
      "Epoch 42:\t train loss : 0.5661410364121062; train accuracy : 0.9849608104340283; \n",
      " validation loss : 0.6401754123015697; validation accuracy : 0.9079497907949791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:\t train loss : 0.5672778111792383; train accuracy : 0.9839884290095728; \n",
      " validation loss : 0.6035727796888649; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5657354993931089; train accuracy : 0.9854824344000743; \n",
      " validation loss : 0.6424229616083369; validation accuracy : 0.9079497907949791\n",
      "Epoch 45:\t train loss : 0.5685172650055943; train accuracy : 0.9825995616344992; \n",
      " validation loss : 0.6286753981083192; validation accuracy : 0.9205020920502092\n",
      "Epoch 46:\t train loss : 0.5665410711833715; train accuracy : 0.9845977648006444; \n",
      " validation loss : 0.6065171426036808; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5713776787797755; train accuracy : 0.9795255816475108; \n",
      " validation loss : 0.6418828466308153; validation accuracy : 0.9079497907949791\n",
      "Epoch 48:\t train loss : 0.5679243688337003; train accuracy : 0.983124477214288; \n",
      " validation loss : 0.6003155074775429; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5679781023367114; train accuracy : 0.9830315375321417; \n",
      " validation loss : 0.6053763069569731; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5648603250428187; train accuracy : 0.9861587642120264; \n",
      " validation loss : 0.6121261088415582; validation accuracy : 0.9372384937238494\n",
      "Epoch 51:\t train loss : 0.5626881458656329; train accuracy : 0.9887628179311627; \n",
      " validation loss : 0.6265965392081666; validation accuracy : 0.9246861924686193\n",
      "Epoch 52:\t train loss : 0.5655852505037662; train accuracy : 0.9856390764893584; \n",
      " validation loss : 0.6133707400736164; validation accuracy : 0.9372384937238494\n",
      "Epoch 53:\t train loss : 0.5683439240021738; train accuracy : 0.9827509758666625; \n",
      " validation loss : 0.6381751603798694; validation accuracy : 0.9121338912133892\n",
      "Epoch 54:\t train loss : 0.5628533786835336; train accuracy : 0.9883221289383191; \n",
      " validation loss : 0.6169827514926263; validation accuracy : 0.9330543933054394\n",
      "Epoch 55:\t train loss : 0.5633720302521429; train accuracy : 0.9879246181728059; \n",
      " validation loss : 0.6278645566182715; validation accuracy : 0.9246861924686193\n",
      "Epoch 56:\t train loss : 0.5636333790938125; train accuracy : 0.9875116174602683; \n",
      " validation loss : 0.6195157243179334; validation accuracy : 0.9288702928870293\n",
      "Epoch 57:\t train loss : 0.5642078355028876; train accuracy : 0.9870004492084637; \n",
      " validation loss : 0.6195623601336251; validation accuracy : 0.9330543933054394\n",
      "Epoch 58:\t train loss : 0.5706163742982042; train accuracy : 0.9804205133368444; \n",
      " validation loss : 0.6304218416602368; validation accuracy : 0.9163179916317992\n",
      "Epoch 59:\t train loss : 0.568533502574724; train accuracy : 0.9826477740946126; \n",
      " validation loss : 0.6443922916811258; validation accuracy : 0.9079497907949791\n",
      "Epoch 60:\t train loss : 0.5672789617731399; train accuracy : 0.9838782567613619; \n",
      " validation loss : 0.6278658698174255; validation accuracy : 0.9246861924686193\n",
      "Epoch 61:\t train loss : 0.5660498253458521; train accuracy : 0.9850452306453112; \n",
      " validation loss : 0.6200694009776098; validation accuracy : 0.9330543933054394\n",
      "Epoch 62:\t train loss : 0.5628959221557756; train accuracy : 0.9883600793085288; \n",
      " validation loss : 0.5931362116481838; validation accuracy : 0.9623430962343096\n",
      "Epoch 63:\t train loss : 0.5607728924304154; train accuracy : 0.99044947953778; \n",
      " validation loss : 0.6089583654425369; validation accuracy : 0.9372384937238494\n",
      "Epoch 64:\t train loss : 0.5602652419839423; train accuracy : 0.9912292047461198; \n",
      " validation loss : 0.6270826897047589; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.5766453773170419; train accuracy : 0.9743554245794479; \n",
      " validation loss : 0.6477334062106566; validation accuracy : 0.9037656903765691\n",
      "Epoch 66:\t train loss : 0.6033269775517925; train accuracy : 0.9474786238731063; \n",
      " validation loss : 0.6253279726364375; validation accuracy : 0.9246861924686193\n",
      "Epoch 67:\t train loss : 0.5786064534457893; train accuracy : 0.9725448433966356; \n",
      " validation loss : 0.6246542877987155; validation accuracy : 0.9246861924686193\n",
      "Epoch 68:\t train loss : 0.5656883390640539; train accuracy : 0.985525419003067; \n",
      " validation loss : 0.6276857512356968; validation accuracy : 0.9246861924686193\n",
      "Epoch 69:\t train loss : 0.568606752653975; train accuracy : 0.9825443786982249; \n",
      " validation loss : 0.6533730911113215; validation accuracy : 0.895397489539749\n",
      "Epoch 70:\t train loss : 0.564310271275179; train accuracy : 0.9869057669072772; \n",
      " validation loss : 0.6183405717778101; validation accuracy : 0.9330543933054394\n",
      "Epoch 71:\t train loss : 0.5637499353242049; train accuracy : 0.987353232751944; \n",
      " validation loss : 0.6211108983860325; validation accuracy : 0.9246861924686193\n",
      "Epoch 72:\t train loss : 0.5633824855086975; train accuracy : 0.987945335976951; \n",
      " validation loss : 0.6184472405512167; validation accuracy : 0.9330543933054394\n",
      "Epoch 73:\t train loss : 0.5611112735775725; train accuracy : 0.9902068682425106; \n",
      " validation loss : 0.6155243837944108; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5620542888289242; train accuracy : 0.9893531785371295; \n",
      " validation loss : 0.5986937710468959; validation accuracy : 0.9497907949790795\n",
      "Epoch 75:\t train loss : 0.5736516252342156; train accuracy : 0.9773105192230243; \n",
      " validation loss : 0.6523228786403833; validation accuracy : 0.899581589958159\n",
      "Epoch 76:\t train loss : 0.5714431979892461; train accuracy : 0.9795790219647449; \n",
      " validation loss : 0.6303057638338022; validation accuracy : 0.9163179916317992\n",
      "Epoch 77:\t train loss : 0.5644868791011122; train accuracy : 0.9867371201090492; \n",
      " validation loss : 0.6116484108851656; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5630622397428291; train accuracy : 0.9880657703150655; \n",
      " validation loss : 0.6349122594002096; validation accuracy : 0.9163179916317992\n",
      "Epoch 79:\t train loss : 0.5647701099943262; train accuracy : 0.9864703057715543; \n",
      " validation loss : 0.6206381234127191; validation accuracy : 0.9288702928870293\n",
      "Epoch 80:\t train loss : 0.5607686963747983; train accuracy : 0.9905304145109823; \n",
      " validation loss : 0.6205292949114793; validation accuracy : 0.9288702928870293\n",
      "Epoch 81:\t train loss : 0.5639211692289138; train accuracy : 0.9873704653180086; \n",
      " validation loss : 0.6169469597286851; validation accuracy : 0.9330543933054394\n",
      "Epoch 82:\t train loss : 0.5751791258595235; train accuracy : 0.975630828092568; \n",
      " validation loss : 0.6294048907750112; validation accuracy : 0.9163179916317992\n",
      "Epoch 83:\t train loss : 0.5659452441332714; train accuracy : 0.9852740946125964; \n",
      " validation loss : 0.6117358468532011; validation accuracy : 0.9372384937238494\n",
      "Epoch 84:\t train loss : 0.560759764021412; train accuracy : 0.9905941169181202; \n",
      " validation loss : 0.6010210514298949; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5651356315034963; train accuracy : 0.9859091824405961; \n",
      " validation loss : 0.6251581563966704; validation accuracy : 0.9246861924686193\n",
      "Epoch 86:\t train loss : 0.5679687575051119; train accuracy : 0.9832656293565476; \n",
      " validation loss : 0.6028098361951115; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.564092098926297; train accuracy : 0.9871690960066917; \n",
      " validation loss : 0.6266968788022087; validation accuracy : 0.9246861924686193\n",
      "Epoch 88:\t train loss : 0.5627681358269518; train accuracy : 0.9885339539638774; \n",
      " validation loss : 0.6264642745285444; validation accuracy : 0.9246861924686193\n",
      "Epoch 89:\t train loss : 0.5647975922831673; train accuracy : 0.9864410684965458; \n",
      " validation loss : 0.6166532094162812; validation accuracy : 0.9330543933054394\n",
      "Epoch 90:\t train loss : 0.5624199774667611; train accuracy : 0.9888902227454383; \n",
      " validation loss : 0.6078147855090779; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5649151287954983; train accuracy : 0.9863463861953592; \n",
      " validation loss : 0.6356022159639708; validation accuracy : 0.9163179916317992\n",
      "Epoch 92:\t train loss : 0.5625140749890274; train accuracy : 0.9887835357353078; \n",
      " validation loss : 0.6017880558210411; validation accuracy : 0.9497907949790795\n",
      "Epoch 93:\t train loss : 0.5641637297545847; train accuracy : 0.9871208835465782; \n",
      " validation loss : 0.6112444194951717; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94:\t train loss : 0.562266706702087; train accuracy : 0.989045122215682; \n",
      " validation loss : 0.6078980185732682; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.5682997674864692; train accuracy : 0.9829523451779795; \n",
      " validation loss : 0.6188910608437486; validation accuracy : 0.9330543933054394\n",
      "Epoch 96:\t train loss : 0.5622363234000113; train accuracy : 0.9890743594906906; \n",
      " validation loss : 0.6273478555677133; validation accuracy : 0.9246861924686193\n",
      "Epoch 97:\t train loss : 0.5617381286902652; train accuracy : 0.9894753554942842; \n",
      " validation loss : 0.6068127927509683; validation accuracy : 0.9456066945606695\n",
      "Epoch 98:\t train loss : 0.5625295446170072; train accuracy : 0.988811030391276; \n",
      " validation loss : 0.6063796200576171; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5605783464280485; train accuracy : 0.9907662489544286; \n",
      " validation loss : 0.6083331143414278; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.559653174760038; train accuracy : 0.9917368877598438; \n",
      " validation loss : 0.6141151646612918; validation accuracy : 0.9372384937238494\n",
      "Epoch 101:\t train loss : 0.564159686535432; train accuracy : 0.9870037408222064; \n",
      " validation loss : 0.6031222651879332; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5667740004961128; train accuracy : 0.9844101428173115; \n",
      " validation loss : 0.6208309833000201; validation accuracy : 0.9288702928870293\n",
      "Epoch 103:\t train loss : 0.5613235563290571; train accuracy : 0.9899400539050156; \n",
      " validation loss : 0.6074420355369655; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.5623191636468932; train accuracy : 0.9889004848353419; \n",
      " validation loss : 0.6175091254843024; validation accuracy : 0.9288702928870293\n",
      "Epoch 105:\t train loss : 0.5652972313769358; train accuracy : 0.9859246723876204; \n",
      " validation loss : 0.6050988675057949; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.5582211511946344; train accuracy : 0.993149958177143; \n",
      " validation loss : 0.6132245958686935; validation accuracy : 0.9372384937238494\n",
      "Epoch 107:\t train loss : 0.5599589640792921; train accuracy : 0.991399594163388; \n",
      " validation loss : 0.6054963502245779; validation accuracy : 0.9456066945606695\n",
      "Epoch 108:\t train loss : 0.5626064105270586; train accuracy : 0.9885459586728214; \n",
      " validation loss : 0.6144575002183537; validation accuracy : 0.9372384937238494\n",
      "Epoch 109:\t train loss : 0.5730049049656254; train accuracy : 0.9783483456736578; \n",
      " validation loss : 0.6342710925979034; validation accuracy : 0.9163179916317992\n",
      "Epoch 110:\t train loss : 0.5696267359274388; train accuracy : 0.9815807103689705; \n",
      " validation loss : 0.6190626275326548; validation accuracy : 0.9330543933054394\n",
      "Epoch 111:\t train loss : 0.5652340827835292; train accuracy : 0.9860108352179435; \n",
      " validation loss : 0.6295466215801182; validation accuracy : 0.9205020920502092\n",
      "Epoch 112:\t train loss : 0.5734432800532737; train accuracy : 0.9776782118405155; \n",
      " validation loss : 0.8379998867335168; validation accuracy : 0.7154811715481172\n",
      "Early stopping at epoch 112\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5628959221557756; Train accuracy : 0.9883600793085288; \n",
      " Validation loss : 0.5931362116481838; Validation accuracy : 0.9623430962343096\n",
      "--- Let's train model 5 ! ---\n",
      "Epoch 1:\t train loss : 0.9596213514306519; train accuracy : 0.571390067845968; \n",
      " validation loss : 0.832347027177606; validation accuracy : 0.7112970711297071\n",
      "Epoch 2:\t train loss : 0.7785319089765156; train accuracy : 0.7693639827751789; \n",
      " validation loss : 0.7113991230152139; validation accuracy : 0.8451882845188284\n",
      "Epoch 3:\t train loss : 0.7121741082958593; train accuracy : 0.8382539731714117; \n",
      " validation loss : 0.6938221703040447; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.6827263450645803; train accuracy : 0.8673502896620093; \n",
      " validation loss : 0.6732332145387301; validation accuracy : 0.8744769874476988\n",
      "Epoch 5:\t train loss : 0.6585899467872048; train accuracy : 0.8922550264878094; \n",
      " validation loss : 0.6519581976167953; validation accuracy : 0.899581589958159\n",
      "Epoch 6:\t train loss : 0.6448376985062447; train accuracy : 0.9060534712971282; \n",
      " validation loss : 0.6491130927465629; validation accuracy : 0.899581589958159\n",
      "Epoch 7:\t train loss : 0.6303154971335377; train accuracy : 0.9207038631927879; \n",
      " validation loss : 0.6505602624873803; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6214640047449888; train accuracy : 0.9295641128907339; \n",
      " validation loss : 0.618650529257893; validation accuracy : 0.9330543933054394\n",
      "Epoch 9:\t train loss : 0.6087548271072315; train accuracy : 0.9428761733634871; \n",
      " validation loss : 0.6059364719238579; validation accuracy : 0.9456066945606695\n",
      "Epoch 10:\t train loss : 0.6110881029387267; train accuracy : 0.9399516713652839; \n",
      " validation loss : 0.6702605654276971; validation accuracy : 0.8786610878661087\n",
      "Epoch 11:\t train loss : 0.6111047882441878; train accuracy : 0.9398401437467084; \n",
      " validation loss : 0.6185406689206167; validation accuracy : 0.9288702928870293\n",
      "Epoch 12:\t train loss : 0.5943553690427575; train accuracy : 0.95694414325103; \n",
      " validation loss : 0.6166890755953213; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.5927446071938183; train accuracy : 0.9585117258898974; \n",
      " validation loss : 0.6248122545878162; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5901607463238769; train accuracy : 0.9608878837634375; \n",
      " validation loss : 0.6017410870573714; validation accuracy : 0.9497907949790795\n",
      "Epoch 15:\t train loss : 0.5849831572017476; train accuracy : 0.9664797546392391; \n",
      " validation loss : 0.6241279149417327; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5862125685379611; train accuracy : 0.9648378202546547; \n",
      " validation loss : 0.6068656489998605; validation accuracy : 0.9414225941422594\n",
      "Epoch 17:\t train loss : 0.5827057698627911; train accuracy : 0.968784658756467; \n",
      " validation loss : 0.6091493801101359; validation accuracy : 0.9414225941422594\n",
      "Epoch 18:\t train loss : 0.584823034893757; train accuracy : 0.9662907772855417; \n",
      " validation loss : 0.5905485745023674; validation accuracy : 0.9581589958158996\n",
      "Epoch 19:\t train loss : 0.5938854410218838; train accuracy : 0.9569162613463862; \n",
      " validation loss : 0.6760227561006625; validation accuracy : 0.8744769874476988\n",
      "Epoch 20:\t train loss : 0.6028534822252017; train accuracy : 0.9474673936615137; \n",
      " validation loss : 0.608615608550007; validation accuracy : 0.9372384937238494\n",
      "Epoch 21:\t train loss : 0.5800336037746935; train accuracy : 0.9711948945134607; \n",
      " validation loss : 0.615338966027346; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5786190877784178; train accuracy : 0.9726261656185136; \n",
      " validation loss : 0.613934054103124; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.577370805081986; train accuracy : 0.9738436754546299; \n",
      " validation loss : 0.61423193254461; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.576519543149629; train accuracy : 0.9745128411660832; \n",
      " validation loss : 0.6024800621535902; validation accuracy : 0.9497907949790795\n",
      "Epoch 25:\t train loss : 0.5752817174490201; train accuracy : 0.9761795594659066; \n",
      " validation loss : 0.6110099388227423; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5782273478728277; train accuracy : 0.9731249419126986; \n",
      " validation loss : 0.6144828270808085; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5749266941494309; train accuracy : 0.9759534062393507; \n",
      " validation loss : 0.6018143101467118; validation accuracy : 0.9539748953974896\n",
      "Epoch 28:\t train loss : 0.5705423201269237; train accuracy : 0.9808234455838161; \n",
      " validation loss : 0.5958557374344495; validation accuracy : 0.9539748953974896\n",
      "Epoch 29:\t train loss : 0.5688926024886629; train accuracy : 0.9823414603922055; \n",
      " validation loss : 0.6223059987960247; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.5756074138023046; train accuracy : 0.9755971374577899; \n",
      " validation loss : 0.6204131726687698; validation accuracy : 0.9288702928870293\n",
      "Epoch 31:\t train loss : 0.5770891395125551; train accuracy : 0.9740233588401127; \n",
      " validation loss : 0.6105735822079524; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:\t train loss : 0.5717715863243509; train accuracy : 0.979571857864246; \n",
      " validation loss : 0.590128650251435; validation accuracy : 0.9623430962343096\n",
      "Epoch 33:\t train loss : 0.5649505604434046; train accuracy : 0.9862882988940178; \n",
      " validation loss : 0.6011023982237523; validation accuracy : 0.9497907949790795\n",
      "Epoch 34:\t train loss : 0.5710169979799009; train accuracy : 0.9804454908764212; \n",
      " validation loss : 0.5832322221503724; validation accuracy : 0.9665271966527197\n",
      "Epoch 35:\t train loss : 0.5779099923698646; train accuracy : 0.9728213389510207; \n",
      " validation loss : 0.6663818977151421; validation accuracy : 0.8870292887029289\n",
      "Epoch 36:\t train loss : 0.5796283449388762; train accuracy : 0.971414851761207; \n",
      " validation loss : 0.605253909114241; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5823057761787559; train accuracy : 0.9683726261656185; \n",
      " validation loss : 0.6202595279945319; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5699301684119173; train accuracy : 0.9813470057932402; \n",
      " validation loss : 0.5913122856529749; validation accuracy : 0.9623430962343096\n",
      "Epoch 39:\t train loss : 0.5654509338440424; train accuracy : 0.9857988165680474; \n",
      " validation loss : 0.5873903070839822; validation accuracy : 0.9623430962343096\n",
      "Epoch 40:\t train loss : 0.5668498794226342; train accuracy : 0.9843644474735896; \n",
      " validation loss : 0.5979474827499962; validation accuracy : 0.9539748953974896\n",
      "Epoch 41:\t train loss : 0.5645866338268324; train accuracy : 0.9867932711670127; \n",
      " validation loss : 0.5839125462259949; validation accuracy : 0.9623430962343096\n",
      "Epoch 42:\t train loss : 0.5660657977470497; train accuracy : 0.9853527060937451; \n",
      " validation loss : 0.5803854461991405; validation accuracy : 0.9707112970711297\n",
      "Epoch 43:\t train loss : 0.5735451272854779; train accuracy : 0.9775519687722668; \n",
      " validation loss : 0.6027111994195813; validation accuracy : 0.9456066945606695\n",
      "Epoch 44:\t train loss : 0.5665641837223654; train accuracy : 0.984730010223365; \n",
      " validation loss : 0.5862869244187656; validation accuracy : 0.9665271966527197\n",
      "Epoch 45:\t train loss : 0.5648896746927111; train accuracy : 0.9863316707456861; \n",
      " validation loss : 0.5996141157911498; validation accuracy : 0.9539748953974896\n",
      "Epoch 46:\t train loss : 0.586476960066055; train accuracy : 0.9643297499922551; \n",
      " validation loss : 0.6024910880233514; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5766764851517802; train accuracy : 0.9743393537594102; \n",
      " validation loss : 0.6018222456849384; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5679676344345497; train accuracy : 0.9833668948852194; \n",
      " validation loss : 0.585917764229928; validation accuracy : 0.9665271966527197\n",
      "Epoch 49:\t train loss : 0.5663477659470467; train accuracy : 0.984881811704204; \n",
      " validation loss : 0.5987333152926031; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5693625916380576; train accuracy : 0.9818179001827814; \n",
      " validation loss : 0.5941010444793289; validation accuracy : 0.9539748953974896\n",
      "Epoch 51:\t train loss : 0.5674386870869895; train accuracy : 0.9836673998574925; \n",
      " validation loss : 0.6056480686696928; validation accuracy : 0.9456066945606695\n",
      "Epoch 52:\t train loss : 0.5642762207161067; train accuracy : 0.9870008364571393; \n",
      " validation loss : 0.5901113108827093; validation accuracy : 0.9581589958158996\n",
      "Epoch 53:\t train loss : 0.566412695419349; train accuracy : 0.9846773444034821; \n",
      " validation loss : 0.6014740918205368; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.5637868458849831; train accuracy : 0.987533690634778; \n",
      " validation loss : 0.5730907365447199; validation accuracy : 0.9790794979079498\n",
      "Epoch 55:\t train loss : 0.5690594887152556; train accuracy : 0.9820409554199324; \n",
      " validation loss : 0.5961488853206179; validation accuracy : 0.9539748953974896\n",
      "Epoch 56:\t train loss : 0.5680102189494787; train accuracy : 0.9831128597540196; \n",
      " validation loss : 0.5989807222090885; validation accuracy : 0.9539748953974896\n",
      "Epoch 57:\t train loss : 0.5645348869275046; train accuracy : 0.9867313113789151; \n",
      " validation loss : 0.585311631410756; validation accuracy : 0.9623430962343096\n",
      "Epoch 58:\t train loss : 0.5635195915841034; train accuracy : 0.9878713714799096; \n",
      " validation loss : 0.5946221366174543; validation accuracy : 0.9539748953974896\n",
      "Epoch 59:\t train loss : 0.564794419651052; train accuracy : 0.986533040057003; \n",
      " validation loss : 0.5990643671031239; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5663000062314986; train accuracy : 0.9847393041915796; \n",
      " validation loss : 0.5971689419933692; validation accuracy : 0.9539748953974896\n",
      "Epoch 61:\t train loss : 0.5658602076857224; train accuracy : 0.9853186282102915; \n",
      " validation loss : 0.6225691644228529; validation accuracy : 0.9246861924686193\n",
      "Epoch 62:\t train loss : 0.5872424820593074; train accuracy : 0.9633445893615044; \n",
      " validation loss : 0.6073773888768312; validation accuracy : 0.9414225941422594\n",
      "Epoch 63:\t train loss : 0.5663867040189012; train accuracy : 0.9847857740326528; \n",
      " validation loss : 0.599165234488033; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5618145712363753; train accuracy : 0.9893831903094892; \n",
      " validation loss : 0.5922043201152002; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.5668191465873914; train accuracy : 0.9844171132934726; \n",
      " validation loss : 0.6336984966332233; validation accuracy : 0.9163179916317992\n",
      "Epoch 66:\t train loss : 0.5700069102436743; train accuracy : 0.9813036339415719; \n",
      " validation loss : 0.5845271487938238; validation accuracy : 0.9665271966527197\n",
      "Epoch 67:\t train loss : 0.5798663663430634; train accuracy : 0.9711948945134607; \n",
      " validation loss : 0.6025423633128251; validation accuracy : 0.9497907949790795\n",
      "Epoch 68:\t train loss : 0.5663627456273587; train accuracy : 0.9848632237677747; \n",
      " validation loss : 0.5750427948272916; validation accuracy : 0.9748953974895398\n",
      "Epoch 69:\t train loss : 0.5635654365597744; train accuracy : 0.9879147433315778; \n",
      " validation loss : 0.595170964119951; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5656917539125914; train accuracy : 0.9855912512779206; \n",
      " validation loss : 0.5893959120464873; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5616055234025307; train accuracy : 0.9895659716843769; \n",
      " validation loss : 0.5839473411405629; validation accuracy : 0.9665271966527197\n",
      "Epoch 72:\t train loss : 0.559471318534648; train accuracy : 0.9918089160135072; \n",
      " validation loss : 0.6053660916760886; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5657499110615424; train accuracy : 0.9854611357229158; \n",
      " validation loss : 0.5974974090166215; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5604462674921153; train accuracy : 0.9908640292450199; \n",
      " validation loss : 0.5946185757428344; validation accuracy : 0.9581589958158996\n",
      "Epoch 75:\t train loss : 0.5642890433308495; train accuracy : 0.9870256203723783; \n",
      " validation loss : 0.5948674766820963; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5611155571095375; train accuracy : 0.9901019238514204; \n",
      " validation loss : 0.59407057376563; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5698632148499406; train accuracy : 0.981300535952167; \n",
      " validation loss : 0.6058406100954984; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5621201189595484; train accuracy : 0.9890950772948356; \n",
      " validation loss : 0.5773124726074015; validation accuracy : 0.9748953974895398\n",
      "Epoch 79:\t train loss : 0.5612153508948751; train accuracy : 0.9900213761268937; \n",
      " validation loss : 0.5969484460376926; validation accuracy : 0.9539748953974896\n",
      "Epoch 80:\t train loss : 0.5669603114857871; train accuracy : 0.984181666098702; \n",
      " validation loss : 0.5995644050624191; validation accuracy : 0.9497907949790795\n",
      "Epoch 81:\t train loss : 0.5615435787204076; train accuracy : 0.9896589113665232; \n",
      " validation loss : 0.5739309140308548; validation accuracy : 0.9748953974895398\n",
      "Epoch 82:\t train loss : 0.5595604571373299; train accuracy : 0.9917748381300536; \n",
      " validation loss : 0.5841035491992019; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:\t train loss : 0.5650601929384657; train accuracy : 0.9861426933919886; \n",
      " validation loss : 0.5929927273355887; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5603249929216493; train accuracy : 0.9909507729483565; \n",
      " validation loss : 0.6006002090711949; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5621184879586361; train accuracy : 0.9892158988816259; \n",
      " validation loss : 0.592087833822444; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5611417985899056; train accuracy : 0.9901855695653521; \n",
      " validation loss : 0.5781478481261235; validation accuracy : 0.9748953974895398\n",
      "Epoch 87:\t train loss : 0.5599203665515108; train accuracy : 0.9914464512531367; \n",
      " validation loss : 0.5974352169536624; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5757134415810486; train accuracy : 0.9753369063477803; \n",
      " validation loss : 0.5912179099408025; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.561086123147713; train accuracy : 0.990238235385235; \n",
      " validation loss : 0.5845088829915409; validation accuracy : 0.9665271966527197\n",
      "Epoch 90:\t train loss : 0.5638051606359156; train accuracy : 0.9875708665076366; \n",
      " validation loss : 0.5880998126181002; validation accuracy : 0.9623430962343096\n",
      "Epoch 91:\t train loss : 0.5629618150273783; train accuracy : 0.9884878713714799; \n",
      " validation loss : 0.5809229977698772; validation accuracy : 0.9707112970711297\n",
      "Epoch 92:\t train loss : 0.5634574922758763; train accuracy : 0.9878001177235974; \n",
      " validation loss : 0.5986146886932989; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5638398519419351; train accuracy : 0.9873787911645342; \n",
      " validation loss : 0.585931033517138; validation accuracy : 0.9665271966527197\n",
      "Epoch 94:\t train loss : 0.5686223545433222; train accuracy : 0.9824715759472102; \n",
      " validation loss : 0.6071003415429354; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.560163726161387; train accuracy : 0.9911366523126491; \n",
      " validation loss : 0.5909430254364557; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.5602027566352062; train accuracy : 0.9910994764397906; \n",
      " validation loss : 0.5769476017015389; validation accuracy : 0.9748953974895398\n",
      "Epoch 97:\t train loss : 0.5622313286594067; train accuracy : 0.9889277858669724; \n",
      " validation loss : 0.5810418631351266; validation accuracy : 0.9707112970711297\n",
      "Epoch 98:\t train loss : 0.5585983945609392; train accuracy : 0.9927971746336628; \n",
      " validation loss : 0.580112311451755; validation accuracy : 0.9707112970711297\n",
      "Epoch 99:\t train loss : 0.5601431173428846; train accuracy : 0.9912357879736051; \n",
      " validation loss : 0.5837737113222446; validation accuracy : 0.9665271966527197\n",
      "Epoch 100:\t train loss : 0.5612116609218757; train accuracy : 0.9900585519997521; \n",
      " validation loss : 0.5819840936266207; validation accuracy : 0.9707112970711297\n",
      "Epoch 101:\t train loss : 0.5596409414511739; train accuracy : 0.9916571145326682; \n",
      " validation loss : 0.5894700201347506; validation accuracy : 0.9623430962343096\n",
      "Epoch 102:\t train loss : 0.562669980503382; train accuracy : 0.9884816753926702; \n",
      " validation loss : 0.6192021972845839; validation accuracy : 0.9330543933054394\n",
      "Epoch 103:\t train loss : 0.5668433146989356; train accuracy : 0.9842962917066823; \n",
      " validation loss : 0.5938880643573814; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.5613283724012094; train accuracy : 0.9900554540103472; \n",
      " validation loss : 0.5761152054603165; validation accuracy : 0.9748953974895398\n",
      "Early stopping at epoch 104\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5637868458849831; Train accuracy : 0.987533690634778; \n",
      " Validation loss : 0.5730907365447199; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 6 ! ---\n",
      "Epoch 1:\t train loss : 0.9832688292965585; train accuracy : 0.5374587812509681; \n",
      " validation loss : 0.9235198782406221; validation accuracy : 0.5983263598326359\n",
      "Epoch 2:\t train loss : 0.7914335218439136; train accuracy : 0.7544274605780849; \n",
      " validation loss : 0.7810977802664617; validation accuracy : 0.7573221757322176\n",
      "Epoch 3:\t train loss : 0.708784342278181; train accuracy : 0.8407538027819945; \n",
      " validation loss : 0.7373780501623626; validation accuracy : 0.8075313807531381\n",
      "Epoch 4:\t train loss : 0.6750067370250745; train accuracy : 0.8757063106044177; \n",
      " validation loss : 0.698114679831215; validation accuracy : 0.8493723849372385\n",
      "Epoch 5:\t train loss : 0.6593343720149883; train accuracy : 0.8909492859134421; \n",
      " validation loss : 0.6862718045563087; validation accuracy : 0.8577405857740585\n",
      "Epoch 6:\t train loss : 0.6417583704981734; train accuracy : 0.9092647231946467; \n",
      " validation loss : 0.6579766645691654; validation accuracy : 0.895397489539749\n",
      "Epoch 7:\t train loss : 0.6265085220443001; train accuracy : 0.9247500851947086; \n",
      " validation loss : 0.6584734019171058; validation accuracy : 0.895397489539749\n",
      "Epoch 8:\t train loss : 0.6200810776832274; train accuracy : 0.9309606865144521; \n",
      " validation loss : 0.6657443993752157; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6107803232140595; train accuracy : 0.9404732488614889; \n",
      " validation loss : 0.648802344306372; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.6001621526458595; train accuracy : 0.9511667647696644; \n",
      " validation loss : 0.6288406059793682; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.5981343305797299; train accuracy : 0.9528660739180272; \n",
      " validation loss : 0.6349676408700377; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.5922470158255582; train accuracy : 0.9590494129310078; \n",
      " validation loss : 0.6577751363469587; validation accuracy : 0.891213389121339\n",
      "Epoch 13:\t train loss : 0.596096110971759; train accuracy : 0.9549480467176802; \n",
      " validation loss : 0.6274358291788918; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.58774282184012; train accuracy : 0.9637646767248056; \n",
      " validation loss : 0.6422887863718979; validation accuracy : 0.9079497907949791\n",
      "Epoch 15:\t train loss : 0.5886793871299032; train accuracy : 0.9626410979274451; \n",
      " validation loss : 0.6211758990496742; validation accuracy : 0.9330543933054394\n",
      "Epoch 16:\t train loss : 0.5876631170664611; train accuracy : 0.9636252672015861; \n",
      " validation loss : 0.6427677478778934; validation accuracy : 0.9037656903765691\n",
      "Epoch 17:\t train loss : 0.5881399382757364; train accuracy : 0.9628625422101056; \n",
      " validation loss : 0.6402938228336557; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.5830577479997423; train accuracy : 0.9682329688032467; \n",
      " validation loss : 0.639029431900856; validation accuracy : 0.9121338912133892\n",
      "Epoch 19:\t train loss : 0.5833544827433134; train accuracy : 0.9680617119489451; \n",
      " validation loss : 0.6372146070019606; validation accuracy : 0.9079497907949791\n",
      "Epoch 20:\t train loss : 0.5867409810083303; train accuracy : 0.9642712599522909; \n",
      " validation loss : 0.638234903577519; validation accuracy : 0.9079497907949791\n",
      "Epoch 21:\t train loss : 0.5839882701554713; train accuracy : 0.9672051798382849; \n",
      " validation loss : 0.613768811827265; validation accuracy : 0.9372384937238494\n",
      "Epoch 22:\t train loss : 0.5805202987560721; train accuracy : 0.9703249790885715; \n",
      " validation loss : 0.6063835031453357; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5755996548934049; train accuracy : 0.9758594752005948; \n",
      " validation loss : 0.6223091017040355; validation accuracy : 0.9246861924686193\n",
      "Epoch 24:\t train loss : 0.5734668077999068; train accuracy : 0.9778421884197156; \n",
      " validation loss : 0.6277240983508126; validation accuracy : 0.9121338912133892\n",
      "Epoch 25:\t train loss : 0.5696680412865333; train accuracy : 0.9819114594628087; \n",
      " validation loss : 0.6331446789099592; validation accuracy : 0.9205020920502092\n",
      "Epoch 26:\t train loss : 0.5688965688257351; train accuracy : 0.9824992100127018; \n",
      " validation loss : 0.6199797655183747; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5834748068632508; train accuracy : 0.9675141113417393; \n",
      " validation loss : 0.6060960811093177; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.5722730916463911; train accuracy : 0.978993029523839; \n",
      " validation loss : 0.6088636857510309; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:\t train loss : 0.5700089791840104; train accuracy : 0.9812207317450974; \n",
      " validation loss : 0.619529031687563; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.5756304916753971; train accuracy : 0.9755396387744354; \n",
      " validation loss : 0.6317354289642431; validation accuracy : 0.9163179916317992\n",
      "Epoch 31:\t train loss : 0.5695661896774107; train accuracy : 0.9815807181139441; \n",
      " validation loss : 0.627428358076845; validation accuracy : 0.9205020920502092\n",
      "Epoch 32:\t train loss : 0.5676585170217607; train accuracy : 0.9835433563617213; \n",
      " validation loss : 0.6240266491512545; validation accuracy : 0.9205020920502092\n",
      "Epoch 33:\t train loss : 0.5846704855982195; train accuracy : 0.9660789987298244; \n",
      " validation loss : 0.6264023716960831; validation accuracy : 0.9246861924686193\n",
      "Epoch 34:\t train loss : 0.5723255273807235; train accuracy : 0.9788608073360389; \n",
      " validation loss : 0.6042060196192054; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.5721360793368316; train accuracy : 0.979102326590043; \n",
      " validation loss : 0.6397634766639272; validation accuracy : 0.9121338912133892\n",
      "Epoch 36:\t train loss : 0.5673196660752093; train accuracy : 0.984094674556213; \n",
      " validation loss : 0.645597262898195; validation accuracy : 0.9037656903765691\n",
      "Epoch 37:\t train loss : 0.564466571222842; train accuracy : 0.9868171876452182; \n",
      " validation loss : 0.6288362568475183; validation accuracy : 0.9246861924686193\n",
      "Epoch 38:\t train loss : 0.5643807900010016; train accuracy : 0.9871014591530097; \n",
      " validation loss : 0.623620184522837; validation accuracy : 0.9288702928870293\n",
      "Epoch 39:\t train loss : 0.5633805577183215; train accuracy : 0.9876900771399362; \n",
      " validation loss : 0.6122047699760128; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5644850111294192; train accuracy : 0.9867451903714489; \n",
      " validation loss : 0.6387429554509549; validation accuracy : 0.9121338912133892\n",
      "Epoch 41:\t train loss : 0.5627210672414042; train accuracy : 0.9887023761578735; \n",
      " validation loss : 0.5993778354339162; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5622263087446423; train accuracy : 0.9889958177143034; \n",
      " validation loss : 0.6180995797034268; validation accuracy : 0.9246861924686193\n",
      "Epoch 43:\t train loss : 0.5689847016462003; train accuracy : 0.982216673378977; \n",
      " validation loss : 0.6373017320810439; validation accuracy : 0.9121338912133892\n",
      "Epoch 44:\t train loss : 0.5675736648872329; train accuracy : 0.9835935437900802; \n",
      " validation loss : 0.6365999960385548; validation accuracy : 0.9121338912133892\n",
      "Epoch 45:\t train loss : 0.5731227512477817; train accuracy : 0.9778903931348555; \n",
      " validation loss : 0.6215174454311888; validation accuracy : 0.9288702928870293\n",
      "Epoch 46:\t train loss : 0.5641704455227264; train accuracy : 0.987106044177329; \n",
      " validation loss : 0.612946533179326; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.563802660333212; train accuracy : 0.9874614455218563; \n",
      " validation loss : 0.612323715922728; validation accuracy : 0.9372384937238494\n",
      "Epoch 48:\t train loss : 0.5646442371917695; train accuracy : 0.9866932680690232; \n",
      " validation loss : 0.6157680194263491; validation accuracy : 0.9330543933054394\n",
      "Epoch 49:\t train loss : 0.5611155208793324; train accuracy : 0.9900746615446575; \n",
      " validation loss : 0.6233200203507494; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5621099427230354; train accuracy : 0.9891616221072523; \n",
      " validation loss : 0.5970826439222581; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5662339804325407; train accuracy : 0.9849575265652591; \n",
      " validation loss : 0.6094438804739831; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5698422616992895; train accuracy : 0.9813420490101924; \n",
      " validation loss : 0.6321136512335827; validation accuracy : 0.9163179916317992\n",
      "Epoch 53:\t train loss : 0.5703712734632598; train accuracy : 0.9807660708200377; \n",
      " validation loss : 0.6177344848517679; validation accuracy : 0.9288702928870293\n",
      "Epoch 54:\t train loss : 0.5638866928942349; train accuracy : 0.9874887078286192; \n",
      " validation loss : 0.6101665387723412; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5642740707525791; train accuracy : 0.9869867096254531; \n",
      " validation loss : 0.6085379547029034; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5619641104800008; train accuracy : 0.9892909941448; \n",
      " validation loss : 0.6141858240694626; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.5630609586555468; train accuracy : 0.9883716348090089; \n",
      " validation loss : 0.6069607706062451; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5712090559338177; train accuracy : 0.9797747142104773; \n",
      " validation loss : 0.6178433631339885; validation accuracy : 0.9330543933054394\n",
      "Epoch 59:\t train loss : 0.5626565077945375; train accuracy : 0.9886295114470709; \n",
      " validation loss : 0.6224731297171712; validation accuracy : 0.9288702928870293\n",
      "Epoch 60:\t train loss : 0.5632562011690425; train accuracy : 0.9879789336720468; \n",
      " validation loss : 0.6168429402759761; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5609659926399945; train accuracy : 0.9902869357786797; \n",
      " validation loss : 0.5990945275612688; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.560770367741537; train accuracy : 0.9906641469686174; \n",
      " validation loss : 0.6005850404456021; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.563575340480145; train accuracy : 0.9875661575637411; \n",
      " validation loss : 0.5880469790518751; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.560386751946762; train accuracy : 0.9910140958517922; \n",
      " validation loss : 0.6084914708344245; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.572420365321307; train accuracy : 0.9786516310914216; \n",
      " validation loss : 0.7052743525985294; validation accuracy : 0.8451882845188284\n",
      "Epoch 66:\t train loss : 0.5902388401475607; train accuracy : 0.9603021159267635; \n",
      " validation loss : 0.6165295005443066; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5777773026140716; train accuracy : 0.9732990489172527; \n",
      " validation loss : 0.6105859148645744; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5691877374876377; train accuracy : 0.9819642492022678; \n",
      " validation loss : 0.6159878631181247; validation accuracy : 0.9372384937238494\n",
      "Epoch 69:\t train loss : 0.5684127518716783; train accuracy : 0.9827780290591406; \n",
      " validation loss : 0.6090355580758943; validation accuracy : 0.9414225941422594\n",
      "Epoch 70:\t train loss : 0.5614262602520478; train accuracy : 0.9898850645930791; \n",
      " validation loss : 0.587381981415323; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5599646902514146; train accuracy : 0.9914222869357787; \n",
      " validation loss : 0.622394994390859; validation accuracy : 0.9288702928870293\n",
      "Epoch 72:\t train loss : 0.5604194863320058; train accuracy : 0.9909484184764088; \n",
      " validation loss : 0.6167075501487846; validation accuracy : 0.9330543933054394\n",
      "Epoch 73:\t train loss : 0.5637785493187123; train accuracy : 0.987576195049413; \n",
      " validation loss : 0.6130591562035086; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5621327620890774; train accuracy : 0.9891297747761703; \n",
      " validation loss : 0.6036494841084608; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5632666782140593; train accuracy : 0.9879224263453019; \n",
      " validation loss : 0.5928987745576357; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5605583535020555; train accuracy : 0.9907725765977881; \n",
      " validation loss : 0.6052987851942098; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5602371046088616; train accuracy : 0.9910413581585551; \n",
      " validation loss : 0.6082310897854691; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5609730081855927; train accuracy : 0.9903853279221785; \n",
      " validation loss : 0.6106375008969996; validation accuracy : 0.9372384937238494\n",
      "Epoch 79:\t train loss : 0.5723128859116183; train accuracy : 0.9788708448217107; \n",
      " validation loss : 0.5940402885726296; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80:\t train loss : 0.5674069173102723; train accuracy : 0.983588958765761; \n",
      " validation loss : 0.6052248200070752; validation accuracy : 0.9497907949790795\n",
      "Epoch 81:\t train loss : 0.5591026769640884; train accuracy : 0.9922185941324081; \n",
      " validation loss : 0.6142932870919648; validation accuracy : 0.9372384937238494\n",
      "Epoch 82:\t train loss : 0.560514371384936; train accuracy : 0.9908190464388612; \n",
      " validation loss : 0.6059644595997772; validation accuracy : 0.9456066945606695\n",
      "Epoch 83:\t train loss : 0.5609073446934136; train accuracy : 0.9904062703305555; \n",
      " validation loss : 0.6083011328379434; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5587958986245964; train accuracy : 0.99254388301992; \n",
      " validation loss : 0.5852489276235764; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.5638771845508675; train accuracy : 0.9874878403915859; \n",
      " validation loss : 0.6241604410744843; validation accuracy : 0.9288702928870293\n",
      "Epoch 86:\t train loss : 0.5704435161923652; train accuracy : 0.9806713962638248; \n",
      " validation loss : 0.6382679371663197; validation accuracy : 0.9121338912133892\n",
      "Epoch 87:\t train loss : 0.5643476674640062; train accuracy : 0.9868636574862913; \n",
      " validation loss : 0.6035317447665993; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5608311626118133; train accuracy : 0.9904673626816196; \n",
      " validation loss : 0.6001269969672892; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.5629231303337194; train accuracy : 0.9882167353387651; \n",
      " validation loss : 0.6129681205682924; validation accuracy : 0.9414225941422594\n",
      "Epoch 90:\t train loss : 0.5617480605902465; train accuracy : 0.9895589082685338; \n",
      " validation loss : 0.6155376983095954; validation accuracy : 0.9372384937238494\n",
      "Epoch 91:\t train loss : 0.5584422402342886; train accuracy : 0.9928427770377025; \n",
      " validation loss : 0.6053981699010086; validation accuracy : 0.9456066945606695\n",
      "Epoch 92:\t train loss : 0.5624712754521844; train accuracy : 0.9888153908113634; \n",
      " validation loss : 0.5912404756319893; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5598896921992043; train accuracy : 0.9914286068341647; \n",
      " validation loss : 0.5970668838233245; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.592628862317572; train accuracy : 0.9583039127606183; \n",
      " validation loss : 0.5955092417715983; validation accuracy : 0.9539748953974896\n",
      "Epoch 95:\t train loss : 0.5673851249590326; train accuracy : 0.9838941726819295; \n",
      " validation loss : 0.6122362760868463; validation accuracy : 0.9372384937238494\n",
      "Epoch 96:\t train loss : 0.5626448688353138; train accuracy : 0.9886860187738158; \n",
      " validation loss : 0.6120031959928989; validation accuracy : 0.9414225941422594\n",
      "Epoch 97:\t train loss : 0.5651721325093491; train accuracy : 0.9860162954242696; \n",
      " validation loss : 0.6154949246962801; validation accuracy : 0.9372384937238494\n",
      "Epoch 98:\t train loss : 0.5627591710329384; train accuracy : 0.9885620991976207; \n",
      " validation loss : 0.6084491414911979; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5608714173902101; train accuracy : 0.9903388580811053; \n",
      " validation loss : 0.6149648544482079; validation accuracy : 0.9372384937238494\n",
      "Epoch 100:\t train loss : 0.5572749077381034; train accuracy : 0.9940928777223582; \n",
      " validation loss : 0.5801900821112526; validation accuracy : 0.9707112970711297\n",
      "Epoch 101:\t train loss : 0.556284926980297; train accuracy : 0.9951252517116391; \n",
      " validation loss : 0.6188316078915627; validation accuracy : 0.9330543933054394\n",
      "Epoch 102:\t train loss : 0.5571286370601871; train accuracy : 0.9942213823228725; \n",
      " validation loss : 0.6026294049481526; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.5586840606298548; train accuracy : 0.9926915951547446; \n",
      " validation loss : 0.6306065066832904; validation accuracy : 0.9163179916317992\n",
      "Epoch 104:\t train loss : 0.5613446762788717; train accuracy : 0.9901320363084358; \n",
      " validation loss : 0.6094982604003565; validation accuracy : 0.9414225941422594\n",
      "Epoch 105:\t train loss : 0.5653940240016984; train accuracy : 0.9858295486229437; \n",
      " validation loss : 0.6426315902215396; validation accuracy : 0.9079497907949791\n",
      "Epoch 106:\t train loss : 0.5635499217765766; train accuracy : 0.9876946621642554; \n",
      " validation loss : 0.6101908576933194; validation accuracy : 0.9372384937238494\n",
      "Epoch 107:\t train loss : 0.5632104887497638; train accuracy : 0.9879178413209827; \n",
      " validation loss : 0.629190177123316; validation accuracy : 0.9246861924686193\n",
      "Epoch 108:\t train loss : 0.5625264556648812; train accuracy : 0.9887571486105518; \n",
      " validation loss : 0.6384236775642115; validation accuracy : 0.9121338912133892\n",
      "Epoch 109:\t train loss : 0.5639009246609612; train accuracy : 0.9873639208153908; \n",
      " validation loss : 0.6230715230576133; validation accuracy : 0.9246861924686193\n",
      "Epoch 110:\t train loss : 0.5589478222668156; train accuracy : 0.9923215713002261; \n",
      " validation loss : 0.607527130827105; validation accuracy : 0.9414225941422594\n",
      "Epoch 111:\t train loss : 0.5635756943667288; train accuracy : 0.9876381548375105; \n",
      " validation loss : 0.6048420127307518; validation accuracy : 0.9456066945606695\n",
      "Epoch 112:\t train loss : 0.5574044894755756; train accuracy : 0.9938504910313206; \n",
      " validation loss : 0.605456530596128; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5652366589584672; train accuracy : 0.9858923758480745; \n",
      " validation loss : 0.6156280960690305; validation accuracy : 0.9372384937238494\n",
      "Epoch 114:\t train loss : 0.5576229329264639; train accuracy : 0.9937411939651166; \n",
      " validation loss : 0.6114834240942468; validation accuracy : 0.9414225941422594\n",
      "Epoch 115:\t train loss : 0.5629846891468251; train accuracy : 0.9882832801511818; \n",
      " validation loss : 0.591098724604228; validation accuracy : 0.9623430962343096\n",
      "Epoch 116:\t train loss : 0.5727561724601856; train accuracy : 0.9780754050621147; \n",
      " validation loss : 0.6389512664456849; validation accuracy : 0.9121338912133892\n",
      "Epoch 117:\t train loss : 0.5650612121119625; train accuracy : 0.9860535952167043; \n",
      " validation loss : 0.5951731474231347; validation accuracy : 0.9581589958158996\n",
      "Epoch 118:\t train loss : 0.5584523552039116; train accuracy : 0.9928737569317513; \n",
      " validation loss : 0.6024959132009146; validation accuracy : 0.9497907949790795\n",
      "Epoch 119:\t train loss : 0.5574545491390359; train accuracy : 0.9939635056848105; \n",
      " validation loss : 0.596636811033048; validation accuracy : 0.9539748953974896\n",
      "Epoch 120:\t train loss : 0.5574441400139418; train accuracy : 0.9939635056848105; \n",
      " validation loss : 0.5935909521887782; validation accuracy : 0.9581589958158996\n",
      "Epoch 121:\t train loss : 0.5572766579125319; train accuracy : 0.9941229901793736; \n",
      " validation loss : 0.613040029487104; validation accuracy : 0.9372384937238494\n",
      "Epoch 122:\t train loss : 0.5556763384021619; train accuracy : 0.9956828898045168; \n",
      " validation loss : 0.5947342594331229; validation accuracy : 0.9581589958158996\n",
      "Epoch 123:\t train loss : 0.5581799411485678; train accuracy : 0.99308516372874; \n",
      " validation loss : 0.6170349692927488; validation accuracy : 0.9330543933054394\n",
      "Epoch 124:\t train loss : 0.5628042280962823; train accuracy : 0.9885374392019579; \n",
      " validation loss : 0.5960231379575454; validation accuracy : 0.9539748953974896\n",
      "Epoch 125:\t train loss : 0.5630001750213678; train accuracy : 0.9883280151181882; \n",
      " validation loss : 0.6373433033115721; validation accuracy : 0.9121338912133892\n",
      "Epoch 126:\t train loss : 0.5627084939311193; train accuracy : 0.9885684190960067; \n",
      " validation loss : 0.5970201047041699; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.5578191808730018; train accuracy : 0.9935142972211035; \n",
      " validation loss : 0.6077004158178813; validation accuracy : 0.9456066945606695\n",
      "Epoch 128:\t train loss : 0.5585844717096375; train accuracy : 0.9927498373555562; \n",
      " validation loss : 0.5941030036929861; validation accuracy : 0.9581589958158996\n",
      "Epoch 129:\t train loss : 0.5575949355135794; train accuracy : 0.9937675888348462; \n",
      " validation loss : 0.6097009392187435; validation accuracy : 0.9372384937238494\n",
      "Epoch 130:\t train loss : 0.5577257655506144; train accuracy : 0.9936227268502742; \n",
      " validation loss : 0.6226145345998905; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131:\t train loss : 0.5586253556151876; train accuracy : 0.9927125375631215; \n",
      " validation loss : 0.6152754316052207; validation accuracy : 0.9372384937238494\n",
      "Epoch 132:\t train loss : 0.559654565343866; train accuracy : 0.9917234115059327; \n",
      " validation loss : 0.6098131611126966; validation accuracy : 0.9414225941422594\n",
      "Epoch 133:\t train loss : 0.5773979968294704; train accuracy : 0.9735050032528889; \n",
      " validation loss : 0.5840567465563601; validation accuracy : 0.9665271966527197\n",
      "Epoch 134:\t train loss : 0.5584693097627402; train accuracy : 0.9928846618544565; \n",
      " validation loss : 0.5905091253930036; validation accuracy : 0.9623430962343096\n",
      "Epoch 135:\t train loss : 0.5570750348596851; train accuracy : 0.9942988320579943; \n",
      " validation loss : 0.6012152994810382; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.5578179358318521; train accuracy : 0.9935561820378574; \n",
      " validation loss : 0.598647899861566; validation accuracy : 0.9539748953974896\n",
      "Epoch 137:\t train loss : 0.5562934872913838; train accuracy : 0.9950842343319186; \n",
      " validation loss : 0.5973507378202956; validation accuracy : 0.9539748953974896\n",
      "Epoch 138:\t train loss : 0.5556903704545617; train accuracy : 0.9956418724247963; \n",
      " validation loss : 0.6122714622838102; validation accuracy : 0.9372384937238494\n",
      "Epoch 139:\t train loss : 0.5570293274289395; train accuracy : 0.994268719600979; \n",
      " validation loss : 0.5930253051923986; validation accuracy : 0.9581589958158996\n",
      "Epoch 140:\t train loss : 0.5564217806997335; train accuracy : 0.995036897053812; \n",
      " validation loss : 0.5878055392982074; validation accuracy : 0.9623430962343096\n",
      "Epoch 141:\t train loss : 0.558396587967515; train accuracy : 0.992801759657982; \n",
      " validation loss : 0.6173078173726619; validation accuracy : 0.9372384937238494\n",
      "Epoch 142:\t train loss : 0.5592816868145052; train accuracy : 0.9919753400043372; \n",
      " validation loss : 0.6058549934833195; validation accuracy : 0.9456066945606695\n",
      "Epoch 143:\t train loss : 0.5570305655541206; train accuracy : 0.9942678521639455; \n",
      " validation loss : 0.6166593075427209; validation accuracy : 0.9372384937238494\n",
      "Epoch 144:\t train loss : 0.5561299681598697; train accuracy : 0.9951507791443354; \n",
      " validation loss : 0.6352569996624873; validation accuracy : 0.9121338912133892\n",
      "Epoch 145:\t train loss : 0.5580075089725215; train accuracy : 0.9933849251835558; \n",
      " validation loss : 0.6137795575604964; validation accuracy : 0.9414225941422594\n",
      "Epoch 146:\t train loss : 0.5569937678835588; train accuracy : 0.9943197744663713; \n",
      " validation loss : 0.5951264339420441; validation accuracy : 0.9539748953974896\n",
      "Epoch 147:\t train loss : 0.560027486706094; train accuracy : 0.9912837448495926; \n",
      " validation loss : 0.598829836063043; validation accuracy : 0.9539748953974896\n",
      "Epoch 148:\t train loss : 0.5564487989158833; train accuracy : 0.9949494098330184; \n",
      " validation loss : 0.6307531821098684; validation accuracy : 0.9163179916317992\n",
      "Epoch 149:\t train loss : 0.5573594814056057; train accuracy : 0.9939635056848105; \n",
      " validation loss : 0.6122745659090834; validation accuracy : 0.9372384937238494\n",
      "Epoch 150:\t train loss : 0.5773690872851153; train accuracy : 0.973738219895288; \n",
      " validation loss : 0.6023832795054286; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 150\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5572749077381034; Train accuracy : 0.9940928777223582; \n",
      " Validation loss : 0.5801900821112526; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 7 ! ---\n",
      "Epoch 1:\t train loss : 0.9619635855969509; train accuracy : 0.5635108814379468; \n",
      " validation loss : 0.8159202175465236; validation accuracy : 0.7196652719665272\n",
      "Epoch 2:\t train loss : 0.7535030392649692; train accuracy : 0.7953106433924383; \n",
      " validation loss : 0.718336616643696; validation accuracy : 0.8326359832635983\n",
      "Epoch 3:\t train loss : 0.7059373873777769; train accuracy : 0.8446742064400204; \n",
      " validation loss : 0.6935517324923007; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.689147685510133; train accuracy : 0.8611668027450184; \n",
      " validation loss : 0.718354646099852; validation accuracy : 0.8242677824267782\n",
      "Epoch 5:\t train loss : 0.6723568292550216; train accuracy : 0.8779085373592539; \n",
      " validation loss : 0.6735199668189635; validation accuracy : 0.8786610878661087\n",
      "Epoch 6:\t train loss : 0.6534226809399435; train accuracy : 0.8967315212427135; \n",
      " validation loss : 0.6496371439609487; validation accuracy : 0.895397489539749\n",
      "Epoch 7:\t train loss : 0.6448248920297917; train accuracy : 0.9047765000514666; \n",
      " validation loss : 0.6738569523532664; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6331291173716445; train accuracy : 0.9171768522229073; \n",
      " validation loss : 0.6478568552416869; validation accuracy : 0.899581589958159\n",
      "Epoch 9:\t train loss : 0.6276282445962428; train accuracy : 0.9229968750281068; \n",
      " validation loss : 0.6601165143902963; validation accuracy : 0.891213389121339\n",
      "Epoch 10:\t train loss : 0.6192377019661299; train accuracy : 0.9312642095280164; \n",
      " validation loss : 0.6217737655522486; validation accuracy : 0.9330543933054394\n",
      "Epoch 11:\t train loss : 0.6128066203113509; train accuracy : 0.9379304831164574; \n",
      " validation loss : 0.6158734907391444; validation accuracy : 0.9372384937238494\n",
      "Epoch 12:\t train loss : 0.6053331521734735; train accuracy : 0.9457810880738401; \n",
      " validation loss : 0.6461426545361957; validation accuracy : 0.899581589958159\n",
      "Epoch 13:\t train loss : 0.6053618098844524; train accuracy : 0.9452487335719119; \n",
      " validation loss : 0.6174136752811975; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.6036933382886476; train accuracy : 0.9473033001581973; \n",
      " validation loss : 0.6625928622560933; validation accuracy : 0.8828451882845189\n",
      "Epoch 15:\t train loss : 0.5971273789872763; train accuracy : 0.9538132751844053; \n",
      " validation loss : 0.6069558901363327; validation accuracy : 0.9456066945606695\n",
      "Epoch 16:\t train loss : 0.6010380055015847; train accuracy : 0.9497366209330145; \n",
      " validation loss : 0.6199602297666236; validation accuracy : 0.9246861924686193\n",
      "Epoch 17:\t train loss : 0.5995127042178738; train accuracy : 0.951264529320471; \n",
      " validation loss : 0.6317904073312834; validation accuracy : 0.9163179916317992\n",
      "Epoch 18:\t train loss : 0.5960763859216788; train accuracy : 0.954810228161923; \n",
      " validation loss : 0.6029640655921622; validation accuracy : 0.9414225941422594\n",
      "Epoch 19:\t train loss : 0.587858016853771; train accuracy : 0.963231162975229; \n",
      " validation loss : 0.6179562174580009; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.5876158602729534; train accuracy : 0.9632325620672184; \n",
      " validation loss : 0.6257194553836762; validation accuracy : 0.9288702928870293\n",
      "Epoch 21:\t train loss : 0.589534338049352; train accuracy : 0.9618243759799889; \n",
      " validation loss : 0.6040383686391303; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5797670722425616; train accuracy : 0.9712901327038752; \n",
      " validation loss : 0.5923836296518707; validation accuracy : 0.9581589958158996\n",
      "Epoch 23:\t train loss : 0.5789203317423501; train accuracy : 0.9723237618785409; \n",
      " validation loss : 0.604885392533538; validation accuracy : 0.9497907949790795\n",
      "Epoch 24:\t train loss : 0.5800474328290064; train accuracy : 0.97124786013877; \n",
      " validation loss : 0.6147411313254448; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5784723873134004; train accuracy : 0.973039097625641; \n",
      " validation loss : 0.6078974083902241; validation accuracy : 0.9414225941422594\n",
      "Epoch 26:\t train loss : 0.5805540411764069; train accuracy : 0.9706254640738161; \n",
      " validation loss : 0.6013495402719046; validation accuracy : 0.9497907949790795\n",
      "Epoch 27:\t train loss : 0.5754443052339078; train accuracy : 0.9759216268641652; \n",
      " validation loss : 0.583313152404102; validation accuracy : 0.9665271966527197\n",
      "Epoch 28:\t train loss : 0.5793249174199409; train accuracy : 0.9716267142624436; \n",
      " validation loss : 0.6107071893326489; validation accuracy : 0.9414225941422594\n",
      "Epoch 29:\t train loss : 0.5786484525348214; train accuracy : 0.972402610705652; \n",
      " validation loss : 0.6231868595237522; validation accuracy : 0.9246861924686193\n",
      "Epoch 30:\t train loss : 0.591123842955955; train accuracy : 0.9596079144635131; \n",
      " validation loss : 0.5929190986434485; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:\t train loss : 0.5771392812121198; train accuracy : 0.9741135003382805; \n",
      " validation loss : 0.609244840263025; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5816353040183958; train accuracy : 0.969548263177198; \n",
      " validation loss : 0.6074277496911845; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.5727895703421224; train accuracy : 0.9784802663071667; \n",
      " validation loss : 0.5795502272430226; validation accuracy : 0.9707112970711297\n",
      "Epoch 34:\t train loss : 0.5723815418027989; train accuracy : 0.9788055551946787; \n",
      " validation loss : 0.6036726753497498; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.5732986393442605; train accuracy : 0.977987386186365; \n",
      " validation loss : 0.5936202160162475; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5721383582294024; train accuracy : 0.9792026974493554; \n",
      " validation loss : 0.5990631314778718; validation accuracy : 0.9539748953974896\n",
      "Epoch 37:\t train loss : 0.5858707572051587; train accuracy : 0.9651884926682583; \n",
      " validation loss : 0.6072070158367682; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5724671300666416; train accuracy : 0.9786957264735187; \n",
      " validation loss : 0.6017706174128294; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.575942279691204; train accuracy : 0.9749640483326322; \n",
      " validation loss : 0.5745384383116735; validation accuracy : 0.9790794979079498\n",
      "Epoch 40:\t train loss : 0.5699575379416923; train accuracy : 0.9810220167111544; \n",
      " validation loss : 0.582456612490688; validation accuracy : 0.9665271966527197\n",
      "Epoch 41:\t train loss : 0.5748315230481001; train accuracy : 0.9760497437163281; \n",
      " validation loss : 0.5871578092800089; validation accuracy : 0.9623430962343096\n",
      "Epoch 42:\t train loss : 0.5764395059254969; train accuracy : 0.9745698041970761; \n",
      " validation loss : 0.6003931971663912; validation accuracy : 0.9539748953974896\n",
      "Epoch 43:\t train loss : 0.5699162174739701; train accuracy : 0.9813754873087366; \n",
      " validation loss : 0.5977575804277174; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.565247456217796; train accuracy : 0.9860125778369838; \n",
      " validation loss : 0.5811025465770892; validation accuracy : 0.9707112970711297\n",
      "Epoch 45:\t train loss : 0.5646106368463476; train accuracy : 0.9865364378518342; \n",
      " validation loss : 0.5818831718496891; validation accuracy : 0.9707112970711297\n",
      "Epoch 46:\t train loss : 0.5657859356993692; train accuracy : 0.9856366218324307; \n",
      " validation loss : 0.5774894769996413; validation accuracy : 0.9748953974895398\n",
      "Epoch 47:\t train loss : 0.5714357684314766; train accuracy : 0.9797842200411933; \n",
      " validation loss : 0.5743990141796822; validation accuracy : 0.9748953974895398\n",
      "Epoch 48:\t train loss : 0.5647369493922497; train accuracy : 0.9865012606818175; \n",
      " validation loss : 0.6039650871084448; validation accuracy : 0.9456066945606695\n",
      "Epoch 49:\t train loss : 0.5658957599512155; train accuracy : 0.9851691252377207; \n",
      " validation loss : 0.5929748436425928; validation accuracy : 0.9581589958158996\n",
      "Epoch 50:\t train loss : 0.5694687026407967; train accuracy : 0.9817458469453325; \n",
      " validation loss : 0.5888707846338944; validation accuracy : 0.9665271966527197\n",
      "Epoch 51:\t train loss : 0.5719938025777024; train accuracy : 0.9792730517893887; \n",
      " validation loss : 0.5917072193263596; validation accuracy : 0.9623430962343096\n",
      "Epoch 52:\t train loss : 0.5623950022684451; train accuracy : 0.9889556677716163; \n",
      " validation loss : 0.5832118514898542; validation accuracy : 0.9707112970711297\n",
      "Epoch 53:\t train loss : 0.566098987185516; train accuracy : 0.985101569081666; \n",
      " validation loss : 0.5937531800830699; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5668286931541; train accuracy : 0.984336865374372; \n",
      " validation loss : 0.5959980263277191; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5694221372046353; train accuracy : 0.9816852862492242; \n",
      " validation loss : 0.6038528432801011; validation accuracy : 0.9497907949790795\n",
      "Epoch 56:\t train loss : 0.5672338842376322; train accuracy : 0.9840608445119118; \n",
      " validation loss : 0.5734940844467192; validation accuracy : 0.9790794979079498\n",
      "Epoch 57:\t train loss : 0.5717250600011833; train accuracy : 0.9793026325914481; \n",
      " validation loss : 0.585895177776664; validation accuracy : 0.9665271966527197\n",
      "Epoch 58:\t train loss : 0.5713002024352812; train accuracy : 0.9797546392391338; \n",
      " validation loss : 0.57412884114494; validation accuracy : 0.9748953974895398\n",
      "Epoch 59:\t train loss : 0.5658567221456511; train accuracy : 0.9852648631038456; \n",
      " validation loss : 0.584088744220701; validation accuracy : 0.9665271966527197\n",
      "Epoch 60:\t train loss : 0.5665120113729842; train accuracy : 0.9846396688549132; \n",
      " validation loss : 0.5937739844847785; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5661105001798112; train accuracy : 0.9850523010566142; \n",
      " validation loss : 0.6176915357174853; validation accuracy : 0.9330543933054394\n",
      "Epoch 62:\t train loss : 0.564975400325023; train accuracy : 0.9861928608333191; \n",
      " validation loss : 0.5956943817124636; validation accuracy : 0.9581589958158996\n",
      "Epoch 63:\t train loss : 0.5611214020796537; train accuracy : 0.990210353480591; \n",
      " validation loss : 0.5744410961958966; validation accuracy : 0.9790794979079498\n",
      "Epoch 64:\t train loss : 0.5711163026657727; train accuracy : 0.9799180331964555; \n",
      " validation loss : 0.6083801547265126; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.571472955144205; train accuracy : 0.9795335827048246; \n",
      " validation loss : 0.5899380068802265; validation accuracy : 0.9581589958158996\n",
      "Epoch 66:\t train loss : 0.5670665764983805; train accuracy : 0.984194657667174; \n",
      " validation loss : 0.5966444960819735; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5676322687326648; train accuracy : 0.983470827432996; \n",
      " validation loss : 0.6118094545373735; validation accuracy : 0.9372384937238494\n",
      "Epoch 68:\t train loss : 0.5811652700268455; train accuracy : 0.9696102229652955; \n",
      " validation loss : 0.6175199858780529; validation accuracy : 0.9288702928870293\n",
      "Epoch 69:\t train loss : 0.5722951154042994; train accuracy : 0.9787295045515461; \n",
      " validation loss : 0.5889245527504838; validation accuracy : 0.9623430962343096\n",
      "Epoch 70:\t train loss : 0.5671501756559756; train accuracy : 0.9840594454199225; \n",
      " validation loss : 0.568648581115039; validation accuracy : 0.9832635983263598\n",
      "Epoch 71:\t train loss : 0.5642717723723963; train accuracy : 0.9870321161566143; \n",
      " validation loss : 0.585927022569568; validation accuracy : 0.9665271966527197\n",
      "Epoch 72:\t train loss : 0.5629654763203491; train accuracy : 0.9883276753387051; \n",
      " validation loss : 0.6014730283568822; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5648018066935109; train accuracy : 0.9863815383815904; \n",
      " validation loss : 0.5962153194882104; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5628227992230939; train accuracy : 0.9884220141128408; \n",
      " validation loss : 0.5872736102574647; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.5644016625843457; train accuracy : 0.9868786157783599; \n",
      " validation loss : 0.6004167890242434; validation accuracy : 0.9497907949790795\n",
      "Epoch 76:\t train loss : 0.5623089665887308; train accuracy : 0.9888599299054913; \n",
      " validation loss : 0.6126372959938603; validation accuracy : 0.9372384937238494\n",
      "Epoch 77:\t train loss : 0.5653935346216813; train accuracy : 0.9857422532776228; \n",
      " validation loss : 0.5830350014475514; validation accuracy : 0.9707112970711297\n",
      "Epoch 78:\t train loss : 0.5732536387100401; train accuracy : 0.9779254263982675; \n",
      " validation loss : 0.6055495528817242; validation accuracy : 0.9414225941422594\n",
      "Epoch 79:\t train loss : 0.565632988962726; train accuracy : 0.9855788593203011; \n",
      " validation loss : 0.5831144310713107; validation accuracy : 0.9665271966527197\n",
      "Epoch 80:\t train loss : 0.5630034439619284; train accuracy : 0.9883980296787385; \n",
      " validation loss : 0.6020093256126164; validation accuracy : 0.9497907949790795\n",
      "Epoch 81:\t train loss : 0.563319846510512; train accuracy : 0.9878699723879203; \n",
      " validation loss : 0.5937658112034763; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82:\t train loss : 0.5639539587388206; train accuracy : 0.987341915097102; \n",
      " validation loss : 0.6144377803664647; validation accuracy : 0.9330543933054394\n",
      "Epoch 83:\t train loss : 0.5772476864790651; train accuracy : 0.9736037311784652; \n",
      " validation loss : 0.6042672315411719; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5648774549658003; train accuracy : 0.9864125182756391; \n",
      " validation loss : 0.6045780445203043; validation accuracy : 0.9456066945606695\n",
      "Epoch 85:\t train loss : 0.5639308641567367; train accuracy : 0.987282753492983; \n",
      " validation loss : 0.594619070482043; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5616692999652628; train accuracy : 0.9895879574156372; \n",
      " validation loss : 0.5811394920819709; validation accuracy : 0.9707112970711297\n",
      "Epoch 87:\t train loss : 0.5614732633160643; train accuracy : 0.9897583468329054; \n",
      " validation loss : 0.5972200237497357; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.5668939516837144; train accuracy : 0.9842510210873143; \n",
      " validation loss : 0.6371399181411637; validation accuracy : 0.9163179916317992\n",
      "Epoch 89:\t train loss : 0.5635930332077822; train accuracy : 0.9877939217447876; \n",
      " validation loss : 0.5952551504816647; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5593462911551477; train accuracy : 0.9919438284553325; \n",
      " validation loss : 0.5728520853099837; validation accuracy : 0.9790794979079498\n",
      "Epoch 91:\t train loss : 0.5630620421701994; train accuracy : 0.9883191808516273; \n",
      " validation loss : 0.5839113410758178; validation accuracy : 0.9665271966527197\n",
      "Epoch 92:\t train loss : 0.561848487509292; train accuracy : 0.989371098157296; \n",
      " validation loss : 0.5916326603835453; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5659233409851677; train accuracy : 0.9853085347609402; \n",
      " validation loss : 0.5939979238193774; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5689248195285079; train accuracy : 0.9821218029498855; \n",
      " validation loss : 0.5859622753905263; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5756681336192412; train accuracy : 0.9753147207462357; \n",
      " validation loss : 0.5723094500040653; validation accuracy : 0.9790794979079498\n",
      "Epoch 96:\t train loss : 0.5658934340925207; train accuracy : 0.9853620000619598; \n",
      " validation loss : 0.5840376106227471; validation accuracy : 0.9665271966527197\n",
      "Epoch 97:\t train loss : 0.5617036123665716; train accuracy : 0.9895569775215884; \n",
      " validation loss : 0.5976667729325448; validation accuracy : 0.9539748953974896\n",
      "Epoch 98:\t train loss : 0.5626514453167312; train accuracy : 0.9885825099510418; \n",
      " validation loss : 0.5890881273483412; validation accuracy : 0.9623430962343096\n",
      "Epoch 99:\t train loss : 0.563979980819698; train accuracy : 0.9873137333870318; \n",
      " validation loss : 0.5848497901112539; validation accuracy : 0.9665271966527197\n",
      "Epoch 100:\t train loss : 0.5607456178832297; train accuracy : 0.9906271829582601; \n",
      " validation loss : 0.5758218543166376; validation accuracy : 0.9748953974895398\n",
      "Epoch 101:\t train loss : 0.5628738384126811; train accuracy : 0.9882403320245161; \n",
      " validation loss : 0.5904347645549618; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.5670939898331453; train accuracy : 0.9840904253139713; \n",
      " validation loss : 0.5872918650928517; validation accuracy : 0.9623430962343096\n",
      "Epoch 103:\t train loss : 0.5653296600823602; train accuracy : 0.9858295965918119; \n",
      " validation loss : 0.609523570958291; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.5653339305077826; train accuracy : 0.9858717692217751; \n",
      " validation loss : 0.5877605455187066; validation accuracy : 0.9623430962343096\n",
      "Epoch 105:\t train loss : 0.5640221995673816; train accuracy : 0.9871729247718231; \n",
      " validation loss : 0.5855186872600122; validation accuracy : 0.9665271966527197\n",
      "Epoch 106:\t train loss : 0.5617829719323557; train accuracy : 0.9893879871963096; \n",
      " validation loss : 0.5735553528359706; validation accuracy : 0.9790794979079498\n",
      "Epoch 107:\t train loss : 0.5607802117789852; train accuracy : 0.9905638240781732; \n",
      " validation loss : 0.5754651490441746; validation accuracy : 0.9790794979079498\n",
      "Epoch 108:\t train loss : 0.5616006428431891; train accuracy : 0.9897301651228353; \n",
      " validation loss : 0.5845314721438292; validation accuracy : 0.9665271966527197\n",
      "Epoch 109:\t train loss : 0.5624720809851113; train accuracy : 0.9887782828944015; \n",
      " validation loss : 0.5908769830427809; validation accuracy : 0.9581589958158996\n",
      "Epoch 110:\t train loss : 0.5616158236172214; train accuracy : 0.9896682053347378; \n",
      " validation loss : 0.5849251432370572; validation accuracy : 0.9665271966527197\n",
      "Epoch 111:\t train loss : 0.5787746629576696; train accuracy : 0.9722856865894035; \n",
      " validation loss : 0.5820642143656228; validation accuracy : 0.9665271966527197\n",
      "Epoch 112:\t train loss : 0.5697367456864386; train accuracy : 0.9813599973617122; \n",
      " validation loss : 0.5808106817417996; validation accuracy : 0.9707112970711297\n",
      "Epoch 113:\t train loss : 0.5683748192689161; train accuracy : 0.9826907337138198; \n",
      " validation loss : 0.5939393219763952; validation accuracy : 0.9581589958158996\n",
      "Epoch 114:\t train loss : 0.5630956429988471; train accuracy : 0.988116412448321; \n",
      " validation loss : 0.5708998910348656; validation accuracy : 0.9832635983263598\n",
      "Epoch 115:\t train loss : 0.5602441645241552; train accuracy : 0.9910257243049261; \n",
      " validation loss : 0.5719236489328672; validation accuracy : 0.9790794979079498\n",
      "Epoch 116:\t train loss : 0.5608936087927633; train accuracy : 0.9903624547668562; \n",
      " validation loss : 0.5985899719094668; validation accuracy : 0.9497907949790795\n",
      "Epoch 117:\t train loss : 0.5606038739014345; train accuracy : 0.9906525664843516; \n",
      " validation loss : 0.59891029635632; validation accuracy : 0.9497907949790795\n",
      "Epoch 118:\t train loss : 0.5589635545162884; train accuracy : 0.9923324762229313; \n",
      " validation loss : 0.5974735231997196; validation accuracy : 0.9539748953974896\n",
      "Epoch 119:\t train loss : 0.5652569173056791; train accuracy : 0.9860252696000296; \n",
      " validation loss : 0.5827234773822423; validation accuracy : 0.9665271966527197\n",
      "Epoch 120:\t train loss : 0.562462180370913; train accuracy : 0.9889077988385537; \n",
      " validation loss : 0.5874317353694929; validation accuracy : 0.9623430962343096\n",
      "Early stopping at epoch 120\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5671501756559756; Train accuracy : 0.9840594454199225; \n",
      " Validation loss : 0.568648581115039; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 8 ! ---\n",
      "Epoch 1:\t train loss : 0.9227978665250991; train accuracy : 0.6157791753152204; \n",
      " validation loss : 0.8082799701020429; validation accuracy : 0.7322175732217573\n",
      "Epoch 2:\t train loss : 0.7284598476748932; train accuracy : 0.8223436909445769; \n",
      " validation loss : 0.7088672294301144; validation accuracy : 0.8368200836820083\n",
      "Epoch 3:\t train loss : 0.6757000199869787; train accuracy : 0.875060317853713; \n",
      " validation loss : 0.6469242818435305; validation accuracy : 0.9037656903765691\n",
      "Epoch 4:\t train loss : 0.6525156868504272; train accuracy : 0.8984564577589145; \n",
      " validation loss : 0.6565623956092757; validation accuracy : 0.895397489539749\n",
      "Epoch 5:\t train loss : 0.6410807418756542; train accuracy : 0.9093404380557019; \n",
      " validation loss : 0.6396048148093728; validation accuracy : 0.9037656903765691\n",
      "Epoch 6:\t train loss : 0.6282601266306013; train accuracy : 0.9225186653861643; \n",
      " validation loss : 0.6414698030719347; validation accuracy : 0.9079497907949791\n",
      "Epoch 7:\t train loss : 0.621010146456863; train accuracy : 0.9298755227857121; \n",
      " validation loss : 0.6428457897504237; validation accuracy : 0.9037656903765691\n",
      "Epoch 8:\t train loss : 0.6110285018478121; train accuracy : 0.9400449828061588; \n",
      " validation loss : 0.630127668687138; validation accuracy : 0.9205020920502092\n",
      "Epoch 9:\t train loss : 0.6043956605807244; train accuracy : 0.9467512624306825; \n",
      " validation loss : 0.6010153860966168; validation accuracy : 0.9497907949790795\n",
      "Epoch 10:\t train loss : 0.595269817434769; train accuracy : 0.9559141237336968; \n",
      " validation loss : 0.6343156018831037; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.6091170884710818; train accuracy : 0.9416404473496701; \n",
      " validation loss : 0.6144285177266785; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\t train loss : 0.5912478938745837; train accuracy : 0.9600123919576194; \n",
      " validation loss : 0.6063729723402613; validation accuracy : 0.9414225941422594\n",
      "Epoch 13:\t train loss : 0.5908130057076967; train accuracy : 0.9601208215867901; \n",
      " validation loss : 0.602065597542044; validation accuracy : 0.9539748953974896\n",
      "Epoch 14:\t train loss : 0.5993709876151686; train accuracy : 0.9515594659066265; \n",
      " validation loss : 0.6213751441517847; validation accuracy : 0.9288702928870293\n",
      "Epoch 15:\t train loss : 0.5917318445292022; train accuracy : 0.9593973791009635; \n",
      " validation loss : 0.590385556675948; validation accuracy : 0.9623430962343096\n",
      "Epoch 16:\t train loss : 0.5983257191747927; train accuracy : 0.9522720034697482; \n",
      " validation loss : 0.5975959415257865; validation accuracy : 0.9581589958158996\n",
      "Epoch 17:\t train loss : 0.5833247666408402; train accuracy : 0.9682166114191889; \n",
      " validation loss : 0.6259394941207723; validation accuracy : 0.9205020920502092\n",
      "Epoch 18:\t train loss : 0.5839569220485907; train accuracy : 0.9670649028780322; \n",
      " validation loss : 0.6264660442211271; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.5832897560366023; train accuracy : 0.967792930388178; \n",
      " validation loss : 0.6072459909674367; validation accuracy : 0.9456066945606695\n",
      "Epoch 20:\t train loss : 0.5826783745205639; train accuracy : 0.9685017503640138; \n",
      " validation loss : 0.5971896532764248; validation accuracy : 0.9539748953974896\n",
      "Epoch 21:\t train loss : 0.5819665439125588; train accuracy : 0.9692251928498404; \n",
      " validation loss : 0.6036622839317621; validation accuracy : 0.9497907949790795\n",
      "Epoch 22:\t train loss : 0.5846852416179849; train accuracy : 0.9662912729638464; \n",
      " validation loss : 0.5936279659858603; validation accuracy : 0.9539748953974896\n",
      "Epoch 23:\t train loss : 0.5837444991561275; train accuracy : 0.9673709842312339; \n",
      " validation loss : 0.6097701396146674; validation accuracy : 0.9414225941422594\n",
      "Epoch 24:\t train loss : 0.5811296249719338; train accuracy : 0.9699778803556491; \n",
      " validation loss : 0.6036472082964294; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.576342894110157; train accuracy : 0.9748253663372471; \n",
      " validation loss : 0.6064468296636237; validation accuracy : 0.9414225941422594\n",
      "Epoch 26:\t train loss : 0.5734663280036221; train accuracy : 0.9778166609870195; \n",
      " validation loss : 0.5986014784107775; validation accuracy : 0.9539748953974896\n",
      "Epoch 27:\t train loss : 0.5830993107422716; train accuracy : 0.967862077511695; \n",
      " validation loss : 0.6002304687234834; validation accuracy : 0.9497907949790795\n",
      "Epoch 28:\t train loss : 0.5787285417252667; train accuracy : 0.9725437591003439; \n",
      " validation loss : 0.6285847540157996; validation accuracy : 0.9246861924686193\n",
      "Epoch 29:\t train loss : 0.576218725933708; train accuracy : 0.9749200408934602; \n",
      " validation loss : 0.6038241107239348; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.5759769945507679; train accuracy : 0.9749865857058769; \n",
      " validation loss : 0.6219791510535302; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5798497486430052; train accuracy : 0.9709692369652095; \n",
      " validation loss : 0.5841335992407896; validation accuracy : 0.9707112970711297\n",
      "Epoch 32:\t train loss : 0.574551905520078; train accuracy : 0.9767679296136808; \n",
      " validation loss : 0.615250600077715; validation accuracy : 0.9330543933054394\n",
      "Epoch 33:\t train loss : 0.5901415217081017; train accuracy : 0.9605126552867189; \n",
      " validation loss : 0.6265052696031312; validation accuracy : 0.9246861924686193\n",
      "Epoch 34:\t train loss : 0.5839986587229529; train accuracy : 0.966678521639456; \n",
      " validation loss : 0.6101397377376168; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5733642299856125; train accuracy : 0.9777638712475604; \n",
      " validation loss : 0.614251377530977; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.572358282025178; train accuracy : 0.978972087115462; \n",
      " validation loss : 0.6237911064843419; validation accuracy : 0.9246861924686193\n",
      "Epoch 37:\t train loss : 0.5730407139989695; train accuracy : 0.978363394157192; \n",
      " validation loss : 0.6220921306687085; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5749418044180943; train accuracy : 0.9762886086929583; \n",
      " validation loss : 0.6138631349270343; validation accuracy : 0.9330543933054394\n",
      "Epoch 39:\t train loss : 0.5785072301694247; train accuracy : 0.9725956814027696; \n",
      " validation loss : 0.6351961182238665; validation accuracy : 0.9163179916317992\n",
      "Epoch 40:\t train loss : 0.5766472884755076; train accuracy : 0.9745938845689148; \n",
      " validation loss : 0.6110929690997925; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5711643937105373; train accuracy : 0.9803314848663217; \n",
      " validation loss : 0.6021607945996025; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.568255837917124; train accuracy : 0.9830258682115307; \n",
      " validation loss : 0.6035882936801182; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5739423527034748; train accuracy : 0.9772263081260262; \n",
      " validation loss : 0.6018466172322277; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5719417612843429; train accuracy : 0.9791743238638124; \n",
      " validation loss : 0.6012407997280046; validation accuracy : 0.9497907949790795\n",
      "Epoch 45:\t train loss : 0.5751844172956778; train accuracy : 0.9757082933176369; \n",
      " validation loss : 0.6113277575362418; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.587103397057866; train accuracy : 0.9638493137953468; \n",
      " validation loss : 0.613086235110035; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.5731502013617029; train accuracy : 0.9779405805632144; \n",
      " validation loss : 0.5910067633697456; validation accuracy : 0.9623430962343096\n",
      "Epoch 48:\t train loss : 0.5672074645631504; train accuracy : 0.9840645620991977; \n",
      " validation loss : 0.5924773601163716; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5676542361425001; train accuracy : 0.9836099011741379; \n",
      " validation loss : 0.6108223722212028; validation accuracy : 0.9372384937238494\n",
      "Epoch 50:\t train loss : 0.5679234411958961; train accuracy : 0.9833720995074197; \n",
      " validation loss : 0.5972844455542994; validation accuracy : 0.9539748953974896\n",
      "Epoch 51:\t train loss : 0.566149613005683; train accuracy : 0.98531379534682; \n",
      " validation loss : 0.6055220586822289; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.567219804091281; train accuracy : 0.9839862449270423; \n",
      " validation loss : 0.6287660997277704; validation accuracy : 0.9246861924686193\n",
      "Epoch 53:\t train loss : 0.5916904780297044; train accuracy : 0.9589335481272654; \n",
      " validation loss : 0.6150603259880514; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5706755894535301; train accuracy : 0.9806048514514081; \n",
      " validation loss : 0.5986335564606434; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5662248749477861; train accuracy : 0.9851597633136094; \n",
      " validation loss : 0.6069726339150675; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.5659751764044915; train accuracy : 0.9853657176492456; \n",
      " validation loss : 0.593115339201766; validation accuracy : 0.9581589958158996\n",
      "Epoch 57:\t train loss : 0.5661216365372407; train accuracy : 0.9851580284395427; \n",
      " validation loss : 0.6058622576259725; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5708530970750573; train accuracy : 0.980243997645528; \n",
      " validation loss : 0.5911192475627295; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5664394359123857; train accuracy : 0.9846832925431395; \n",
      " validation loss : 0.5975554508463927; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5642331833010156; train accuracy : 0.9871789088881316; \n",
      " validation loss : 0.6116463319232166; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5708740517595762; train accuracy : 0.9804508194181976; \n",
      " validation loss : 0.6033476912170999; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5665994900408761; train accuracy : 0.9845292605099291; \n",
      " validation loss : 0.5935001895022572; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63:\t train loss : 0.5691920540205955; train accuracy : 0.9818549521360637; \n",
      " validation loss : 0.6330719089562606; validation accuracy : 0.9163179916317992\n",
      "Epoch 64:\t train loss : 0.5690536017758966; train accuracy : 0.9819734192509062; \n",
      " validation loss : 0.6301895130837488; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.5726996463917723; train accuracy : 0.9784399764552805; \n",
      " validation loss : 0.6615576086680947; validation accuracy : 0.8828451882845189\n",
      "Epoch 66:\t train loss : 0.5722910488579149; train accuracy : 0.9788800148703491; \n",
      " validation loss : 0.6349658121208301; validation accuracy : 0.9121338912133892\n",
      "Epoch 67:\t train loss : 0.5671197138703034; train accuracy : 0.984100994454599; \n",
      " validation loss : 0.6055670745022661; validation accuracy : 0.9497907949790795\n",
      "Epoch 68:\t train loss : 0.5628527374912539; train accuracy : 0.988315127482264; \n",
      " validation loss : 0.6067247756200933; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.564896314700797; train accuracy : 0.9863197744663713; \n",
      " validation loss : 0.598843007669174; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.563689233851569; train accuracy : 0.9875552526410359; \n",
      " validation loss : 0.5976258438463469; validation accuracy : 0.9539748953974896\n",
      "Epoch 71:\t train loss : 0.5641433263887699; train accuracy : 0.9871114966386815; \n",
      " validation loss : 0.6095022104475337; validation accuracy : 0.9372384937238494\n",
      "Epoch 72:\t train loss : 0.5636642525159166; train accuracy : 0.9875661575637411; \n",
      " validation loss : 0.6219133319401128; validation accuracy : 0.9246861924686193\n",
      "Epoch 73:\t train loss : 0.5633574427859647; train accuracy : 0.9880208184888007; \n",
      " validation loss : 0.5949877943008106; validation accuracy : 0.9581589958158996\n",
      "Epoch 74:\t train loss : 0.5646559952502503; train accuracy : 0.9865538585458038; \n",
      " validation loss : 0.611207532665304; validation accuracy : 0.9414225941422594\n",
      "Epoch 75:\t train loss : 0.567139497937097; train accuracy : 0.9841583692183773; \n",
      " validation loss : 0.6058393353683811; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5640870316231893; train accuracy : 0.9871114966386815; \n",
      " validation loss : 0.5970871817427605; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5612387265882027; train accuracy : 0.9899507419684624; \n",
      " validation loss : 0.6004302024473823; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5624824737905404; train accuracy : 0.9888300133213545; \n",
      " validation loss : 0.6128467676907658; validation accuracy : 0.9372384937238494\n",
      "Epoch 79:\t train loss : 0.5636692504622626; train accuracy : 0.9874978778772576; \n",
      " validation loss : 0.6063397269034699; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5650714720358206; train accuracy : 0.9862850769850368; \n",
      " validation loss : 0.6135158031491721; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.5684056278896967; train accuracy : 0.9825875646705289; \n",
      " validation loss : 0.6106554566255257; validation accuracy : 0.9414225941422594\n",
      "Early stopping at epoch 81\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5798497486430052; Train accuracy : 0.9709692369652095; \n",
      " Validation loss : 0.5841335992407896; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 9 ! ---\n",
      "Epoch 1:\t train loss : 0.9678170535619824; train accuracy : 0.5573891123608147; \n",
      " validation loss : 0.9076772139984268; validation accuracy : 0.6108786610878661\n",
      "Epoch 2:\t train loss : 0.7843870558840347; train accuracy : 0.7637156958817938; \n",
      " validation loss : 0.7370852868673915; validation accuracy : 0.8158995815899581\n",
      "Epoch 3:\t train loss : 0.7136766848570099; train accuracy : 0.8361261436064836; \n",
      " validation loss : 0.7411020162812975; validation accuracy : 0.803347280334728\n",
      "Epoch 4:\t train loss : 0.6996249939649406; train accuracy : 0.8494664120880285; \n",
      " validation loss : 0.7122262610374958; validation accuracy : 0.8368200836820083\n",
      "Epoch 5:\t train loss : 0.6777762406121334; train accuracy : 0.8723038116683325; \n",
      " validation loss : 0.6859277026068259; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.659920938335852; train accuracy : 0.8905406969823952; \n",
      " validation loss : 0.6741840707703803; validation accuracy : 0.8702928870292888\n",
      "Epoch 7:\t train loss : 0.6494716821523899; train accuracy : 0.9011100585193893; \n",
      " validation loss : 0.6669046553209009; validation accuracy : 0.8828451882845189\n",
      "Epoch 8:\t train loss : 0.645064431303383; train accuracy : 0.9054369714055578; \n",
      " validation loss : 0.6698968133538954; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.632414354662916; train accuracy : 0.9181886219001762; \n",
      " validation loss : 0.6435915131261024; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.6240676933583547; train accuracy : 0.926887123940773; \n",
      " validation loss : 0.6497803086497927; validation accuracy : 0.895397489539749\n",
      "Epoch 11:\t train loss : 0.6137712938155205; train accuracy : 0.9374359409164504; \n",
      " validation loss : 0.6346340852751453; validation accuracy : 0.9205020920502092\n",
      "Epoch 12:\t train loss : 0.6036414273657867; train accuracy : 0.9480431305345989; \n",
      " validation loss : 0.6363516501793953; validation accuracy : 0.9163179916317992\n",
      "Epoch 13:\t train loss : 0.6036264277207976; train accuracy : 0.9473907591867615; \n",
      " validation loss : 0.6230299518648177; validation accuracy : 0.9288702928870293\n",
      "Epoch 14:\t train loss : 0.5997428978770803; train accuracy : 0.9513304233973204; \n",
      " validation loss : 0.6465528928537029; validation accuracy : 0.9037656903765691\n",
      "Epoch 15:\t train loss : 0.5980940088419333; train accuracy : 0.9532356868813193; \n",
      " validation loss : 0.6204683850118661; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.5906342762503036; train accuracy : 0.9606692309322828; \n",
      " validation loss : 0.631040207360276; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.5916060737645389; train accuracy : 0.9598551119270962; \n",
      " validation loss : 0.6198285142699859; validation accuracy : 0.9288702928870293\n",
      "Epoch 18:\t train loss : 0.5859341825656939; train accuracy : 0.9654417651365317; \n",
      " validation loss : 0.6029839574089633; validation accuracy : 0.9497907949790795\n",
      "Epoch 19:\t train loss : 0.5804085016130517; train accuracy : 0.9712402229900163; \n",
      " validation loss : 0.6170349417054113; validation accuracy : 0.9372384937238494\n",
      "Epoch 20:\t train loss : 0.5861600916119742; train accuracy : 0.9651303356753046; \n",
      " validation loss : 0.6245188077410808; validation accuracy : 0.9246861924686193\n",
      "Epoch 21:\t train loss : 0.5848861435882907; train accuracy : 0.965989130948751; \n",
      " validation loss : 0.6143935958994582; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5858297239604364; train accuracy : 0.9652816479999218; \n",
      " validation loss : 0.6163166894429087; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5877204031349009; train accuracy : 0.9633833957551023; \n",
      " validation loss : 0.623399499166016; validation accuracy : 0.9246861924686193\n",
      "Epoch 24:\t train loss : 0.5789242863074937; train accuracy : 0.9722985940019664; \n",
      " validation loss : 0.6041233084232348; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5825304836186272; train accuracy : 0.9685346999271157; \n",
      " validation loss : 0.6034103017765569; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5822512259299065; train accuracy : 0.968760037893302; \n",
      " validation loss : 0.6119983475306534; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5781014495335661; train accuracy : 0.973300385944259; \n",
      " validation loss : 0.5909391010152463; validation accuracy : 0.9581589958158996\n",
      "Epoch 28:\t train loss : 0.5770910215841368; train accuracy : 0.9739286255851531; \n",
      " validation loss : 0.6068606896464188; validation accuracy : 0.9414225941422594\n",
      "Epoch 29:\t train loss : 0.5738926174116517; train accuracy : 0.9771280333800205; \n",
      " validation loss : 0.6172533928507745; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5720824991712707; train accuracy : 0.9794482643921989; \n",
      " validation loss : 0.5971933458420466; validation accuracy : 0.9539748953974896\n",
      "Epoch 31:\t train loss : 0.5735176355057295; train accuracy : 0.9780266133595086; \n",
      " validation loss : 0.6032720206656574; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:\t train loss : 0.5701490369969576; train accuracy : 0.9812587946212382; \n",
      " validation loss : 0.597032077134545; validation accuracy : 0.9497907949790795\n",
      "Epoch 33:\t train loss : 0.5867358298757555; train accuracy : 0.9642594745483866; \n",
      " validation loss : 0.6035542092923085; validation accuracy : 0.9456066945606695\n",
      "Epoch 34:\t train loss : 0.5732512417551757; train accuracy : 0.9779216078238907; \n",
      " validation loss : 0.6001855490562451; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.5708113803862149; train accuracy : 0.9803070596656455; \n",
      " validation loss : 0.5877028006238896; validation accuracy : 0.9623430962343096\n",
      "Epoch 36:\t train loss : 0.5734538919353245; train accuracy : 0.9774999551606797; \n",
      " validation loss : 0.5962586662443063; validation accuracy : 0.9539748953974896\n",
      "Epoch 37:\t train loss : 0.5702536216017692; train accuracy : 0.9809421474936451; \n",
      " validation loss : 0.5936950277917495; validation accuracy : 0.9581589958158996\n",
      "Epoch 38:\t train loss : 0.5738185658973988; train accuracy : 0.9771867321266393; \n",
      " validation loss : 0.59331288206326; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5711877787683862; train accuracy : 0.9799886189652389; \n",
      " validation loss : 0.6122779592394734; validation accuracy : 0.9372384937238494\n",
      "Epoch 40:\t train loss : 0.5711272427946504; train accuracy : 0.9799851948716862; \n",
      " validation loss : 0.607511965800681; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5704712373720018; train accuracy : 0.9807389846095147; \n",
      " validation loss : 0.6048132373101445; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5663803632637888; train accuracy : 0.9849264879724637; \n",
      " validation loss : 0.5967039147167627; validation accuracy : 0.9539748953974896\n",
      "Epoch 43:\t train loss : 0.5718309462776725; train accuracy : 0.9794877229940926; \n",
      " validation loss : 0.6188553869017065; validation accuracy : 0.9288702928870293\n",
      "Epoch 44:\t train loss : 0.588063865253682; train accuracy : 0.9627947777681758; \n",
      " validation loss : 0.5967576322406135; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5666165958594521; train accuracy : 0.9845064658299921; \n",
      " validation loss : 0.6019807943332119; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5679791728823647; train accuracy : 0.9833121093883753; \n",
      " validation loss : 0.6069734030720142; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5668455860946997; train accuracy : 0.9845082594028055; \n",
      " validation loss : 0.5848180980275434; validation accuracy : 0.9665271966527197\n",
      "Epoch 48:\t train loss : 0.5663002573069253; train accuracy : 0.9848611040908135; \n",
      " validation loss : 0.5949648539753584; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5726588131100122; train accuracy : 0.9784065246917908; \n",
      " validation loss : 0.6666226343878348; validation accuracy : 0.8786610878661087\n",
      "Epoch 50:\t train loss : 0.5782599867306839; train accuracy : 0.9726842121568365; \n",
      " validation loss : 0.5961421338712282; validation accuracy : 0.9539748953974896\n",
      "Epoch 51:\t train loss : 0.5721594122939183; train accuracy : 0.9789662824616298; \n",
      " validation loss : 0.5827218057037625; validation accuracy : 0.9665271966527197\n",
      "Epoch 52:\t train loss : 0.5656719840288417; train accuracy : 0.985490974252447; \n",
      " validation loss : 0.6073878539344957; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5692478277074272; train accuracy : 0.9817287106983358; \n",
      " validation loss : 0.5807519354515467; validation accuracy : 0.9707112970711297\n",
      "Epoch 54:\t train loss : 0.5748878949298952; train accuracy : 0.9765464266322735; \n",
      " validation loss : 0.6126369032533014; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.5736289540112862; train accuracy : 0.9774723993601837; \n",
      " validation loss : 0.5895372145802279; validation accuracy : 0.9623430962343096\n",
      "Epoch 56:\t train loss : 0.5648812246419584; train accuracy : 0.9864376545937477; \n",
      " validation loss : 0.5884944383978722; validation accuracy : 0.9623430962343096\n",
      "Epoch 57:\t train loss : 0.5673659089031893; train accuracy : 0.9838576816277814; \n",
      " validation loss : 0.5880752523140669; validation accuracy : 0.9623430962343096\n",
      "Epoch 58:\t train loss : 0.5651841408852147; train accuracy : 0.9860848099057395; \n",
      " validation loss : 0.5898395991298027; validation accuracy : 0.9623430962343096\n",
      "Epoch 59:\t train loss : 0.5629546469542186; train accuracy : 0.988377322065348; \n",
      " validation loss : 0.6137758660564278; validation accuracy : 0.9372384937238494\n",
      "Epoch 60:\t train loss : 0.5772833304006999; train accuracy : 0.9735775744699585; \n",
      " validation loss : 0.6126570939603057; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5669202960552657; train accuracy : 0.9842638443439682; \n",
      " validation loss : 0.5924249927951604; validation accuracy : 0.9581589958158996\n",
      "Epoch 62:\t train loss : 0.5656470977435158; train accuracy : 0.9856356014420325; \n",
      " validation loss : 0.5814950040091932; validation accuracy : 0.9707112970711297\n",
      "Epoch 63:\t train loss : 0.5629132966430244; train accuracy : 0.988496023975177; \n",
      " validation loss : 0.5898743615521965; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.5637393986766146; train accuracy : 0.9875235814061937; \n",
      " validation loss : 0.6068955977707224; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.5637184710710055; train accuracy : 0.9876372287017304; \n",
      " validation loss : 0.5964588234375081; validation accuracy : 0.9581589958158996\n",
      "Epoch 66:\t train loss : 0.5725306295564457; train accuracy : 0.9784430483563535; \n",
      " validation loss : 0.6173484232269142; validation accuracy : 0.9330543933054394\n",
      "Epoch 67:\t train loss : 0.5670446041866036; train accuracy : 0.9842914001444641; \n",
      " validation loss : 0.590965239334887; validation accuracy : 0.9623430962343096\n",
      "Epoch 68:\t train loss : 0.5616145184486044; train accuracy : 0.9897748413910951; \n",
      " validation loss : 0.6018915589188697; validation accuracy : 0.9497907949790795\n",
      "Epoch 69:\t train loss : 0.5633665689649129; train accuracy : 0.987955669402137; \n",
      " validation loss : 0.5895272441530484; validation accuracy : 0.9623430962343096\n",
      "Epoch 70:\t train loss : 0.5622217151655972; train accuracy : 0.9891053495754939; \n",
      " validation loss : 0.59503181384279; validation accuracy : 0.9539748953974896\n",
      "Epoch 71:\t train loss : 0.5592609810809892; train accuracy : 0.9920140355225249; \n",
      " validation loss : 0.5832200341767207; validation accuracy : 0.9665271966527197\n",
      "Epoch 72:\t train loss : 0.5603120600995117; train accuracy : 0.9909607191248669; \n",
      " validation loss : 0.6057333261359674; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5756301923898897; train accuracy : 0.9753122854846152; \n",
      " validation loss : 0.6379208016318186; validation accuracy : 0.9121338912133892\n",
      "Epoch 74:\t train loss : 0.5886300133698683; train accuracy : 0.9620150627505907; \n",
      " validation loss : 0.5904696414302487; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.5678837458959644; train accuracy : 0.9831847657186276; \n",
      " validation loss : 0.5994420642389569; validation accuracy : 0.9539748953974896\n",
      "Epoch 76:\t train loss : 0.5599797881395732; train accuracy : 0.9915304230712162; \n",
      " validation loss : 0.6049161515802919; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.560173606571243; train accuracy : 0.9910570829005659; \n",
      " validation loss : 0.6265252488410796; validation accuracy : 0.9205020920502092\n",
      "Epoch 78:\t train loss : 0.5867504938460046; train accuracy : 0.9640460393835979; \n",
      " validation loss : 0.5791995527592328; validation accuracy : 0.9707112970711297\n",
      "Epoch 79:\t train loss : 0.5659074461719291; train accuracy : 0.9853877622896424; \n",
      " validation loss : 0.597120987992784; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5628877116411283; train accuracy : 0.9882379125421286; \n",
      " validation loss : 0.5850804553484312; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.577429049078606; train accuracy : 0.9735878467506167; \n",
      " validation loss : 0.5954992547528727; validation accuracy : 0.9581589958158996\n",
      "Epoch 82:\t train loss : 0.5634264615174959; train accuracy : 0.9876802744492509; \n",
      " validation loss : 0.6012066942561638; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:\t train loss : 0.5630733801893945; train accuracy : 0.988079588978332; \n",
      " validation loss : 0.5889992074702396; validation accuracy : 0.9623430962343096\n",
      "Epoch 84:\t train loss : 0.5589858424557417; train accuracy : 0.9922842128090448; \n",
      " validation loss : 0.5905540212719184; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5586516383110526; train accuracy : 0.99265597153763; \n",
      " validation loss : 0.5901561094581432; validation accuracy : 0.9623430962343096\n",
      "Epoch 86:\t train loss : 0.561201012435766; train accuracy : 0.9900502363439811; \n",
      " validation loss : 0.5958369679267882; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5601538009336505; train accuracy : 0.9911069768351919; \n",
      " validation loss : 0.6082986423964019; validation accuracy : 0.9414225941422594\n",
      "Epoch 88:\t train loss : 0.5624788211918235; train accuracy : 0.9886406511647625; \n",
      " validation loss : 0.5876417703928969; validation accuracy : 0.9623430962343096\n",
      "Epoch 89:\t train loss : 0.5637013936378875; train accuracy : 0.9874409140047057; \n",
      " validation loss : 0.6329398153139606; validation accuracy : 0.9205020920502092\n",
      "Epoch 90:\t train loss : 0.5670212479793822; train accuracy : 0.9841055207801715; \n",
      " validation loss : 0.5955831492806062; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5584288222352993; train accuracy : 0.9929709881444837; \n",
      " validation loss : 0.5709073938499944; validation accuracy : 0.9790794979079498\n",
      "Epoch 92:\t train loss : 0.5727945457415622; train accuracy : 0.9780677024821417; \n",
      " validation loss : 0.6305158204436786; validation accuracy : 0.9205020920502092\n",
      "Epoch 93:\t train loss : 0.5644003019959531; train accuracy : 0.9868524590698532; \n",
      " validation loss : 0.5703207530066832; validation accuracy : 0.9832635983263598\n",
      "Epoch 94:\t train loss : 0.5613757846289307; train accuracy : 0.989962514328201; \n",
      " validation loss : 0.5934468095368528; validation accuracy : 0.9539748953974896\n",
      "Epoch 95:\t train loss : 0.5642603475020819; train accuracy : 0.9869333328985278; \n",
      " validation loss : 0.5877382237038672; validation accuracy : 0.9623430962343096\n",
      "Epoch 96:\t train loss : 0.5681647924298364; train accuracy : 0.9829007290058226; \n",
      " validation loss : 0.6064292816766099; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.5719616446153646; train accuracy : 0.9792382533209631; \n",
      " validation loss : 0.6182686544627108; validation accuracy : 0.9330543933054394\n",
      "Epoch 98:\t train loss : 0.5638242832607361; train accuracy : 0.9873893895493404; \n",
      " validation loss : 0.5909748076957815; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5583217429440541; train accuracy : 0.9930019680385325; \n",
      " validation loss : 0.5730881249227097; validation accuracy : 0.9790794979079498\n",
      "Epoch 100:\t train loss : 0.558266010795025; train accuracy : 0.9928883207429957; \n",
      " validation loss : 0.5863646662778228; validation accuracy : 0.9623430962343096\n",
      "Epoch 101:\t train loss : 0.5656389176264773; train accuracy : 0.9853378683550166; \n",
      " validation loss : 0.6084208424731187; validation accuracy : 0.9414225941422594\n",
      "Epoch 102:\t train loss : 0.5598281194986314; train accuracy : 0.991533847164769; \n",
      " validation loss : 0.6018702236283384; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.5601433259824868; train accuracy : 0.9911242603550295; \n",
      " validation loss : 0.6021311802610283; validation accuracy : 0.9497907949790795\n",
      "Epoch 104:\t train loss : 0.5598589927619566; train accuracy : 0.9915441194454273; \n",
      " validation loss : 0.5896165018798863; validation accuracy : 0.9623430962343096\n",
      "Epoch 105:\t train loss : 0.5596810092014967; train accuracy : 0.9916044487127854; \n",
      " validation loss : 0.5810356231723539; validation accuracy : 0.9707112970711297\n",
      "Epoch 106:\t train loss : 0.55915124312702; train accuracy : 0.992184424939793; \n",
      " validation loss : 0.5904105716076941; validation accuracy : 0.9623430962343096\n",
      "Epoch 107:\t train loss : 0.5591910430270824; train accuracy : 0.9920415913230208; \n",
      " validation loss : 0.5935983270987037; validation accuracy : 0.9581589958158996\n",
      "Epoch 108:\t train loss : 0.5576037296273937; train accuracy : 0.993714505601654; \n",
      " validation loss : 0.5908769959545003; validation accuracy : 0.9581589958158996\n",
      "Epoch 109:\t train loss : 0.5567890670884328; train accuracy : 0.9945423209810517; \n",
      " validation loss : 0.5974635361012556; validation accuracy : 0.9539748953974896\n",
      "Epoch 110:\t train loss : 0.5587114898824027; train accuracy : 0.9926026535094513; \n",
      " validation loss : 0.6144546143384394; validation accuracy : 0.9372384937238494\n",
      "Epoch 111:\t train loss : 0.5752694288115962; train accuracy : 0.975861444869648; \n",
      " validation loss : 0.5913356572885856; validation accuracy : 0.9581589958158996\n",
      "Epoch 112:\t train loss : 0.5583356092024008; train accuracy : 0.9930552860667111; \n",
      " validation loss : 0.5864127291440093; validation accuracy : 0.9623430962343096\n",
      "Epoch 113:\t train loss : 0.5663293185477357; train accuracy : 0.9847802302621388; \n",
      " validation loss : 0.6121456608164599; validation accuracy : 0.9330543933054394\n",
      "Epoch 114:\t train loss : 0.559751688472298; train accuracy : 0.9915097154578257; \n",
      " validation loss : 0.599665091306478; validation accuracy : 0.9497907949790795\n",
      "Epoch 115:\t train loss : 0.5593695692588583; train accuracy : 0.9918814741864109; \n",
      " validation loss : 0.5853601450719542; validation accuracy : 0.9665271966527197\n",
      "Epoch 116:\t train loss : 0.5596653916009094; train accuracy : 0.9915992310464192; \n",
      " validation loss : 0.5855540744154275; validation accuracy : 0.9665271966527197\n",
      "Epoch 117:\t train loss : 0.5576223164421557; train accuracy : 0.9937024397481824; \n",
      " validation loss : 0.5852570112479201; validation accuracy : 0.9665271966527197\n",
      "Epoch 118:\t train loss : 0.5558294453228848; train accuracy : 0.9954837836559862; \n",
      " validation loss : 0.5683137569505207; validation accuracy : 0.9832635983263598\n",
      "Epoch 119:\t train loss : 0.5628183973828318; train accuracy : 0.9882636747698113; \n",
      " validation loss : 0.5869431711460718; validation accuracy : 0.9623430962343096\n",
      "Epoch 120:\t train loss : 0.564128442603956; train accuracy : 0.9871278540227393; \n",
      " validation loss : 0.593776120395875; validation accuracy : 0.9581589958158996\n",
      "Epoch 121:\t train loss : 0.5585732296096876; train accuracy : 0.9927575529796951; \n",
      " validation loss : 0.5808924668913286; validation accuracy : 0.9707112970711297\n",
      "Epoch 122:\t train loss : 0.5567053491440326; train accuracy : 0.994717928064686; \n",
      " validation loss : 0.5777913898320626; validation accuracy : 0.9748953974895398\n",
      "Epoch 123:\t train loss : 0.5570794517159993; train accuracy : 0.9943031235885804; \n",
      " validation loss : 0.5888679126178973; validation accuracy : 0.9623430962343096\n",
      "Epoch 124:\t train loss : 0.5565920268475266; train accuracy : 0.9948177159339379; \n",
      " validation loss : 0.5888507459577352; validation accuracy : 0.9623430962343096\n",
      "Epoch 125:\t train loss : 0.5593160009482212; train accuracy : 0.991859136052281; \n",
      " validation loss : 0.5883664411643696; validation accuracy : 0.9623430962343096\n",
      "Epoch 126:\t train loss : 0.5689142145202462; train accuracy : 0.9822278130966687; \n",
      " validation loss : 0.5950156416264183; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.5727188061568218; train accuracy : 0.9782503208049554; \n",
      " validation loss : 0.5993999526784067; validation accuracy : 0.9497907949790795\n",
      "Epoch 128:\t train loss : 0.5660988567832865; train accuracy : 0.985000513614033; \n",
      " validation loss : 0.5902553389244327; validation accuracy : 0.9623430962343096\n",
      "Epoch 129:\t train loss : 0.5588556099726874; train accuracy : 0.9925044961609389; \n",
      " validation loss : 0.5970694814861118; validation accuracy : 0.9581589958158996\n",
      "Epoch 130:\t train loss : 0.5594265121257679; train accuracy : 0.9919744138685572; \n",
      " validation loss : 0.5960332895066778; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5575800321622254; train accuracy : 0.9937299955486784; \n",
      " validation loss : 0.5989859829458393; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5567323577984741; train accuracy : 0.9945974325820437; \n",
      " validation loss : 0.5994979249095452; validation accuracy : 0.9497907949790795\n",
      "Epoch 133:\t train loss : 0.5572010751414042; train accuracy : 0.9940931125173447; \n",
      " validation loss : 0.5970949542652648; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134:\t train loss : 0.5565768933816145; train accuracy : 0.9948332058809622; \n",
      " validation loss : 0.5896809654320485; validation accuracy : 0.9623430962343096\n",
      "Epoch 135:\t train loss : 0.5569321497249424; train accuracy : 0.9944304672583283; \n",
      " validation loss : 0.583112627537789; validation accuracy : 0.9665271966527197\n",
      "Epoch 136:\t train loss : 0.5565585563225217; train accuracy : 0.9948022259869135; \n",
      " validation loss : 0.5826706959123074; validation accuracy : 0.9707112970711297\n",
      "Epoch 137:\t train loss : 0.5575298066557756; train accuracy : 0.9938539151248734; \n",
      " validation loss : 0.584466120674225; validation accuracy : 0.9665271966527197\n",
      "Epoch 138:\t train loss : 0.5687276111310773; train accuracy : 0.9823207527788149; \n",
      " validation loss : 0.5974070595493449; validation accuracy : 0.9539748953974896\n",
      "Epoch 139:\t train loss : 0.5608501276401635; train accuracy : 0.9903789493250459; \n",
      " validation loss : 0.5757051604888996; validation accuracy : 0.9748953974895398\n",
      "Epoch 140:\t train loss : 0.5594912254179196; train accuracy : 0.9918659842393865; \n",
      " validation loss : 0.6000709172607379; validation accuracy : 0.9497907949790795\n",
      "Epoch 141:\t train loss : 0.5591447007338152; train accuracy : 0.9922773646219393; \n",
      " validation loss : 0.5933679861886623; validation accuracy : 0.9581589958158996\n",
      "Epoch 142:\t train loss : 0.5557423304188025; train accuracy : 0.9956318349391245; \n",
      " validation loss : 0.5902451510798129; validation accuracy : 0.9623430962343096\n",
      "Epoch 143:\t train loss : 0.5547683301164568; train accuracy : 0.996642105589262; \n",
      " validation loss : 0.5835078367603331; validation accuracy : 0.9665271966527197\n",
      "Epoch 144:\t train loss : 0.5573279895728172; train accuracy : 0.9939933246480929; \n",
      " validation loss : 0.5791747728674266; validation accuracy : 0.9748953974895398\n",
      "Epoch 145:\t train loss : 0.5565110337407946; train accuracy : 0.994932993750214; \n",
      " validation loss : 0.5914566050167611; validation accuracy : 0.9581589958158996\n",
      "Epoch 146:\t train loss : 0.5573665439261217; train accuracy : 0.9938710355926372; \n",
      " validation loss : 0.5859906524043936; validation accuracy : 0.9623430962343096\n",
      "Epoch 147:\t train loss : 0.557172118868091; train accuracy : 0.9940862643302392; \n",
      " validation loss : 0.5929211969958774; validation accuracy : 0.9581589958158996\n",
      "Epoch 148:\t train loss : 0.5546775949618518; train accuracy : 0.996738469364961; \n",
      " validation loss : 0.5847818384435405; validation accuracy : 0.9665271966527197\n",
      "Epoch 149:\t train loss : 0.5556879250456815; train accuracy : 0.9956730871138315; \n",
      " validation loss : 0.5894449584356225; validation accuracy : 0.9623430962343096\n",
      "Epoch 150:\t train loss : 0.5567544880096151; train accuracy : 0.9945509627409705; \n",
      " validation loss : 0.5958206080460456; validation accuracy : 0.9539748953974896\n",
      "Epoch 151:\t train loss : 0.5570013837939602; train accuracy : 0.994337527576182; \n",
      " validation loss : 0.6077845523762351; validation accuracy : 0.9414225941422594\n",
      "Epoch 152:\t train loss : 0.5631073131909032; train accuracy : 0.9881363311000634; \n",
      " validation loss : 0.6147965486007615; validation accuracy : 0.9330543933054394\n",
      "Epoch 153:\t train loss : 0.5677535574561695; train accuracy : 0.9834084731640744; \n",
      " validation loss : 0.6286528248677873; validation accuracy : 0.9246861924686193\n",
      "Epoch 154:\t train loss : 0.560683306245664; train accuracy : 0.9907076623061107; \n",
      " validation loss : 0.5939948009984335; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5590405567659115; train accuracy : 0.9923324762229313; \n",
      " validation loss : 0.577685444071969; validation accuracy : 0.9748953974895398\n",
      "Epoch 156:\t train loss : 0.5573847631241765; train accuracy : 0.9938728291654506; \n",
      " validation loss : 0.5818261898831966; validation accuracy : 0.9707112970711297\n",
      "Epoch 157:\t train loss : 0.5617509306430533; train accuracy : 0.989554558039201; \n",
      " validation loss : 0.5899902753005167; validation accuracy : 0.9623430962343096\n",
      "Epoch 158:\t train loss : 0.5581486372327976; train accuracy : 0.9931568675087763; \n",
      " validation loss : 0.6020878966199721; validation accuracy : 0.9497907949790795\n",
      "Epoch 159:\t train loss : 0.5561414377117158; train accuracy : 0.9952514344506205; \n",
      " validation loss : 0.5929789112762559; validation accuracy : 0.9581589958158996\n",
      "Epoch 160:\t train loss : 0.5566582044664875; train accuracy : 0.9947334180117103; \n",
      " validation loss : 0.6094211294988198; validation accuracy : 0.9414225941422594\n",
      "Epoch 161:\t train loss : 0.5549146446139513; train accuracy : 0.9964475844650506; \n",
      " validation loss : 0.5947505919746386; validation accuracy : 0.9581589958158996\n",
      "Epoch 162:\t train loss : 0.5553609218738976; train accuracy : 0.9960035936677096; \n",
      " validation loss : 0.5928610460850426; validation accuracy : 0.9581589958158996\n",
      "Epoch 163:\t train loss : 0.5569529608079543; train accuracy : 0.9943409516697348; \n",
      " validation loss : 0.5965024185963589; validation accuracy : 0.9539748953974896\n",
      "Epoch 164:\t train loss : 0.5560556473012218; train accuracy : 0.9953994857337588; \n",
      " validation loss : 0.5772948420662863; validation accuracy : 0.9748953974895398\n",
      "Epoch 165:\t train loss : 0.561584259862304; train accuracy : 0.9895167299580467; \n",
      " validation loss : 0.6086524713665342; validation accuracy : 0.9414225941422594\n",
      "Epoch 166:\t train loss : 0.5638363218142108; train accuracy : 0.9874100971627309; \n",
      " validation loss : 0.5877709423397082; validation accuracy : 0.9623430962343096\n",
      "Epoch 167:\t train loss : 0.5571267494547842; train accuracy : 0.9942256738534586; \n",
      " validation loss : 0.5829204640455932; validation accuracy : 0.9665271966527197\n",
      "Epoch 168:\t train loss : 0.5565027452982042; train accuracy : 0.9948762516284826; \n",
      " validation loss : 0.5994028616800874; validation accuracy : 0.9539748953974896\n",
      "Early stopping at epoch 168\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5558294453228848; Train accuracy : 0.9954837836559862; \n",
      " Validation loss : 0.5683137569505207; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 10 ! ---\n",
      "Epoch 1:\t train loss : 0.9226987488421371; train accuracy : 0.6034539483874966; \n",
      " validation loss : 0.7863623353821132; validation accuracy : 0.7531380753138075\n",
      "Epoch 2:\t train loss : 0.7069763524557618; train accuracy : 0.8445689147743115; \n",
      " validation loss : 0.706338271228552; validation accuracy : 0.8410041841004184\n",
      "Epoch 3:\t train loss : 0.6698969456836941; train accuracy : 0.8804281421357539; \n",
      " validation loss : 0.709946022513463; validation accuracy : 0.8326359832635983\n",
      "Epoch 4:\t train loss : 0.6547619848576384; train accuracy : 0.8953743920195792; \n",
      " validation loss : 0.6742769181590034; validation accuracy : 0.8702928870292888\n",
      "Epoch 5:\t train loss : 0.6379093319369513; train accuracy : 0.9120939310387558; \n",
      " validation loss : 0.6896823835288737; validation accuracy : 0.8577405857740585\n",
      "Epoch 6:\t train loss : 0.6228295210947454; train accuracy : 0.9281319123888596; \n",
      " validation loss : 0.6484604797752875; validation accuracy : 0.9037656903765691\n",
      "Epoch 7:\t train loss : 0.6144001556443718; train accuracy : 0.9364831624275844; \n",
      " validation loss : 0.6297634587957538; validation accuracy : 0.9205020920502092\n",
      "Epoch 8:\t train loss : 0.6096400078510931; train accuracy : 0.9413875894544441; \n",
      " validation loss : 0.6829282576676093; validation accuracy : 0.8535564853556485\n",
      "Epoch 9:\t train loss : 0.6248247202496322; train accuracy : 0.9257117630657703; \n",
      " validation loss : 0.6467087182394915; validation accuracy : 0.9037656903765691\n",
      "Epoch 10:\t train loss : 0.6062177985564228; train accuracy : 0.9451184980947365; \n",
      " validation loss : 0.6462773460044686; validation accuracy : 0.899581589958159\n",
      "Epoch 11:\t train loss : 0.5984132411849499; train accuracy : 0.9530072183153133; \n",
      " validation loss : 0.6121587309223885; validation accuracy : 0.9414225941422594\n",
      "Epoch 12:\t train loss : 0.5923070862272234; train accuracy : 0.9590792775488708; \n",
      " validation loss : 0.619684517040478; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.6004485076630751; train accuracy : 0.9505443167384368; \n",
      " validation loss : 0.6255987058492195; validation accuracy : 0.9205020920502092\n",
      "Epoch 14:\t train loss : 0.6050826031979865; train accuracy : 0.9457985067691068; \n",
      " validation loss : 0.6361672297570163; validation accuracy : 0.9121338912133892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\t train loss : 0.593845172026066; train accuracy : 0.9574912481799313; \n",
      " validation loss : 0.6304049660499544; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5869945173591155; train accuracy : 0.964169583940023; \n",
      " validation loss : 0.6083100603914845; validation accuracy : 0.9497907949790795\n",
      "Epoch 17:\t train loss : 0.5878231565205881; train accuracy : 0.9634976300381053; \n",
      " validation loss : 0.6068607058631317; validation accuracy : 0.9456066945606695\n",
      "Epoch 18:\t train loss : 0.5858569767517388; train accuracy : 0.965205241798073; \n",
      " validation loss : 0.6443811155204804; validation accuracy : 0.9037656903765691\n",
      "Epoch 19:\t train loss : 0.5956621199303148; train accuracy : 0.955218563152514; \n",
      " validation loss : 0.6160943124690146; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.5905525313372292; train accuracy : 0.9605604262833422; \n",
      " validation loss : 0.6457027014331155; validation accuracy : 0.899581589958159\n",
      "Epoch 21:\t train loss : 0.5901677621221081; train accuracy : 0.9611180643762198; \n",
      " validation loss : 0.6466453412456168; validation accuracy : 0.9037656903765691\n",
      "Epoch 22:\t train loss : 0.5848073992001667; train accuracy : 0.966597788035565; \n",
      " validation loss : 0.622613911968178; validation accuracy : 0.9288702928870293\n",
      "Epoch 23:\t train loss : 0.5833758235062911; train accuracy : 0.9679469624213886; \n",
      " validation loss : 0.6091871833941641; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5835353094124017; train accuracy : 0.9676916880944267; \n",
      " validation loss : 0.6059425545546775; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5818297270873545; train accuracy : 0.9691108770408006; \n",
      " validation loss : 0.6487876140553966; validation accuracy : 0.9037656903765691\n",
      "Epoch 26:\t train loss : 0.5858459813945681; train accuracy : 0.9651727129093218; \n",
      " validation loss : 0.6219855410161451; validation accuracy : 0.9246861924686193\n",
      "Epoch 27:\t train loss : 0.582948972605341; train accuracy : 0.9680516744632733; \n",
      " validation loss : 0.621610497225336; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.5773620314540635; train accuracy : 0.9738758945444407; \n",
      " validation loss : 0.6552035711930808; validation accuracy : 0.895397489539749\n",
      "Epoch 29:\t train loss : 0.5757571508390835; train accuracy : 0.9752641035967657; \n",
      " validation loss : 0.6091726294787553; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5733152869807678; train accuracy : 0.978023482759689; \n",
      " validation loss : 0.6080202001451938; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5755967974362173; train accuracy : 0.9754035131199851; \n",
      " validation loss : 0.6432279399201246; validation accuracy : 0.9121338912133892\n",
      "Epoch 32:\t train loss : 0.5878872766167916; train accuracy : 0.9626884352055516; \n",
      " validation loss : 0.6262663832881428; validation accuracy : 0.9246861924686193\n",
      "Epoch 33:\t train loss : 0.5742163067854776; train accuracy : 0.9770107500232349; \n",
      " validation loss : 0.5948380604491605; validation accuracy : 0.9623430962343096\n",
      "Epoch 34:\t train loss : 0.5832303165613555; train accuracy : 0.9675987484122804; \n",
      " validation loss : 0.6103088340557536; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.573375579119505; train accuracy : 0.977872300876731; \n",
      " validation loss : 0.6135349227892376; validation accuracy : 0.9330543933054394\n",
      "Epoch 36:\t train loss : 0.5716343819740525; train accuracy : 0.9793519006164999; \n",
      " validation loss : 0.6157911566768096; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5733207344379999; train accuracy : 0.9778493757551349; \n",
      " validation loss : 0.5982862175147714; validation accuracy : 0.9497907949790795\n",
      "Epoch 38:\t train loss : 0.5680587981905765; train accuracy : 0.9832339911397503; \n",
      " validation loss : 0.5839288582904124; validation accuracy : 0.9623430962343096\n",
      "Epoch 39:\t train loss : 0.567612058805951; train accuracy : 0.9835688837944174; \n",
      " validation loss : 0.5900969851332857; validation accuracy : 0.9623430962343096\n",
      "Epoch 40:\t train loss : 0.5670115761650519; train accuracy : 0.9843337773784814; \n",
      " validation loss : 0.6113765603851508; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5771954573100533; train accuracy : 0.9737423712010905; \n",
      " validation loss : 0.5983466093864489; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5690010159298258; train accuracy : 0.9824130239474581; \n",
      " validation loss : 0.5982121772843733; validation accuracy : 0.9581589958158996\n",
      "Epoch 43:\t train loss : 0.5702646496932431; train accuracy : 0.9807283373090864; \n",
      " validation loss : 0.6109037569334371; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5834600769497623; train accuracy : 0.9674379627621673; \n",
      " validation loss : 0.6194915397898502; validation accuracy : 0.9288702928870293\n",
      "Epoch 45:\t train loss : 0.5711933240273555; train accuracy : 0.9800179683385483; \n",
      " validation loss : 0.6051309474786385; validation accuracy : 0.9456066945606695\n",
      "Epoch 46:\t train loss : 0.5641614155345688; train accuracy : 0.987158833916788; \n",
      " validation loss : 0.6099649999431856; validation accuracy : 0.9414225941422594\n",
      "Epoch 47:\t train loss : 0.5665665818300035; train accuracy : 0.9845602404039778; \n",
      " validation loss : 0.6203814360625347; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5639824312571199; train accuracy : 0.9873911831221537; \n",
      " validation loss : 0.6212756854343839; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5708667543659144; train accuracy : 0.980300504972273; \n",
      " validation loss : 0.6124115018428815; validation accuracy : 0.9330543933054394\n",
      "Epoch 50:\t train loss : 0.5676699691887428; train accuracy : 0.9835128101861892; \n",
      " validation loss : 0.6180499204736544; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.565028433027623; train accuracy : 0.9862486446296354; \n",
      " validation loss : 0.5937287035338575; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5652901477151323; train accuracy : 0.9862176647355866; \n",
      " validation loss : 0.5980838140063588; validation accuracy : 0.9539748953974896\n",
      "Epoch 53:\t train loss : 0.5792401626720374; train accuracy : 0.9720192694940983; \n",
      " validation loss : 0.592770791672035; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5673950964319323; train accuracy : 0.9837333870318163; \n",
      " validation loss : 0.5886877734986514; validation accuracy : 0.9623430962343096\n",
      "Epoch 55:\t train loss : 0.5635034168317947; train accuracy : 0.9877260757768208; \n",
      " validation loss : 0.6166546767839539; validation accuracy : 0.9372384937238494\n",
      "Epoch 56:\t train loss : 0.565613667932335; train accuracy : 0.9855884630874563; \n",
      " validation loss : 0.6034551391138685; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.564640098488211; train accuracy : 0.9867133430403668; \n",
      " validation loss : 0.5905935911609763; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.5656510044793528; train accuracy : 0.9856349329285294; \n",
      " validation loss : 0.6051160121436797; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5640324808320302; train accuracy : 0.9872554911862201; \n",
      " validation loss : 0.6271277953981776; validation accuracy : 0.9246861924686193\n",
      "Epoch 60:\t train loss : 0.5673035932837708; train accuracy : 0.9839369249357167; \n",
      " validation loss : 0.5973117206253885; validation accuracy : 0.9539748953974896\n",
      "Epoch 61:\t train loss : 0.5632436198930642; train accuracy : 0.9878809752470646; \n",
      " validation loss : 0.5979917069086733; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5635967866024912; train accuracy : 0.9876272499148053; \n",
      " validation loss : 0.5848898306803958; validation accuracy : 0.9665271966527197\n",
      "Epoch 63:\t train loss : 0.5629542773351285; train accuracy : 0.9884017472660244; \n",
      " validation loss : 0.6035102561574922; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5692832277691133; train accuracy : 0.9818612720344496; \n",
      " validation loss : 0.601934020123669; validation accuracy : 0.9497907949790795\n",
      "Epoch 65:\t train loss : 0.5809291392750499; train accuracy : 0.9700557638092878; \n",
      " validation loss : 0.6170782468599249; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66:\t train loss : 0.570066229065525; train accuracy : 0.9811310759317203; \n",
      " validation loss : 0.5968837514922372; validation accuracy : 0.9581589958158996\n",
      "Epoch 67:\t train loss : 0.5631356357039418; train accuracy : 0.9882564515629356; \n",
      " validation loss : 0.610776183753517; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5625206561827722; train accuracy : 0.9887639022274544; \n",
      " validation loss : 0.5887637562995597; validation accuracy : 0.9623430962343096\n",
      "Epoch 69:\t train loss : 0.570389453560059; train accuracy : 0.9806877536478825; \n",
      " validation loss : 0.5949999491671409; validation accuracy : 0.9581589958158996\n",
      "Epoch 70:\t train loss : 0.5661798478501834; train accuracy : 0.9850308249945785; \n",
      " validation loss : 0.6063718118491535; validation accuracy : 0.9456066945606695\n",
      "Epoch 71:\t train loss : 0.5626324212400572; train accuracy : 0.9884909693608848; \n",
      " validation loss : 0.614309835276621; validation accuracy : 0.9372384937238494\n",
      "Epoch 72:\t train loss : 0.5624979071035451; train accuracy : 0.9889438954118777; \n",
      " validation loss : 0.6085345871613201; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5720073855818131; train accuracy : 0.9790517054431673; \n",
      " validation loss : 0.6293570820022832; validation accuracy : 0.9205020920502092\n",
      "Epoch 74:\t train loss : 0.5725547911040771; train accuracy : 0.978596610799591; \n",
      " validation loss : 0.618755934458578; validation accuracy : 0.9330543933054394\n",
      "Epoch 75:\t train loss : 0.5653047600122506; train accuracy : 0.9860008054772452; \n",
      " validation loss : 0.6069606958690011; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5624884139034255; train accuracy : 0.9887735059946094; \n",
      " validation loss : 0.6114908659959905; validation accuracy : 0.9372384937238494\n",
      "Epoch 77:\t train loss : 0.5623368333182281; train accuracy : 0.9889807614857957; \n",
      " validation loss : 0.612789857353669; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5625786400889384; train accuracy : 0.9887329223334056; \n",
      " validation loss : 0.6004863403851408; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5622530701010862; train accuracy : 0.9890833049350971; \n",
      " validation loss : 0.5999537109356519; validation accuracy : 0.9539748953974896\n",
      "Epoch 80:\t train loss : 0.5666325659146458; train accuracy : 0.9845639579912637; \n",
      " validation loss : 0.5955051700730506; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5653762088419392; train accuracy : 0.985783946218904; \n",
      " validation loss : 0.5958807375466167; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5619987899878954; train accuracy : 0.9893370302673565; \n",
      " validation loss : 0.5917807792337936; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5616437087711058; train accuracy : 0.9897862387310635; \n",
      " validation loss : 0.5957999518591273; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.5649471206974278; train accuracy : 0.9862449270423496; \n",
      " validation loss : 0.6036832099643397; validation accuracy : 0.9456066945606695\n",
      "Epoch 85:\t train loss : 0.5607785120015601; train accuracy : 0.9905238700083646; \n",
      " validation loss : 0.5808044625482872; validation accuracy : 0.9707112970711297\n",
      "Epoch 86:\t train loss : 0.5663057983963804; train accuracy : 0.9846841599801729; \n",
      " validation loss : 0.5974921102213394; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5665135495548926; train accuracy : 0.9847925896093436; \n",
      " validation loss : 0.6018750931390416; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5600135388852908; train accuracy : 0.9913662133275504; \n",
      " validation loss : 0.5935024776316906; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5660801814508922; train accuracy : 0.9850308249945785; \n",
      " validation loss : 0.6011506083267476; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5698787643381925; train accuracy : 0.9813110691161436; \n",
      " validation loss : 0.5904932908865463; validation accuracy : 0.9623430962343096\n",
      "Epoch 91:\t train loss : 0.5680961146151134; train accuracy : 0.9830171318814089; \n",
      " validation loss : 0.6195317222447028; validation accuracy : 0.9288702928870293\n",
      "Epoch 92:\t train loss : 0.5606812974518238; train accuracy : 0.9906440719972738; \n",
      " validation loss : 0.5890610094588083; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5600803369630701; train accuracy : 0.991226803804331; \n",
      " validation loss : 0.6240444511897207; validation accuracy : 0.9246861924686193\n",
      "Epoch 94:\t train loss : 0.5610502001745644; train accuracy : 0.9903962328448837; \n",
      " validation loss : 0.5902686500403962; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5613860530960539; train accuracy : 0.9899566281483317; \n",
      " validation loss : 0.5937456039779085; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.5621580838016884; train accuracy : 0.9891725270299575; \n",
      " validation loss : 0.5927076440477366; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5616549244327423; train accuracy : 0.9896527153877134; \n",
      " validation loss : 0.6158320544635503; validation accuracy : 0.9330543933054394\n",
      "Epoch 98:\t train loss : 0.5620225335281515; train accuracy : 0.9893097679605936; \n",
      " validation loss : 0.6095946900669124; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5730062627834515; train accuracy : 0.9781783822299328; \n",
      " validation loss : 0.6083183214251077; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5653767277530519; train accuracy : 0.9858090399330834; \n",
      " validation loss : 0.6199021967664884; validation accuracy : 0.9330543933054394\n",
      "Epoch 101:\t train loss : 0.5609614337386863; train accuracy : 0.9903342730567861; \n",
      " validation loss : 0.6035452831763577; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.560504519347057; train accuracy : 0.9908550450757458; \n",
      " validation loss : 0.6128628914566778; validation accuracy : 0.9372384937238494\n",
      "Epoch 103:\t train loss : 0.5649763777144988; train accuracy : 0.9862582483967904; \n",
      " validation loss : 0.6076770562105083; validation accuracy : 0.9456066945606695\n",
      "Epoch 104:\t train loss : 0.5614583996253294; train accuracy : 0.989925648254283; \n",
      " validation loss : 0.6105040769334258; validation accuracy : 0.9372384937238494\n",
      "Epoch 105:\t train loss : 0.5608543308561806; train accuracy : 0.9905799436165929; \n",
      " validation loss : 0.6078235199410114; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.561448677036197; train accuracy : 0.9899101583072586; \n",
      " validation loss : 0.6097049253210638; validation accuracy : 0.9414225941422594\n",
      "Epoch 107:\t train loss : 0.56113708680593; train accuracy : 0.9902199572477463; \n",
      " validation loss : 0.6075914441655774; validation accuracy : 0.9414225941422594\n",
      "Epoch 108:\t train loss : 0.5593316490442736; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.6013671289443211; validation accuracy : 0.9497907949790795\n",
      "Epoch 109:\t train loss : 0.5629702893428923; train accuracy : 0.9882468477957805; \n",
      " validation loss : 0.6087443447355598; validation accuracy : 0.9414225941422594\n",
      "Epoch 110:\t train loss : 0.5601551415647122; train accuracy : 0.9911803339632579; \n",
      " validation loss : 0.5894749028685052; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.5594578759436163; train accuracy : 0.9918987577062487; \n",
      " validation loss : 0.5985817236160826; validation accuracy : 0.9497907949790795\n",
      "Epoch 112:\t train loss : 0.5595062398709969; train accuracy : 0.9917999318442331; \n",
      " validation loss : 0.6130064944454362; validation accuracy : 0.9414225941422594\n",
      "Epoch 113:\t train loss : 0.5785073051093028; train accuracy : 0.9725555314600824; \n",
      " validation loss : 0.619752494288361; validation accuracy : 0.9288702928870293\n",
      "Epoch 114:\t train loss : 0.5652112055971159; train accuracy : 0.9860162954242696; \n",
      " validation loss : 0.6116494609993913; validation accuracy : 0.9414225941422594\n",
      "Epoch 115:\t train loss : 0.5616148444962763; train accuracy : 0.9897146751758109; \n",
      " validation loss : 0.6042791364350523; validation accuracy : 0.9456066945606695\n",
      "Epoch 116:\t train loss : 0.5635302774933136; train accuracy : 0.9878168468663837; \n",
      " validation loss : 0.6223236667857464; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117:\t train loss : 0.5628298080209492; train accuracy : 0.9884290095727872; \n",
      " validation loss : 0.6011467329880754; validation accuracy : 0.9497907949790795\n",
      "Epoch 118:\t train loss : 0.5603279894441521; train accuracy : 0.9909575885250472; \n",
      " validation loss : 0.5943786479504545; validation accuracy : 0.9581589958158996\n",
      "Epoch 119:\t train loss : 0.5677274527442973; train accuracy : 0.983429474271198; \n",
      " validation loss : 0.5843989432316078; validation accuracy : 0.9665271966527197\n",
      "Epoch 120:\t train loss : 0.5631848422558738; train accuracy : 0.9881074382725611; \n",
      " validation loss : 0.6151869492514761; validation accuracy : 0.9330543933054394\n",
      "Epoch 121:\t train loss : 0.5671769568029835; train accuracy : 0.9839465287028718; \n",
      " validation loss : 0.6013888725508608; validation accuracy : 0.9497907949790795\n",
      "Epoch 122:\t train loss : 0.5594289080444084; train accuracy : 0.9918714953994857; \n",
      " validation loss : 0.5998004003288296; validation accuracy : 0.9497907949790795\n",
      "Epoch 123:\t train loss : 0.5611700535104757; train accuracy : 0.9901211313857307; \n",
      " validation loss : 0.621432213183683; validation accuracy : 0.9288702928870293\n",
      "Epoch 124:\t train loss : 0.5620115285238791; train accuracy : 0.9893370302673565; \n",
      " validation loss : 0.6046652761134793; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5633313893724328; train accuracy : 0.987809411691812; \n",
      " validation loss : 0.591046207758614; validation accuracy : 0.9623430962343096\n",
      "Epoch 126:\t train loss : 0.5589179172967669; train accuracy : 0.9925124694073546; \n",
      " validation loss : 0.6095612642407511; validation accuracy : 0.9414225941422594\n",
      "Epoch 127:\t train loss : 0.5618599783352785; train accuracy : 0.989563493292853; \n",
      " validation loss : 0.6003040326139479; validation accuracy : 0.9539748953974896\n",
      "Epoch 128:\t train loss : 0.5579237657316655; train accuracy : 0.9934632423557112; \n",
      " validation loss : 0.6005297836806492; validation accuracy : 0.9497907949790795\n",
      "Epoch 129:\t train loss : 0.5589770819626728; train accuracy : 0.9923207038631928; \n",
      " validation loss : 0.6044501066446901; validation accuracy : 0.9456066945606695\n",
      "Epoch 130:\t train loss : 0.5589113647376827; train accuracy : 0.9924291334923635; \n",
      " validation loss : 0.587325028962162; validation accuracy : 0.9665271966527197\n",
      "Epoch 131:\t train loss : 0.562606505131599; train accuracy : 0.9886399826512593; \n",
      " validation loss : 0.6020885058674815; validation accuracy : 0.9497907949790795\n",
      "Epoch 132:\t train loss : 0.566636101813395; train accuracy : 0.9846029926577651; \n",
      " validation loss : 0.6019971859395744; validation accuracy : 0.9497907949790795\n",
      "Epoch 133:\t train loss : 0.5622046895157553; train accuracy : 0.989146813717897; \n",
      " validation loss : 0.6063753740211063; validation accuracy : 0.9456066945606695\n",
      "Epoch 134:\t train loss : 0.567157340352808; train accuracy : 0.9840859382260913; \n",
      " validation loss : 0.5965145669542554; validation accuracy : 0.9581589958158996\n",
      "Epoch 135:\t train loss : 0.5624250165494206; train accuracy : 0.9889807614857957; \n",
      " validation loss : 0.5894770862936998; validation accuracy : 0.9623430962343096\n",
      "Early stopping at epoch 135\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5607785120015601; Train accuracy : 0.9905238700083646; \n",
      " Validation loss : 0.5808044625482872; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 11 ! ---\n",
      "Epoch 1:\t train loss : 0.9403839295108705; train accuracy : 0.593080083026116; \n",
      " validation loss : 0.8485329589462071; validation accuracy : 0.6903765690376569\n",
      "Epoch 2:\t train loss : 0.7557307407368727; train accuracy : 0.7943106044177329; \n",
      " validation loss : 0.7269594955907152; validation accuracy : 0.8158995815899581\n",
      "Epoch 3:\t train loss : 0.6933671427704873; train accuracy : 0.8571777316521577; \n",
      " validation loss : 0.6903714645579703; validation accuracy : 0.8661087866108786\n",
      "Epoch 4:\t train loss : 0.6699834121138858; train accuracy : 0.8804645744911552; \n",
      " validation loss : 0.6815403518888407; validation accuracy : 0.8661087866108786\n",
      "Epoch 5:\t train loss : 0.6584265162831335; train accuracy : 0.8919845100529756; \n",
      " validation loss : 0.6996742444616997; validation accuracy : 0.8535564853556485\n",
      "Epoch 6:\t train loss : 0.6559842548015572; train accuracy : 0.8941448000247839; \n",
      " validation loss : 0.6700719615038625; validation accuracy : 0.8786610878661087\n",
      "Epoch 7:\t train loss : 0.6352761078522839; train accuracy : 0.9157030886954367; \n",
      " validation loss : 0.6747512153542188; validation accuracy : 0.8661087866108786\n",
      "Epoch 8:\t train loss : 0.62931066818756; train accuracy : 0.9215310263638898; \n",
      " validation loss : 0.6633301028849713; validation accuracy : 0.8786610878661087\n",
      "Epoch 9:\t train loss : 0.6172633619485097; train accuracy : 0.9336430496607702; \n",
      " validation loss : 0.6567279621134625; validation accuracy : 0.891213389121339\n",
      "Epoch 10:\t train loss : 0.6126900799100671; train accuracy : 0.9383037888410422; \n",
      " validation loss : 0.6496268545216379; validation accuracy : 0.899581589958159\n",
      "Epoch 11:\t train loss : 0.6057204376792255; train accuracy : 0.9452587750549893; \n",
      " validation loss : 0.6451521205477286; validation accuracy : 0.9079497907949791\n",
      "Epoch 12:\t train loss : 0.6017317232589842; train accuracy : 0.949726199696397; \n",
      " validation loss : 0.6271739901184251; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.6068117585000398; train accuracy : 0.9439831469376375; \n",
      " validation loss : 0.6162617695980455; validation accuracy : 0.9372384937238494\n",
      "Epoch 14:\t train loss : 0.5964030951889233; train accuracy : 0.9552334335016575; \n",
      " validation loss : 0.6310986094486828; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.599561430575061; train accuracy : 0.9514874686328573; \n",
      " validation loss : 0.6165482562414641; validation accuracy : 0.9330543933054394\n",
      "Epoch 16:\t train loss : 0.5882681601111587; train accuracy : 0.9626858328944515; \n",
      " validation loss : 0.6435049848965779; validation accuracy : 0.9079497907949791\n",
      "Epoch 17:\t train loss : 0.5920679300990824; train accuracy : 0.9591997273769324; \n",
      " validation loss : 0.6234964473582951; validation accuracy : 0.9246861924686193\n",
      "Epoch 18:\t train loss : 0.5909974035810085; train accuracy : 0.9602447411629852; \n",
      " validation loss : 0.6118659756277294; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5917430434411953; train accuracy : 0.9595040738560674; \n",
      " validation loss : 0.6167951094084875; validation accuracy : 0.9414225941422594\n",
      "Epoch 20:\t train loss : 0.5892406042080988; train accuracy : 0.9616534589051705; \n",
      " validation loss : 0.6298376462566716; validation accuracy : 0.9246861924686193\n",
      "Epoch 21:\t train loss : 0.5824698179905038; train accuracy : 0.9688580191455746; \n",
      " validation loss : 0.608306317705665; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5862355393943989; train accuracy : 0.9649281576257009; \n",
      " validation loss : 0.598012876167655; validation accuracy : 0.9539748953974896\n",
      "Epoch 23:\t train loss : 0.5815841719650334; train accuracy : 0.9694012825676136; \n",
      " validation loss : 0.5951402140636938; validation accuracy : 0.9497907949790795\n",
      "Epoch 24:\t train loss : 0.5833507938325592; train accuracy : 0.967725518138728; \n",
      " validation loss : 0.6198340194211719; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.580163345912405; train accuracy : 0.9710931565414046; \n",
      " validation loss : 0.602730099962; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5921987751310506; train accuracy : 0.9584743021778865; \n",
      " validation loss : 0.6115115182637678; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5938927087799207; train accuracy : 0.9570064747978562; \n",
      " validation loss : 0.6018617868348349; validation accuracy : 0.9497907949790795\n",
      "Epoch 28:\t train loss : 0.5827826353225768; train accuracy : 0.9684406580129495; \n",
      " validation loss : 0.6016512545769283; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5811520336088136; train accuracy : 0.9701783822299328; \n",
      " validation loss : 0.5861599298270684; validation accuracy : 0.9707112970711297\n",
      "Epoch 30:\t train loss : 0.5797879650274457; train accuracy : 0.9713711081508101; \n",
      " validation loss : 0.6189310374015926; validation accuracy : 0.9330543933054394\n",
      "Epoch 31:\t train loss : 0.5770402387261105; train accuracy : 0.9739633817652343; \n",
      " validation loss : 0.6143919403294865; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:\t train loss : 0.5831147029868958; train accuracy : 0.9677054431673844; \n",
      " validation loss : 0.6180268708247807; validation accuracy : 0.9330543933054394\n",
      "Epoch 33:\t train loss : 0.5773186272955967; train accuracy : 0.9737063725642058; \n",
      " validation loss : 0.6192632756642371; validation accuracy : 0.9330543933054394\n",
      "Epoch 34:\t train loss : 0.5725866732524983; train accuracy : 0.9786895504817373; \n",
      " validation loss : 0.6089241840935634; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5758292040892443; train accuracy : 0.975683633321974; \n",
      " validation loss : 0.6113031778740423; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.5759046721795755; train accuracy : 0.9751205427677437; \n",
      " validation loss : 0.6131829249875856; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.5742728821888863; train accuracy : 0.9768499643731219; \n",
      " validation loss : 0.6399595658703027; validation accuracy : 0.9037656903765691\n",
      "Epoch 38:\t train loss : 0.5755116298029237; train accuracy : 0.975725518138728; \n",
      " validation loss : 0.6013575972029798; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5752386122858991; train accuracy : 0.9759788097524706; \n",
      " validation loss : 0.5923731927276357; validation accuracy : 0.9623430962343096\n",
      "Epoch 40:\t train loss : 0.5773325138377414; train accuracy : 0.9737428049196072; \n",
      " validation loss : 0.6109396993034745; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5726054767584096; train accuracy : 0.978529198550141; \n",
      " validation loss : 0.5961574477456103; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.5708925033050652; train accuracy : 0.9800635707425881; \n",
      " validation loss : 0.604087955670902; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5743038379096763; train accuracy : 0.976709687412869; \n",
      " validation loss : 0.5859993930813089; validation accuracy : 0.9665271966527197\n",
      "Epoch 44:\t train loss : 0.5748094227268709; train accuracy : 0.9763497010440224; \n",
      " validation loss : 0.5995822490198228; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.5762894994764781; train accuracy : 0.974909135970755; \n",
      " validation loss : 0.5894862654846691; validation accuracy : 0.9623430962343096\n",
      "Epoch 46:\t train loss : 0.5719080138410533; train accuracy : 0.9792480560116484; \n",
      " validation loss : 0.5984325575405426; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5686042333941475; train accuracy : 0.9824837200656774; \n",
      " validation loss : 0.5984829798223127; validation accuracy : 0.9497907949790795\n",
      "Epoch 48:\t train loss : 0.5677042453236909; train accuracy : 0.9835898262027943; \n",
      " validation loss : 0.5886197189284034; validation accuracy : 0.9623430962343096\n",
      "Epoch 49:\t train loss : 0.5730443854296251; train accuracy : 0.977966975432944; \n",
      " validation loss : 0.6125779361794894; validation accuracy : 0.9372384937238494\n",
      "Epoch 50:\t train loss : 0.5684869168408848; train accuracy : 0.9827588215248304; \n",
      " validation loss : 0.6139827911615328; validation accuracy : 0.9372384937238494\n",
      "Epoch 51:\t train loss : 0.5688506027152379; train accuracy : 0.982237615787354; \n",
      " validation loss : 0.5949384119782284; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5667750697102101; train accuracy : 0.9843835310883237; \n",
      " validation loss : 0.6041310708511082; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5687853732104728; train accuracy : 0.9825218872951454; \n",
      " validation loss : 0.6148770689364902; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5660716445653069; train accuracy : 0.9851961956690108; \n",
      " validation loss : 0.6017016626405143; validation accuracy : 0.9456066945606695\n",
      "Epoch 55:\t train loss : 0.5684159139221089; train accuracy : 0.9830049258031538; \n",
      " validation loss : 0.6057493345774795; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5677855482547999; train accuracy : 0.9834203042225595; \n",
      " validation loss : 0.5941970813186083; validation accuracy : 0.9581589958158996\n",
      "Epoch 57:\t train loss : 0.5658148437323637; train accuracy : 0.9853766225719508; \n",
      " validation loss : 0.5929380963650259; validation accuracy : 0.9581589958158996\n",
      "Epoch 58:\t train loss : 0.5662689899671389; train accuracy : 0.9848381920133833; \n",
      " validation loss : 0.6018492005317791; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5656542211766596; train accuracy : 0.9857584187862077; \n",
      " validation loss : 0.6123132849780172; validation accuracy : 0.9372384937238494\n",
      "Epoch 60:\t train loss : 0.5648331651355029; train accuracy : 0.986378016667183; \n",
      " validation loss : 0.6006940322867623; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5730936002726943; train accuracy : 0.977960655534558; \n",
      " validation loss : 0.5957978972176741; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5664738930146502; train accuracy : 0.9849374515939155; \n",
      " validation loss : 0.6010552306939936; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5651765950441151; train accuracy : 0.9862021747885622; \n",
      " validation loss : 0.6075995755367306; validation accuracy : 0.9414225941422594\n",
      "Epoch 64:\t train loss : 0.5656565692091082; train accuracy : 0.9857073639208154; \n",
      " validation loss : 0.5917096483875492; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.5655569674779902; train accuracy : 0.985685554075405; \n",
      " validation loss : 0.6018585515473219; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5654838842815604; train accuracy : 0.9857638712475604; \n",
      " validation loss : 0.5961986934992772; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5641127216587408; train accuracy : 0.9872663961089253; \n",
      " validation loss : 0.5865096484864104; validation accuracy : 0.9665271966527197\n",
      "Epoch 68:\t train loss : 0.5703788207547217; train accuracy : 0.9806094364757273; \n",
      " validation loss : 0.6111307046069204; validation accuracy : 0.9414225941422594\n",
      "Epoch 69:\t train loss : 0.5712502404100428; train accuracy : 0.979851296508566; \n",
      " validation loss : 0.6103651892430451; validation accuracy : 0.9414225941422594\n",
      "Epoch 70:\t train loss : 0.5644951536178701; train accuracy : 0.9868016976981939; \n",
      " validation loss : 0.5694247250541619; validation accuracy : 0.9832635983263598\n",
      "Epoch 71:\t train loss : 0.5632391950495218; train accuracy : 0.9880928157625701; \n",
      " validation loss : 0.6157172810282101; validation accuracy : 0.9330543933054394\n",
      "Epoch 72:\t train loss : 0.5623519984286228; train accuracy : 0.9889447628489111; \n",
      " validation loss : 0.5860825019797961; validation accuracy : 0.9665271966527197\n",
      "Epoch 73:\t train loss : 0.5613144092924974; train accuracy : 0.9899461569441432; \n",
      " validation loss : 0.5836112361349816; validation accuracy : 0.9665271966527197\n",
      "Epoch 74:\t train loss : 0.5599371999964974; train accuracy : 0.9914177019114595; \n",
      " validation loss : 0.5942961598779236; validation accuracy : 0.9581589958158996\n",
      "Epoch 75:\t train loss : 0.5650787766952329; train accuracy : 0.9861410824374981; \n",
      " validation loss : 0.5821430353206859; validation accuracy : 0.9707112970711297\n",
      "Epoch 76:\t train loss : 0.5628620980951579; train accuracy : 0.9884071997273769; \n",
      " validation loss : 0.5882547361571576; validation accuracy : 0.9623430962343096\n",
      "Epoch 77:\t train loss : 0.564883424861494; train accuracy : 0.9863889215898881; \n",
      " validation loss : 0.5915585133506865; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5710554837112826; train accuracy : 0.9799651785990892; \n",
      " validation loss : 0.5998516485869291; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5622042194847925; train accuracy : 0.988965705257288; \n",
      " validation loss : 0.5809262585132577; validation accuracy : 0.9707112970711297\n",
      "Epoch 80:\t train loss : 0.5639929099981181; train accuracy : 0.9871789088881316; \n",
      " validation loss : 0.6037757060677161; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.5695300151717366; train accuracy : 0.9814221010564144; \n",
      " validation loss : 0.6110589989591602; validation accuracy : 0.9372384937238494\n",
      "Epoch 82:\t train loss : 0.5600347048178924; train accuracy : 0.9911179404566436; \n",
      " validation loss : 0.5864799543037138; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:\t train loss : 0.562342530732611; train accuracy : 0.9890377025310574; \n",
      " validation loss : 0.5886111773568088; validation accuracy : 0.9623430962343096\n",
      "Epoch 84:\t train loss : 0.5614002043213231; train accuracy : 0.9899934942222498; \n",
      " validation loss : 0.58676256099711; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.5596644439059395; train accuracy : 0.9916454660925059; \n",
      " validation loss : 0.5926172864360792; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5588484702222971; train accuracy : 0.9925894854239599; \n",
      " validation loss : 0.5871257793257809; validation accuracy : 0.9623430962343096\n",
      "Epoch 87:\t train loss : 0.5618653607791475; train accuracy : 0.9893365965488398; \n",
      " validation loss : 0.589766356649796; validation accuracy : 0.9581589958158996\n",
      "Epoch 88:\t train loss : 0.5598759703348245; train accuracy : 0.9914076644257876; \n",
      " validation loss : 0.6053298728587446; validation accuracy : 0.9456066945606695\n",
      "Epoch 89:\t train loss : 0.558932829824933; train accuracy : 0.9924099259580532; \n",
      " validation loss : 0.5969023186764163; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5603094602154927; train accuracy : 0.9910413581585551; \n",
      " validation loss : 0.5939514460056015; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5618921447352946; train accuracy : 0.9893010316304718; \n",
      " validation loss : 0.5992855824526244; validation accuracy : 0.9497907949790795\n",
      "Epoch 92:\t train loss : 0.557945930469244; train accuracy : 0.9935033922983983; \n",
      " validation loss : 0.5899401381986211; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5635292710400004; train accuracy : 0.9876071749434617; \n",
      " validation loss : 0.578769462578616; validation accuracy : 0.9707112970711297\n",
      "Epoch 94:\t train loss : 0.5603441184118114; train accuracy : 0.9909484184764088; \n",
      " validation loss : 0.5827513198327117; validation accuracy : 0.9665271966527197\n",
      "Epoch 95:\t train loss : 0.5587946489059062; train accuracy : 0.9925028656401995; \n",
      " validation loss : 0.5746713105794831; validation accuracy : 0.9748953974895398\n",
      "Epoch 96:\t train loss : 0.5685859362106569; train accuracy : 0.9827178041451098; \n",
      " validation loss : 0.5928216289190347; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5605428598937043; train accuracy : 0.9906695994299699; \n",
      " validation loss : 0.5953015110032699; validation accuracy : 0.9539748953974896\n",
      "Epoch 98:\t train loss : 0.5602275544172346; train accuracy : 0.9910204157501781; \n",
      " validation loss : 0.5909588369431151; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5584497399323375; train accuracy : 0.9928227020663589; \n",
      " validation loss : 0.5877641639423816; validation accuracy : 0.9581589958158996\n",
      "Epoch 100:\t train loss : 0.5604265104453446; train accuracy : 0.990829083924533; \n",
      " validation loss : 0.6023307804523214; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.5613987963603388; train accuracy : 0.9898331422906533; \n",
      " validation loss : 0.6029077506898737; validation accuracy : 0.9497907949790795\n",
      "Epoch 102:\t train loss : 0.5580480276925894; train accuracy : 0.993215403203321; \n",
      " validation loss : 0.5776082811521507; validation accuracy : 0.9748953974895398\n",
      "Epoch 103:\t train loss : 0.6041749056668059; train accuracy : 0.9463648811921063; \n",
      " validation loss : 0.6281536097730861; validation accuracy : 0.9246861924686193\n",
      "Epoch 104:\t train loss : 0.6162587247592737; train accuracy : 0.9339063787601847; \n",
      " validation loss : 0.633736176868741; validation accuracy : 0.9163179916317992\n",
      "Epoch 105:\t train loss : 0.5790869778444387; train accuracy : 0.971744601753462; \n",
      " validation loss : 0.6135583373676115; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.575723713587056; train accuracy : 0.9751523900988258; \n",
      " validation loss : 0.6223201337299414; validation accuracy : 0.9246861924686193\n",
      "Epoch 107:\t train loss : 0.5714682711025889; train accuracy : 0.9798986337866724; \n",
      " validation loss : 0.5993081111424778; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.5690755913029218; train accuracy : 0.9821647510765513; \n",
      " validation loss : 0.6045515195903746; validation accuracy : 0.9456066945606695\n",
      "Epoch 109:\t train loss : 0.5667561179852213; train accuracy : 0.9844216983177918; \n",
      " validation loss : 0.5935199612444689; validation accuracy : 0.9581589958158996\n",
      "Epoch 110:\t train loss : 0.5661010733851859; train accuracy : 0.9852518355587224; \n",
      " validation loss : 0.5913386045622729; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5647569599412087; train accuracy : 0.9865538585458038; \n",
      " validation loss : 0.5985779276520675; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5647645567959694; train accuracy : 0.9864353914309613; \n",
      " validation loss : 0.6106425509919001; validation accuracy : 0.9372384937238494\n",
      "Epoch 113:\t train loss : 0.5657075560290132; train accuracy : 0.9854804671768023; \n",
      " validation loss : 0.6147224584593605; validation accuracy : 0.9330543933054394\n",
      "Epoch 114:\t train loss : 0.5636423268305316; train accuracy : 0.9875971374577899; \n",
      " validation loss : 0.5858385744672253; validation accuracy : 0.9665271966527197\n",
      "Epoch 115:\t train loss : 0.5605728920493441; train accuracy : 0.9907981040304842; \n",
      " validation loss : 0.5977789163070963; validation accuracy : 0.9497907949790795\n",
      "Epoch 116:\t train loss : 0.5618933460660294; train accuracy : 0.9892545617893986; \n",
      " validation loss : 0.5967867204555355; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5610034890411854; train accuracy : 0.9903124632113758; \n",
      " validation loss : 0.6125514094275077; validation accuracy : 0.9330543933054394\n",
      "Epoch 118:\t train loss : 0.5594984012340692; train accuracy : 0.9919087951919204; \n",
      " validation loss : 0.5849606358571008; validation accuracy : 0.9665271966527197\n",
      "Epoch 119:\t train loss : 0.5618655573727023; train accuracy : 0.9894395737166579; \n",
      " validation loss : 0.591282981094828; validation accuracy : 0.9581589958158996\n",
      "Epoch 120:\t train loss : 0.5601734771435427; train accuracy : 0.9910660181542179; \n",
      " validation loss : 0.5940477179131176; validation accuracy : 0.9539748953974896\n",
      "Early stopping at epoch 120\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5644951536178701; Train accuracy : 0.9868016976981939; \n",
      " Validation loss : 0.5694247250541619; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 12 ! ---\n",
      "Epoch 1:\t train loss : 0.9682302910552875; train accuracy : 0.552154341832151; \n",
      " validation loss : 0.8684708095442262; validation accuracy : 0.6861924686192469\n",
      "Epoch 2:\t train loss : 0.7765674743231086; train accuracy : 0.7704975370984232; \n",
      " validation loss : 0.7630373355633193; validation accuracy : 0.7907949790794979\n",
      "Epoch 3:\t train loss : 0.7047073617834293; train accuracy : 0.8452232101366214; \n",
      " validation loss : 0.6832468914143309; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.6739435869766618; train accuracy : 0.8758629449487283; \n",
      " validation loss : 0.688560830077685; validation accuracy : 0.8619246861924686\n",
      "Epoch 5:\t train loss : 0.6564140342850789; train accuracy : 0.8939648068403606; \n",
      " validation loss : 0.6882909059715678; validation accuracy : 0.8577405857740585\n",
      "Epoch 6:\t train loss : 0.6343294300333558; train accuracy : 0.9169150221506243; \n",
      " validation loss : 0.6562019286394631; validation accuracy : 0.8870292887029289\n",
      "Epoch 7:\t train loss : 0.6264854998969612; train accuracy : 0.9244239288701632; \n",
      " validation loss : 0.6437484286741313; validation accuracy : 0.9079497907949791\n",
      "Epoch 8:\t train loss : 0.6170062922315432; train accuracy : 0.9343721924471018; \n",
      " validation loss : 0.6082080212042109; validation accuracy : 0.9497907949790795\n",
      "Epoch 9:\t train loss : 0.6131489151830849; train accuracy : 0.9380123299978314; \n",
      " validation loss : 0.6373556218425531; validation accuracy : 0.9121338912133892\n",
      "Epoch 10:\t train loss : 0.60332976093369; train accuracy : 0.948084513150965; \n",
      " validation loss : 0.639659068237732; validation accuracy : 0.9037656903765691\n",
      "Epoch 11:\t train loss : 0.6006168519733348; train accuracy : 0.9502980265807491; \n",
      " validation loss : 0.6364446273203646; validation accuracy : 0.9079497907949791\n",
      "Epoch 12:\t train loss : 0.5967544531390058; train accuracy : 0.9546410979274451; \n",
      " validation loss : 0.6493371715770699; validation accuracy : 0.899581589958159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\t train loss : 0.5960547544737173; train accuracy : 0.9551581523591189; \n",
      " validation loss : 0.6321719913947096; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5936465162025494; train accuracy : 0.9576210539359955; \n",
      " validation loss : 0.6398181555421892; validation accuracy : 0.9037656903765691\n",
      "Epoch 15:\t train loss : 0.5902634836970767; train accuracy : 0.9607713993618142; \n",
      " validation loss : 0.6070928840264683; validation accuracy : 0.9456066945606695\n",
      "Epoch 16:\t train loss : 0.5917144621761032; train accuracy : 0.9594178877908237; \n",
      " validation loss : 0.611687249511149; validation accuracy : 0.9414225941422594\n",
      "Epoch 17:\t train loss : 0.5859747359656571; train accuracy : 0.9649691750054215; \n",
      " validation loss : 0.6089888967987283; validation accuracy : 0.9414225941422594\n",
      "Epoch 18:\t train loss : 0.5873040354877593; train accuracy : 0.9636680194553735; \n",
      " validation loss : 0.6383541057501497; validation accuracy : 0.9121338912133892\n",
      "Epoch 19:\t train loss : 0.5854079574045624; train accuracy : 0.9655481892251928; \n",
      " validation loss : 0.6104600218311881; validation accuracy : 0.9414225941422594\n",
      "Epoch 20:\t train loss : 0.5841990813756457; train accuracy : 0.9670197341925091; \n",
      " validation loss : 0.6035342076701701; validation accuracy : 0.9456066945606695\n",
      "Epoch 21:\t train loss : 0.5808175197324698; train accuracy : 0.9705241798073051; \n",
      " validation loss : 0.6040277701559021; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5791933502634805; train accuracy : 0.971976517240311; \n",
      " validation loss : 0.6292652013211988; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.5870241139776865; train accuracy : 0.9637609591375198; \n",
      " validation loss : 0.6152475160948367; validation accuracy : 0.9330543933054394\n",
      "Epoch 24:\t train loss : 0.5793500774358481; train accuracy : 0.9717751479289941; \n",
      " validation loss : 0.6168839069794716; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5814954313980715; train accuracy : 0.9694693144149447; \n",
      " validation loss : 0.6258072086671953; validation accuracy : 0.9246861924686193\n",
      "Epoch 26:\t train loss : 0.5812874683052666; train accuracy : 0.9695910653985563; \n",
      " validation loss : 0.604861343879748; validation accuracy : 0.9456066945606695\n",
      "Epoch 27:\t train loss : 0.5734527093067915; train accuracy : 0.9779054493633632; \n",
      " validation loss : 0.601232624864342; validation accuracy : 0.9497907949790795\n",
      "Epoch 28:\t train loss : 0.575043821474724; train accuracy : 0.9762362526720159; \n",
      " validation loss : 0.6004193686039115; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5823830752579849; train accuracy : 0.9688320579943617; \n",
      " validation loss : 0.6346922095970647; validation accuracy : 0.9163179916317992\n",
      "Epoch 30:\t train loss : 0.5812951304426216; train accuracy : 0.9696744013135475; \n",
      " validation loss : 0.6185453138778435; validation accuracy : 0.9205020920502092\n",
      "Epoch 31:\t train loss : 0.5728559331921215; train accuracy : 0.9785656309055423; \n",
      " validation loss : 0.6647188501616235; validation accuracy : 0.8828451882845189\n",
      "Epoch 32:\t train loss : 0.5747606721041733; train accuracy : 0.9765925214535767; \n",
      " validation loss : 0.6082166450886684; validation accuracy : 0.9414225941422594\n",
      "Epoch 33:\t train loss : 0.5760904215457011; train accuracy : 0.974894513460764; \n",
      " validation loss : 0.5973079959757613; validation accuracy : 0.9539748953974896\n",
      "Epoch 34:\t train loss : 0.570353260727606; train accuracy : 0.9808795191920444; \n",
      " validation loss : 0.6165809369494034; validation accuracy : 0.9330543933054394\n",
      "Epoch 35:\t train loss : 0.5706019210429066; train accuracy : 0.9805985315530221; \n",
      " validation loss : 0.6141091700731549; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.5688236070784718; train accuracy : 0.982540661110939; \n",
      " validation loss : 0.5960222923123734; validation accuracy : 0.9581589958158996\n",
      "Epoch 37:\t train loss : 0.5710335326267765; train accuracy : 0.9801824715759472; \n",
      " validation loss : 0.6252298804574574; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5788327544556674; train accuracy : 0.9721063229963753; \n",
      " validation loss : 0.60838764535686; validation accuracy : 0.9414225941422594\n",
      "Epoch 39:\t train loss : 0.5736957787335865; train accuracy : 0.9773574150376406; \n",
      " validation loss : 0.5991697619856649; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5748308261905141; train accuracy : 0.9760289971808297; \n",
      " validation loss : 0.6082169280624496; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5736910017742519; train accuracy : 0.9772372130487313; \n",
      " validation loss : 0.6260384802642597; validation accuracy : 0.9205020920502092\n",
      "Epoch 42:\t train loss : 0.5692665554014644; train accuracy : 0.9820102853248242; \n",
      " validation loss : 0.5948992656799515; validation accuracy : 0.9539748953974896\n",
      "Epoch 43:\t train loss : 0.5698444504945804; train accuracy : 0.9812859754019642; \n",
      " validation loss : 0.622445502236443; validation accuracy : 0.9246861924686193\n",
      "Epoch 44:\t train loss : 0.5672521039517474; train accuracy : 0.9839871123640758; \n",
      " validation loss : 0.613191136246726; validation accuracy : 0.9414225941422594\n",
      "Epoch 45:\t train loss : 0.5666422257251126; train accuracy : 0.9845078843830354; \n",
      " validation loss : 0.6117777246142606; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5752879021528963; train accuracy : 0.9756225409709098; \n",
      " validation loss : 0.6384664256583908; validation accuracy : 0.9121338912133892\n",
      "Epoch 47:\t train loss : 0.5701027645370876; train accuracy : 0.9811177545772793; \n",
      " validation loss : 0.5928898322587433; validation accuracy : 0.9581589958158996\n",
      "Epoch 48:\t train loss : 0.5731075394743436; train accuracy : 0.9777970197341925; \n",
      " validation loss : 0.6111015178707656; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.5740617976378005; train accuracy : 0.9770321261501286; \n",
      " validation loss : 0.6260454837411722; validation accuracy : 0.9246861924686193\n",
      "Epoch 50:\t train loss : 0.566723607496968; train accuracy : 0.9845816165308715; \n",
      " validation loss : 0.6100115535478398; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5681714260542398; train accuracy : 0.9831100715635552; \n",
      " validation loss : 0.5942179855951302; validation accuracy : 0.9581589958158996\n",
      "Epoch 52:\t train loss : 0.5660638952337692; train accuracy : 0.9850714086557824; \n",
      " validation loss : 0.5830010564532151; validation accuracy : 0.9665271966527197\n",
      "Epoch 53:\t train loss : 0.5651754047490799; train accuracy : 0.9861107841011184; \n",
      " validation loss : 0.6031463552052846; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.5842306495559045; train accuracy : 0.9667158214318907; \n",
      " validation loss : 0.6519586492183893; validation accuracy : 0.899581589958159\n",
      "Epoch 55:\t train loss : 0.5720587836463366; train accuracy : 0.9791056104588123; \n",
      " validation loss : 0.601984266878557; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5723745662426983; train accuracy : 0.978724247963072; \n",
      " validation loss : 0.6045820106987091; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5722500456060452; train accuracy : 0.9788658260788748; \n",
      " validation loss : 0.6124542378164946; validation accuracy : 0.9372384937238494\n",
      "Epoch 58:\t train loss : 0.5699574209897367; train accuracy : 0.9811775457727935; \n",
      " validation loss : 0.611766845987658; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5641452409655188; train accuracy : 0.9870194243935686; \n",
      " validation loss : 0.6115682904553333; validation accuracy : 0.9330543933054394\n",
      "Epoch 60:\t train loss : 0.5634429986939462; train accuracy : 0.9878942966015056; \n",
      " validation loss : 0.6385106989245385; validation accuracy : 0.9079497907949791\n",
      "Epoch 61:\t train loss : 0.5671358593453367; train accuracy : 0.984203971622417; \n",
      " validation loss : 0.6016476542276568; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5647997389236054; train accuracy : 0.9864286378140587; \n",
      " validation loss : 0.6088013510188055; validation accuracy : 0.9414225941422594\n",
      "Epoch 63:\t train loss : 0.5623904668083497; train accuracy : 0.9887366399206915; \n",
      " validation loss : 0.6180534189488828; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:\t train loss : 0.5687225797133282; train accuracy : 0.9823296880324669; \n",
      " validation loss : 0.6012120648759084; validation accuracy : 0.9497907949790795\n",
      "Epoch 65:\t train loss : 0.563135360848975; train accuracy : 0.9882313578487562; \n",
      " validation loss : 0.6068156520378434; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5642863663997401; train accuracy : 0.9869729545524955; \n",
      " validation loss : 0.5963608915603648; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5622926059411739; train accuracy : 0.9891142848291459; \n",
      " validation loss : 0.597222883597691; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5635199202538025; train accuracy : 0.9877201895969516; \n",
      " validation loss : 0.5979682122174725; validation accuracy : 0.9539748953974896\n",
      "Epoch 69:\t train loss : 0.5647057647554584; train accuracy : 0.9866049134111962; \n",
      " validation loss : 0.605846623592684; validation accuracy : 0.9456066945606695\n",
      "Epoch 70:\t train loss : 0.5724496379070334; train accuracy : 0.9787205303757861; \n",
      " validation loss : 0.6174497708579145; validation accuracy : 0.9330543933054394\n",
      "Epoch 71:\t train loss : 0.5662188706778861; train accuracy : 0.9849261129526937; \n",
      " validation loss : 0.599238337630456; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.563144377701286; train accuracy : 0.9881907741875523; \n",
      " validation loss : 0.6010560056234094; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5620758782016163; train accuracy : 0.9892691842993897; \n",
      " validation loss : 0.5999294339043756; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5632768774363878; train accuracy : 0.9881170420397162; \n",
      " validation loss : 0.5979525770924583; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.564441843988052; train accuracy : 0.9869398060658633; \n",
      " validation loss : 0.5927554271896914; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5633420176652197; train accuracy : 0.9879429350351622; \n",
      " validation loss : 0.5974893661612694; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5720511663606914; train accuracy : 0.9788695436661606; \n",
      " validation loss : 0.5989686503915789; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5638444720684171; train accuracy : 0.9874066730691781; \n",
      " validation loss : 0.5911014947261561; validation accuracy : 0.9623430962343096\n",
      "Epoch 79:\t train loss : 0.5654020793325326; train accuracy : 0.9858208122928219; \n",
      " validation loss : 0.590909483150089; validation accuracy : 0.9581589958158996\n",
      "Epoch 80:\t train loss : 0.5625826406168882; train accuracy : 0.9888568419096007; \n",
      " validation loss : 0.6022355369018111; validation accuracy : 0.9497907949790795\n",
      "Epoch 81:\t train loss : 0.5693059914268193; train accuracy : 0.9819018556956535; \n",
      " validation loss : 0.6124651173526064; validation accuracy : 0.9372384937238494\n",
      "Epoch 82:\t train loss : 0.5628147021917048; train accuracy : 0.9883552774249512; \n",
      " validation loss : 0.5940609670226863; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5667613344471434; train accuracy : 0.9845602404039778; \n",
      " validation loss : 0.6214545913391133; validation accuracy : 0.9288702928870293\n",
      "Epoch 84:\t train loss : 0.5676375230316144; train accuracy : 0.9833461383562069; \n",
      " validation loss : 0.603654714463046; validation accuracy : 0.9456066945606695\n",
      "Epoch 85:\t train loss : 0.562461633549232; train accuracy : 0.9888162582483968; \n",
      " validation loss : 0.6006671282057543; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5616912954688931; train accuracy : 0.9896003593667709; \n",
      " validation loss : 0.5963570289574815; validation accuracy : 0.9581589958158996\n",
      "Epoch 87:\t train loss : 0.5602804514086104; train accuracy : 0.9909789646519409; \n",
      " validation loss : 0.5974805499851381; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5656145708609829; train accuracy : 0.9853502277022212; \n",
      " validation loss : 0.6005977251293636; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.5601343349609587; train accuracy : 0.9912172000371758; \n",
      " validation loss : 0.6045710116030396; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5598767067602805; train accuracy : 0.991387589454444; \n",
      " validation loss : 0.6153889024439189; validation accuracy : 0.9330543933054394\n",
      "Epoch 91:\t train loss : 0.5582488012477655; train accuracy : 0.993101087394281; \n",
      " validation loss : 0.5938243376958222; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5639506555712769; train accuracy : 0.9873617522228074; \n",
      " validation loss : 0.6472731737024987; validation accuracy : 0.9079497907949791\n",
      "Epoch 93:\t train loss : 0.567145360953204; train accuracy : 0.9840084884909693; \n",
      " validation loss : 0.5965604590566271; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5777670634127181; train accuracy : 0.9732312029492859; \n",
      " validation loss : 0.6196602933646265; validation accuracy : 0.9330543933054394\n",
      "Epoch 95:\t train loss : 0.5689509389392805; train accuracy : 0.9821032250069704; \n",
      " validation loss : 0.60851358285385; validation accuracy : 0.9414225941422594\n",
      "Epoch 96:\t train loss : 0.5679872521257125; train accuracy : 0.9833114408748722; \n",
      " validation loss : 0.6250545246015644; validation accuracy : 0.9246861924686193\n",
      "Epoch 97:\t train loss : 0.5625667666136359; train accuracy : 0.9886458688311286; \n",
      " validation loss : 0.6100075455814958; validation accuracy : 0.9372384937238494\n",
      "Epoch 98:\t train loss : 0.5598626598023655; train accuracy : 0.9914495492425416; \n",
      " validation loss : 0.6004799263290512; validation accuracy : 0.9497907949790795\n",
      "Epoch 99:\t train loss : 0.5594591183965659; train accuracy : 0.9918522878651755; \n",
      " validation loss : 0.6052292730640305; validation accuracy : 0.9456066945606695\n",
      "Epoch 100:\t train loss : 0.5592124363188007; train accuracy : 0.9921407106787695; \n",
      " validation loss : 0.6014579606281546; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.5579586471716143; train accuracy : 0.9933548127265405; \n",
      " validation loss : 0.601354012278836; validation accuracy : 0.9497907949790795\n",
      "Epoch 102:\t train loss : 0.5585167495210529; train accuracy : 0.9927816846866384; \n",
      " validation loss : 0.6010518208011549; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 102\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5660638952337692; Train accuracy : 0.9850714086557824; \n",
      " Validation loss : 0.5830010564532151; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 13 ! ---\n",
      "Epoch 1:\t train loss : 0.9513956462271872; train accuracy : 0.5769354688806965; \n",
      " validation loss : 0.8555634913331209; validation accuracy : 0.6820083682008368\n",
      "Epoch 2:\t train loss : 0.7693505965790167; train accuracy : 0.7791629232628025; \n",
      " validation loss : 0.7371007633928492; validation accuracy : 0.8242677824267782\n",
      "Epoch 3:\t train loss : 0.7161557791524416; train accuracy : 0.8333002881130146; \n",
      " validation loss : 0.7165870844976068; validation accuracy : 0.8284518828451883\n",
      "Epoch 4:\t train loss : 0.6848086302742206; train accuracy : 0.8654667121038446; \n",
      " validation loss : 0.7118818284752833; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.6730733935870837; train accuracy : 0.8769354688806964; \n",
      " validation loss : 0.7080416463936806; validation accuracy : 0.8368200836820083\n",
      "Epoch 6:\t train loss : 0.6598762179453661; train accuracy : 0.8900585519997521; \n",
      " validation loss : 0.7081956197012098; validation accuracy : 0.8368200836820083\n",
      "Epoch 7:\t train loss : 0.642254719476417; train accuracy : 0.9083800613401902; \n",
      " validation loss : 0.649491017721271; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6298990516689044; train accuracy : 0.9209207224511292; \n",
      " validation loss : 0.64235657409498; validation accuracy : 0.899581589958159\n",
      "Epoch 9:\t train loss : 0.6189974492563622; train accuracy : 0.9321447380649959; \n",
      " validation loss : 0.6396909385961366; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.6161263018067821; train accuracy : 0.9349360265187893; \n",
      " validation loss : 0.6370941222480263; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.6081450230051072; train accuracy : 0.9428451934694383; \n",
      " validation loss : 0.648577429999207; validation accuracy : 0.899581589958159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\t train loss : 0.603989764941946; train accuracy : 0.9473310821276991; \n",
      " validation loss : 0.6354404247519082; validation accuracy : 0.9121338912133892\n",
      "Epoch 13:\t train loss : 0.5979608878791813; train accuracy : 0.9532048700393445; \n",
      " validation loss : 0.6078048188550821; validation accuracy : 0.9456066945606695\n",
      "Epoch 14:\t train loss : 0.5949133987034095; train accuracy : 0.9559403946838502; \n",
      " validation loss : 0.6541633076628932; validation accuracy : 0.899581589958159\n",
      "Epoch 15:\t train loss : 0.5924974371783774; train accuracy : 0.9588587007032436; \n",
      " validation loss : 0.6239517129855423; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5916544317733469; train accuracy : 0.9594442207007652; \n",
      " validation loss : 0.6254113961275123; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.585391967792364; train accuracy : 0.9660367421543419; \n",
      " validation loss : 0.616327153922716; validation accuracy : 0.9288702928870293\n",
      "Epoch 18:\t train loss : 0.586127044132341; train accuracy : 0.9652932246971715; \n",
      " validation loss : 0.6193581220427573; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5876604401293534; train accuracy : 0.9635521546516311; \n",
      " validation loss : 0.631905068670558; validation accuracy : 0.9205020920502092\n",
      "Epoch 20:\t train loss : 0.5821918528887163; train accuracy : 0.9690139099724279; \n",
      " validation loss : 0.6612786243962792; validation accuracy : 0.891213389121339\n",
      "Epoch 21:\t train loss : 0.5857176495471713; train accuracy : 0.9654914960190836; \n",
      " validation loss : 0.6392837209956593; validation accuracy : 0.9163179916317992\n",
      "Epoch 22:\t train loss : 0.5829061946075159; train accuracy : 0.9678552619350042; \n",
      " validation loss : 0.6070273257391404; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5825870121972729; train accuracy : 0.9682951764304966; \n",
      " validation loss : 0.6434793779016881; validation accuracy : 0.899581589958159\n",
      "Epoch 24:\t train loss : 0.5891514089108565; train accuracy : 0.9617863006908516; \n",
      " validation loss : 0.6063495469494458; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5748299904772988; train accuracy : 0.9764521825335357; \n",
      " validation loss : 0.603429377155628; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.576408098210008; train accuracy : 0.9748226401065708; \n",
      " validation loss : 0.6307780127578393; validation accuracy : 0.9163179916317992\n",
      "Epoch 27:\t train loss : 0.5744017210913711; train accuracy : 0.9771864060224914; \n",
      " validation loss : 0.587999861643851; validation accuracy : 0.9665271966527197\n",
      "Epoch 28:\t train loss : 0.5813581610718245; train accuracy : 0.9697512314507885; \n",
      " validation loss : 0.6142233812706788; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5816544605560566; train accuracy : 0.968986028067784; \n",
      " validation loss : 0.6477253051464055; validation accuracy : 0.9037656903765691\n",
      "Epoch 30:\t train loss : 0.5775550153633854; train accuracy : 0.9735710523870008; \n",
      " validation loss : 0.6010769420556767; validation accuracy : 0.9497907949790795\n",
      "Epoch 31:\t train loss : 0.5703840741139382; train accuracy : 0.9807428978592894; \n",
      " validation loss : 0.6399096239783474; validation accuracy : 0.9121338912133892\n",
      "Epoch 32:\t train loss : 0.5822224559591965; train accuracy : 0.96883732457635; \n",
      " validation loss : 0.6193704446421917; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5779738946445824; train accuracy : 0.9729793364106695; \n",
      " validation loss : 0.6212333641548392; validation accuracy : 0.9205020920502092\n",
      "Epoch 34:\t train loss : 0.5735514826852219; train accuracy : 0.9776139285603643; \n",
      " validation loss : 0.6119843144528452; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5653303526906952; train accuracy : 0.985981597942935; \n",
      " validation loss : 0.6281107690894344; validation accuracy : 0.9246861924686193\n",
      "Epoch 36:\t train loss : 0.5708492959340783; train accuracy : 0.9804145109823724; \n",
      " validation loss : 0.6138781355052635; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5679667436360458; train accuracy : 0.9833730908640292; \n",
      " validation loss : 0.6046702911594524; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5677079050867042; train accuracy : 0.9837975154124973; \n",
      " validation loss : 0.6093581814221664; validation accuracy : 0.9456066945606695\n",
      "Epoch 39:\t train loss : 0.5829434517087273; train accuracy : 0.9681123950556089; \n",
      " validation loss : 0.6017379604237527; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.5787490894869178; train accuracy : 0.9722048390594504; \n",
      " validation loss : 0.619625914867024; validation accuracy : 0.9330543933054394\n",
      "Epoch 41:\t train loss : 0.5770025092553379; train accuracy : 0.9738839493168934; \n",
      " validation loss : 0.6044643244919746; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.57639470336884; train accuracy : 0.9747513863502587; \n",
      " validation loss : 0.6520066046273427; validation accuracy : 0.891213389121339\n",
      "Epoch 43:\t train loss : 0.575865279331106; train accuracy : 0.9750518913225317; \n",
      " validation loss : 0.6081747890767661; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5683277923747637; train accuracy : 0.9829610582731807; \n",
      " validation loss : 0.5972468982811817; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5703511129906187; train accuracy : 0.9806158802936894; \n",
      " validation loss : 0.6055272584997641; validation accuracy : 0.9456066945606695\n",
      "Epoch 46:\t train loss : 0.5662026364054717; train accuracy : 0.9849592614393259; \n",
      " validation loss : 0.5996036698276127; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5665721817227536; train accuracy : 0.9845534248272871; \n",
      " validation loss : 0.6254115637456333; validation accuracy : 0.9246861924686193\n",
      "Epoch 48:\t train loss : 0.5711895213805814; train accuracy : 0.9798196970166362; \n",
      " validation loss : 0.6562076287478079; validation accuracy : 0.891213389121339\n",
      "Epoch 49:\t train loss : 0.5752075995345506; train accuracy : 0.9758914464512531; \n",
      " validation loss : 0.6206941156752099; validation accuracy : 0.9205020920502092\n",
      "Epoch 50:\t train loss : 0.5649293386439325; train accuracy : 0.9864215124384275; \n",
      " validation loss : 0.6148115001442753; validation accuracy : 0.9330543933054394\n",
      "Epoch 51:\t train loss : 0.5656063892797277; train accuracy : 0.9854673317017256; \n",
      " validation loss : 0.6231390645709013; validation accuracy : 0.9288702928870293\n",
      "Epoch 52:\t train loss : 0.5624504887648252; train accuracy : 0.9888286502060163; \n",
      " validation loss : 0.5986506467519973; validation accuracy : 0.9497907949790795\n",
      "Epoch 53:\t train loss : 0.5714695297155412; train accuracy : 0.979497506118529; \n",
      " validation loss : 0.6348247050146555; validation accuracy : 0.9163179916317992\n",
      "Epoch 54:\t train loss : 0.56700222255933; train accuracy : 0.9840918244059605; \n",
      " validation loss : 0.5976082343401252; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5726927752198581; train accuracy : 0.9785247374453979; \n",
      " validation loss : 0.630568147569305; validation accuracy : 0.9288702928870293\n",
      "Epoch 56:\t train loss : 0.5836921055144936; train accuracy : 0.9671117444778339; \n",
      " validation loss : 0.6208401167644362; validation accuracy : 0.9246861924686193\n",
      "Epoch 57:\t train loss : 0.5756437607944858; train accuracy : 0.9753245143901608; \n",
      " validation loss : 0.6009925951460864; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5664156781361677; train accuracy : 0.9848415378419406; \n",
      " validation loss : 0.6036668079341205; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5642823599465971; train accuracy : 0.9868769168809443; \n",
      " validation loss : 0.585764945666648; validation accuracy : 0.9665271966527197\n",
      "Epoch 60:\t train loss : 0.5643677784674129; train accuracy : 0.9867932711670127; \n",
      " validation loss : 0.5990373246184647; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5652397093207638; train accuracy : 0.9858700703243595; \n",
      " validation loss : 0.5941301292209825; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5636085808539294; train accuracy : 0.9876823941262121; \n",
      " validation loss : 0.6190506053342463; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63:\t train loss : 0.5630853172061911; train accuracy : 0.9880417608971778; \n",
      " validation loss : 0.6067821680853436; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5669791521020137; train accuracy : 0.9840887264165556; \n",
      " validation loss : 0.6772801620429062; validation accuracy : 0.8702928870292888\n",
      "Epoch 65:\t train loss : 0.5748488028314329; train accuracy : 0.9761888534341212; \n",
      " validation loss : 0.5989998825487869; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5650635687220952; train accuracy : 0.9861519873602033; \n",
      " validation loss : 0.6070282006146338; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5682846766348025; train accuracy : 0.9827565909724588; \n",
      " validation loss : 0.5908485981321443; validation accuracy : 0.9581589958158996\n",
      "Epoch 68:\t train loss : 0.5635737824654319; train accuracy : 0.9876142383593048; \n",
      " validation loss : 0.5927644771520738; validation accuracy : 0.9581589958158996\n",
      "Epoch 69:\t train loss : 0.5635965350011349; train accuracy : 0.9877257659778803; \n",
      " validation loss : 0.6196433254579912; validation accuracy : 0.9330543933054394\n",
      "Epoch 70:\t train loss : 0.5639509774709742; train accuracy : 0.9871774218532172; \n",
      " validation loss : 0.6232702045616635; validation accuracy : 0.9205020920502092\n",
      "Epoch 71:\t train loss : 0.5696435778056869; train accuracy : 0.9813129279097865; \n",
      " validation loss : 0.650037182400504; validation accuracy : 0.9037656903765691\n",
      "Epoch 72:\t train loss : 0.5717418154967474; train accuracy : 0.9796555035781778; \n",
      " validation loss : 0.5994699083215427; validation accuracy : 0.9539748953974896\n",
      "Epoch 73:\t train loss : 0.5607037552132037; train accuracy : 0.9906409740078689; \n",
      " validation loss : 0.5983508914482677; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5615339250503736; train accuracy : 0.9896960872393816; \n",
      " validation loss : 0.5959525309190874; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.5615575562253761; train accuracy : 0.9897146751758109; \n",
      " validation loss : 0.6083279567849912; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5652209363297401; train accuracy : 0.9860373617522228; \n",
      " validation loss : 0.5948665351763212; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.579113902252106; train accuracy : 0.9720685275256359; \n",
      " validation loss : 0.6011194700995229; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.573040676368798; train accuracy : 0.978022863161808; \n",
      " validation loss : 0.5799104351490351; validation accuracy : 0.9707112970711297\n",
      "Epoch 79:\t train loss : 0.5626446259029806; train accuracy : 0.9885839090430311; \n",
      " validation loss : 0.6061357791183766; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5599972163743803; train accuracy : 0.9913318256451563; \n",
      " validation loss : 0.619089596727191; validation accuracy : 0.9330543933054394\n",
      "Epoch 81:\t train loss : 0.5605306891652414; train accuracy : 0.9907494036370396; \n",
      " validation loss : 0.6045756511765855; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5596544168830052; train accuracy : 0.9916973883949317; \n",
      " validation loss : 0.6025488984498543; validation accuracy : 0.9497907949790795\n",
      "Epoch 83:\t train loss : 0.5587161210089622; train accuracy : 0.9925617274388921; \n",
      " validation loss : 0.6135245393917655; validation accuracy : 0.9372384937238494\n",
      "Epoch 84:\t train loss : 0.5629262343789416; train accuracy : 0.9883577558164751; \n",
      " validation loss : 0.5914835210885245; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.5602143654994566; train accuracy : 0.9910530065987174; \n",
      " validation loss : 0.6002198244100757; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5622291572454052; train accuracy : 0.988912295919948; \n",
      " validation loss : 0.6050882233690728; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.569326787889317; train accuracy : 0.9819139378543326; \n",
      " validation loss : 0.5868598866087366; validation accuracy : 0.9665271966527197\n",
      "Epoch 88:\t train loss : 0.5611372489702491; train accuracy : 0.990188667554757; \n",
      " validation loss : 0.6233440906326425; validation accuracy : 0.9288702928870293\n",
      "Epoch 89:\t train loss : 0.5615156263239299; train accuracy : 0.9896186375042597; \n",
      " validation loss : 0.6177093210433078; validation accuracy : 0.9288702928870293\n",
      "Epoch 90:\t train loss : 0.5598785287563944; train accuracy : 0.9915734688187366; \n",
      " validation loss : 0.6044787828329063; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5661248761835811; train accuracy : 0.9848973016512284; \n",
      " validation loss : 0.6335033056982529; validation accuracy : 0.9121338912133892\n",
      "Epoch 92:\t train loss : 0.5681032700306548; train accuracy : 0.9830756838811612; \n",
      " validation loss : 0.6066658775938448; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5629099028831399; train accuracy : 0.9883515598376653; \n",
      " validation loss : 0.6034723466393659; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5611151209379589; train accuracy : 0.990210353480591; \n",
      " validation loss : 0.6071185557332921; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5601473982563856; train accuracy : 0.9911924161219369; \n",
      " validation loss : 0.5974665330732895; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5597246001042294; train accuracy : 0.9915858607763561; \n",
      " validation loss : 0.6055952399037338; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.5602650883698036; train accuracy : 0.9910003407788345; \n",
      " validation loss : 0.6150342635439269; validation accuracy : 0.9330543933054394\n",
      "Epoch 98:\t train loss : 0.5649559528022332; train accuracy : 0.9861705752966324; \n",
      " validation loss : 0.5997920409456832; validation accuracy : 0.9497907949790795\n",
      "Epoch 99:\t train loss : 0.5613295113365282; train accuracy : 0.9899749062858205; \n",
      " validation loss : 0.6075992477618033; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5591885320444774; train accuracy : 0.9920784410917315; \n",
      " validation loss : 0.62226651735733; validation accuracy : 0.9288702928870293\n",
      "Epoch 101:\t train loss : 0.5599741013148681; train accuracy : 0.9912141020477709; \n",
      " validation loss : 0.5940521253934548; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.5657918083946637; train accuracy : 0.985454939744106; \n",
      " validation loss : 0.6118387336230214; validation accuracy : 0.9372384937238494\n",
      "Epoch 103:\t train loss : 0.560222793334201; train accuracy : 0.9910684965457418; \n",
      " validation loss : 0.6149872836270309; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.5579771482491084; train accuracy : 0.9935004182285696; \n",
      " validation loss : 0.5938114089147409; validation accuracy : 0.9581589958158996\n",
      "Epoch 105:\t train loss : 0.561943594780002; train accuracy : 0.989386288298894; \n",
      " validation loss : 0.5932068135317369; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5613163928195; train accuracy : 0.9899687103070107; \n",
      " validation loss : 0.5915983103815646; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5619080075927086; train accuracy : 0.9894978159174695; \n",
      " validation loss : 0.60039097085999; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.558358716852567; train accuracy : 0.9930512097648626; \n",
      " validation loss : 0.5945189537382396; validation accuracy : 0.9581589958158996\n",
      "Epoch 109:\t train loss : 0.5616323992169666; train accuracy : 0.9895164038538988; \n",
      " validation loss : 0.6062327916854606; validation accuracy : 0.9456066945606695\n",
      "Epoch 110:\t train loss : 0.5586236523350059; train accuracy : 0.9927352148455653; \n",
      " validation loss : 0.6150116128169674; validation accuracy : 0.9372384937238494\n",
      "Epoch 111:\t train loss : 0.557727096925583; train accuracy : 0.9935252021438087; \n",
      " validation loss : 0.6049656886471817; validation accuracy : 0.9456066945606695\n",
      "Epoch 112:\t train loss : 0.5614215024835891; train accuracy : 0.9898726726354595; \n",
      " validation loss : 0.5927804786340677; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5600663585297111; train accuracy : 0.9912543759100344; \n",
      " validation loss : 0.5908082577017968; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114:\t train loss : 0.5580928947116536; train accuracy : 0.9931224635211747; \n",
      " validation loss : 0.6090139225040893; validation accuracy : 0.9414225941422594\n",
      "Epoch 115:\t train loss : 0.5629861767844944; train accuracy : 0.9884042256575483; \n",
      " validation loss : 0.5974989547198529; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5599215444904234; train accuracy : 0.9914309613061123; \n",
      " validation loss : 0.5770732685961959; validation accuracy : 0.9748953974895398\n",
      "Epoch 117:\t train loss : 0.556149161560216; train accuracy : 0.9951981164224418; \n",
      " validation loss : 0.5949762055026113; validation accuracy : 0.9539748953974896\n",
      "Epoch 118:\t train loss : 0.576664420756885; train accuracy : 0.9742619040242882; \n",
      " validation loss : 0.6090508836098819; validation accuracy : 0.9414225941422594\n",
      "Epoch 119:\t train loss : 0.5627744762106804; train accuracy : 0.9883794417423092; \n",
      " validation loss : 0.5930871267079871; validation accuracy : 0.9581589958158996\n",
      "Epoch 120:\t train loss : 0.5583980445081351; train accuracy : 0.9929830539979553; \n",
      " validation loss : 0.5988116081456596; validation accuracy : 0.9497907949790795\n",
      "Epoch 121:\t train loss : 0.5627573323001361; train accuracy : 0.9884909693608848; \n",
      " validation loss : 0.6005956757153916; validation accuracy : 0.9497907949790795\n",
      "Epoch 122:\t train loss : 0.5585127344519257; train accuracy : 0.99286533040057; \n",
      " validation loss : 0.6132731832244601; validation accuracy : 0.9372384937238494\n",
      "Epoch 123:\t train loss : 0.5577821418885066; train accuracy : 0.9934539483874965; \n",
      " validation loss : 0.6037407510510483; validation accuracy : 0.9456066945606695\n",
      "Epoch 124:\t train loss : 0.5569069232746668; train accuracy : 0.9944391090182472; \n",
      " validation loss : 0.5912434501171691; validation accuracy : 0.9581589958158996\n",
      "Epoch 125:\t train loss : 0.5578703121775216; train accuracy : 0.9934539483874965; \n",
      " validation loss : 0.5936752623211198; validation accuracy : 0.9581589958158996\n",
      "Epoch 126:\t train loss : 0.5567808186028408; train accuracy : 0.9946373803401592; \n",
      " validation loss : 0.6091179541026275; validation accuracy : 0.9372384937238494\n",
      "Epoch 127:\t train loss : 0.5657042111005112; train accuracy : 0.9856160351931597; \n",
      " validation loss : 0.6059987674709765; validation accuracy : 0.9456066945606695\n",
      "Epoch 128:\t train loss : 0.5650151453751291; train accuracy : 0.9861117134979398; \n",
      " validation loss : 0.6057392397885272; validation accuracy : 0.9414225941422594\n",
      "Epoch 129:\t train loss : 0.5582844651239475; train accuracy : 0.9929892499767651; \n",
      " validation loss : 0.5897219842053423; validation accuracy : 0.9581589958158996\n",
      "Epoch 130:\t train loss : 0.5559262067248074; train accuracy : 0.9954831314476904; \n",
      " validation loss : 0.5978695427672291; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5549076784466407; train accuracy : 0.9965612317605874; \n",
      " validation loss : 0.6030059256092378; validation accuracy : 0.9497907949790795\n",
      "Epoch 132:\t train loss : 0.5575324041659925; train accuracy : 0.9937885312432231; \n",
      " validation loss : 0.5976309499252734; validation accuracy : 0.9539748953974896\n",
      "Epoch 133:\t train loss : 0.5561549916761468; train accuracy : 0.9952012144118467; \n",
      " validation loss : 0.6180734181899351; validation accuracy : 0.9288702928870293\n",
      "Epoch 134:\t train loss : 0.5601800116611769; train accuracy : 0.9911831221537222; \n",
      " validation loss : 0.6197432509272376; validation accuracy : 0.9330543933054394\n",
      "Epoch 135:\t train loss : 0.5593390988169217; train accuracy : 0.9918832677592243; \n",
      " validation loss : 0.596345821098589; validation accuracy : 0.9539748953974896\n",
      "Epoch 136:\t train loss : 0.5689726149297664; train accuracy : 0.9821865609219617; \n",
      " validation loss : 0.6061293614563348; validation accuracy : 0.9414225941422594\n",
      "Epoch 137:\t train loss : 0.5643057886346757; train accuracy : 0.9870473062982125; \n",
      " validation loss : 0.5889169263313516; validation accuracy : 0.9623430962343096\n",
      "Epoch 138:\t train loss : 0.5605200236492128; train accuracy : 0.9907525016264445; \n",
      " validation loss : 0.5904570841741543; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.558040777772412; train accuracy : 0.9933145388642771; \n",
      " validation loss : 0.6038204358460536; validation accuracy : 0.9456066945606695\n",
      "Epoch 140:\t train loss : 0.5579629172617953; train accuracy : 0.9934012825676136; \n",
      " validation loss : 0.5843274245577248; validation accuracy : 0.9665271966527197\n",
      "Epoch 141:\t train loss : 0.5579078874914619; train accuracy : 0.9933703026735649; \n",
      " validation loss : 0.5819640772506786; validation accuracy : 0.9707112970711297\n",
      "Epoch 142:\t train loss : 0.560399113412694; train accuracy : 0.9909724588741906; \n",
      " validation loss : 0.6242250493220036; validation accuracy : 0.9246861924686193\n",
      "Epoch 143:\t train loss : 0.5585469675252525; train accuracy : 0.9927878806654481; \n",
      " validation loss : 0.5938059543247652; validation accuracy : 0.9581589958158996\n",
      "Epoch 144:\t train loss : 0.5564066597228852; train accuracy : 0.9949595712382664; \n",
      " validation loss : 0.5964122148091363; validation accuracy : 0.9581589958158996\n",
      "Epoch 145:\t train loss : 0.557714792739471; train accuracy : 0.9936243378047647; \n",
      " validation loss : 0.5883238743802; validation accuracy : 0.9623430962343096\n",
      "Epoch 146:\t train loss : 0.5588248902519477; train accuracy : 0.99249047368258; \n",
      " validation loss : 0.6232799168199877; validation accuracy : 0.9288702928870293\n",
      "Epoch 147:\t train loss : 0.559207908301792; train accuracy : 0.9921187149539948; \n",
      " validation loss : 0.6040052240884903; validation accuracy : 0.9456066945606695\n",
      "Epoch 148:\t train loss : 0.5629208814169789; train accuracy : 0.9883267759224263; \n",
      " validation loss : 0.5984714321613369; validation accuracy : 0.9539748953974896\n",
      "Epoch 149:\t train loss : 0.5566578700834025; train accuracy : 0.9946249883825398; \n",
      " validation loss : 0.5851740839274794; validation accuracy : 0.9665271966527197\n",
      "Epoch 150:\t train loss : 0.5559759246546869; train accuracy : 0.9954924254159051; \n",
      " validation loss : 0.595472030798119; validation accuracy : 0.9539748953974896\n",
      "Epoch 151:\t train loss : 0.5610372341986658; train accuracy : 0.9900678459679668; \n",
      " validation loss : 0.5989022103726666; validation accuracy : 0.9539748953974896\n",
      "Epoch 152:\t train loss : 0.5622961193998735; train accuracy : 0.9889649617398308; \n",
      " validation loss : 0.588869985441221; validation accuracy : 0.9623430962343096\n",
      "Epoch 153:\t train loss : 0.5568665273958313; train accuracy : 0.9944545989652716; \n",
      " validation loss : 0.590766780093033; validation accuracy : 0.9623430962343096\n",
      "Epoch 154:\t train loss : 0.5569182802844755; train accuracy : 0.9945010688063447; \n",
      " validation loss : 0.5976133914398052; validation accuracy : 0.9539748953974896\n",
      "Epoch 155:\t train loss : 0.5567143166542122; train accuracy : 0.9947643979057591; \n",
      " validation loss : 0.5832445898758603; validation accuracy : 0.9665271966527197\n",
      "Epoch 156:\t train loss : 0.5578209625056352; train accuracy : 0.9935097121967843; \n",
      " validation loss : 0.6018290581889304; validation accuracy : 0.9497907949790795\n",
      "Epoch 157:\t train loss : 0.5631693680613512; train accuracy : 0.9881470925369435; \n",
      " validation loss : 0.6627612721914496; validation accuracy : 0.8870292887029289\n",
      "Epoch 158:\t train loss : 0.5580520541766557; train accuracy : 0.9933238328324917; \n",
      " validation loss : 0.5930787039117138; validation accuracy : 0.9581589958158996\n",
      "Epoch 159:\t train loss : 0.557518324463858; train accuracy : 0.9937947272220329; \n",
      " validation loss : 0.6002903534320817; validation accuracy : 0.9497907949790795\n",
      "Epoch 160:\t train loss : 0.5598032775988928; train accuracy : 0.9914309613061123; \n",
      " validation loss : 0.5922028667930129; validation accuracy : 0.9623430962343096\n",
      "Epoch 161:\t train loss : 0.5581683911356663; train accuracy : 0.9930759936801016; \n",
      " validation loss : 0.5922861001518395; validation accuracy : 0.9581589958158996\n",
      "Epoch 162:\t train loss : 0.5680676465796509; train accuracy : 0.9830849778493758; \n",
      " validation loss : 0.5779132668667445; validation accuracy : 0.9748953974895398\n",
      "Epoch 163:\t train loss : 0.557389738233632; train accuracy : 0.9939589206604913; \n",
      " validation loss : 0.5884761982825731; validation accuracy : 0.9665271966527197\n",
      "Epoch 164:\t train loss : 0.5550585624185533; train accuracy : 0.9963660584280801; \n",
      " validation loss : 0.5849459802360985; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165:\t train loss : 0.5605725542683507; train accuracy : 0.990687443848942; \n",
      " validation loss : 0.6015427269185212; validation accuracy : 0.9497907949790795\n",
      "Epoch 166:\t train loss : 0.557538582039392; train accuracy : 0.9938040211902475; \n",
      " validation loss : 0.5972133599610938; validation accuracy : 0.9539748953974896\n",
      "Early stopping at epoch 166\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5599215444904234; Train accuracy : 0.9914309613061123; \n",
      " Validation loss : 0.5770732685961959; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 14 ! ---\n",
      "Epoch 1:\t train loss : 0.929730826847054; train accuracy : 0.6088643334112525; \n",
      " validation loss : 0.8278486717893355; validation accuracy : 0.7322175732217573\n",
      "Epoch 2:\t train loss : 0.7431100942897352; train accuracy : 0.807203951907939; \n",
      " validation loss : 0.7278067537781836; validation accuracy : 0.8200836820083682\n",
      "Epoch 3:\t train loss : 0.6939327745451452; train accuracy : 0.8562911715751023; \n",
      " validation loss : 0.7150324645944484; validation accuracy : 0.8410041841004184\n",
      "Epoch 4:\t train loss : 0.665684177950128; train accuracy : 0.8846687545237686; \n",
      " validation loss : 0.6961525695729988; validation accuracy : 0.8451882845188284\n",
      "Epoch 5:\t train loss : 0.6511459843695315; train accuracy : 0.8990063903072361; \n",
      " validation loss : 0.6675242473675788; validation accuracy : 0.8870292887029289\n",
      "Epoch 6:\t train loss : 0.6407668234084437; train accuracy : 0.9097492318394453; \n",
      " validation loss : 0.6699400682009278; validation accuracy : 0.8786610878661087\n",
      "Epoch 7:\t train loss : 0.6349662359499052; train accuracy : 0.9155148717573204; \n",
      " validation loss : 0.6491126192579548; validation accuracy : 0.9037656903765691\n",
      "Epoch 8:\t train loss : 0.619199437546602; train accuracy : 0.9319126704950306; \n",
      " validation loss : 0.6345097446181174; validation accuracy : 0.9163179916317992\n",
      "Epoch 9:\t train loss : 0.6054393194399904; train accuracy : 0.9462098915985344; \n",
      " validation loss : 0.6489486156488765; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.6025169348238538; train accuracy : 0.9488299457288584; \n",
      " validation loss : 0.6454851969100166; validation accuracy : 0.899581589958159\n",
      "Epoch 11:\t train loss : 0.5993212986432768; train accuracy : 0.9517254392808159; \n",
      " validation loss : 0.6327345979855261; validation accuracy : 0.9163179916317992\n",
      "Epoch 12:\t train loss : 0.5958759743344224; train accuracy : 0.9553274152347854; \n",
      " validation loss : 0.6404260280688837; validation accuracy : 0.9121338912133892\n",
      "Epoch 13:\t train loss : 0.6004213109955777; train accuracy : 0.9505731280399021; \n",
      " validation loss : 0.6248970125989062; validation accuracy : 0.9205020920502092\n",
      "Epoch 14:\t train loss : 0.5896486431907932; train accuracy : 0.9614459443094159; \n",
      " validation loss : 0.6364440766307454; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5874443889795278; train accuracy : 0.9635404667825127; \n",
      " validation loss : 0.6174590372407809; validation accuracy : 0.9330543933054394\n",
      "Epoch 16:\t train loss : 0.5836373335748565; train accuracy : 0.9677930205115062; \n",
      " validation loss : 0.6133017166019744; validation accuracy : 0.9372384937238494\n",
      "Epoch 17:\t train loss : 0.5807020339830421; train accuracy : 0.9706896406050655; \n",
      " validation loss : 0.6369165937619966; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.6066501855461335; train accuracy : 0.9442392887016327; \n",
      " validation loss : 0.6820280065129223; validation accuracy : 0.8577405857740585\n",
      "Epoch 19:\t train loss : 0.5873242771417614; train accuracy : 0.9643066558894187; \n",
      " validation loss : 0.6213802401229225; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5800810593327351; train accuracy : 0.9711830658266422; \n",
      " validation loss : 0.6084473075908445; validation accuracy : 0.9414225941422594\n",
      "Epoch 21:\t train loss : 0.5790846765800495; train accuracy : 0.9722042757886495; \n",
      " validation loss : 0.605899434786542; validation accuracy : 0.9497907949790795\n",
      "Epoch 22:\t train loss : 0.5764765949194841; train accuracy : 0.9748348912464901; \n",
      " validation loss : 0.6071058441056578; validation accuracy : 0.9456066945606695\n",
      "Epoch 23:\t train loss : 0.5729992472182777; train accuracy : 0.9785883870458981; \n",
      " validation loss : 0.6025514005008769; validation accuracy : 0.9414225941422594\n",
      "Epoch 24:\t train loss : 0.576466972924307; train accuracy : 0.9748326381632866; \n",
      " validation loss : 0.6184206714423083; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5722600293159713; train accuracy : 0.9790973022144992; \n",
      " validation loss : 0.6221460596313615; validation accuracy : 0.9246861924686193\n",
      "Epoch 26:\t train loss : 0.58022707007249; train accuracy : 0.9708362318309962; \n",
      " validation loss : 0.6374839045910853; validation accuracy : 0.9163179916317992\n",
      "Epoch 27:\t train loss : 0.5762664275927989; train accuracy : 0.9750959672627011; \n",
      " validation loss : 0.6160310485586876; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5744240196313046; train accuracy : 0.976941524041806; \n",
      " validation loss : 0.6189257089817943; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.5775467548526512; train accuracy : 0.9736255488369866; \n",
      " validation loss : 0.602273546685329; validation accuracy : 0.9497907949790795\n",
      "Epoch 30:\t train loss : 0.5695267404375092; train accuracy : 0.9818424024626199; \n",
      " validation loss : 0.6196936415945632; validation accuracy : 0.9330543933054394\n",
      "Epoch 31:\t train loss : 0.5692547268058369; train accuracy : 0.9819209787393436; \n",
      " validation loss : 0.6339097130548401; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.5682445414186968; train accuracy : 0.9829671134342902; \n",
      " validation loss : 0.5891919204597587; validation accuracy : 0.9665271966527197\n",
      "Epoch 33:\t train loss : 0.5778222225983519; train accuracy : 0.973221683672751; \n",
      " validation loss : 0.6261268182152863; validation accuracy : 0.9205020920502092\n",
      "Epoch 34:\t train loss : 0.5673312968375419; train accuracy : 0.983802444032005; \n",
      " validation loss : 0.6190869244441048; validation accuracy : 0.9246861924686193\n",
      "Epoch 35:\t train loss : 0.5674791272251962; train accuracy : 0.9838572221173912; \n",
      " validation loss : 0.5942022031770283; validation accuracy : 0.9581589958158996\n",
      "Epoch 36:\t train loss : 0.5680461808754202; train accuracy : 0.9831352497683549; \n",
      " validation loss : 0.6292220210444192; validation accuracy : 0.9205020920502092\n",
      "Epoch 37:\t train loss : 0.5671250404321841; train accuracy : 0.9843053040394966; \n",
      " validation loss : 0.6023717505416941; validation accuracy : 0.9497907949790795\n",
      "Epoch 38:\t train loss : 0.5689710290070255; train accuracy : 0.9822164142744086; \n",
      " validation loss : 0.5974248760606874; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5654852515283192; train accuracy : 0.9860496128921421; \n",
      " validation loss : 0.598171955418541; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.570966016431975; train accuracy : 0.9799847353612959; \n",
      " validation loss : 0.6400181239459835; validation accuracy : 0.9121338912133892\n",
      "Epoch 41:\t train loss : 0.5689815340016957; train accuracy : 0.9820686965068761; \n",
      " validation loss : 0.615511414211926; validation accuracy : 0.9372384937238494\n",
      "Epoch 42:\t train loss : 0.5695286155331473; train accuracy : 0.9816421596929048; \n",
      " validation loss : 0.608910077418023; validation accuracy : 0.9414225941422594\n",
      "Epoch 43:\t train loss : 0.5653622394912586; train accuracy : 0.9859185116132357; \n",
      " validation loss : 0.5964677313442779; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.5769820381903494; train accuracy : 0.9739092965029332; \n",
      " validation loss : 0.6304781817130833; validation accuracy : 0.9205020920502092\n",
      "Epoch 45:\t train loss : 0.5918279669006433; train accuracy : 0.958877992728174; \n",
      " validation loss : 0.5977276114299894; validation accuracy : 0.9539748953974896\n",
      "Epoch 46:\t train loss : 0.5646789464663486; train accuracy : 0.9866299226347555; \n",
      " validation loss : 0.6141782462577345; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.564709463820547; train accuracy : 0.9865811997104789; \n",
      " validation loss : 0.6224394052067229; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5645792165102208; train accuracy : 0.9866752659342268; \n",
      " validation loss : 0.6095238145399946; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49:\t train loss : 0.56445321455518; train accuracy : 0.9868434022682915; \n",
      " validation loss : 0.6075773555025482; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5631943133794637; train accuracy : 0.9881777907955919; \n",
      " validation loss : 0.6042566683065768; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5645952091287041; train accuracy : 0.986606124443418; \n",
      " validation loss : 0.6073493244722046; validation accuracy : 0.9456066945606695\n",
      "Epoch 52:\t train loss : 0.5636358857308469; train accuracy : 0.987637895732942; \n",
      " validation loss : 0.6015254723355806; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5647738070070957; train accuracy : 0.9864893865699343; \n",
      " validation loss : 0.6244556493311978; validation accuracy : 0.9246861924686193\n",
      "Epoch 54:\t train loss : 0.5640079617800517; train accuracy : 0.9870863128011739; \n",
      " validation loss : 0.6358147943934014; validation accuracy : 0.9121338912133892\n",
      "Epoch 55:\t train loss : 0.5664110074113854; train accuracy : 0.98471409782324; \n",
      " validation loss : 0.6477566239569348; validation accuracy : 0.899581589958159\n",
      "Epoch 56:\t train loss : 0.5742816621581291; train accuracy : 0.9769513812808215; \n",
      " validation loss : 0.6192898068271548; validation accuracy : 0.9288702928870293\n",
      "Epoch 57:\t train loss : 0.569410702563851; train accuracy : 0.9818899988452948; \n",
      " validation loss : 0.5958972863640496; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.5641613383172844; train accuracy : 0.9870182978519668; \n",
      " validation loss : 0.5932933732597054; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5636992252816002; train accuracy : 0.9875902993502671; \n",
      " validation loss : 0.5982023102387588; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5622372579644139; train accuracy : 0.9891559105413315; \n",
      " validation loss : 0.6158002397976539; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5629232693765276; train accuracy : 0.9884052113814498; \n",
      " validation loss : 0.6028468366230005; validation accuracy : 0.9456066945606695\n",
      "Epoch 62:\t train loss : 0.56554743552499; train accuracy : 0.9857519242738735; \n",
      " validation loss : 0.6161064257378501; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5653381891347468; train accuracy : 0.9857923389538371; \n",
      " validation loss : 0.6195544937827067; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.564990125682123; train accuracy : 0.9862974520445322; \n",
      " validation loss : 0.6089614157510495; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.5659033225511421; train accuracy : 0.98526680729661; \n",
      " validation loss : 0.6156682985819262; validation accuracy : 0.9330543933054394\n",
      "Epoch 66:\t train loss : 0.5608068081529499; train accuracy : 0.9905262075821882; \n",
      " validation loss : 0.6153838093807789; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5682026551013895; train accuracy : 0.982950496945664; \n",
      " validation loss : 0.6189652624863115; validation accuracy : 0.9246861924686193\n",
      "Epoch 68:\t train loss : 0.5716007503586283; train accuracy : 0.9796212848770239; \n",
      " validation loss : 0.6079323734097647; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5619387837759215; train accuracy : 0.9894883811315547; \n",
      " validation loss : 0.5953556280790706; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5614615272479802; train accuracy : 0.9898601398601399; \n",
      " validation loss : 0.6255124553090876; validation accuracy : 0.9246861924686193\n",
      "Epoch 71:\t train loss : 0.5664244791260568; train accuracy : 0.984662699362659; \n",
      " validation loss : 0.6098416369155967; validation accuracy : 0.9414225941422594\n",
      "Epoch 72:\t train loss : 0.5628975319577707; train accuracy : 0.9884577363836324; \n",
      " validation loss : 0.6030311689656778; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5649752396543489; train accuracy : 0.9863677200769427; \n",
      " validation loss : 0.6119328625735037; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5648207657398421; train accuracy : 0.9864357350261499; \n",
      " validation loss : 0.6101354215872058; validation accuracy : 0.9414225941422594\n",
      "Epoch 75:\t train loss : 0.5621216581342144; train accuracy : 0.9892488502234776; \n",
      " validation loss : 0.6114343593398597; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5668326603477961; train accuracy : 0.9842969957951835; \n",
      " validation loss : 0.6139812271142442; validation accuracy : 0.9372384937238494\n",
      "Epoch 77:\t train loss : 0.56276927190742; train accuracy : 0.9886043276095632; \n",
      " validation loss : 0.6007882377296263; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5629313600376326; train accuracy : 0.9884112665425593; \n",
      " validation loss : 0.5979768862931405; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5657212395194415; train accuracy : 0.9855777327786993; \n",
      " validation loss : 0.6159974790251005; validation accuracy : 0.9330543933054394\n",
      "Epoch 80:\t train loss : 0.5634298283512363; train accuracy : 0.9878547549912834; \n",
      " validation loss : 0.5892894630666953; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5678471903462862; train accuracy : 0.9834937716331192; \n",
      " validation loss : 0.6004427076770178; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5612764471228872; train accuracy : 0.99010797901253; \n",
      " validation loss : 0.587788333643321; validation accuracy : 0.9623430962343096\n",
      "Epoch 83:\t train loss : 0.5653501662120402; train accuracy : 0.9859102033689227; \n",
      " validation loss : 0.6240937338968388; validation accuracy : 0.9288702928870293\n",
      "Epoch 84:\t train loss : 0.5612690188496746; train accuracy : 0.9900698174157699; \n",
      " validation loss : 0.5968115029581099; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5636627735856763; train accuracy : 0.9875736828616409; \n",
      " validation loss : 0.5934751550013636; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.55989261498199; train accuracy : 0.991379281210131; \n",
      " validation loss : 0.581995840875618; validation accuracy : 0.9707112970711297\n",
      "Epoch 87:\t train loss : 0.560715707151406; train accuracy : 0.9906202738059363; \n",
      " validation loss : 0.596124866336733; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.562946549541168; train accuracy : 0.9883969031371367; \n",
      " validation loss : 0.6060582778572069; validation accuracy : 0.9456066945606695\n",
      "Epoch 89:\t train loss : 0.5621674831773307; train accuracy : 0.9890690260202947; \n",
      " validation loss : 0.6114974351943689; validation accuracy : 0.9414225941422594\n",
      "Epoch 90:\t train loss : 0.5636492660394803; train accuracy : 0.9875653746173279; \n",
      " validation loss : 0.5858137745937029; validation accuracy : 0.9665271966527197\n",
      "Epoch 91:\t train loss : 0.5733194278945888; train accuracy : 0.9777779811811226; \n",
      " validation loss : 0.6095502874361899; validation accuracy : 0.9414225941422594\n",
      "Epoch 92:\t train loss : 0.5620009641889712; train accuracy : 0.9893025017672621; \n",
      " validation loss : 0.5962574745297152; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5605117851757939; train accuracy : 0.9907132134880826; \n",
      " validation loss : 0.5940149555740207; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5621272402620331; train accuracy : 0.9891642187856444; \n",
      " validation loss : 0.6008635700204961; validation accuracy : 0.9497907949790795\n",
      "Epoch 95:\t train loss : 0.5604120718844369; train accuracy : 0.9909444361518466; \n",
      " validation loss : 0.632515210033154; validation accuracy : 0.9205020920502092\n",
      "Epoch 96:\t train loss : 0.5619737450638559; train accuracy : 0.9893323551197091; \n",
      " validation loss : 0.608400974005541; validation accuracy : 0.9414225941422594\n",
      "Epoch 97:\t train loss : 0.5591073976588807; train accuracy : 0.9923241679786182; \n",
      " validation loss : 0.5879211055987832; validation accuracy : 0.9665271966527197\n",
      "Epoch 98:\t train loss : 0.5616687882195857; train accuracy : 0.989581320813701; \n",
      " validation loss : 0.6062191962521246; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5611074862217879; train accuracy : 0.9901223424179526; \n",
      " validation loss : 0.5995412438709974; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100:\t train loss : 0.5669328794894046; train accuracy : 0.984205182654639; \n",
      " validation loss : 0.6092728316845722; validation accuracy : 0.9414225941422594\n",
      "Epoch 101:\t train loss : 0.5626428450403819; train accuracy : 0.9887686618657219; \n",
      " validation loss : 0.5972332037751376; validation accuracy : 0.9539748953974896\n",
      "Epoch 102:\t train loss : 0.5618482659365321; train accuracy : 0.9895027445369773; \n",
      " validation loss : 0.6224802322218921; validation accuracy : 0.9288702928870293\n",
      "Epoch 103:\t train loss : 0.5627672179188062; train accuracy : 0.98851969617173; \n",
      " validation loss : 0.5809834646140241; validation accuracy : 0.9707112970711297\n",
      "Epoch 104:\t train loss : 0.5650012407805658; train accuracy : 0.9863118154499548; \n",
      " validation loss : 0.6160157154175202; validation accuracy : 0.9330543933054394\n",
      "Epoch 105:\t train loss : 0.5641526285118019; train accuracy : 0.9871350357254506; \n",
      " validation loss : 0.6053437201291518; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.5660976974459692; train accuracy : 0.9851954127225976; \n",
      " validation loss : 0.625290405734104; validation accuracy : 0.9246861924686193\n",
      "Epoch 107:\t train loss : 0.5655043109552629; train accuracy : 0.9856468742695081; \n",
      " validation loss : 0.6017434749280491; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.5679005841915187; train accuracy : 0.98329733094131; \n",
      " validation loss : 0.6094804791374447; validation accuracy : 0.9414225941422594\n",
      "Epoch 109:\t train loss : 0.5624690563374378; train accuracy : 0.9888532933035551; \n",
      " validation loss : 0.5937939131708176; validation accuracy : 0.9581589958158996\n",
      "Epoch 110:\t train loss : 0.5630687604771358; train accuracy : 0.9881025941436735; \n",
      " validation loss : 0.5968173556015205; validation accuracy : 0.9539748953974896\n",
      "Epoch 111:\t train loss : 0.5602878789827456; train accuracy : 0.9910218858869685; \n",
      " validation loss : 0.6056728474719892; validation accuracy : 0.9456066945606695\n",
      "Epoch 112:\t train loss : 0.5606024956049956; train accuracy : 0.9907751732761801; \n",
      " validation loss : 0.5898708128054732; validation accuracy : 0.9623430962343096\n",
      "Epoch 113:\t train loss : 0.5647172996005911; train accuracy : 0.9866586494456007; \n",
      " validation loss : 0.6168878790853387; validation accuracy : 0.9288702928870293\n",
      "Epoch 114:\t train loss : 0.562152832412723; train accuracy : 0.9891392940527053; \n",
      " validation loss : 0.5975324176414756; validation accuracy : 0.9539748953974896\n",
      "Epoch 115:\t train loss : 0.5648361951739649; train accuracy : 0.9863975734293897; \n",
      " validation loss : 0.6026443093191851; validation accuracy : 0.9497907949790795\n",
      "Epoch 116:\t train loss : 0.5610769721626546; train accuracy : 0.990270060185485; \n",
      " validation loss : 0.6180711471816045; validation accuracy : 0.9330543933054394\n",
      "Epoch 117:\t train loss : 0.5593420541307526; train accuracy : 0.992089565690049; \n",
      " validation loss : 0.6058779540528324; validation accuracy : 0.9456066945606695\n",
      "Epoch 118:\t train loss : 0.5600639297225876; train accuracy : 0.9912243817398871; \n",
      " validation loss : 0.5879748014947312; validation accuracy : 0.9665271966527197\n",
      "Epoch 119:\t train loss : 0.559720385139415; train accuracy : 0.9915557257885087; \n",
      " validation loss : 0.6041614750650058; validation accuracy : 0.9497907949790795\n",
      "Epoch 120:\t train loss : 0.5607939818320709; train accuracy : 0.9905809856675745; \n",
      " validation loss : 0.602624660707142; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5591173139120504; train accuracy : 0.9922754450543415; \n",
      " validation loss : 0.6101786767364209; validation accuracy : 0.9414225941422594\n",
      "Epoch 122:\t train loss : 0.5601903624683107; train accuracy : 0.9911159521107165; \n",
      " validation loss : 0.6082851913837609; validation accuracy : 0.9414225941422594\n",
      "Epoch 123:\t train loss : 0.5618811637865293; train accuracy : 0.9893417899056239; \n",
      " validation loss : 0.5900799246485898; validation accuracy : 0.9581589958158996\n",
      "Epoch 124:\t train loss : 0.560184524092924; train accuracy : 0.9912088917928628; \n",
      " validation loss : 0.5935837900299195; validation accuracy : 0.9581589958158996\n",
      "Epoch 125:\t train loss : 0.5592780831032331; train accuracy : 0.9920442223905775; \n",
      " validation loss : 0.6014214278412965; validation accuracy : 0.9497907949790795\n",
      "Epoch 126:\t train loss : 0.5677685821044939; train accuracy : 0.983409140195286; \n",
      " validation loss : 0.6060176971161833; validation accuracy : 0.9414225941422594\n",
      "Epoch 127:\t train loss : 0.5623216919885141; train accuracy : 0.9890474809121608; \n",
      " validation loss : 0.5821187865792302; validation accuracy : 0.9707112970711297\n",
      "Epoch 128:\t train loss : 0.5595291202943048; train accuracy : 0.9918953780814433; \n",
      " validation loss : 0.6107465621230482; validation accuracy : 0.9414225941422594\n",
      "Epoch 129:\t train loss : 0.5701777678292639; train accuracy : 0.98105466824758; \n",
      " validation loss : 0.6311913075413773; validation accuracy : 0.9205020920502092\n",
      "Epoch 130:\t train loss : 0.5619487315835984; train accuracy : 0.9893572798526483; \n",
      " validation loss : 0.6054100322101525; validation accuracy : 0.9456066945606695\n",
      "Epoch 131:\t train loss : 0.5600879894405477; train accuracy : 0.9913007049334073; \n",
      " validation loss : 0.6145194044446419; validation accuracy : 0.9372384937238494\n",
      "Epoch 132:\t train loss : 0.5594038258615168; train accuracy : 0.9919905708467931; \n",
      " validation loss : 0.6177548626224035; validation accuracy : 0.9330543933054394\n",
      "Epoch 133:\t train loss : 0.5617728165560897; train accuracy : 0.9895276692699165; \n",
      " validation loss : 0.6005654380400156; validation accuracy : 0.9497907949790795\n",
      "Epoch 134:\t train loss : 0.5595281331729279; train accuracy : 0.9918284896738381; \n",
      " validation loss : 0.5975518321841309; validation accuracy : 0.9539748953974896\n",
      "Epoch 135:\t train loss : 0.5591529326322779; train accuracy : 0.9922229200521588; \n",
      " validation loss : 0.6102358040101544; validation accuracy : 0.9414225941422594\n",
      "Epoch 136:\t train loss : 0.5606504635316097; train accuracy : 0.9906965969994564; \n",
      " validation loss : 0.5804232395617145; validation accuracy : 0.9707112970711297\n",
      "Epoch 137:\t train loss : 0.5583243770421973; train accuracy : 0.9930820488412111; \n",
      " validation loss : 0.6101537010308938; validation accuracy : 0.9456066945606695\n",
      "Epoch 138:\t train loss : 0.5594791420692146; train accuracy : 0.9918904494619356; \n",
      " validation loss : 0.5946746773626008; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5615130089432967; train accuracy : 0.9897207303369204; \n",
      " validation loss : 0.6181434339655704; validation accuracy : 0.9288702928870293\n",
      "Epoch 140:\t train loss : 0.559465553015855; train accuracy : 0.9918666512705981; \n",
      " validation loss : 0.6093801524985233; validation accuracy : 0.9414225941422594\n",
      "Epoch 141:\t train loss : 0.5612009052718673; train accuracy : 0.9900924890655056; \n",
      " validation loss : 0.6057762530851857; validation accuracy : 0.9456066945606695\n",
      "Epoch 142:\t train loss : 0.5587691078388758; train accuracy : 0.9925482089396709; \n",
      " validation loss : 0.5982642827050336; validation accuracy : 0.9581589958158996\n",
      "Epoch 143:\t train loss : 0.5603616599499956; train accuracy : 0.9908836029053508; \n",
      " validation loss : 0.5948883223395127; validation accuracy : 0.9497907949790795\n",
      "Epoch 144:\t train loss : 0.563193082043501; train accuracy : 0.9881407557404336; \n",
      " validation loss : 0.6011490088078005; validation accuracy : 0.9497907949790795\n",
      "Epoch 145:\t train loss : 0.5616164701375315; train accuracy : 0.989619482410461; \n",
      " validation loss : 0.6040941535635783; validation accuracy : 0.9456066945606695\n",
      "Epoch 146:\t train loss : 0.5593221335791857; train accuracy : 0.992097873934362; \n",
      " validation loss : 0.6148655539814877; validation accuracy : 0.9372384937238494\n",
      "Epoch 147:\t train loss : 0.5595051434112454; train accuracy : 0.9918417265376589; \n",
      " validation loss : 0.6334386649057058; validation accuracy : 0.9163179916317992\n",
      "Epoch 148:\t train loss : 0.5609323498033346; train accuracy : 0.9904725560384038; \n",
      " validation loss : 0.5892367426245162; validation accuracy : 0.9623430962343096\n",
      "Epoch 149:\t train loss : 0.5615666495678012; train accuracy : 0.98976494709479; \n",
      " validation loss : 0.629485808838872; validation accuracy : 0.9121338912133892\n",
      "Epoch 150:\t train loss : 0.5842213990167231; train accuracy : 0.9667688533777942; \n",
      " validation loss : 0.7412389733254099; validation accuracy : 0.8075313807531381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151:\t train loss : 0.6092970430219773; train accuracy : 0.9410815925918624; \n",
      " validation loss : 0.6405389612232015; validation accuracy : 0.9079497907949791\n",
      "Epoch 152:\t train loss : 0.5715257950327397; train accuracy : 0.9794807488122027; \n",
      " validation loss : 0.6180584996505485; validation accuracy : 0.9330543933054394\n",
      "Epoch 153:\t train loss : 0.5645665740954907; train accuracy : 0.9866465391233816; \n",
      " validation loss : 0.587201906160277; validation accuracy : 0.9623430962343096\n",
      "Epoch 154:\t train loss : 0.56514033292926; train accuracy : 0.9862498556618573; \n",
      " validation loss : 0.6020299976424923; validation accuracy : 0.9497907949790795\n",
      "Epoch 155:\t train loss : 0.560089937835689; train accuracy : 0.9912769067420698; \n",
      " validation loss : 0.6015013104645702; validation accuracy : 0.9497907949790795\n",
      "Epoch 156:\t train loss : 0.5603420763175199; train accuracy : 0.9909742895042936; \n",
      " validation loss : 0.5974154953874654; validation accuracy : 0.9539748953974896\n",
      "Epoch 157:\t train loss : 0.5656154590660963; train accuracy : 0.985668419377642; \n",
      " validation loss : 0.586938526733653; validation accuracy : 0.9581589958158996\n",
      "Epoch 158:\t train loss : 0.5638095337090316; train accuracy : 0.9875974810529784; \n",
      " validation loss : 0.5800555489549791; validation accuracy : 0.9707112970711297\n",
      "Epoch 159:\t train loss : 0.5604030300353181; train accuracy : 0.9908907846080621; \n",
      " validation loss : 0.6039354938601663; validation accuracy : 0.9456066945606695\n",
      "Epoch 160:\t train loss : 0.5614627315528287; train accuracy : 0.9898529581574286; \n",
      " validation loss : 0.5974928022184833; validation accuracy : 0.9539748953974896\n",
      "Epoch 161:\t train loss : 0.5626267065924492; train accuracy : 0.9885208227133317; \n",
      " validation loss : 0.5995039044938135; validation accuracy : 0.9497907949790795\n",
      "Epoch 162:\t train loss : 0.5621915424812205; train accuracy : 0.9891547839997297; \n",
      " validation loss : 0.6075894709693163; validation accuracy : 0.9414225941422594\n",
      "Epoch 163:\t train loss : 0.5608206196611051; train accuracy : 0.9905035359324526; \n",
      " validation loss : 0.5927371343104954; validation accuracy : 0.9581589958158996\n",
      "Epoch 164:\t train loss : 0.5612295324160698; train accuracy : 0.9901212158763508; \n",
      " validation loss : 0.6278770568148785; validation accuracy : 0.9246861924686193\n",
      "Epoch 165:\t train loss : 0.5604861714039266; train accuracy : 0.9907823549788914; \n",
      " validation loss : 0.5890089331108443; validation accuracy : 0.9623430962343096\n",
      "Epoch 166:\t train loss : 0.5590169980405577; train accuracy : 0.9922538999462076; \n",
      " validation loss : 0.5987945434061709; validation accuracy : 0.9539748953974896\n",
      "Epoch 167:\t train loss : 0.5604952790751867; train accuracy : 0.990844314766989; \n",
      " validation loss : 0.5957177822581285; validation accuracy : 0.9539748953974896\n",
      "Epoch 168:\t train loss : 0.5607521748585349; train accuracy : 0.9905345158265013; \n",
      " validation loss : 0.5899226138162899; validation accuracy : 0.9623430962343096\n",
      "Epoch 169:\t train loss : 0.5601178473538012; train accuracy : 0.9912625433366472; \n",
      " validation loss : 0.5808874939628664; validation accuracy : 0.9707112970711297\n",
      "Epoch 170:\t train loss : 0.5582721415662428; train accuracy : 0.9930831753828129; \n",
      " validation loss : 0.6014609279891848; validation accuracy : 0.9497907949790795\n",
      "Epoch 171:\t train loss : 0.5602817514468589; train accuracy : 0.9909671078015823; \n",
      " validation loss : 0.5781419181204506; validation accuracy : 0.9748953974895398\n",
      "Epoch 172:\t train loss : 0.5621484901621833; train accuracy : 0.9890081927737989; \n",
      " validation loss : 0.5957799911103349; validation accuracy : 0.9539748953974896\n",
      "Epoch 173:\t train loss : 0.560581366646533; train accuracy : 0.9907895366816027; \n",
      " validation loss : 0.6206780683040782; validation accuracy : 0.9330543933054394\n",
      "Epoch 174:\t train loss : 0.568468234117714; train accuracy : 0.9827049108764775; \n",
      " validation loss : 0.5891046699896259; validation accuracy : 0.9623430962343096\n",
      "Epoch 175:\t train loss : 0.5607928454266214; train accuracy : 0.9905333892848995; \n",
      " validation loss : 0.6183023197900982; validation accuracy : 0.9330543933054394\n",
      "Epoch 176:\t train loss : 0.5608033924328422; train accuracy : 0.9905333892848995; \n",
      " validation loss : 0.5818532645927857; validation accuracy : 0.9707112970711297\n",
      "Epoch 177:\t train loss : 0.558608836592179; train accuracy : 0.9928187197417967; \n",
      " validation loss : 0.5971353742873847; validation accuracy : 0.9539748953974896\n",
      "Epoch 178:\t train loss : 0.5580217214667418; train accuracy : 0.9933774843762762; \n",
      " validation loss : 0.5941584639701029; validation accuracy : 0.9581589958158996\n",
      "Epoch 179:\t train loss : 0.5578477902415641; train accuracy : 0.99353238384652; \n",
      " validation loss : 0.5823892698908932; validation accuracy : 0.9707112970711297\n",
      "Epoch 180:\t train loss : 0.558436886611203; train accuracy : 0.9929343310736787; \n",
      " validation loss : 0.5737735913609862; validation accuracy : 0.9790794979079498\n",
      "Epoch 181:\t train loss : 0.5585139688010726; train accuracy : 0.9928818060714959; \n",
      " validation loss : 0.5935613831056566; validation accuracy : 0.9581589958158996\n",
      "Epoch 182:\t train loss : 0.582216743603908; train accuracy : 0.9688716840952041; \n",
      " validation loss : 0.6445262675795572; validation accuracy : 0.9079497907949791\n",
      "Epoch 183:\t train loss : 0.5744686271882471; train accuracy : 0.9765769470159321; \n",
      " validation loss : 0.5849416738933618; validation accuracy : 0.9665271966527197\n",
      "Epoch 184:\t train loss : 0.5613653407217655; train accuracy : 0.9899685694893106; \n",
      " validation loss : 0.5959075271248621; validation accuracy : 0.9539748953974896\n",
      "Epoch 185:\t train loss : 0.5615933094801822; train accuracy : 0.989705240389896; \n",
      " validation loss : 0.6046792510705272; validation accuracy : 0.9497907949790795\n",
      "Epoch 186:\t train loss : 0.5602647737477714; train accuracy : 0.9910993356220903; \n",
      " validation loss : 0.5853679671836695; validation accuracy : 0.9665271966527197\n",
      "Epoch 187:\t train loss : 0.5634023585519602; train accuracy : 0.9879084065350678; \n",
      " validation loss : 0.5940326157123411; validation accuracy : 0.9539748953974896\n",
      "Epoch 188:\t train loss : 0.5582024523964221; train accuracy : 0.9931761150649592; \n",
      " validation loss : 0.5973954269796949; validation accuracy : 0.9539748953974896\n",
      "Epoch 189:\t train loss : 0.5592535522393282; train accuracy : 0.9920668940403132; \n",
      " validation loss : 0.6029520160583227; validation accuracy : 0.9497907949790795\n",
      "Epoch 190:\t train loss : 0.557411952806004; train accuracy : 0.994019753906987; \n",
      " validation loss : 0.5836600690831797; validation accuracy : 0.9665271966527197\n",
      "Epoch 191:\t train loss : 0.558150934631799; train accuracy : 0.9932225849060323; \n",
      " validation loss : 0.6005283178215667; validation accuracy : 0.9497907949790795\n",
      "Epoch 192:\t train loss : 0.5596713258344275; train accuracy : 0.9916497920122568; \n",
      " validation loss : 0.5928661931249645; validation accuracy : 0.9581589958158996\n",
      "Epoch 193:\t train loss : 0.561244321320576; train accuracy : 0.9901450140676883; \n",
      " validation loss : 0.5976062214545387; validation accuracy : 0.9539748953974896\n",
      "Epoch 194:\t train loss : 0.5605668567140102; train accuracy : 0.9907264503519034; \n",
      " validation loss : 0.5968322360459783; validation accuracy : 0.9539748953974896\n",
      "Epoch 195:\t train loss : 0.5613510780295943; train accuracy : 0.9899984228417575; \n",
      " validation loss : 0.6099322200215467; validation accuracy : 0.9414225941422594\n",
      "Epoch 196:\t train loss : 0.5591281631183871; train accuracy : 0.9922002484024232; \n",
      " validation loss : 0.5887323430553433; validation accuracy : 0.9623430962343096\n",
      "Epoch 197:\t train loss : 0.5600941222875397; train accuracy : 0.991331684827456; \n",
      " validation loss : 0.6016938227114008; validation accuracy : 0.9497907949790795\n",
      "Epoch 198:\t train loss : 0.5591448990517615; train accuracy : 0.9921144904229882; \n",
      " validation loss : 0.5810201556454754; validation accuracy : 0.9707112970711297\n",
      "Epoch 199:\t train loss : 0.558176360355312; train accuracy : 0.993245256555768; \n",
      " validation loss : 0.5974730914249058; validation accuracy : 0.9539748953974896\n",
      "Epoch 200:\t train loss : 0.558105714368008; train accuracy : 0.993245256555768; \n",
      " validation loss : 0.5914021668523644; validation accuracy : 0.9581589958158996\n",
      "Epoch 201:\t train loss : 0.5607343606353771; train accuracy : 0.9905654957205501; \n",
      " validation loss : 0.5943771648485877; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202:\t train loss : 0.5587588091656924; train accuracy : 0.992586370536431; \n",
      " validation loss : 0.6405487011630052; validation accuracy : 0.9037656903765691\n",
      "Epoch 203:\t train loss : 0.5580842748643963; train accuracy : 0.9932690547471055; \n",
      " validation loss : 0.6028416761715091; validation accuracy : 0.9497907949790795\n",
      "Epoch 204:\t train loss : 0.5635882233759864; train accuracy : 0.9877916686615841; \n",
      " validation loss : 0.5934252217253235; validation accuracy : 0.9581589958158996\n",
      "Epoch 205:\t train loss : 0.5600002660060258; train accuracy : 0.9913245031247447; \n",
      " validation loss : 0.5847651457298423; validation accuracy : 0.9665271966527197\n",
      "Epoch 206:\t train loss : 0.5621555482455876; train accuracy : 0.9891763291078636; \n",
      " validation loss : 0.6019407386222564; validation accuracy : 0.9497907949790795\n",
      "Epoch 207:\t train loss : 0.5593890765356614; train accuracy : 0.9920990004759638; \n",
      " validation loss : 0.6049670361083389; validation accuracy : 0.9456066945606695\n",
      "Epoch 208:\t train loss : 0.5591702320477823; train accuracy : 0.9922146118078458; \n",
      " validation loss : 0.6109601073314199; validation accuracy : 0.9372384937238494\n",
      "Epoch 209:\t train loss : 0.5598685246306334; train accuracy : 0.9914794025949886; \n",
      " validation loss : 0.597344792742259; validation accuracy : 0.9539748953974896\n",
      "Epoch 210:\t train loss : 0.5594060453420773; train accuracy : 0.9919667726554557; \n",
      " validation loss : 0.6106450568981872; validation accuracy : 0.9414225941422594\n",
      "Epoch 211:\t train loss : 0.5598299580393619; train accuracy : 0.991580650521448; \n",
      " validation loss : 0.5931409030570823; validation accuracy : 0.9581589958158996\n",
      "Epoch 212:\t train loss : 0.5604455603986283; train accuracy : 0.9907740467345784; \n",
      " validation loss : 0.6148247067656898; validation accuracy : 0.9372384937238494\n",
      "Epoch 213:\t train loss : 0.5592845989841791; train accuracy : 0.9920918187732525; \n",
      " validation loss : 0.5903467192308652; validation accuracy : 0.9581589958158996\n",
      "Epoch 214:\t train loss : 0.558539718719329; train accuracy : 0.9927888663893497; \n",
      " validation loss : 0.5908360339386933; validation accuracy : 0.9623430962343096\n",
      "Epoch 215:\t train loss : 0.5575569874314564; train accuracy : 0.9937790964573083; \n",
      " validation loss : 0.5954215900648936; validation accuracy : 0.9539748953974896\n",
      "Epoch 216:\t train loss : 0.5574860869513073; train accuracy : 0.9939041425751051; \n",
      " validation loss : 0.6031979050598545; validation accuracy : 0.9456066945606695\n",
      "Epoch 217:\t train loss : 0.5579316378064272; train accuracy : 0.9934394441643737; \n",
      " validation loss : 0.6021047685914395; validation accuracy : 0.9497907949790795\n",
      "Epoch 218:\t train loss : 0.5593484817672401; train accuracy : 0.9920823839873376; \n",
      " validation loss : 0.6256102699277514; validation accuracy : 0.9288702928870293\n",
      "Epoch 219:\t train loss : 0.5587306388189593; train accuracy : 0.992680436760179; \n",
      " validation loss : 0.601520745681908; validation accuracy : 0.9497907949790795\n",
      "Epoch 220:\t train loss : 0.5574326253243195; train accuracy : 0.993981592310227; \n",
      " validation loss : 0.6020248726909643; validation accuracy : 0.9497907949790795\n",
      "Epoch 221:\t train loss : 0.5569670216592711; train accuracy : 0.994422492529621; \n",
      " validation loss : 0.6133420408058132; validation accuracy : 0.9372384937238494\n",
      "Epoch 222:\t train loss : 0.5578415458890628; train accuracy : 0.9935777271459914; \n",
      " validation loss : 0.5932477871273895; validation accuracy : 0.9581589958158996\n",
      "Epoch 223:\t train loss : 0.5594473641157488; train accuracy : 0.9919584644111427; \n",
      " validation loss : 0.6130844145695555; validation accuracy : 0.9372384937238494\n",
      "Epoch 224:\t train loss : 0.5594823186379326; train accuracy : 0.9917427316944031; \n",
      " validation loss : 0.5881572392583502; validation accuracy : 0.9623430962343096\n",
      "Epoch 225:\t train loss : 0.5585314730319935; train accuracy : 0.9928485730942437; \n",
      " validation loss : 0.575423617218576; validation accuracy : 0.9748953974895398\n",
      "Epoch 226:\t train loss : 0.5662979062475708; train accuracy : 0.9848961751096266; \n",
      " validation loss : 0.5903491222536514; validation accuracy : 0.9581589958158996\n",
      "Epoch 227:\t train loss : 0.5596634386957693; train accuracy : 0.9917117518003543; \n",
      " validation loss : 0.6015952891137385; validation accuracy : 0.9497907949790795\n",
      "Epoch 228:\t train loss : 0.5578394502246313; train accuracy : 0.9935932170930157; \n",
      " validation loss : 0.5881230665427797; validation accuracy : 0.9623430962343096\n",
      "Epoch 229:\t train loss : 0.5580305820136364; train accuracy : 0.9933929743233005; \n",
      " validation loss : 0.5887743158289921; validation accuracy : 0.9623430962343096\n",
      "Epoch 230:\t train loss : 0.5578364203757062; train accuracy : 0.9935633637405688; \n",
      " validation loss : 0.5675341983004413; validation accuracy : 0.9832635983263598\n",
      "Epoch 231:\t train loss : 0.5633613853794954; train accuracy : 0.9878309567999459; \n",
      " validation loss : 0.5914985076365735; validation accuracy : 0.9581589958158996\n",
      "Epoch 232:\t train loss : 0.5635719433678564; train accuracy : 0.9877380171177996; \n",
      " validation loss : 0.5844759296000559; validation accuracy : 0.9665271966527197\n",
      "Epoch 233:\t train loss : 0.5600705223971463; train accuracy : 0.9913078866361186; \n",
      " validation loss : 0.6023085483396083; validation accuracy : 0.9497907949790795\n",
      "Epoch 234:\t train loss : 0.5587836962569588; train accuracy : 0.9925636988866953; \n",
      " validation loss : 0.586661263490389; validation accuracy : 0.9623430962343096\n",
      "Epoch 235:\t train loss : 0.56131741134774; train accuracy : 0.9900056045444688; \n",
      " validation loss : 0.6105056768880505; validation accuracy : 0.9414225941422594\n",
      "Epoch 236:\t train loss : 0.5605488489694764; train accuracy : 0.9908276982783628; \n",
      " validation loss : 0.584603946402397; validation accuracy : 0.9665271966527197\n",
      "Epoch 237:\t train loss : 0.5623427793164482; train accuracy : 0.9890081927737989; \n",
      " validation loss : 0.5981502999182401; validation accuracy : 0.9497907949790795\n",
      "Epoch 238:\t train loss : 0.5587167209215818; train accuracy : 0.9926948001656016; \n",
      " validation loss : 0.5922658174540435; validation accuracy : 0.9581589958158996\n",
      "Epoch 239:\t train loss : 0.5603590922490725; train accuracy : 0.9910290675896798; \n",
      " validation loss : 0.5967559845190823; validation accuracy : 0.9539748953974896\n",
      "Epoch 240:\t train loss : 0.5594451281383518; train accuracy : 0.991973954358167; \n",
      " validation loss : 0.6090577741010129; validation accuracy : 0.9414225941422594\n",
      "Epoch 241:\t train loss : 0.5645722146342155; train accuracy : 0.9867228623169018; \n",
      " validation loss : 0.6016381163698268; validation accuracy : 0.9497907949790795\n",
      "Epoch 242:\t train loss : 0.5588790790171304; train accuracy : 0.992385001225114; \n",
      " validation loss : 0.6016757381130154; validation accuracy : 0.9497907949790795\n",
      "Epoch 243:\t train loss : 0.5600004403155318; train accuracy : 0.9913090131777204; \n",
      " validation loss : 0.5960785641368809; validation accuracy : 0.9539748953974896\n",
      "Epoch 244:\t train loss : 0.5614541754459692; train accuracy : 0.989782690125018; \n",
      " validation loss : 0.6025186006928251; validation accuracy : 0.9497907949790795\n",
      "Epoch 245:\t train loss : 0.5571577207336805; train accuracy : 0.9942139415155927; \n",
      " validation loss : 0.5892728856952859; validation accuracy : 0.9623430962343096\n",
      "Epoch 246:\t train loss : 0.5569619019245629; train accuracy : 0.9944833257761168; \n",
      " validation loss : 0.5883920986791219; validation accuracy : 0.9623430962343096\n",
      "Epoch 247:\t train loss : 0.557063917587406; train accuracy : 0.9943533510388122; \n",
      " validation loss : 0.5849721456245992; validation accuracy : 0.9665271966527197\n",
      "Epoch 248:\t train loss : 0.5580493024610453; train accuracy : 0.9933298879936012; \n",
      " validation loss : 0.5970794136381148; validation accuracy : 0.9539748953974896\n",
      "Epoch 249:\t train loss : 0.5609416031721025; train accuracy : 0.9903773632730539; \n",
      " validation loss : 0.5958943174989387; validation accuracy : 0.9539748953974896\n",
      "Epoch 250:\t train loss : 0.5586016316556555; train accuracy : 0.9928043563363741; \n",
      " validation loss : 0.5961028142819866; validation accuracy : 0.9539748953974896\n",
      "Epoch 251:\t train loss : 0.561572744592928; train accuracy : 0.9897290385812335; \n",
      " validation loss : 0.5925570899605695; validation accuracy : 0.9581589958158996\n",
      "Epoch 252:\t train loss : 0.5578889890296614; train accuracy : 0.9934704240584225; \n",
      " validation loss : 0.5974095811427989; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253:\t train loss : 0.5573189419315251; train accuracy : 0.9940745319923733; \n",
      " validation loss : 0.6014822234213552; validation accuracy : 0.9497907949790795\n",
      "Epoch 254:\t train loss : 0.5586612364751586; train accuracy : 0.9927114166542278; \n",
      " validation loss : 0.5881200846238273; validation accuracy : 0.9623430962343096\n",
      "Epoch 255:\t train loss : 0.558330975751744; train accuracy : 0.9930593771914754; \n",
      " validation loss : 0.5945522942540946; validation accuracy : 0.9581589958158996\n",
      "Epoch 256:\t train loss : 0.5643190118626176; train accuracy : 0.9869718280108937; \n",
      " validation loss : 0.6018840305079278; validation accuracy : 0.9497907949790795\n",
      "Epoch 257:\t train loss : 0.5606118557080296; train accuracy : 0.990796718384314; \n",
      " validation loss : 0.5980606497587986; validation accuracy : 0.9539748953974896\n",
      "Epoch 258:\t train loss : 0.5581645347328179; train accuracy : 0.9932690547471055; \n",
      " validation loss : 0.5958086955986002; validation accuracy : 0.9539748953974896\n",
      "Epoch 259:\t train loss : 0.5585227545687536; train accuracy : 0.9928508261774471; \n",
      " validation loss : 0.5934833664601948; validation accuracy : 0.9581589958158996\n",
      "Epoch 260:\t train loss : 0.5571955197556979; train accuracy : 0.9941746533772309; \n",
      " validation loss : 0.5721166036638974; validation accuracy : 0.9832635983263598\n",
      "Epoch 261:\t train loss : 0.5591542059434049; train accuracy : 0.9921299803700125; \n",
      " validation loss : 0.6013640458064589; validation accuracy : 0.9497907949790795\n",
      "Epoch 262:\t train loss : 0.5592824054327769; train accuracy : 0.9921216721256995; \n",
      " validation loss : 0.5845462167938892; validation accuracy : 0.9665271966527197\n",
      "Epoch 263:\t train loss : 0.5643727168170922; train accuracy : 0.9869718280108937; \n",
      " validation loss : 0.6059351531852897; validation accuracy : 0.9456066945606695\n",
      "Epoch 264:\t train loss : 0.5636473542620669; train accuracy : 0.9876511325967628; \n",
      " validation loss : 0.5914676314556924; validation accuracy : 0.9581589958158996\n",
      "Epoch 265:\t train loss : 0.5594391608952863; train accuracy : 0.9919822626024801; \n",
      " validation loss : 0.5873676881803007; validation accuracy : 0.9623430962343096\n",
      "Epoch 266:\t train loss : 0.5588201711198016; train accuracy : 0.9925482089396709; \n",
      " validation loss : 0.6002770957241347; validation accuracy : 0.9497907949790795\n",
      "Epoch 267:\t train loss : 0.5578961305958492; train accuracy : 0.9935478737935444; \n",
      " validation loss : 0.6077554705779502; validation accuracy : 0.9414225941422594\n",
      "Epoch 268:\t train loss : 0.5595702318629667; train accuracy : 0.9917665298857405; \n",
      " validation loss : 0.5981328558768405; validation accuracy : 0.9539748953974896\n",
      "Epoch 269:\t train loss : 0.5611098228112031; train accuracy : 0.9902247168860137; \n",
      " validation loss : 0.5849941608257248; validation accuracy : 0.9665271966527197\n",
      "Epoch 270:\t train loss : 0.5599813246420652; train accuracy : 0.9913864629128423; \n",
      " validation loss : 0.5883766314247504; validation accuracy : 0.9623430962343096\n",
      "Epoch 271:\t train loss : 0.559869409335613; train accuracy : 0.9915186907333504; \n",
      " validation loss : 0.5888007207896768; validation accuracy : 0.9623430962343096\n",
      "Epoch 272:\t train loss : 0.5585404142789664; train accuracy : 0.992825901444508; \n",
      " validation loss : 0.6195222552831828; validation accuracy : 0.9330543933054394\n",
      "Epoch 273:\t train loss : 0.5577062605999983; train accuracy : 0.9937099549664995; \n",
      " validation loss : 0.5973141201057868; validation accuracy : 0.9539748953974896\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5578364203757062; Train accuracy : 0.9935633637405688; \n",
      " Validation loss : 0.5675341983004413; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 15 ! ---\n",
      "Epoch 1:\t train loss : 0.9463824280652321; train accuracy : 0.5851878930574057; \n",
      " validation loss : 0.8504248961693854; validation accuracy : 0.6903765690376569\n",
      "Epoch 2:\t train loss : 0.7680462107424737; train accuracy : 0.7806502679760835; \n",
      " validation loss : 0.8009260932273707; validation accuracy : 0.7405857740585774\n",
      "Epoch 3:\t train loss : 0.7175507918747452; train accuracy : 0.8321667337897705; \n",
      " validation loss : 0.7511058804563149; validation accuracy : 0.7949790794979079\n",
      "Epoch 4:\t train loss : 0.6875793333616123; train accuracy : 0.8628839183369993; \n",
      " validation loss : 0.7164099896127163; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.6774792258189292; train accuracy : 0.8727702221258403; \n",
      " validation loss : 0.7170248391941457; validation accuracy : 0.8284518828451883\n",
      "Epoch 6:\t train loss : 0.6601093073745242; train accuracy : 0.8899950432169522; \n",
      " validation loss : 0.6926609041394877; validation accuracy : 0.8577405857740585\n",
      "Epoch 7:\t train loss : 0.6476866521091608; train accuracy : 0.9026444437560024; \n",
      " validation loss : 0.6928188694257507; validation accuracy : 0.8535564853556485\n",
      "Epoch 8:\t train loss : 0.6314520615051872; train accuracy : 0.9195092784782676; \n",
      " validation loss : 0.6601411954923412; validation accuracy : 0.891213389121339\n",
      "Epoch 9:\t train loss : 0.6259899365089266; train accuracy : 0.924880572508442; \n",
      " validation loss : 0.7006302982873617; validation accuracy : 0.8368200836820083\n",
      "Epoch 10:\t train loss : 0.624329457926441; train accuracy : 0.9262923262802442; \n",
      " validation loss : 0.6590293690565968; validation accuracy : 0.8828451882845189\n",
      "Epoch 11:\t train loss : 0.609751956389185; train accuracy : 0.9417085411567893; \n",
      " validation loss : 0.674361102710723; validation accuracy : 0.8702928870292888\n",
      "Epoch 12:\t train loss : 0.6069866396440695; train accuracy : 0.9444177328913536; \n",
      " validation loss : 0.658509465975493; validation accuracy : 0.895397489539749\n",
      "Epoch 13:\t train loss : 0.6029851627709715; train accuracy : 0.9484578208742526; \n",
      " validation loss : 0.702138456900309; validation accuracy : 0.8451882845188284\n",
      "Epoch 14:\t train loss : 0.6060992182590187; train accuracy : 0.9450543697140555; \n",
      " validation loss : 0.6456308166224458; validation accuracy : 0.9037656903765691\n",
      "Epoch 15:\t train loss : 0.5963919466011223; train accuracy : 0.9551132315127482; \n",
      " validation loss : 0.675976793573847; validation accuracy : 0.8702928870292888\n",
      "Epoch 16:\t train loss : 0.5991189591035948; train accuracy : 0.9521118993773041; \n",
      " validation loss : 0.6613336029630253; validation accuracy : 0.8870292887029289\n",
      "Epoch 17:\t train loss : 0.5914307479457805; train accuracy : 0.9599194522754733; \n",
      " validation loss : 0.6513816658530602; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.5861308754707967; train accuracy : 0.9652052417980731; \n",
      " validation loss : 0.6761312417818525; validation accuracy : 0.8702928870292888\n",
      "Epoch 19:\t train loss : 0.5896798993752791; train accuracy : 0.9618690170079618; \n",
      " validation loss : 0.6636598952116359; validation accuracy : 0.8786610878661087\n",
      "Epoch 20:\t train loss : 0.5892920111112997; train accuracy : 0.9619133182564515; \n",
      " validation loss : 0.648715319555485; validation accuracy : 0.9037656903765691\n",
      "Epoch 21:\t train loss : 0.5857106791954345; train accuracy : 0.9655636791722172; \n",
      " validation loss : 0.6864601139413264; validation accuracy : 0.8619246861924686\n",
      "Epoch 22:\t train loss : 0.5833550204406842; train accuracy : 0.9676195049412931; \n",
      " validation loss : 0.7260721757855942; validation accuracy : 0.8200836820083682\n",
      "Epoch 23:\t train loss : 0.588079033004556; train accuracy : 0.9628352799033427; \n",
      " validation loss : 0.6444627966949077; validation accuracy : 0.9037656903765691\n",
      "Epoch 24:\t train loss : 0.5837117625344049; train accuracy : 0.967472660243502; \n",
      " validation loss : 0.6454036892600478; validation accuracy : 0.9079497907949791\n",
      "Epoch 25:\t train loss : 0.5790715295705958; train accuracy : 0.9718718051984262; \n",
      " validation loss : 0.6582812674703188; validation accuracy : 0.895397489539749\n",
      "Epoch 26:\t train loss : 0.576271049311576; train accuracy : 0.9749484184764088; \n",
      " validation loss : 0.6347956574624416; validation accuracy : 0.9121338912133892\n",
      "Epoch 27:\t train loss : 0.5769590551304795; train accuracy : 0.9742594256327644; \n",
      " validation loss : 0.6424793826325715; validation accuracy : 0.9037656903765691\n",
      "Epoch 28:\t train loss : 0.5751168093872845; train accuracy : 0.9759766411598872; \n",
      " validation loss : 0.6350741746481662; validation accuracy : 0.9163179916317992\n",
      "Epoch 29:\t train loss : 0.5751391026522797; train accuracy : 0.9760193934136745; \n",
      " validation loss : 0.6185202401138722; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:\t train loss : 0.5714946182512283; train accuracy : 0.9797465844666812; \n",
      " validation loss : 0.6251458931077603; validation accuracy : 0.9205020920502092\n",
      "Epoch 31:\t train loss : 0.567361846372934; train accuracy : 0.9840778834536386; \n",
      " validation loss : 0.6315095673129011; validation accuracy : 0.9205020920502092\n",
      "Epoch 32:\t train loss : 0.5665038263723672; train accuracy : 0.984867870751882; \n",
      " validation loss : 0.630530578079795; validation accuracy : 0.9205020920502092\n",
      "Epoch 33:\t train loss : 0.5770593245722938; train accuracy : 0.9740484525542923; \n",
      " validation loss : 0.6023493813757138; validation accuracy : 0.9497907949790795\n",
      "Epoch 34:\t train loss : 0.5714354360146968; train accuracy : 0.9800969670683727; \n",
      " validation loss : 0.6343893663368739; validation accuracy : 0.9163179916317992\n",
      "Epoch 35:\t train loss : 0.5713820878991128; train accuracy : 0.9797444158740977; \n",
      " validation loss : 0.6138521638122696; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.5697995880110188; train accuracy : 0.9813885188512655; \n",
      " validation loss : 0.6299366613856586; validation accuracy : 0.9121338912133892\n",
      "Epoch 37:\t train loss : 0.5705924119820984; train accuracy : 0.9808057870442083; \n",
      " validation loss : 0.6484373151227528; validation accuracy : 0.895397489539749\n",
      "Epoch 38:\t train loss : 0.5707405855042372; train accuracy : 0.9804185383685988; \n",
      " validation loss : 0.6181895053530402; validation accuracy : 0.9330543933054394\n",
      "Epoch 39:\t train loss : 0.5684419645513801; train accuracy : 0.9828039902103535; \n",
      " validation loss : 0.6094316527846537; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.567403965622238; train accuracy : 0.98375476315871; \n",
      " validation loss : 0.6206596217669073; validation accuracy : 0.9288702928870293\n",
      "Epoch 41:\t train loss : 0.5687369535866597; train accuracy : 0.9825620372378326; \n",
      " validation loss : 0.6118042076457147; validation accuracy : 0.9372384937238494\n",
      "Epoch 42:\t train loss : 0.5689591608596761; train accuracy : 0.9824263453018991; \n",
      " validation loss : 0.608732346915838; validation accuracy : 0.9372384937238494\n",
      "Epoch 43:\t train loss : 0.5711006820586721; train accuracy : 0.9801087394281112; \n",
      " validation loss : 0.6128017051819864; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5651044894791423; train accuracy : 0.9861749124817993; \n",
      " validation loss : 0.6232176988773729; validation accuracy : 0.9288702928870293\n",
      "Epoch 45:\t train loss : 0.565579966578725; train accuracy : 0.9855745221351343; \n",
      " validation loss : 0.6053663511713139; validation accuracy : 0.9456066945606695\n",
      "Epoch 46:\t train loss : 0.5665599846353668; train accuracy : 0.9845543542241085; \n",
      " validation loss : 0.6226562590065239; validation accuracy : 0.9288702928870293\n",
      "Epoch 47:\t train loss : 0.563304152749309; train accuracy : 0.9880433098918802; \n",
      " validation loss : 0.6228897428654988; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5683891924029132; train accuracy : 0.9826277146132161; \n",
      " validation loss : 0.6456725218051199; validation accuracy : 0.9079497907949791\n",
      "Epoch 49:\t train loss : 0.5712030823923518; train accuracy : 0.9797812819480157; \n",
      " validation loss : 0.6261904310248179; validation accuracy : 0.9246861924686193\n",
      "Epoch 50:\t train loss : 0.5701686742528006; train accuracy : 0.980675981288144; \n",
      " validation loss : 0.6040084683291993; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5655120552849688; train accuracy : 0.9857721738591654; \n",
      " validation loss : 0.6199466278175361; validation accuracy : 0.9330543933054394\n",
      "Epoch 52:\t train loss : 0.5670964113778484; train accuracy : 0.9840837696335079; \n",
      " validation loss : 0.6183461945399368; validation accuracy : 0.9330543933054394\n",
      "Epoch 53:\t train loss : 0.5625013221879993; train accuracy : 0.9887831097617646; \n",
      " validation loss : 0.6130265563337125; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5626446681980499; train accuracy : 0.9886127203444964; \n",
      " validation loss : 0.6192892948446043; validation accuracy : 0.9330543933054394\n",
      "Epoch 55:\t train loss : 0.5643539882050864; train accuracy : 0.9870033148486632; \n",
      " validation loss : 0.6508752486917517; validation accuracy : 0.895397489539749\n",
      "Epoch 56:\t train loss : 0.5693373199369169; train accuracy : 0.9819594782985842; \n",
      " validation loss : 0.679311520239386; validation accuracy : 0.8744769874476988\n",
      "Epoch 57:\t train loss : 0.5871204521214766; train accuracy : 0.9635109513925463; \n",
      " validation loss : 0.6278283265344521; validation accuracy : 0.9163179916317992\n",
      "Epoch 58:\t train loss : 0.5737084453678264; train accuracy : 0.9771811394405031; \n",
      " validation loss : 0.6103715344819279; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5676050843050305; train accuracy : 0.9836714272437188; \n",
      " validation loss : 0.6149921359794303; validation accuracy : 0.9372384937238494\n",
      "Epoch 60:\t train loss : 0.56228051565412; train accuracy : 0.9889011431580904; \n",
      " validation loss : 0.6025306577557221; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5604297414141591; train accuracy : 0.9910040583661204; \n",
      " validation loss : 0.6122483045730804; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5635354728020507; train accuracy : 0.9877180210043681; \n",
      " validation loss : 0.6246637382449425; validation accuracy : 0.9246861924686193\n",
      "Epoch 63:\t train loss : 0.5686782916609768; train accuracy : 0.9825369435236532; \n",
      " validation loss : 0.6152238722685536; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.5606800298393603; train accuracy : 0.990700145605502; \n",
      " validation loss : 0.6155969455489898; validation accuracy : 0.9372384937238494\n",
      "Epoch 65:\t train loss : 0.563131492638046; train accuracy : 0.9880454784844636; \n",
      " validation loss : 0.621384614200944; validation accuracy : 0.9288702928870293\n",
      "Epoch 66:\t train loss : 0.5617406595524708; train accuracy : 0.9895480033458286; \n",
      " validation loss : 0.6030894675621638; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5612996927460953; train accuracy : 0.9899603457356175; \n",
      " validation loss : 0.6045147778721248; validation accuracy : 0.9456066945606695\n",
      "Epoch 68:\t train loss : 0.561410239903295; train accuracy : 0.9899448557885931; \n",
      " validation loss : 0.6144201236181644; validation accuracy : 0.9372384937238494\n",
      "Epoch 69:\t train loss : 0.5609393191608403; train accuracy : 0.9904811177545773; \n",
      " validation loss : 0.6041708333301719; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5652249625554686; train accuracy : 0.9860878589795223; \n",
      " validation loss : 0.6185602038861702; validation accuracy : 0.9330543933054394\n",
      "Epoch 71:\t train loss : 0.5659816087555423; train accuracy : 0.9852882679141237; \n",
      " validation loss : 0.6218146326341513; validation accuracy : 0.9330543933054394\n",
      "Epoch 72:\t train loss : 0.5640503320132713; train accuracy : 0.9871529477369188; \n",
      " validation loss : 0.6043613312859756; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5605256923670856; train accuracy : 0.9908934601443663; \n",
      " validation loss : 0.6033843145315194; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.5749277710916179; train accuracy : 0.9758527215836922; \n",
      " validation loss : 0.6270507463095127; validation accuracy : 0.9246861924686193\n",
      "Epoch 75:\t train loss : 0.5631677449382203; train accuracy : 0.9881362495740265; \n",
      " validation loss : 0.6201214046177643; validation accuracy : 0.9288702928870293\n",
      "Epoch 76:\t train loss : 0.5650428556043711; train accuracy : 0.9860841413922364; \n",
      " validation loss : 0.6076069769356781; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5649011584789437; train accuracy : 0.986347470491651; \n",
      " validation loss : 0.6206310905820276; validation accuracy : 0.9288702928870293\n",
      "Epoch 78:\t train loss : 0.562247648962268; train accuracy : 0.9888258620155519; \n",
      " validation loss : 0.6012277407479879; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.559560621189639; train accuracy : 0.9917203135165278; \n",
      " validation loss : 0.6176998668876286; validation accuracy : 0.9330543933054394\n",
      "Epoch 80:\t train loss : 0.5584577132940561; train accuracy : 0.9929461879240373; \n",
      " validation loss : 0.5875207351662696; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81:\t train loss : 0.5596522656996221; train accuracy : 0.9917261996963971; \n",
      " validation loss : 0.632621488561459; validation accuracy : 0.9163179916317992\n",
      "Epoch 82:\t train loss : 0.5608670123763256; train accuracy : 0.9903571981783822; \n",
      " validation loss : 0.6054208343950847; validation accuracy : 0.9497907949790795\n",
      "Epoch 83:\t train loss : 0.5627152022446218; train accuracy : 0.9884984045354565; \n",
      " validation loss : 0.632799386818072; validation accuracy : 0.9205020920502092\n",
      "Epoch 84:\t train loss : 0.5757674359524141; train accuracy : 0.9751305802534155; \n",
      " validation loss : 0.5954403706073779; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5651678362986161; train accuracy : 0.985994919297376; \n",
      " validation loss : 0.6094198982948; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.565768627297615; train accuracy : 0.9853753214164007; \n",
      " validation loss : 0.6047145177045108; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.5655266739436103; train accuracy : 0.9858459060070015; \n",
      " validation loss : 0.6289449736073629; validation accuracy : 0.9205020920502092\n",
      "Epoch 88:\t train loss : 0.5598361858506714; train accuracy : 0.9916140524799405; \n",
      " validation loss : 0.6040980876883639; validation accuracy : 0.9456066945606695\n",
      "Epoch 89:\t train loss : 0.5594146659095055; train accuracy : 0.9918464016853062; \n",
      " validation loss : 0.6266755871752859; validation accuracy : 0.9246861924686193\n",
      "Epoch 90:\t train loss : 0.5663518115579891; train accuracy : 0.9846723876204343; \n",
      " validation loss : 0.6082576031593593; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5606359858277323; train accuracy : 0.9907775953406239; \n",
      " validation loss : 0.6292088945963042; validation accuracy : 0.9205020920502092\n",
      "Epoch 92:\t train loss : 0.5661409537411123; train accuracy : 0.9850264878094117; \n",
      " validation loss : 0.6186426403992531; validation accuracy : 0.9330543933054394\n",
      "Epoch 93:\t train loss : 0.5716643956872148; train accuracy : 0.9793726571455126; \n",
      " validation loss : 0.6031450320845787; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5680955909113296; train accuracy : 0.9829706620403358; \n",
      " validation loss : 0.6115448914712501; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.562146902032749; train accuracy : 0.989046438861179; \n",
      " validation loss : 0.6228403291378131; validation accuracy : 0.9288702928870293\n",
      "Epoch 96:\t train loss : 0.5609431748237855; train accuracy : 0.9904309303262183; \n",
      " validation loss : 0.6107192616265033; validation accuracy : 0.9372384937238494\n",
      "Epoch 97:\t train loss : 0.5609068442103129; train accuracy : 0.9903593667709656; \n",
      " validation loss : 0.5927422103505527; validation accuracy : 0.9581589958158996\n",
      "Epoch 98:\t train loss : 0.5580096965107949; train accuracy : 0.9933334365996468; \n",
      " validation loss : 0.619054494780867; validation accuracy : 0.9288702928870293\n",
      "Epoch 99:\t train loss : 0.5596339130356726; train accuracy : 0.9918036494315189; \n",
      " validation loss : 0.6109871907418452; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5584348000129885; train accuracy : 0.9929557916911924; \n",
      " validation loss : 0.6158821533123455; validation accuracy : 0.9330543933054394\n",
      "Epoch 101:\t train loss : 0.5607671195604637; train accuracy : 0.9905644536695685; \n",
      " validation loss : 0.6214378631278537; validation accuracy : 0.9288702928870293\n",
      "Epoch 102:\t train loss : 0.5597014904682394; train accuracy : 0.9916332600142508; \n",
      " validation loss : 0.6282535248467668; validation accuracy : 0.9246861924686193\n",
      "Epoch 103:\t train loss : 0.562428878542263; train accuracy : 0.9888664456767557; \n",
      " validation loss : 0.6142495343008181; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.5590688925080258; train accuracy : 0.992289723969144; \n",
      " validation loss : 0.6172832572128291; validation accuracy : 0.9330543933054394\n",
      "Epoch 105:\t train loss : 0.5579715286971785; train accuracy : 0.9934108863347687; \n",
      " validation loss : 0.6129925029109456; validation accuracy : 0.9372384937238494\n",
      "Epoch 106:\t train loss : 0.5585442521939827; train accuracy : 0.9927485362000061; \n",
      " validation loss : 0.5933664046559416; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5625274667080878; train accuracy : 0.9887115462065119; \n",
      " validation loss : 0.6036859187564695; validation accuracy : 0.9456066945606695\n",
      "Epoch 108:\t train loss : 0.5588168476405597; train accuracy : 0.9925530530685585; \n",
      " validation loss : 0.5934445896987295; validation accuracy : 0.9581589958158996\n",
      "Epoch 109:\t train loss : 0.5580013133948287; train accuracy : 0.9933371541869327; \n",
      " validation loss : 0.6169162559635394; validation accuracy : 0.9330543933054394\n",
      "Epoch 110:\t train loss : 0.5614709469500196; train accuracy : 0.9898423123392918; \n",
      " validation loss : 0.5977867870537007; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.5655391970291601; train accuracy : 0.9856445366956845; \n",
      " validation loss : 0.5935870440348078; validation accuracy : 0.9581589958158996\n",
      "Epoch 112:\t train loss : 0.5631492197633008; train accuracy : 0.9880764583785123; \n",
      " validation loss : 0.5955878469746997; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5648852347388255; train accuracy : 0.9863784503856997; \n",
      " validation loss : 0.6218184605741305; validation accuracy : 0.9288702928870293\n",
      "Epoch 114:\t train loss : 0.5596815115939648; train accuracy : 0.9917320858762663; \n",
      " validation loss : 0.6130194776202086; validation accuracy : 0.9372384937238494\n",
      "Epoch 115:\t train loss : 0.5627961783175316; train accuracy : 0.9885448743765296; \n",
      " validation loss : 0.6047355186912071; validation accuracy : 0.9414225941422594\n",
      "Epoch 116:\t train loss : 0.5594842820350675; train accuracy : 0.9919024752935345; \n",
      " validation loss : 0.6142404105428826; validation accuracy : 0.9372384937238494\n",
      "Epoch 117:\t train loss : 0.5592202671470095; train accuracy : 0.9920920722451129; \n",
      " validation loss : 0.6280107027667763; validation accuracy : 0.9246861924686193\n",
      "Epoch 118:\t train loss : 0.5607656762195155; train accuracy : 0.9906013197434864; \n",
      " validation loss : 0.6024423684155464; validation accuracy : 0.9497907949790795\n",
      "Epoch 119:\t train loss : 0.5590223557755356; train accuracy : 0.9924040397781839; \n",
      " validation loss : 0.6192359914823874; validation accuracy : 0.9330543933054394\n",
      "Epoch 120:\t train loss : 0.559233885685811; train accuracy : 0.992078750890672; \n",
      " validation loss : 0.5881100859050049; validation accuracy : 0.9623430962343096\n",
      "Epoch 121:\t train loss : 0.5623791414453756; train accuracy : 0.9888236934229685; \n",
      " validation loss : 0.612828333879512; validation accuracy : 0.9372384937238494\n",
      "Epoch 122:\t train loss : 0.5594059830991956; train accuracy : 0.9920397162241705; \n",
      " validation loss : 0.6106370198486782; validation accuracy : 0.9414225941422594\n",
      "Epoch 123:\t train loss : 0.562646987088387; train accuracy : 0.9886533040057003; \n",
      " validation loss : 0.6086620880839673; validation accuracy : 0.9456066945606695\n",
      "Epoch 124:\t train loss : 0.5618432373175746; train accuracy : 0.9893813315158462; \n",
      " validation loss : 0.6344643379514948; validation accuracy : 0.9163179916317992\n",
      "Epoch 125:\t train loss : 0.5575901366204893; train accuracy : 0.9938387186715821; \n",
      " validation loss : 0.6021655191394664; validation accuracy : 0.9497907949790795\n",
      "Epoch 126:\t train loss : 0.5604190931191781; train accuracy : 0.9908705350227702; \n",
      " validation loss : 0.61532886286547; validation accuracy : 0.9372384937238494\n",
      "Epoch 127:\t train loss : 0.5564427593398509; train accuracy : 0.9950255584125902; \n",
      " validation loss : 0.6114519217520208; validation accuracy : 0.9414225941422594\n",
      "Epoch 128:\t train loss : 0.5601319806476606; train accuracy : 0.9912054276774374; \n",
      " validation loss : 0.618054271010061; validation accuracy : 0.9330543933054394\n",
      "Epoch 129:\t train loss : 0.5588859282954084; train accuracy : 0.992454227206543; \n",
      " validation loss : 0.606230473253194; validation accuracy : 0.9456066945606695\n",
      "Epoch 130:\t train loss : 0.5767150704232757; train accuracy : 0.9743715728492208; \n",
      " validation loss : 0.6052321927248829; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 130\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5584577132940561; Train accuracy : 0.9929461879240373; \n",
      " Validation loss : 0.5875207351662696; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 16 ! ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t train loss : 0.936294880516642; train accuracy : 0.5992316986275907; \n",
      " validation loss : 0.8388639266105611; validation accuracy : 0.7112970711297071\n",
      "Epoch 2:\t train loss : 0.752842383756848; train accuracy : 0.7965023699618947; \n",
      " validation loss : 0.7394709788505304; validation accuracy : 0.799163179916318\n",
      "Epoch 3:\t train loss : 0.7052069386883342; train accuracy : 0.8451469995972614; \n",
      " validation loss : 0.7125125008826266; validation accuracy : 0.8451882845188284\n",
      "Epoch 4:\t train loss : 0.6771776188320201; train accuracy : 0.8732395675206791; \n",
      " validation loss : 0.6844096261512638; validation accuracy : 0.8619246861924686\n",
      "Epoch 5:\t train loss : 0.6660947666471585; train accuracy : 0.8840949223953654; \n",
      " validation loss : 0.6908469081115313; validation accuracy : 0.8661087866108786\n",
      "Epoch 6:\t train loss : 0.6396927706950137; train accuracy : 0.9114036989993495; \n",
      " validation loss : 0.6612886659441525; validation accuracy : 0.899581589958159\n",
      "Epoch 7:\t train loss : 0.6248131534605466; train accuracy : 0.9259022894141702; \n",
      " validation loss : 0.6449543906119105; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6175861351283869; train accuracy : 0.9332878961553952; \n",
      " validation loss : 0.6301591622441157; validation accuracy : 0.9288702928870293\n",
      "Epoch 9:\t train loss : 0.6075664999566948; train accuracy : 0.943628984788872; \n",
      " validation loss : 0.6296123880060583; validation accuracy : 0.9163179916317992\n",
      "Epoch 10:\t train loss : 0.6002148574332524; train accuracy : 0.951039375445336; \n",
      " validation loss : 0.6385071820373586; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.5968814565218653; train accuracy : 0.9541094829455683; \n",
      " validation loss : 0.6424143304516461; validation accuracy : 0.9079497907949791\n",
      "Epoch 12:\t train loss : 0.600027962372074; train accuracy : 0.9508813779856873; \n",
      " validation loss : 0.6204018588980045; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.5900660450503029; train accuracy : 0.9615260695808421; \n",
      " validation loss : 0.6277742707508248; validation accuracy : 0.9205020920502092\n",
      "Epoch 14:\t train loss : 0.5868718770495829; train accuracy : 0.9643328479816599; \n",
      " validation loss : 0.6449824512638783; validation accuracy : 0.9037656903765691\n",
      "Epoch 15:\t train loss : 0.5926230953203353; train accuracy : 0.9584435701229902; \n",
      " validation loss : 0.6161601390284208; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.5923249495898846; train accuracy : 0.9590043062052728; \n",
      " validation loss : 0.6413742639883313; validation accuracy : 0.9037656903765691\n",
      "Epoch 17:\t train loss : 0.5884852880544182; train accuracy : 0.9629263607918461; \n",
      " validation loss : 0.6470818081061318; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.5847943706224908; train accuracy : 0.9664363827875708; \n",
      " validation loss : 0.6057373282959878; validation accuracy : 0.9497907949790795\n",
      "Epoch 19:\t train loss : 0.592776898610935; train accuracy : 0.9581616530871464; \n",
      " validation loss : 0.6165498280364458; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5779097182250319; train accuracy : 0.9732457634994889; \n",
      " validation loss : 0.6149086572565857; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.579926411154844; train accuracy : 0.9715542612844263; \n",
      " validation loss : 0.6156764671011195; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5786310821482685; train accuracy : 0.9727810650887574; \n",
      " validation loss : 0.6302139622833235; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.5928505126407276; train accuracy : 0.9583940022925121; \n",
      " validation loss : 0.6410949251730854; validation accuracy : 0.9079497907949791\n",
      "Epoch 24:\t train loss : 0.5800720261306517; train accuracy : 0.9709501533504755; \n",
      " validation loss : 0.6112835070106983; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.575165020782268; train accuracy : 0.9759781901545896; \n",
      " validation loss : 0.6229594795190392; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5745451166676511; train accuracy : 0.9766256699402088; \n",
      " validation loss : 0.607528990788539; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5754053696170159; train accuracy : 0.9758604665572044; \n",
      " validation loss : 0.6331343694058744; validation accuracy : 0.9163179916317992\n",
      "Epoch 28:\t train loss : 0.5812315114236044; train accuracy : 0.9698441711329348; \n",
      " validation loss : 0.6056846995241592; validation accuracy : 0.9456066945606695\n",
      "Epoch 29:\t train loss : 0.5779571866842595; train accuracy : 0.9733108212769912; \n",
      " validation loss : 0.6282334438640063; validation accuracy : 0.9163179916317992\n",
      "Epoch 30:\t train loss : 0.5765958378443367; train accuracy : 0.9746150748164442; \n",
      " validation loss : 0.652581032205261; validation accuracy : 0.899581589958159\n",
      "Epoch 31:\t train loss : 0.5753320224481505; train accuracy : 0.975919328355897; \n",
      " validation loss : 0.6171083417087136; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5721960716241191; train accuracy : 0.9788748102481489; \n",
      " validation loss : 0.6021039815923157; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.5686749675751636; train accuracy : 0.9827101211313858; \n",
      " validation loss : 0.6223061150888342; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.5674811411436578; train accuracy : 0.9840236686390532; \n",
      " validation loss : 0.6081523855607754; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5787596892340956; train accuracy : 0.9721955450912357; \n",
      " validation loss : 0.6205098871451262; validation accuracy : 0.9330543933054394\n",
      "Epoch 36:\t train loss : 0.5734039204996776; train accuracy : 0.9775426748040522; \n",
      " validation loss : 0.6114739309639998; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.587686775254871; train accuracy : 0.9631927878806654; \n",
      " validation loss : 0.6516766449335613; validation accuracy : 0.895397489539749\n",
      "Epoch 38:\t train loss : 0.5789915309936103; train accuracy : 0.9718082964156263; \n",
      " validation loss : 0.6232538261930071; validation accuracy : 0.9246861924686193\n",
      "Epoch 39:\t train loss : 0.5714762553938644; train accuracy : 0.979698875429846; \n",
      " validation loss : 0.6214414559143528; validation accuracy : 0.9288702928870293\n",
      "Epoch 40:\t train loss : 0.5664043270814387; train accuracy : 0.9849158895876576; \n",
      " validation loss : 0.619292069049595; validation accuracy : 0.9288702928870293\n",
      "Epoch 41:\t train loss : 0.5752775086769445; train accuracy : 0.9757613308962483; \n",
      " validation loss : 0.6329678661660949; validation accuracy : 0.9205020920502092\n",
      "Epoch 42:\t train loss : 0.5779100169638957; train accuracy : 0.9729731404318597; \n",
      " validation loss : 0.6345828027989588; validation accuracy : 0.9205020920502092\n",
      "Epoch 43:\t train loss : 0.5741550464796361; train accuracy : 0.9769168809442672; \n",
      " validation loss : 0.6322255390549869; validation accuracy : 0.9163179916317992\n",
      "Epoch 44:\t train loss : 0.5642186754307295; train accuracy : 0.9872703615353635; \n",
      " validation loss : 0.5971734190516714; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5651043448750444; train accuracy : 0.9861891632330617; \n",
      " validation loss : 0.6022664002313435; validation accuracy : 0.9497907949790795\n",
      "Epoch 46:\t train loss : 0.5667280126982688; train accuracy : 0.984531738901453; \n",
      " validation loss : 0.6038745136556762; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5697553114893863; train accuracy : 0.981300535952167; \n",
      " validation loss : 0.625896748762587; validation accuracy : 0.9246861924686193\n",
      "Epoch 48:\t train loss : 0.5748613307666592; train accuracy : 0.9761175996778091; \n",
      " validation loss : 0.6422999342462139; validation accuracy : 0.9079497907949791\n",
      "Epoch 49:\t train loss : 0.5903086857233835; train accuracy : 0.9602404039778184; \n",
      " validation loss : 0.6114812289590421; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.571925546388373; train accuracy : 0.9789832398773196; \n",
      " validation loss : 0.6230690104655351; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.5686244336202002; train accuracy : 0.9825397317141176; \n",
      " validation loss : 0.6308304344978324; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:\t train loss : 0.5668523279838675; train accuracy : 0.9845782087425261; \n",
      " validation loss : 0.5929368767648512; validation accuracy : 0.9539748953974896\n",
      "Epoch 53:\t train loss : 0.5656059009965677; train accuracy : 0.9856377211189937; \n",
      " validation loss : 0.6028289788032775; validation accuracy : 0.9456066945606695\n",
      "Epoch 54:\t train loss : 0.5644834765008304; train accuracy : 0.9866910375166517; \n",
      " validation loss : 0.597706506050908; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5667163246847781; train accuracy : 0.9845720127637163; \n",
      " validation loss : 0.5935338044435152; validation accuracy : 0.9539748953974896\n",
      "Epoch 56:\t train loss : 0.5658772420329824; train accuracy : 0.9852287865175501; \n",
      " validation loss : 0.6283587003188721; validation accuracy : 0.9246861924686193\n",
      "Epoch 57:\t train loss : 0.56899751556158; train accuracy : 0.9822206388054153; \n",
      " validation loss : 0.6223803995379721; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.5623792525821445; train accuracy : 0.9889463738034016; \n",
      " validation loss : 0.6078098272398202; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5648908607123614; train accuracy : 0.9863130828092568; \n",
      " validation loss : 0.6010166638623947; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5631304672042146; train accuracy : 0.9882772080919483; \n",
      " validation loss : 0.5997305774211505; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5647056223372919; train accuracy : 0.9866011958239103; \n",
      " validation loss : 0.6104878993701724; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5641178221958453; train accuracy : 0.9871433439697637; \n",
      " validation loss : 0.5996867274763037; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5625388204589613; train accuracy : 0.9886303788841042; \n",
      " validation loss : 0.5908788913596841; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.5617129162578575; train accuracy : 0.9895287958115183; \n",
      " validation loss : 0.6044946696726201; validation accuracy : 0.9497907949790795\n",
      "Epoch 65:\t train loss : 0.5623819676120714; train accuracy : 0.9889277858669724; \n",
      " validation loss : 0.6238759545626936; validation accuracy : 0.9246861924686193\n",
      "Epoch 66:\t train loss : 0.5696155010170495; train accuracy : 0.9814616314012206; \n",
      " validation loss : 0.6215304250982068; validation accuracy : 0.9288702928870293\n",
      "Epoch 67:\t train loss : 0.5666781922046396; train accuracy : 0.9847083242975309; \n",
      " validation loss : 0.6117434117342235; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5603471366209573; train accuracy : 0.9909662628953809; \n",
      " validation loss : 0.6245260401771688; validation accuracy : 0.9246861924686193\n",
      "Epoch 69:\t train loss : 0.5625922248160887; train accuracy : 0.9886117909476749; \n",
      " validation loss : 0.6091312335202632; validation accuracy : 0.9372384937238494\n",
      "Epoch 70:\t train loss : 0.5644120465415154; train accuracy : 0.9867622912729639; \n",
      " validation loss : 0.6007105589676274; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5677582397183787; train accuracy : 0.9833483069487903; \n",
      " validation loss : 0.6172380488047873; validation accuracy : 0.9330543933054394\n",
      "Epoch 72:\t train loss : 0.562434226947854; train accuracy : 0.9887388085132749; \n",
      " validation loss : 0.6349329744046045; validation accuracy : 0.9121338912133892\n",
      "Epoch 73:\t train loss : 0.564864591995488; train accuracy : 0.9863533566715201; \n",
      " validation loss : 0.6271108477648274; validation accuracy : 0.9205020920502092\n",
      "Epoch 74:\t train loss : 0.6218517643270374; train accuracy : 0.9280058242200812; \n",
      " validation loss : 0.6150616633947181; validation accuracy : 0.9330543933054394\n",
      "Epoch 75:\t train loss : 0.588529518070156; train accuracy : 0.962052727779671; \n",
      " validation loss : 0.6076453838899962; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.576685072007926; train accuracy : 0.9743393537594102; \n",
      " validation loss : 0.65036008861916; validation accuracy : 0.899581589958159\n",
      "Epoch 77:\t train loss : 0.5903904108150512; train accuracy : 0.9602961677871061; \n",
      " validation loss : 0.6035804989469012; validation accuracy : 0.9456066945606695\n",
      "Epoch 78:\t train loss : 0.5721486068542923; train accuracy : 0.97872300876731; \n",
      " validation loss : 0.6077575914317811; validation accuracy : 0.9414225941422594\n",
      "Epoch 79:\t train loss : 0.5702053621578055; train accuracy : 0.9812478701322842; \n",
      " validation loss : 0.6384385751010276; validation accuracy : 0.9121338912133892\n",
      "Epoch 80:\t train loss : 0.5694552332731977; train accuracy : 0.9818148021933765; \n",
      " validation loss : 0.6327691258184209; validation accuracy : 0.9163179916317992\n",
      "Epoch 81:\t train loss : 0.5695301066098024; train accuracy : 0.981650608754918; \n",
      " validation loss : 0.6185465133672194; validation accuracy : 0.9330543933054394\n",
      "Epoch 82:\t train loss : 0.5691370491265565; train accuracy : 0.9819820936212398; \n",
      " validation loss : 0.6367604446244459; validation accuracy : 0.9121338912133892\n",
      "Epoch 83:\t train loss : 0.5675781623829247; train accuracy : 0.983655007899873; \n",
      " validation loss : 0.6000959172053051; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.566880228481493; train accuracy : 0.9844016233464482; \n",
      " validation loss : 0.5944902929578203; validation accuracy : 0.9539748953974896\n",
      "Epoch 85:\t train loss : 0.5649609317665563; train accuracy : 0.986334768735091; \n",
      " validation loss : 0.5886656308626815; validation accuracy : 0.9623430962343096\n",
      "Epoch 86:\t train loss : 0.5631246845060642; train accuracy : 0.9882710121131386; \n",
      " validation loss : 0.5944356475545878; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5651869009869478; train accuracy : 0.9861488893707984; \n",
      " validation loss : 0.5909003199573696; validation accuracy : 0.9623430962343096\n",
      "Epoch 88:\t train loss : 0.5650960715529841; train accuracy : 0.9861736732860373; \n",
      " validation loss : 0.5764699021864411; validation accuracy : 0.9748953974895398\n",
      "Epoch 89:\t train loss : 0.5660302898882839; train accuracy : 0.9852225905387404; \n",
      " validation loss : 0.5843064284443837; validation accuracy : 0.9665271966527197\n",
      "Epoch 90:\t train loss : 0.5650468110257529; train accuracy : 0.9859723039747205; \n",
      " validation loss : 0.614216482852554; validation accuracy : 0.9372384937238494\n",
      "Epoch 91:\t train loss : 0.5642525808876959; train accuracy : 0.987134050001549; \n",
      " validation loss : 0.6053655160658855; validation accuracy : 0.9414225941422594\n",
      "Epoch 92:\t train loss : 0.5631972236876254; train accuracy : 0.988159484494563; \n",
      " validation loss : 0.6073382042052857; validation accuracy : 0.9414225941422594\n",
      "Epoch 93:\t train loss : 0.5662116632758638; train accuracy : 0.9850738870473063; \n",
      " validation loss : 0.5959647760975525; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5648295606109319; train accuracy : 0.986433904396047; \n",
      " validation loss : 0.6014291292280834; validation accuracy : 0.9497907949790795\n",
      "Epoch 95:\t train loss : 0.5674410531273545; train accuracy : 0.9837572415502339; \n",
      " validation loss : 0.6160944441589143; validation accuracy : 0.9330543933054394\n",
      "Epoch 96:\t train loss : 0.5632259789121383; train accuracy : 0.9881718764521825; \n",
      " validation loss : 0.5914776887211294; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5639854936324477; train accuracy : 0.9873509092598903; \n",
      " validation loss : 0.5978814512174023; validation accuracy : 0.9539748953974896\n",
      "Epoch 98:\t train loss : 0.56103626685721; train accuracy : 0.9903156851203568; \n",
      " validation loss : 0.5849651994609097; validation accuracy : 0.9665271966527197\n",
      "Epoch 99:\t train loss : 0.5621022972220419; train accuracy : 0.9892158988816259; \n",
      " validation loss : 0.5956116158721186; validation accuracy : 0.9581589958158996\n",
      "Epoch 100:\t train loss : 0.5629820172407953; train accuracy : 0.9882617181449239; \n",
      " validation loss : 0.5862258575330076; validation accuracy : 0.9665271966527197\n",
      "Epoch 101:\t train loss : 0.563055750903942; train accuracy : 0.9881873663992069; \n",
      " validation loss : 0.6034639841022107; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5648822647078551; train accuracy : 0.9863812385761641; \n",
      " validation loss : 0.5920968162866616; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103:\t train loss : 0.5616079508920787; train accuracy : 0.9897580470274792; \n",
      " validation loss : 0.5851359568675795; validation accuracy : 0.9665271966527197\n",
      "Epoch 104:\t train loss : 0.560365042038201; train accuracy : 0.9909662628953809; \n",
      " validation loss : 0.623747073545387; validation accuracy : 0.9246861924686193\n",
      "Epoch 105:\t train loss : 0.5655716544626977; train accuracy : 0.9857182688435205; \n",
      " validation loss : 0.5831244150781626; validation accuracy : 0.9707112970711297\n",
      "Epoch 106:\t train loss : 0.5665487720285495; train accuracy : 0.984655658477648; \n",
      " validation loss : 0.6092480843975916; validation accuracy : 0.9372384937238494\n",
      "Epoch 107:\t train loss : 0.565251290937055; train accuracy : 0.9861055175191301; \n",
      " validation loss : 0.6193596994399748; validation accuracy : 0.9330543933054394\n",
      "Epoch 108:\t train loss : 0.5715758172798073; train accuracy : 0.979525388023173; \n",
      " validation loss : 0.6269108120278358; validation accuracy : 0.9246861924686193\n",
      "Epoch 109:\t train loss : 0.5625554838533942; train accuracy : 0.9887388085132749; \n",
      " validation loss : 0.6146986179704541; validation accuracy : 0.9372384937238494\n",
      "Epoch 110:\t train loss : 0.5629828969538213; train accuracy : 0.9882896000495678; \n",
      " validation loss : 0.6040675302151506; validation accuracy : 0.9456066945606695\n",
      "Epoch 111:\t train loss : 0.5636476594952633; train accuracy : 0.9874965147619195; \n",
      " validation loss : 0.6100520613671531; validation accuracy : 0.9372384937238494\n",
      "Epoch 112:\t train loss : 0.5624577565343354; train accuracy : 0.9886427708417237; \n",
      " validation loss : 0.603314149482908; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5623304481372641; train accuracy : 0.9889835496762601; \n",
      " validation loss : 0.596962887098995; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5624382216645232; train accuracy : 0.9888317481954212; \n",
      " validation loss : 0.5952658030632616; validation accuracy : 0.9539748953974896\n",
      "Epoch 115:\t train loss : 0.5616751197082097; train accuracy : 0.9896341274512841; \n",
      " validation loss : 0.5954914494216276; validation accuracy : 0.9581589958158996\n",
      "Epoch 116:\t train loss : 0.5588760162642692; train accuracy : 0.9925493354812727; \n",
      " validation loss : 0.5927714280716623; validation accuracy : 0.9581589958158996\n",
      "Epoch 117:\t train loss : 0.5601224726949672; train accuracy : 0.9912512779206295; \n",
      " validation loss : 0.6013936290359655; validation accuracy : 0.9456066945606695\n",
      "Epoch 118:\t train loss : 0.577288825641541; train accuracy : 0.9737321478360544; \n",
      " validation loss : 0.6221806786799765; validation accuracy : 0.9288702928870293\n",
      "Epoch 119:\t train loss : 0.5677021348359674; train accuracy : 0.983329719012361; \n",
      " validation loss : 0.6212058599611179; validation accuracy : 0.9330543933054394\n",
      "Epoch 120:\t train loss : 0.5627362151654852; train accuracy : 0.9885591251277921; \n",
      " validation loss : 0.6088978816014958; validation accuracy : 0.9414225941422594\n",
      "Epoch 121:\t train loss : 0.5615934920102206; train accuracy : 0.989764243006289; \n",
      " validation loss : 0.6068894084373223; validation accuracy : 0.9414225941422594\n",
      "Epoch 122:\t train loss : 0.5630873212707321; train accuracy : 0.9881408965581338; \n",
      " validation loss : 0.5933900531672878; validation accuracy : 0.9581589958158996\n",
      "Epoch 123:\t train loss : 0.5604177206060215; train accuracy : 0.9909910468106199; \n",
      " validation loss : 0.6140698394101253; validation accuracy : 0.9372384937238494\n",
      "Epoch 124:\t train loss : 0.5626631241468203; train accuracy : 0.9886985346510115; \n",
      " validation loss : 0.5894429369198555; validation accuracy : 0.9623430962343096\n",
      "Epoch 125:\t train loss : 0.5615302560120982; train accuracy : 0.9898664766566498; \n",
      " validation loss : 0.5935593669634627; validation accuracy : 0.9581589958158996\n",
      "Epoch 126:\t train loss : 0.5619972504167261; train accuracy : 0.9892778586697234; \n",
      " validation loss : 0.6011022939034458; validation accuracy : 0.9497907949790795\n",
      "Epoch 127:\t train loss : 0.5604101145568616; train accuracy : 0.9907958734781127; \n",
      " validation loss : 0.6172453726323273; validation accuracy : 0.9288702928870293\n",
      "Epoch 128:\t train loss : 0.5605348726213089; train accuracy : 0.9907989714675176; \n",
      " validation loss : 0.602138527960106; validation accuracy : 0.9497907949790795\n",
      "Epoch 129:\t train loss : 0.5617054278676177; train accuracy : 0.9896062455466402; \n",
      " validation loss : 0.6035932631548641; validation accuracy : 0.9456066945606695\n",
      "Epoch 130:\t train loss : 0.5589722333003864; train accuracy : 0.9924254159050776; \n",
      " validation loss : 0.5850063032043074; validation accuracy : 0.9665271966527197\n",
      "Epoch 131:\t train loss : 0.5621851133363819; train accuracy : 0.9890764893584064; \n",
      " validation loss : 0.6005613699338987; validation accuracy : 0.9497907949790795\n",
      "Epoch 132:\t train loss : 0.5629063518462926; train accuracy : 0.9883484618482605; \n",
      " validation loss : 0.6288420136810562; validation accuracy : 0.9205020920502092\n",
      "Epoch 133:\t train loss : 0.5769137443407046; train accuracy : 0.9740295548189225; \n",
      " validation loss : 0.589801206148595; validation accuracy : 0.9623430962343096\n",
      "Epoch 134:\t train loss : 0.5633900812972978; train accuracy : 0.9878868614269339; \n",
      " validation loss : 0.6143983090094026; validation accuracy : 0.9372384937238494\n",
      "Epoch 135:\t train loss : 0.559877946711365; train accuracy : 0.9913720995074197; \n",
      " validation loss : 0.6054284840830723; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.559679338260724; train accuracy : 0.991688094426717; \n",
      " validation loss : 0.6086441977319659; validation accuracy : 0.9414225941422594\n",
      "Epoch 137:\t train loss : 0.5602848763397799; train accuracy : 0.9909693608847858; \n",
      " validation loss : 0.6133461947244013; validation accuracy : 0.9372384937238494\n",
      "Epoch 138:\t train loss : 0.5604732345182242; train accuracy : 0.990814461414542; \n",
      " validation loss : 0.5941432971541176; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 138\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5650960715529841; Train accuracy : 0.9861736732860373; \n",
      " Validation loss : 0.5764699021864411; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 17 ! ---\n",
      "Epoch 1:\t train loss : 0.9322809595550847; train accuracy : 0.599960655534558; \n",
      " validation loss : 0.8051150926096452; validation accuracy : 0.7531380753138075\n",
      "Epoch 2:\t train loss : 0.7393415684055861; train accuracy : 0.8111416090956969; \n",
      " validation loss : 0.7218425077777996; validation accuracy : 0.8284518828451883\n",
      "Epoch 3:\t train loss : 0.6990668392250015; train accuracy : 0.8513284178568109; \n",
      " validation loss : 0.6908067809511019; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.6817307544819514; train accuracy : 0.8687508906719539; \n",
      " validation loss : 0.681237157921266; validation accuracy : 0.8786610878661087\n",
      "Epoch 5:\t train loss : 0.6666459699185678; train accuracy : 0.8832649710337991; \n",
      " validation loss : 0.6914181958974012; validation accuracy : 0.8535564853556485\n",
      "Epoch 6:\t train loss : 0.6528268608461253; train accuracy : 0.8980947365160011; \n",
      " validation loss : 0.6949076985650345; validation accuracy : 0.8535564853556485\n",
      "Epoch 7:\t train loss : 0.6371858411218735; train accuracy : 0.913317636853682; \n",
      " validation loss : 0.6716177841318737; validation accuracy : 0.8744769874476988\n",
      "Epoch 8:\t train loss : 0.6273200248199053; train accuracy : 0.9234945320487004; \n",
      " validation loss : 0.6756809786078022; validation accuracy : 0.8744769874476988\n",
      "Epoch 9:\t train loss : 0.6134954946294254; train accuracy : 0.9379001827813749; \n",
      " validation loss : 0.6305362906052071; validation accuracy : 0.9121338912133892\n",
      "Epoch 10:\t train loss : 0.6011963462140684; train accuracy : 0.9506254840608445; \n",
      " validation loss : 0.627292767293571; validation accuracy : 0.9205020920502092\n",
      "Epoch 11:\t train loss : 0.5916911759879303; train accuracy : 0.9600065057777503; \n",
      " validation loss : 0.6446057804336798; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.5970025370583009; train accuracy : 0.9539322779516094; \n",
      " validation loss : 0.6524467902445217; validation accuracy : 0.891213389121339\n",
      "Epoch 13:\t train loss : 0.5854862138917183; train accuracy : 0.9659022894141702; \n",
      " validation loss : 0.6218940420763021; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\t train loss : 0.5805355447908163; train accuracy : 0.9710663279531584; \n",
      " validation loss : 0.6333454896893546; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5866047755729048; train accuracy : 0.9648025031754391; \n",
      " validation loss : 0.6406765531175359; validation accuracy : 0.9037656903765691\n",
      "Epoch 16:\t train loss : 0.5829788696752287; train accuracy : 0.9683091173828186; \n",
      " validation loss : 0.7792903513505415; validation accuracy : 0.7615062761506276\n",
      "Epoch 17:\t train loss : 0.5886170625139371; train accuracy : 0.9628293937234734; \n",
      " validation loss : 0.6169686338632272; validation accuracy : 0.9372384937238494\n",
      "Epoch 18:\t train loss : 0.5820066595296385; train accuracy : 0.9693934136745253; \n",
      " validation loss : 0.6495824521913335; validation accuracy : 0.899581589958159\n",
      "Epoch 19:\t train loss : 0.5812363496683924; train accuracy : 0.9700071253756312; \n",
      " validation loss : 0.6434170650506521; validation accuracy : 0.899581589958159\n",
      "Epoch 20:\t train loss : 0.5777019988241514; train accuracy : 0.9734945320487004; \n",
      " validation loss : 0.6225056689420998; validation accuracy : 0.9288702928870293\n",
      "Epoch 21:\t train loss : 0.5732996375540674; train accuracy : 0.9779770129186158; \n",
      " validation loss : 0.612440041225081; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5720977448031374; train accuracy : 0.9793187521298677; \n",
      " validation loss : 0.59383518021176; validation accuracy : 0.9581589958158996\n",
      "Epoch 23:\t train loss : 0.5742447152840315; train accuracy : 0.9771036897053812; \n",
      " validation loss : 0.6200782420640515; validation accuracy : 0.9288702928870293\n",
      "Epoch 24:\t train loss : 0.569759809312751; train accuracy : 0.9815530220886645; \n",
      " validation loss : 0.617681625792108; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5675439989232456; train accuracy : 0.9842910251246941; \n",
      " validation loss : 0.6209421580901471; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5692229909450763; train accuracy : 0.9821128287741256; \n",
      " validation loss : 0.5893245843626733; validation accuracy : 0.9665271966527197\n",
      "Epoch 27:\t train loss : 0.5711579647380216; train accuracy : 0.98002540351312; \n",
      " validation loss : 0.6193291567878311; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.5719751792406755; train accuracy : 0.9791889463738034; \n",
      " validation loss : 0.605281979458543; validation accuracy : 0.9456066945606695\n",
      "Epoch 29:\t train loss : 0.5682348659031762; train accuracy : 0.9831196753307103; \n",
      " validation loss : 0.6120670890442445; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5677333035761135; train accuracy : 0.98364044734967; \n",
      " validation loss : 0.6080624256376422; validation accuracy : 0.9372384937238494\n",
      "Epoch 31:\t train loss : 0.5771265565576552; train accuracy : 0.9739570618668484; \n",
      " validation loss : 0.6204227962980842; validation accuracy : 0.9330543933054394\n",
      "Epoch 32:\t train loss : 0.575066767992993; train accuracy : 0.975994299699495; \n",
      " validation loss : 0.616134192008801; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5701154530917183; train accuracy : 0.9812704854549398; \n",
      " validation loss : 0.6122447914459372; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5666946935956243; train accuracy : 0.9846222001920754; \n",
      " validation loss : 0.5912822537749755; validation accuracy : 0.9623430962343096\n",
      "Epoch 35:\t train loss : 0.5635060916444967; train accuracy : 0.9878323368134081; \n",
      " validation loss : 0.6102741644354184; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.565942906145931; train accuracy : 0.9852396294804672; \n",
      " validation loss : 0.6129948407448209; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.566080067251244; train accuracy : 0.9849939589206606; \n",
      " validation loss : 0.6255806245598992; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.568393890194612; train accuracy : 0.9825871309520121; \n",
      " validation loss : 0.6373987407788955; validation accuracy : 0.9121338912133892\n",
      "Epoch 39:\t train loss : 0.5668622804234728; train accuracy : 0.9844827906688559; \n",
      " validation loss : 0.5985377679372506; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5678927470059896; train accuracy : 0.9831971250658322; \n",
      " validation loss : 0.5917990602525545; validation accuracy : 0.9623430962343096\n",
      "Epoch 41:\t train loss : 0.5685596808168578; train accuracy : 0.9826122246661917; \n",
      " validation loss : 0.6252809206955515; validation accuracy : 0.9205020920502092\n",
      "Epoch 42:\t train loss : 0.5655551875248823; train accuracy : 0.9856851203568884; \n",
      " validation loss : 0.6211836587225321; validation accuracy : 0.9246861924686193\n",
      "Epoch 43:\t train loss : 0.570909841426339; train accuracy : 0.9802946187924038; \n",
      " validation loss : 0.6200273860830761; validation accuracy : 0.9288702928870293\n",
      "Epoch 44:\t train loss : 0.5645128043102253; train accuracy : 0.9868217726695375; \n",
      " validation loss : 0.5931724373955113; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.562999672812001; train accuracy : 0.9882623377428049; \n",
      " validation loss : 0.6173304413133994; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5660900199961179; train accuracy : 0.985179838284953; \n",
      " validation loss : 0.6277627222615318; validation accuracy : 0.9163179916317992\n",
      "Epoch 47:\t train loss : 0.5652332723735302; train accuracy : 0.9859233557421233; \n",
      " validation loss : 0.6044221638359659; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5704654181398335; train accuracy : 0.9805793240187118; \n",
      " validation loss : 0.636508204924688; validation accuracy : 0.9163179916317992\n",
      "Epoch 49:\t train loss : 0.565701490583079; train accuracy : 0.9854719786858329; \n",
      " validation loss : 0.6079517265917546; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5623734796204255; train accuracy : 0.9887425261005607; \n",
      " validation loss : 0.6008483582295271; validation accuracy : 0.9539748953974896\n",
      "Epoch 51:\t train loss : 0.5614421959445933; train accuracy : 0.9899507419684624; \n",
      " validation loss : 0.6189035479261161; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5625450083348278; train accuracy : 0.9886031165773413; \n",
      " validation loss : 0.6199514402932429; validation accuracy : 0.9288702928870293\n",
      "Epoch 53:\t train loss : 0.5639201785780414; train accuracy : 0.9874007868893089; \n",
      " validation loss : 0.6159465276325654; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5657469113845618; train accuracy : 0.9854837510455714; \n",
      " validation loss : 0.631836274960157; validation accuracy : 0.9205020920502092\n",
      "Epoch 55:\t train loss : 0.5680326736868174; train accuracy : 0.9830555469500294; \n",
      " validation loss : 0.6385235407680946; validation accuracy : 0.9079497907949791\n",
      "Epoch 56:\t train loss : 0.5757337124585743; train accuracy : 0.9751947086340965; \n",
      " validation loss : 0.6019089788951265; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.563145258956746; train accuracy : 0.9880491960717495; \n",
      " validation loss : 0.6059500604506288; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5601602771872947; train accuracy : 0.9911338641221847; \n",
      " validation loss : 0.6211863877653252; validation accuracy : 0.9288702928870293\n",
      "Epoch 59:\t train loss : 0.5610464115360533; train accuracy : 0.9902915208029989; \n",
      " validation loss : 0.6049967955934831; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5588686246812516; train accuracy : 0.9924697171535674; \n",
      " validation loss : 0.6115983740060659; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5652898703072073; train accuracy : 0.9856659128225781; \n",
      " validation loss : 0.6111964148213682; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5573462767508602; train accuracy : 0.9940710678769479; \n",
      " validation loss : 0.5845093382282143; validation accuracy : 0.9665271966527197\n",
      "Epoch 63:\t train loss : 0.5622060733084515; train accuracy : 0.9889652715387713; \n",
      " validation loss : 0.6019259133436595; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5635541133541841; train accuracy : 0.9877511694910004; \n",
      " validation loss : 0.5967284888106491; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:\t train loss : 0.5634636592729257; train accuracy : 0.9878905790142197; \n",
      " validation loss : 0.6139477787858754; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.5609792062222513; train accuracy : 0.9902391647820564; \n",
      " validation loss : 0.6219424347379751; validation accuracy : 0.9288702928870293\n",
      "Epoch 67:\t train loss : 0.5599097124906849; train accuracy : 0.9915093404380557; \n",
      " validation loss : 0.6173714023907486; validation accuracy : 0.9330543933054394\n",
      "Epoch 68:\t train loss : 0.5581075671169318; train accuracy : 0.9932965705257288; \n",
      " validation loss : 0.6122539770136203; validation accuracy : 0.9414225941422594\n",
      "Epoch 69:\t train loss : 0.5610325469228007; train accuracy : 0.9902819170358438; \n",
      " validation loss : 0.6339553908051373; validation accuracy : 0.9205020920502092\n",
      "Epoch 70:\t train loss : 0.5662522677457206; train accuracy : 0.9848892468787757; \n",
      " validation loss : 0.6338334912810936; validation accuracy : 0.9163179916317992\n",
      "Epoch 71:\t train loss : 0.5656870941022859; train accuracy : 0.9854741472784163; \n",
      " validation loss : 0.6235887002073234; validation accuracy : 0.9246861924686193\n",
      "Epoch 72:\t train loss : 0.5622194741721455; train accuracy : 0.9889652715387713; \n",
      " validation loss : 0.6067628440869822; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5599194934371992; train accuracy : 0.9913699309148363; \n",
      " validation loss : 0.5918112371007543; validation accuracy : 0.9581589958158996\n",
      "Epoch 74:\t train loss : 0.5727365602014333; train accuracy : 0.9783177917531523; \n",
      " validation loss : 0.6059520848093654; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5645109711524999; train accuracy : 0.9867694166485951; \n",
      " validation loss : 0.6068537540494424; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5593385887857971; train accuracy : 0.9920167911025745; \n",
      " validation loss : 0.5984595761357963; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5587124329428546; train accuracy : 0.992527959354379; \n",
      " validation loss : 0.6019609727796482; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5569997436869089; train accuracy : 0.9943247932092072; \n",
      " validation loss : 0.6022152055637213; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5617616754566508; train accuracy : 0.9894005390501565; \n",
      " validation loss : 0.6631372509370118; validation accuracy : 0.8870292887029289\n",
      "Epoch 80:\t train loss : 0.5915426712026767; train accuracy : 0.9591567272839927; \n",
      " validation loss : 0.6144399363165802; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.5627990945486635; train accuracy : 0.9882446792031971; \n",
      " validation loss : 0.6169445738197373; validation accuracy : 0.9330543933054394\n",
      "Epoch 82:\t train loss : 0.561357393405447; train accuracy : 0.9898946683602342; \n",
      " validation loss : 0.6100364674152917; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5568229741369604; train accuracy : 0.9944487127854023; \n",
      " validation loss : 0.5965583190122614; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5592827894418629; train accuracy : 0.9920205086898602; \n",
      " validation loss : 0.625668162348504; validation accuracy : 0.9246861924686193\n",
      "Epoch 85:\t train loss : 0.5602817599639685; train accuracy : 0.9909944545989653; \n",
      " validation loss : 0.6158667201375415; validation accuracy : 0.9330543933054394\n",
      "Epoch 86:\t train loss : 0.5555356583345034; train accuracy : 0.9958155457108336; \n",
      " validation loss : 0.6169950803386924; validation accuracy : 0.9330543933054394\n",
      "Epoch 87:\t train loss : 0.5572361065227874; train accuracy : 0.9940149942687196; \n",
      " validation loss : 0.6004119686732611; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5586944822919947; train accuracy : 0.9926630316924316; \n",
      " validation loss : 0.6125605200847961; validation accuracy : 0.9414225941422594\n",
      "Epoch 89:\t train loss : 0.5668688787025311; train accuracy : 0.9843492673255058; \n",
      " validation loss : 0.6119197284553324; validation accuracy : 0.9414225941422594\n",
      "Epoch 90:\t train loss : 0.5607285272501439; train accuracy : 0.9905452461352582; \n",
      " validation loss : 0.6041993581618211; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5585999709961145; train accuracy : 0.992816382167973; \n",
      " validation loss : 0.6558269283812647; validation accuracy : 0.895397489539749\n",
      "Epoch 92:\t train loss : 0.5581888557966005; train accuracy : 0.9930893150345426; \n",
      " validation loss : 0.607401313812103; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5627311214678675; train accuracy : 0.9886031165773413; \n",
      " validation loss : 0.622560796822025; validation accuracy : 0.9288702928870293\n",
      "Epoch 94:\t train loss : 0.5582512879597045; train accuracy : 0.9930679389076489; \n",
      " validation loss : 0.5945235225114076; validation accuracy : 0.9539748953974896\n",
      "Epoch 95:\t train loss : 0.5612560192787094; train accuracy : 0.9899603457356175; \n",
      " validation loss : 0.6374495144092502; validation accuracy : 0.9121338912133892\n",
      "Epoch 96:\t train loss : 0.5865866161176725; train accuracy : 0.9642838997490628; \n",
      " validation loss : 0.6234071242245712; validation accuracy : 0.9288702928870293\n",
      "Epoch 97:\t train loss : 0.5620757581632246; train accuracy : 0.9891666408500883; \n",
      " validation loss : 0.6136801891179814; validation accuracy : 0.9372384937238494\n",
      "Epoch 98:\t train loss : 0.5579857566830592; train accuracy : 0.9934050001548994; \n",
      " validation loss : 0.5876929594779968; validation accuracy : 0.9623430962343096\n",
      "Epoch 99:\t train loss : 0.5579970116481865; train accuracy : 0.9933275504197776; \n",
      " validation loss : 0.6154611221173036; validation accuracy : 0.9372384937238494\n",
      "Epoch 100:\t train loss : 0.558565198393948; train accuracy : 0.9928997180829642; \n",
      " validation loss : 0.6061445881416122; validation accuracy : 0.9456066945606695\n",
      "Epoch 101:\t train loss : 0.5582052376053704; train accuracy : 0.9930642213203631; \n",
      " validation loss : 0.6056998824810568; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5600108169129789; train accuracy : 0.9912983673595837; \n",
      " validation loss : 0.6055503364817094; validation accuracy : 0.9456066945606695\n",
      "Epoch 103:\t train loss : 0.5589212266413535; train accuracy : 0.9923420799900864; \n",
      " validation loss : 0.5936336765326792; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.5573908058991582; train accuracy : 0.9939006784596797; \n",
      " validation loss : 0.601316721912011; validation accuracy : 0.9497907949790795\n",
      "Epoch 105:\t train loss : 0.5569477252354157; train accuracy : 0.9944583165525573; \n",
      " validation loss : 0.605488828963468; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.559713973267644; train accuracy : 0.9914997366709005; \n",
      " validation loss : 0.6110060173244278; validation accuracy : 0.9414225941422594\n",
      "Epoch 107:\t train loss : 0.5605864413264107; train accuracy : 0.9907466154465752; \n",
      " validation loss : 0.6058207979803781; validation accuracy : 0.9456066945606695\n",
      "Epoch 108:\t train loss : 0.5619925064030588; train accuracy : 0.9892227144583166; \n",
      " validation loss : 0.6195502031388094; validation accuracy : 0.9288702928870293\n",
      "Epoch 109:\t train loss : 0.5639817126442704; train accuracy : 0.987222342699588; \n",
      " validation loss : 0.6215471979780558; validation accuracy : 0.9288702928870293\n",
      "Epoch 110:\t train loss : 0.571208620751612; train accuracy : 0.9798454103286967; \n",
      " validation loss : 0.6132809053310215; validation accuracy : 0.9330543933054394\n",
      "Epoch 111:\t train loss : 0.5596743728372453; train accuracy : 0.9915462065119737; \n",
      " validation loss : 0.6219962577684819; validation accuracy : 0.9288702928870293\n",
      "Epoch 112:\t train loss : 0.5573704334956602; train accuracy : 0.993916168406704; \n",
      " validation loss : 0.6155986662256385; validation accuracy : 0.9372384937238494\n",
      "Early stopping at epoch 112\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5573462767508602; Train accuracy : 0.9940710678769479; \n",
      " Validation loss : 0.5845093382282143; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 18 ! ---\n",
      "Epoch 1:\t train loss : 0.9478285234090748; train accuracy : 0.5783227485362; \n",
      " validation loss : 0.8989536229127866; validation accuracy : 0.6443514644351465\n",
      "Epoch 2:\t train loss : 0.7685763058998744; train accuracy : 0.7801360017348741; \n",
      " validation loss : 0.7488675302660894; validation accuracy : 0.8117154811715481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\t train loss : 0.7084835072246657; train accuracy : 0.84217912574739; \n",
      " validation loss : 0.6955942376963938; validation accuracy : 0.8410041841004184\n",
      "Epoch 4:\t train loss : 0.6767534557261355; train accuracy : 0.8736686390532544; \n",
      " validation loss : 0.6687222085407988; validation accuracy : 0.8828451882845189\n",
      "Epoch 5:\t train loss : 0.6586597786189056; train accuracy : 0.8919254004151306; \n",
      " validation loss : 0.656355929865944; validation accuracy : 0.891213389121339\n",
      "Epoch 6:\t train loss : 0.6447026746288528; train accuracy : 0.9068016357384058; \n",
      " validation loss : 0.628435604665834; validation accuracy : 0.9246861924686193\n",
      "Epoch 7:\t train loss : 0.6331445342519042; train accuracy : 0.9177573654698101; \n",
      " validation loss : 0.649916589338082; validation accuracy : 0.895397489539749\n",
      "Epoch 8:\t train loss : 0.6275275702551474; train accuracy : 0.9232755041977756; \n",
      " validation loss : 0.6276113817790264; validation accuracy : 0.9288702928870293\n",
      "Epoch 9:\t train loss : 0.6096703554323568; train accuracy : 0.9414585334118157; \n",
      " validation loss : 0.6427138040034805; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.6063404806852531; train accuracy : 0.9451782892902506; \n",
      " validation loss : 0.6404702414661428; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.6009188131467025; train accuracy : 0.9498562532916137; \n",
      " validation loss : 0.6141347281611655; validation accuracy : 0.9414225941422594\n",
      "Epoch 12:\t train loss : 0.5890975349877948; train accuracy : 0.9620084265311812; \n",
      " validation loss : 0.6073379962700899; validation accuracy : 0.9456066945606695\n",
      "Epoch 13:\t train loss : 0.5843075318511759; train accuracy : 0.9674704916509186; \n",
      " validation loss : 0.6128093279050759; validation accuracy : 0.9372384937238494\n",
      "Epoch 14:\t train loss : 0.5831041402850915; train accuracy : 0.9681498807274079; \n",
      " validation loss : 0.612355517579146; validation accuracy : 0.9414225941422594\n",
      "Epoch 15:\t train loss : 0.5829050498514973; train accuracy : 0.9681210694259426; \n",
      " validation loss : 0.6021354093940071; validation accuracy : 0.9456066945606695\n",
      "Epoch 16:\t train loss : 0.5793718233723453; train accuracy : 0.9719065026797609; \n",
      " validation loss : 0.6152897033663368; validation accuracy : 0.9330543933054394\n",
      "Epoch 17:\t train loss : 0.5744764562340666; train accuracy : 0.976996809070913; \n",
      " validation loss : 0.6218775084265092; validation accuracy : 0.9288702928870293\n",
      "Epoch 18:\t train loss : 0.5708184950525489; train accuracy : 0.9806796988754298; \n",
      " validation loss : 0.614729472529176; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5746265083835758; train accuracy : 0.9765770315065523; \n",
      " validation loss : 0.5992487091696241; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5777383285830565; train accuracy : 0.9736066792651569; \n",
      " validation loss : 0.6065575150048511; validation accuracy : 0.9414225941422594\n",
      "Epoch 21:\t train loss : 0.5690771827124257; train accuracy : 0.9824433842436259; \n",
      " validation loss : 0.5937250686970931; validation accuracy : 0.9539748953974896\n",
      "Epoch 22:\t train loss : 0.579280615962104; train accuracy : 0.9719625762879891; \n",
      " validation loss : 0.6141809456172617; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5698879159197685; train accuracy : 0.9813789150841105; \n",
      " validation loss : 0.5871300242453973; validation accuracy : 0.9623430962343096\n",
      "Epoch 24:\t train loss : 0.5678420813284788; train accuracy : 0.9835608290219647; \n",
      " validation loss : 0.6188783424807524; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5696983183145864; train accuracy : 0.9817196939186468; \n",
      " validation loss : 0.5865173012340915; validation accuracy : 0.9623430962343096\n",
      "Epoch 26:\t train loss : 0.5678531507529703; train accuracy : 0.9834620031599492; \n",
      " validation loss : 0.6005108606685651; validation accuracy : 0.9497907949790795\n",
      "Epoch 27:\t train loss : 0.579369137906119; train accuracy : 0.9717884692834351; \n",
      " validation loss : 0.5970537080742858; validation accuracy : 0.9581589958158996\n",
      "Epoch 28:\t train loss : 0.5692487835744028; train accuracy : 0.9819712506583228; \n",
      " validation loss : 0.6207618537976767; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5695998033794557; train accuracy : 0.9817175253260634; \n",
      " validation loss : 0.6284956377197118; validation accuracy : 0.9163179916317992\n",
      "Epoch 30:\t train loss : 0.5771321828757823; train accuracy : 0.9738796121317265; \n",
      " validation loss : 0.6096232160637425; validation accuracy : 0.9372384937238494\n",
      "Epoch 31:\t train loss : 0.5662579050942584; train accuracy : 0.9849106230056693; \n",
      " validation loss : 0.6217273146145288; validation accuracy : 0.9246861924686193\n",
      "Epoch 32:\t train loss : 0.5721684683348296; train accuracy : 0.9792450199820316; \n",
      " validation loss : 0.5889206595612222; validation accuracy : 0.9623430962343096\n",
      "Epoch 33:\t train loss : 0.575095482045158; train accuracy : 0.9759958486941974; \n",
      " validation loss : 0.5921572679899139; validation accuracy : 0.9539748953974896\n",
      "Epoch 34:\t train loss : 0.5659768141099439; train accuracy : 0.9850943337773785; \n",
      " validation loss : 0.5934243614709189; validation accuracy : 0.9581589958158996\n",
      "Epoch 35:\t train loss : 0.5623567069954549; train accuracy : 0.9890811363425137; \n",
      " validation loss : 0.6270334683240021; validation accuracy : 0.9246861924686193\n",
      "Epoch 36:\t train loss : 0.5697510779047346; train accuracy : 0.9813361628303231; \n",
      " validation loss : 0.6026596903567015; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.563800736106222; train accuracy : 0.9874413705505127; \n",
      " validation loss : 0.598401612877172; validation accuracy : 0.9497907949790795\n",
      "Epoch 38:\t train loss : 0.5657216903549619; train accuracy : 0.9855760711298367; \n",
      " validation loss : 0.5893172329192194; validation accuracy : 0.9623430962343096\n",
      "Epoch 39:\t train loss : 0.5753717523257238; train accuracy : 0.975632144738065; \n",
      " validation loss : 0.5935127839062452; validation accuracy : 0.9581589958158996\n",
      "Epoch 40:\t train loss : 0.5631906682087395; train accuracy : 0.9881229282195855; \n",
      " validation loss : 0.6133696501291148; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5645433627365483; train accuracy : 0.9868276588494067; \n",
      " validation loss : 0.5938477915972823; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.5611326491596554; train accuracy : 0.9902915208029989; \n",
      " validation loss : 0.5832834420186149; validation accuracy : 0.9707112970711297\n",
      "Epoch 43:\t train loss : 0.5653713060454025; train accuracy : 0.9860066916571145; \n",
      " validation loss : 0.5876629190164041; validation accuracy : 0.9623430962343096\n",
      "Epoch 44:\t train loss : 0.5621706141401983; train accuracy : 0.9890656463954893; \n",
      " validation loss : 0.5843860282764446; validation accuracy : 0.9623430962343096\n",
      "Epoch 45:\t train loss : 0.5664868905946719; train accuracy : 0.9848486632175718; \n",
      " validation loss : 0.6148328484997458; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5797717738707377; train accuracy : 0.9711902475293535; \n",
      " validation loss : 0.5961620876845998; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5735796352443927; train accuracy : 0.9775175810898726; \n",
      " validation loss : 0.6421573815510647; validation accuracy : 0.9037656903765691\n",
      "Epoch 48:\t train loss : 0.5703748592715211; train accuracy : 0.9809259890331176; \n",
      " validation loss : 0.5878790448645527; validation accuracy : 0.9623430962343096\n",
      "Epoch 49:\t train loss : 0.5648017730379139; train accuracy : 0.9864184144490226; \n",
      " validation loss : 0.6190256850920234; validation accuracy : 0.9330543933054394\n",
      "Epoch 50:\t train loss : 0.5639811938369113; train accuracy : 0.9871721552712289; \n",
      " validation loss : 0.6123852028570612; validation accuracy : 0.9330543933054394\n",
      "Epoch 51:\t train loss : 0.5655967132933062; train accuracy : 0.9858090399330834; \n",
      " validation loss : 0.6121274084132585; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5644369555788653; train accuracy : 0.9868158864896682; \n",
      " validation loss : 0.6067601000564337; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.5646665455472092; train accuracy : 0.9865407850305152; \n",
      " validation loss : 0.5913551157541977; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54:\t train loss : 0.5681400539627461; train accuracy : 0.9830357198178382; \n",
      " validation loss : 0.6545424908030348; validation accuracy : 0.895397489539749\n",
      "Epoch 55:\t train loss : 0.6030622754804102; train accuracy : 0.9473880851327489; \n",
      " validation loss : 0.6282259641882945; validation accuracy : 0.9246861924686193\n",
      "Epoch 56:\t train loss : 0.5712547479338735; train accuracy : 0.9799132562966635; \n",
      " validation loss : 0.5735422624927016; validation accuracy : 0.9790794979079498\n",
      "Epoch 57:\t train loss : 0.5615299259051318; train accuracy : 0.9897434864772763; \n",
      " validation loss : 0.5883516540671433; validation accuracy : 0.9623430962343096\n",
      "Epoch 58:\t train loss : 0.5608306956846958; train accuracy : 0.990525419003067; \n",
      " validation loss : 0.5939543151382007; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5644964995835605; train accuracy : 0.9868254902568233; \n",
      " validation loss : 0.587337476406482; validation accuracy : 0.9623430962343096\n",
      "Epoch 60:\t train loss : 0.5611884711835751; train accuracy : 0.9900334582855727; \n",
      " validation loss : 0.5816380631471156; validation accuracy : 0.9707112970711297\n",
      "Epoch 61:\t train loss : 0.5702614086664826; train accuracy : 0.9807475448433967; \n",
      " validation loss : 0.6119888607394316; validation accuracy : 0.9372384937238494\n",
      "Epoch 62:\t train loss : 0.5635766749204704; train accuracy : 0.9876287989095077; \n",
      " validation loss : 0.593847161512487; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.569560106829161; train accuracy : 0.9814563648192324; \n",
      " validation loss : 0.5906445502004257; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.5610290209034384; train accuracy : 0.990301124570154; \n",
      " validation loss : 0.5898465142570362; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.5624325659732319; train accuracy : 0.9888215248303851; \n",
      " validation loss : 0.5840514647169065; validation accuracy : 0.9707112970711297\n",
      "Epoch 66:\t train loss : 0.568003230313726; train accuracy : 0.9830924130239475; \n",
      " validation loss : 0.6031239632652245; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5659250202027312; train accuracy : 0.9853598314693763; \n",
      " validation loss : 0.6163407537850505; validation accuracy : 0.9288702928870293\n",
      "Epoch 68:\t train loss : 0.5660781732745012; train accuracy : 0.9852919855014096; \n",
      " validation loss : 0.6066428619493252; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5652553331779788; train accuracy : 0.985994919297376; \n",
      " validation loss : 0.599546635931213; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5643604060511817; train accuracy : 0.9868276588494067; \n",
      " validation loss : 0.6065358126288682; validation accuracy : 0.9456066945606695\n",
      "Epoch 71:\t train loss : 0.5664616380731444; train accuracy : 0.9847498373555562; \n",
      " validation loss : 0.6153275971695884; validation accuracy : 0.9372384937238494\n",
      "Epoch 72:\t train loss : 0.5613239350277509; train accuracy : 0.9899817218625112; \n",
      " validation loss : 0.5771655834049011; validation accuracy : 0.9748953974895398\n",
      "Epoch 73:\t train loss : 0.5606584340013838; train accuracy : 0.9906419034046904; \n",
      " validation loss : 0.5943094383412001; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5632414006995602; train accuracy : 0.9880182161777007; \n",
      " validation loss : 0.6026531732443491; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5616324262099099; train accuracy : 0.9895421171659593; \n",
      " validation loss : 0.6046010733618317; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5611887874188699; train accuracy : 0.9901830911738282; \n",
      " validation loss : 0.5914717560459851; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5600898886675877; train accuracy : 0.991290312587131; \n",
      " validation loss : 0.5967424622213316; validation accuracy : 0.9539748953974896\n",
      "Epoch 78:\t train loss : 0.5691767463510142; train accuracy : 0.9820818488800769; \n",
      " validation loss : 0.601201184894695; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5633036606250446; train accuracy : 0.9879001827813749; \n",
      " validation loss : 0.5827741700402287; validation accuracy : 0.9665271966527197\n",
      "Epoch 80:\t train loss : 0.5702698762737868; train accuracy : 0.98081322221878; \n",
      " validation loss : 0.603071564968501; validation accuracy : 0.9497907949790795\n",
      "Epoch 81:\t train loss : 0.5688850863254897; train accuracy : 0.9821704513770563; \n",
      " validation loss : 0.61812031887453; validation accuracy : 0.9330543933054394\n",
      "Epoch 82:\t train loss : 0.5693263927507217; train accuracy : 0.9818067474209238; \n",
      " validation loss : 0.5948953051851085; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5619495549040827; train accuracy : 0.9893562378016667; \n",
      " validation loss : 0.5963305343227647; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.5598455918826436; train accuracy : 0.9914938504910313; \n",
      " validation loss : 0.5910370866959396; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5592055850926175; train accuracy : 0.9922005018742835; \n",
      " validation loss : 0.5976737541297465; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5604848508959971; train accuracy : 0.9908897425570804; \n",
      " validation loss : 0.6097832895816616; validation accuracy : 0.9414225941422594\n",
      "Epoch 87:\t train loss : 0.5617224664684447; train accuracy : 0.98953623098609; \n",
      " validation loss : 0.6005041909003525; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.5590345827359676; train accuracy : 0.9923516837572416; \n",
      " validation loss : 0.5844284515667629; validation accuracy : 0.9665271966527197\n",
      "Epoch 89:\t train loss : 0.5596355851389598; train accuracy : 0.9916118838873571; \n",
      " validation loss : 0.5736981709588522; validation accuracy : 0.9748953974895398\n",
      "Epoch 90:\t train loss : 0.5612209749220127; train accuracy : 0.9901676012268038; \n",
      " validation loss : 0.5965692833139576; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5616529174155214; train accuracy : 0.9896756405093095; \n",
      " validation loss : 0.5950858350308723; validation accuracy : 0.9539748953974896\n",
      "Epoch 92:\t train loss : 0.5611939927785922; train accuracy : 0.9901071904334087; \n",
      " validation loss : 0.593479000415258; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5722100497431111; train accuracy : 0.9786291396883423; \n",
      " validation loss : 0.6043014828929311; validation accuracy : 0.9414225941422594\n",
      "Epoch 94:\t train loss : 0.5756676492475685; train accuracy : 0.9753260633848633; \n",
      " validation loss : 0.6095283764569204; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5622001481098038; train accuracy : 0.989160754670219; \n",
      " validation loss : 0.6047483023628523; validation accuracy : 0.9456066945606695\n",
      "Epoch 96:\t train loss : 0.5589047694300092; train accuracy : 0.9925744291954521; \n",
      " validation loss : 0.5891006952506507; validation accuracy : 0.9623430962343096\n",
      "Epoch 97:\t train loss : 0.5600714373169168; train accuracy : 0.9912887635924285; \n",
      " validation loss : 0.5801768256674901; validation accuracy : 0.9707112970711297\n",
      "Epoch 98:\t train loss : 0.5592430741279368; train accuracy : 0.9920573747637783; \n",
      " validation loss : 0.5781634320194868; validation accuracy : 0.9707112970711297\n",
      "Epoch 99:\t train loss : 0.5611885636040744; train accuracy : 0.9900436816506087; \n",
      " validation loss : 0.6044794514453634; validation accuracy : 0.9456066945606695\n",
      "Epoch 100:\t train loss : 0.5594926274712638; train accuracy : 0.9918464016853062; \n",
      " validation loss : 0.5952905418461989; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5579652462496636; train accuracy : 0.993389510207875; \n",
      " validation loss : 0.5884482588652837; validation accuracy : 0.9623430962343096\n",
      "Epoch 102:\t train loss : 0.55995383413376; train accuracy : 0.9913426686080733; \n",
      " validation loss : 0.6041773614264676; validation accuracy : 0.9456066945606695\n",
      "Epoch 103:\t train loss : 0.5652005752682918; train accuracy : 0.9860472753183184; \n",
      " validation loss : 0.6067039999734896; validation accuracy : 0.9456066945606695\n",
      "Epoch 104:\t train loss : 0.5606811637786666; train accuracy : 0.9905799436165929; \n",
      " validation loss : 0.5943056010245196; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105:\t train loss : 0.5600724560397575; train accuracy : 0.9913079711267387; \n",
      " validation loss : 0.5890497244244892; validation accuracy : 0.9623430962343096\n",
      "Epoch 106:\t train loss : 0.5825997556936956; train accuracy : 0.9681018618916323; \n",
      " validation loss : 0.6173664821092401; validation accuracy : 0.9372384937238494\n",
      "Early stopping at epoch 106\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5712547479338735; Train accuracy : 0.9799132562966635; \n",
      " Validation loss : 0.5735422624927016; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 19 ! ---\n",
      "Epoch 1:\t train loss : 0.9264308975814051; train accuracy : 0.6098255831965055; \n",
      " validation loss : 0.7949914067180194; validation accuracy : 0.7531380753138075\n",
      "Epoch 2:\t train loss : 0.7469256581394947; train accuracy : 0.8010149013290374; \n",
      " validation loss : 0.7098134843230588; validation accuracy : 0.8493723849372385\n",
      "Epoch 3:\t train loss : 0.68967579707706; train accuracy : 0.8605412187490319; \n",
      " validation loss : 0.6825758632146512; validation accuracy : 0.8744769874476988\n",
      "Epoch 4:\t train loss : 0.6643706896584871; train accuracy : 0.8859815979429351; \n",
      " validation loss : 0.6639209558499473; validation accuracy : 0.8870292887029289\n",
      "Epoch 5:\t train loss : 0.6412635677210436; train accuracy : 0.9088661358778153; \n",
      " validation loss : 0.6409824582932573; validation accuracy : 0.9079497907949791\n",
      "Epoch 6:\t train loss : 0.630197476229256; train accuracy : 0.9206192880820347; \n",
      " validation loss : 0.6669653745587921; validation accuracy : 0.8828451882845189\n",
      "Epoch 7:\t train loss : 0.6159760399070402; train accuracy : 0.9352727779670994; \n",
      " validation loss : 0.6500357814547529; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6158935345523167; train accuracy : 0.9345447504569534; \n",
      " validation loss : 0.6540333177330384; validation accuracy : 0.8870292887029289\n",
      "Epoch 9:\t train loss : 0.6074706091308435; train accuracy : 0.9439375445335977; \n",
      " validation loss : 0.6316676999751946; validation accuracy : 0.9205020920502092\n",
      "Epoch 10:\t train loss : 0.6000236963909392; train accuracy : 0.9516360482047151; \n",
      " validation loss : 0.6093493794099691; validation accuracy : 0.9414225941422594\n",
      "Epoch 11:\t train loss : 0.6042167393791693; train accuracy : 0.9468592583413364; \n",
      " validation loss : 0.6089061383567306; validation accuracy : 0.9497907949790795\n",
      "Epoch 12:\t train loss : 0.5906667220863294; train accuracy : 0.9606725734997986; \n",
      " validation loss : 0.6212913172705382; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.6033396051105632; train accuracy : 0.9471904334087178; \n",
      " validation loss : 0.6220161605193983; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5890897664789227; train accuracy : 0.9623609777254561; \n",
      " validation loss : 0.6072301012129042; validation accuracy : 0.9414225941422594\n",
      "Epoch 15:\t train loss : 0.5872152461685989; train accuracy : 0.9641113417392112; \n",
      " validation loss : 0.6202057685204497; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.5884187917208098; train accuracy : 0.9626840980203848; \n",
      " validation loss : 0.6305856292791868; validation accuracy : 0.9163179916317992\n",
      "Epoch 17:\t train loss : 0.5811682371577218; train accuracy : 0.9698794882121503; \n",
      " validation loss : 0.5967261033669525; validation accuracy : 0.9539748953974896\n",
      "Epoch 18:\t train loss : 0.5772337781629652; train accuracy : 0.9743929489761145; \n",
      " validation loss : 0.6007851127989887; validation accuracy : 0.9497907949790795\n",
      "Epoch 19:\t train loss : 0.5730520180455422; train accuracy : 0.978311905573283; \n",
      " validation loss : 0.5996555753232989; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5765859435061336; train accuracy : 0.9748421574398215; \n",
      " validation loss : 0.6169292326880204; validation accuracy : 0.9288702928870293\n",
      "Epoch 21:\t train loss : 0.5755938648141473; train accuracy : 0.9757250844202113; \n",
      " validation loss : 0.604882573438344; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5856247441582462; train accuracy : 0.9653387651414232; \n",
      " validation loss : 0.6172854828455676; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.586057717181373; train accuracy : 0.9651336782428204; \n",
      " validation loss : 0.6214570999273685; validation accuracy : 0.9288702928870293\n",
      "Epoch 24:\t train loss : 0.606461623776515; train accuracy : 0.9440283156231606; \n",
      " validation loss : 0.6795757102706318; validation accuracy : 0.8619246861924686\n",
      "Epoch 25:\t train loss : 0.5813659947021961; train accuracy : 0.9694457696954676; \n",
      " validation loss : 0.6061377317468214; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5724149411855176; train accuracy : 0.9787707178041452; \n",
      " validation loss : 0.6119250994966666; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5789043478774708; train accuracy : 0.9722494501068806; \n",
      " validation loss : 0.6020250824882176; validation accuracy : 0.9539748953974896\n",
      "Epoch 28:\t train loss : 0.569931309358364; train accuracy : 0.9813634251370861; \n",
      " validation loss : 0.603824083459957; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5722440134979786; train accuracy : 0.9789138449146504; \n",
      " validation loss : 0.6277620396937655; validation accuracy : 0.9205020920502092\n",
      "Epoch 30:\t train loss : 0.5733277110541568; train accuracy : 0.9777446637132501; \n",
      " validation loss : 0.6091983347657618; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5686988373593005; train accuracy : 0.9824012515877196; \n",
      " validation loss : 0.5991668077560904; validation accuracy : 0.9497907949790795\n",
      "Epoch 32:\t train loss : 0.5664304643000857; train accuracy : 0.9846819913875895; \n",
      " validation loss : 0.6171200432151436; validation accuracy : 0.9330543933054394\n",
      "Epoch 33:\t train loss : 0.5650798832556311; train accuracy : 0.9863260943647573; \n",
      " validation loss : 0.6167679724898624; validation accuracy : 0.9330543933054394\n",
      "Epoch 34:\t train loss : 0.5661009596203695; train accuracy : 0.985193159639394; \n",
      " validation loss : 0.5981491789814973; validation accuracy : 0.9539748953974896\n",
      "Epoch 35:\t train loss : 0.5713961754411222; train accuracy : 0.9797214907525016; \n",
      " validation loss : 0.6050430649166414; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5678248813424056; train accuracy : 0.9833888906099941; \n",
      " validation loss : 0.6041863528897665; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.5699321153104133; train accuracy : 0.9811000960376716; \n",
      " validation loss : 0.617321890718944; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5711910055851586; train accuracy : 0.9797930543077543; \n",
      " validation loss : 0.5932209327208541; validation accuracy : 0.9581589958158996\n",
      "Epoch 39:\t train loss : 0.5645262463929903; train accuracy : 0.9868992224046593; \n",
      " validation loss : 0.6054913656407979; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5832307586065685; train accuracy : 0.9677536478825243; \n",
      " validation loss : 0.6292963761132565; validation accuracy : 0.9205020920502092\n",
      "Epoch 41:\t train loss : 0.5649240970293432; train accuracy : 0.9865488398029679; \n",
      " validation loss : 0.5967487392169474; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5759616110752258; train accuracy : 0.9750590166981629; \n",
      " validation loss : 0.6185007951767141; validation accuracy : 0.9288702928870293\n",
      "Epoch 43:\t train loss : 0.5730134077933049; train accuracy : 0.9780891601350723; \n",
      " validation loss : 0.5986029340126064; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.5629408678498422; train accuracy : 0.988299203816723; \n",
      " validation loss : 0.5986938170909224; validation accuracy : 0.9497907949790795\n",
      "Epoch 45:\t train loss : 0.5608357579810314; train accuracy : 0.9905703398494377; \n",
      " validation loss : 0.5883344511475445; validation accuracy : 0.9581589958158996\n",
      "Epoch 46:\t train loss : 0.5702322317951437; train accuracy : 0.980836766938257; \n",
      " validation loss : 0.5879319416311948; validation accuracy : 0.9623430962343096\n",
      "Epoch 47:\t train loss : 0.5649024063757455; train accuracy : 0.9863047182378636; \n",
      " validation loss : 0.6046451463400452; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5639566024092523; train accuracy : 0.9874007868893089; \n",
      " validation loss : 0.6044553709511362; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49:\t train loss : 0.5655193926389822; train accuracy : 0.9857743424517488; \n",
      " validation loss : 0.6217158171661938; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5654130301264876; train accuracy : 0.9859698255831965; \n",
      " validation loss : 0.6148596859698428; validation accuracy : 0.9330543933054394\n",
      "Epoch 51:\t train loss : 0.5652346591678074; train accuracy : 0.986132160228012; \n",
      " validation loss : 0.5977369104859342; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5639745764023377; train accuracy : 0.9873019610272933; \n",
      " validation loss : 0.606750473584865; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5779849715883272; train accuracy : 0.9731072833730908; \n",
      " validation loss : 0.5951445305129012; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5660435787876074; train accuracy : 0.9850868986028067; \n",
      " validation loss : 0.6025562328128287; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.564958849447757; train accuracy : 0.9861151212862852; \n",
      " validation loss : 0.6001242304181398; validation accuracy : 0.9497907949790795\n",
      "Epoch 56:\t train loss : 0.5686475923898515; train accuracy : 0.9826026208990365; \n",
      " validation loss : 0.5996997715070763; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5632345541641027; train accuracy : 0.9879776325164968; \n",
      " validation loss : 0.6085164185750584; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5639595696331602; train accuracy : 0.9873831283497011; \n",
      " validation loss : 0.608134644658523; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5629723669030674; train accuracy : 0.9883456736577961; \n",
      " validation loss : 0.6064848650541047; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5641246514727442; train accuracy : 0.9872554911862201; \n",
      " validation loss : 0.5794604375862468; validation accuracy : 0.9748953974895398\n",
      "Epoch 61:\t train loss : 0.5640281449606537; train accuracy : 0.987222342699588; \n",
      " validation loss : 0.6002512691766474; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5659718638089923; train accuracy : 0.9851968772266799; \n",
      " validation loss : 0.6224088173545886; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5650334072722446; train accuracy : 0.9861711948945134; \n",
      " validation loss : 0.5991701391864996; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5599417239497243; train accuracy : 0.9914067969887543; \n",
      " validation loss : 0.5904325866358139; validation accuracy : 0.9623430962343096\n",
      "Epoch 65:\t train loss : 0.5589068602172006; train accuracy : 0.9924232473124942; \n",
      " validation loss : 0.6095517933290586; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5643074188677841; train accuracy : 0.9869280337061247; \n",
      " validation loss : 0.6044404914238668; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.5681971885716857; train accuracy : 0.9829279097865485; \n",
      " validation loss : 0.6021580597705909; validation accuracy : 0.9456066945606695\n",
      "Epoch 68:\t train loss : 0.5608391434784812; train accuracy : 0.9903166145171783; \n",
      " validation loss : 0.5905251818597018; validation accuracy : 0.9581589958158996\n",
      "Epoch 69:\t train loss : 0.5664752169449697; train accuracy : 0.9846472939062548; \n",
      " validation loss : 0.6635215775961023; validation accuracy : 0.8870292887029289\n",
      "Epoch 70:\t train loss : 0.5746630718801106; train accuracy : 0.9762768363332197; \n",
      " validation loss : 0.6016229114534266; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5625744584872122; train accuracy : 0.9886186065243657; \n",
      " validation loss : 0.594110061600267; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5608194860604508; train accuracy : 0.9904870039344466; \n",
      " validation loss : 0.5919810479176868; validation accuracy : 0.9623430962343096\n",
      "Epoch 73:\t train loss : 0.5590819621494878; train accuracy : 0.992326590043062; \n",
      " validation loss : 0.5963380877751537; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5611244327991682; train accuracy : 0.990223674835032; \n",
      " validation loss : 0.5946473489434353; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.5615167075957201; train accuracy : 0.9898017286780879; \n",
      " validation loss : 0.5981009164274257; validation accuracy : 0.9539748953974896\n",
      "Epoch 76:\t train loss : 0.5579463450969115; train accuracy : 0.9934455838161034; \n",
      " validation loss : 0.5890764504262517; validation accuracy : 0.9623430962343096\n",
      "Epoch 77:\t train loss : 0.5595178025496955; train accuracy : 0.991739521050838; \n",
      " validation loss : 0.6076134588243625; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5776187513135584; train accuracy : 0.9734229684934478; \n",
      " validation loss : 0.593047435142721; validation accuracy : 0.9623430962343096\n",
      "Epoch 79:\t train loss : 0.5618594020460519; train accuracy : 0.9894860435577311; \n",
      " validation loss : 0.5989433471720248; validation accuracy : 0.9539748953974896\n",
      "Epoch 80:\t train loss : 0.5596506704193372; train accuracy : 0.9915034542581864; \n",
      " validation loss : 0.6047767148033618; validation accuracy : 0.9456066945606695\n",
      "Epoch 81:\t train loss : 0.5615680069974185; train accuracy : 0.9897183927630967; \n",
      " validation loss : 0.5982523250633622; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5604250896061995; train accuracy : 0.9909730784720716; \n",
      " validation loss : 0.5998056260239553; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5652589485093514; train accuracy : 0.9860472753183184; \n",
      " validation loss : 0.5994503021209064; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5590690340864579; train accuracy : 0.9923420799900864; \n",
      " validation loss : 0.5985769626628249; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5576674593470816; train accuracy : 0.9937206852752564; \n",
      " validation loss : 0.5986937098453625; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.558857983147383; train accuracy : 0.9924136435453391; \n",
      " validation loss : 0.5757016641584372; validation accuracy : 0.9748953974895398\n",
      "Epoch 87:\t train loss : 0.5583273042406159; train accuracy : 0.9929926577651105; \n",
      " validation loss : 0.6030300047176093; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.5611333597323859; train accuracy : 0.9901985811208526; \n",
      " validation loss : 0.6173141132610694; validation accuracy : 0.9330543933054394\n",
      "Epoch 89:\t train loss : 0.5601202087488771; train accuracy : 0.9910254344930141; \n",
      " validation loss : 0.602407816859707; validation accuracy : 0.9456066945606695\n",
      "Epoch 90:\t train loss : 0.557279881812039; train accuracy : 0.9940555779299235; \n",
      " validation loss : 0.5794942788388872; validation accuracy : 0.9707112970711297\n",
      "Epoch 91:\t train loss : 0.5605371990234781; train accuracy : 0.9906846556584776; \n",
      " validation loss : 0.5966277848114995; validation accuracy : 0.9539748953974896\n",
      "Epoch 92:\t train loss : 0.559406719970202; train accuracy : 0.9918928715263794; \n",
      " validation loss : 0.5909047923306981; validation accuracy : 0.9581589958158996\n",
      "Epoch 93:\t train loss : 0.5609770228801647; train accuracy : 0.990388178072431; \n",
      " validation loss : 0.5920184681962407; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5625637666128359; train accuracy : 0.9887676198147403; \n",
      " validation loss : 0.589767393666018; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5709658568856625; train accuracy : 0.9799191424765328; \n",
      " validation loss : 0.65807131752934; validation accuracy : 0.891213389121339\n",
      "Epoch 96:\t train loss : 0.5684184549969219; train accuracy : 0.9828873261253447; \n",
      " validation loss : 0.6173074375299831; validation accuracy : 0.9330543933054394\n",
      "Epoch 97:\t train loss : 0.5596819357597964; train accuracy : 0.9915307165649493; \n",
      " validation loss : 0.595402729786463; validation accuracy : 0.9539748953974896\n",
      "Epoch 98:\t train loss : 0.55897252749891; train accuracy : 0.9923575699371108; \n",
      " validation loss : 0.5969787625497635; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5575474102984058; train accuracy : 0.9938328324917128; \n",
      " validation loss : 0.5924633543315797; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100:\t train loss : 0.5591585394611966; train accuracy : 0.9922373679482016; \n",
      " validation loss : 0.5984280008859271; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5607666823893386; train accuracy : 0.9905238700083646; \n",
      " validation loss : 0.5955495939147332; validation accuracy : 0.9539748953974896\n",
      "Epoch 102:\t train loss : 0.5611128690683217; train accuracy : 0.9901152452058614; \n",
      " validation loss : 0.6247782160990271; validation accuracy : 0.9246861924686193\n",
      "Epoch 103:\t train loss : 0.5670688967858823; train accuracy : 0.9838322128938319; \n",
      " validation loss : 0.5864784686942666; validation accuracy : 0.9665271966527197\n",
      "Epoch 104:\t train loss : 0.5587532533830035; train accuracy : 0.9924350196722327; \n",
      " validation loss : 0.5830278707724381; validation accuracy : 0.9665271966527197\n",
      "Epoch 105:\t train loss : 0.5579515373522981; train accuracy : 0.9933991139750302; \n",
      " validation loss : 0.5937209229126843; validation accuracy : 0.9581589958158996\n",
      "Epoch 106:\t train loss : 0.5594290908017988; train accuracy : 0.991927569007714; \n",
      " validation loss : 0.5940796944680247; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5590038663898429; train accuracy : 0.9923361938102172; \n",
      " validation loss : 0.5795694895722384; validation accuracy : 0.9707112970711297\n",
      "Epoch 108:\t train loss : 0.5582999905412388; train accuracy : 0.9930738250875182; \n",
      " validation loss : 0.6133109566031879; validation accuracy : 0.9372384937238494\n",
      "Epoch 109:\t train loss : 0.5632626130042482; train accuracy : 0.9880048948232597; \n",
      " validation loss : 0.5900672128039132; validation accuracy : 0.9623430962343096\n",
      "Epoch 110:\t train loss : 0.5586062125124666; train accuracy : 0.9926924625917779; \n",
      " validation loss : 0.5866199289056645; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5585541400631268; train accuracy : 0.9929093218501193; \n",
      " validation loss : 0.5938341265587884; validation accuracy : 0.9581589958158996\n",
      "Epoch 112:\t train loss : 0.5605413528658038; train accuracy : 0.9907385606741225; \n",
      " validation loss : 0.6010241873532395; validation accuracy : 0.9497907949790795\n",
      "Epoch 113:\t train loss : 0.5677198983262578; train accuracy : 0.9834139843241736; \n",
      " validation loss : 0.5996190001912031; validation accuracy : 0.9497907949790795\n",
      "Epoch 114:\t train loss : 0.5670736895534958; train accuracy : 0.9840490721521733; \n",
      " validation loss : 0.6115503001055957; validation accuracy : 0.9414225941422594\n",
      "Epoch 115:\t train loss : 0.5654380066147829; train accuracy : 0.9859233557421233; \n",
      " validation loss : 0.5856094330557673; validation accuracy : 0.9665271966527197\n",
      "Epoch 116:\t train loss : 0.5596766788156835; train accuracy : 0.9916915022150624; \n",
      " validation loss : 0.5930586630267274; validation accuracy : 0.9581589958158996\n",
      "Epoch 117:\t train loss : 0.5606651718019412; train accuracy : 0.9906168096905108; \n",
      " validation loss : 0.5844240713817392; validation accuracy : 0.9665271966527197\n",
      "Epoch 118:\t train loss : 0.5584587656162742; train accuracy : 0.9928473620620217; \n",
      " validation loss : 0.5834403418941034; validation accuracy : 0.9665271966527197\n",
      "Epoch 119:\t train loss : 0.5604333659838521; train accuracy : 0.9909111186839741; \n",
      " validation loss : 0.5984983069871009; validation accuracy : 0.9497907949790795\n",
      "Epoch 120:\t train loss : 0.5581275732207363; train accuracy : 0.9932501006846557; \n",
      " validation loss : 0.5905490751648788; validation accuracy : 0.9623430962343096\n",
      "Epoch 121:\t train loss : 0.5590843092307293; train accuracy : 0.9921503144459246; \n",
      " validation loss : 0.5884800210305382; validation accuracy : 0.9623430962343096\n",
      "Epoch 122:\t train loss : 0.5581120031816073; train accuracy : 0.9931512748226401; \n",
      " validation loss : 0.5989771415584954; validation accuracy : 0.9539748953974896\n",
      "Epoch 123:\t train loss : 0.5602232656131189; train accuracy : 0.9910660181542179; \n",
      " validation loss : 0.6123549254872285; validation accuracy : 0.9372384937238494\n",
      "Epoch 124:\t train loss : 0.5597917886189127; train accuracy : 0.991474642956721; \n",
      " validation loss : 0.5852532606917847; validation accuracy : 0.9623430962343096\n",
      "Epoch 125:\t train loss : 0.5592003143420345; train accuracy : 0.9922181604138913; \n",
      " validation loss : 0.5886776002979427; validation accuracy : 0.9623430962343096\n",
      "Epoch 126:\t train loss : 0.5574205553466269; train accuracy : 0.9939567520679079; \n",
      " validation loss : 0.5967515623151344; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.558439563871039; train accuracy : 0.9929306979770129; \n",
      " validation loss : 0.5891220201430872; validation accuracy : 0.9623430962343096\n",
      "Epoch 128:\t train loss : 0.5584242467066809; train accuracy : 0.9928879457232256; \n",
      " validation loss : 0.6051753298503884; validation accuracy : 0.9456066945606695\n",
      "Epoch 129:\t train loss : 0.560211342274287; train accuracy : 0.9910505282071935; \n",
      " validation loss : 0.5966667253655061; validation accuracy : 0.9539748953974896\n",
      "Epoch 130:\t train loss : 0.5624885666651884; train accuracy : 0.9888546733170173; \n",
      " validation loss : 0.6143769602131991; validation accuracy : 0.9372384937238494\n",
      "Epoch 131:\t train loss : 0.5655179069841653; train accuracy : 0.9857161002509371; \n",
      " validation loss : 0.6024542319751476; validation accuracy : 0.9497907949790795\n",
      "Epoch 132:\t train loss : 0.5664096840350564; train accuracy : 0.9848833606989064; \n",
      " validation loss : 0.6035495762998203; validation accuracy : 0.9456066945606695\n",
      "Epoch 133:\t train loss : 0.5616781760066935; train accuracy : 0.9896158493137953; \n",
      " validation loss : 0.6086675775052327; validation accuracy : 0.9414225941422594\n",
      "Epoch 134:\t train loss : 0.5600870208172273; train accuracy : 0.9912422937513553; \n",
      " validation loss : 0.6065241223298924; validation accuracy : 0.9456066945606695\n",
      "Epoch 135:\t train loss : 0.55725412667685; train accuracy : 0.9940924440038414; \n",
      " validation loss : 0.6001902103900655; validation accuracy : 0.9497907949790795\n",
      "Epoch 136:\t train loss : 0.5567920869237192; train accuracy : 0.9945763499488831; \n",
      " validation loss : 0.5766742912700014; validation accuracy : 0.9748953974895398\n",
      "Early stopping at epoch 136\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.558857983147383; Train accuracy : 0.9924136435453391; \n",
      " Validation loss : 0.5757016641584372; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 20 ! ---\n",
      "Epoch 1:\t train loss : 0.939104574963336; train accuracy : 0.585268130982992; \n",
      " validation loss : 0.833231147059603; validation accuracy : 0.7238493723849372\n",
      "Epoch 2:\t train loss : 0.7487887843332676; train accuracy : 0.799735121905883; \n",
      " validation loss : 0.7399278135125766; validation accuracy : 0.7949790794979079\n",
      "Epoch 3:\t train loss : 0.7005351017929726; train accuracy : 0.8496768797050714; \n",
      " validation loss : 0.7212195590517757; validation accuracy : 0.8284518828451883\n",
      "Epoch 4:\t train loss : 0.6697932083442056; train accuracy : 0.8812977477617027; \n",
      " validation loss : 0.7515883402722539; validation accuracy : 0.7949790794979079\n",
      "Epoch 5:\t train loss : 0.6573943636108197; train accuracy : 0.8926481613432882; \n",
      " validation loss : 0.6993520074411732; validation accuracy : 0.8493723849372385\n",
      "Epoch 6:\t train loss : 0.6496952876726824; train accuracy : 0.9002788190464388; \n",
      " validation loss : 0.7171350177610841; validation accuracy : 0.8242677824267782\n",
      "Epoch 7:\t train loss : 0.6382670731256579; train accuracy : 0.9127813748876978; \n",
      " validation loss : 0.6987435885082324; validation accuracy : 0.8535564853556485\n",
      "Epoch 8:\t train loss : 0.6281582707563625; train accuracy : 0.9223578797360513; \n",
      " validation loss : 0.6844608985148114; validation accuracy : 0.8577405857740585\n",
      "Epoch 9:\t train loss : 0.6164746963670251; train accuracy : 0.9348139657362372; \n",
      " validation loss : 0.6699617715549909; validation accuracy : 0.8786610878661087\n",
      "Epoch 10:\t train loss : 0.6067125270469528; train accuracy : 0.9447024381176616; \n",
      " validation loss : 0.6656743569714543; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.6044598726108401; train accuracy : 0.9467567148920351; \n",
      " validation loss : 0.6964444903592945; validation accuracy : 0.8451882845188284\n",
      "Epoch 12:\t train loss : 0.596468976658607; train accuracy : 0.9550769850367111; \n",
      " validation loss : 0.6453983572379492; validation accuracy : 0.9037656903765691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\t train loss : 0.5903651102150227; train accuracy : 0.9614839369249357; \n",
      " validation loss : 0.6735598875117512; validation accuracy : 0.8744769874476988\n",
      "Epoch 14:\t train loss : 0.5899688013184802; train accuracy : 0.961489823104805; \n",
      " validation loss : 0.6603246161307574; validation accuracy : 0.8870292887029289\n",
      "Epoch 15:\t train loss : 0.5961347823258426; train accuracy : 0.9548601257783699; \n",
      " validation loss : 0.6585747394814107; validation accuracy : 0.891213389121339\n",
      "Epoch 16:\t train loss : 0.5834979030013645; train accuracy : 0.9676024659995662; \n",
      " validation loss : 0.6789809842984562; validation accuracy : 0.8702928870292888\n",
      "Epoch 17:\t train loss : 0.5941585653585886; train accuracy : 0.9565891136652312; \n",
      " validation loss : 0.6742548628234363; validation accuracy : 0.8744769874476988\n",
      "Epoch 18:\t train loss : 0.589349030052115; train accuracy : 0.9618925617274389; \n",
      " validation loss : 0.6636500833928816; validation accuracy : 0.8870292887029289\n",
      "Epoch 19:\t train loss : 0.5854248485489296; train accuracy : 0.9655732829393724; \n",
      " validation loss : 0.6664087199081303; validation accuracy : 0.8870292887029289\n",
      "Epoch 20:\t train loss : 0.5850154183699203; train accuracy : 0.9659915115090306; \n",
      " validation loss : 0.6543651127640211; validation accuracy : 0.899581589958159\n",
      "Epoch 21:\t train loss : 0.5787826612136453; train accuracy : 0.9725400415130581; \n",
      " validation loss : 0.6531383005936174; validation accuracy : 0.895397489539749\n",
      "Epoch 22:\t train loss : 0.578789015164222; train accuracy : 0.9724567055980669; \n",
      " validation loss : 0.6346587194777454; validation accuracy : 0.9121338912133892\n",
      "Epoch 23:\t train loss : 0.579609194415708; train accuracy : 0.9719241612193686; \n",
      " validation loss : 0.6852893386596337; validation accuracy : 0.8577405857740585\n",
      "Epoch 24:\t train loss : 0.5795673676315483; train accuracy : 0.971527308776604; \n",
      " validation loss : 0.6422608626089774; validation accuracy : 0.9121338912133892\n",
      "Epoch 25:\t train loss : 0.5746003704017227; train accuracy : 0.976484091824406; \n",
      " validation loss : 0.6398575195487175; validation accuracy : 0.9079497907949791\n",
      "Epoch 26:\t train loss : 0.5745059367677572; train accuracy : 0.9770011462560798; \n",
      " validation loss : 0.6512623312255038; validation accuracy : 0.899581589958159\n",
      "Epoch 27:\t train loss : 0.5791169094840763; train accuracy : 0.9718659190185569; \n",
      " validation loss : 0.6662486905518998; validation accuracy : 0.8828451882845189\n",
      "Epoch 28:\t train loss : 0.5918667826167668; train accuracy : 0.958658880386629; \n",
      " validation loss : 0.6581704480114579; validation accuracy : 0.8870292887029289\n",
      "Epoch 29:\t train loss : 0.5765983670828205; train accuracy : 0.9741451098237244; \n",
      " validation loss : 0.6514128724410143; validation accuracy : 0.895397489539749\n",
      "Epoch 30:\t train loss : 0.5695141157647614; train accuracy : 0.981775767526875; \n",
      " validation loss : 0.667920290856403; validation accuracy : 0.8828451882845189\n",
      "Epoch 31:\t train loss : 0.5706735411726452; train accuracy : 0.9806567737538338; \n",
      " validation loss : 0.6455711490719933; validation accuracy : 0.9079497907949791\n",
      "Epoch 32:\t train loss : 0.5724908317042663; train accuracy : 0.9786548530004028; \n",
      " validation loss : 0.6316026131833792; validation accuracy : 0.9205020920502092\n",
      "Epoch 33:\t train loss : 0.5697609440253338; train accuracy : 0.9816769416648595; \n",
      " validation loss : 0.6667314882609218; validation accuracy : 0.8786610878661087\n",
      "Epoch 34:\t train loss : 0.5815592557268706; train accuracy : 0.9691536292945878; \n",
      " validation loss : 0.6515929117566138; validation accuracy : 0.895397489539749\n",
      "Epoch 35:\t train loss : 0.5695591713442164; train accuracy : 0.9816053781096069; \n",
      " validation loss : 0.6429525551573503; validation accuracy : 0.9121338912133892\n",
      "Epoch 36:\t train loss : 0.5676642725510193; train accuracy : 0.9836522197094086; \n",
      " validation loss : 0.6306757484837694; validation accuracy : 0.9205020920502092\n",
      "Epoch 37:\t train loss : 0.5679656265334604; train accuracy : 0.9831816351188079; \n",
      " validation loss : 0.6497793672680594; validation accuracy : 0.9037656903765691\n",
      "Epoch 38:\t train loss : 0.5680116986861069; train accuracy : 0.9830422255955885; \n",
      " validation loss : 0.6297580416544444; validation accuracy : 0.9205020920502092\n",
      "Epoch 39:\t train loss : 0.568724554788137; train accuracy : 0.98237615787354; \n",
      " validation loss : 0.660354351833994; validation accuracy : 0.891213389121339\n",
      "Epoch 40:\t train loss : 0.5716671892782474; train accuracy : 0.9794736516001116; \n",
      " validation loss : 0.6322341675198336; validation accuracy : 0.9205020920502092\n",
      "Epoch 41:\t train loss : 0.5701800415279656; train accuracy : 0.9810653985563369; \n",
      " validation loss : 0.6515918567916463; validation accuracy : 0.895397489539749\n",
      "Epoch 42:\t train loss : 0.568939075541142; train accuracy : 0.9821902785092474; \n",
      " validation loss : 0.6617794061874465; validation accuracy : 0.8828451882845189\n",
      "Epoch 43:\t train loss : 0.5712948212960128; train accuracy : 0.9799132562966635; \n",
      " validation loss : 0.6296264480754227; validation accuracy : 0.9163179916317992\n",
      "Epoch 44:\t train loss : 0.5734005531156886; train accuracy : 0.9775897642430063; \n",
      " validation loss : 0.6299501208432545; validation accuracy : 0.9163179916317992\n",
      "Epoch 45:\t train loss : 0.56685429463114; train accuracy : 0.9843529849127916; \n",
      " validation loss : 0.6539766894408259; validation accuracy : 0.899581589958159\n",
      "Epoch 46:\t train loss : 0.5717863028592354; train accuracy : 0.979260509929056; \n",
      " validation loss : 0.6759749182622456; validation accuracy : 0.8744769874476988\n",
      "Epoch 47:\t train loss : 0.566564793581288; train accuracy : 0.9844518107748071; \n",
      " validation loss : 0.6433332564358356; validation accuracy : 0.9079497907949791\n",
      "Epoch 48:\t train loss : 0.5660421587004543; train accuracy : 0.9851857244648223; \n",
      " validation loss : 0.6252315830791505; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5621111697520823; train accuracy : 0.9892035069240063; \n",
      " validation loss : 0.6254893866042347; validation accuracy : 0.9246861924686193\n",
      "Epoch 50:\t train loss : 0.5716465359361677; train accuracy : 0.9796809070912977; \n",
      " validation loss : 0.6527892976895179; validation accuracy : 0.895397489539749\n",
      "Epoch 51:\t train loss : 0.5657566040957738; train accuracy : 0.9855649183679792; \n",
      " validation loss : 0.6361105537907701; validation accuracy : 0.9121338912133892\n",
      "Epoch 52:\t train loss : 0.5690816142819809; train accuracy : 0.9818708758016047; \n",
      " validation loss : 0.645996322912292; validation accuracy : 0.899581589958159\n",
      "Epoch 53:\t train loss : 0.5634675673442913; train accuracy : 0.9877917531522042; \n",
      " validation loss : 0.6430737991559924; validation accuracy : 0.9079497907949791\n",
      "Epoch 54:\t train loss : 0.5687587569967401; train accuracy : 0.9825096812168902; \n",
      " validation loss : 0.6669510782162495; validation accuracy : 0.8786610878661087\n",
      "Epoch 55:\t train loss : 0.5644388852673524; train accuracy : 0.9867811890083336; \n",
      " validation loss : 0.6502849052975813; validation accuracy : 0.895397489539749\n",
      "Epoch 56:\t train loss : 0.5618579502247641; train accuracy : 0.9894240837696335; \n",
      " validation loss : 0.6529316052760887; validation accuracy : 0.899581589958159\n",
      "Epoch 57:\t train loss : 0.5643376069990125; train accuracy : 0.9869825583196505; \n",
      " validation loss : 0.6535119830468515; validation accuracy : 0.895397489539749\n",
      "Epoch 58:\t train loss : 0.5603181418291565; train accuracy : 0.9912481799312246; \n",
      " validation loss : 0.6360179376109609; validation accuracy : 0.9163179916317992\n",
      "Epoch 59:\t train loss : 0.5570788959235227; train accuracy : 0.994355773103256; \n",
      " validation loss : 0.6141650832896935; validation accuracy : 0.9330543933054394\n",
      "Epoch 60:\t train loss : 0.561317540092599; train accuracy : 0.9900185879364293; \n",
      " validation loss : 0.6459319842076748; validation accuracy : 0.9037656903765691\n",
      "Epoch 61:\t train loss : 0.5637202019765059; train accuracy : 0.9873927321168562; \n",
      " validation loss : 0.669705003866343; validation accuracy : 0.8828451882845189\n",
      "Epoch 62:\t train loss : 0.5701218257934184; train accuracy : 0.9811583382384832; \n",
      " validation loss : 0.6480980876159498; validation accuracy : 0.9037656903765691\n",
      "Epoch 63:\t train loss : 0.5744199711328214; train accuracy : 0.9766972334954614; \n",
      " validation loss : 0.6519937747218509; validation accuracy : 0.895397489539749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:\t train loss : 0.5627673799389866; train accuracy : 0.9884327271600731; \n",
      " validation loss : 0.658414506743886; validation accuracy : 0.891213389121339\n",
      "Epoch 65:\t train loss : 0.5655148324483623; train accuracy : 0.9855884630874563; \n",
      " validation loss : 0.6361844797701929; validation accuracy : 0.9163179916317992\n",
      "Epoch 66:\t train loss : 0.5615733837846048; train accuracy : 0.9897707487840391; \n",
      " validation loss : 0.6410770373692531; validation accuracy : 0.9121338912133892\n",
      "Epoch 67:\t train loss : 0.5640504804725823; train accuracy : 0.9872997924347099; \n",
      " validation loss : 0.6309049494883016; validation accuracy : 0.9205020920502092\n",
      "Epoch 68:\t train loss : 0.5652052232408535; train accuracy : 0.9862390408624803; \n",
      " validation loss : 0.6357454783605062; validation accuracy : 0.9163179916317992\n",
      "Epoch 69:\t train loss : 0.5647256724431673; train accuracy : 0.9865835372843025; \n",
      " validation loss : 0.6423702672300133; validation accuracy : 0.9079497907949791\n",
      "Epoch 70:\t train loss : 0.5612122252434777; train accuracy : 0.9902354471947706; \n",
      " validation loss : 0.6390247648273629; validation accuracy : 0.9079497907949791\n",
      "Epoch 71:\t train loss : 0.5582067115804762; train accuracy : 0.9931379534681991; \n",
      " validation loss : 0.6126756160007645; validation accuracy : 0.9372384937238494\n",
      "Epoch 72:\t train loss : 0.5872060572313494; train accuracy : 0.963317636853682; \n",
      " validation loss : 0.6915753470266569; validation accuracy : 0.8577405857740585\n",
      "Epoch 73:\t train loss : 0.5743404966738358; train accuracy : 0.9768521329657053; \n",
      " validation loss : 0.6523620223579454; validation accuracy : 0.899581589958159\n",
      "Epoch 74:\t train loss : 0.5686782340194435; train accuracy : 0.9822869357786796; \n",
      " validation loss : 0.7013753411204016; validation accuracy : 0.8493723849372385\n",
      "Epoch 75:\t train loss : 0.5684865351744438; train accuracy : 0.9824845875027107; \n",
      " validation loss : 0.6676324870848873; validation accuracy : 0.8828451882845189\n",
      "Epoch 76:\t train loss : 0.5659361341179426; train accuracy : 0.9852167043588711; \n",
      " validation loss : 0.6225652892628422; validation accuracy : 0.9288702928870293\n",
      "Epoch 77:\t train loss : 0.5673774066297197; train accuracy : 0.983717897084792; \n",
      " validation loss : 0.6198179417932007; validation accuracy : 0.9330543933054394\n",
      "Epoch 78:\t train loss : 0.5626431269809523; train accuracy : 0.9885839090430311; \n",
      " validation loss : 0.6322639353469061; validation accuracy : 0.9205020920502092\n",
      "Epoch 79:\t train loss : 0.5641957293753499; train accuracy : 0.9868837324576349; \n",
      " validation loss : 0.6330611009442235; validation accuracy : 0.9163179916317992\n",
      "Epoch 80:\t train loss : 0.561353176034622; train accuracy : 0.9899352520214381; \n",
      " validation loss : 0.6281203913077154; validation accuracy : 0.9163179916317992\n",
      "Epoch 81:\t train loss : 0.5602571547596211; train accuracy : 0.9909730784720716; \n",
      " validation loss : 0.6595457069957997; validation accuracy : 0.891213389121339\n",
      "Epoch 82:\t train loss : 0.5613815259010003; train accuracy : 0.9898076148579572; \n",
      " validation loss : 0.6303654870680035; validation accuracy : 0.9205020920502092\n",
      "Epoch 83:\t train loss : 0.5604877492198529; train accuracy : 0.9908181790018278; \n",
      " validation loss : 0.6220958454273009; validation accuracy : 0.9288702928870293\n",
      "Epoch 84:\t train loss : 0.560409004884719; train accuracy : 0.9908299513615664; \n",
      " validation loss : 0.6242053304130941; validation accuracy : 0.9288702928870293\n",
      "Epoch 85:\t train loss : 0.5580667080455319; train accuracy : 0.9932714768115493; \n",
      " validation loss : 0.6260786652010013; validation accuracy : 0.9246861924686193\n",
      "Epoch 86:\t train loss : 0.5573563564046261; train accuracy : 0.9940555779299235; \n",
      " validation loss : 0.6504551020378732; validation accuracy : 0.895397489539749\n",
      "Epoch 87:\t train loss : 0.5602255239220929; train accuracy : 0.9910040583661204; \n",
      " validation loss : 0.6476532961646487; validation accuracy : 0.9037656903765691\n",
      "Epoch 88:\t train loss : 0.56533357461694; train accuracy : 0.9859912017100901; \n",
      " validation loss : 0.6214309887364978; validation accuracy : 0.9330543933054394\n",
      "Epoch 89:\t train loss : 0.562568025619455; train accuracy : 0.9886960562594876; \n",
      " validation loss : 0.6385477883019688; validation accuracy : 0.9079497907949791\n",
      "Epoch 90:\t train loss : 0.5595331077715272; train accuracy : 0.9917283682889805; \n",
      " validation loss : 0.6420503469989018; validation accuracy : 0.9079497907949791\n",
      "Epoch 91:\t train loss : 0.5603112875558289; train accuracy : 0.9909266086309985; \n",
      " validation loss : 0.6229540832984989; validation accuracy : 0.9288702928870293\n",
      "Epoch 92:\t train loss : 0.570610351024432; train accuracy : 0.9805948139657362; \n",
      " validation loss : 0.6338268576191007; validation accuracy : 0.9205020920502092\n",
      "Epoch 93:\t train loss : 0.5631333341042574; train accuracy : 0.9880513646643329; \n",
      " validation loss : 0.6372982958813314; validation accuracy : 0.9121338912133892\n",
      "Epoch 94:\t train loss : 0.5640875873551536; train accuracy : 0.9871315716100251; \n",
      " validation loss : 0.6314402940801712; validation accuracy : 0.9205020920502092\n",
      "Epoch 95:\t train loss : 0.572614590447427; train accuracy : 0.9782403420180303; \n",
      " validation loss : 0.6298631614116676; validation accuracy : 0.9205020920502092\n",
      "Epoch 96:\t train loss : 0.5621428647807921; train accuracy : 0.9891121162365625; \n",
      " validation loss : 0.642410131906904; validation accuracy : 0.9121338912133892\n",
      "Epoch 97:\t train loss : 0.5622672186875398; train accuracy : 0.9888546733170173; \n",
      " validation loss : 0.6621979370988935; validation accuracy : 0.8870292887029289\n",
      "Epoch 98:\t train loss : 0.5613287900692047; train accuracy : 0.9898327085721367; \n",
      " validation loss : 0.6402596782349287; validation accuracy : 0.9121338912133892\n",
      "Epoch 99:\t train loss : 0.556818562958637; train accuracy : 0.9945571424145729; \n",
      " validation loss : 0.626412411342584; validation accuracy : 0.9205020920502092\n",
      "Epoch 100:\t train loss : 0.5573513682708917; train accuracy : 0.9938814709253694; \n",
      " validation loss : 0.626235683666098; validation accuracy : 0.9246861924686193\n",
      "Epoch 101:\t train loss : 0.556730192008226; train accuracy : 0.9946559682765885; \n",
      " validation loss : 0.6240602329588665; validation accuracy : 0.9288702928870293\n",
      "Epoch 102:\t train loss : 0.5584821601584931; train accuracy : 0.9929499055113231; \n",
      " validation loss : 0.6282500074222878; validation accuracy : 0.9246861924686193\n",
      "Epoch 103:\t train loss : 0.559613724596192; train accuracy : 0.9916332600142508; \n",
      " validation loss : 0.6377348399261126; validation accuracy : 0.9121338912133892\n",
      "Epoch 104:\t train loss : 0.5656640622697221; train accuracy : 0.9853753214164007; \n",
      " validation loss : 0.640926825346817; validation accuracy : 0.9121338912133892\n",
      "Epoch 105:\t train loss : 0.5588875341612068; train accuracy : 0.9923981535983147; \n",
      " validation loss : 0.6163798010439064; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.5592004555836501; train accuracy : 0.9920728647108027; \n",
      " validation loss : 0.646494086208164; validation accuracy : 0.9037656903765691\n",
      "Epoch 107:\t train loss : 0.5630163034746282; train accuracy : 0.9881015520926918; \n",
      " validation loss : 0.6439140717250733; validation accuracy : 0.9079497907949791\n",
      "Epoch 108:\t train loss : 0.5591719386561962; train accuracy : 0.9921562006257938; \n",
      " validation loss : 0.6376156757040796; validation accuracy : 0.9163179916317992\n",
      "Epoch 109:\t train loss : 0.5590111222880871; train accuracy : 0.9922240465937606; \n",
      " validation loss : 0.6246385789365362; validation accuracy : 0.9288702928870293\n",
      "Epoch 110:\t train loss : 0.5649503275072694; train accuracy : 0.9861615911273584; \n",
      " validation loss : 0.6355876298703826; validation accuracy : 0.9121338912133892\n",
      "Epoch 111:\t train loss : 0.5604278467272774; train accuracy : 0.9907834815204932; \n",
      " validation loss : 0.6231518573700512; validation accuracy : 0.9288702928870293\n",
      "Epoch 112:\t train loss : 0.5597934843396322; train accuracy : 0.9915675826388674; \n",
      " validation loss : 0.64584796898092; validation accuracy : 0.9079497907949791\n",
      "Epoch 113:\t train loss : 0.5596684818162679; train accuracy : 0.99163914619412; \n",
      " validation loss : 0.6224443457146422; validation accuracy : 0.9288702928870293\n",
      "Epoch 114:\t train loss : 0.5557930354174547; train accuracy : 0.9956318349391245; \n",
      " validation loss : 0.6002309349043079; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115:\t train loss : 0.5598185142089854; train accuracy : 0.9914222869357787; \n",
      " validation loss : 0.6386802539071267; validation accuracy : 0.9121338912133892\n",
      "Epoch 116:\t train loss : 0.5610280817984835; train accuracy : 0.9903283868769168; \n",
      " validation loss : 0.6477671060081099; validation accuracy : 0.9037656903765691\n",
      "Epoch 117:\t train loss : 0.5641938554248213; train accuracy : 0.9870541218749032; \n",
      " validation loss : 0.617054898494865; validation accuracy : 0.9330543933054394\n",
      "Epoch 118:\t train loss : 0.5611086168978987; train accuracy : 0.9900089841692742; \n",
      " validation loss : 0.6313960697816616; validation accuracy : 0.9205020920502092\n",
      "Epoch 119:\t train loss : 0.5580369176502982; train accuracy : 0.9932463830973698; \n",
      " validation loss : 0.6230426839112241; validation accuracy : 0.9288702928870293\n",
      "Epoch 120:\t train loss : 0.5615734768495023; train accuracy : 0.9896195669010812; \n",
      " validation loss : 0.6594491853737137; validation accuracy : 0.8870292887029289\n",
      "Epoch 121:\t train loss : 0.5647462105248265; train accuracy : 0.986471390067846; \n",
      " validation loss : 0.6239782392967048; validation accuracy : 0.9288702928870293\n",
      "Epoch 122:\t train loss : 0.558223199276236; train accuracy : 0.9931069735741503; \n",
      " validation loss : 0.6153410857053261; validation accuracy : 0.9330543933054394\n",
      "Epoch 123:\t train loss : 0.5562437398386739; train accuracy : 0.9951516465813687; \n",
      " validation loss : 0.6356307707990094; validation accuracy : 0.9163179916317992\n",
      "Epoch 124:\t train loss : 0.5578670690826735; train accuracy : 0.9935406920908331; \n",
      " validation loss : 0.6136128807709936; validation accuracy : 0.9372384937238494\n",
      "Epoch 125:\t train loss : 0.5582094728320501; train accuracy : 0.9932346107376313; \n",
      " validation loss : 0.6379587456170032; validation accuracy : 0.9121338912133892\n",
      "Epoch 126:\t train loss : 0.5608061508125963; train accuracy : 0.9905179838284953; \n",
      " validation loss : 0.6155723937576975; validation accuracy : 0.9330543933054394\n",
      "Epoch 127:\t train loss : 0.5603748260861866; train accuracy : 0.9908122928219585; \n",
      " validation loss : 0.6326755442145849; validation accuracy : 0.9205020920502092\n",
      "Epoch 128:\t train loss : 0.5562808368774365; train accuracy : 0.9951206666873199; \n",
      " validation loss : 0.6184007598597822; validation accuracy : 0.9330543933054394\n",
      "Epoch 129:\t train loss : 0.5551425024398587; train accuracy : 0.9962359428730754; \n",
      " validation loss : 0.6122772640466809; validation accuracy : 0.9372384937238494\n",
      "Epoch 130:\t train loss : 0.5557771097238802; train accuracy : 0.9956163449921; \n",
      " validation loss : 0.6310716136600197; validation accuracy : 0.9205020920502092\n",
      "Epoch 131:\t train loss : 0.5562765303376656; train accuracy : 0.9951243842746058; \n",
      " validation loss : 0.6360075323383534; validation accuracy : 0.9121338912133892\n",
      "Epoch 132:\t train loss : 0.5572136035501901; train accuracy : 0.9941138201307351; \n",
      " validation loss : 0.6340200623466937; validation accuracy : 0.9163179916317992\n",
      "Epoch 133:\t train loss : 0.556095970488419; train accuracy : 0.995244586263515; \n",
      " validation loss : 0.6349339800528747; validation accuracy : 0.9121338912133892\n",
      "Epoch 134:\t train loss : 0.5580179885805447; train accuracy : 0.9933489265466712; \n",
      " validation loss : 0.6446355236023387; validation accuracy : 0.9079497907949791\n",
      "Epoch 135:\t train loss : 0.5785375454111534; train accuracy : 0.9722922023606679; \n",
      " validation loss : 0.6706112438850936; validation accuracy : 0.8828451882845189\n",
      "Epoch 136:\t train loss : 0.5672437794273896; train accuracy : 0.9839480776975743; \n",
      " validation loss : 0.6654877280074715; validation accuracy : 0.8828451882845189\n",
      "Epoch 137:\t train loss : 0.5641844668469306; train accuracy : 0.9870290281607237; \n",
      " validation loss : 0.6338664252488103; validation accuracy : 0.9205020920502092\n",
      "Epoch 138:\t train loss : 0.5609135637824231; train accuracy : 0.9903187831097617; \n",
      " validation loss : 0.6320474581738184; validation accuracy : 0.9163179916317992\n",
      "Epoch 139:\t train loss : 0.5581159376356939; train accuracy : 0.993228724557762; \n",
      " validation loss : 0.617370083450352; validation accuracy : 0.9330543933054394\n",
      "Epoch 140:\t train loss : 0.55851823606453; train accuracy : 0.9927816846866384; \n",
      " validation loss : 0.644278997300668; validation accuracy : 0.9037656903765691\n",
      "Epoch 141:\t train loss : 0.5583633766287303; train accuracy : 0.9929152080299886; \n",
      " validation loss : 0.6330819022112661; validation accuracy : 0.9205020920502092\n",
      "Epoch 142:\t train loss : 0.5574297646113275; train accuracy : 0.993916168406704; \n",
      " validation loss : 0.6508100219974335; validation accuracy : 0.895397489539749\n",
      "Epoch 143:\t train loss : 0.5558640225086765; train accuracy : 0.9955853650980514; \n",
      " validation loss : 0.6171453968529087; validation accuracy : 0.9330543933054394\n",
      "Epoch 144:\t train loss : 0.5584703756477992; train accuracy : 0.9928067784008179; \n",
      " validation loss : 0.6249271943604983; validation accuracy : 0.9205020920502092\n",
      "Epoch 145:\t train loss : 0.5586531462588251; train accuracy : 0.9926267852163946; \n",
      " validation loss : 0.6194232557420422; validation accuracy : 0.9288702928870293\n",
      "Epoch 146:\t train loss : 0.5601153183622262; train accuracy : 0.9910564143870628; \n",
      " validation loss : 0.6079232619107715; validation accuracy : 0.9414225941422594\n",
      "Epoch 147:\t train loss : 0.5561317358348227; train accuracy : 0.9952541900306701; \n",
      " validation loss : 0.6106462727361469; validation accuracy : 0.9414225941422594\n",
      "Epoch 148:\t train loss : 0.5611850660861732; train accuracy : 0.9900709439573716; \n",
      " validation loss : 0.64262760949273; validation accuracy : 0.9079497907949791\n",
      "Epoch 149:\t train loss : 0.558161313746415; train accuracy : 0.9931320672883298; \n",
      " validation loss : 0.6377069170794651; validation accuracy : 0.9121338912133892\n",
      "Epoch 150:\t train loss : 0.5569651540989059; train accuracy : 0.9944081291241984; \n",
      " validation loss : 0.6058306765273596; validation accuracy : 0.9456066945606695\n",
      "Epoch 151:\t train loss : 0.5570817281630615; train accuracy : 0.9942665510083956; \n",
      " validation loss : 0.6367682080690715; validation accuracy : 0.9121338912133892\n",
      "Epoch 152:\t train loss : 0.5585883671573031; train accuracy : 0.9927485362000061; \n",
      " validation loss : 0.6232843568770653; validation accuracy : 0.9288702928870293\n",
      "Epoch 153:\t train loss : 0.5619041891045292; train accuracy : 0.9893680101614052; \n",
      " validation loss : 0.6294478561855971; validation accuracy : 0.9205020920502092\n",
      "Epoch 154:\t train loss : 0.5592360799350686; train accuracy : 0.9919954149756808; \n",
      " validation loss : 0.6392726332928704; validation accuracy : 0.9121338912133892\n",
      "Epoch 155:\t train loss : 0.5572070851854813; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.6385499746929779; validation accuracy : 0.9121338912133892\n",
      "Epoch 156:\t train loss : 0.5544283535347219; train accuracy : 0.9970414201183432; \n",
      " validation loss : 0.619086197974609; validation accuracy : 0.9288702928870293\n",
      "Epoch 157:\t train loss : 0.5575995756733877; train accuracy : 0.9937804764707705; \n",
      " validation loss : 0.662886578001466; validation accuracy : 0.8870292887029289\n",
      "Epoch 158:\t train loss : 0.559022483614905; train accuracy : 0.9923479661699557; \n",
      " validation loss : 0.6252716920817807; validation accuracy : 0.9205020920502092\n",
      "Epoch 159:\t train loss : 0.5589813624722832; train accuracy : 0.9922816691966914; \n",
      " validation loss : 0.6459280321884024; validation accuracy : 0.9037656903765691\n",
      "Epoch 160:\t train loss : 0.5616232987268085; train accuracy : 0.9896468292078441; \n",
      " validation loss : 0.6189969868902921; validation accuracy : 0.9330543933054394\n",
      "Epoch 161:\t train loss : 0.556737240006155; train accuracy : 0.994594008488491; \n",
      " validation loss : 0.6313333299115194; validation accuracy : 0.9205020920502092\n",
      "Epoch 162:\t train loss : 0.5559611873962987; train accuracy : 0.9954769354688807; \n",
      " validation loss : 0.6185751516845067; validation accuracy : 0.9330543933054394\n",
      "Epoch 163:\t train loss : 0.5577847488784001; train accuracy : 0.9935097121967843; \n",
      " validation loss : 0.6148664125917798; validation accuracy : 0.9330543933054394\n",
      "Epoch 164:\t train loss : 0.5567891303192861; train accuracy : 0.9944583165525573; \n",
      " validation loss : 0.6147992004607511; validation accuracy : 0.9372384937238494\n",
      "Early stopping at epoch 164\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5557930354174547; Train accuracy : 0.9956318349391245; \n",
      " Validation loss : 0.6002309349043079; Validation accuracy : 0.9497907949790795\n",
      "--- Let's train model 21 ! ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t train loss : 0.9376135097596713; train accuracy : 0.58867220174107; \n",
      " validation loss : 0.8371455772858444; validation accuracy : 0.702928870292887\n",
      "Epoch 2:\t train loss : 0.7611813902352865; train accuracy : 0.7873292233340562; \n",
      " validation loss : 0.71636696313025; validation accuracy : 0.8326359832635983\n",
      "Epoch 3:\t train loss : 0.7054111042928636; train accuracy : 0.8437532141640075; \n",
      " validation loss : 0.7005772831086954; validation accuracy : 0.8410041841004184\n",
      "Epoch 4:\t train loss : 0.6880973401058594; train accuracy : 0.8611388209052325; \n",
      " validation loss : 0.6822896974268862; validation accuracy : 0.8702928870292888\n",
      "Epoch 5:\t train loss : 0.6648658060630219; train accuracy : 0.8847829858421884; \n",
      " validation loss : 0.6538245110678698; validation accuracy : 0.899581589958159\n",
      "Epoch 6:\t train loss : 0.6473600277343103; train accuracy : 0.9030626723256606; \n",
      " validation loss : 0.6716644749776983; validation accuracy : 0.891213389121339\n",
      "Epoch 7:\t train loss : 0.6353838584011762; train accuracy : 0.9148430868366431; \n",
      " validation loss : 0.6533748627920548; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6224183934002261; train accuracy : 0.928449146503919; \n",
      " validation loss : 0.6584367231644288; validation accuracy : 0.8870292887029289\n",
      "Epoch 9:\t train loss : 0.6118620108451315; train accuracy : 0.9391217200037176; \n",
      " validation loss : 0.6241413563763958; validation accuracy : 0.9288702928870293\n",
      "Epoch 10:\t train loss : 0.6113465433402676; train accuracy : 0.9391276061835868; \n",
      " validation loss : 0.6282487717091397; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.6025960829251419; train accuracy : 0.9484525542922643; \n",
      " validation loss : 0.6231478828239656; validation accuracy : 0.9246861924686193\n",
      "Epoch 12:\t train loss : 0.6024729192179434; train accuracy : 0.9486774683230583; \n",
      " validation loss : 0.6118858524634184; validation accuracy : 0.9414225941422594\n",
      "Epoch 13:\t train loss : 0.6023294009685213; train accuracy : 0.9483809907370117; \n",
      " validation loss : 0.6099823673233101; validation accuracy : 0.9372384937238494\n",
      "Epoch 14:\t train loss : 0.5978110571131224; train accuracy : 0.9529585798816568; \n",
      " validation loss : 0.601392051124474; validation accuracy : 0.9497907949790795\n",
      "Epoch 15:\t train loss : 0.5911359354850069; train accuracy : 0.9598435515350537; \n",
      " validation loss : 0.5979189175243915; validation accuracy : 0.9497907949790795\n",
      "Epoch 16:\t train loss : 0.5901448517677463; train accuracy : 0.9612958889680597; \n",
      " validation loss : 0.5978903463059102; validation accuracy : 0.9497907949790795\n",
      "Epoch 17:\t train loss : 0.587258242673074; train accuracy : 0.9640338920040893; \n",
      " validation loss : 0.5921568718741519; validation accuracy : 0.9581589958158996\n",
      "Epoch 18:\t train loss : 0.5901121688159954; train accuracy : 0.9610657083552774; \n",
      " validation loss : 0.6172829003629347; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5863560282933584; train accuracy : 0.9648548591963816; \n",
      " validation loss : 0.6391051636856255; validation accuracy : 0.9079497907949791\n",
      "Epoch 20:\t train loss : 0.5904870816132488; train accuracy : 0.9604653180086125; \n",
      " validation loss : 0.6273099648406874; validation accuracy : 0.9246861924686193\n",
      "Epoch 21:\t train loss : 0.5848526738278368; train accuracy : 0.9663573840577465; \n",
      " validation loss : 0.6065560845090089; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5787045025228263; train accuracy : 0.97261749124818; \n",
      " validation loss : 0.611180301001907; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5794586581638757; train accuracy : 0.9717302270826234; \n",
      " validation loss : 0.6036718775176534; validation accuracy : 0.9456066945606695\n",
      "Epoch 24:\t train loss : 0.5898010431458605; train accuracy : 0.9610015799745965; \n",
      " validation loss : 0.6048213767832218; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5867465959181796; train accuracy : 0.9642566374423; \n",
      " validation loss : 0.6190218916723711; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5754811256366522; train accuracy : 0.9757015397007343; \n",
      " validation loss : 0.6039115201016547; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.595453654744324; train accuracy : 0.9552761857554447; \n",
      " validation loss : 0.6208372605743349; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.5823332711403165; train accuracy : 0.9685783326621022; \n",
      " validation loss : 0.6079398079952605; validation accuracy : 0.9414225941422594\n",
      "Epoch 29:\t train loss : 0.5734016091561729; train accuracy : 0.9779438644319837; \n",
      " validation loss : 0.5950980657568402; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.5710381782920545; train accuracy : 0.9801028532482419; \n",
      " validation loss : 0.6261152067789038; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5742355081826936; train accuracy : 0.9769952600762105; \n",
      " validation loss : 0.613565765283965; validation accuracy : 0.9330543933054394\n",
      "Epoch 32:\t train loss : 0.570792036588521; train accuracy : 0.9806722637008581; \n",
      " validation loss : 0.6093440946711357; validation accuracy : 0.9414225941422594\n",
      "Epoch 33:\t train loss : 0.5864324432342403; train accuracy : 0.9644697791133554; \n",
      " validation loss : 0.6103057807532334; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.5776286051436804; train accuracy : 0.9734362898478888; \n",
      " validation loss : 0.5881826366207993; validation accuracy : 0.9623430962343096\n",
      "Epoch 35:\t train loss : 0.5727694477968579; train accuracy : 0.9780950463149416; \n",
      " validation loss : 0.5974639181671931; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5730355813544552; train accuracy : 0.9780330865268441; \n",
      " validation loss : 0.6308039392997212; validation accuracy : 0.9205020920502092\n",
      "Epoch 37:\t train loss : 0.5751322984301199; train accuracy : 0.9761219368629759; \n",
      " validation loss : 0.5782161470814585; validation accuracy : 0.9748953974895398\n",
      "Epoch 38:\t train loss : 0.5659712665936509; train accuracy : 0.9852417980730506; \n",
      " validation loss : 0.5996409624573404; validation accuracy : 0.9456066945606695\n",
      "Epoch 39:\t train loss : 0.5706592904728346; train accuracy : 0.9804104835961461; \n",
      " validation loss : 0.6036764347719156; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5711779095520877; train accuracy : 0.9798955977570557; \n",
      " validation loss : 0.6063524198710062; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5681246918086459; train accuracy : 0.9830326218284333; \n",
      " validation loss : 0.5955910216374117; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.571691399996839; train accuracy : 0.9796071749434617; \n",
      " validation loss : 0.5794086400334523; validation accuracy : 0.9707112970711297\n",
      "Epoch 43:\t train loss : 0.5690653579019926; train accuracy : 0.9819734192509062; \n",
      " validation loss : 0.6144527318579392; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5711868311346138; train accuracy : 0.980149323089315; \n",
      " validation loss : 0.5883028022942769; validation accuracy : 0.9623430962343096\n",
      "Epoch 45:\t train loss : 0.5744219747295725; train accuracy : 0.9764317358034635; \n",
      " validation loss : 0.5904931253970264; validation accuracy : 0.9623430962343096\n",
      "Epoch 46:\t train loss : 0.5645436588906491; train accuracy : 0.98675981288144; \n",
      " validation loss : 0.5955097843284681; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.564990849214629; train accuracy : 0.9863164905976022; \n",
      " validation loss : 0.5944238276582496; validation accuracy : 0.9539748953974896\n",
      "Epoch 48:\t train loss : 0.560749950433834; train accuracy : 0.9906691657114532; \n",
      " validation loss : 0.5889679700070738; validation accuracy : 0.9623430962343096\n",
      "Epoch 49:\t train loss : 0.562635836719723; train accuracy : 0.9884541032869667; \n",
      " validation loss : 0.6064399825265411; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5664315838913141; train accuracy : 0.9848486632175718; \n",
      " validation loss : 0.5867219869519684; validation accuracy : 0.9665271966527197\n",
      "Epoch 51:\t train loss : 0.5682153760526396; train accuracy : 0.982691842993897; \n",
      " validation loss : 0.5896060800132068; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:\t train loss : 0.5636146738026282; train accuracy : 0.9876058737879116; \n",
      " validation loss : 0.5917544433129508; validation accuracy : 0.9581589958158996\n",
      "Epoch 53:\t train loss : 0.5639760958371303; train accuracy : 0.987209021345147; \n",
      " validation loss : 0.6030565723624215; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.5705486055723774; train accuracy : 0.9806973574150376; \n",
      " validation loss : 0.6029019495045755; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.5691168751867842; train accuracy : 0.9820626413457666; \n",
      " validation loss : 0.5916265170204015; validation accuracy : 0.9623430962343096\n",
      "Epoch 56:\t train loss : 0.5629671673188119; train accuracy : 0.9882003779547074; \n",
      " validation loss : 0.6060029584353257; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5775969357278152; train accuracy : 0.9732990489172527; \n",
      " validation loss : 0.6047369255961526; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5641696791577733; train accuracy : 0.9871470615570495; \n",
      " validation loss : 0.6142498922608371; validation accuracy : 0.9372384937238494\n",
      "Epoch 59:\t train loss : 0.559450062614313; train accuracy : 0.9918367979181512; \n",
      " validation loss : 0.6121699978135865; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5629676348195911; train accuracy : 0.9882837138696986; \n",
      " validation loss : 0.585513793583079; validation accuracy : 0.9665271966527197\n",
      "Epoch 61:\t train loss : 0.5649775849484366; train accuracy : 0.9861284426407262; \n",
      " validation loss : 0.5909991106877327; validation accuracy : 0.9581589958158996\n",
      "Epoch 62:\t train loss : 0.5735603543974219; train accuracy : 0.9773633012175098; \n",
      " validation loss : 0.6134533365395449; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5647084603412815; train accuracy : 0.9865894234641718; \n",
      " validation loss : 0.6013497559652949; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5590509130936913; train accuracy : 0.9922491403079401; \n",
      " validation loss : 0.598058806646145; validation accuracy : 0.9539748953974896\n",
      "Epoch 65:\t train loss : 0.5603100817415928; train accuracy : 0.9909634747049165; \n",
      " validation loss : 0.5914474026129999; validation accuracy : 0.9581589958158996\n",
      "Epoch 66:\t train loss : 0.5581409389639526; train accuracy : 0.9932308931503454; \n",
      " validation loss : 0.6056482153652443; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5620017992450891; train accuracy : 0.9891666408500883; \n",
      " validation loss : 0.6079476936292042; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5945299252389636; train accuracy : 0.9561126428947613; \n",
      " validation loss : 0.6210688252806263; validation accuracy : 0.9288702928870293\n",
      "Epoch 69:\t train loss : 0.5766281764328741; train accuracy : 0.9742904055268131; \n",
      " validation loss : 0.6125631007989767; validation accuracy : 0.9372384937238494\n",
      "Epoch 70:\t train loss : 0.56259621157615; train accuracy : 0.9885529291489823; \n",
      " validation loss : 0.5949742842918944; validation accuracy : 0.9581589958158996\n",
      "Epoch 71:\t train loss : 0.5620230517034409; train accuracy : 0.989247808172496; \n",
      " validation loss : 0.6116722004205382; validation accuracy : 0.9372384937238494\n",
      "Epoch 72:\t train loss : 0.5588802310781636; train accuracy : 0.9924873756931751; \n",
      " validation loss : 0.5921345145949983; validation accuracy : 0.9623430962343096\n",
      "Epoch 73:\t train loss : 0.5587296440281309; train accuracy : 0.9925744291954521; \n",
      " validation loss : 0.6013410707683573; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5587639665218987; train accuracy : 0.9926673688775984; \n",
      " validation loss : 0.6036225261524867; validation accuracy : 0.9497907949790795\n",
      "Epoch 75:\t train loss : 0.5664587970521341; train accuracy : 0.984891415471359; \n",
      " validation loss : 0.5997257699396984; validation accuracy : 0.9497907949790795\n",
      "Epoch 76:\t train loss : 0.5587535309711437; train accuracy : 0.9926305028036804; \n",
      " validation loss : 0.5968931018196314; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.558943746519798; train accuracy : 0.9925028656401995; \n",
      " validation loss : 0.5925031031227079; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5600499645538484; train accuracy : 0.991263669878249; \n",
      " validation loss : 0.5725741342082493; validation accuracy : 0.9790794979079498\n",
      "Epoch 79:\t train loss : 0.5660849230811206; train accuracy : 0.9851392546237492; \n",
      " validation loss : 0.5989299004555293; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.567294948924995; train accuracy : 0.9837665355184485; \n",
      " validation loss : 0.595308310791229; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.5594482847370416; train accuracy : 0.9917379720561356; \n",
      " validation loss : 0.5836840617022896; validation accuracy : 0.9623430962343096\n",
      "Epoch 82:\t train loss : 0.5618666622740776; train accuracy : 0.9894144800024783; \n",
      " validation loss : 0.5989069794953916; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5734986526454627; train accuracy : 0.977372904984665; \n",
      " validation loss : 0.6017117894244443; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.6054302383441791; train accuracy : 0.9451479289940828; \n",
      " validation loss : 0.6093575790291401; validation accuracy : 0.9414225941422594\n",
      "Epoch 85:\t train loss : 0.57612598517901; train accuracy : 0.9748694197465845; \n",
      " validation loss : 0.5939761938364044; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5672110868445971; train accuracy : 0.9837621983332817; \n",
      " validation loss : 0.6046305903354041; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.5619221256723063; train accuracy : 0.9893274265002013; \n",
      " validation loss : 0.5923956397091509; validation accuracy : 0.9581589958158996\n",
      "Epoch 88:\t train loss : 0.5581142935344068; train accuracy : 0.9931475572353542; \n",
      " validation loss : 0.5801296160594835; validation accuracy : 0.9707112970711297\n",
      "Epoch 89:\t train loss : 0.5579119194299714; train accuracy : 0.9934108863347687; \n",
      " validation loss : 0.5891874306402959; validation accuracy : 0.9623430962343096\n",
      "Epoch 90:\t train loss : 0.5583668413496885; train accuracy : 0.992940301744168; \n",
      " validation loss : 0.6079017584171317; validation accuracy : 0.9414225941422594\n",
      "Epoch 91:\t train loss : 0.5584710189782184; train accuracy : 0.9928938319030949; \n",
      " validation loss : 0.6018665044153814; validation accuracy : 0.9456066945606695\n",
      "Epoch 92:\t train loss : 0.5574204623714908; train accuracy : 0.9939530344806221; \n",
      " validation loss : 0.5848451645820184; validation accuracy : 0.9665271966527197\n",
      "Epoch 93:\t train loss : 0.558453268793611; train accuracy : 0.9928687381889154; \n",
      " validation loss : 0.6074301648480662; validation accuracy : 0.9414225941422594\n",
      "Epoch 94:\t train loss : 0.5706267208004788; train accuracy : 0.9805136466433285; \n",
      " validation loss : 0.5950405824542444; validation accuracy : 0.9581589958158996\n",
      "Epoch 95:\t train loss : 0.5582959045744512; train accuracy : 0.9930605037330772; \n",
      " validation loss : 0.5864497064615896; validation accuracy : 0.9665271966527197\n",
      "Epoch 96:\t train loss : 0.5572362485787141; train accuracy : 0.994191269865857; \n",
      " validation loss : 0.5699378983353318; validation accuracy : 0.9790794979079498\n",
      "Epoch 97:\t train loss : 0.5576318045855436; train accuracy : 0.9936646116670281; \n",
      " validation loss : 0.5913513707723285; validation accuracy : 0.9581589958158996\n",
      "Epoch 98:\t train loss : 0.5694526374668406; train accuracy : 0.9815338145543542; \n",
      " validation loss : 0.6257556484371857; validation accuracy : 0.9205020920502092\n",
      "Epoch 99:\t train loss : 0.579600132964458; train accuracy : 0.9712639796771895; \n",
      " validation loss : 0.5788986679803657; validation accuracy : 0.9748953974895398\n",
      "Epoch 100:\t train loss : 0.5689282790094763; train accuracy : 0.982289104371263; \n",
      " validation loss : 0.5831006270956148; validation accuracy : 0.9665271966527197\n",
      "Epoch 101:\t train loss : 0.5699315667127994; train accuracy : 0.9809798940487624; \n",
      " validation loss : 0.5891333239729105; validation accuracy : 0.9623430962343096\n",
      "Epoch 102:\t train loss : 0.5710511544452296; train accuracy : 0.9801263979677189; \n",
      " validation loss : 0.5856242231469062; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103:\t train loss : 0.5618528382312566; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.5828989558458525; validation accuracy : 0.9665271966527197\n",
      "Epoch 104:\t train loss : 0.5616600344094458; train accuracy : 0.98965054679513; \n",
      " validation loss : 0.585637372397834; validation accuracy : 0.9665271966527197\n",
      "Epoch 105:\t train loss : 0.561316553665555; train accuracy : 0.9899721180953561; \n",
      " validation loss : 0.5871127366503381; validation accuracy : 0.9623430962343096\n",
      "Epoch 106:\t train loss : 0.561442560707176; train accuracy : 0.989851916106447; \n",
      " validation loss : 0.5952503011631923; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.5632579839153731; train accuracy : 0.9879739149292109; \n",
      " validation loss : 0.5846443194828185; validation accuracy : 0.9665271966527197\n",
      "Epoch 108:\t train loss : 0.5673471190158893; train accuracy : 0.983905945041668; \n",
      " validation loss : 0.5897527221352559; validation accuracy : 0.9581589958158996\n",
      "Epoch 109:\t train loss : 0.5636871909946751; train accuracy : 0.9876390222745438; \n",
      " validation loss : 0.5956727186717387; validation accuracy : 0.9539748953974896\n",
      "Epoch 110:\t train loss : 0.5658592667329891; train accuracy : 0.9852535704327892; \n",
      " validation loss : 0.581089546332016; validation accuracy : 0.9665271966527197\n",
      "Epoch 111:\t train loss : 0.5668042499588607; train accuracy : 0.9844378698224852; \n",
      " validation loss : 0.599122097629158; validation accuracy : 0.9497907949790795\n",
      "Epoch 112:\t train loss : 0.5657701881120087; train accuracy : 0.9853347377551969; \n",
      " validation loss : 0.5967429156749755; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5618629854266651; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.6273962121231341; validation accuracy : 0.9246861924686193\n",
      "Epoch 114:\t train loss : 0.5612323668726669; train accuracy : 0.9900089841692742; \n",
      " validation loss : 0.5890903220786188; validation accuracy : 0.9665271966527197\n",
      "Epoch 115:\t train loss : 0.5585125836371391; train accuracy : 0.9927448186127203; \n",
      " validation loss : 0.5968526628460695; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5603564870180406; train accuracy : 0.9907679915734688; \n",
      " validation loss : 0.5952039052677749; validation accuracy : 0.9581589958158996\n",
      "Epoch 117:\t train loss : 0.5609993115300188; train accuracy : 0.9903903466650144; \n",
      " validation loss : 0.5928427077192834; validation accuracy : 0.9581589958158996\n",
      "Epoch 118:\t train loss : 0.5570251539874591; train accuracy : 0.9942996994950277; \n",
      " validation loss : 0.577873173479072; validation accuracy : 0.9748953974895398\n",
      "Epoch 119:\t train loss : 0.5605267472629426; train accuracy : 0.9906846556584776; \n",
      " validation loss : 0.5895496947760891; validation accuracy : 0.9623430962343096\n",
      "Epoch 120:\t train loss : 0.5694769143145076; train accuracy : 0.9816171504693454; \n",
      " validation loss : 0.5914002782601067; validation accuracy : 0.9623430962343096\n",
      "Epoch 121:\t train loss : 0.5581997795782035; train accuracy : 0.9932308931503454; \n",
      " validation loss : 0.6011331946857357; validation accuracy : 0.9497907949790795\n",
      "Epoch 122:\t train loss : 0.55853162729446; train accuracy : 0.992853248241891; \n",
      " validation loss : 0.5812350661651886; validation accuracy : 0.9707112970711297\n",
      "Epoch 123:\t train loss : 0.5623933014237346; train accuracy : 0.9888878218036494; \n",
      " validation loss : 0.5850937669985615; validation accuracy : 0.9665271966527197\n",
      "Epoch 124:\t train loss : 0.5618550239931026; train accuracy : 0.9894609498435515; \n",
      " validation loss : 0.5888908373030638; validation accuracy : 0.9623430962343096\n",
      "Epoch 125:\t train loss : 0.5581019168884297; train accuracy : 0.9931379534681991; \n",
      " validation loss : 0.5830850753585685; validation accuracy : 0.9665271966527197\n",
      "Epoch 126:\t train loss : 0.559333497832633; train accuracy : 0.9919548313144769; \n",
      " validation loss : 0.5891016998136753; validation accuracy : 0.9623430962343096\n",
      "Epoch 127:\t train loss : 0.5573245605451402; train accuracy : 0.9940245980358747; \n",
      " validation loss : 0.600126272866829; validation accuracy : 0.9497907949790795\n",
      "Epoch 128:\t train loss : 0.55644409285988; train accuracy : 0.994882431302085; \n",
      " validation loss : 0.5873520017337415; validation accuracy : 0.9623430962343096\n",
      "Epoch 129:\t train loss : 0.5599862617685976; train accuracy : 0.9913544409678119; \n",
      " validation loss : 0.5929240878757818; validation accuracy : 0.9581589958158996\n",
      "Epoch 130:\t train loss : 0.5638164338788297; train accuracy : 0.9874317667833576; \n",
      " validation loss : 0.5685009941500564; validation accuracy : 0.9832635983263598\n",
      "Epoch 131:\t train loss : 0.5658681255357055; train accuracy : 0.9852476842529199; \n",
      " validation loss : 0.5735751162941878; validation accuracy : 0.9748953974895398\n",
      "Epoch 132:\t train loss : 0.5630165079597463; train accuracy : 0.9881656804733728; \n",
      " validation loss : 0.5795131214523911; validation accuracy : 0.9707112970711297\n",
      "Epoch 133:\t train loss : 0.5588783534733782; train accuracy : 0.9923575699371108; \n",
      " validation loss : 0.5848640458138513; validation accuracy : 0.9665271966527197\n",
      "Epoch 134:\t train loss : 0.5599615357642143; train accuracy : 0.9912017100901515; \n",
      " validation loss : 0.5864299809633983; validation accuracy : 0.9623430962343096\n",
      "Epoch 135:\t train loss : 0.5576242345411891; train accuracy : 0.9937110815081013; \n",
      " validation loss : 0.589922110513562; validation accuracy : 0.9623430962343096\n",
      "Epoch 136:\t train loss : 0.5569313287383586; train accuracy : 0.9943867529973047; \n",
      " validation loss : 0.5887003107487759; validation accuracy : 0.9623430962343096\n",
      "Epoch 137:\t train loss : 0.5596606824705045; train accuracy : 0.9917069921620868; \n",
      " validation loss : 0.5767033564944706; validation accuracy : 0.9748953974895398\n",
      "Epoch 138:\t train loss : 0.560873484770634; train accuracy : 0.9904058366120387; \n",
      " validation loss : 0.593503119401332; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5590715841585254; train accuracy : 0.9922860063818582; \n",
      " validation loss : 0.6013753732322489; validation accuracy : 0.9497907949790795\n",
      "Epoch 140:\t train loss : 0.5616026144117244; train accuracy : 0.9896991852287865; \n",
      " validation loss : 0.5889509860766124; validation accuracy : 0.9623430962343096\n",
      "Epoch 141:\t train loss : 0.5593285509426195; train accuracy : 0.9920691471235168; \n",
      " validation loss : 0.5890563983743106; validation accuracy : 0.9623430962343096\n",
      "Epoch 142:\t train loss : 0.5603999902434864; train accuracy : 0.9909228910437127; \n",
      " validation loss : 0.6051353704872421; validation accuracy : 0.9456066945606695\n",
      "Epoch 143:\t train loss : 0.5613269959558354; train accuracy : 0.989962514328201; \n",
      " validation loss : 0.5850662805814776; validation accuracy : 0.9665271966527197\n",
      "Epoch 144:\t train loss : 0.5576609205753882; train accuracy : 0.9937265714551257; \n",
      " validation loss : 0.5829605079065885; validation accuracy : 0.9665271966527197\n",
      "Epoch 145:\t train loss : 0.5575958663179345; train accuracy : 0.9938195111372718; \n",
      " validation loss : 0.6004724643626075; validation accuracy : 0.9497907949790795\n",
      "Epoch 146:\t train loss : 0.5577677962230555; train accuracy : 0.9934263762817931; \n",
      " validation loss : 0.5900862280444155; validation accuracy : 0.9581589958158996\n",
      "Epoch 147:\t train loss : 0.5576155654142008; train accuracy : 0.9936587254871588; \n",
      " validation loss : 0.5934554511664172; validation accuracy : 0.9581589958158996\n",
      "Epoch 148:\t train loss : 0.5589521252059515; train accuracy : 0.9923634561169801; \n",
      " validation loss : 0.5768190757386904; validation accuracy : 0.9748953974895398\n",
      "Epoch 149:\t train loss : 0.5630142980814661; train accuracy : 0.9882372440286255; \n",
      " validation loss : 0.5853804144682085; validation accuracy : 0.9665271966527197\n",
      "Epoch 150:\t train loss : 0.5583012633627832; train accuracy : 0.9930081477121349; \n",
      " validation loss : 0.5932661918060005; validation accuracy : 0.9581589958158996\n",
      "Epoch 151:\t train loss : 0.5579936475679188; train accuracy : 0.9933489265466712; \n",
      " validation loss : 0.573531731423383; validation accuracy : 0.9748953974895398\n",
      "Epoch 152:\t train loss : 0.557655457005595; train accuracy : 0.9936683292543139; \n",
      " validation loss : 0.5979509897519307; validation accuracy : 0.9539748953974896\n",
      "Epoch 153:\t train loss : 0.5653305569530996; train accuracy : 0.9858363022398463; \n",
      " validation loss : 0.5932881969836334; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154:\t train loss : 0.557355014846708; train accuracy : 0.9940053905015644; \n",
      " validation loss : 0.5865781758907198; validation accuracy : 0.9665271966527197\n",
      "Epoch 155:\t train loss : 0.5612275674827518; train accuracy : 0.9900030979894049; \n",
      " validation loss : 0.5916493502616068; validation accuracy : 0.9581589958158996\n",
      "Epoch 156:\t train loss : 0.55819078750292; train accuracy : 0.9932463830973698; \n",
      " validation loss : 0.5764524182639852; validation accuracy : 0.9748953974895398\n",
      "Epoch 157:\t train loss : 0.5622290690243542; train accuracy : 0.9890331175067382; \n",
      " validation loss : 0.5874933547696058; validation accuracy : 0.9623430962343096\n",
      "Epoch 158:\t train loss : 0.5595977438363374; train accuracy : 0.9916295424269649; \n",
      " validation loss : 0.5807332017954977; validation accuracy : 0.9707112970711297\n",
      "Epoch 159:\t train loss : 0.5565633570253864; train accuracy : 0.9948728275349298; \n",
      " validation loss : 0.5885559555445046; validation accuracy : 0.9623430962343096\n",
      "Epoch 160:\t train loss : 0.5557293087214769; train accuracy : 0.995693794727222; \n",
      " validation loss : 0.5826988565041759; validation accuracy : 0.9707112970711297\n",
      "Epoch 161:\t train loss : 0.5582630305677803; train accuracy : 0.9930759936801016; \n",
      " validation loss : 0.5938676139926293; validation accuracy : 0.9581589958158996\n",
      "Epoch 162:\t train loss : 0.5601431713926253; train accuracy : 0.9911648440162335; \n",
      " validation loss : 0.5834438460752758; validation accuracy : 0.9665271966527197\n",
      "Epoch 163:\t train loss : 0.5563930266841969; train accuracy : 0.994969484804362; \n",
      " validation loss : 0.6025038372155133; validation accuracy : 0.9497907949790795\n",
      "Epoch 164:\t train loss : 0.5582253381427424; train accuracy : 0.9930605037330772; \n",
      " validation loss : 0.59251555970659; validation accuracy : 0.9581589958158996\n",
      "Epoch 165:\t train loss : 0.5583357656652781; train accuracy : 0.9929344155642987; \n",
      " validation loss : 0.592550951141524; validation accuracy : 0.9581589958158996\n",
      "Epoch 166:\t train loss : 0.5569563423373204; train accuracy : 0.994355773103256; \n",
      " validation loss : 0.5760849411577051; validation accuracy : 0.9748953974895398\n",
      "Epoch 167:\t train loss : 0.5731231680045574; train accuracy : 0.9780154279872363; \n",
      " validation loss : 0.606150247245846; validation accuracy : 0.9456066945606695\n",
      "Epoch 168:\t train loss : 0.5604579809080875; train accuracy : 0.9908609312556151; \n",
      " validation loss : 0.579910966508305; validation accuracy : 0.9707112970711297\n",
      "Epoch 169:\t train loss : 0.5588972459744054; train accuracy : 0.9924814895133058; \n",
      " validation loss : 0.586429831755047; validation accuracy : 0.9623430962343096\n",
      "Epoch 170:\t train loss : 0.5752073037925497; train accuracy : 0.9758607763561449; \n",
      " validation loss : 0.6075324475596562; validation accuracy : 0.9414225941422594\n",
      "Epoch 171:\t train loss : 0.5715083867374162; train accuracy : 0.9796344372502246; \n",
      " validation loss : 0.6125361459596593; validation accuracy : 0.9372384937238494\n",
      "Epoch 172:\t train loss : 0.5636360748760035; train accuracy : 0.9876176461476501; \n",
      " validation loss : 0.5807806173758304; validation accuracy : 0.9707112970711297\n",
      "Epoch 173:\t train loss : 0.5599910681352673; train accuracy : 0.9912673874655349; \n",
      " validation loss : 0.5793201908953013; validation accuracy : 0.9707112970711297\n",
      "Epoch 174:\t train loss : 0.5635942983082428; train accuracy : 0.9875460825923975; \n",
      " validation loss : 0.5846958842150393; validation accuracy : 0.9665271966527197\n",
      "Epoch 175:\t train loss : 0.5570655666681172; train accuracy : 0.9942842095480033; \n",
      " validation loss : 0.5825107918995711; validation accuracy : 0.9707112970711297\n",
      "Epoch 176:\t train loss : 0.5581522920957837; train accuracy : 0.9931726509495338; \n",
      " validation loss : 0.58781296206657; validation accuracy : 0.9623430962343096\n",
      "Epoch 177:\t train loss : 0.5581594086785303; train accuracy : 0.9931475572353542; \n",
      " validation loss : 0.57665608297335; validation accuracy : 0.9748953974895398\n",
      "Epoch 178:\t train loss : 0.5602638773828491; train accuracy : 0.9909517023451779; \n",
      " validation loss : 0.5959004523309157; validation accuracy : 0.9539748953974896\n",
      "Epoch 179:\t train loss : 0.5590579554277836; train accuracy : 0.9922432541280709; \n",
      " validation loss : 0.5880950189423598; validation accuracy : 0.9623430962343096\n",
      "Epoch 180:\t train loss : 0.5630752917644591; train accuracy : 0.9882217540816011; \n",
      " validation loss : 0.5999786519012913; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 180\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5638164338788297; Train accuracy : 0.9874317667833576; \n",
      " Validation loss : 0.5685009941500564; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 22 ! ---\n",
      "Epoch 1:\t train loss : 0.9000428716708868; train accuracy : 0.6347061557049475; \n",
      " validation loss : 0.7999029247352525; validation accuracy : 0.7489539748953975\n",
      "Epoch 2:\t train loss : 0.7422406730373238; train accuracy : 0.8087208401747266; \n",
      " validation loss : 0.7285935170074469; validation accuracy : 0.8158995815899581\n",
      "Epoch 3:\t train loss : 0.6964744757208682; train accuracy : 0.854366616066173; \n",
      " validation loss : 0.7261855218143604; validation accuracy : 0.8284518828451883\n",
      "Epoch 4:\t train loss : 0.6675042940269679; train accuracy : 0.8828077077976393; \n",
      " validation loss : 0.7290846853233777; validation accuracy : 0.8158995815899581\n",
      "Epoch 5:\t train loss : 0.643437278030485; train accuracy : 0.9074742092382044; \n",
      " validation loss : 0.6898691119382746; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6285666308398119; train accuracy : 0.9222206388054153; \n",
      " validation loss : 0.6790098504658297; validation accuracy : 0.8619246861924686\n",
      "Epoch 7:\t train loss : 0.6261290642413934; train accuracy : 0.9249003996406332; \n",
      " validation loss : 0.6825579032485948; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6203802198587773; train accuracy : 0.9309297066204033; \n",
      " validation loss : 0.6755362627694551; validation accuracy : 0.8661087866108786\n",
      "Epoch 9:\t train loss : 0.605097852266872; train accuracy : 0.945693794727222; \n",
      " validation loss : 0.648570268446212; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.5977155258119322; train accuracy : 0.9534115059326497; \n",
      " validation loss : 0.6387793177400062; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.5983567419373671; train accuracy : 0.9529821246011339; \n",
      " validation loss : 0.6341214495171087; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.5941137058117618; train accuracy : 0.9569667585736856; \n",
      " validation loss : 0.6484436234636083; validation accuracy : 0.899581589958159\n",
      "Epoch 13:\t train loss : 0.5910979573278804; train accuracy : 0.9602196474488057; \n",
      " validation loss : 0.6598646467885745; validation accuracy : 0.8870292887029289\n",
      "Epoch 14:\t train loss : 0.5903614689753113; train accuracy : 0.9608488490969361; \n",
      " validation loss : 0.6582367299956877; validation accuracy : 0.8828451882845189\n",
      "Epoch 15:\t train loss : 0.5869716398450429; train accuracy : 0.9640397781839586; \n",
      " validation loss : 0.6668923387184256; validation accuracy : 0.8828451882845189\n",
      "Epoch 16:\t train loss : 0.5836839359805299; train accuracy : 0.9673140431859722; \n",
      " validation loss : 0.6175324565160896; validation accuracy : 0.9330543933054394\n",
      "Epoch 17:\t train loss : 0.5783119995845387; train accuracy : 0.9729951361566344; \n",
      " validation loss : 0.6530873627915249; validation accuracy : 0.8870292887029289\n",
      "Epoch 18:\t train loss : 0.5792975216131833; train accuracy : 0.9717906378760185; \n",
      " validation loss : 0.632839991182722; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.583060826094882; train accuracy : 0.9682065739335172; \n",
      " validation loss : 0.6363814357988195; validation accuracy : 0.9205020920502092\n",
      "Epoch 20:\t train loss : 0.5799481463445306; train accuracy : 0.9712831872114998; \n",
      " validation loss : 0.664911437397142; validation accuracy : 0.8786610878661087\n",
      "Epoch 21:\t train loss : 0.5818012696295733; train accuracy : 0.9694169583940023; \n",
      " validation loss : 0.6167407580685584; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5736795597040245; train accuracy : 0.9778376033953964; \n",
      " validation loss : 0.6302571054664208; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.571547777361824; train accuracy : 0.9797952229003377; \n",
      " validation loss : 0.6149989329373479; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:\t train loss : 0.5719878223196369; train accuracy : 0.9795938535890207; \n",
      " validation loss : 0.6322585358413135; validation accuracy : 0.9163179916317992\n",
      "Epoch 25:\t train loss : 0.5725097158243676; train accuracy : 0.9786954366616066; \n",
      " validation loss : 0.6548800383886944; validation accuracy : 0.899581589958159\n",
      "Epoch 26:\t train loss : 0.5731494875131797; train accuracy : 0.9779925028656402; \n",
      " validation loss : 0.6218423118052072; validation accuracy : 0.9246861924686193\n",
      "Epoch 27:\t train loss : 0.5813995347781817; train accuracy : 0.9694885219492549; \n",
      " validation loss : 0.6085817656673982; validation accuracy : 0.9456066945606695\n",
      "Epoch 28:\t train loss : 0.57011704625481; train accuracy : 0.9813073515288577; \n",
      " validation loss : 0.6140787820434337; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5681538407531902; train accuracy : 0.9832243873725952; \n",
      " validation loss : 0.612047312055754; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5647690066036423; train accuracy : 0.9866262895380897; \n",
      " validation loss : 0.6084413059976665; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5653927145925379; train accuracy : 0.985944731869017; \n",
      " validation loss : 0.6089754633558778; validation accuracy : 0.9414225941422594\n",
      "Epoch 32:\t train loss : 0.5638111824218588; train accuracy : 0.9873949007094396; \n",
      " validation loss : 0.6161078242996912; validation accuracy : 0.9330543933054394\n",
      "Epoch 33:\t train loss : 0.5759319652386783; train accuracy : 0.9751696149199169; \n",
      " validation loss : 0.6168162963731324; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.5671068099062007; train accuracy : 0.9842467238762044; \n",
      " validation loss : 0.6239828845885064; validation accuracy : 0.9288702928870293\n",
      "Epoch 35:\t train loss : 0.572049608187249; train accuracy : 0.9790960066916571; \n",
      " validation loss : 0.6504571000089638; validation accuracy : 0.895397489539749\n",
      "Epoch 36:\t train loss : 0.5705758873812358; train accuracy : 0.9805446265373773; \n",
      " validation loss : 0.6341432311581018; validation accuracy : 0.9121338912133892\n",
      "Epoch 37:\t train loss : 0.565912175793849; train accuracy : 0.985179838284953; \n",
      " validation loss : 0.6086394837274207; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5657223171898346; train accuracy : 0.9855921806747421; \n",
      " validation loss : 0.6127503360777004; validation accuracy : 0.9330543933054394\n",
      "Epoch 39:\t train loss : 0.5644009231562223; train accuracy : 0.9870231419808544; \n",
      " validation loss : 0.6261316611625044; validation accuracy : 0.9205020920502092\n",
      "Epoch 40:\t train loss : 0.5655408500987156; train accuracy : 0.9857337587905449; \n",
      " validation loss : 0.6125167115852315; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5665342768316501; train accuracy : 0.984519656742774; \n",
      " validation loss : 0.6358328671537753; validation accuracy : 0.9121338912133892\n",
      "Epoch 42:\t train loss : 0.5661642791224392; train accuracy : 0.9851857244648223; \n",
      " validation loss : 0.6274638133395886; validation accuracy : 0.9246861924686193\n",
      "Epoch 43:\t train loss : 0.5723768745909925; train accuracy : 0.9787670002168593; \n",
      " validation loss : 0.5975709133933749; validation accuracy : 0.9456066945606695\n",
      "Epoch 44:\t train loss : 0.5698250459842904; train accuracy : 0.9812608816877846; \n",
      " validation loss : 0.637488358578815; validation accuracy : 0.9163179916317992\n",
      "Epoch 45:\t train loss : 0.5634161361663959; train accuracy : 0.9879429350351622; \n",
      " validation loss : 0.6114151560345845; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5614614547922041; train accuracy : 0.9898540846990304; \n",
      " validation loss : 0.6216999173777461; validation accuracy : 0.9288702928870293\n",
      "Epoch 47:\t train loss : 0.5597894631267778; train accuracy : 0.991474642956721; \n",
      " validation loss : 0.6245380888143316; validation accuracy : 0.9163179916317992\n",
      "Epoch 48:\t train loss : 0.5633693814436491; train accuracy : 0.9878345054059915; \n",
      " validation loss : 0.6176150271087287; validation accuracy : 0.9330543933054394\n",
      "Epoch 49:\t train loss : 0.5640939802620754; train accuracy : 0.9872186251123021; \n",
      " validation loss : 0.6232306058930268; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5634993532537874; train accuracy : 0.9877201895969516; \n",
      " validation loss : 0.6301663762695551; validation accuracy : 0.9205020920502092\n",
      "Epoch 51:\t train loss : 0.5948913543948394; train accuracy : 0.9558883484618482; \n",
      " validation loss : 0.6351379493174582; validation accuracy : 0.9163179916317992\n",
      "Epoch 52:\t train loss : 0.5740359161807932; train accuracy : 0.9768927166269091; \n",
      " validation loss : 0.6369425749713147; validation accuracy : 0.9121338912133892\n",
      "Epoch 53:\t train loss : 0.5647913983751305; train accuracy : 0.9866513832522693; \n",
      " validation loss : 0.6115059498879856; validation accuracy : 0.9414225941422594\n",
      "Epoch 54:\t train loss : 0.5681319749580217; train accuracy : 0.982953003500728; \n",
      " validation loss : 0.6174388917859167; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.566081597312852; train accuracy : 0.9853288515753276; \n",
      " validation loss : 0.6234448070896373; validation accuracy : 0.9288702928870293\n",
      "Epoch 56:\t train loss : 0.565773345714998; train accuracy : 0.9854837510455714; \n",
      " validation loss : 0.6321180214220566; validation accuracy : 0.9205020920502092\n",
      "Epoch 57:\t train loss : 0.5673006687030396; train accuracy : 0.9839465287028718; \n",
      " validation loss : 0.6080949603179318; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5659101276168185; train accuracy : 0.9852882679141237; \n",
      " validation loss : 0.6426928145706738; validation accuracy : 0.9037656903765691\n",
      "Epoch 59:\t train loss : 0.5658004942780717; train accuracy : 0.985179838284953; \n",
      " validation loss : 0.6073848012997634; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5648802812818349; train accuracy : 0.9862892282908392; \n",
      " validation loss : 0.6164904150020101; validation accuracy : 0.9330543933054394\n",
      "Epoch 61:\t train loss : 0.5636467871247273; train accuracy : 0.9874915579788717; \n",
      " validation loss : 0.6138018858728674; validation accuracy : 0.9372384937238494\n",
      "Epoch 62:\t train loss : 0.5701019604702258; train accuracy : 0.9810595123764677; \n",
      " validation loss : 0.6208521840432838; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5606925804454097; train accuracy : 0.9907097493726571; \n",
      " validation loss : 0.6027635952390832; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5625374603282954; train accuracy : 0.9887425261005607; \n",
      " validation loss : 0.6048818800747782; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.56305603587957; train accuracy : 0.9881656804733728; \n",
      " validation loss : 0.6007483799698203; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5625626031341835; train accuracy : 0.9885448743765296; \n",
      " validation loss : 0.6083401459517792; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5616667243017957; train accuracy : 0.98965054679513; \n",
      " validation loss : 0.620402119109055; validation accuracy : 0.9288702928870293\n",
      "Epoch 68:\t train loss : 0.5645089218743211; train accuracy : 0.9865178599089192; \n",
      " validation loss : 0.615453546387155; validation accuracy : 0.9330543933054394\n",
      "Epoch 69:\t train loss : 0.563705930874293; train accuracy : 0.9875092165184796; \n",
      " validation loss : 0.6281400367835187; validation accuracy : 0.9205020920502092\n",
      "Epoch 70:\t train loss : 0.5642365751280279; train accuracy : 0.9868778462777658; \n",
      " validation loss : 0.6220975438133549; validation accuracy : 0.9288702928870293\n",
      "Epoch 71:\t train loss : 0.5611279171371708; train accuracy : 0.9901521112797794; \n",
      " validation loss : 0.6317821845746093; validation accuracy : 0.9163179916317992\n",
      "Epoch 72:\t train loss : 0.569389271889395; train accuracy : 0.9816053781096069; \n",
      " validation loss : 0.6264828462021949; validation accuracy : 0.9205020920502092\n",
      "Epoch 73:\t train loss : 0.5634162579841735; train accuracy : 0.9878558815328852; \n",
      " validation loss : 0.6038357487146054; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.5590849950848226; train accuracy : 0.9923730598841352; \n",
      " validation loss : 0.606407712916885; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75:\t train loss : 0.5597073092735867; train accuracy : 0.9914901329037454; \n",
      " validation loss : 0.6255091947642557; validation accuracy : 0.9246861924686193\n",
      "Epoch 76:\t train loss : 0.5610013666426542; train accuracy : 0.9901948635335667; \n",
      " validation loss : 0.6131357361566623; validation accuracy : 0.9372384937238494\n",
      "Epoch 77:\t train loss : 0.5591763327264845; train accuracy : 0.9921695219802348; \n",
      " validation loss : 0.6361343835163107; validation accuracy : 0.9163179916317992\n",
      "Epoch 78:\t train loss : 0.5606113125667513; train accuracy : 0.9907289569069674; \n",
      " validation loss : 0.6077300819996609; validation accuracy : 0.9456066945606695\n",
      "Epoch 79:\t train loss : 0.5633824910527381; train accuracy : 0.9877415657238452; \n",
      " validation loss : 0.6173701223807236; validation accuracy : 0.9330543933054394\n",
      "Epoch 80:\t train loss : 0.5586611253713918; train accuracy : 0.992729328665696; \n",
      " validation loss : 0.607638247698922; validation accuracy : 0.9456066945606695\n",
      "Epoch 81:\t train loss : 0.5569490310214633; train accuracy : 0.994392639177174; \n",
      " validation loss : 0.6059506183178959; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5583807691030674; train accuracy : 0.992940301744168; \n",
      " validation loss : 0.6145341436248496; validation accuracy : 0.9372384937238494\n",
      "Epoch 83:\t train loss : 0.5718918402879063; train accuracy : 0.9793320734843087; \n",
      " validation loss : 0.6081374139101159; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5643620498703854; train accuracy : 0.9868180550822516; \n",
      " validation loss : 0.5974534047226918; validation accuracy : 0.9539748953974896\n",
      "Epoch 85:\t train loss : 0.5604979972046935; train accuracy : 0.9907930852876483; \n",
      " validation loss : 0.6153971316978967; validation accuracy : 0.9330543933054394\n",
      "Epoch 86:\t train loss : 0.5589891086316724; train accuracy : 0.992367173704266; \n",
      " validation loss : 0.6181947798034584; validation accuracy : 0.9330543933054394\n",
      "Epoch 87:\t train loss : 0.5574650902931904; train accuracy : 0.9937671551163295; \n",
      " validation loss : 0.6152632348304033; validation accuracy : 0.9372384937238494\n",
      "Epoch 88:\t train loss : 0.5644863400682804; train accuracy : 0.9867811890083336; \n",
      " validation loss : 0.6044627758884541; validation accuracy : 0.9456066945606695\n",
      "Epoch 89:\t train loss : 0.5587579288926738; train accuracy : 0.9925840329626072; \n",
      " validation loss : 0.6105897881547682; validation accuracy : 0.9414225941422594\n",
      "Epoch 90:\t train loss : 0.5601374603111792; train accuracy : 0.9911397503020539; \n",
      " validation loss : 0.5918424415106982; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5586692198964532; train accuracy : 0.9926924625917779; \n",
      " validation loss : 0.6126594761182655; validation accuracy : 0.9372384937238494\n",
      "Epoch 92:\t train loss : 0.5573815312236369; train accuracy : 0.9938387186715821; \n",
      " validation loss : 0.603058417016149; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5616771926639166; train accuracy : 0.9894919297376003; \n",
      " validation loss : 0.6014565384798952; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5626324067508848; train accuracy : 0.9885005731280398; \n",
      " validation loss : 0.6108415764143649; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.5584390948737983; train accuracy : 0.9927816846866384; \n",
      " validation loss : 0.6101505430898458; validation accuracy : 0.9414225941422594\n",
      "Epoch 96:\t train loss : 0.5567958309173093; train accuracy : 0.9945785185414666; \n",
      " validation loss : 0.6056950237863582; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.558618478334667; train accuracy : 0.9925877505498931; \n",
      " validation loss : 0.6032832948496619; validation accuracy : 0.9456066945606695\n",
      "Epoch 98:\t train loss : 0.5569580720941115; train accuracy : 0.9944177328913535; \n",
      " validation loss : 0.597201293499516; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5583286586751873; train accuracy : 0.992990489172527; \n",
      " validation loss : 0.609241828155786; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5583762933293467; train accuracy : 0.9930332414263143; \n",
      " validation loss : 0.6057915594115587; validation accuracy : 0.9456066945606695\n",
      "Epoch 101:\t train loss : 0.5599578351502248; train accuracy : 0.991387589454444; \n",
      " validation loss : 0.6016013128926874; validation accuracy : 0.9497907949790795\n",
      "Epoch 102:\t train loss : 0.5607943194837496; train accuracy : 0.9903962328448837; \n",
      " validation loss : 0.6216272687772904; validation accuracy : 0.9288702928870293\n",
      "Epoch 103:\t train loss : 0.559754393038073; train accuracy : 0.9916140524799405; \n",
      " validation loss : 0.6172961052840327; validation accuracy : 0.9330543933054394\n",
      "Epoch 104:\t train loss : 0.5613240255390239; train accuracy : 0.9898791784132098; \n",
      " validation loss : 0.6243513707004394; validation accuracy : 0.9288702928870293\n",
      "Epoch 105:\t train loss : 0.5588119936595021; train accuracy : 0.9924483410266737; \n",
      " validation loss : 0.5985647965094862; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.5576395339735716; train accuracy : 0.993705195328232; \n",
      " validation loss : 0.5906925238159639; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5564105112737896; train accuracy : 0.9949753709842312; \n",
      " validation loss : 0.5864677393720445; validation accuracy : 0.9665271966527197\n",
      "Epoch 108:\t train loss : 0.5586171551592163; train accuracy : 0.992766194739614; \n",
      " validation loss : 0.5936400242201872; validation accuracy : 0.9581589958158996\n",
      "Epoch 109:\t train loss : 0.5583142318915943; train accuracy : 0.9929616778710617; \n",
      " validation loss : 0.5963261047204028; validation accuracy : 0.9539748953974896\n",
      "Epoch 110:\t train loss : 0.5565091497370699; train accuracy : 0.9949192973760029; \n",
      " validation loss : 0.5952762337011726; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.5559126307645414; train accuracy : 0.9954924254159051; \n",
      " validation loss : 0.6184101211875467; validation accuracy : 0.9330543933054394\n",
      "Epoch 112:\t train loss : 0.5580890352484384; train accuracy : 0.9931689333622479; \n",
      " validation loss : 0.6371162069233597; validation accuracy : 0.9163179916317992\n",
      "Epoch 113:\t train loss : 0.5595776302399967; train accuracy : 0.9916487499612752; \n",
      " validation loss : 0.6147139449607261; validation accuracy : 0.9330543933054394\n",
      "Epoch 114:\t train loss : 0.5576361938835124; train accuracy : 0.9936432355401345; \n",
      " validation loss : 0.6176085154189094; validation accuracy : 0.9288702928870293\n",
      "Epoch 115:\t train loss : 0.5667998003315051; train accuracy : 0.9843957371665789; \n",
      " validation loss : 0.612327165354791; validation accuracy : 0.9372384937238494\n",
      "Epoch 116:\t train loss : 0.5569894539593508; train accuracy : 0.9943712630502803; \n",
      " validation loss : 0.6018248147151976; validation accuracy : 0.9497907949790795\n",
      "Epoch 117:\t train loss : 0.5569957943701854; train accuracy : 0.9943247932092072; \n",
      " validation loss : 0.6121873268840979; validation accuracy : 0.9372384937238494\n",
      "Epoch 118:\t train loss : 0.5587004006539112; train accuracy : 0.9925995229096316; \n",
      " validation loss : 0.6341168830175239; validation accuracy : 0.9163179916317992\n",
      "Epoch 119:\t train loss : 0.5581290002956978; train accuracy : 0.9932655906316801; \n",
      " validation loss : 0.6072817173376969; validation accuracy : 0.9456066945606695\n",
      "Epoch 120:\t train loss : 0.5653539917910342; train accuracy : 0.9858149261129527; \n",
      " validation loss : 0.59861858097383; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5577843207670351; train accuracy : 0.9936491217200037; \n",
      " validation loss : 0.6115658275771537; validation accuracy : 0.9414225941422594\n",
      "Epoch 122:\t train loss : 0.5578767328384442; train accuracy : 0.9934632423557112; \n",
      " validation loss : 0.6016719023046164; validation accuracy : 0.9497907949790795\n",
      "Epoch 123:\t train loss : 0.5578391595241932; train accuracy : 0.9934787323027355; \n",
      " validation loss : 0.6014880609786744; validation accuracy : 0.9497907949790795\n",
      "Epoch 124:\t train loss : 0.5550144459413676; train accuracy : 0.9963635800365562; \n",
      " validation loss : 0.6100953394041208; validation accuracy : 0.9414225941422594\n",
      "Epoch 125:\t train loss : 0.5564943945918426; train accuracy : 0.9948049815669631; \n",
      " validation loss : 0.6004811727906322; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126:\t train loss : 0.5591882812619045; train accuracy : 0.9921252207317451; \n",
      " validation loss : 0.5998131994475101; validation accuracy : 0.9497907949790795\n",
      "Epoch 127:\t train loss : 0.5618076940997985; train accuracy : 0.989435856129372; \n",
      " validation loss : 0.6176683448538278; validation accuracy : 0.9330543933054394\n",
      "Epoch 128:\t train loss : 0.5558554802354012; train accuracy : 0.995445955574832; \n",
      " validation loss : 0.6024993110497059; validation accuracy : 0.9456066945606695\n",
      "Epoch 129:\t train loss : 0.5601857134452504; train accuracy : 0.9911124879952911; \n",
      " validation loss : 0.6035713316780187; validation accuracy : 0.9497907949790795\n",
      "Epoch 130:\t train loss : 0.5563226172404339; train accuracy : 0.9950896867932711; \n",
      " validation loss : 0.6021362954168809; validation accuracy : 0.9456066945606695\n",
      "Epoch 131:\t train loss : 0.5611173037571775; train accuracy : 0.9900960376715512; \n",
      " validation loss : 0.6065245310881673; validation accuracy : 0.9456066945606695\n",
      "Epoch 132:\t train loss : 0.5585714389740452; train accuracy : 0.992742650020137; \n",
      " validation loss : 0.6329594017708589; validation accuracy : 0.9163179916317992\n",
      "Epoch 133:\t train loss : 0.5597418526391388; train accuracy : 0.9915579788717123; \n",
      " validation loss : 0.5944829221057369; validation accuracy : 0.9539748953974896\n",
      "Epoch 134:\t train loss : 0.558442736472365; train accuracy : 0.9928355897022832; \n",
      " validation loss : 0.617784911328751; validation accuracy : 0.9330543933054394\n",
      "Epoch 135:\t train loss : 0.5566816888011364; train accuracy : 0.9947622293131757; \n",
      " validation loss : 0.6028235240960312; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.5577767741038032; train accuracy : 0.9936122556460857; \n",
      " validation loss : 0.6146432285122636; validation accuracy : 0.9372384937238494\n",
      "Epoch 137:\t train loss : 0.5573132819482327; train accuracy : 0.9940363703956132; \n",
      " validation loss : 0.6079136525441076; validation accuracy : 0.9414225941422594\n",
      "Epoch 138:\t train loss : 0.5572549644109878; train accuracy : 0.9939899005545401; \n",
      " validation loss : 0.5772210633234784; validation accuracy : 0.9748953974895398\n",
      "Epoch 139:\t train loss : 0.5567116618118373; train accuracy : 0.9946094984355154; \n",
      " validation loss : 0.6157254245627926; validation accuracy : 0.9330543933054394\n",
      "Epoch 140:\t train loss : 0.5537471970056155; train accuracy : 0.9977229777874159; \n",
      " validation loss : 0.609162104287291; validation accuracy : 0.9414225941422594\n",
      "Epoch 141:\t train loss : 0.5584683841968283; train accuracy : 0.9928318721149973; \n",
      " validation loss : 0.6014523714093569; validation accuracy : 0.9497907949790795\n",
      "Epoch 142:\t train loss : 0.5598392612257157; train accuracy : 0.9915115090306391; \n",
      " validation loss : 0.6159669755461472; validation accuracy : 0.9330543933054394\n",
      "Epoch 143:\t train loss : 0.5583664580008787; train accuracy : 0.9929365841568821; \n",
      " validation loss : 0.6403921671097418; validation accuracy : 0.9121338912133892\n",
      "Epoch 144:\t train loss : 0.5556319425305497; train accuracy : 0.9958022243563927; \n",
      " validation loss : 0.623046646277155; validation accuracy : 0.9288702928870293\n",
      "Epoch 145:\t train loss : 0.5562688459079536; train accuracy : 0.9950838006134018; \n",
      " validation loss : 0.6213717908672365; validation accuracy : 0.9288702928870293\n",
      "Epoch 146:\t train loss : 0.5572817687631447; train accuracy : 0.994067350289662; \n",
      " validation loss : 0.600203728350522; validation accuracy : 0.9497907949790795\n",
      "Epoch 147:\t train loss : 0.5570994611934325; train accuracy : 0.9943247932092072; \n",
      " validation loss : 0.6045064996659403; validation accuracy : 0.9456066945606695\n",
      "Epoch 148:\t train loss : 0.5553425797945162; train accuracy : 0.9960345735617584; \n",
      " validation loss : 0.6007328044072976; validation accuracy : 0.9497907949790795\n",
      "Epoch 149:\t train loss : 0.5546530651476599; train accuracy : 0.9967161312308311; \n",
      " validation loss : 0.6017906224432258; validation accuracy : 0.9497907949790795\n",
      "Epoch 150:\t train loss : 0.5545827537081651; train accuracy : 0.996793580965953; \n",
      " validation loss : 0.6067540613313035; validation accuracy : 0.9456066945606695\n",
      "Epoch 151:\t train loss : 0.557075099368224; train accuracy : 0.9942377397069302; \n",
      " validation loss : 0.5975378954556712; validation accuracy : 0.9539748953974896\n",
      "Epoch 152:\t train loss : 0.5576100793828964; train accuracy : 0.9936742154341832; \n",
      " validation loss : 0.6022274628698825; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.557674012066463; train accuracy : 0.9936004832863472; \n",
      " validation loss : 0.6106921822616431; validation accuracy : 0.9372384937238494\n",
      "Epoch 154:\t train loss : 0.5622065926839664; train accuracy : 0.9890176275597138; \n",
      " validation loss : 0.5911777911333032; validation accuracy : 0.9623430962343096\n",
      "Epoch 155:\t train loss : 0.5573173240867417; train accuracy : 0.9940128256761361; \n",
      " validation loss : 0.5982759560496955; validation accuracy : 0.9539748953974896\n",
      "Epoch 156:\t train loss : 0.5631226617021138; train accuracy : 0.9880727407912265; \n",
      " validation loss : 0.6096522870740703; validation accuracy : 0.9414225941422594\n",
      "Epoch 157:\t train loss : 0.5577215238739504; train accuracy : 0.993618141825955; \n",
      " validation loss : 0.5987437988431553; validation accuracy : 0.9539748953974896\n",
      "Epoch 158:\t train loss : 0.5564683508003717; train accuracy : 0.9948108677468323; \n",
      " validation loss : 0.5978472133131929; validation accuracy : 0.9539748953974896\n",
      "Epoch 159:\t train loss : 0.5565521398609695; train accuracy : 0.994841847640881; \n",
      " validation loss : 0.6205761186517026; validation accuracy : 0.9330543933054394\n",
      "Epoch 160:\t train loss : 0.5571314375732952; train accuracy : 0.9942067598128814; \n",
      " validation loss : 0.602894678217373; validation accuracy : 0.9456066945606695\n",
      "Epoch 161:\t train loss : 0.5586691383667803; train accuracy : 0.9926246166238112; \n",
      " validation loss : 0.6234388362276843; validation accuracy : 0.9246861924686193\n",
      "Epoch 162:\t train loss : 0.5682436533746772; train accuracy : 0.9829337959664178; \n",
      " validation loss : 0.6066951736998764; validation accuracy : 0.9456066945606695\n",
      "Epoch 163:\t train loss : 0.5578873307127327; train accuracy : 0.9933644164936956; \n",
      " validation loss : 0.6012741542196334; validation accuracy : 0.9497907949790795\n",
      "Epoch 164:\t train loss : 0.5550182051396794; train accuracy : 0.9963171101954831; \n",
      " validation loss : 0.5999850785998087; validation accuracy : 0.9497907949790795\n",
      "Epoch 165:\t train loss : 0.55832448808722; train accuracy : 0.9929675640509309; \n",
      " validation loss : 0.5940941745130347; validation accuracy : 0.9581589958158996\n",
      "Epoch 166:\t train loss : 0.5555871459758251; train accuracy : 0.9957963381765235; \n",
      " validation loss : 0.601179565807738; validation accuracy : 0.9497907949790795\n",
      "Epoch 167:\t train loss : 0.5553815378782093; train accuracy : 0.9960382911490443; \n",
      " validation loss : 0.5937847756018232; validation accuracy : 0.9581589958158996\n",
      "Epoch 168:\t train loss : 0.5540442825433587; train accuracy : 0.9973202391647821; \n",
      " validation loss : 0.6101202664595134; validation accuracy : 0.9414225941422594\n",
      "Epoch 169:\t train loss : 0.5540878887346945; train accuracy : 0.9972774869109947; \n",
      " validation loss : 0.5897813539393055; validation accuracy : 0.9581589958158996\n",
      "Epoch 170:\t train loss : 0.5555065071706485; train accuracy : 0.9959047678056941; \n",
      " validation loss : 0.5898723687582397; validation accuracy : 0.9623430962343096\n",
      "Epoch 171:\t train loss : 0.557837377185982; train accuracy : 0.9934359800489482; \n",
      " validation loss : 0.6485242699323946; validation accuracy : 0.895397489539749\n",
      "Epoch 172:\t train loss : 0.5625265351175428; train accuracy : 0.9886864524923324; \n",
      " validation loss : 0.6102050412174881; validation accuracy : 0.9414225941422594\n",
      "Epoch 173:\t train loss : 0.556776001617195; train accuracy : 0.994594008488491; \n",
      " validation loss : 0.6180132043576855; validation accuracy : 0.9330543933054394\n",
      "Epoch 174:\t train loss : 0.5576154568383686; train accuracy : 0.9937110815081013; \n",
      " validation loss : 0.5972951758417988; validation accuracy : 0.9539748953974896\n",
      "Epoch 175:\t train loss : 0.5603817648776527; train accuracy : 0.9910003407788345; \n",
      " validation loss : 0.5992547799222139; validation accuracy : 0.9539748953974896\n",
      "Epoch 176:\t train loss : 0.5580650554820948; train accuracy : 0.9933334365996468; \n",
      " validation loss : 0.6305973509900491; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177:\t train loss : 0.5591855068144777; train accuracy : 0.9921097307847208; \n",
      " validation loss : 0.5976806659716715; validation accuracy : 0.9539748953974896\n",
      "Epoch 178:\t train loss : 0.5595665656510623; train accuracy : 0.991763065770315; \n",
      " validation loss : 0.5994438022681013; validation accuracy : 0.9497907949790795\n",
      "Epoch 179:\t train loss : 0.556430410301457; train accuracy : 0.9949192973760029; \n",
      " validation loss : 0.6145537011863971; validation accuracy : 0.9372384937238494\n",
      "Epoch 180:\t train loss : 0.5570259050815513; train accuracy : 0.9943616592831253; \n",
      " validation loss : 0.5941980452557054; validation accuracy : 0.9539748953974896\n",
      "Epoch 181:\t train loss : 0.5564939684609487; train accuracy : 0.9948883174819542; \n",
      " validation loss : 0.594951374495841; validation accuracy : 0.9539748953974896\n",
      "Epoch 182:\t train loss : 0.5555112310198304; train accuracy : 0.9958486941974658; \n",
      " validation loss : 0.5975053559982918; validation accuracy : 0.9539748953974896\n",
      "Epoch 183:\t train loss : 0.5570867313400352; train accuracy : 0.9942222497599058; \n",
      " validation loss : 0.6084752879729811; validation accuracy : 0.9414225941422594\n",
      "Epoch 184:\t train loss : 0.5546426253800362; train accuracy : 0.9967412249450107; \n",
      " validation loss : 0.5936153588183832; validation accuracy : 0.9581589958158996\n",
      "Epoch 185:\t train loss : 0.5539444765895237; train accuracy : 0.9974751386350259; \n",
      " validation loss : 0.6086976656939546; validation accuracy : 0.9372384937238494\n",
      "Epoch 186:\t train loss : 0.5711228824097302; train accuracy : 0.9799346324235572; \n",
      " validation loss : 0.6308382613851461; validation accuracy : 0.9163179916317992\n",
      "Epoch 187:\t train loss : 0.5692498992558637; train accuracy : 0.9817838222993277; \n",
      " validation loss : 0.6222260730164586; validation accuracy : 0.9246861924686193\n",
      "Epoch 188:\t train loss : 0.5577552995161691; train accuracy : 0.9935502958579882; \n",
      " validation loss : 0.6102030511014338; validation accuracy : 0.9414225941422594\n",
      "Early stopping at epoch 188\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5572549644109878; Train accuracy : 0.9939899005545401; \n",
      " Validation loss : 0.5772210633234784; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 23 ! ---\n",
      "Epoch 1:\t train loss : 0.9642998884744114; train accuracy : 0.5551373958301062; \n",
      " validation loss : 0.8619927862713108; validation accuracy : 0.6652719665271967\n",
      "Epoch 2:\t train loss : 0.795606081750128; train accuracy : 0.7512574738994393; \n",
      " validation loss : 0.7692693062549298; validation accuracy : 0.7740585774058577\n",
      "Epoch 3:\t train loss : 0.7237948473862452; train accuracy : 0.8257758914464512; \n",
      " validation loss : 0.7260938020814319; validation accuracy : 0.8242677824267782\n",
      "Epoch 4:\t train loss : 0.6929881557318671; train accuracy : 0.8569010811983023; \n",
      " validation loss : 0.7213674219090462; validation accuracy : 0.8158995815899581\n",
      "Epoch 5:\t train loss : 0.6731266526227808; train accuracy : 0.8777623222528579; \n",
      " validation loss : 0.7145024002257838; validation accuracy : 0.8368200836820083\n",
      "Epoch 6:\t train loss : 0.6596926563290941; train accuracy : 0.890261160506831; \n",
      " validation loss : 0.6869476420349975; validation accuracy : 0.8535564853556485\n",
      "Epoch 7:\t train loss : 0.6401563542651635; train accuracy : 0.9110096347470492; \n",
      " validation loss : 0.6776802746222534; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6321406741606793; train accuracy : 0.9183946218903931; \n",
      " validation loss : 0.6838553942291312; validation accuracy : 0.8535564853556485\n",
      "Epoch 9:\t train loss : 0.6188850491135899; train accuracy : 0.9320604727531832; \n",
      " validation loss : 0.6396087132894218; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.6105597209820932; train accuracy : 0.940727407912265; \n",
      " validation loss : 0.6675365040490122; validation accuracy : 0.8786610878661087\n",
      "Epoch 11:\t train loss : 0.6068587456266844; train accuracy : 0.9443365655689457; \n",
      " validation loss : 0.6389070658622926; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.5986618995536186; train accuracy : 0.9526701570680628; \n",
      " validation loss : 0.6321350732095611; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.6027731146738721; train accuracy : 0.9479088571517086; \n",
      " validation loss : 0.6352428552085838; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5959982250331104; train accuracy : 0.9552377706868243; \n",
      " validation loss : 0.6458266994145421; validation accuracy : 0.899581589958159\n",
      "Epoch 15:\t train loss : 0.5940364225276534; train accuracy : 0.9570810743827256; \n",
      " validation loss : 0.6485064683267115; validation accuracy : 0.9037656903765691\n",
      "Epoch 16:\t train loss : 0.5886392620732409; train accuracy : 0.9624752935344961; \n",
      " validation loss : 0.6475451478186546; validation accuracy : 0.9037656903765691\n",
      "Epoch 17:\t train loss : 0.5852787282737462; train accuracy : 0.9662179745345271; \n",
      " validation loss : 0.6390507429697135; validation accuracy : 0.9121338912133892\n",
      "Epoch 18:\t train loss : 0.5813693097874977; train accuracy : 0.9696161591127358; \n",
      " validation loss : 0.6182177963870243; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5873576574659101; train accuracy : 0.9638346912853558; \n",
      " validation loss : 0.6381476650898625; validation accuracy : 0.9121338912133892\n",
      "Epoch 20:\t train loss : 0.5847727789082503; train accuracy : 0.9664562099197621; \n",
      " validation loss : 0.6317847202023785; validation accuracy : 0.9205020920502092\n",
      "Epoch 21:\t train loss : 0.5810788867798374; train accuracy : 0.9701796833854828; \n",
      " validation loss : 0.6032893068254732; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5786214646664979; train accuracy : 0.9723888596301; \n",
      " validation loss : 0.6144327786179515; validation accuracy : 0.9288702928870293\n",
      "Epoch 23:\t train loss : 0.5856848374894945; train accuracy : 0.965456798537749; \n",
      " validation loss : 0.6496112576023858; validation accuracy : 0.899581589958159\n",
      "Epoch 24:\t train loss : 0.584675275047295; train accuracy : 0.9663632702376158; \n",
      " validation loss : 0.628244446378014; validation accuracy : 0.9205020920502092\n",
      "Epoch 25:\t train loss : 0.5764880806422158; train accuracy : 0.9747145202763406; \n",
      " validation loss : 0.6077224564361481; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.571829630681087; train accuracy : 0.97948542395985; \n",
      " validation loss : 0.6343886379421145; validation accuracy : 0.9121338912133892\n",
      "Epoch 27:\t train loss : 0.5893566011741701; train accuracy : 0.9613268688621085; \n",
      " validation loss : 0.6341077968354346; validation accuracy : 0.9163179916317992\n",
      "Epoch 28:\t train loss : 0.5775566608713002; train accuracy : 0.9735815855509774; \n",
      " validation loss : 0.6336719988812234; validation accuracy : 0.9163179916317992\n",
      "Epoch 29:\t train loss : 0.5713157242285752; train accuracy : 0.9800040273862264; \n",
      " validation loss : 0.6112264268933284; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.5723426903610808; train accuracy : 0.9787477926825491; \n",
      " validation loss : 0.613964086761586; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5687902566181537; train accuracy : 0.9822736144242387; \n",
      " validation loss : 0.622472755498515; validation accuracy : 0.9288702928870293\n",
      "Epoch 32:\t train loss : 0.570577674711155; train accuracy : 0.9805985315530221; \n",
      " validation loss : 0.628764883447955; validation accuracy : 0.9205020920502092\n",
      "Epoch 33:\t train loss : 0.5746045570566933; train accuracy : 0.9765946900461601; \n",
      " validation loss : 0.6223904407563792; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.5668600095152447; train accuracy : 0.984203971622417; \n",
      " validation loss : 0.6202148033107081; validation accuracy : 0.9288702928870293\n",
      "Epoch 35:\t train loss : 0.5675197476137179; train accuracy : 0.9838978902692153; \n",
      " validation loss : 0.6418404251807072; validation accuracy : 0.9037656903765691\n",
      "Epoch 36:\t train loss : 0.5747267694427679; train accuracy : 0.9761182192756901; \n",
      " validation loss : 0.6354275158438956; validation accuracy : 0.9121338912133892\n",
      "Epoch 37:\t train loss : 0.5721790235067137; train accuracy : 0.9788599398990055; \n",
      " validation loss : 0.6281764007702477; validation accuracy : 0.9163179916317992\n",
      "Epoch 38:\t train loss : 0.5693434525234172; train accuracy : 0.9818302921404009; \n",
      " validation loss : 0.6496521374230152; validation accuracy : 0.899581589958159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39:\t train loss : 0.5826211363537798; train accuracy : 0.9679432448341027; \n",
      " validation loss : 0.6245419146158349; validation accuracy : 0.9246861924686193\n",
      "Epoch 40:\t train loss : 0.5870894298990953; train accuracy : 0.9636488119210632; \n",
      " validation loss : 0.6533338703221071; validation accuracy : 0.895397489539749\n",
      "Epoch 41:\t train loss : 0.5718950898978646; train accuracy : 0.9793150345425818; \n",
      " validation loss : 0.6053767941574645; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.5644185850241841; train accuracy : 0.9869574646054711; \n",
      " validation loss : 0.5936447481170835; validation accuracy : 0.9581589958158996\n",
      "Epoch 43:\t train loss : 0.5640231963377239; train accuracy : 0.9873152823817343; \n",
      " validation loss : 0.6174229485156159; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5662012951980371; train accuracy : 0.985092784782676; \n",
      " validation loss : 0.6162639538782871; validation accuracy : 0.9330543933054394\n",
      "Epoch 45:\t train loss : 0.6278172015745342; train accuracy : 0.9215604572632362; \n",
      " validation loss : 0.7006009036996058; validation accuracy : 0.8535564853556485\n",
      "Epoch 46:\t train loss : 0.6006132151814743; train accuracy : 0.9498162892282909; \n",
      " validation loss : 0.6201899153832987; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.5775970574463754; train accuracy : 0.9737231636667802; \n",
      " validation loss : 0.6058800187565255; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5730879736422047; train accuracy : 0.9780677840081787; \n",
      " validation loss : 0.6127351680926295; validation accuracy : 0.9330543933054394\n",
      "Epoch 49:\t train loss : 0.5670216534530125; train accuracy : 0.9842098578022863; \n",
      " validation loss : 0.6152668973952793; validation accuracy : 0.9330543933054394\n",
      "Epoch 50:\t train loss : 0.5691668592784308; train accuracy : 0.9820471513987422; \n",
      " validation loss : 0.6240464014345342; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.5682455558444446; train accuracy : 0.9829551720933114; \n",
      " validation loss : 0.6258354110288832; validation accuracy : 0.9246861924686193\n",
      "Epoch 52:\t train loss : 0.5656108856195867; train accuracy : 0.9857743424517488; \n",
      " validation loss : 0.6369600785147477; validation accuracy : 0.9163179916317992\n",
      "Epoch 53:\t train loss : 0.5662325954856093; train accuracy : 0.985106106137117; \n",
      " validation loss : 0.6305063009882687; validation accuracy : 0.9163179916317992\n",
      "Epoch 54:\t train loss : 0.5650418316315889; train accuracy : 0.9862641345766597; \n",
      " validation loss : 0.619444582605163; validation accuracy : 0.9288702928870293\n",
      "Epoch 55:\t train loss : 0.5678112855512117; train accuracy : 0.9833365345890517; \n",
      " validation loss : 0.6348370686701816; validation accuracy : 0.9163179916317992\n",
      "Epoch 56:\t train loss : 0.5659867310947715; train accuracy : 0.9852049319991326; \n",
      " validation loss : 0.6280032356437202; validation accuracy : 0.9163179916317992\n",
      "Epoch 57:\t train loss : 0.5648596958215; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.6067227698190786; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5673410619327608; train accuracy : 0.9839074940363703; \n",
      " validation loss : 0.6304664820998437; validation accuracy : 0.9205020920502092\n",
      "Epoch 59:\t train loss : 0.570938955941528; train accuracy : 0.9800777595340624; \n",
      " validation loss : 0.631632853250718; validation accuracy : 0.9163179916317992\n",
      "Epoch 60:\t train loss : 0.5730288612858605; train accuracy : 0.9781415161560147; \n",
      " validation loss : 0.6014045941200555; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5720434608886215; train accuracy : 0.9790746305647635; \n",
      " validation loss : 0.6166572347880873; validation accuracy : 0.9330543933054394\n",
      "Epoch 62:\t train loss : 0.5640461180665569; train accuracy : 0.9871780414510982; \n",
      " validation loss : 0.6215677786453317; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5631653112826243; train accuracy : 0.9880860621456674; \n",
      " validation loss : 0.6031324067484746; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5643751088952592; train accuracy : 0.9869419746584467; \n",
      " validation loss : 0.6287893636271932; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.5709768015374602; train accuracy : 0.9802518665386164; \n",
      " validation loss : 0.6056708488565636; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5669009300465224; train accuracy : 0.9843027974844326; \n",
      " validation loss : 0.607486753677062; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5631217582211371; train accuracy : 0.988184888007683; \n",
      " validation loss : 0.6397856039779093; validation accuracy : 0.9079497907949791\n",
      "Epoch 68:\t train loss : 0.5827082039062046; train accuracy : 0.968273180705722; \n",
      " validation loss : 0.7558418386294142; validation accuracy : 0.7949790794979079\n",
      "Epoch 69:\t train loss : 0.5931694770975249; train accuracy : 0.9574469469314415; \n",
      " validation loss : 0.6205645869299498; validation accuracy : 0.9288702928870293\n",
      "Epoch 70:\t train loss : 0.579278362848049; train accuracy : 0.9718584838439852; \n",
      " validation loss : 0.5916414442873735; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5676545392733696; train accuracy : 0.9835475076675237; \n",
      " validation loss : 0.5990739825655143; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5712163006000093; train accuracy : 0.9797193221599182; \n",
      " validation loss : 0.6200059453637067; validation accuracy : 0.9288702928870293\n",
      "Epoch 73:\t train loss : 0.5743898334473293; train accuracy : 0.9764686018773816; \n",
      " validation loss : 0.6084419026616865; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5710872261318186; train accuracy : 0.9799965922116546; \n",
      " validation loss : 0.6200155666192674; validation accuracy : 0.9246861924686193\n",
      "Epoch 75:\t train loss : 0.5636820193341088; train accuracy : 0.9874258806034883; \n",
      " validation loss : 0.6034560322458872; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5614385099524523; train accuracy : 0.9898924997676508; \n",
      " validation loss : 0.6084642293726129; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5654463039502838; train accuracy : 0.9857780600390347; \n",
      " validation loss : 0.604677620267686; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5620577625890273; train accuracy : 0.9893562378016667; \n",
      " validation loss : 0.6029934141238925; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5781040997847156; train accuracy : 0.972891973109452; \n",
      " validation loss : 0.632689310736929; validation accuracy : 0.9205020920502092\n",
      "Epoch 80:\t train loss : 0.5717655583205193; train accuracy : 0.9793962018649897; \n",
      " validation loss : 0.6025404684795432; validation accuracy : 0.9497907949790795\n",
      "Epoch 81:\t train loss : 0.5646486282415414; train accuracy : 0.9865931410514576; \n",
      " validation loss : 0.6102670182283041; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5630786653451304; train accuracy : 0.9883552774249512; \n",
      " validation loss : 0.5920268034782273; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.566797305757865; train accuracy : 0.9844592459493788; \n",
      " validation loss : 0.6113531521238409; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5650820624959126; train accuracy : 0.9861984572012764; \n",
      " validation loss : 0.6265283869376708; validation accuracy : 0.9246861924686193\n",
      "Epoch 85:\t train loss : 0.5638659564914478; train accuracy : 0.9874317667833576; \n",
      " validation loss : 0.6138231973120469; validation accuracy : 0.9330543933054394\n",
      "Epoch 86:\t train loss : 0.570621052407845; train accuracy : 0.9804842157439821; \n",
      " validation loss : 0.6219360615595941; validation accuracy : 0.9288702928870293\n",
      "Epoch 87:\t train loss : 0.5770044387484203; train accuracy : 0.9739710028191704; \n",
      " validation loss : 0.615728067452064; validation accuracy : 0.9330543933054394\n",
      "Epoch 88:\t train loss : 0.5642672865767525; train accuracy : 0.9869899934942222; \n",
      " validation loss : 0.5992819140090302; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5646097677075084; train accuracy : 0.9865407850305152; \n",
      " validation loss : 0.6138811982660576; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90:\t train loss : 0.5642033441491866; train accuracy : 0.9871005917159763; \n",
      " validation loss : 0.6119228910148292; validation accuracy : 0.9372384937238494\n",
      "Epoch 91:\t train loss : 0.5622095012256392; train accuracy : 0.9891570370829331; \n",
      " validation loss : 0.610665501607369; validation accuracy : 0.9372384937238494\n",
      "Epoch 92:\t train loss : 0.5618754739505228; train accuracy : 0.9894801573778618; \n",
      " validation loss : 0.61290614539009; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5648823331677586; train accuracy : 0.986430806406642; \n",
      " validation loss : 0.6153252239782332; validation accuracy : 0.9330543933054394\n",
      "Epoch 94:\t train loss : 0.5669139301779831; train accuracy : 0.9841825954955234; \n",
      " validation loss : 0.619378566372818; validation accuracy : 0.9330543933054394\n",
      "Epoch 95:\t train loss : 0.5640499764677831; train accuracy : 0.9872282288794573; \n",
      " validation loss : 0.6088837119913286; validation accuracy : 0.9414225941422594\n",
      "Epoch 96:\t train loss : 0.5655854687667765; train accuracy : 0.9857278726106756; \n",
      " validation loss : 0.5891609288954858; validation accuracy : 0.9623430962343096\n",
      "Epoch 97:\t train loss : 0.5660332597906735; train accuracy : 0.9851894420521082; \n",
      " validation loss : 0.6224645249768598; validation accuracy : 0.9288702928870293\n",
      "Epoch 98:\t train loss : 0.5670119383288084; train accuracy : 0.9843086836643019; \n",
      " validation loss : 0.6000058149831606; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5615936516727439; train accuracy : 0.989687412869048; \n",
      " validation loss : 0.6052728245357224; validation accuracy : 0.9456066945606695\n",
      "Epoch 100:\t train loss : 0.5677818224157902; train accuracy : 0.983429474271198; \n",
      " validation loss : 0.6207609376380895; validation accuracy : 0.9288702928870293\n",
      "Epoch 101:\t train loss : 0.5635291346223643; train accuracy : 0.9876737197558785; \n",
      " validation loss : 0.6136497995180805; validation accuracy : 0.9372384937238494\n",
      "Epoch 102:\t train loss : 0.5618189387723829; train accuracy : 0.9894764397905759; \n",
      " validation loss : 0.6156222601334824; validation accuracy : 0.9330543933054394\n",
      "Epoch 103:\t train loss : 0.5608772141987789; train accuracy : 0.9904309303262183; \n",
      " validation loss : 0.6159866952450804; validation accuracy : 0.9330543933054394\n",
      "Epoch 104:\t train loss : 0.5903133174569378; train accuracy : 0.9605043526751138; \n",
      " validation loss : 0.6241565541727636; validation accuracy : 0.9205020920502092\n",
      "Epoch 105:\t train loss : 0.574388215570999; train accuracy : 0.9765364478453483; \n",
      " validation loss : 0.5973011624940032; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5669065598582245; train accuracy : 0.9844576969546764; \n",
      " validation loss : 0.5927138029186698; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.5651311467805452; train accuracy : 0.9860258991914248; \n",
      " validation loss : 0.596688653006169; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5611533348335431; train accuracy : 0.9900201369311317; \n",
      " validation loss : 0.5935782470759163; validation accuracy : 0.9539748953974896\n",
      "Epoch 109:\t train loss : 0.5624653614408058; train accuracy : 0.9888413519625763; \n",
      " validation loss : 0.6074998880281978; validation accuracy : 0.9456066945606695\n",
      "Epoch 110:\t train loss : 0.561183650862769; train accuracy : 0.9901676012268038; \n",
      " validation loss : 0.5974232397563051; validation accuracy : 0.9539748953974896\n",
      "Epoch 111:\t train loss : 0.5599707964329704; train accuracy : 0.9913971932215991; \n",
      " validation loss : 0.6302162672846187; validation accuracy : 0.9205020920502092\n",
      "Epoch 112:\t train loss : 0.5602356213152145; train accuracy : 0.9911087704080052; \n",
      " validation loss : 0.5979428167808676; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5618351743665602; train accuracy : 0.9895597757055671; \n",
      " validation loss : 0.6098664842774993; validation accuracy : 0.9414225941422594\n",
      "Epoch 114:\t train loss : 0.5614446594726535; train accuracy : 0.9898578022863161; \n",
      " validation loss : 0.6020004003350092; validation accuracy : 0.9456066945606695\n",
      "Epoch 115:\t train loss : 0.5622805769651383; train accuracy : 0.9889689891260572; \n",
      " validation loss : 0.6345990907622789; validation accuracy : 0.9163179916317992\n",
      "Epoch 116:\t train loss : 0.5848425316211372; train accuracy : 0.9660283775829487; \n",
      " validation loss : 0.6047188909011056; validation accuracy : 0.9497907949790795\n",
      "Epoch 117:\t train loss : 0.5752654184476138; train accuracy : 0.9757154806530561; \n",
      " validation loss : 0.6017112084650063; validation accuracy : 0.9456066945606695\n",
      "Epoch 118:\t train loss : 0.5657604681757775; train accuracy : 0.985582576907587; \n",
      " validation loss : 0.594687471658958; validation accuracy : 0.9581589958158996\n",
      "Epoch 119:\t train loss : 0.5667816188396317; train accuracy : 0.9847151398742217; \n",
      " validation loss : 0.6236388842832674; validation accuracy : 0.9288702928870293\n",
      "Epoch 120:\t train loss : 0.5624012154712221; train accuracy : 0.9890309489141547; \n",
      " validation loss : 0.6039307502973433; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5628328490597106; train accuracy : 0.9883958610861551; \n",
      " validation loss : 0.6192171773663784; validation accuracy : 0.9288702928870293\n",
      "Epoch 122:\t train loss : 0.5593530414920312; train accuracy : 0.9920942408376964; \n",
      " validation loss : 0.6056335774448088; validation accuracy : 0.9456066945606695\n",
      "Epoch 123:\t train loss : 0.5599856878106234; train accuracy : 0.9913662133275504; \n",
      " validation loss : 0.599164440496829; validation accuracy : 0.9539748953974896\n",
      "Epoch 124:\t train loss : 0.559104652799506; train accuracy : 0.992326590043062; \n",
      " validation loss : 0.6066075792207815; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5613279270873418; train accuracy : 0.990049567830478; \n",
      " validation loss : 0.6050991949825272; validation accuracy : 0.9456066945606695\n",
      "Epoch 126:\t train loss : 0.5596356578700057; train accuracy : 0.9917940456643638; \n",
      " validation loss : 0.5861975875932075; validation accuracy : 0.9623430962343096\n",
      "Epoch 127:\t train loss : 0.5607195108073997; train accuracy : 0.9906419034046904; \n",
      " validation loss : 0.6167139450826805; validation accuracy : 0.9330543933054394\n",
      "Epoch 128:\t train loss : 0.5719711781787541; train accuracy : 0.9791232689984201; \n",
      " validation loss : 0.6013964585283694; validation accuracy : 0.9497907949790795\n",
      "Epoch 129:\t train loss : 0.5603578654691554; train accuracy : 0.9909789646519409; \n",
      " validation loss : 0.6218813363665413; validation accuracy : 0.9288702928870293\n",
      "Epoch 130:\t train loss : 0.5606217699743427; train accuracy : 0.9907466154465752; \n",
      " validation loss : 0.5845485701044079; validation accuracy : 0.9665271966527197\n",
      "Epoch 131:\t train loss : 0.5604834708805775; train accuracy : 0.990814461414542; \n",
      " validation loss : 0.6165654377182012; validation accuracy : 0.9330543933054394\n",
      "Epoch 132:\t train loss : 0.5608417366546669; train accuracy : 0.9904464202732427; \n",
      " validation loss : 0.5855650207503654; validation accuracy : 0.9665271966527197\n",
      "Epoch 133:\t train loss : 0.5604515450796582; train accuracy : 0.9909324948108678; \n",
      " validation loss : 0.6060482684317582; validation accuracy : 0.9456066945606695\n",
      "Epoch 134:\t train loss : 0.5637259691110922; train accuracy : 0.9875151026983487; \n",
      " validation loss : 0.6184393342436295; validation accuracy : 0.9288702928870293\n",
      "Epoch 135:\t train loss : 0.5603376077604427; train accuracy : 0.9910158307258589; \n",
      " validation loss : 0.5957918308026222; validation accuracy : 0.9581589958158996\n",
      "Epoch 136:\t train loss : 0.559648128504459; train accuracy : 0.9917069921620868; \n",
      " validation loss : 0.5817022895154276; validation accuracy : 0.9707112970711297\n",
      "Epoch 137:\t train loss : 0.5608669131540482; train accuracy : 0.9903262182843334; \n",
      " validation loss : 0.6089929460405132; validation accuracy : 0.9414225941422594\n",
      "Epoch 138:\t train loss : 0.5619221313562281; train accuracy : 0.9894048762353232; \n",
      " validation loss : 0.6098740929627664; validation accuracy : 0.9414225941422594\n",
      "Epoch 139:\t train loss : 0.5611784830767264; train accuracy : 0.9901579974596487; \n",
      " validation loss : 0.6064326567164361; validation accuracy : 0.9456066945606695\n",
      "Epoch 140:\t train loss : 0.5685481616402446; train accuracy : 0.9826218284333468; \n",
      " validation loss : 0.6249240394724596; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141:\t train loss : 0.5670813613646449; train accuracy : 0.9840955419932463; \n",
      " validation loss : 0.5895150531213277; validation accuracy : 0.9623430962343096\n",
      "Epoch 142:\t train loss : 0.5614591613461885; train accuracy : 0.9898327085721367; \n",
      " validation loss : 0.5864578872025883; validation accuracy : 0.9665271966527197\n",
      "Epoch 143:\t train loss : 0.5608520000787555; train accuracy : 0.9904774001672915; \n",
      " validation loss : 0.6062144751059446; validation accuracy : 0.9456066945606695\n",
      "Epoch 144:\t train loss : 0.5611605069884368; train accuracy : 0.9902295610149013; \n",
      " validation loss : 0.6050334543776147; validation accuracy : 0.9456066945606695\n",
      "Epoch 145:\t train loss : 0.5611944199989406; train accuracy : 0.990086433904396; \n",
      " validation loss : 0.5932072101200374; validation accuracy : 0.9623430962343096\n",
      "Epoch 146:\t train loss : 0.5599921833595033; train accuracy : 0.9912791598252734; \n",
      " validation loss : 0.6012726900341275; validation accuracy : 0.9497907949790795\n",
      "Epoch 147:\t train loss : 0.5616345459952724; train accuracy : 0.9897766349639084; \n",
      " validation loss : 0.5911698876802666; validation accuracy : 0.9623430962343096\n",
      "Epoch 148:\t train loss : 0.5601830129828881; train accuracy : 0.9911162055825768; \n",
      " validation loss : 0.6133803850315553; validation accuracy : 0.9372384937238494\n",
      "Epoch 149:\t train loss : 0.5620726628528193; train accuracy : 0.9892131106911615; \n",
      " validation loss : 0.6130328919190612; validation accuracy : 0.9372384937238494\n",
      "Epoch 150:\t train loss : 0.5612642370012032; train accuracy : 0.9900223055237151; \n",
      " validation loss : 0.5990012865430391; validation accuracy : 0.9539748953974896\n",
      "Epoch 151:\t train loss : 0.5655017218085437; train accuracy : 0.9856541404628396; \n",
      " validation loss : 0.6074454802867373; validation accuracy : 0.9456066945606695\n",
      "Epoch 152:\t train loss : 0.5608454295447973; train accuracy : 0.990498776294185; \n",
      " validation loss : 0.6006824469201066; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.5714883331197631; train accuracy : 0.9797487530592646; \n",
      " validation loss : 0.6188157080785205; validation accuracy : 0.9330543933054394\n",
      "Epoch 154:\t train loss : 0.5636379331091907; train accuracy : 0.9876176461476501; \n",
      " validation loss : 0.5972227586006379; validation accuracy : 0.9539748953974896\n",
      "Epoch 155:\t train loss : 0.5605420924902554; train accuracy : 0.9908587626630316; \n",
      " validation loss : 0.6135558549109484; validation accuracy : 0.9372384937238494\n",
      "Epoch 156:\t train loss : 0.5588071582412718; train accuracy : 0.992651878930574; \n",
      " validation loss : 0.5963102580969242; validation accuracy : 0.9581589958158996\n",
      "Epoch 157:\t train loss : 0.5606374443351315; train accuracy : 0.9907311254995508; \n",
      " validation loss : 0.5945584262135566; validation accuracy : 0.9539748953974896\n",
      "Epoch 158:\t train loss : 0.5598099145380442; train accuracy : 0.9914975680783171; \n",
      " validation loss : 0.6286071913472931; validation accuracy : 0.9246861924686193\n",
      "Epoch 159:\t train loss : 0.5594539381117469; train accuracy : 0.991877381579355; \n",
      " validation loss : 0.5954003279306035; validation accuracy : 0.9539748953974896\n",
      "Epoch 160:\t train loss : 0.5594701054482304; train accuracy : 0.991850119272592; \n",
      " validation loss : 0.6141287721176841; validation accuracy : 0.9372384937238494\n",
      "Epoch 161:\t train loss : 0.5608591230391075; train accuracy : 0.9904464202732427; \n",
      " validation loss : 0.5875077731060414; validation accuracy : 0.9623430962343096\n",
      "Epoch 162:\t train loss : 0.5646257176868151; train accuracy : 0.9867037392732116; \n",
      " validation loss : 0.6122626774402318; validation accuracy : 0.9372384937238494\n",
      "Epoch 163:\t train loss : 0.5640733623601125; train accuracy : 0.9872207937048856; \n",
      " validation loss : 0.5933644701623314; validation accuracy : 0.9581589958158996\n",
      "Epoch 164:\t train loss : 0.5585827500088691; train accuracy : 0.9927603085597447; \n",
      " validation loss : 0.5980182584851201; validation accuracy : 0.9497907949790795\n",
      "Epoch 165:\t train loss : 0.560481195258541; train accuracy : 0.990787199107779; \n",
      " validation loss : 0.6294398171037396; validation accuracy : 0.9205020920502092\n",
      "Epoch 166:\t train loss : 0.5600604281632819; train accuracy : 0.991400910808885; \n",
      " validation loss : 0.5911931001265774; validation accuracy : 0.9581589958158996\n",
      "Epoch 167:\t train loss : 0.5611159134744277; train accuracy : 0.9901926949409833; \n",
      " validation loss : 0.6065929250519005; validation accuracy : 0.9456066945606695\n",
      "Epoch 168:\t train loss : 0.5612856854806053; train accuracy : 0.9899854394497971; \n",
      " validation loss : 0.6084522550736788; validation accuracy : 0.9414225941422594\n",
      "Epoch 169:\t train loss : 0.5602509864720141; train accuracy : 0.9911471854766256; \n",
      " validation loss : 0.5976154369371038; validation accuracy : 0.9539748953974896\n",
      "Epoch 170:\t train loss : 0.5620492209021455; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.588326286662625; validation accuracy : 0.9623430962343096\n",
      "Epoch 171:\t train loss : 0.5594840643188584; train accuracy : 0.9918191393785433; \n",
      " validation loss : 0.6013901917064756; validation accuracy : 0.9497907949790795\n",
      "Epoch 172:\t train loss : 0.5595158741238966; train accuracy : 0.9919238514204282; \n",
      " validation loss : 0.5975234296591093; validation accuracy : 0.9539748953974896\n",
      "Epoch 173:\t train loss : 0.5591520212543917; train accuracy : 0.9922159918213079; \n",
      " validation loss : 0.6103905558158571; validation accuracy : 0.9414225941422594\n",
      "Epoch 174:\t train loss : 0.5596214906460103; train accuracy : 0.9917069921620868; \n",
      " validation loss : 0.5795761256796098; validation accuracy : 0.9707112970711297\n",
      "Epoch 175:\t train loss : 0.5593645656186177; train accuracy : 0.9920728647108027; \n",
      " validation loss : 0.6099107737115979; validation accuracy : 0.9414225941422594\n",
      "Epoch 176:\t train loss : 0.5684047781412964; train accuracy : 0.9826896744013135; \n",
      " validation loss : 0.588405957105219; validation accuracy : 0.9623430962343096\n",
      "Epoch 177:\t train loss : 0.5704396694811522; train accuracy : 0.9808057870442083; \n",
      " validation loss : 0.6105121442934655; validation accuracy : 0.9414225941422594\n",
      "Epoch 178:\t train loss : 0.5612634073244877; train accuracy : 0.9901019238514204; \n",
      " validation loss : 0.5887277812843651; validation accuracy : 0.9623430962343096\n",
      "Epoch 179:\t train loss : 0.5596400899602374; train accuracy : 0.9917069921620868; \n",
      " validation loss : 0.5797268354769504; validation accuracy : 0.9707112970711297\n",
      "Epoch 180:\t train loss : 0.5582269423722395; train accuracy : 0.993178537129403; \n",
      " validation loss : 0.6134848320003192; validation accuracy : 0.9372384937238494\n",
      "Epoch 181:\t train loss : 0.5631218219911682; train accuracy : 0.9882062641345767; \n",
      " validation loss : 0.5853021284936822; validation accuracy : 0.9665271966527197\n",
      "Epoch 182:\t train loss : 0.5585997648115921; train accuracy : 0.9927234424858267; \n",
      " validation loss : 0.5852965447803827; validation accuracy : 0.9665271966527197\n",
      "Epoch 183:\t train loss : 0.5576801174044133; train accuracy : 0.9937671551163295; \n",
      " validation loss : 0.6058741183248765; validation accuracy : 0.9456066945606695\n",
      "Epoch 184:\t train loss : 0.5620591229954279; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.5933491036984311; validation accuracy : 0.9581589958158996\n",
      "Epoch 185:\t train loss : 0.5627986580107105; train accuracy : 0.988423123392918; \n",
      " validation loss : 0.5942062803317038; validation accuracy : 0.9581589958158996\n",
      "Epoch 186:\t train loss : 0.5619618040367373; train accuracy : 0.9894240837696335; \n",
      " validation loss : 0.6171603667335426; validation accuracy : 0.9330543933054394\n",
      "Epoch 187:\t train loss : 0.561157206099465; train accuracy : 0.9901115276185756; \n",
      " validation loss : 0.6036017297422626; validation accuracy : 0.9497907949790795\n",
      "Epoch 188:\t train loss : 0.5608310054013212; train accuracy : 0.990425044146349; \n",
      " validation loss : 0.5976209186871996; validation accuracy : 0.9497907949790795\n",
      "Epoch 189:\t train loss : 0.5612301934672155; train accuracy : 0.9901425075126243; \n",
      " validation loss : 0.5978449553446227; validation accuracy : 0.9539748953974896\n",
      "Epoch 190:\t train loss : 0.5602337212092804; train accuracy : 0.9910409244400384; \n",
      " validation loss : 0.6098232736323561; validation accuracy : 0.9414225941422594\n",
      "Epoch 191:\t train loss : 0.5589602032973845; train accuracy : 0.9923730598841352; \n",
      " validation loss : 0.5990709441581835; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192:\t train loss : 0.564518260257323; train accuracy : 0.9867849065956195; \n",
      " validation loss : 0.6193011856735916; validation accuracy : 0.9330543933054394\n",
      "Epoch 193:\t train loss : 0.5607413191392778; train accuracy : 0.9906168096905108; \n",
      " validation loss : 0.6083433055872692; validation accuracy : 0.9414225941422594\n",
      "Epoch 194:\t train loss : 0.5583030074614528; train accuracy : 0.9930391276061836; \n",
      " validation loss : 0.5968804211082336; validation accuracy : 0.9539748953974896\n",
      "Epoch 195:\t train loss : 0.557937069967703; train accuracy : 0.9934396976362341; \n",
      " validation loss : 0.6108007464934254; validation accuracy : 0.9414225941422594\n",
      "Epoch 196:\t train loss : 0.5597261516821321; train accuracy : 0.9916295424269649; \n",
      " validation loss : 0.605726850718629; validation accuracy : 0.9456066945606695\n",
      "Epoch 197:\t train loss : 0.5592114492764255; train accuracy : 0.9920728647108027; \n",
      " validation loss : 0.6105022173856193; validation accuracy : 0.9414225941422594\n",
      "Epoch 198:\t train loss : 0.5633639675466495; train accuracy : 0.9880278199448558; \n",
      " validation loss : 0.6489568068743979; validation accuracy : 0.899581589958159\n",
      "Epoch 199:\t train loss : 0.5741411553904464; train accuracy : 0.9770321261501286; \n",
      " validation loss : 0.5992857908837532; validation accuracy : 0.9497907949790795\n",
      "Epoch 200:\t train loss : 0.5636974451376321; train accuracy : 0.9876368536819604; \n",
      " validation loss : 0.5927584635767561; validation accuracy : 0.9581589958158996\n",
      "Epoch 201:\t train loss : 0.571423757144203; train accuracy : 0.979736980699526; \n",
      " validation loss : 0.5801141070999715; validation accuracy : 0.9707112970711297\n",
      "Epoch 202:\t train loss : 0.5611417494811582; train accuracy : 0.9902642584962359; \n",
      " validation loss : 0.6188378508203033; validation accuracy : 0.9330543933054394\n",
      "Epoch 203:\t train loss : 0.558855415191304; train accuracy : 0.992564825428297; \n",
      " validation loss : 0.6080049253200404; validation accuracy : 0.9414225941422594\n",
      "Epoch 204:\t train loss : 0.5587755866631579; train accuracy : 0.9925434493014034; \n",
      " validation loss : 0.5918455953078122; validation accuracy : 0.9581589958158996\n",
      "Epoch 205:\t train loss : 0.5596173284853069; train accuracy : 0.9917165959292419; \n",
      " validation loss : 0.580925165863181; validation accuracy : 0.9707112970711297\n",
      "Epoch 206:\t train loss : 0.5588311928123427; train accuracy : 0.9925995229096316; \n",
      " validation loss : 0.5953079469536375; validation accuracy : 0.9539748953974896\n",
      "Epoch 207:\t train loss : 0.5600795871991692; train accuracy : 0.991263669878249; \n",
      " validation loss : 0.598033175514085; validation accuracy : 0.9539748953974896\n",
      "Epoch 208:\t train loss : 0.5576355500076786; train accuracy : 0.9937981350103783; \n",
      " validation loss : 0.595758529850919; validation accuracy : 0.9539748953974896\n",
      "Epoch 209:\t train loss : 0.558043777433218; train accuracy : 0.9933526441339571; \n",
      " validation loss : 0.60523130118939; validation accuracy : 0.9456066945606695\n",
      "Epoch 210:\t train loss : 0.5595947418053182; train accuracy : 0.9917881594844945; \n",
      " validation loss : 0.5993280790747983; validation accuracy : 0.9497907949790795\n",
      "Epoch 211:\t train loss : 0.5584551727834606; train accuracy : 0.9929056042628334; \n",
      " validation loss : 0.6224909064000964; validation accuracy : 0.9288702928870293\n",
      "Epoch 212:\t train loss : 0.5597996233301087; train accuracy : 0.99163914619412; \n",
      " validation loss : 0.6246651797402758; validation accuracy : 0.9246861924686193\n",
      "Epoch 213:\t train loss : 0.5603383683714858; train accuracy : 0.9910350382601691; \n",
      " validation loss : 0.6114380652210644; validation accuracy : 0.9372384937238494\n",
      "Epoch 214:\t train loss : 0.5602209720348539; train accuracy : 0.9910777905139564; \n",
      " validation loss : 0.5996507674393672; validation accuracy : 0.9539748953974896\n",
      "Epoch 215:\t train loss : 0.5582653129602269; train accuracy : 0.9931571610025094; \n",
      " validation loss : 0.5895528499993337; validation accuracy : 0.9623430962343096\n",
      "Epoch 216:\t train loss : 0.5583596103005382; train accuracy : 0.9929557916911924; \n",
      " validation loss : 0.6053780737119991; validation accuracy : 0.9456066945606695\n",
      "Epoch 217:\t train loss : 0.5639196267567504; train accuracy : 0.9873698069952601; \n",
      " validation loss : 0.6012176420561129; validation accuracy : 0.9497907949790795\n",
      "Epoch 218:\t train loss : 0.5594934900338124; train accuracy : 0.9918095356113882; \n",
      " validation loss : 0.5849472593316898; validation accuracy : 0.9665271966527197\n",
      "Epoch 219:\t train loss : 0.5588834000900869; train accuracy : 0.9925124694073546; \n",
      " validation loss : 0.5985792149702344; validation accuracy : 0.9539748953974896\n",
      "Epoch 220:\t train loss : 0.5584571912712898; train accuracy : 0.9929616778710617; \n",
      " validation loss : 0.6105939927109297; validation accuracy : 0.9414225941422594\n",
      "Epoch 221:\t train loss : 0.6011825953966687; train accuracy : 0.9496121317265095; \n",
      " validation loss : 0.6724526302584589; validation accuracy : 0.8786610878661087\n",
      "Epoch 222:\t train loss : 0.5920025889197226; train accuracy : 0.9589708479197001; \n",
      " validation loss : 0.6294552671074722; validation accuracy : 0.9205020920502092\n",
      "Epoch 223:\t train loss : 0.5688977453037696; train accuracy : 0.9824418352489235; \n",
      " validation loss : 0.6489288532924968; validation accuracy : 0.899581589958159\n",
      "Epoch 224:\t train loss : 0.5649572899153649; train accuracy : 0.986357074258806; \n",
      " validation loss : 0.6104692058966628; validation accuracy : 0.9372384937238494\n",
      "Early stopping at epoch 224\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5596214906460103; Train accuracy : 0.9917069921620868; \n",
      " Validation loss : 0.5795761256796098; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 24 ! ---\n",
      "Epoch 1:\t train loss : 0.9246369175168876; train accuracy : 0.6112543759100344; \n",
      " validation loss : 0.8350049620613819; validation accuracy : 0.702928870292887\n",
      "Epoch 2:\t train loss : 0.7621044071619337; train accuracy : 0.7874958951640385; \n",
      " validation loss : 0.752600014963648; validation accuracy : 0.803347280334728\n",
      "Epoch 3:\t train loss : 0.7166707188689395; train accuracy : 0.8338765141423217; \n",
      " validation loss : 0.7292135640571125; validation accuracy : 0.8200836820083682\n",
      "Epoch 4:\t train loss : 0.6885657345958379; train accuracy : 0.8619464667430837; \n",
      " validation loss : 0.6915644282402281; validation accuracy : 0.8619246861924686\n",
      "Epoch 5:\t train loss : 0.6710115903284934; train accuracy : 0.879049536850584; \n",
      " validation loss : 0.6725492829629857; validation accuracy : 0.8786610878661087\n",
      "Epoch 6:\t train loss : 0.6581164464457374; train accuracy : 0.8923516837572415; \n",
      " validation loss : 0.6605192968502079; validation accuracy : 0.891213389121339\n",
      "Epoch 7:\t train loss : 0.6377625754146683; train accuracy : 0.9126840980203847; \n",
      " validation loss : 0.6884015636418127; validation accuracy : 0.8535564853556485\n",
      "Epoch 8:\t train loss : 0.6271032849377961; train accuracy : 0.9233684438799219; \n",
      " validation loss : 0.6638403735558432; validation accuracy : 0.8870292887029289\n",
      "Epoch 9:\t train loss : 0.6279458060351385; train accuracy : 0.9225806251742619; \n",
      " validation loss : 0.658882697345605; validation accuracy : 0.891213389121339\n",
      "Epoch 10:\t train loss : 0.6178194453869343; train accuracy : 0.9333247622293132; \n",
      " validation loss : 0.643112075796848; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.6077910138298038; train accuracy : 0.9432708572136683; \n",
      " validation loss : 0.6446281263762063; validation accuracy : 0.9079497907949791\n",
      "Epoch 12:\t train loss : 0.6093965594405695; train accuracy : 0.9411781653706744; \n",
      " validation loss : 0.6333360381851546; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.6060962024221511; train accuracy : 0.9452675113851111; \n",
      " validation loss : 0.6185581797501966; validation accuracy : 0.9330543933054394\n",
      "Epoch 14:\t train loss : 0.603099926676544; train accuracy : 0.9482592397534001; \n",
      " validation loss : 0.6420696290611645; validation accuracy : 0.9079497907949791\n",
      "Epoch 15:\t train loss : 0.5986128269990534; train accuracy : 0.9525211437776883; \n",
      " validation loss : 0.6217639175408366; validation accuracy : 0.9246861924686193\n",
      "Epoch 16:\t train loss : 0.5986546641870888; train accuracy : 0.9518027200346975; \n",
      " validation loss : 0.613303585005485; validation accuracy : 0.9372384937238494\n",
      "Epoch 17:\t train loss : 0.5917802977055797; train accuracy : 0.9593714179497506; \n",
      " validation loss : 0.6494243179907095; validation accuracy : 0.895397489539749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:\t train loss : 0.584620793511899; train accuracy : 0.9669806995260076; \n",
      " validation loss : 0.5909059560189459; validation accuracy : 0.9581589958158996\n",
      "Epoch 19:\t train loss : 0.5858428919100367; train accuracy : 0.965155054369714; \n",
      " validation loss : 0.637313127724571; validation accuracy : 0.9163179916317992\n",
      "Epoch 20:\t train loss : 0.5917467194187431; train accuracy : 0.9590786579509898; \n",
      " validation loss : 0.6170825775169393; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.594051603074888; train accuracy : 0.9569491000340778; \n",
      " validation loss : 0.6633279258603745; validation accuracy : 0.8828451882845189\n",
      "Epoch 22:\t train loss : 0.5843159153338081; train accuracy : 0.9670795253880231; \n",
      " validation loss : 0.6253515521850308; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.5827244177459991; train accuracy : 0.9687391183122154; \n",
      " validation loss : 0.6113781141488611; validation accuracy : 0.9414225941422594\n",
      "Epoch 24:\t train loss : 0.5907073796104334; train accuracy : 0.960201988909198; \n",
      " validation loss : 0.6387014328574206; validation accuracy : 0.9121338912133892\n",
      "Epoch 25:\t train loss : 0.588762928874628; train accuracy : 0.9624501998203167; \n",
      " validation loss : 0.6527906746587931; validation accuracy : 0.899581589958159\n",
      "Epoch 26:\t train loss : 0.580409050549682; train accuracy : 0.970913597075498; \n",
      " validation loss : 0.6055169092938659; validation accuracy : 0.9456066945606695\n",
      "Epoch 27:\t train loss : 0.5745784043582324; train accuracy : 0.97665819882896; \n",
      " validation loss : 0.6086350978488023; validation accuracy : 0.9456066945606695\n",
      "Epoch 28:\t train loss : 0.5785813426580255; train accuracy : 0.9723637659159206; \n",
      " validation loss : 0.5991279307708774; validation accuracy : 0.9539748953974896\n",
      "Epoch 29:\t train loss : 0.5788655217945033; train accuracy : 0.972013383314229; \n",
      " validation loss : 0.6141739433791282; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5731973870590255; train accuracy : 0.9781046500820967; \n",
      " validation loss : 0.6051446501145693; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5706952508350243; train accuracy : 0.9806685461135723; \n",
      " validation loss : 0.5995524892748397; validation accuracy : 0.9497907949790795\n",
      "Epoch 32:\t train loss : 0.5814981684324023; train accuracy : 0.9694089036215496; \n",
      " validation loss : 0.6153692336181837; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5673508458532998; train accuracy : 0.9839096626289539; \n",
      " validation loss : 0.6143398132696063; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.5658494535630769; train accuracy : 0.9855457108336689; \n",
      " validation loss : 0.5918615743437796; validation accuracy : 0.9623430962343096\n",
      "Epoch 35:\t train loss : 0.5681724152147333; train accuracy : 0.9830577155426129; \n",
      " validation loss : 0.6135902404036653; validation accuracy : 0.9330543933054394\n",
      "Epoch 36:\t train loss : 0.5782407342474513; train accuracy : 0.9728572756281173; \n",
      " validation loss : 0.6081469728626159; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.575479519679239; train accuracy : 0.9756203723783264; \n",
      " validation loss : 0.6206305353816999; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5833045551318202; train accuracy : 0.9675987484122804; \n",
      " validation loss : 0.6066397548830621; validation accuracy : 0.9456066945606695\n",
      "Epoch 39:\t train loss : 0.5756440486635547; train accuracy : 0.9753592118714954; \n",
      " validation loss : 0.611622388497159; validation accuracy : 0.9372384937238494\n",
      "Epoch 40:\t train loss : 0.5684114874848022; train accuracy : 0.9826608630998482; \n",
      " validation loss : 0.6135619241622011; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.564597250651804; train accuracy : 0.9867656990613092; \n",
      " validation loss : 0.5998095766254229; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5694914001534401; train accuracy : 0.981675392670157; \n",
      " validation loss : 0.6082023702999155; validation accuracy : 0.9414225941422594\n",
      "Epoch 43:\t train loss : 0.5666890854562185; train accuracy : 0.9843337773784814; \n",
      " validation loss : 0.5909723780553807; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.5677007851114926; train accuracy : 0.9835069240063199; \n",
      " validation loss : 0.6010832693124557; validation accuracy : 0.9497907949790795\n",
      "Epoch 45:\t train loss : 0.5792574195942695; train accuracy : 0.9718429938969608; \n",
      " validation loss : 0.6068978292812703; validation accuracy : 0.9456066945606695\n",
      "Epoch 46:\t train loss : 0.5671393419436295; train accuracy : 0.984015923665541; \n",
      " validation loss : 0.5926194843788274; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5618990320699035; train accuracy : 0.9895133058644939; \n",
      " validation loss : 0.5846645124912576; validation accuracy : 0.9623430962343096\n",
      "Epoch 48:\t train loss : 0.5630944949207216; train accuracy : 0.9882682239226742; \n",
      " validation loss : 0.6070695394512401; validation accuracy : 0.9456066945606695\n",
      "Epoch 49:\t train loss : 0.5638636682711318; train accuracy : 0.9876582298088541; \n",
      " validation loss : 0.5978077891492325; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5628575978819598; train accuracy : 0.9884888007683014; \n",
      " validation loss : 0.5959583281895369; validation accuracy : 0.9581589958158996\n",
      "Epoch 51:\t train loss : 0.5687677543297602; train accuracy : 0.9825598686452492; \n",
      " validation loss : 0.6012255424207499; validation accuracy : 0.9497907949790795\n",
      "Epoch 52:\t train loss : 0.5688881566468317; train accuracy : 0.9822212584032962; \n",
      " validation loss : 0.6647918742598711; validation accuracy : 0.8870292887029289\n",
      "Epoch 53:\t train loss : 0.5738562480941799; train accuracy : 0.977245267821184; \n",
      " validation loss : 0.622338894977785; validation accuracy : 0.9288702928870293\n",
      "Epoch 54:\t train loss : 0.5659724471103145; train accuracy : 0.9852145357662877; \n",
      " validation loss : 0.5879914123548122; validation accuracy : 0.9623430962343096\n",
      "Epoch 55:\t train loss : 0.564384692356943; train accuracy : 0.9869707859599121; \n",
      " validation loss : 0.582116152075884; validation accuracy : 0.9707112970711297\n",
      "Epoch 56:\t train loss : 0.5662326422611029; train accuracy : 0.9849784689736362; \n",
      " validation loss : 0.6126894417497462; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5680866678745919; train accuracy : 0.9829994733418012; \n",
      " validation loss : 0.6015129976511963; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.5667214069440396; train accuracy : 0.9844208308807584; \n",
      " validation loss : 0.5940062433875852; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5696549176280115; train accuracy : 0.9814371572849221; \n",
      " validation loss : 0.6349311833602266; validation accuracy : 0.9079497907949791\n",
      "Epoch 60:\t train loss : 0.5646256551105432; train accuracy : 0.9864788252424177; \n",
      " validation loss : 0.6053766124349449; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5639088006650141; train accuracy : 0.9874354843706434; \n",
      " validation loss : 0.6030093345642212; validation accuracy : 0.9456066945606695\n",
      "Epoch 62:\t train loss : 0.57281597670064; train accuracy : 0.9782964156262586; \n",
      " validation loss : 0.6006114548789103; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5736992031389465; train accuracy : 0.9774813346138356; \n",
      " validation loss : 0.6078066408676167; validation accuracy : 0.9414225941422594\n",
      "Epoch 64:\t train loss : 0.5688787419527344; train accuracy : 0.9824728151429722; \n",
      " validation loss : 0.6306383900091613; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.5675405753078999; train accuracy : 0.9836057498683355; \n",
      " validation loss : 0.5864439169108298; validation accuracy : 0.9623430962343096\n",
      "Epoch 66:\t train loss : 0.5655897826323933; train accuracy : 0.9855206171194895; \n",
      " validation loss : 0.5911475161812593; validation accuracy : 0.9581589958158996\n",
      "Epoch 67:\t train loss : 0.5644706112176394; train accuracy : 0.9867811890083336; \n",
      " validation loss : 0.5867320103184742; validation accuracy : 0.9623430962343096\n",
      "Epoch 68:\t train loss : 0.5628168117706475; train accuracy : 0.988547042969113; \n",
      " validation loss : 0.5771519536100268; validation accuracy : 0.9748953974895398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:\t train loss : 0.5602693578060014; train accuracy : 0.9910446420273242; \n",
      " validation loss : 0.5816600664376315; validation accuracy : 0.9707112970711297\n",
      "Epoch 70:\t train loss : 0.5587968291259696; train accuracy : 0.9924793209207224; \n",
      " validation loss : 0.600463624316886; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.562607105309184; train accuracy : 0.9885721366832926; \n",
      " validation loss : 0.5906021662941238; validation accuracy : 0.9623430962343096\n",
      "Epoch 72:\t train loss : 0.5680766721630232; train accuracy : 0.9831004677964001; \n",
      " validation loss : 0.6056567561993922; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5672651468617984; train accuracy : 0.9838749651476192; \n",
      " validation loss : 0.6205942769689656; validation accuracy : 0.9330543933054394\n",
      "Epoch 74:\t train loss : 0.5615775529402887; train accuracy : 0.9895325133988042; \n",
      " validation loss : 0.5849513360350761; validation accuracy : 0.9665271966527197\n",
      "Epoch 75:\t train loss : 0.5765384602741125; train accuracy : 0.974252919855014; \n",
      " validation loss : 0.6413025998079555; validation accuracy : 0.9121338912133892\n",
      "Epoch 76:\t train loss : 0.5899258633261072; train accuracy : 0.9609978623873107; \n",
      " validation loss : 0.6211263788349063; validation accuracy : 0.9246861924686193\n",
      "Epoch 77:\t train loss : 0.5712442446360486; train accuracy : 0.9799789336720468; \n",
      " validation loss : 0.621077875930255; validation accuracy : 0.9288702928870293\n",
      "Epoch 78:\t train loss : 0.5703919058211385; train accuracy : 0.9804259735431705; \n",
      " validation loss : 0.5918246688172837; validation accuracy : 0.9581589958158996\n",
      "Epoch 79:\t train loss : 0.5722143201940685; train accuracy : 0.978797980110908; \n",
      " validation loss : 0.5934039475860908; validation accuracy : 0.9581589958158996\n",
      "Epoch 80:\t train loss : 0.5683893362081969; train accuracy : 0.9826741844542892; \n",
      " validation loss : 0.5919631980164876; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5679927181358772; train accuracy : 0.9830945816165308; \n",
      " validation loss : 0.5878899431747603; validation accuracy : 0.9623430962343096\n",
      "Epoch 82:\t train loss : 0.5658835527048443; train accuracy : 0.9851835558722389; \n",
      " validation loss : 0.5868024566987231; validation accuracy : 0.9665271966527197\n",
      "Epoch 83:\t train loss : 0.5638209898667623; train accuracy : 0.9874045044765947; \n",
      " validation loss : 0.5801297793425543; validation accuracy : 0.9707112970711297\n",
      "Epoch 84:\t train loss : 0.5618575877934161; train accuracy : 0.9893097679605936; \n",
      " validation loss : 0.5774706854645522; validation accuracy : 0.9707112970711297\n",
      "Epoch 85:\t train loss : 0.5616112181962933; train accuracy : 0.9897338827101211; \n",
      " validation loss : 0.5662614766903059; validation accuracy : 0.9874476987447699\n",
      "Epoch 86:\t train loss : 0.5624684304310199; train accuracy : 0.9886148889370798; \n",
      " validation loss : 0.5839132918920034; validation accuracy : 0.9623430962343096\n",
      "Epoch 87:\t train loss : 0.5668597692926943; train accuracy : 0.9842969113045633; \n",
      " validation loss : 0.591951708931414; validation accuracy : 0.9581589958158996\n",
      "Epoch 88:\t train loss : 0.5647367387412673; train accuracy : 0.9866668731992937; \n",
      " validation loss : 0.5843271903108249; validation accuracy : 0.9707112970711297\n",
      "Epoch 89:\t train loss : 0.5623743693378306; train accuracy : 0.9888797670311967; \n",
      " validation loss : 0.5892870749178972; validation accuracy : 0.9623430962343096\n",
      "Epoch 90:\t train loss : 0.5623257433327361; train accuracy : 0.9889711577186406; \n",
      " validation loss : 0.5789605527630077; validation accuracy : 0.9707112970711297\n",
      "Epoch 91:\t train loss : 0.5593393398353108; train accuracy : 0.9919954149756808; \n",
      " validation loss : 0.5825513890562857; validation accuracy : 0.9665271966527197\n",
      "Epoch 92:\t train loss : 0.5605573777840623; train accuracy : 0.9907466154465752; \n",
      " validation loss : 0.5967291274650897; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5608505091400735; train accuracy : 0.9903844604851452; \n",
      " validation loss : 0.621286243306913; validation accuracy : 0.9246861924686193\n",
      "Epoch 94:\t train loss : 0.560243757626348; train accuracy : 0.9910409244400384; \n",
      " validation loss : 0.6124080200229404; validation accuracy : 0.9372384937238494\n",
      "Epoch 95:\t train loss : 0.5613091657977546; train accuracy : 0.9899160444871279; \n",
      " validation loss : 0.5864530031441603; validation accuracy : 0.9665271966527197\n",
      "Epoch 96:\t train loss : 0.5705295828862077; train accuracy : 0.9805734378388425; \n",
      " validation loss : 0.5773279735787537; validation accuracy : 0.9748953974895398\n",
      "Epoch 97:\t train loss : 0.5616802840014539; train accuracy : 0.9896874128690479; \n",
      " validation loss : 0.5720526093350665; validation accuracy : 0.9790794979079498\n",
      "Epoch 98:\t train loss : 0.5613108446136517; train accuracy : 0.9899507419684624; \n",
      " validation loss : 0.5814196980264055; validation accuracy : 0.9707112970711297\n",
      "Epoch 99:\t train loss : 0.560046945636074; train accuracy : 0.991313857306608; \n",
      " validation loss : 0.5775971342033069; validation accuracy : 0.9748953974895398\n",
      "Epoch 100:\t train loss : 0.5629523882494155; train accuracy : 0.9882933176368537; \n",
      " validation loss : 0.5806113810352522; validation accuracy : 0.9707112970711297\n",
      "Epoch 101:\t train loss : 0.5621089444100787; train accuracy : 0.9890929087022522; \n",
      " validation loss : 0.5798401321047544; validation accuracy : 0.9707112970711297\n",
      "Epoch 102:\t train loss : 0.5571393889181143; train accuracy : 0.9941853836859877; \n",
      " validation loss : 0.5855763018501686; validation accuracy : 0.9623430962343096\n",
      "Epoch 103:\t train loss : 0.5626316221344462; train accuracy : 0.9887462436878466; \n",
      " validation loss : 0.6118984122307886; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.560395657032588; train accuracy : 0.9909170048638434; \n",
      " validation loss : 0.5686625407243263; validation accuracy : 0.9832635983263598\n",
      "Epoch 105:\t train loss : 0.5606673032698215; train accuracy : 0.9907060317853713; \n",
      " validation loss : 0.5889262643738102; validation accuracy : 0.9623430962343096\n",
      "Epoch 106:\t train loss : 0.562286724261348; train accuracy : 0.9888878218036494; \n",
      " validation loss : 0.604687108039539; validation accuracy : 0.9456066945606695\n",
      "Epoch 107:\t train loss : 0.5596462572744844; train accuracy : 0.9916354286068342; \n",
      " validation loss : 0.6014399715272766; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.5621473258526554; train accuracy : 0.9890795873478113; \n",
      " validation loss : 0.5889883571332732; validation accuracy : 0.9665271966527197\n",
      "Epoch 109:\t train loss : 0.5626968949518774; train accuracy : 0.988510176895195; \n",
      " validation loss : 0.6119162268076164; validation accuracy : 0.9372384937238494\n",
      "Epoch 110:\t train loss : 0.5598063001548783; train accuracy : 0.991474642956721; \n",
      " validation loss : 0.5806624639968074; validation accuracy : 0.9707112970711297\n",
      "Epoch 111:\t train loss : 0.5638430258262744; train accuracy : 0.9873852969422845; \n",
      " validation loss : 0.5739156916910096; validation accuracy : 0.9707112970711297\n",
      "Epoch 112:\t train loss : 0.5608741024725156; train accuracy : 0.9903999504321696; \n",
      " validation loss : 0.5851121876440792; validation accuracy : 0.9665271966527197\n",
      "Epoch 113:\t train loss : 0.5578785591167825; train accuracy : 0.993389510207875; \n",
      " validation loss : 0.567434391034253; validation accuracy : 0.9790794979079498\n",
      "Epoch 114:\t train loss : 0.5584520498237299; train accuracy : 0.9928591344217603; \n",
      " validation loss : 0.5763223859696953; validation accuracy : 0.9748953974895398\n",
      "Epoch 115:\t train loss : 0.5596278757595108; train accuracy : 0.9916354286068342; \n",
      " validation loss : 0.5908672474946003; validation accuracy : 0.9581589958158996\n",
      "Epoch 116:\t train loss : 0.5584778592500729; train accuracy : 0.9929248117971436; \n",
      " validation loss : 0.5913242860534391; validation accuracy : 0.9581589958158996\n",
      "Epoch 117:\t train loss : 0.5635536914457688; train accuracy : 0.9876021562006257; \n",
      " validation loss : 0.5889848023675994; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5622816971177508; train accuracy : 0.9890154589671303; \n",
      " validation loss : 0.5867538314149121; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.5600170646625762; train accuracy : 0.9912924811797144; \n",
      " validation loss : 0.5842692383041497; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120:\t train loss : 0.5610064623437848; train accuracy : 0.9902568233216642; \n",
      " validation loss : 0.5720371167394067; validation accuracy : 0.9790794979079498\n",
      "Epoch 121:\t train loss : 0.5587342542648982; train accuracy : 0.9925995229096316; \n",
      " validation loss : 0.5801928681169509; validation accuracy : 0.9707112970711297\n",
      "Epoch 122:\t train loss : 0.561452329742431; train accuracy : 0.9896254530809504; \n",
      " validation loss : 0.5892569109751896; validation accuracy : 0.9623430962343096\n",
      "Epoch 123:\t train loss : 0.5573601297816712; train accuracy : 0.9939744106075157; \n",
      " validation loss : 0.5715998151337512; validation accuracy : 0.9790794979079498\n",
      "Epoch 124:\t train loss : 0.5584129111680677; train accuracy : 0.9929808854053719; \n",
      " validation loss : 0.5848720821123861; validation accuracy : 0.9665271966527197\n",
      "Epoch 125:\t train loss : 0.5586367087382376; train accuracy : 0.9927079525388023; \n",
      " validation loss : 0.5952317943231562; validation accuracy : 0.9539748953974896\n",
      "Epoch 126:\t train loss : 0.5582031439906936; train accuracy : 0.9931940270764273; \n",
      " validation loss : 0.5663045190117609; validation accuracy : 0.9832635983263598\n",
      "Epoch 127:\t train loss : 0.5637301241513726; train accuracy : 0.987419994423619; \n",
      " validation loss : 0.5775551706232276; validation accuracy : 0.9748953974895398\n",
      "Epoch 128:\t train loss : 0.5584005572349533; train accuracy : 0.993014033892004; \n",
      " validation loss : 0.5923614727546466; validation accuracy : 0.9581589958158996\n",
      "Epoch 129:\t train loss : 0.5615825769868681; train accuracy : 0.9896564329749992; \n",
      " validation loss : 0.5736477368794493; validation accuracy : 0.9790794979079498\n",
      "Epoch 130:\t train loss : 0.5594567150422237; train accuracy : 0.9917881594844945; \n",
      " validation loss : 0.5839127006697181; validation accuracy : 0.9665271966527197\n",
      "Epoch 131:\t train loss : 0.5617284140697321; train accuracy : 0.9894823259704452; \n",
      " validation loss : 0.5845028801850248; validation accuracy : 0.9665271966527197\n",
      "Epoch 132:\t train loss : 0.5587586314717189; train accuracy : 0.9925316769416649; \n",
      " validation loss : 0.5744659731918962; validation accuracy : 0.9748953974895398\n",
      "Epoch 133:\t train loss : 0.5581510778343981; train accuracy : 0.9931069735741503; \n",
      " validation loss : 0.5756783779674909; validation accuracy : 0.9748953974895398\n",
      "Epoch 134:\t train loss : 0.5570986901088545; train accuracy : 0.9942473434740853; \n",
      " validation loss : 0.5537379132546331; validation accuracy : 1.0\n",
      "Epoch 135:\t train loss : 0.5585717548058464; train accuracy : 0.992642275163419; \n",
      " validation loss : 0.5794553558689306; validation accuracy : 0.9707112970711297\n",
      "Epoch 136:\t train loss : 0.5569976236636109; train accuracy : 0.9942975309024443; \n",
      " validation loss : 0.5812579750967638; validation accuracy : 0.9707112970711297\n",
      "Epoch 137:\t train loss : 0.557346837361515; train accuracy : 0.9940149942687195; \n",
      " validation loss : 0.5734628628663128; validation accuracy : 0.9790794979079498\n",
      "Epoch 138:\t train loss : 0.5614432703677105; train accuracy : 0.9898305399795533; \n",
      " validation loss : 0.6281778880668902; validation accuracy : 0.9246861924686193\n",
      "Epoch 139:\t train loss : 0.5619268809887678; train accuracy : 0.9893060503733078; \n",
      " validation loss : 0.5940983880959086; validation accuracy : 0.9581589958158996\n",
      "Epoch 140:\t train loss : 0.5570427427102864; train accuracy : 0.9943093032621828; \n",
      " validation loss : 0.5643581768444558; validation accuracy : 0.9874476987447699\n",
      "Epoch 141:\t train loss : 0.5566290724099571; train accuracy : 0.994841847640881; \n",
      " validation loss : 0.5723471794230006; validation accuracy : 0.9790794979079498\n",
      "Epoch 142:\t train loss : 0.5566635114569014; train accuracy : 0.994681061990768; \n",
      " validation loss : 0.5761301688736203; validation accuracy : 0.9748953974895398\n",
      "Epoch 143:\t train loss : 0.5579042458820973; train accuracy : 0.9934050001548994; \n",
      " validation loss : 0.5957410616512469; validation accuracy : 0.9539748953974896\n",
      "Epoch 144:\t train loss : 0.5728842764673178; train accuracy : 0.9780795563679172; \n",
      " validation loss : 0.5761955622183654; validation accuracy : 0.9748953974895398\n",
      "Epoch 145:\t train loss : 0.5585707271879977; train accuracy : 0.992729328665696; \n",
      " validation loss : 0.5876533196414001; validation accuracy : 0.9623430962343096\n",
      "Epoch 146:\t train loss : 0.5586878561023167; train accuracy : 0.9926128442640726; \n",
      " validation loss : 0.604485689967004; validation accuracy : 0.9456066945606695\n",
      "Epoch 147:\t train loss : 0.5579834622166264; train accuracy : 0.9933703026735649; \n",
      " validation loss : 0.5728831921968403; validation accuracy : 0.9790794979079498\n",
      "Epoch 148:\t train loss : 0.5568963295592854; train accuracy : 0.9944738064995817; \n",
      " validation loss : 0.5701907042577653; validation accuracy : 0.9790794979079498\n",
      "Epoch 149:\t train loss : 0.5609579679315828; train accuracy : 0.9903283868769168; \n",
      " validation loss : 0.5822464580136837; validation accuracy : 0.9665271966527197\n",
      "Epoch 150:\t train loss : 0.5593598969929111; train accuracy : 0.9918677778121999; \n",
      " validation loss : 0.5954339467873302; validation accuracy : 0.9539748953974896\n",
      "Epoch 151:\t train loss : 0.5569356337293676; train accuracy : 0.994392639177174; \n",
      " validation loss : 0.5868246186418175; validation accuracy : 0.9623430962343096\n",
      "Epoch 152:\t train loss : 0.5565663019775612; train accuracy : 0.9947489079587347; \n",
      " validation loss : 0.5657040688599975; validation accuracy : 0.9832635983263598\n",
      "Epoch 153:\t train loss : 0.5563356315700985; train accuracy : 0.9949945785185415; \n",
      " validation loss : 0.5670663524621237; validation accuracy : 0.9832635983263598\n",
      "Epoch 154:\t train loss : 0.5587412098200675; train accuracy : 0.9925899191424765; \n",
      " validation loss : 0.5839170229707112; validation accuracy : 0.9665271966527197\n",
      "Epoch 155:\t train loss : 0.5554924423652335; train accuracy : 0.9959608414139224; \n",
      " validation loss : 0.5793202573893809; validation accuracy : 0.9707112970711297\n",
      "Epoch 156:\t train loss : 0.556385882048295; train accuracy : 0.9950122370581492; \n",
      " validation loss : 0.572483707737002; validation accuracy : 0.9790794979079498\n",
      "Epoch 157:\t train loss : 0.5562617746144959; train accuracy : 0.995043216952198; \n",
      " validation loss : 0.570835902403565; validation accuracy : 0.9790794979079498\n",
      "Epoch 158:\t train loss : 0.5572507175430171; train accuracy : 0.9940459741627683; \n",
      " validation loss : 0.5766712759615635; validation accuracy : 0.9748953974895398\n",
      "Epoch 159:\t train loss : 0.5918799970430308; train accuracy : 0.9589318132531987; \n",
      " validation loss : 0.6063499238331796; validation accuracy : 0.9456066945606695\n",
      "Epoch 160:\t train loss : 0.5688094728176997; train accuracy : 0.9822271445831655; \n",
      " validation loss : 0.5962299563734837; validation accuracy : 0.9539748953974896\n",
      "Epoch 161:\t train loss : 0.5629310178334893; train accuracy : 0.9882837138696986; \n",
      " validation loss : 0.5926519795699458; validation accuracy : 0.9581589958158996\n",
      "Epoch 162:\t train loss : 0.5609219158489732; train accuracy : 0.9903283868769168; \n",
      " validation loss : 0.5876347819163455; validation accuracy : 0.9623430962343096\n",
      "Epoch 163:\t train loss : 0.5574865068026733; train accuracy : 0.9938504910313206; \n",
      " validation loss : 0.5750999429498462; validation accuracy : 0.9748953974895398\n",
      "Epoch 164:\t train loss : 0.5558664642089798; train accuracy : 0.9955020291830602; \n",
      " validation loss : 0.5725635480897993; validation accuracy : 0.9790794979079498\n",
      "Epoch 165:\t train loss : 0.5564726062384053; train accuracy : 0.9949753709842312; \n",
      " validation loss : 0.5640155342951856; validation accuracy : 0.9874476987447699\n",
      "Epoch 166:\t train loss : 0.5583169676463634; train accuracy : 0.9929306979770129; \n",
      " validation loss : 0.5722148700912022; validation accuracy : 0.9790794979079498\n",
      "Epoch 167:\t train loss : 0.5596384732598724; train accuracy : 0.99163914619412; \n",
      " validation loss : 0.5859210874048224; validation accuracy : 0.9665271966527197\n",
      "Epoch 168:\t train loss : 0.5646826872515183; train accuracy : 0.9865488398029679; \n",
      " validation loss : 0.5839618087165926; validation accuracy : 0.9665271966527197\n",
      "Epoch 169:\t train loss : 0.557954408536917; train accuracy : 0.9933644164936956; \n",
      " validation loss : 0.5680707204430542; validation accuracy : 0.9832635983263598\n",
      "Epoch 170:\t train loss : 0.5589094964511188; train accuracy : 0.9924099259580532; \n",
      " validation loss : 0.573599220821752; validation accuracy : 0.9790794979079498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171:\t train loss : 0.558228303938795; train accuracy : 0.9930605037330772; \n",
      " validation loss : 0.572072355145061; validation accuracy : 0.9790794979079498\n",
      "Epoch 172:\t train loss : 0.5569217221689279; train accuracy : 0.9944951826264754; \n",
      " validation loss : 0.5726987336155783; validation accuracy : 0.9790794979079498\n",
      "Epoch 173:\t train loss : 0.5578079799041191; train accuracy : 0.9935289197310945; \n",
      " validation loss : 0.5780939355703043; validation accuracy : 0.9748953974895398\n",
      "Epoch 174:\t train loss : 0.5546215321666119; train accuracy : 0.9967876947860839; \n",
      " validation loss : 0.6036132540030421; validation accuracy : 0.9497907949790795\n",
      "Epoch 175:\t train loss : 0.5578997562618743; train accuracy : 0.9933857926205892; \n",
      " validation loss : 0.5829027542850127; validation accuracy : 0.9665271966527197\n",
      "Epoch 176:\t train loss : 0.5547974783283597; train accuracy : 0.9965494594008488; \n",
      " validation loss : 0.5919863652267499; validation accuracy : 0.9581589958158996\n",
      "Epoch 177:\t train loss : 0.554488453736051; train accuracy : 0.9969639703832213; \n",
      " validation loss : 0.5796078342912292; validation accuracy : 0.9707112970711297\n",
      "Epoch 178:\t train loss : 0.5584564894461; train accuracy : 0.9929306979770129; \n",
      " validation loss : 0.5763388460527612; validation accuracy : 0.9748953974895398\n",
      "Epoch 179:\t train loss : 0.5580525405992363; train accuracy : 0.9932463830973698; \n",
      " validation loss : 0.6002786820702134; validation accuracy : 0.9497907949790795\n",
      "Epoch 180:\t train loss : 0.5557631922374691; train accuracy : 0.9956163449921002; \n",
      " validation loss : 0.5741572730396491; validation accuracy : 0.9748953974895398\n",
      "Epoch 181:\t train loss : 0.5594709160628749; train accuracy : 0.9918618916323306; \n",
      " validation loss : 0.5807340866624295; validation accuracy : 0.9707112970711297\n",
      "Epoch 182:\t train loss : 0.5577447500008318; train accuracy : 0.993503826016915; \n",
      " validation loss : 0.5734922501612304; validation accuracy : 0.9790794979079498\n",
      "Epoch 183:\t train loss : 0.5571260906164761; train accuracy : 0.9941389138449146; \n",
      " validation loss : 0.5731252164065099; validation accuracy : 0.9790794979079498\n",
      "Epoch 184:\t train loss : 0.5551414768211436; train accuracy : 0.9962920164813036; \n",
      " validation loss : 0.5823567255416209; validation accuracy : 0.9707112970711297\n",
      "Early stopping at epoch 184\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5570986901088545; Train accuracy : 0.9942473434740853; \n",
      " Validation loss : 0.5537379132546331; Validation accuracy : 1.0\n",
      "--- Let's train model 25 ! ---\n",
      "Epoch 1:\t train loss : 0.9416842383235787; train accuracy : 0.587283373090864; \n",
      " validation loss : 0.832870488824884; validation accuracy : 0.7280334728033473\n",
      "Epoch 2:\t train loss : 0.7681838292679634; train accuracy : 0.7805579478918182; \n",
      " validation loss : 0.7542234750106755; validation accuracy : 0.8075313807531381\n",
      "Epoch 3:\t train loss : 0.707138009743685; train accuracy : 0.8431903094891415; \n",
      " validation loss : 0.7124487304898862; validation accuracy : 0.8368200836820083\n",
      "Epoch 4:\t train loss : 0.6810268287573503; train accuracy : 0.8693704885529292; \n",
      " validation loss : 0.7058486682641657; validation accuracy : 0.8368200836820083\n",
      "Epoch 5:\t train loss : 0.6675659260782292; train accuracy : 0.8834279252764956; \n",
      " validation loss : 0.7065497428633153; validation accuracy : 0.8410041841004184\n",
      "Epoch 6:\t train loss : 0.6546474726667973; train accuracy : 0.8961355680163574; \n",
      " validation loss : 0.6542708967939581; validation accuracy : 0.895397489539749\n",
      "Epoch 7:\t train loss : 0.6503791404833061; train accuracy : 0.9002964775860467; \n",
      " validation loss : 0.7854514101483269; validation accuracy : 0.7615062761506276\n",
      "Epoch 8:\t train loss : 0.6401509083877412; train accuracy : 0.9102410235756994; \n",
      " validation loss : 0.6618244604658013; validation accuracy : 0.891213389121339\n",
      "Epoch 9:\t train loss : 0.6190075645560387; train accuracy : 0.932353232751944; \n",
      " validation loss : 0.6714229208118541; validation accuracy : 0.8702928870292888\n",
      "Epoch 10:\t train loss : 0.6139308566659445; train accuracy : 0.9368239412621209; \n",
      " validation loss : 0.6573040032751011; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.6085154048758878; train accuracy : 0.9426754236500511; \n",
      " validation loss : 0.6391138025071547; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.6036269730155056; train accuracy : 0.9478078626971096; \n",
      " validation loss : 0.6653350291741519; validation accuracy : 0.8870292887029289\n",
      "Epoch 13:\t train loss : 0.6063684817512973; train accuracy : 0.9451147805074507; \n",
      " validation loss : 0.6367906956386404; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5939241249272935; train accuracy : 0.9573326311224015; \n",
      " validation loss : 0.6378990907659674; validation accuracy : 0.9121338912133892\n",
      "Epoch 15:\t train loss : 0.5989962920991948; train accuracy : 0.9520409554199325; \n",
      " validation loss : 0.6326277377847231; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5908242695986707; train accuracy : 0.9605545401034729; \n",
      " validation loss : 0.6563740406630536; validation accuracy : 0.895397489539749\n",
      "Epoch 17:\t train loss : 0.5879046501795021; train accuracy : 0.9633427305678615; \n",
      " validation loss : 0.6276017520780279; validation accuracy : 0.9205020920502092\n",
      "Epoch 18:\t train loss : 0.5862262600061454; train accuracy : 0.9648511416090957; \n",
      " validation loss : 0.6528382106945511; validation accuracy : 0.895397489539749\n",
      "Epoch 19:\t train loss : 0.5924742358445668; train accuracy : 0.9584633972551814; \n",
      " validation loss : 0.6715160674166155; validation accuracy : 0.8702928870292888\n",
      "Epoch 20:\t train loss : 0.5912331394214282; train accuracy : 0.9599467145822361; \n",
      " validation loss : 0.6626255399264142; validation accuracy : 0.8870292887029289\n",
      "Epoch 21:\t train loss : 0.5825034266268839; train accuracy : 0.9688342265869451; \n",
      " validation loss : 0.6502058122134737; validation accuracy : 0.895397489539749\n",
      "Epoch 22:\t train loss : 0.5805147054108966; train accuracy : 0.9708959385358902; \n",
      " validation loss : 0.6302979306798873; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.583982503333863; train accuracy : 0.96660739180272; \n",
      " validation loss : 0.6248481431049298; validation accuracy : 0.9246861924686193\n",
      "Epoch 24:\t train loss : 0.5786830884233053; train accuracy : 0.9725341553331888; \n",
      " validation loss : 0.6385395309863495; validation accuracy : 0.9121338912133892\n",
      "Epoch 25:\t train loss : 0.5775217182815153; train accuracy : 0.9736376591592056; \n",
      " validation loss : 0.6499089566852365; validation accuracy : 0.899581589958159\n",
      "Epoch 26:\t train loss : 0.5911291723217771; train accuracy : 0.9596582917686421; \n",
      " validation loss : 0.648145874115713; validation accuracy : 0.9037656903765691\n",
      "Epoch 27:\t train loss : 0.5950894066400055; train accuracy : 0.9558301062610366; \n",
      " validation loss : 0.6326604452554383; validation accuracy : 0.9163179916317992\n",
      "Epoch 28:\t train loss : 0.5840175031936642; train accuracy : 0.9671030701075002; \n",
      " validation loss : 0.6586869733303079; validation accuracy : 0.8870292887029289\n",
      "Epoch 29:\t train loss : 0.5794931779845716; train accuracy : 0.9713222218780012; \n",
      " validation loss : 0.6137085521634308; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5754080798554421; train accuracy : 0.9756941045261626; \n",
      " validation loss : 0.6202152557192918; validation accuracy : 0.9330543933054394\n",
      "Epoch 31:\t train loss : 0.5755101220436668; train accuracy : 0.9755664673626816; \n",
      " validation loss : 0.6183675730129223; validation accuracy : 0.9330543933054394\n",
      "Epoch 32:\t train loss : 0.5805220062435902; train accuracy : 0.970175965798197; \n",
      " validation loss : 0.6027800540340693; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.5696133830978081; train accuracy : 0.9816946002044673; \n",
      " validation loss : 0.631688589934384; validation accuracy : 0.9163179916317992\n",
      "Epoch 34:\t train loss : 0.5778686227478185; train accuracy : 0.9729988537439201; \n",
      " validation loss : 0.6053846137254298; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5706874442236158; train accuracy : 0.9804052170141578; \n",
      " validation loss : 0.5877963255760741; validation accuracy : 0.9623430962343096\n",
      "Epoch 36:\t train loss : 0.5718643690717339; train accuracy : 0.9793807119179653; \n",
      " validation loss : 0.6378618027307056; validation accuracy : 0.9121338912133892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:\t train loss : 0.5789530069667699; train accuracy : 0.9720016109544906; \n",
      " validation loss : 0.6135622540570203; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5684178677164238; train accuracy : 0.9828777223581896; \n",
      " validation loss : 0.6130770236196127; validation accuracy : 0.9330543933054394\n",
      "Epoch 39:\t train loss : 0.569644130446417; train accuracy : 0.9816481303633942; \n",
      " validation loss : 0.5946314272074974; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.5680084984364724; train accuracy : 0.9833402521763376; \n",
      " validation loss : 0.6288758472568872; validation accuracy : 0.9205020920502092\n",
      "Epoch 41:\t train loss : 0.5734855651677586; train accuracy : 0.9777195699990706; \n",
      " validation loss : 0.6014178319822718; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5725621559658666; train accuracy : 0.9786799467145822; \n",
      " validation loss : 0.6315737237427791; validation accuracy : 0.9205020920502092\n",
      "Epoch 43:\t train loss : 0.5715987822286887; train accuracy : 0.9796926794510363; \n",
      " validation loss : 0.6143542828172381; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5703702308394383; train accuracy : 0.9807246197218006; \n",
      " validation loss : 0.6155820904719563; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5683118574206051; train accuracy : 0.9830385080083026; \n",
      " validation loss : 0.5968875564281054; validation accuracy : 0.9539748953974896\n",
      "Epoch 46:\t train loss : 0.5654222053657363; train accuracy : 0.9858112085256668; \n",
      " validation loss : 0.60329820186092; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5656651124869966; train accuracy : 0.9855788593203011; \n",
      " validation loss : 0.6092146090685004; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.5709564747164508; train accuracy : 0.9800777595340624; \n",
      " validation loss : 0.5893367608316066; validation accuracy : 0.9623430962343096\n",
      "Epoch 49:\t train loss : 0.5724953217370867; train accuracy : 0.9785885560271383; \n",
      " validation loss : 0.6662616147525905; validation accuracy : 0.8828451882845189\n",
      "Epoch 50:\t train loss : 0.5922612480678393; train accuracy : 0.958273800303603; \n",
      " validation loss : 0.6001696051370147; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5682192278247712; train accuracy : 0.9830636017224821; \n",
      " validation loss : 0.6005109904670053; validation accuracy : 0.9497907949790795\n",
      "Epoch 52:\t train loss : 0.565799663868621; train accuracy : 0.985307475448434; \n",
      " validation loss : 0.6094614753783748; validation accuracy : 0.9372384937238494\n",
      "Epoch 53:\t train loss : 0.5702742030593629; train accuracy : 0.9806781498807274; \n",
      " validation loss : 0.6101457235844083; validation accuracy : 0.9372384937238494\n",
      "Epoch 54:\t train loss : 0.5639212240198809; train accuracy : 0.9874723504445615; \n",
      " validation loss : 0.6070178980631276; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5673027880401841; train accuracy : 0.9836831996034574; \n",
      " validation loss : 0.5838104476492824; validation accuracy : 0.9665271966527197\n",
      "Epoch 56:\t train loss : 0.5658410402804874; train accuracy : 0.9853502277022212; \n",
      " validation loss : 0.573731097397448; validation accuracy : 0.9790794979079498\n",
      "Epoch 57:\t train loss : 0.5692256262818928; train accuracy : 0.9818148021933765; \n",
      " validation loss : 0.5846476027595522; validation accuracy : 0.9707112970711297\n",
      "Epoch 58:\t train loss : 0.5671416696029898; train accuracy : 0.9841324080671644; \n",
      " validation loss : 0.5880183047766466; validation accuracy : 0.9623430962343096\n",
      "Epoch 59:\t train loss : 0.5628385197918361; train accuracy : 0.9885160630750642; \n",
      " validation loss : 0.5938357614253424; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5661754706487038; train accuracy : 0.9850035626878156; \n",
      " validation loss : 0.6099889219697349; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5646350887229719; train accuracy : 0.9867502091142848; \n",
      " validation loss : 0.592411390464993; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.565122300323049; train accuracy : 0.9860008054772452; \n",
      " validation loss : 0.5967536544123239; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.5690741736812146; train accuracy : 0.9820818488800769; \n",
      " validation loss : 0.6313324740614716; validation accuracy : 0.9121338912133892\n",
      "Epoch 64:\t train loss : 0.5690906148027717; train accuracy : 0.9819889091979306; \n",
      " validation loss : 0.6061103653289642; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.5732620642317414; train accuracy : 0.9776266303169243; \n",
      " validation loss : 0.5925537213790054; validation accuracy : 0.9539748953974896\n",
      "Epoch 66:\t train loss : 0.5694811027731401; train accuracy : 0.9817528424052789; \n",
      " validation loss : 0.5977574291416289; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5659519081775345; train accuracy : 0.9853870937761393; \n",
      " validation loss : 0.6149983927581072; validation accuracy : 0.9372384937238494\n",
      "Epoch 68:\t train loss : 0.5674803679579274; train accuracy : 0.9836463335295393; \n",
      " validation loss : 0.5895207754707805; validation accuracy : 0.9623430962343096\n",
      "Epoch 69:\t train loss : 0.5675679840266095; train accuracy : 0.9835379039003687; \n",
      " validation loss : 0.5855124271786692; validation accuracy : 0.9665271966527197\n",
      "Epoch 70:\t train loss : 0.5674066721296258; train accuracy : 0.9838380990737011; \n",
      " validation loss : 0.6015627274208151; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.563342907176323; train accuracy : 0.9880513646643329; \n",
      " validation loss : 0.5927071376394042; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5607773827012518; train accuracy : 0.990613092103225; \n",
      " validation loss : 0.5991730640163897; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5618293413006925; train accuracy : 0.989398990055454; \n",
      " validation loss : 0.6050717041884258; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.564385108216095; train accuracy : 0.9870658942346417; \n",
      " validation loss : 0.5931353918037651; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.5674617832885277; train accuracy : 0.983905945041668; \n",
      " validation loss : 0.5855599924313144; validation accuracy : 0.9665271966527197\n",
      "Epoch 76:\t train loss : 0.5660093521017568; train accuracy : 0.9852690603798135; \n",
      " validation loss : 0.6297354774596465; validation accuracy : 0.9163179916317992\n",
      "Epoch 77:\t train loss : 0.567207293047596; train accuracy : 0.984029864617863; \n",
      " validation loss : 0.6074983844178672; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5668040741864939; train accuracy : 0.9843161188388736; \n",
      " validation loss : 0.6274739874400633; validation accuracy : 0.9205020920502092\n",
      "Epoch 79:\t train loss : 0.5781847699237495; train accuracy : 0.9727008271631711; \n",
      " validation loss : 0.5945732975093412; validation accuracy : 0.9581589958158996\n",
      "Epoch 80:\t train loss : 0.5653166272722708; train accuracy : 0.9859698255831965; \n",
      " validation loss : 0.6134811158157719; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.5668210705456879; train accuracy : 0.9843374949657672; \n",
      " validation loss : 0.6147803569823785; validation accuracy : 0.9330543933054394\n",
      "Epoch 82:\t train loss : 0.5721424467820663; train accuracy : 0.9788658260788748; \n",
      " validation loss : 0.6134163687325592; validation accuracy : 0.9372384937238494\n",
      "Epoch 83:\t train loss : 0.5635223962180628; train accuracy : 0.9878249016388364; \n",
      " validation loss : 0.6132240285572614; validation accuracy : 0.9372384937238494\n",
      "Epoch 84:\t train loss : 0.5643621478115902; train accuracy : 0.9868837324576349; \n",
      " validation loss : 0.6038425191241377; validation accuracy : 0.9414225941422594\n",
      "Epoch 85:\t train loss : 0.5668088633359759; train accuracy : 0.9844422070076521; \n",
      " validation loss : 0.5984138025664415; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5650801261429478; train accuracy : 0.9862796245236841; \n",
      " validation loss : 0.5977418088236568; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5640710539934883; train accuracy : 0.9869884444995198; \n",
      " validation loss : 0.5983840331710037; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88:\t train loss : 0.5618867758809486; train accuracy : 0.9894823259704452; \n",
      " validation loss : 0.5903991136069019; validation accuracy : 0.9623430962343096\n",
      "Epoch 89:\t train loss : 0.5613855525747294; train accuracy : 0.9898695746460547; \n",
      " validation loss : 0.6007305797272591; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5601183033840573; train accuracy : 0.9912946497722978; \n",
      " validation loss : 0.5947831563748971; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5611093370527442; train accuracy : 0.9902295610149013; \n",
      " validation loss : 0.5931244809209539; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5598459493652258; train accuracy : 0.9914997366709005; \n",
      " validation loss : 0.6123809999214267; validation accuracy : 0.9414225941422594\n",
      "Epoch 93:\t train loss : 0.5733042951258609; train accuracy : 0.9778819046438861; \n",
      " validation loss : 0.6121614056742732; validation accuracy : 0.9372384937238494\n",
      "Epoch 94:\t train loss : 0.5715329423815045; train accuracy : 0.9795222900337681; \n",
      " validation loss : 0.5859284607698572; validation accuracy : 0.9665271966527197\n",
      "Epoch 95:\t train loss : 0.5633965484625315; train accuracy : 0.987896465194089; \n",
      " validation loss : 0.6061837362863243; validation accuracy : 0.9456066945606695\n",
      "Epoch 96:\t train loss : 0.5618987695822629; train accuracy : 0.9893835001084297; \n",
      " validation loss : 0.5778000646257225; validation accuracy : 0.9748953974895398\n",
      "Epoch 97:\t train loss : 0.5707471922991135; train accuracy : 0.9802673564856408; \n",
      " validation loss : 0.6245278486416764; validation accuracy : 0.9288702928870293\n",
      "Epoch 98:\t train loss : 0.5778131690265065; train accuracy : 0.9733204250441464; \n",
      " validation loss : 0.6046105123383522; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5649422934359626; train accuracy : 0.9862449270423496; \n",
      " validation loss : 0.5999509759865777; validation accuracy : 0.9497907949790795\n",
      "Epoch 100:\t train loss : 0.561921412270514; train accuracy : 0.9892809566591282; \n",
      " validation loss : 0.5933994218060401; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5614348805632802; train accuracy : 0.9898695746460547; \n",
      " validation loss : 0.5813645398962844; validation accuracy : 0.9707112970711297\n",
      "Epoch 102:\t train loss : 0.5580401994047477; train accuracy : 0.9932618730443942; \n",
      " validation loss : 0.6017267292326313; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.5604759540636458; train accuracy : 0.9908240651816971; \n",
      " validation loss : 0.5919477891464864; validation accuracy : 0.9623430962343096\n",
      "Epoch 104:\t train loss : 0.5606645083961038; train accuracy : 0.9906595619442982; \n",
      " validation loss : 0.6024166028392745; validation accuracy : 0.9497907949790795\n",
      "Epoch 105:\t train loss : 0.5630401277432134; train accuracy : 0.9882778276898293; \n",
      " validation loss : 0.5868035480036635; validation accuracy : 0.9623430962343096\n",
      "Epoch 106:\t train loss : 0.5677368045154396; train accuracy : 0.9831661451717835; \n",
      " validation loss : 0.6466824867497635; validation accuracy : 0.9037656903765691\n",
      "Early stopping at epoch 106\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5658410402804874; Train accuracy : 0.9853502277022212; \n",
      " Validation loss : 0.573731097397448; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 26 ! ---\n",
      "Epoch 1:\t train loss : 0.9565593040285816; train accuracy : 0.5672105703398495; \n",
      " validation loss : 0.8466932534979366; validation accuracy : 0.6903765690376569\n",
      "Epoch 2:\t train loss : 0.754029803741281; train accuracy : 0.7946153846153846; \n",
      " validation loss : 0.7339185275497778; validation accuracy : 0.8117154811715481\n",
      "Epoch 3:\t train loss : 0.6921314639167201; train accuracy : 0.8579227981040305; \n",
      " validation loss : 0.6976373607173076; validation accuracy : 0.8410041841004184\n",
      "Epoch 4:\t train loss : 0.6729444515964885; train accuracy : 0.8772911180643762; \n",
      " validation loss : 0.7012449785039953; validation accuracy : 0.8493723849372385\n",
      "Epoch 5:\t train loss : 0.653483827641424; train accuracy : 0.8967043588710927; \n",
      " validation loss : 0.6737198279185018; validation accuracy : 0.8661087866108786\n",
      "Epoch 6:\t train loss : 0.6421981806111133; train accuracy : 0.9085637721118994; \n",
      " validation loss : 0.642562026487146; validation accuracy : 0.9121338912133892\n",
      "Epoch 7:\t train loss : 0.6268954918219745; train accuracy : 0.9238604045974163; \n",
      " validation loss : 0.6446005506086642; validation accuracy : 0.9037656903765691\n",
      "Epoch 8:\t train loss : 0.6177157008650409; train accuracy : 0.9330496607701602; \n",
      " validation loss : 0.6381985472644708; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.6140518168589713; train accuracy : 0.9369692369652096; \n",
      " validation loss : 0.6213027815191484; validation accuracy : 0.9330543933054394\n",
      "Epoch 10:\t train loss : 0.6111766725091581; train accuracy : 0.939998760804238; \n",
      " validation loss : 0.6332518205779225; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.606329937455362; train accuracy : 0.9444273366585086; \n",
      " validation loss : 0.612627990308758; validation accuracy : 0.9456066945606695\n",
      "Epoch 12:\t train loss : 0.5980161648536255; train accuracy : 0.9536726664394808; \n",
      " validation loss : 0.6164807646630797; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.5978124191651794; train accuracy : 0.953165835372843; \n",
      " validation loss : 0.6373443857738564; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5949018960939539; train accuracy : 0.9561959788097525; \n",
      " validation loss : 0.6115040469364788; validation accuracy : 0.9456066945606695\n",
      "Epoch 15:\t train loss : 0.5954220747522894; train accuracy : 0.9557387155735927; \n",
      " validation loss : 0.636493842911823; validation accuracy : 0.9163179916317992\n",
      "Epoch 16:\t train loss : 0.5935031873778599; train accuracy : 0.9576461476501751; \n",
      " validation loss : 0.6163963050862429; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5922056478981744; train accuracy : 0.9587245577620125; \n",
      " validation loss : 0.6340117571610808; validation accuracy : 0.9121338912133892\n",
      "Epoch 18:\t train loss : 0.5888611361101972; train accuracy : 0.9623609777254561; \n",
      " validation loss : 0.6250478490073555; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.5855089552306302; train accuracy : 0.9656507326744942; \n",
      " validation loss : 0.601197512204675; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5969439832126515; train accuracy : 0.9538334520895938; \n",
      " validation loss : 0.6138335692739644; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5881771746896646; train accuracy : 0.963290374546919; \n",
      " validation loss : 0.5901309086261619; validation accuracy : 0.9623430962343096\n",
      "Epoch 22:\t train loss : 0.5845579115316873; train accuracy : 0.9664385513801543; \n",
      " validation loss : 0.6268327893405236; validation accuracy : 0.9246861924686193\n",
      "Epoch 23:\t train loss : 0.5815190246691027; train accuracy : 0.9698212460113387; \n",
      " validation loss : 0.620998579821312; validation accuracy : 0.9246861924686193\n",
      "Epoch 24:\t train loss : 0.5879089813022909; train accuracy : 0.963166454970724; \n",
      " validation loss : 0.6068627876845475; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.58393564897606; train accuracy : 0.9670448279066886; \n",
      " validation loss : 0.591156520870549; validation accuracy : 0.9623430962343096\n",
      "Epoch 26:\t train loss : 0.5761604836173034; train accuracy : 0.9751556739675951; \n",
      " validation loss : 0.6165940135287983; validation accuracy : 0.9288702928870293\n",
      "Epoch 27:\t train loss : 0.5780594839671546; train accuracy : 0.9730859072461973; \n",
      " validation loss : 0.6288497818430009; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.5812045980145805; train accuracy : 0.9699783140741659; \n",
      " validation loss : 0.6152443433480324; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5765399957887034; train accuracy : 0.9745146999597262; \n",
      " validation loss : 0.5966895685453187; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.5721047050704856; train accuracy : 0.9790244431364045; \n",
      " validation loss : 0.6038153710913825; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5719355247338328; train accuracy : 0.9794058056321447; \n",
      " validation loss : 0.6092732203899205; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:\t train loss : 0.5735566212693567; train accuracy : 0.9774038848787138; \n",
      " validation loss : 0.6012001574491838; validation accuracy : 0.9497907949790795\n",
      "Epoch 33:\t train loss : 0.569548258239589; train accuracy : 0.9816599027231326; \n",
      " validation loss : 0.591828283732234; validation accuracy : 0.9581589958158996\n",
      "Epoch 34:\t train loss : 0.569750437959413; train accuracy : 0.9815183246073298; \n",
      " validation loss : 0.5968019661853149; validation accuracy : 0.9539748953974896\n",
      "Epoch 35:\t train loss : 0.5715206268807872; train accuracy : 0.9796071749434617; \n",
      " validation loss : 0.6019017201820979; validation accuracy : 0.9456066945606695\n",
      "Epoch 36:\t train loss : 0.570843366083067; train accuracy : 0.9802577527184857; \n",
      " validation loss : 0.5927481254761411; validation accuracy : 0.9539748953974896\n",
      "Epoch 37:\t train loss : 0.567668555046783; train accuracy : 0.9835475076675237; \n",
      " validation loss : 0.5889837513939443; validation accuracy : 0.9623430962343096\n",
      "Epoch 38:\t train loss : 0.5687349633518964; train accuracy : 0.98237615787354; \n",
      " validation loss : 0.6085563885463481; validation accuracy : 0.9414225941422594\n",
      "Epoch 39:\t train loss : 0.5698180410942253; train accuracy : 0.9813789150841105; \n",
      " validation loss : 0.5862609241937659; validation accuracy : 0.9665271966527197\n",
      "Epoch 40:\t train loss : 0.5710611990801691; train accuracy : 0.9800504972272995; \n",
      " validation loss : 0.5878696648341913; validation accuracy : 0.9623430962343096\n",
      "Epoch 41:\t train loss : 0.571536971757627; train accuracy : 0.9794699340128257; \n",
      " validation loss : 0.5993431841045243; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5745709492821527; train accuracy : 0.9765460516125035; \n",
      " validation loss : 0.5915420279529923; validation accuracy : 0.9623430962343096\n",
      "Epoch 43:\t train loss : 0.5695857949775347; train accuracy : 0.9816791102574429; \n",
      " validation loss : 0.6143744972675498; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5691961274136879; train accuracy : 0.9819851916106447; \n",
      " validation loss : 0.5843917093557014; validation accuracy : 0.9665271966527197\n",
      "Epoch 45:\t train loss : 0.5650276956191443; train accuracy : 0.9864404101737972; \n",
      " validation loss : 0.5989585637603911; validation accuracy : 0.9539748953974896\n",
      "Epoch 46:\t train loss : 0.5689079627247974; train accuracy : 0.9821806747420924; \n",
      " validation loss : 0.588379109079803; validation accuracy : 0.9623430962343096\n",
      "Epoch 47:\t train loss : 0.5638692500285277; train accuracy : 0.9874258806034883; \n",
      " validation loss : 0.604493151550746; validation accuracy : 0.9497907949790795\n",
      "Epoch 48:\t train loss : 0.5685634004997004; train accuracy : 0.9824845875027107; \n",
      " validation loss : 0.6113652301748501; validation accuracy : 0.9372384937238494\n",
      "Epoch 49:\t train loss : 0.5700571762656743; train accuracy : 0.9809953839957868; \n",
      " validation loss : 0.5855267488040538; validation accuracy : 0.9665271966527197\n",
      "Epoch 50:\t train loss : 0.5700576814518877; train accuracy : 0.9810034387682394; \n",
      " validation loss : 0.6033857528154188; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5673044294644531; train accuracy : 0.9836463335295393; \n",
      " validation loss : 0.5942300824492531; validation accuracy : 0.9581589958158996\n",
      "Epoch 52:\t train loss : 0.5651757118732519; train accuracy : 0.9861615911273584; \n",
      " validation loss : 0.6098321236828645; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.5650574172715078; train accuracy : 0.9860413891384492; \n",
      " validation loss : 0.5756675031435171; validation accuracy : 0.9748953974895398\n",
      "Epoch 54:\t train loss : 0.5634645166238709; train accuracy : 0.9879193903156851; \n",
      " validation loss : 0.5869491771788229; validation accuracy : 0.9581589958158996\n",
      "Epoch 55:\t train loss : 0.5613720213375668; train accuracy : 0.9898732922333405; \n",
      " validation loss : 0.5885852381541313; validation accuracy : 0.9623430962343096\n",
      "Epoch 56:\t train loss : 0.5756872017453345; train accuracy : 0.9754425477864865; \n",
      " validation loss : 0.5910956820075167; validation accuracy : 0.9581589958158996\n",
      "Epoch 57:\t train loss : 0.5760125301441581; train accuracy : 0.9750258682115307; \n",
      " validation loss : 0.6012981092586155; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.5634070370113421; train accuracy : 0.9878345054059915; \n",
      " validation loss : 0.5962566274723845; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5616090940206974; train accuracy : 0.9898438613339943; \n",
      " validation loss : 0.5851571237672947; validation accuracy : 0.9707112970711297\n",
      "Epoch 60:\t train loss : 0.5615123973865378; train accuracy : 0.9898017286780879; \n",
      " validation loss : 0.5802496922156765; validation accuracy : 0.9707112970711297\n",
      "Epoch 61:\t train loss : 0.559372992341495; train accuracy : 0.9919954149756808; \n",
      " validation loss : 0.5717979675342741; validation accuracy : 0.9790794979079498\n",
      "Epoch 62:\t train loss : 0.5621609036197802; train accuracy : 0.9890582112209176; \n",
      " validation loss : 0.5890402815376901; validation accuracy : 0.9581589958158996\n",
      "Epoch 63:\t train loss : 0.5608506335969717; train accuracy : 0.9904058366120387; \n",
      " validation loss : 0.5874655609451961; validation accuracy : 0.9665271966527197\n",
      "Epoch 64:\t train loss : 0.5757388012270424; train accuracy : 0.9752950834908145; \n",
      " validation loss : 0.5883580043315823; validation accuracy : 0.9665271966527197\n",
      "Epoch 65:\t train loss : 0.5744161855651624; train accuracy : 0.9764435081632021; \n",
      " validation loss : 0.5751007781080475; validation accuracy : 0.9748953974895398\n",
      "Epoch 66:\t train loss : 0.5706729212350277; train accuracy : 0.9804340283156232; \n",
      " validation loss : 0.5994091467905376; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5688236560975777; train accuracy : 0.9822640106570836; \n",
      " validation loss : 0.6158378662101954; validation accuracy : 0.9288702928870293\n",
      "Epoch 68:\t train loss : 0.5600189304675722; train accuracy : 0.9912946497722978; \n",
      " validation loss : 0.5781950353829443; validation accuracy : 0.9748953974895398\n",
      "Epoch 69:\t train loss : 0.560469892157242; train accuracy : 0.990663279531584; \n",
      " validation loss : 0.5846026594929238; validation accuracy : 0.9665271966527197\n",
      "Epoch 70:\t train loss : 0.5612491096405423; train accuracy : 0.990039964063323; \n",
      " validation loss : 0.5782821781491337; validation accuracy : 0.9748953974895398\n",
      "Epoch 71:\t train loss : 0.5582264802886848; train accuracy : 0.9931881408965582; \n",
      " validation loss : 0.5790932924563522; validation accuracy : 0.9748953974895398\n",
      "Epoch 72:\t train loss : 0.560795611561874; train accuracy : 0.9904619102202671; \n",
      " validation loss : 0.5899742275668682; validation accuracy : 0.9623430962343096\n",
      "Epoch 73:\t train loss : 0.5615609725466344; train accuracy : 0.9897552588370148; \n",
      " validation loss : 0.5905802516196501; validation accuracy : 0.9581589958158996\n",
      "Epoch 74:\t train loss : 0.5665739726215742; train accuracy : 0.9846222001920754; \n",
      " validation loss : 0.5975227430046411; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5618931857207564; train accuracy : 0.9894764397905759; \n",
      " validation loss : 0.5840146802118497; validation accuracy : 0.9665271966527197\n",
      "Epoch 76:\t train loss : 0.5582379550990036; train accuracy : 0.9932404969175005; \n",
      " validation loss : 0.5703216328270104; validation accuracy : 0.9832635983263598\n",
      "Epoch 77:\t train loss : 0.5609089206745492; train accuracy : 0.9902856346231296; \n",
      " validation loss : 0.5853428413677457; validation accuracy : 0.9623430962343096\n",
      "Epoch 78:\t train loss : 0.5621456383105057; train accuracy : 0.9890021376126894; \n",
      " validation loss : 0.5753850262695588; validation accuracy : 0.9748953974895398\n",
      "Epoch 79:\t train loss : 0.5605966022079106; train accuracy : 0.9906883732457635; \n",
      " validation loss : 0.595691734958041; validation accuracy : 0.9581589958158996\n",
      "Epoch 80:\t train loss : 0.5607827970754748; train accuracy : 0.9903534805910964; \n",
      " validation loss : 0.5786728867019142; validation accuracy : 0.9707112970711297\n",
      "Epoch 81:\t train loss : 0.559951992494872; train accuracy : 0.9913293472536324; \n",
      " validation loss : 0.5856917053201666; validation accuracy : 0.9665271966527197\n",
      "Epoch 82:\t train loss : 0.5616340892957009; train accuracy : 0.9896601505622851; \n",
      " validation loss : 0.581310534902463; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:\t train loss : 0.5685849696210423; train accuracy : 0.9824594937885313; \n",
      " validation loss : 0.5800047237996255; validation accuracy : 0.9748953974895398\n",
      "Epoch 84:\t train loss : 0.5620033582013669; train accuracy : 0.9893835001084297; \n",
      " validation loss : 0.5917492926757253; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5606714438088191; train accuracy : 0.9905201524210787; \n",
      " validation loss : 0.5976124283649032; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5608893931146973; train accuracy : 0.9903342730567861; \n",
      " validation loss : 0.5831689787156092; validation accuracy : 0.9665271966527197\n",
      "Epoch 87:\t train loss : 0.5590546299166993; train accuracy : 0.992367173704266; \n",
      " validation loss : 0.5961977273974683; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5656735703292685; train accuracy : 0.9853598314693763; \n",
      " validation loss : 0.5698689730889566; validation accuracy : 0.9832635983263598\n",
      "Epoch 89:\t train loss : 0.5587964599715042; train accuracy : 0.9924718857461508; \n",
      " validation loss : 0.5778342777534521; validation accuracy : 0.9748953974895398\n",
      "Epoch 90:\t train loss : 0.5580397452153515; train accuracy : 0.9931224635211747; \n",
      " validation loss : 0.5764816102777183; validation accuracy : 0.9748953974895398\n",
      "Epoch 91:\t train loss : 0.5606675322695154; train accuracy : 0.990700145605502; \n",
      " validation loss : 0.584125609232943; validation accuracy : 0.9665271966527197\n",
      "Epoch 92:\t train loss : 0.5601159249396707; train accuracy : 0.9911338641221847; \n",
      " validation loss : 0.5835200737606773; validation accuracy : 0.9665271966527197\n",
      "Epoch 93:\t train loss : 0.5616438260445193; train accuracy : 0.9895421171659593; \n",
      " validation loss : 0.5708865253629367; validation accuracy : 0.9790794979079498\n",
      "Epoch 94:\t train loss : 0.5650230953254597; train accuracy : 0.9859970878899594; \n",
      " validation loss : 0.5724824557755276; validation accuracy : 0.9790794979079498\n",
      "Epoch 95:\t train loss : 0.5581780369776328; train accuracy : 0.9931726509495338; \n",
      " validation loss : 0.5811615163325982; validation accuracy : 0.9707112970711297\n",
      "Epoch 96:\t train loss : 0.556720322296566; train accuracy : 0.9945881223086217; \n",
      " validation loss : 0.5858231075856377; validation accuracy : 0.9665271966527197\n",
      "Epoch 97:\t train loss : 0.5598802517820862; train accuracy : 0.9914960190836147; \n",
      " validation loss : 0.5917534924994097; validation accuracy : 0.9581589958158996\n",
      "Epoch 98:\t train loss : 0.564433412660772; train accuracy : 0.9867576442888565; \n",
      " validation loss : 0.5914891061420359; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5768511170312606; train accuracy : 0.974216673378977; \n",
      " validation loss : 0.6028484658833965; validation accuracy : 0.9497907949790795\n",
      "Epoch 100:\t train loss : 0.5686242762948381; train accuracy : 0.9824690975556863; \n",
      " validation loss : 0.5797104501626695; validation accuracy : 0.9665271966527197\n",
      "Epoch 101:\t train loss : 0.5590298968908043; train accuracy : 0.9923303076303479; \n",
      " validation loss : 0.5686095335663903; validation accuracy : 0.9832635983263598\n",
      "Epoch 102:\t train loss : 0.5599326911770035; train accuracy : 0.9911803339632579; \n",
      " validation loss : 0.5734453420039611; validation accuracy : 0.9748953974895398\n",
      "Epoch 103:\t train loss : 0.5599767907704186; train accuracy : 0.9913448372006568; \n",
      " validation loss : 0.5896518883795403; validation accuracy : 0.9623430962343096\n",
      "Epoch 104:\t train loss : 0.568293140394384; train accuracy : 0.9828718361783203; \n",
      " validation loss : 0.5819483447148162; validation accuracy : 0.9707112970711297\n",
      "Epoch 105:\t train loss : 0.5580846713605018; train accuracy : 0.9932501006846557; \n",
      " validation loss : 0.575800611558768; validation accuracy : 0.9748953974895398\n",
      "Epoch 106:\t train loss : 0.5571048499356185; train accuracy : 0.9942414572942161; \n",
      " validation loss : 0.5692425582371143; validation accuracy : 0.9832635983263598\n",
      "Epoch 107:\t train loss : 0.5584280121137902; train accuracy : 0.9928126645806872; \n",
      " validation loss : 0.5895469438722463; validation accuracy : 0.9623430962343096\n",
      "Epoch 108:\t train loss : 0.5587562060220047; train accuracy : 0.9926267852163946; \n",
      " validation loss : 0.5765281195765724; validation accuracy : 0.9748953974895398\n",
      "Epoch 109:\t train loss : 0.5634834664434544; train accuracy : 0.987608042380495; \n",
      " validation loss : 0.5697608003642414; validation accuracy : 0.9832635983263598\n",
      "Epoch 110:\t train loss : 0.5588432033175348; train accuracy : 0.992527959354379; \n",
      " validation loss : 0.6010463600192782; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.5585994130704774; train accuracy : 0.9926577651104433; \n",
      " validation loss : 0.5737272064278014; validation accuracy : 0.9790794979079498\n",
      "Epoch 112:\t train loss : 0.5590554235069477; train accuracy : 0.9922085566467362; \n",
      " validation loss : 0.5762662448782059; validation accuracy : 0.9748953974895398\n",
      "Epoch 113:\t train loss : 0.5571173215749647; train accuracy : 0.9942318535270609; \n",
      " validation loss : 0.5723204369858705; validation accuracy : 0.9790794979079498\n",
      "Epoch 114:\t train loss : 0.5692774822674511; train accuracy : 0.9817063725642058; \n",
      " validation loss : 0.6113832661316572; validation accuracy : 0.9372384937238494\n",
      "Epoch 115:\t train loss : 0.5635259234841816; train accuracy : 0.9876021562006257; \n",
      " validation loss : 0.579649158783178; validation accuracy : 0.9707112970711297\n",
      "Epoch 116:\t train loss : 0.5575535178994256; train accuracy : 0.9938387186715821; \n",
      " validation loss : 0.576384274005218; validation accuracy : 0.9748953974895398\n",
      "Epoch 117:\t train loss : 0.5539356197756065; train accuracy : 0.9974441587409771; \n",
      " validation loss : 0.5758175011303972; validation accuracy : 0.9748953974895398\n",
      "Epoch 118:\t train loss : 0.5583416551794724; train accuracy : 0.9929093218501193; \n",
      " validation loss : 0.5821044738515977; validation accuracy : 0.9707112970711297\n",
      "Epoch 119:\t train loss : 0.5612111652005592; train accuracy : 0.9900554540103472; \n",
      " validation loss : 0.5908014608076889; validation accuracy : 0.9623430962343096\n",
      "Epoch 120:\t train loss : 0.5603132870304322; train accuracy : 0.9908956287369497; \n",
      " validation loss : 0.5890925795845399; validation accuracy : 0.9623430962343096\n",
      "Epoch 121:\t train loss : 0.5619858868164803; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.5805980178888654; validation accuracy : 0.9707112970711297\n",
      "Epoch 122:\t train loss : 0.5593531710540072; train accuracy : 0.9919858112085257; \n",
      " validation loss : 0.6053800900985867; validation accuracy : 0.9456066945606695\n",
      "Epoch 123:\t train loss : 0.5578834139646112; train accuracy : 0.9934050001548994; \n",
      " validation loss : 0.5930515531246052; validation accuracy : 0.9581589958158996\n",
      "Epoch 124:\t train loss : 0.5596479140186515; train accuracy : 0.991588958765761; \n",
      " validation loss : 0.5804199375231593; validation accuracy : 0.9707112970711297\n",
      "Epoch 125:\t train loss : 0.5564582241504704; train accuracy : 0.9949075250162644; \n",
      " validation loss : 0.5810531999262293; validation accuracy : 0.9707112970711297\n",
      "Epoch 126:\t train loss : 0.5716911021236154; train accuracy : 0.9793342420768921; \n",
      " validation loss : 0.5918502403375007; validation accuracy : 0.9623430962343096\n",
      "Epoch 127:\t train loss : 0.5619077864045129; train accuracy : 0.9894144800024783; \n",
      " validation loss : 0.577496022682127; validation accuracy : 0.9748953974895398\n",
      "Epoch 128:\t train loss : 0.5573603750912866; train accuracy : 0.9941020477709966; \n",
      " validation loss : 0.5758566330293308; validation accuracy : 0.9748953974895398\n",
      "Epoch 129:\t train loss : 0.5560199679117989; train accuracy : 0.9953006598717432; \n",
      " validation loss : 0.5819758319475978; validation accuracy : 0.9707112970711297\n",
      "Epoch 130:\t train loss : 0.5650260268911571; train accuracy : 0.9862021747885622; \n",
      " validation loss : 0.5721224814923223; validation accuracy : 0.9832635983263598\n",
      "Epoch 131:\t train loss : 0.5599532223326753; train accuracy : 0.9913256296663465; \n",
      " validation loss : 0.5681238534445436; validation accuracy : 0.9832635983263598\n",
      "Epoch 132:\t train loss : 0.5580247068272893; train accuracy : 0.9932501006846557; \n",
      " validation loss : 0.6032239253868033; validation accuracy : 0.9456066945606695\n",
      "Epoch 133:\t train loss : 0.5605181949231922; train accuracy : 0.9907038631927879; \n",
      " validation loss : 0.5828616015598115; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134:\t train loss : 0.5584753023723391; train accuracy : 0.9928938319030949; \n",
      " validation loss : 0.5942371206135858; validation accuracy : 0.9581589958158996\n",
      "Epoch 135:\t train loss : 0.5560502549850257; train accuracy : 0.9953065460516125; \n",
      " validation loss : 0.5856186802694834; validation accuracy : 0.9665271966527197\n",
      "Epoch 136:\t train loss : 0.5589698944055168; train accuracy : 0.9923767774714211; \n",
      " validation loss : 0.5903275603899448; validation accuracy : 0.9623430962343096\n",
      "Epoch 137:\t train loss : 0.5665226054932776; train accuracy : 0.9847616097152948; \n",
      " validation loss : 0.5797790398383359; validation accuracy : 0.9707112970711297\n",
      "Epoch 138:\t train loss : 0.5579121743524839; train accuracy : 0.9933120604727532; \n",
      " validation loss : 0.5660979015635925; validation accuracy : 0.9832635983263598\n",
      "Epoch 139:\t train loss : 0.555643900121333; train accuracy : 0.9957963381765235; \n",
      " validation loss : 0.5807161967601074; validation accuracy : 0.9707112970711297\n",
      "Epoch 140:\t train loss : 0.5566346416440039; train accuracy : 0.9946249883825398; \n",
      " validation loss : 0.578326751251351; validation accuracy : 0.9748953974895398\n",
      "Epoch 141:\t train loss : 0.5611067638600747; train accuracy : 0.9901056414387063; \n",
      " validation loss : 0.5794925370501356; validation accuracy : 0.9707112970711297\n",
      "Epoch 142:\t train loss : 0.5670756150178395; train accuracy : 0.9840490721521732; \n",
      " validation loss : 0.5947049572350386; validation accuracy : 0.9581589958158996\n",
      "Epoch 143:\t train loss : 0.5601444624209998; train accuracy : 0.9910350382601691; \n",
      " validation loss : 0.5934526042611086; validation accuracy : 0.9581589958158996\n",
      "Epoch 144:\t train loss : 0.5558500341992285; train accuracy : 0.9954961430031909; \n",
      " validation loss : 0.5888459713359933; validation accuracy : 0.9623430962343096\n",
      "Epoch 145:\t train loss : 0.5555613706000098; train accuracy : 0.9957343783884259; \n",
      " validation loss : 0.5768875895601032; validation accuracy : 0.9748953974895398\n",
      "Epoch 146:\t train loss : 0.5549768228128492; train accuracy : 0.9963849561634499; \n",
      " validation loss : 0.5827075868763532; validation accuracy : 0.9665271966527197\n",
      "Epoch 147:\t train loss : 0.5572888565602462; train accuracy : 0.9940518603426376; \n",
      " validation loss : 0.5754984472359821; validation accuracy : 0.9748953974895398\n",
      "Epoch 148:\t train loss : 0.558196797658997; train accuracy : 0.9931534434152235; \n",
      " validation loss : 0.5816128684171069; validation accuracy : 0.9665271966527197\n",
      "Epoch 149:\t train loss : 0.5687609285200786; train accuracy : 0.9823488955667772; \n",
      " validation loss : 0.596716470232478; validation accuracy : 0.9539748953974896\n",
      "Epoch 150:\t train loss : 0.5646538062856007; train accuracy : 0.9866166857709346; \n",
      " validation loss : 0.5839607653000757; validation accuracy : 0.9665271966527197\n",
      "Epoch 151:\t train loss : 0.5586001202639944; train accuracy : 0.9927042349515165; \n",
      " validation loss : 0.5839057354860439; validation accuracy : 0.9665271966527197\n",
      "Epoch 152:\t train loss : 0.5665222282844473; train accuracy : 0.9848235695033923; \n",
      " validation loss : 0.5852143689181427; validation accuracy : 0.9665271966527197\n",
      "Epoch 153:\t train loss : 0.5585722636917468; train accuracy : 0.9926887450044921; \n",
      " validation loss : 0.5686412512600819; validation accuracy : 0.9832635983263598\n",
      "Epoch 154:\t train loss : 0.5552206459666694; train accuracy : 0.9961739830849778; \n",
      " validation loss : 0.5778728587080983; validation accuracy : 0.9665271966527197\n",
      "Epoch 155:\t train loss : 0.5584868890363499; train accuracy : 0.9928222683478423; \n",
      " validation loss : 0.5817760982924497; validation accuracy : 0.9707112970711297\n",
      "Epoch 156:\t train loss : 0.5593053412014658; train accuracy : 0.9919083614734038; \n",
      " validation loss : 0.5847489966716928; validation accuracy : 0.9665271966527197\n",
      "Epoch 157:\t train loss : 0.5554716468464624; train accuracy : 0.9957594721026054; \n",
      " validation loss : 0.5687604497416541; validation accuracy : 0.9832635983263598\n",
      "Epoch 158:\t train loss : 0.5593463763428412; train accuracy : 0.9920493199913256; \n",
      " validation loss : 0.5919542902196478; validation accuracy : 0.9581589958158996\n",
      "Epoch 159:\t train loss : 0.5580855099057415; train accuracy : 0.9932714768115493; \n",
      " validation loss : 0.5772978349918108; validation accuracy : 0.9707112970711297\n",
      "Epoch 160:\t train loss : 0.5591991226700838; train accuracy : 0.9921348244989002; \n",
      " validation loss : 0.5873479103071333; validation accuracy : 0.9623430962343096\n",
      "Epoch 161:\t train loss : 0.5572620093696452; train accuracy : 0.9940769540568171; \n",
      " validation loss : 0.5641245444270315; validation accuracy : 0.9874476987447699\n",
      "Epoch 162:\t train loss : 0.5579977189151551; train accuracy : 0.9933179466526224; \n",
      " validation loss : 0.5878657922169308; validation accuracy : 0.9623430962343096\n",
      "Epoch 163:\t train loss : 0.5588919849327139; train accuracy : 0.9924814895133058; \n",
      " validation loss : 0.593021968399615; validation accuracy : 0.9623430962343096\n",
      "Epoch 164:\t train loss : 0.5579948680305555; train accuracy : 0.9933548127265405; \n",
      " validation loss : 0.5925850316749455; validation accuracy : 0.9581589958158996\n",
      "Epoch 165:\t train loss : 0.5547296534081739; train accuracy : 0.9966541714427336; \n",
      " validation loss : 0.5823750805022517; validation accuracy : 0.9707112970711297\n",
      "Epoch 166:\t train loss : 0.5555932485063911; train accuracy : 0.9957557545153195; \n",
      " validation loss : 0.5768775289363837; validation accuracy : 0.9748953974895398\n",
      "Epoch 167:\t train loss : 0.5568013596321603; train accuracy : 0.9945549738219895; \n",
      " validation loss : 0.5890287633333556; validation accuracy : 0.9623430962343096\n",
      "Epoch 168:\t train loss : 0.5581241581717761; train accuracy : 0.9932404969175005; \n",
      " validation loss : 0.5920936069497714; validation accuracy : 0.9581589958158996\n",
      "Epoch 169:\t train loss : 0.5587487130051209; train accuracy : 0.9925995229096316; \n",
      " validation loss : 0.5993165089119221; validation accuracy : 0.9539748953974896\n",
      "Epoch 170:\t train loss : 0.5574657365543015; train accuracy : 0.9937516651693051; \n",
      " validation loss : 0.577601805764018; validation accuracy : 0.9748953974895398\n",
      "Epoch 171:\t train loss : 0.5555094907141592; train accuracy : 0.9958465256048824; \n",
      " validation loss : 0.5779313455099107; validation accuracy : 0.9748953974895398\n",
      "Epoch 172:\t train loss : 0.5577566932357099; train accuracy : 0.9934012825676136; \n",
      " validation loss : 0.5893750875012833; validation accuracy : 0.9623430962343096\n",
      "Epoch 173:\t train loss : 0.558123131300917; train accuracy : 0.9931940270764273; \n",
      " validation loss : 0.5867321527974066; validation accuracy : 0.9623430962343096\n",
      "Epoch 174:\t train loss : 0.5591108269858223; train accuracy : 0.9922336503609157; \n",
      " validation loss : 0.5789044614922533; validation accuracy : 0.9707112970711297\n",
      "Epoch 175:\t train loss : 0.5608547419846233; train accuracy : 0.99048917252703; \n",
      " validation loss : 0.5697822723026875; validation accuracy : 0.9832635983263598\n",
      "Epoch 176:\t train loss : 0.5586389856547004; train accuracy : 0.9927042349515165; \n",
      " validation loss : 0.57421539637474; validation accuracy : 0.9790794979079498\n",
      "Epoch 177:\t train loss : 0.5575048316751414; train accuracy : 0.9938696985656309; \n",
      " validation loss : 0.5875723914914438; validation accuracy : 0.9665271966527197\n",
      "Epoch 178:\t train loss : 0.5576903365211127; train accuracy : 0.9936277455931101; \n",
      " validation loss : 0.5900555264019139; validation accuracy : 0.9623430962343096\n",
      "Epoch 179:\t train loss : 0.5555354616832092; train accuracy : 0.9957498683354503; \n",
      " validation loss : 0.5947204442886178; validation accuracy : 0.9539748953974896\n",
      "Epoch 180:\t train loss : 0.559708362705748; train accuracy : 0.9915093404380557; \n",
      " validation loss : 0.5812309086272641; validation accuracy : 0.9707112970711297\n",
      "Epoch 181:\t train loss : 0.5562313789295883; train accuracy : 0.9951361566343443; \n",
      " validation loss : 0.5782438220172077; validation accuracy : 0.9748953974895398\n",
      "Epoch 182:\t train loss : 0.5552453320700824; train accuracy : 0.9961371170110598; \n",
      " validation loss : 0.5910334001177655; validation accuracy : 0.9581589958158996\n",
      "Epoch 183:\t train loss : 0.5566546941869583; train accuracy : 0.9946132160228012; \n",
      " validation loss : 0.5960521753493573; validation accuracy : 0.9539748953974896\n",
      "Epoch 184:\t train loss : 0.5588203816079069; train accuracy : 0.9925220731745097; \n",
      " validation loss : 0.5890654896803479; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185:\t train loss : 0.5597057557299778; train accuracy : 0.9916973883949317; \n",
      " validation loss : 0.5805545497682701; validation accuracy : 0.9707112970711297\n",
      "Epoch 186:\t train loss : 0.5564715545977034; train accuracy : 0.9948728275349298; \n",
      " validation loss : 0.5844813702591604; validation accuracy : 0.9665271966527197\n",
      "Epoch 187:\t train loss : 0.5680409392539998; train accuracy : 0.9831816351188079; \n",
      " validation loss : 0.5810977825019061; validation accuracy : 0.9707112970711297\n",
      "Epoch 188:\t train loss : 0.5608558785899836; train accuracy : 0.9903187831097617; \n",
      " validation loss : 0.5790891482704571; validation accuracy : 0.9707112970711297\n",
      "Epoch 189:\t train loss : 0.5573703923897021; train accuracy : 0.9939877319619567; \n",
      " validation loss : 0.5888679026413951; validation accuracy : 0.9623430962343096\n",
      "Epoch 190:\t train loss : 0.5577863287996228; train accuracy : 0.9935812757520369; \n",
      " validation loss : 0.5833216043032293; validation accuracy : 0.9665271966527197\n",
      "Epoch 191:\t train loss : 0.5556762016028544; train accuracy : 0.995656928653304; \n",
      " validation loss : 0.5755281713866102; validation accuracy : 0.9748953974895398\n",
      "Epoch 192:\t train loss : 0.5545040742311055; train accuracy : 0.9969116143622788; \n",
      " validation loss : 0.5682679323287363; validation accuracy : 0.9832635983263598\n",
      "Epoch 193:\t train loss : 0.5558701601685904; train accuracy : 0.995569875151027; \n",
      " validation loss : 0.5785797994035975; validation accuracy : 0.9748953974895398\n",
      "Epoch 194:\t train loss : 0.5579871584907381; train accuracy : 0.993302456705598; \n",
      " validation loss : 0.577888569887361; validation accuracy : 0.9748953974895398\n",
      "Epoch 195:\t train loss : 0.557382675243544; train accuracy : 0.9939198859939898; \n",
      " validation loss : 0.5908217264227398; validation accuracy : 0.9581589958158996\n",
      "Epoch 196:\t train loss : 0.5571599535597457; train accuracy : 0.9942377397069302; \n",
      " validation loss : 0.5875707491680671; validation accuracy : 0.9623430962343096\n",
      "Epoch 197:\t train loss : 0.5555985737507921; train accuracy : 0.9957092846742464; \n",
      " validation loss : 0.5848054395384952; validation accuracy : 0.9665271966527197\n",
      "Epoch 198:\t train loss : 0.5580469697326271; train accuracy : 0.9932308931503454; \n",
      " validation loss : 0.5709688084610223; validation accuracy : 0.9832635983263598\n",
      "Epoch 199:\t train loss : 0.5553089375481562; train accuracy : 0.9960751572229622; \n",
      " validation loss : 0.5947397199787824; validation accuracy : 0.9581589958158996\n",
      "Epoch 200:\t train loss : 0.5550875147449633; train accuracy : 0.9963133926081973; \n",
      " validation loss : 0.5764593783208429; validation accuracy : 0.9748953974895398\n",
      "Epoch 201:\t train loss : 0.5575335073190507; train accuracy : 0.9937457789894358; \n",
      " validation loss : 0.5908583595121376; validation accuracy : 0.9581589958158996\n",
      "Epoch 202:\t train loss : 0.5571389464630815; train accuracy : 0.9942067598128814; \n",
      " validation loss : 0.5839029460886788; validation accuracy : 0.9665271966527197\n",
      "Epoch 203:\t train loss : 0.5562597899183845; train accuracy : 0.9950875182006877; \n",
      " validation loss : 0.5849306517540485; validation accuracy : 0.9665271966527197\n",
      "Epoch 204:\t train loss : 0.5560251874667738; train accuracy : 0.9953471297128164; \n",
      " validation loss : 0.5962046357693915; validation accuracy : 0.9581589958158996\n",
      "Epoch 205:\t train loss : 0.5561376383691312; train accuracy : 0.9952290963164906; \n",
      " validation loss : 0.5780094858542508; validation accuracy : 0.9748953974895398\n",
      "Epoch 206:\t train loss : 0.5577386791159541; train accuracy : 0.9935406920908331; \n",
      " validation loss : 0.5728939847261613; validation accuracy : 0.9790794979079498\n",
      "Epoch 207:\t train loss : 0.5575048462782612; train accuracy : 0.9938232287245578; \n",
      " validation loss : 0.6049954542188121; validation accuracy : 0.9456066945606695\n",
      "Epoch 208:\t train loss : 0.5566207184230854; train accuracy : 0.9947836054400694; \n",
      " validation loss : 0.5769092915336637; validation accuracy : 0.9748953974895398\n",
      "Epoch 209:\t train loss : 0.5591557503797999; train accuracy : 0.9923169862759069; \n",
      " validation loss : 0.573447117038844; validation accuracy : 0.9790794979079498\n",
      "Epoch 210:\t train loss : 0.5548029143389802; train accuracy : 0.9964624058985718; \n",
      " validation loss : 0.5806849667294103; validation accuracy : 0.9707112970711297\n",
      "Epoch 211:\t train loss : 0.5583789732035596; train accuracy : 0.9929189256172744; \n",
      " validation loss : 0.5862969842832239; validation accuracy : 0.9665271966527197\n",
      "Early stopping at epoch 211\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5572620093696452; Train accuracy : 0.9940769540568171; \n",
      " Validation loss : 0.5641245444270315; Validation accuracy : 0.9874476987447699\n",
      "--- Let's train model 27 ! ---\n",
      "Epoch 1:\t train loss : 0.9081456956764024; train accuracy : 0.6256061216270641; \n",
      " validation loss : 0.8375998411304485; validation accuracy : 0.702928870292887\n",
      "Epoch 2:\t train loss : 0.7368755269604116; train accuracy : 0.8122355091545587; \n",
      " validation loss : 0.7261888466834383; validation accuracy : 0.8284518828451883\n",
      "Epoch 3:\t train loss : 0.6925114777933373; train accuracy : 0.8577898943585613; \n",
      " validation loss : 0.715537710492292; validation accuracy : 0.8284518828451883\n",
      "Epoch 4:\t train loss : 0.6674113197380601; train accuracy : 0.8827751789088881; \n",
      " validation loss : 0.6677418710562784; validation accuracy : 0.8870292887029289\n",
      "Epoch 5:\t train loss : 0.6604995015380728; train accuracy : 0.8903733077232876; \n",
      " validation loss : 0.7050828155981862; validation accuracy : 0.8410041841004184\n",
      "Epoch 6:\t train loss : 0.6432450391408105; train accuracy : 0.9069416648595062; \n",
      " validation loss : 0.6660931841382638; validation accuracy : 0.8828451882845189\n",
      "Epoch 7:\t train loss : 0.6393779666710727; train accuracy : 0.9109786548530004; \n",
      " validation loss : 0.7000852314805931; validation accuracy : 0.8410041841004184\n",
      "Epoch 8:\t train loss : 0.6276675865755058; train accuracy : 0.9230976796059357; \n",
      " validation loss : 0.6449091276613756; validation accuracy : 0.9121338912133892\n",
      "Epoch 9:\t train loss : 0.6210737099836167; train accuracy : 0.9300740419467766; \n",
      " validation loss : 0.6503188907101449; validation accuracy : 0.9037656903765691\n",
      "Epoch 10:\t train loss : 0.6081717606282337; train accuracy : 0.9434012825676136; \n",
      " validation loss : 0.6438379280141205; validation accuracy : 0.9037656903765691\n",
      "Epoch 11:\t train loss : 0.5986733875883024; train accuracy : 0.9527727005173642; \n",
      " validation loss : 0.6356974105307245; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.5939988578594927; train accuracy : 0.9573577248365811; \n",
      " validation loss : 0.6587670340543945; validation accuracy : 0.895397489539749\n",
      "Epoch 13:\t train loss : 0.59157195195405; train accuracy : 0.9598825862015552; \n",
      " validation loss : 0.6392613231708715; validation accuracy : 0.9079497907949791\n",
      "Epoch 14:\t train loss : 0.5933512696890848; train accuracy : 0.9576424300628892; \n",
      " validation loss : 0.6263149318660989; validation accuracy : 0.9246861924686193\n",
      "Epoch 15:\t train loss : 0.5945077769643097; train accuracy : 0.9571157718640602; \n",
      " validation loss : 0.67007708690936; validation accuracy : 0.8786610878661087\n",
      "Epoch 16:\t train loss : 0.5911716544058968; train accuracy : 0.9601090492270516; \n",
      " validation loss : 0.6430863846071092; validation accuracy : 0.9079497907949791\n",
      "Epoch 17:\t train loss : 0.5839228748776258; train accuracy : 0.9674667740636327; \n",
      " validation loss : 0.633637483838912; validation accuracy : 0.9163179916317992\n",
      "Epoch 18:\t train loss : 0.5876943300171695; train accuracy : 0.9635515350537501; \n",
      " validation loss : 0.6356450896721003; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.5837584185600845; train accuracy : 0.9674379627621673; \n",
      " validation loss : 0.6317392982762747; validation accuracy : 0.9163179916317992\n",
      "Epoch 20:\t train loss : 0.5835660304562795; train accuracy : 0.9677632516496794; \n",
      " validation loss : 0.6227243853917344; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5870839002187007; train accuracy : 0.963817032745748; \n",
      " validation loss : 0.6282150394450992; validation accuracy : 0.9246861924686193\n",
      "Epoch 22:\t train loss : 0.5855964213065615; train accuracy : 0.965269370178754; \n",
      " validation loss : 0.619147797520398; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5916313238606156; train accuracy : 0.9591449549242541; \n",
      " validation loss : 0.6523548297415382; validation accuracy : 0.895397489539749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:\t train loss : 0.5813710810008053; train accuracy : 0.9698447907308156; \n",
      " validation loss : 0.6341660577439416; validation accuracy : 0.9121338912133892\n",
      "Epoch 25:\t train loss : 0.5808699821742083; train accuracy : 0.9702379255862945; \n",
      " validation loss : 0.6139938770248753; validation accuracy : 0.9330543933054394\n",
      "Epoch 26:\t train loss : 0.5775466605002693; train accuracy : 0.9736708076458378; \n",
      " validation loss : 0.6164217321727637; validation accuracy : 0.9288702928870293\n",
      "Epoch 27:\t train loss : 0.5832168214236791; train accuracy : 0.9680383531088324; \n",
      " validation loss : 0.6210915237564874; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.5743143868206985; train accuracy : 0.9768425291985502; \n",
      " validation loss : 0.6472861098155263; validation accuracy : 0.9037656903765691\n",
      "Epoch 29:\t train loss : 0.5692719571426802; train accuracy : 0.982215372223427; \n",
      " validation loss : 0.6078271610698596; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.5715120702778461; train accuracy : 0.9798240342018031; \n",
      " validation loss : 0.6413755840143156; validation accuracy : 0.9163179916317992\n",
      "Epoch 31:\t train loss : 0.5755527589779907; train accuracy : 0.9756284271507791; \n",
      " validation loss : 0.6077225394999024; validation accuracy : 0.9456066945606695\n",
      "Epoch 32:\t train loss : 0.5682327149413785; train accuracy : 0.9831159577434245; \n",
      " validation loss : 0.5947433909605631; validation accuracy : 0.9581589958158996\n",
      "Epoch 33:\t train loss : 0.5784879177653739; train accuracy : 0.9725998327085721; \n",
      " validation loss : 0.611554974112386; validation accuracy : 0.9456066945606695\n",
      "Epoch 34:\t train loss : 0.5694094781260972; train accuracy : 0.9816267542365005; \n",
      " validation loss : 0.5901482393560256; validation accuracy : 0.9581589958158996\n",
      "Epoch 35:\t train loss : 0.5679051512431307; train accuracy : 0.983255367266644; \n",
      " validation loss : 0.6035843844566786; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5719570720960383; train accuracy : 0.9793903156851204; \n",
      " validation loss : 0.6219108025920703; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5744584587785193; train accuracy : 0.9767570246909756; \n",
      " validation loss : 0.6193774860724327; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5718659656776843; train accuracy : 0.979374825738096; \n",
      " validation loss : 0.5983442266506174; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5756596626711439; train accuracy : 0.9754521515536417; \n",
      " validation loss : 0.619204508499267; validation accuracy : 0.9330543933054394\n",
      "Epoch 40:\t train loss : 0.5672426759311048; train accuracy : 0.9839443601102884; \n",
      " validation loss : 0.6206684998882834; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5750259190986455; train accuracy : 0.9760931255615106; \n",
      " validation loss : 0.6187780954551465; validation accuracy : 0.9330543933054394\n",
      "Epoch 42:\t train loss : 0.5704874180271853; train accuracy : 0.981024814895133; \n",
      " validation loss : 0.6038591819384851; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.5652397159922998; train accuracy : 0.986155704947489; \n",
      " validation loss : 0.612272715838671; validation accuracy : 0.9288702928870293\n",
      "Epoch 44:\t train loss : 0.5655220366891597; train accuracy : 0.9856968927166269; \n",
      " validation loss : 0.630359930648627; validation accuracy : 0.9205020920502092\n",
      "Epoch 45:\t train loss : 0.5627047726637; train accuracy : 0.9886709625453081; \n",
      " validation loss : 0.6118489869688551; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5688053449689464; train accuracy : 0.9823451779794913; \n",
      " validation loss : 0.6191120512348943; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.5780080402370223; train accuracy : 0.9729406115431085; \n",
      " validation loss : 0.6556806534924939; validation accuracy : 0.8870292887029289\n",
      "Epoch 48:\t train loss : 0.5696321788095888; train accuracy : 0.981614981876762; \n",
      " validation loss : 0.7024442347534204; validation accuracy : 0.8493723849372385\n",
      "Epoch 49:\t train loss : 0.5667139194874483; train accuracy : 0.9844886768487252; \n",
      " validation loss : 0.6190950660039963; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5659310004073774; train accuracy : 0.9852263081260262; \n",
      " validation loss : 0.6379668373775841; validation accuracy : 0.9121338912133892\n",
      "Epoch 51:\t train loss : 0.5669198322166437; train accuracy : 0.9841692741410825; \n",
      " validation loss : 0.6127044741056457; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5732890869157895; train accuracy : 0.9776864215124385; \n",
      " validation loss : 0.6388754354419373; validation accuracy : 0.9079497907949791\n",
      "Epoch 53:\t train loss : 0.567842245331125; train accuracy : 0.9833520245360761; \n",
      " validation loss : 0.63314866898199; validation accuracy : 0.9163179916317992\n",
      "Epoch 54:\t train loss : 0.5644788040857576; train accuracy : 0.9867384367545463; \n",
      " validation loss : 0.6174368279988341; validation accuracy : 0.9330543933054394\n",
      "Epoch 55:\t train loss : 0.5646904542043955; train accuracy : 0.9864596177081074; \n",
      " validation loss : 0.6122263401319828; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.5645810983413462; train accuracy : 0.9868121689023823; \n",
      " validation loss : 0.6008691180429416; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5664606575838667; train accuracy : 0.9847727624771523; \n",
      " validation loss : 0.6201740356826237; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.5693507639662341; train accuracy : 0.9818377273149725; \n",
      " validation loss : 0.6331899176504124; validation accuracy : 0.9163179916317992\n",
      "Epoch 59:\t train loss : 0.5652656261216484; train accuracy : 0.9859233557421233; \n",
      " validation loss : 0.6023628430695711; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5712930245149718; train accuracy : 0.9798785588153288; \n",
      " validation loss : 0.6085888007238607; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5703896041139621; train accuracy : 0.9808020694569225; \n",
      " validation loss : 0.6025341002063443; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5623201258748982; train accuracy : 0.9890021376126894; \n",
      " validation loss : 0.6017730527108142; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5614675743461969; train accuracy : 0.9898578022863161; \n",
      " validation loss : 0.6047605219335646; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5637287475807282; train accuracy : 0.9877917531522042; \n",
      " validation loss : 0.6104084160512233; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.5624089599488167; train accuracy : 0.98886272808947; \n",
      " validation loss : 0.6215772691323569; validation accuracy : 0.9288702928870293\n",
      "Epoch 66:\t train loss : 0.5676081403349265; train accuracy : 0.9835726013817033; \n",
      " validation loss : 0.6140660465560752; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5667547570700641; train accuracy : 0.9845447504569534; \n",
      " validation loss : 0.6078305436058066; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.561305240311546; train accuracy : 0.9899448557885931; \n",
      " validation loss : 0.6283956222178895; validation accuracy : 0.9246861924686193\n",
      "Epoch 69:\t train loss : 0.569626309184484; train accuracy : 0.9815242107871991; \n",
      " validation loss : 0.6191307926657474; validation accuracy : 0.9288702928870293\n",
      "Epoch 70:\t train loss : 0.5655225450955942; train accuracy : 0.9855574831934075; \n",
      " validation loss : 0.6100625412833539; validation accuracy : 0.9414225941422594\n",
      "Epoch 71:\t train loss : 0.5654650444890026; train accuracy : 0.9856327643359459; \n",
      " validation loss : 0.6032119634219828; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5646686599765396; train accuracy : 0.9864964837820255; \n",
      " validation loss : 0.5998574008693567; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.561548419350072; train accuracy : 0.9896468292078441; \n",
      " validation loss : 0.5940732280981111; validation accuracy : 0.9581589958158996\n",
      "Epoch 74:\t train loss : 0.5686301903575476; train accuracy : 0.9824263453018991; \n",
      " validation loss : 0.6255782900064917; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75:\t train loss : 0.5635536678430701; train accuracy : 0.9876796059357477; \n",
      " validation loss : 0.6416695205571209; validation accuracy : 0.9079497907949791\n",
      "Epoch 76:\t train loss : 0.5981900104134282; train accuracy : 0.9519731094519657; \n",
      " validation loss : 0.635342210807972; validation accuracy : 0.9121338912133892\n",
      "Epoch 77:\t train loss : 0.579803372571922; train accuracy : 0.9710588927785867; \n",
      " validation loss : 0.6144977777947619; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5684653868302542; train accuracy : 0.9826800706341584; \n",
      " validation loss : 0.6027326924151334; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5653632147756351; train accuracy : 0.985981597942935; \n",
      " validation loss : 0.5919732196332675; validation accuracy : 0.9581589958158996\n",
      "Epoch 80:\t train loss : 0.5650003805253536; train accuracy : 0.9863998265125933; \n",
      " validation loss : 0.6150200073061343; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.5645125590077579; train accuracy : 0.9867945103627745; \n",
      " validation loss : 0.6054676817652207; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5664842587316277; train accuracy : 0.984643576318969; \n",
      " validation loss : 0.6108230495131962; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5653040749395877; train accuracy : 0.9858672821338951; \n",
      " validation loss : 0.6308977627828264; validation accuracy : 0.9163179916317992\n",
      "Epoch 84:\t train loss : 0.5662856713306015; train accuracy : 0.9850131664549707; \n",
      " validation loss : 0.6118626672942632; validation accuracy : 0.9372384937238494\n",
      "Early stopping at epoch 84\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5694094781260972; Train accuracy : 0.9816267542365005; \n",
      " Validation loss : 0.5901482393560256; Validation accuracy : 0.9581589958158996\n",
      "--- Let's train model 28 ! ---\n",
      "Epoch 1:\t train loss : 0.9691218037490356; train accuracy : 0.5493426066482853; \n",
      " validation loss : 0.8449327924574795; validation accuracy : 0.6861924686192469\n",
      "Epoch 2:\t train loss : 0.7896159218750542; train accuracy : 0.7567734440348214; \n",
      " validation loss : 0.7131246708090697; validation accuracy : 0.8451882845188284\n",
      "Epoch 3:\t train loss : 0.7243224036572892; train accuracy : 0.8252588370147774; \n",
      " validation loss : 0.6812902858181077; validation accuracy : 0.8786610878661087\n",
      "Epoch 4:\t train loss : 0.6883301977143668; train accuracy : 0.8623823538523498; \n",
      " validation loss : 0.6692044066693721; validation accuracy : 0.891213389121339\n",
      "Epoch 5:\t train loss : 0.6676649243480289; train accuracy : 0.8822234269958796; \n",
      " validation loss : 0.6600116696436972; validation accuracy : 0.895397489539749\n",
      "Epoch 6:\t train loss : 0.6525382048460129; train accuracy : 0.8984317977632517; \n",
      " validation loss : 0.6716692202497767; validation accuracy : 0.8661087866108786\n",
      "Epoch 7:\t train loss : 0.6420808900954076; train accuracy : 0.9088314383964807; \n",
      " validation loss : 0.6686208948286219; validation accuracy : 0.8828451882845189\n",
      "Epoch 8:\t train loss : 0.6297678546620142; train accuracy : 0.9213259394652871; \n",
      " validation loss : 0.6399680682021833; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.6181977723829775; train accuracy : 0.9332457634994888; \n",
      " validation loss : 0.6566376576810682; validation accuracy : 0.895397489539749\n",
      "Epoch 10:\t train loss : 0.6110627397054517; train accuracy : 0.9402781994485578; \n",
      " validation loss : 0.6359113586418005; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.5959304809468066; train accuracy : 0.9558263886737507; \n",
      " validation loss : 0.6432284781730323; validation accuracy : 0.9037656903765691\n",
      "Epoch 12:\t train loss : 0.5960970443199338; train accuracy : 0.9555454010347284; \n",
      " validation loss : 0.630064091105301; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.5936413772272982; train accuracy : 0.9577781219988227; \n",
      " validation loss : 0.6280813402009928; validation accuracy : 0.9288702928870293\n",
      "Epoch 14:\t train loss : 0.5887840613182109; train accuracy : 0.962818240961616; \n",
      " validation loss : 0.6294649055108205; validation accuracy : 0.9246861924686193\n",
      "Epoch 15:\t train loss : 0.5840389839261606; train accuracy : 0.9677595340623935; \n",
      " validation loss : 0.6218932557051127; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5801078780836684; train accuracy : 0.9713841816660987; \n",
      " validation loss : 0.594867998148567; validation accuracy : 0.9581589958158996\n",
      "Epoch 17:\t train loss : 0.5748089371835479; train accuracy : 0.9767533071036897; \n",
      " validation loss : 0.6177862381849197; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.5755381875180868; train accuracy : 0.9759633198054463; \n",
      " validation loss : 0.6374306888683987; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.5776822089419053; train accuracy : 0.9733978747792682; \n",
      " validation loss : 0.5941045563866367; validation accuracy : 0.9581589958158996\n",
      "Epoch 20:\t train loss : 0.586569423810999; train accuracy : 0.9643827256110784; \n",
      " validation loss : 0.6137839803071145; validation accuracy : 0.9372384937238494\n",
      "Epoch 21:\t train loss : 0.5776975923838042; train accuracy : 0.9735992440905852; \n",
      " validation loss : 0.5890014256236107; validation accuracy : 0.9581589958158996\n",
      "Epoch 22:\t train loss : 0.5677879867980816; train accuracy : 0.9837141794975062; \n",
      " validation loss : 0.6077105023557058; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.5689270854949787; train accuracy : 0.9824498900213762; \n",
      " validation loss : 0.6176103290962738; validation accuracy : 0.9288702928870293\n",
      "Epoch 24:\t train loss : 0.5658032346110676; train accuracy : 0.9855633693732767; \n",
      " validation loss : 0.6066787223354471; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.5754342006833133; train accuracy : 0.9758858700703243; \n",
      " validation loss : 0.6172315401792864; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5698146818892141; train accuracy : 0.9814526472319465; \n",
      " validation loss : 0.5962828335822694; validation accuracy : 0.9539748953974896\n",
      "Epoch 27:\t train loss : 0.5631714373923723; train accuracy : 0.9883611636048205; \n",
      " validation loss : 0.601289809261035; validation accuracy : 0.9539748953974896\n",
      "Epoch 28:\t train loss : 0.5634028318015057; train accuracy : 0.9881192106322997; \n",
      " validation loss : 0.588324458132805; validation accuracy : 0.9623430962343096\n",
      "Epoch 29:\t train loss : 0.5645126616057217; train accuracy : 0.9867656990613092; \n",
      " validation loss : 0.6072506542531979; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.56530350451315; train accuracy : 0.9859137519749682; \n",
      " validation loss : 0.5908707228871944; validation accuracy : 0.9539748953974896\n",
      "Epoch 31:\t train loss : 0.5649932007397033; train accuracy : 0.9862294370953252; \n",
      " validation loss : 0.5867655439534385; validation accuracy : 0.9623430962343096\n",
      "Epoch 32:\t train loss : 0.5651354267868849; train accuracy : 0.9862486446296354; \n",
      " validation loss : 0.5999336907999285; validation accuracy : 0.9497907949790795\n",
      "Epoch 33:\t train loss : 0.5695693057249427; train accuracy : 0.9819077418755228; \n",
      " validation loss : 0.6096485254033834; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5640165875778204; train accuracy : 0.9872207937048856; \n",
      " validation loss : 0.5833936065380005; validation accuracy : 0.9665271966527197\n",
      "Epoch 35:\t train loss : 0.5633620334869636; train accuracy : 0.9879894048762353; \n",
      " validation loss : 0.5985864470445547; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5614758416740739; train accuracy : 0.9899411382013074; \n",
      " validation loss : 0.5958947112228562; validation accuracy : 0.9539748953974896\n",
      "Epoch 37:\t train loss : 0.5622647881547361; train accuracy : 0.9890176275597138; \n",
      " validation loss : 0.5989041948349637; validation accuracy : 0.9539748953974896\n",
      "Epoch 38:\t train loss : 0.5645858111815326; train accuracy : 0.9864617863006908; \n",
      " validation loss : 0.6106890163533362; validation accuracy : 0.9414225941422594\n",
      "Epoch 39:\t train loss : 0.5753705351581889; train accuracy : 0.9754617553207968; \n",
      " validation loss : 0.5976781190407582; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.5703386588998873; train accuracy : 0.980538740357508; \n",
      " validation loss : 0.599211728348052; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41:\t train loss : 0.5628063497833464; train accuracy : 0.9885839090430311; \n",
      " validation loss : 0.593007138656311; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.564025246823868; train accuracy : 0.987158833916788; \n",
      " validation loss : 0.5921075836802955; validation accuracy : 0.9539748953974896\n",
      "Epoch 43:\t train loss : 0.5641457513735478; train accuracy : 0.9870968741286905; \n",
      " validation loss : 0.6206545022897274; validation accuracy : 0.9246861924686193\n",
      "Epoch 44:\t train loss : 0.5639483106321381; train accuracy : 0.9872768673131138; \n",
      " validation loss : 0.5830195136166987; validation accuracy : 0.9707112970711297\n",
      "Epoch 45:\t train loss : 0.5593901525830267; train accuracy : 0.9918832677592243; \n",
      " validation loss : 0.5933688241659848; validation accuracy : 0.9539748953974896\n",
      "Epoch 46:\t train loss : 0.5595263994068431; train accuracy : 0.9916915022150624; \n",
      " validation loss : 0.6065069550144836; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.559760404499125; train accuracy : 0.9914687567768519; \n",
      " validation loss : 0.578844287806062; validation accuracy : 0.9748953974895398\n",
      "Epoch 48:\t train loss : 0.564339667284946; train accuracy : 0.9868837324576349; \n",
      " validation loss : 0.624173703477843; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5629111256417189; train accuracy : 0.9884444995198116; \n",
      " validation loss : 0.5932918758696952; validation accuracy : 0.9581589958158996\n",
      "Epoch 50:\t train loss : 0.5610492077187971; train accuracy : 0.9902199572477463; \n",
      " validation loss : 0.5880546094918967; validation accuracy : 0.9623430962343096\n",
      "Epoch 51:\t train loss : 0.5606822205632309; train accuracy : 0.9905976021562006; \n",
      " validation loss : 0.5806578798678358; validation accuracy : 0.9707112970711297\n",
      "Epoch 52:\t train loss : 0.5889421953138168; train accuracy : 0.961750983611636; \n",
      " validation loss : 0.6117426486154877; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.5844592104518921; train accuracy : 0.9663691564174851; \n",
      " validation loss : 0.6433494960110566; validation accuracy : 0.9079497907949791\n",
      "Epoch 54:\t train loss : 0.568100927097241; train accuracy : 0.9828563462312959; \n",
      " validation loss : 0.5901512474450303; validation accuracy : 0.9581589958158996\n",
      "Epoch 55:\t train loss : 0.561081178654253; train accuracy : 0.9900842653118126; \n",
      " validation loss : 0.5907392531264778; validation accuracy : 0.9623430962343096\n",
      "Epoch 56:\t train loss : 0.5595209949442078; train accuracy : 0.9916818984479073; \n",
      " validation loss : 0.6000335079651262; validation accuracy : 0.9539748953974896\n",
      "Epoch 57:\t train loss : 0.5607559053517358; train accuracy : 0.9905201524210787; \n",
      " validation loss : 0.5890110492807153; validation accuracy : 0.9581589958158996\n",
      "Epoch 58:\t train loss : 0.5589890925860995; train accuracy : 0.992239536540785; \n",
      " validation loss : 0.5856636499249155; validation accuracy : 0.9665271966527197\n",
      "Epoch 59:\t train loss : 0.5626191208775548; train accuracy : 0.9884541032869668; \n",
      " validation loss : 0.6081298899759701; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5619990029008753; train accuracy : 0.9891880169769819; \n",
      " validation loss : 0.5824610056678865; validation accuracy : 0.9665271966527197\n",
      "Epoch 61:\t train loss : 0.5774844815403121; train accuracy : 0.9733764986523746; \n",
      " validation loss : 0.6309254606148791; validation accuracy : 0.9205020920502092\n",
      "Epoch 62:\t train loss : 0.5814069322644009; train accuracy : 0.9692834350506522; \n",
      " validation loss : 0.6180575274175663; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5742521174408236; train accuracy : 0.9767495895164039; \n",
      " validation loss : 0.5940109568199923; validation accuracy : 0.9581589958158996\n",
      "Epoch 64:\t train loss : 0.5629215759946993; train accuracy : 0.9883301837107717; \n",
      " validation loss : 0.5841895939858261; validation accuracy : 0.9707112970711297\n",
      "Epoch 65:\t train loss : 0.5637614113262097; train accuracy : 0.9874878403915859; \n",
      " validation loss : 0.6018973416155091; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5599124958440909; train accuracy : 0.9913101397193221; \n",
      " validation loss : 0.5799951032373057; validation accuracy : 0.9665271966527197\n",
      "Epoch 67:\t train loss : 0.5635770150653127; train accuracy : 0.987608042380495; \n",
      " validation loss : 0.5805546048332733; validation accuracy : 0.9707112970711297\n",
      "Epoch 68:\t train loss : 0.5743498426787244; train accuracy : 0.9766876297283064; \n",
      " validation loss : 0.5932119460596845; validation accuracy : 0.9539748953974896\n",
      "Epoch 69:\t train loss : 0.5659489716191413; train accuracy : 0.9850986709625453; \n",
      " validation loss : 0.5937090605087076; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5598795830254315; train accuracy : 0.9915211127977942; \n",
      " validation loss : 0.6007000068859385; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5625833798603351; train accuracy : 0.9889091979305431; \n",
      " validation loss : 0.5963862127254351; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5611065789826266; train accuracy : 0.9901676012268038; \n",
      " validation loss : 0.5930833849480966; validation accuracy : 0.9539748953974896\n",
      "Epoch 73:\t train loss : 0.5588848450348437; train accuracy : 0.9924659995662815; \n",
      " validation loss : 0.6089848109521817; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5585933368506082; train accuracy : 0.9927603085597447; \n",
      " validation loss : 0.5913570879575966; validation accuracy : 0.9581589958158996\n",
      "Epoch 75:\t train loss : 0.5610549988748689; train accuracy : 0.9900399640633228; \n",
      " validation loss : 0.5983469498087515; validation accuracy : 0.9539748953974896\n",
      "Epoch 76:\t train loss : 0.563348795277927; train accuracy : 0.987896465194089; \n",
      " validation loss : 0.6058148475123106; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5591097998799234; train accuracy : 0.9921930666997119; \n",
      " validation loss : 0.59027078601864; validation accuracy : 0.9623430962343096\n",
      "Epoch 78:\t train loss : 0.5589005001762517; train accuracy : 0.9924601133864122; \n",
      " validation loss : 0.5902679103943816; validation accuracy : 0.9581589958158996\n",
      "Epoch 79:\t train loss : 0.5610569666462059; train accuracy : 0.990210353480591; \n",
      " validation loss : 0.5817247454298475; validation accuracy : 0.9665271966527197\n",
      "Epoch 80:\t train loss : 0.5640117352855019; train accuracy : 0.9873019610272933; \n",
      " validation loss : 0.6385694190206591; validation accuracy : 0.9121338912133892\n",
      "Epoch 81:\t train loss : 0.5675045613672253; train accuracy : 0.9836116360482047; \n",
      " validation loss : 0.6032839394550416; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.560053653481241; train accuracy : 0.9911707301961027; \n",
      " validation loss : 0.5843643288832617; validation accuracy : 0.9665271966527197\n",
      "Epoch 83:\t train loss : 0.5618263045587879; train accuracy : 0.9893060503733078; \n",
      " validation loss : 0.5965158342610353; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.5593078650139933; train accuracy : 0.9919916973883949; \n",
      " validation loss : 0.5744372426265513; validation accuracy : 0.9748953974895398\n",
      "Epoch 85:\t train loss : 0.5588874163898652; train accuracy : 0.9923516837572416; \n",
      " validation loss : 0.5971694699212817; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5609539716709638; train accuracy : 0.9903342730567861; \n",
      " validation loss : 0.5976893456199467; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5600265994194349; train accuracy : 0.9913101397193221; \n",
      " validation loss : 0.5844843973124978; validation accuracy : 0.9665271966527197\n",
      "Epoch 88:\t train loss : 0.5609735747007035; train accuracy : 0.9902258434276154; \n",
      " validation loss : 0.5918659442931817; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5635068342674574; train accuracy : 0.9877511694910003; \n",
      " validation loss : 0.5901172243794337; validation accuracy : 0.9623430962343096\n",
      "Epoch 90:\t train loss : 0.5591468964774259; train accuracy : 0.9920536571764924; \n",
      " validation loss : 0.5746477062570765; validation accuracy : 0.9748953974895398\n",
      "Epoch 91:\t train loss : 0.5616393952631564; train accuracy : 0.9895133058644939; \n",
      " validation loss : 0.5960821159259418; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:\t train loss : 0.561831017055344; train accuracy : 0.9893776139285604; \n",
      " validation loss : 0.6105533131714538; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5684129451547636; train accuracy : 0.9827206542953623; \n",
      " validation loss : 0.6150906422305563; validation accuracy : 0.9372384937238494\n",
      "Epoch 94:\t train loss : 0.5667253843726099; train accuracy : 0.9845410328696675; \n",
      " validation loss : 0.5650927194052849; validation accuracy : 0.9874476987447699\n",
      "Epoch 95:\t train loss : 0.5587566674261517; train accuracy : 0.9926267852163946; \n",
      " validation loss : 0.5647227288990851; validation accuracy : 0.9874476987447699\n",
      "Epoch 96:\t train loss : 0.5605743941383806; train accuracy : 0.9907097493726571; \n",
      " validation loss : 0.5934238338040704; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5634395618160037; train accuracy : 0.987809411691812; \n",
      " validation loss : 0.6022902498414788; validation accuracy : 0.9497907949790795\n",
      "Epoch 98:\t train loss : 0.5584709818678574; train accuracy : 0.9929210942098577; \n",
      " validation loss : 0.579969163133276; validation accuracy : 0.9707112970711297\n",
      "Epoch 99:\t train loss : 0.5589869950595597; train accuracy : 0.9923014963288825; \n",
      " validation loss : 0.5882084722714996; validation accuracy : 0.9623430962343096\n",
      "Epoch 100:\t train loss : 0.5627067191563222; train accuracy : 0.9883611636048205; \n",
      " validation loss : 0.5980264633444538; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5590923220043971; train accuracy : 0.9923420799900864; \n",
      " validation loss : 0.6056254936691142; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5562306659844689; train accuracy : 0.9950992905604262; \n",
      " validation loss : 0.5999391274056504; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5589167287245709; train accuracy : 0.9924195297252083; \n",
      " validation loss : 0.588361221436772; validation accuracy : 0.9623430962343096\n",
      "Epoch 104:\t train loss : 0.5568027639162673; train accuracy : 0.994594008488491; \n",
      " validation loss : 0.5823180226798608; validation accuracy : 0.9707112970711297\n",
      "Epoch 105:\t train loss : 0.5559951368513381; train accuracy : 0.9954304656278076; \n",
      " validation loss : 0.6075290991531759; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.5572179350663962; train accuracy : 0.994067350289662; \n",
      " validation loss : 0.5862240128600558; validation accuracy : 0.9665271966527197\n",
      "Epoch 107:\t train loss : 0.5603189068326802; train accuracy : 0.9908764212026395; \n",
      " validation loss : 0.5880946974577185; validation accuracy : 0.9623430962343096\n",
      "Epoch 108:\t train loss : 0.5587359945102395; train accuracy : 0.9925899191424765; \n",
      " validation loss : 0.6089517321687266; validation accuracy : 0.9414225941422594\n",
      "Epoch 109:\t train loss : 0.5590602786217272; train accuracy : 0.9921620868056631; \n",
      " validation loss : 0.572137065071684; validation accuracy : 0.9790794979079498\n",
      "Epoch 110:\t train loss : 0.5575956415136141; train accuracy : 0.9938040211902475; \n",
      " validation loss : 0.5838823208133098; validation accuracy : 0.9665271966527197\n",
      "Epoch 111:\t train loss : 0.565583374082415; train accuracy : 0.9856253291613742; \n",
      " validation loss : 0.5757713230829142; validation accuracy : 0.9790794979079498\n",
      "Epoch 112:\t train loss : 0.5574638704964817; train accuracy : 0.9938446048514514; \n",
      " validation loss : 0.5793477277491696; validation accuracy : 0.9707112970711297\n",
      "Epoch 113:\t train loss : 0.5573546775044841; train accuracy : 0.9939316583537284; \n",
      " validation loss : 0.589178685786421; validation accuracy : 0.9623430962343096\n",
      "Epoch 114:\t train loss : 0.559386706207389; train accuracy : 0.9918987577062487; \n",
      " validation loss : 0.600675192373547; validation accuracy : 0.9497907949790795\n",
      "Epoch 115:\t train loss : 0.5592615243698641; train accuracy : 0.9921311069116143; \n",
      " validation loss : 0.5890851990840509; validation accuracy : 0.9623430962343096\n",
      "Epoch 116:\t train loss : 0.5609500518618137; train accuracy : 0.9904213265590631; \n",
      " validation loss : 0.611445543672501; validation accuracy : 0.9372384937238494\n",
      "Epoch 117:\t train loss : 0.5577619748179694; train accuracy : 0.9936491217200037; \n",
      " validation loss : 0.5765647172969118; validation accuracy : 0.9748953974895398\n",
      "Epoch 118:\t train loss : 0.5607733966859912; train accuracy : 0.9904619102202671; \n",
      " validation loss : 0.6024370852089223; validation accuracy : 0.9497907949790795\n",
      "Epoch 119:\t train loss : 0.5675198047994177; train accuracy : 0.9836271259952291; \n",
      " validation loss : 0.5977517112096603; validation accuracy : 0.9539748953974896\n",
      "Epoch 120:\t train loss : 0.557440064901359; train accuracy : 0.9938350010842962; \n",
      " validation loss : 0.5890235733622478; validation accuracy : 0.9623430962343096\n",
      "Epoch 121:\t train loss : 0.560734032812293; train accuracy : 0.9906013197434865; \n",
      " validation loss : 0.5884764962942737; validation accuracy : 0.9623430962343096\n",
      "Epoch 122:\t train loss : 0.5617314684827803; train accuracy : 0.989522909631649; \n",
      " validation loss : 0.5741776715862066; validation accuracy : 0.9790794979079498\n",
      "Epoch 123:\t train loss : 0.560802473278356; train accuracy : 0.990576226029307; \n",
      " validation loss : 0.583271767811754; validation accuracy : 0.9707112970711297\n",
      "Epoch 124:\t train loss : 0.5594008724280921; train accuracy : 0.9919548313144769; \n",
      " validation loss : 0.6050508432659171; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.564191626480066; train accuracy : 0.9870658942346417; \n",
      " validation loss : 0.5964094512670162; validation accuracy : 0.9539748953974896\n",
      "Epoch 126:\t train loss : 0.559354517066398; train accuracy : 0.9919858112085257; \n",
      " validation loss : 0.5873383550188026; validation accuracy : 0.9623430962343096\n",
      "Epoch 127:\t train loss : 0.5561596256470912; train accuracy : 0.9951981164224418; \n",
      " validation loss : 0.5852011006073512; validation accuracy : 0.9665271966527197\n",
      "Epoch 128:\t train loss : 0.5591787365705309; train accuracy : 0.9920226772824436; \n",
      " validation loss : 0.5660571277559185; validation accuracy : 0.9832635983263598\n",
      "Epoch 129:\t train loss : 0.5588611678159472; train accuracy : 0.992440905852102; \n",
      " validation loss : 0.5726672224738586; validation accuracy : 0.9790794979079498\n",
      "Epoch 130:\t train loss : 0.5592713654422479; train accuracy : 0.9921001270175656; \n",
      " validation loss : 0.5727159773310742; validation accuracy : 0.9790794979079498\n",
      "Epoch 131:\t train loss : 0.5586741254246718; train accuracy : 0.9926732550574677; \n",
      " validation loss : 0.5737878678671913; validation accuracy : 0.9748953974895398\n",
      "Epoch 132:\t train loss : 0.558868232755812; train accuracy : 0.9924040397781839; \n",
      " validation loss : 0.5762769656182495; validation accuracy : 0.9748953974895398\n",
      "Epoch 133:\t train loss : 0.5562586706852001; train accuracy : 0.9951051767402955; \n",
      " validation loss : 0.5935223588484271; validation accuracy : 0.9539748953974896\n",
      "Epoch 134:\t train loss : 0.5578975214516749; train accuracy : 0.9935406920908331; \n",
      " validation loss : 0.5900837188571443; validation accuracy : 0.9623430962343096\n",
      "Epoch 135:\t train loss : 0.56127812918589; train accuracy : 0.9899411382013074; \n",
      " validation loss : 0.5862125883883474; validation accuracy : 0.9623430962343096\n",
      "Epoch 136:\t train loss : 0.5622366694994997; train accuracy : 0.9889342916447226; \n",
      " validation loss : 0.6300445285432194; validation accuracy : 0.9163179916317992\n",
      "Epoch 137:\t train loss : 0.5601228447371934; train accuracy : 0.9910815081012423; \n",
      " validation loss : 0.5738382545791036; validation accuracy : 0.9748953974895398\n",
      "Epoch 138:\t train loss : 0.5558776537096021; train accuracy : 0.9955234053099539; \n",
      " validation loss : 0.5871903745870269; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5608398239572476; train accuracy : 0.9904427026859568; \n",
      " validation loss : 0.6100628570103215; validation accuracy : 0.9414225941422594\n",
      "Epoch 140:\t train loss : 0.5578599191956456; train accuracy : 0.9936026518789306; \n",
      " validation loss : 0.5762148361961543; validation accuracy : 0.9748953974895398\n",
      "Epoch 141:\t train loss : 0.5565834112985724; train accuracy : 0.9947024381176617; \n",
      " validation loss : 0.5766469000485812; validation accuracy : 0.9748953974895398\n",
      "Epoch 142:\t train loss : 0.5558216265747954; train accuracy : 0.9956104588122309; \n",
      " validation loss : 0.5909639402947117; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143:\t train loss : 0.5571553515714531; train accuracy : 0.994191269865857; \n",
      " validation loss : 0.5690135865847037; validation accuracy : 0.9832635983263598\n",
      "Epoch 144:\t train loss : 0.559839720760346; train accuracy : 0.9913720995074197; \n",
      " validation loss : 0.5753566504844886; validation accuracy : 0.9748953974895398\n",
      "Epoch 145:\t train loss : 0.5580034499472994; train accuracy : 0.9934012825676136; \n",
      " validation loss : 0.5791445825021502; validation accuracy : 0.9707112970711297\n",
      "Early stopping at epoch 145\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5587566674261517; Train accuracy : 0.9926267852163946; \n",
      " Validation loss : 0.5647227288990851; Validation accuracy : 0.9874476987447699\n",
      "--- Let's train model 29 ! ---\n",
      "Epoch 1:\t train loss : 0.9469533520168111; train accuracy : 0.5776978840732365; \n",
      " validation loss : 0.8290867287546004; validation accuracy : 0.7238493723849372\n",
      "Epoch 2:\t train loss : 0.7655717108926798; train accuracy : 0.7840459741627683; \n",
      " validation loss : 0.7127411763950787; validation accuracy : 0.8410041841004184\n",
      "Epoch 3:\t train loss : 0.708365116521729; train accuracy : 0.8418795501719384; \n",
      " validation loss : 0.7034762970954075; validation accuracy : 0.8535564853556485\n",
      "Epoch 4:\t train loss : 0.6809314622798721; train accuracy : 0.8692465689767341; \n",
      " validation loss : 0.6819680597099755; validation accuracy : 0.8619246861924686\n",
      "Epoch 5:\t train loss : 0.668658949204884; train accuracy : 0.8815573592738313; \n",
      " validation loss : 0.6771937752335268; validation accuracy : 0.8828451882845189\n",
      "Epoch 6:\t train loss : 0.655220693899084; train accuracy : 0.8951767402955482; \n",
      " validation loss : 0.6818487052659773; validation accuracy : 0.8661087866108786\n",
      "Epoch 7:\t train loss : 0.639898976603198; train accuracy : 0.9107772855416835; \n",
      " validation loss : 0.6824076127120458; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6357931012297613; train accuracy : 0.9147987855881533; \n",
      " validation loss : 0.6774397031630938; validation accuracy : 0.8661087866108786\n",
      "Epoch 9:\t train loss : 0.6272189391793324; train accuracy : 0.9240986399826513; \n",
      " validation loss : 0.6852385988605242; validation accuracy : 0.8619246861924686\n",
      "Epoch 10:\t train loss : 0.6295967728235261; train accuracy : 0.921114966386815; \n",
      " validation loss : 0.7027153722808337; validation accuracy : 0.8451882845188284\n",
      "Epoch 11:\t train loss : 0.6218464396855258; train accuracy : 0.9292124910932804; \n",
      " validation loss : 0.6529490838966574; validation accuracy : 0.895397489539749\n",
      "Epoch 12:\t train loss : 0.610064198264454; train accuracy : 0.9410740729266706; \n",
      " validation loss : 0.6386284016321517; validation accuracy : 0.9079497907949791\n",
      "Epoch 13:\t train loss : 0.6043032467848892; train accuracy : 0.9468518231667648; \n",
      " validation loss : 0.6337492903088079; validation accuracy : 0.9163179916317992\n",
      "Epoch 14:\t train loss : 0.5984089633715426; train accuracy : 0.9524591839895907; \n",
      " validation loss : 0.6534718980512031; validation accuracy : 0.8870292887029289\n",
      "Epoch 15:\t train loss : 0.5987937026005302; train accuracy : 0.9516493695591561; \n",
      " validation loss : 0.6467997930608218; validation accuracy : 0.895397489539749\n",
      "Epoch 16:\t train loss : 0.596261317010284; train accuracy : 0.9546026828588247; \n",
      " validation loss : 0.6509291369155699; validation accuracy : 0.895397489539749\n",
      "Epoch 17:\t train loss : 0.5869170857970039; train accuracy : 0.9643650670714706; \n",
      " validation loss : 0.6251903436068522; validation accuracy : 0.9205020920502092\n",
      "Epoch 18:\t train loss : 0.5875995831444685; train accuracy : 0.9638133151584621; \n",
      " validation loss : 0.6528575749881791; validation accuracy : 0.899581589958159\n",
      "Epoch 19:\t train loss : 0.585033270846225; train accuracy : 0.9660128876359243; \n",
      " validation loss : 0.6110394922691157; validation accuracy : 0.9372384937238494\n",
      "Epoch 20:\t train loss : 0.5840155949691225; train accuracy : 0.9669171907432077; \n",
      " validation loss : 0.6302709645365941; validation accuracy : 0.9205020920502092\n",
      "Epoch 21:\t train loss : 0.5861199844019342; train accuracy : 0.9650119272592088; \n",
      " validation loss : 0.6216509669239011; validation accuracy : 0.9205020920502092\n",
      "Epoch 22:\t train loss : 0.589819937925391; train accuracy : 0.9614449022584343; \n",
      " validation loss : 0.6389171719151352; validation accuracy : 0.9037656903765691\n",
      "Epoch 23:\t train loss : 0.5812139580942156; train accuracy : 0.9698094736516001; \n",
      " validation loss : 0.6323135686594025; validation accuracy : 0.9205020920502092\n",
      "Epoch 24:\t train loss : 0.5849927457749529; train accuracy : 0.9661677871061681; \n",
      " validation loss : 0.6163638648284756; validation accuracy : 0.9372384937238494\n",
      "Epoch 25:\t train loss : 0.5792209969215361; train accuracy : 0.9720288732612534; \n",
      " validation loss : 0.6139734585654842; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5787810548477275; train accuracy : 0.9722302425725704; \n",
      " validation loss : 0.6156756481617329; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5772827656039781; train accuracy : 0.9739629480467177; \n",
      " validation loss : 0.6121165398070327; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5811478574730528; train accuracy : 0.9696589113665232; \n",
      " validation loss : 0.617682181466249; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5747106304556964; train accuracy : 0.9765113541311689; \n",
      " validation loss : 0.6248257020831237; validation accuracy : 0.9246861924686193\n",
      "Epoch 30:\t train loss : 0.5747420074151158; train accuracy : 0.9765593729669444; \n",
      " validation loss : 0.6210831002660059; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5804238181282525; train accuracy : 0.9705167446327334; \n",
      " validation loss : 0.6146718403134117; validation accuracy : 0.9330543933054394\n",
      "Epoch 32:\t train loss : 0.5729631720234928; train accuracy : 0.9781820998172186; \n",
      " validation loss : 0.6139929526554343; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5702916052710629; train accuracy : 0.9810750023234921; \n",
      " validation loss : 0.6149916963270872; validation accuracy : 0.9330543933054394\n",
      "Epoch 34:\t train loss : 0.5767627132919276; train accuracy : 0.9741723721304874; \n",
      " validation loss : 0.6188691509992782; validation accuracy : 0.9330543933054394\n",
      "Epoch 35:\t train loss : 0.5731808701987273; train accuracy : 0.9780330865268441; \n",
      " validation loss : 0.6070132978737152; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.5720869280659356; train accuracy : 0.9790885715170854; \n",
      " validation loss : 0.6082227461156843; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.5697900443997884; train accuracy : 0.9816481303633942; \n",
      " validation loss : 0.6105780848176525; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5707032204801528; train accuracy : 0.9805210818179002; \n",
      " validation loss : 0.5985733799456813; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5804551854043708; train accuracy : 0.9704953685058397; \n",
      " validation loss : 0.6204477746413999; validation accuracy : 0.9288702928870293\n",
      "Epoch 40:\t train loss : 0.5689670148182002; train accuracy : 0.982292821958549; \n",
      " validation loss : 0.6087857201278194; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.576359489139138; train accuracy : 0.9746680504352675; \n",
      " validation loss : 0.6089069392225611; validation accuracy : 0.9372384937238494\n",
      "Epoch 42:\t train loss : 0.5691594100728226; train accuracy : 0.9821534124353295; \n",
      " validation loss : 0.6003246972205324; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.5664780750267698; train accuracy : 0.9848353418631308; \n",
      " validation loss : 0.6184727025115994; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5655132275172419; train accuracy : 0.9856504228755537; \n",
      " validation loss : 0.6233316596206311; validation accuracy : 0.9205020920502092\n",
      "Epoch 45:\t train loss : 0.56939760290643; train accuracy : 0.9819734192509062; \n",
      " validation loss : 0.5906028170785927; validation accuracy : 0.9623430962343096\n",
      "Epoch 46:\t train loss : 0.5660725105987535; train accuracy : 0.9852049319991326; \n",
      " validation loss : 0.604186734411379; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5699325897328454; train accuracy : 0.981189318132532; \n",
      " validation loss : 0.6046431377346584; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48:\t train loss : 0.5662407364527657; train accuracy : 0.9850419777564361; \n",
      " validation loss : 0.657785282602926; validation accuracy : 0.8870292887029289\n",
      "Epoch 49:\t train loss : 0.5710424263060886; train accuracy : 0.9802791288453794; \n",
      " validation loss : 0.6202941797165827; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5695264893401829; train accuracy : 0.9813922364385513; \n",
      " validation loss : 0.6217988608293875; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.5709934441851323; train accuracy : 0.9800446110474302; \n",
      " validation loss : 0.5996788087031181; validation accuracy : 0.9497907949790795\n",
      "Epoch 52:\t train loss : 0.5651005155378583; train accuracy : 0.9861247250534403; \n",
      " validation loss : 0.6004467167816471; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5678007077183049; train accuracy : 0.9833675144831004; \n",
      " validation loss : 0.6300132684889929; validation accuracy : 0.9163179916317992\n",
      "Epoch 54:\t train loss : 0.5833215699916996; train accuracy : 0.9673171411753771; \n",
      " validation loss : 0.6927450894711904; validation accuracy : 0.8577405857740585\n",
      "Epoch 55:\t train loss : 0.576933771812004; train accuracy : 0.9740270764273986; \n",
      " validation loss : 0.6153509862744041; validation accuracy : 0.9330543933054394\n",
      "Epoch 56:\t train loss : 0.5716410113845863; train accuracy : 0.9794020880448588; \n",
      " validation loss : 0.622247056788311; validation accuracy : 0.9246861924686193\n",
      "Epoch 57:\t train loss : 0.5662029131629814; train accuracy : 0.9850772948356517; \n",
      " validation loss : 0.62560161527953; validation accuracy : 0.9246861924686193\n",
      "Epoch 58:\t train loss : 0.5674300719409527; train accuracy : 0.9838204405340933; \n",
      " validation loss : 0.6098251995608287; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5727628174138168; train accuracy : 0.9781068186746801; \n",
      " validation loss : 0.6056192369744753; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5634250103831663; train accuracy : 0.987809411691812; \n",
      " validation loss : 0.6436921398060105; validation accuracy : 0.899581589958159\n",
      "Epoch 61:\t train loss : 0.5676854735823159; train accuracy : 0.983452399392794; \n",
      " validation loss : 0.6124170916816193; validation accuracy : 0.9372384937238494\n",
      "Epoch 62:\t train loss : 0.5672786551930802; train accuracy : 0.9838263267139626; \n",
      " validation loss : 0.6192235727955481; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5672557019158027; train accuracy : 0.9840704482790669; \n",
      " validation loss : 0.5891826384499429; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.5646656695134951; train accuracy : 0.986521577496205; \n",
      " validation loss : 0.6306109427023506; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.5756229683300353; train accuracy : 0.9754787942625236; \n",
      " validation loss : 0.6417931959125823; validation accuracy : 0.9079497907949791\n",
      "Epoch 66:\t train loss : 0.5773467533147788; train accuracy : 0.9736147340376096; \n",
      " validation loss : 0.6143788581566239; validation accuracy : 0.9330543933054394\n",
      "Epoch 67:\t train loss : 0.5662381728704555; train accuracy : 0.9851082747297004; \n",
      " validation loss : 0.6168759709439999; validation accuracy : 0.9330543933054394\n",
      "Epoch 68:\t train loss : 0.5638519073771389; train accuracy : 0.9873735245825459; \n",
      " validation loss : 0.6057243115132087; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.563783388452146; train accuracy : 0.9875498001796834; \n",
      " validation loss : 0.6016991718508731; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5667237692611357; train accuracy : 0.984492394436011; \n",
      " validation loss : 0.6211632873547688; validation accuracy : 0.9288702928870293\n",
      "Epoch 71:\t train loss : 0.5658145749066952; train accuracy : 0.9854468849716534; \n",
      " validation loss : 0.5949569493013387; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5647741867278644; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.6359671875791185; validation accuracy : 0.9121338912133892\n",
      "Epoch 73:\t train loss : 0.5711826839172293; train accuracy : 0.9799436165928312; \n",
      " validation loss : 0.6489751924068526; validation accuracy : 0.899581589958159\n",
      "Epoch 74:\t train loss : 0.5693210485914573; train accuracy : 0.9818804795687599; \n",
      " validation loss : 0.6050595495713949; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5638787251720024; train accuracy : 0.9872923572601382; \n",
      " validation loss : 0.6024132378327188; validation accuracy : 0.9497907949790795\n",
      "Epoch 76:\t train loss : 0.5638287296209914; train accuracy : 0.9873890145295703; \n",
      " validation loss : 0.6169000671073305; validation accuracy : 0.9330543933054394\n",
      "Epoch 77:\t train loss : 0.5994986435753582; train accuracy : 0.951287834195607; \n",
      " validation loss : 0.610137238550782; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5724201833770467; train accuracy : 0.9786254221010564; \n",
      " validation loss : 0.6273248584996385; validation accuracy : 0.9205020920502092\n",
      "Epoch 79:\t train loss : 0.5694539348698471; train accuracy : 0.9817196939186468; \n",
      " validation loss : 0.6066540699389537; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5654620182168061; train accuracy : 0.985783946218904; \n",
      " validation loss : 0.5914502115239697; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5645870200656049; train accuracy : 0.9865702159298615; \n",
      " validation loss : 0.6010238007192515; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5627165571741174; train accuracy : 0.9886709625453081; \n",
      " validation loss : 0.5975137320618041; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5644090154269524; train accuracy : 0.9869088261718145; \n",
      " validation loss : 0.6190086627163824; validation accuracy : 0.9288702928870293\n",
      "Epoch 84:\t train loss : 0.5677744683046662; train accuracy : 0.9833188760494439; \n",
      " validation loss : 0.6039075956584472; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5657199195497139; train accuracy : 0.9855862944948728; \n",
      " validation loss : 0.6207635940936203; validation accuracy : 0.9288702928870293\n",
      "Epoch 86:\t train loss : 0.5639037155271588; train accuracy : 0.987507047925896; \n",
      " validation loss : 0.5898439538908548; validation accuracy : 0.9623430962343096\n",
      "Epoch 87:\t train loss : 0.5652809942830181; train accuracy : 0.9862390408624803; \n",
      " validation loss : 0.5979105769331473; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.568477257224041; train accuracy : 0.9824845875027107; \n",
      " validation loss : 0.6075685180255554; validation accuracy : 0.9456066945606695\n",
      "Epoch 89:\t train loss : 0.5686516170405415; train accuracy : 0.9825694724124043; \n",
      " validation loss : 0.6108317809629512; validation accuracy : 0.9372384937238494\n",
      "Epoch 90:\t train loss : 0.5650640671648876; train accuracy : 0.9862080609684315; \n",
      " validation loss : 0.5999462184242466; validation accuracy : 0.9497907949790795\n",
      "Epoch 91:\t train loss : 0.5661426399313274; train accuracy : 0.9852380804857648; \n",
      " validation loss : 0.6064825094828952; validation accuracy : 0.9456066945606695\n",
      "Epoch 92:\t train loss : 0.5671445504827103; train accuracy : 0.9840239784379937; \n",
      " validation loss : 0.6062258745533103; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5644186822717029; train accuracy : 0.9869611821927569; \n",
      " validation loss : 0.592610233804223; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5656390226312269; train accuracy : 0.9856386505158152; \n",
      " validation loss : 0.5899420582096283; validation accuracy : 0.9581589958158996\n",
      "Epoch 95:\t train loss : 0.5626217052071633; train accuracy : 0.9886495864184145; \n",
      " validation loss : 0.5935307438010922; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.5606190564500758; train accuracy : 0.9907930852876483; \n",
      " validation loss : 0.603679453145764; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.5640445361817622; train accuracy : 0.9871876452182533; \n",
      " validation loss : 0.617848523461355; validation accuracy : 0.9330543933054394\n",
      "Epoch 98:\t train loss : 0.5652609804103569; train accuracy : 0.9858747173084668; \n",
      " validation loss : 0.6007698064095134; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99:\t train loss : 0.563540803179813; train accuracy : 0.9875962700207566; \n",
      " validation loss : 0.6073449551445466; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5665747742921636; train accuracy : 0.9845971064778959; \n",
      " validation loss : 0.5943007226336073; validation accuracy : 0.9581589958158996\n",
      "Epoch 101:\t train loss : 0.5660800810515488; train accuracy : 0.9850847300102233; \n",
      " validation loss : 0.6013697147776685; validation accuracy : 0.9497907949790795\n",
      "Epoch 102:\t train loss : 0.5638493407190014; train accuracy : 0.987410390656464; \n",
      " validation loss : 0.6040985634012729; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.561939589531912; train accuracy : 0.9892654667121038; \n",
      " validation loss : 0.6153858786193777; validation accuracy : 0.9330543933054394\n",
      "Epoch 104:\t train loss : 0.568662805072844; train accuracy : 0.9824071377675888; \n",
      " validation loss : 0.6060936522860716; validation accuracy : 0.9456066945606695\n",
      "Epoch 105:\t train loss : 0.5655332927956377; train accuracy : 0.9857780600390347; \n",
      " validation loss : 0.6066817483027643; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.5667201527779225; train accuracy : 0.9844635831345456; \n",
      " validation loss : 0.5956652706640799; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5618675254640157; train accuracy : 0.9893835001084297; \n",
      " validation loss : 0.5974686450278945; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5613828840648669; train accuracy : 0.9898172186251123; \n",
      " validation loss : 0.5860741166481611; validation accuracy : 0.9665271966527197\n",
      "Epoch 109:\t train loss : 0.5646924826333993; train accuracy : 0.9866786455590322; \n",
      " validation loss : 0.5760330879664973; validation accuracy : 0.9748953974895398\n",
      "Epoch 110:\t train loss : 0.5591714446179383; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.5986865500452632; validation accuracy : 0.9539748953974896\n",
      "Epoch 111:\t train loss : 0.5612305130803388; train accuracy : 0.9901174137984448; \n",
      " validation loss : 0.6060823424282707; validation accuracy : 0.9414225941422594\n",
      "Epoch 112:\t train loss : 0.5618366830243575; train accuracy : 0.9894203661823476; \n",
      " validation loss : 0.5964684259825873; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5598226903171588; train accuracy : 0.9915462065119737; \n",
      " validation loss : 0.5963068141852936; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5607859053269124; train accuracy : 0.9905917159763313; \n",
      " validation loss : 0.6023151823731205; validation accuracy : 0.9497907949790795\n",
      "Epoch 115:\t train loss : 0.5668606408279175; train accuracy : 0.9842151243842746; \n",
      " validation loss : 0.656830684832189; validation accuracy : 0.895397489539749\n",
      "Epoch 116:\t train loss : 0.5657081778645847; train accuracy : 0.9856039530344807; \n",
      " validation loss : 0.5934389697859783; validation accuracy : 0.9581589958158996\n",
      "Epoch 117:\t train loss : 0.5614273295211719; train accuracy : 0.9898172186251123; \n",
      " validation loss : 0.5988023367756393; validation accuracy : 0.9497907949790795\n",
      "Epoch 118:\t train loss : 0.5602903964220693; train accuracy : 0.9910409244400384; \n",
      " validation loss : 0.5884822279520888; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.560800262318338; train accuracy : 0.9904368165060875; \n",
      " validation loss : 0.5783560540519369; validation accuracy : 0.9748953974895398\n",
      "Epoch 120:\t train loss : 0.5697638795458777; train accuracy : 0.9812240156138666; \n",
      " validation loss : 0.6216876815002073; validation accuracy : 0.9288702928870293\n",
      "Epoch 121:\t train loss : 0.5652890871297882; train accuracy : 0.9859388456891477; \n",
      " validation loss : 0.5866780465890693; validation accuracy : 0.9623430962343096\n",
      "Epoch 122:\t train loss : 0.565027276212551; train accuracy : 0.9862759069363983; \n",
      " validation loss : 0.6071872682060216; validation accuracy : 0.9456066945606695\n",
      "Epoch 123:\t train loss : 0.5603451219521455; train accuracy : 0.9910254344930141; \n",
      " validation loss : 0.5829234629895468; validation accuracy : 0.9665271966527197\n",
      "Epoch 124:\t train loss : 0.5602274910562605; train accuracy : 0.991189937730413; \n",
      " validation loss : 0.5946412932433052; validation accuracy : 0.9539748953974896\n",
      "Epoch 125:\t train loss : 0.5603798580345878; train accuracy : 0.9908705350227702; \n",
      " validation loss : 0.6246063553181999; validation accuracy : 0.9246861924686193\n",
      "Epoch 126:\t train loss : 0.560353411113755; train accuracy : 0.9908550450757458; \n",
      " validation loss : 0.5979385438867189; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.5591446419620061; train accuracy : 0.9920322810495988; \n",
      " validation loss : 0.586405716024605; validation accuracy : 0.9665271966527197\n",
      "Epoch 128:\t train loss : 0.5625949650980852; train accuracy : 0.9887425261005607; \n",
      " validation loss : 0.5979547394050618; validation accuracy : 0.9539748953974896\n",
      "Epoch 129:\t train loss : 0.5601774973118117; train accuracy : 0.9911685616035193; \n",
      " validation loss : 0.5981039043092412; validation accuracy : 0.9539748953974896\n",
      "Epoch 130:\t train loss : 0.5605528213244881; train accuracy : 0.9907658229808854; \n",
      " validation loss : 0.5947153402747902; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5588232213975076; train accuracy : 0.9924948108677468; \n",
      " validation loss : 0.5992780699822488; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5648767605283717; train accuracy : 0.9863511880789367; \n",
      " validation loss : 0.6053902275921368; validation accuracy : 0.9456066945606695\n",
      "Epoch 133:\t train loss : 0.5635278708283014; train accuracy : 0.9877297933641067; \n",
      " validation loss : 0.6259161787050734; validation accuracy : 0.9246861924686193\n",
      "Epoch 134:\t train loss : 0.5625848945722516; train accuracy : 0.9886399826512593; \n",
      " validation loss : 0.6293268651540714; validation accuracy : 0.9246861924686193\n",
      "Epoch 135:\t train loss : 0.5624039898344009; train accuracy : 0.9887521298677159; \n",
      " validation loss : 0.6080849876493052; validation accuracy : 0.9414225941422594\n",
      "Epoch 136:\t train loss : 0.5614898343354632; train accuracy : 0.989811332445243; \n",
      " validation loss : 0.6080649143879383; validation accuracy : 0.9456066945606695\n",
      "Epoch 137:\t train loss : 0.5587920124655743; train accuracy : 0.9924756033334367; \n",
      " validation loss : 0.6155841380011687; validation accuracy : 0.9372384937238494\n",
      "Epoch 138:\t train loss : 0.5578365693859477; train accuracy : 0.9934728461228662; \n",
      " validation loss : 0.6086638121558174; validation accuracy : 0.9414225941422594\n",
      "Epoch 139:\t train loss : 0.5587985889854193; train accuracy : 0.9925257907617956; \n",
      " validation loss : 0.5986226522822768; validation accuracy : 0.9539748953974896\n",
      "Epoch 140:\t train loss : 0.559078995704774; train accuracy : 0.9922026704668669; \n",
      " validation loss : 0.6165375102812634; validation accuracy : 0.9330543933054394\n",
      "Epoch 141:\t train loss : 0.5617725641543228; train accuracy : 0.9894454598965271; \n",
      " validation loss : 0.6057674665129859; validation accuracy : 0.9456066945606695\n",
      "Epoch 142:\t train loss : 0.5610084121962439; train accuracy : 0.9903283868769168; \n",
      " validation loss : 0.5981927384950687; validation accuracy : 0.9539748953974896\n",
      "Epoch 143:\t train loss : 0.5574701264289227; train accuracy : 0.9939124508194181; \n",
      " validation loss : 0.5981797485380125; validation accuracy : 0.9539748953974896\n",
      "Epoch 144:\t train loss : 0.5564513459688751; train accuracy : 0.9949192973760029; \n",
      " validation loss : 0.6045068026909178; validation accuracy : 0.9456066945606695\n",
      "Epoch 145:\t train loss : 0.5567199322575709; train accuracy : 0.9945977260757768; \n",
      " validation loss : 0.5919604587383522; validation accuracy : 0.9581589958158996\n",
      "Epoch 146:\t train loss : 0.557835932259192; train accuracy : 0.9935657858050125; \n",
      " validation loss : 0.6007753453204545; validation accuracy : 0.9497907949790795\n",
      "Epoch 147:\t train loss : 0.556018328647596; train accuracy : 0.9953626196598407; \n",
      " validation loss : 0.5950687576632839; validation accuracy : 0.9539748953974896\n",
      "Epoch 148:\t train loss : 0.5555376105358997; train accuracy : 0.9958214318907029; \n",
      " validation loss : 0.5906307762897217; validation accuracy : 0.9581589958158996\n",
      "Epoch 149:\t train loss : 0.5581594459197876; train accuracy : 0.9931261811084606; \n",
      " validation loss : 0.5982403433001144; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150:\t train loss : 0.5589732977835657; train accuracy : 0.9923981535983147; \n",
      " validation loss : 0.6073304473118126; validation accuracy : 0.9456066945606695\n",
      "Epoch 151:\t train loss : 0.5567806539264543; train accuracy : 0.9945320487003935; \n",
      " validation loss : 0.5855581657927529; validation accuracy : 0.9665271966527197\n",
      "Epoch 152:\t train loss : 0.5569721780368091; train accuracy : 0.9944155642987701; \n",
      " validation loss : 0.5929592049838927; validation accuracy : 0.9581589958158996\n",
      "Epoch 153:\t train loss : 0.5641403514846753; train accuracy : 0.9870696118219275; \n",
      " validation loss : 0.5870571514773001; validation accuracy : 0.9665271966527197\n",
      "Epoch 154:\t train loss : 0.5576400199563535; train accuracy : 0.9937089129155178; \n",
      " validation loss : 0.6055269787534018; validation accuracy : 0.9456066945606695\n",
      "Epoch 155:\t train loss : 0.5613906138976945; train accuracy : 0.9897840701384801; \n",
      " validation loss : 0.5987735965398263; validation accuracy : 0.9497907949790795\n",
      "Epoch 156:\t train loss : 0.5610671300463712; train accuracy : 0.9900687753647882; \n",
      " validation loss : 0.6083928299345531; validation accuracy : 0.9414225941422594\n",
      "Epoch 157:\t train loss : 0.5583533117734377; train accuracy : 0.9929248117971436; \n",
      " validation loss : 0.5894836535334267; validation accuracy : 0.9623430962343096\n",
      "Epoch 158:\t train loss : 0.5573242289927964; train accuracy : 0.9939530344806221; \n",
      " validation loss : 0.6074871126827156; validation accuracy : 0.9456066945606695\n",
      "Epoch 159:\t train loss : 0.5570538212199088; train accuracy : 0.9942938133151584; \n",
      " validation loss : 0.6146159747856516; validation accuracy : 0.9372384937238494\n",
      "Early stopping at epoch 159\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5646924826333993; Train accuracy : 0.9866786455590322; \n",
      " Validation loss : 0.5760330879664973; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 30 ! ---\n",
      "Epoch 1:\t train loss : 0.9391583626601203; train accuracy : 0.5899181743548437; \n",
      " validation loss : 0.866402003499779; validation accuracy : 0.6610878661087866\n",
      "Epoch 2:\t train loss : 0.7495069462431562; train accuracy : 0.800383763437529; \n",
      " validation loss : 0.7437434654903625; validation accuracy : 0.7949790794979079\n",
      "Epoch 3:\t train loss : 0.6979665861715519; train accuracy : 0.8518431100715635; \n",
      " validation loss : 0.7187308469981558; validation accuracy : 0.8284518828451883\n",
      "Epoch 4:\t train loss : 0.6752298998548428; train accuracy : 0.87552569007714; \n",
      " validation loss : 0.7304381758238089; validation accuracy : 0.8117154811715481\n",
      "Epoch 5:\t train loss : 0.6541077371459082; train accuracy : 0.896447574274296; \n",
      " validation loss : 0.6852250093757759; validation accuracy : 0.8661087866108786\n",
      "Epoch 6:\t train loss : 0.6539309218843317; train accuracy : 0.8956970863409647; \n",
      " validation loss : 0.6979969930176382; validation accuracy : 0.8619246861924686\n",
      "Epoch 7:\t train loss : 0.6408154755127862; train accuracy : 0.9099203429474271; \n",
      " validation loss : 0.6908811538216615; validation accuracy : 0.8535564853556485\n",
      "Epoch 8:\t train loss : 0.6238310307742313; train accuracy : 0.9271126351497878; \n",
      " validation loss : 0.6439959623838447; validation accuracy : 0.899581589958159\n",
      "Epoch 9:\t train loss : 0.6120757454255137; train accuracy : 0.9390002013693113; \n",
      " validation loss : 0.661950148289613; validation accuracy : 0.891213389121339\n",
      "Epoch 10:\t train loss : 0.607671859679725; train accuracy : 0.9433770795253881; \n",
      " validation loss : 0.6642160250649778; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.6047586847175314; train accuracy : 0.9463064221320363; \n",
      " validation loss : 0.6660378520792497; validation accuracy : 0.8786610878661087\n",
      "Epoch 12:\t train loss : 0.5926121729808193; train accuracy : 0.9584677731652158; \n",
      " validation loss : 0.650296129005538; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.5922830325207195; train accuracy : 0.9588617986926484; \n",
      " validation loss : 0.6406298847032234; validation accuracy : 0.9079497907949791\n",
      "Epoch 14:\t train loss : 0.5962858401534474; train accuracy : 0.9545213219120791; \n",
      " validation loss : 0.6442153043519901; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.591021206022169; train accuracy : 0.9601923851420429; \n",
      " validation loss : 0.6383106973050631; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.5899211268308766; train accuracy : 0.9612336968307569; \n",
      " validation loss : 0.6167699451016109; validation accuracy : 0.9372384937238494\n",
      "Epoch 17:\t train loss : 0.5814313169851743; train accuracy : 0.9700199820316614; \n",
      " validation loss : 0.6461704660354948; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.5844203279463106; train accuracy : 0.9666879008023792; \n",
      " validation loss : 0.6343479343677367; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.5799236804800698; train accuracy : 0.9714053641686545; \n",
      " validation loss : 0.6412100657060829; validation accuracy : 0.9121338912133892\n",
      "Epoch 20:\t train loss : 0.5814022623525399; train accuracy : 0.9697239304191579; \n",
      " validation loss : 0.6282336487142248; validation accuracy : 0.9163179916317992\n",
      "Epoch 21:\t train loss : 0.5797020993510364; train accuracy : 0.9716154465751727; \n",
      " validation loss : 0.6255165107819781; validation accuracy : 0.9288702928870293\n",
      "Epoch 22:\t train loss : 0.5791044492465113; train accuracy : 0.9720404519966541; \n",
      " validation loss : 0.6421836362544627; validation accuracy : 0.899581589958159\n",
      "Epoch 23:\t train loss : 0.578444428978806; train accuracy : 0.9728219198240342; \n",
      " validation loss : 0.634883407738741; validation accuracy : 0.9121338912133892\n",
      "Epoch 24:\t train loss : 0.5773830933882614; train accuracy : 0.9737530592645374; \n",
      " validation loss : 0.6105090367072097; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.5841209480669445; train accuracy : 0.9669804671768022; \n",
      " validation loss : 0.6221188356793893; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5812685424097381; train accuracy : 0.9696584853929799; \n",
      " validation loss : 0.6411212999698133; validation accuracy : 0.9079497907949791\n",
      "Epoch 27:\t train loss : 0.5749257570446538; train accuracy : 0.9761557436723567; \n",
      " validation loss : 0.6090836337807386; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.5731175417632908; train accuracy : 0.9782761237956566; \n",
      " validation loss : 0.6161118854457499; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.5698068572918454; train accuracy : 0.9815324979088572; \n",
      " validation loss : 0.5989690890864107; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.5692773441647893; train accuracy : 0.9820574134886458; \n",
      " validation loss : 0.628742440224333; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5755900840045187; train accuracy : 0.9755429226432045; \n",
      " validation loss : 0.6125971778045015; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5860727467625786; train accuracy : 0.9648203940642522; \n",
      " validation loss : 0.6347219089397472; validation accuracy : 0.9121338912133892\n",
      "Epoch 33:\t train loss : 0.5922462444216502; train accuracy : 0.9585264413395707; \n",
      " validation loss : 0.6018035989278878; validation accuracy : 0.9497907949790795\n",
      "Epoch 34:\t train loss : 0.5693998493399124; train accuracy : 0.9820419235416215; \n",
      " validation loss : 0.6175134651128922; validation accuracy : 0.9330543933054394\n",
      "Epoch 35:\t train loss : 0.5718975609649863; train accuracy : 0.9792244958022244; \n",
      " validation loss : 0.6111415210967788; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.569643179602192; train accuracy : 0.9815944576969546; \n",
      " validation loss : 0.6047814199677811; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.5684544212851056; train accuracy : 0.982857662876793; \n",
      " validation loss : 0.6149225887586343; validation accuracy : 0.9372384937238494\n",
      "Epoch 38:\t train loss : 0.5674110259665862; train accuracy : 0.9838559899625143; \n",
      " validation loss : 0.628222706364371; validation accuracy : 0.9163179916317992\n",
      "Epoch 39:\t train loss : 0.5714458773427223; train accuracy : 0.9799680132593946; \n",
      " validation loss : 0.6282946458403743; validation accuracy : 0.9163179916317992\n",
      "Epoch 40:\t train loss : 0.5709782304688718; train accuracy : 0.98009367545463; \n",
      " validation loss : 0.6176786264857208; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41:\t train loss : 0.5684901286077655; train accuracy : 0.9828336534589052; \n",
      " validation loss : 0.6003072335895066; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5690513979153106; train accuracy : 0.9820591561076861; \n",
      " validation loss : 0.6071904556506295; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5649249937739864; train accuracy : 0.9864720483905945; \n",
      " validation loss : 0.610096157511133; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5716010425452027; train accuracy : 0.9795945119117693; \n",
      " validation loss : 0.6039345412750493; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.5709747652899317; train accuracy : 0.9802623222528579; \n",
      " validation loss : 0.6108969494868606; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5693516456472272; train accuracy : 0.9816529322469717; \n",
      " validation loss : 0.60476692076661; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5677242565276336; train accuracy : 0.9833275891446451; \n",
      " validation loss : 0.6314266367356489; validation accuracy : 0.9163179916317992\n",
      "Epoch 48:\t train loss : 0.5664263250118039; train accuracy : 0.9849555825769076; \n",
      " validation loss : 0.6338512980691517; validation accuracy : 0.9121338912133892\n",
      "Epoch 49:\t train loss : 0.5785411247055446; train accuracy : 0.9725516202484588; \n",
      " validation loss : 0.6221119031567176; validation accuracy : 0.9246861924686193\n",
      "Epoch 50:\t train loss : 0.5658872104086392; train accuracy : 0.9852173626816196; \n",
      " validation loss : 0.6015846329087686; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5644280529097682; train accuracy : 0.9867146596858639; \n",
      " validation loss : 0.6409446179351455; validation accuracy : 0.9079497907949791\n",
      "Epoch 52:\t train loss : 0.5692493975487728; train accuracy : 0.9817923417701911; \n",
      " validation loss : 0.6022177971045057; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5836857040783173; train accuracy : 0.9669820161715047; \n",
      " validation loss : 0.6521393681156675; validation accuracy : 0.899581589958159\n",
      "Epoch 54:\t train loss : 0.5822124097988772; train accuracy : 0.9683643003190929; \n",
      " validation loss : 0.6081320391060294; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5714767484012572; train accuracy : 0.9796237491867777; \n",
      " validation loss : 0.58659168314873; validation accuracy : 0.9623430962343096\n",
      "Epoch 56:\t train loss : 0.5691679869402172; train accuracy : 0.9820986554725983; \n",
      " validation loss : 0.5930838548265543; validation accuracy : 0.9623430962343096\n",
      "Epoch 57:\t train loss : 0.5664588679043894; train accuracy : 0.9847216843768394; \n",
      " validation loss : 0.6087878052867248; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5661805868345063; train accuracy : 0.9850642058304161; \n",
      " validation loss : 0.5996255341423338; validation accuracy : 0.9497907949790795\n",
      "Epoch 59:\t train loss : 0.5667160242666667; train accuracy : 0.9843361783202702; \n",
      " validation loss : 0.589870570103577; validation accuracy : 0.9665271966527197\n",
      "Epoch 60:\t train loss : 0.5647723639629526; train accuracy : 0.9864720483905945; \n",
      " validation loss : 0.5960120403332796; validation accuracy : 0.9581589958158996\n",
      "Epoch 61:\t train loss : 0.5659053075423895; train accuracy : 0.985265575141733; \n",
      " validation loss : 0.5880974637053206; validation accuracy : 0.9623430962343096\n",
      "Epoch 62:\t train loss : 0.5667699760762114; train accuracy : 0.9843499256482543; \n",
      " validation loss : 0.5960224514194885; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.5653378329350498; train accuracy : 0.985850707890579; \n",
      " validation loss : 0.5840908042083769; validation accuracy : 0.9665271966527197\n",
      "Epoch 64:\t train loss : 0.5707282944071034; train accuracy : 0.980372300876731; \n",
      " validation loss : 0.607967064099883; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.5773799050389982; train accuracy : 0.9735706651383252; \n",
      " validation loss : 0.6207044859867229; validation accuracy : 0.9330543933054394\n",
      "Epoch 66:\t train loss : 0.573770968951241; train accuracy : 0.9773054849902413; \n",
      " validation loss : 0.6111328068813926; validation accuracy : 0.9414225941422594\n",
      "Epoch 67:\t train loss : 0.563413666716884; train accuracy : 0.9878214164007559; \n",
      " validation loss : 0.5882882412914094; validation accuracy : 0.9623430962343096\n",
      "Epoch 68:\t train loss : 0.56328106933349; train accuracy : 0.9879263607918461; \n",
      " validation loss : 0.5922290445170453; validation accuracy : 0.9539748953974896\n",
      "Epoch 69:\t train loss : 0.5639633881527655; train accuracy : 0.9872482883608538; \n",
      " validation loss : 0.6010228013597063; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5615006154301959; train accuracy : 0.9897559171597633; \n",
      " validation loss : 0.6055531279416364; validation accuracy : 0.9456066945606695\n",
      "Epoch 71:\t train loss : 0.5603433107848812; train accuracy : 0.9910450680008674; \n",
      " validation loss : 0.5959864789553667; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5624111859270835; train accuracy : 0.9889659298615199; \n",
      " validation loss : 0.6038931864992011; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5662644100340525; train accuracy : 0.9847576985036711; \n",
      " validation loss : 0.6205685705961188; validation accuracy : 0.9330543933054394\n",
      "Epoch 74:\t train loss : 0.5713777331811166; train accuracy : 0.979637496514762; \n",
      " validation loss : 0.6227985704292265; validation accuracy : 0.9246861924686193\n",
      "Epoch 75:\t train loss : 0.5705400140577123; train accuracy : 0.9807097880975247; \n",
      " validation loss : 0.5973231137739891; validation accuracy : 0.9539748953974896\n",
      "Epoch 76:\t train loss : 0.5686604399792871; train accuracy : 0.9823327472970043; \n",
      " validation loss : 0.6071859600237186; validation accuracy : 0.9372384937238494\n",
      "Epoch 77:\t train loss : 0.5639407802793044; train accuracy : 0.9872740403977819; \n",
      " validation loss : 0.6205472821102987; validation accuracy : 0.9288702928870293\n",
      "Epoch 78:\t train loss : 0.5652766045437239; train accuracy : 0.9860158694507265; \n",
      " validation loss : 0.59023463581201; validation accuracy : 0.9581589958158996\n",
      "Epoch 79:\t train loss : 0.5605858727610052; train accuracy : 0.9906853139812262; \n",
      " validation loss : 0.6177173371215667; validation accuracy : 0.9330543933054394\n",
      "Epoch 80:\t train loss : 0.5594197558577705; train accuracy : 0.9919125050342328; \n",
      " validation loss : 0.5894082255893207; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5645806280648782; train accuracy : 0.9866734177019114; \n",
      " validation loss : 0.5834022595336112; validation accuracy : 0.9665271966527197\n",
      "Epoch 82:\t train loss : 0.566042423367239; train accuracy : 0.9850504585024319; \n",
      " validation loss : 0.5935471076627034; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5657848903333998; train accuracy : 0.985389494717928; \n",
      " validation loss : 0.6104910607603984; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5618101986295425; train accuracy : 0.9895270531924781; \n",
      " validation loss : 0.6066126143556803; validation accuracy : 0.9456066945606695\n",
      "Epoch 85:\t train loss : 0.5621669911174079; train accuracy : 0.9892000216859258; \n",
      " validation loss : 0.6114657124831442; validation accuracy : 0.9372384937238494\n",
      "Epoch 86:\t train loss : 0.5665993761785763; train accuracy : 0.9846492688745004; \n",
      " validation loss : 0.6310116230212209; validation accuracy : 0.9205020920502092\n",
      "Epoch 87:\t train loss : 0.5695887542889635; train accuracy : 0.9814258108987267; \n",
      " validation loss : 0.6192136824196658; validation accuracy : 0.9288702928870293\n",
      "Epoch 88:\t train loss : 0.5625168556308473; train accuracy : 0.9886991155240249; \n",
      " validation loss : 0.623336713838298; validation accuracy : 0.9205020920502092\n",
      "Epoch 89:\t train loss : 0.572836519170677; train accuracy : 0.9782950989807615; \n",
      " validation loss : 0.5899244467847401; validation accuracy : 0.9623430962343096\n",
      "Epoch 90:\t train loss : 0.5604628429501607; train accuracy : 0.9909089500913907; \n",
      " validation loss : 0.6272267193639643; validation accuracy : 0.9246861924686193\n",
      "Epoch 91:\t train loss : 0.5610904778764658; train accuracy : 0.9900674587192911; \n",
      " validation loss : 0.6057078211334346; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:\t train loss : 0.5630358082122138; train accuracy : 0.9881432200501874; \n",
      " validation loss : 0.5957800065370659; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5634222800074628; train accuracy : 0.9878041838346913; \n",
      " validation loss : 0.597383280943426; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5651904878652391; train accuracy : 0.9861330121750984; \n",
      " validation loss : 0.6054194991522068; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5593036957770359; train accuracy : 0.9920139641872425; \n",
      " validation loss : 0.5889318455290611; validation accuracy : 0.9623430962343096\n",
      "Epoch 96:\t train loss : 0.5606183512940563; train accuracy : 0.9905941169181202; \n",
      " validation loss : 0.5925815736689247; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5616903491788289; train accuracy : 0.9895098206264135; \n",
      " validation loss : 0.575819857372149; validation accuracy : 0.9748953974895398\n",
      "Epoch 98:\t train loss : 0.5615287366393114; train accuracy : 0.9897868970538121; \n",
      " validation loss : 0.5992061859761574; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5587788320597027; train accuracy : 0.9925630828092568; \n",
      " validation loss : 0.5929882039808934; validation accuracy : 0.9581589958158996\n",
      "Epoch 100:\t train loss : 0.5634154661653591; train accuracy : 0.9877422240465937; \n",
      " validation loss : 0.5999516217693921; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.5598995445550169; train accuracy : 0.9914081136342514; \n",
      " validation loss : 0.5902712944427242; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.559865589170153; train accuracy : 0.9914478066235013; \n",
      " validation loss : 0.5907042209859965; validation accuracy : 0.9623430962343096\n",
      "Epoch 103:\t train loss : 0.5587134785508424; train accuracy : 0.992590577465225; \n",
      " validation loss : 0.5939867411807421; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.556651282040987; train accuracy : 0.9947419374825738; \n",
      " validation loss : 0.6246858858911692; validation accuracy : 0.9246861924686193\n",
      "Epoch 105:\t train loss : 0.5577138603823582; train accuracy : 0.9935681867468014; \n",
      " validation loss : 0.5886516792570156; validation accuracy : 0.9623430962343096\n",
      "Epoch 106:\t train loss : 0.5687349386580978; train accuracy : 0.9822915053130519; \n",
      " validation loss : 0.6022075984142256; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5587753016672082; train accuracy : 0.9924511679420056; \n",
      " validation loss : 0.594429238954424; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5589178901778519; train accuracy : 0.9923650051116825; \n",
      " validation loss : 0.5866943325193256; validation accuracy : 0.9623430962343096\n",
      "Epoch 109:\t train loss : 0.5601800365842992; train accuracy : 0.9910915378419406; \n",
      " validation loss : 0.6065277432584865; validation accuracy : 0.9414225941422594\n",
      "Epoch 110:\t train loss : 0.5600010367970616; train accuracy : 0.9912292047461198; \n",
      " validation loss : 0.5873787366942593; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5577291732053591; train accuracy : 0.9935389494717928; \n",
      " validation loss : 0.5972438341568208; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5578421829229893; train accuracy : 0.9933358375414356; \n",
      " validation loss : 0.5851788742491455; validation accuracy : 0.9665271966527197\n",
      "Epoch 113:\t train loss : 0.5620100292152699; train accuracy : 0.9891345766597478; \n",
      " validation loss : 0.6259190042338939; validation accuracy : 0.9246861924686193\n",
      "Epoch 114:\t train loss : 0.5649819622482135; train accuracy : 0.9863945986554726; \n",
      " validation loss : 0.6123080397259697; validation accuracy : 0.9372384937238494\n",
      "Epoch 115:\t train loss : 0.5583345977739663; train accuracy : 0.993117235664054; \n",
      " validation loss : 0.5793014068131715; validation accuracy : 0.9748953974895398\n",
      "Epoch 116:\t train loss : 0.5599333192558297; train accuracy : 0.9913256296663465; \n",
      " validation loss : 0.5932748385587836; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.560701212657237; train accuracy : 0.9905871464419591; \n",
      " validation loss : 0.6207959797757292; validation accuracy : 0.9288702928870293\n",
      "Epoch 118:\t train loss : 0.5587665195505521; train accuracy : 0.9926198147402335; \n",
      " validation loss : 0.6108540316878768; validation accuracy : 0.9414225941422594\n",
      "Epoch 119:\t train loss : 0.556998571545464; train accuracy : 0.9944631184361349; \n",
      " validation loss : 0.5861807690758197; validation accuracy : 0.9665271966527197\n",
      "Epoch 120:\t train loss : 0.5583174735252616; train accuracy : 0.9930415285479723; \n",
      " validation loss : 0.595491582295182; validation accuracy : 0.9581589958158996\n",
      "Epoch 121:\t train loss : 0.5654136321717252; train accuracy : 0.9856923231822547; \n",
      " validation loss : 0.6416626254149701; validation accuracy : 0.9079497907949791\n",
      "Epoch 122:\t train loss : 0.5638057212836155; train accuracy : 0.9876543185972304; \n",
      " validation loss : 0.6058129008680218; validation accuracy : 0.9456066945606695\n",
      "Epoch 123:\t train loss : 0.5610688635309949; train accuracy : 0.9901121859413241; \n",
      " validation loss : 0.6072699601093869; validation accuracy : 0.9414225941422594\n",
      "Epoch 124:\t train loss : 0.5602668735091304; train accuracy : 0.990996855540754; \n",
      " validation loss : 0.5972080942925037; validation accuracy : 0.9539748953974896\n",
      "Epoch 125:\t train loss : 0.5560491506081935; train accuracy : 0.99536850583971; \n",
      " validation loss : 0.585085976629375; validation accuracy : 0.9665271966527197\n",
      "Epoch 126:\t train loss : 0.5621878474412266; train accuracy : 0.9891688481675392; \n",
      " validation loss : 0.6197210353237416; validation accuracy : 0.9288702928870293\n",
      "Epoch 127:\t train loss : 0.5632851733909435; train accuracy : 0.9879590833049351; \n",
      " validation loss : 0.5804723693295192; validation accuracy : 0.9707112970711297\n",
      "Epoch 128:\t train loss : 0.5584582651650943; train accuracy : 0.9928091793426066; \n",
      " validation loss : 0.5878859470248571; validation accuracy : 0.9623430962343096\n",
      "Epoch 129:\t train loss : 0.5566616274702926; train accuracy : 0.9946834629325567; \n",
      " validation loss : 0.607230593135383; validation accuracy : 0.9456066945606695\n",
      "Epoch 130:\t train loss : 0.5565971550194747; train accuracy : 0.9946834629325567; \n",
      " validation loss : 0.5836460578594116; validation accuracy : 0.9707112970711297\n",
      "Epoch 131:\t train loss : 0.5582501729692845; train accuracy : 0.9930277812199882; \n",
      " validation loss : 0.5938244953614586; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.560251907508264; train accuracy : 0.9910760478949162; \n",
      " validation loss : 0.5943262808672181; validation accuracy : 0.9539748953974896\n",
      "Epoch 133:\t train loss : 0.5577362894235219; train accuracy : 0.9935217169057282; \n",
      " validation loss : 0.6011818439206831; validation accuracy : 0.9497907949790795\n",
      "Epoch 134:\t train loss : 0.556070001005218; train accuracy : 0.9953460454165247; \n",
      " validation loss : 0.5875629719712645; validation accuracy : 0.9623430962343096\n",
      "Epoch 135:\t train loss : 0.5589400396281338; train accuracy : 0.9923582282598593; \n",
      " validation loss : 0.6119978767509163; validation accuracy : 0.9372384937238494\n",
      "Epoch 136:\t train loss : 0.5574376475552231; train accuracy : 0.993936460237306; \n",
      " validation loss : 0.5889027177258662; validation accuracy : 0.9623430962343096\n",
      "Epoch 137:\t train loss : 0.5650147060385976; train accuracy : 0.9863378667244957; \n",
      " validation loss : 0.5889824794506867; validation accuracy : 0.9623430962343096\n",
      "Epoch 138:\t train loss : 0.5625983430737704; train accuracy : 0.9885322113448372; \n",
      " validation loss : 0.6082856399729104; validation accuracy : 0.9414225941422594\n",
      "Epoch 139:\t train loss : 0.5612380685545174; train accuracy : 0.9899865237460888; \n",
      " validation loss : 0.606235800239631; validation accuracy : 0.9456066945606695\n",
      "Epoch 140:\t train loss : 0.5579785053606245; train accuracy : 0.9933668174354844; \n",
      " validation loss : 0.5976546082595443; validation accuracy : 0.9539748953974896\n",
      "Epoch 141:\t train loss : 0.5564877678867091; train accuracy : 0.9949158121379225; \n",
      " validation loss : 0.5965847378227223; validation accuracy : 0.9539748953974896\n",
      "Epoch 142:\t train loss : 0.557915473229722; train accuracy : 0.9934150298955977; \n",
      " validation loss : 0.5951915825352899; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143:\t train loss : 0.5599136202695051; train accuracy : 0.991490791226494; \n",
      " validation loss : 0.6053864588175367; validation accuracy : 0.9414225941422594\n",
      "Epoch 144:\t train loss : 0.5576506379090211; train accuracy : 0.9936318891539391; \n",
      " validation loss : 0.5796107905192454; validation accuracy : 0.9707112970711297\n",
      "Epoch 145:\t train loss : 0.5577260374977445; train accuracy : 0.9936903637039561; \n",
      " validation loss : 0.600476216192584; validation accuracy : 0.9539748953974896\n",
      "Epoch 146:\t train loss : 0.5554854824645652; train accuracy : 0.9958159716843769; \n",
      " validation loss : 0.5974863133942647; validation accuracy : 0.9539748953974896\n",
      "Epoch 147:\t train loss : 0.5563365348981567; train accuracy : 0.9950414743331578; \n",
      " validation loss : 0.5836472733083079; validation accuracy : 0.9665271966527197\n",
      "Early stopping at epoch 147\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5616903491788289; Train accuracy : 0.9895098206264135; \n",
      " Validation loss : 0.575819857372149; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 31 ! ---\n",
      "Epoch 1:\t train loss : 0.9223537683202906; train accuracy : 0.6134406270330556; \n",
      " validation loss : 0.7813908643871094; validation accuracy : 0.7615062761506276\n",
      "Epoch 2:\t train loss : 0.7457353262917337; train accuracy : 0.8036401375507296; \n",
      " validation loss : 0.6885769443948029; validation accuracy : 0.8702928870292888\n",
      "Epoch 3:\t train loss : 0.6945083991675834; train accuracy : 0.8560617971436538; \n",
      " validation loss : 0.6913139972600233; validation accuracy : 0.8535564853556485\n",
      "Epoch 4:\t train loss : 0.6660542647769822; train accuracy : 0.884355153505375; \n",
      " validation loss : 0.6820417249417982; validation accuracy : 0.8702928870292888\n",
      "Epoch 5:\t train loss : 0.6434914667586463; train accuracy : 0.9071580981443044; \n",
      " validation loss : 0.6851785505563645; validation accuracy : 0.8535564853556485\n",
      "Epoch 6:\t train loss : 0.6235152083598735; train accuracy : 0.9273759642492022; \n",
      " validation loss : 0.6265975219182701; validation accuracy : 0.9288702928870293\n",
      "Epoch 7:\t train loss : 0.6140341385445478; train accuracy : 0.9377337045757304; \n",
      " validation loss : 0.6363666144023709; validation accuracy : 0.9163179916317992\n",
      "Epoch 8:\t train loss : 0.6046594943461266; train accuracy : 0.9468297887171225; \n",
      " validation loss : 0.6313911647273018; validation accuracy : 0.9121338912133892\n",
      "Epoch 9:\t train loss : 0.5976672929042733; train accuracy : 0.9536556274977539; \n",
      " validation loss : 0.6194326934420504; validation accuracy : 0.9288702928870293\n",
      "Epoch 10:\t train loss : 0.5936263028459798; train accuracy : 0.9575505746770346; \n",
      " validation loss : 0.6226250566547301; validation accuracy : 0.9288702928870293\n",
      "Epoch 11:\t train loss : 0.5955292189776608; train accuracy : 0.9556983642615943; \n",
      " validation loss : 0.6458893236271349; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.5896916703635149; train accuracy : 0.9618705272777966; \n",
      " validation loss : 0.6149230881837652; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.5894896517278764; train accuracy : 0.9616364354533907; \n",
      " validation loss : 0.5964618772068783; validation accuracy : 0.9581589958158996\n",
      "Epoch 14:\t train loss : 0.5875767096835035; train accuracy : 0.9637293209207225; \n",
      " validation loss : 0.6291902682359446; validation accuracy : 0.9205020920502092\n",
      "Epoch 15:\t train loss : 0.5825789280936255; train accuracy : 0.9687790436506707; \n",
      " validation loss : 0.6490172519800226; validation accuracy : 0.899581589958159\n",
      "Epoch 16:\t train loss : 0.5943664693394403; train accuracy : 0.9563818581740451; \n",
      " validation loss : 0.6223043750312844; validation accuracy : 0.9246861924686193\n",
      "Epoch 17:\t train loss : 0.5894852584431537; train accuracy : 0.9612371820688373; \n",
      " validation loss : 0.6274174973603229; validation accuracy : 0.9163179916317992\n",
      "Epoch 18:\t train loss : 0.5850466859810846; train accuracy : 0.9664865314910623; \n",
      " validation loss : 0.5990788990733753; validation accuracy : 0.9497907949790795\n",
      "Epoch 19:\t train loss : 0.5821787939654951; train accuracy : 0.9690096502369961; \n",
      " validation loss : 0.6189280799121814; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5823389855405474; train accuracy : 0.9687273459524768; \n",
      " validation loss : 0.6251478743958601; validation accuracy : 0.9246861924686193\n",
      "Epoch 21:\t train loss : 0.5876372828905245; train accuracy : 0.963355819573097; \n",
      " validation loss : 0.6029627256667673; validation accuracy : 0.9497907949790795\n",
      "Epoch 22:\t train loss : 0.5803207652505735; train accuracy : 0.970784023668639; \n",
      " validation loss : 0.60209567104481; validation accuracy : 0.9456066945606695\n",
      "Epoch 23:\t train loss : 0.577698350686795; train accuracy : 0.9734122804300009; \n",
      " validation loss : 0.6102723709169368; validation accuracy : 0.9414225941422594\n",
      "Epoch 24:\t train loss : 0.572155215417872; train accuracy : 0.9791487886861427; \n",
      " validation loss : 0.6066788006359864; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5772408863041157; train accuracy : 0.9739441664859506; \n",
      " validation loss : 0.6162698011869799; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5833500793605604; train accuracy : 0.9677257272530128; \n",
      " validation loss : 0.6048461501420433; validation accuracy : 0.9497907949790795\n",
      "Epoch 27:\t train loss : 0.5681359106393843; train accuracy : 0.9832983518696367; \n",
      " validation loss : 0.6057111599855572; validation accuracy : 0.9456066945606695\n",
      "Epoch 28:\t train loss : 0.5769597694543144; train accuracy : 0.9739389386288299; \n",
      " validation loss : 0.608968078464893; validation accuracy : 0.9414225941422594\n",
      "Epoch 29:\t train loss : 0.5711016127682249; train accuracy : 0.9802191440255275; \n",
      " validation loss : 0.6018394227304638; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.569563697727787; train accuracy : 0.9816012345487779; \n",
      " validation loss : 0.6182027562442101; validation accuracy : 0.9288702928870293\n",
      "Epoch 31:\t train loss : 0.5673648610472637; train accuracy : 0.9838869698565631; \n",
      " validation loss : 0.6001848462254226; validation accuracy : 0.9539748953974896\n",
      "Epoch 32:\t train loss : 0.5693934520478877; train accuracy : 0.9817493571671985; \n",
      " validation loss : 0.591628592767688; validation accuracy : 0.9623430962343096\n",
      "Epoch 33:\t train loss : 0.5668909261383612; train accuracy : 0.984413628055392; \n",
      " validation loss : 0.6204712189183841; validation accuracy : 0.9246861924686193\n",
      "Epoch 34:\t train loss : 0.5649787493946377; train accuracy : 0.9863361241054556; \n",
      " validation loss : 0.6028637537143504; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.5690049579797991; train accuracy : 0.982136605842808; \n",
      " validation loss : 0.5960594063325517; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5663288442851614; train accuracy : 0.9849058211220918; \n",
      " validation loss : 0.625055389104593; validation accuracy : 0.9163179916317992\n",
      "Epoch 37:\t train loss : 0.5760806836268803; train accuracy : 0.9752435794169584; \n",
      " validation loss : 0.6198077790142678; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5685609709027478; train accuracy : 0.9824773846773444; \n",
      " validation loss : 0.5908523119115353; validation accuracy : 0.9623430962343096\n",
      "Epoch 39:\t train loss : 0.5643622669661456; train accuracy : 0.986924742092382; \n",
      " validation loss : 0.5941204668263904; validation accuracy : 0.9581589958158996\n",
      "Epoch 40:\t train loss : 0.5657278628461795; train accuracy : 0.9855443941881719; \n",
      " validation loss : 0.5886699936015695; validation accuracy : 0.9623430962343096\n",
      "Epoch 41:\t train loss : 0.5630329588545049; train accuracy : 0.9884100343876824; \n",
      " validation loss : 0.6259038824079177; validation accuracy : 0.9246861924686193\n",
      "Epoch 42:\t train loss : 0.5731478446144757; train accuracy : 0.9780627497753958; \n",
      " validation loss : 0.6060023435454174; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5764081626296018; train accuracy : 0.9746962034139843; \n",
      " validation loss : 0.6150872454155373; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5700122667085846; train accuracy : 0.9808991526998978; \n",
      " validation loss : 0.6067590805869408; validation accuracy : 0.9414225941422594\n",
      "Epoch 45:\t train loss : 0.568409523450446; train accuracy : 0.9829695777440441; \n",
      " validation loss : 0.629361397027996; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:\t train loss : 0.5756368374728278; train accuracy : 0.9753674989931534; \n",
      " validation loss : 0.6015119578097144; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5664126423321747; train accuracy : 0.984816366678026; \n",
      " validation loss : 0.5949661094858856; validation accuracy : 0.9539748953974896\n",
      "Epoch 48:\t train loss : 0.5641390685821503; train accuracy : 0.9871088788376344; \n",
      " validation loss : 0.6049059167361103; validation accuracy : 0.9456066945606695\n",
      "Epoch 49:\t train loss : 0.5716936030879323; train accuracy : 0.9794258651135413; \n",
      " validation loss : 0.5987166197063227; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5645879022997298; train accuracy : 0.9866923928870164; \n",
      " validation loss : 0.627110410928714; validation accuracy : 0.9246861924686193\n",
      "Epoch 51:\t train loss : 0.5638307397986431; train accuracy : 0.9874651476191951; \n",
      " validation loss : 0.5976373229951546; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5904614473612513; train accuracy : 0.9601339105920258; \n",
      " validation loss : 0.6137040471861358; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.567766699690112; train accuracy : 0.983405038879767; \n",
      " validation loss : 0.6183443008141736; validation accuracy : 0.9288702928870293\n",
      "Epoch 54:\t train loss : 0.5660982791213541; train accuracy : 0.9849230536881564; \n",
      " validation loss : 0.6018685993001484; validation accuracy : 0.9456066945606695\n",
      "Epoch 55:\t train loss : 0.5645766808540127; train accuracy : 0.9867061402150005; \n",
      " validation loss : 0.6006701205524041; validation accuracy : 0.9539748953974896\n",
      "Epoch 56:\t train loss : 0.5627682326267757; train accuracy : 0.9883807971126739; \n",
      " validation loss : 0.5970789989774722; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5607414855317417; train accuracy : 0.9904874299079897; \n",
      " validation loss : 0.6031497319017586; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5636685732050354; train accuracy : 0.9876062997614549; \n",
      " validation loss : 0.5904522207564787; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5637724189811827; train accuracy : 0.9872792682549025; \n",
      " validation loss : 0.6032740509235976; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5630414202786039; train accuracy : 0.9882276402614703; \n",
      " validation loss : 0.5901332564561681; validation accuracy : 0.9623430962343096\n",
      "Epoch 61:\t train loss : 0.5627455461924488; train accuracy : 0.9885494439109018; \n",
      " validation loss : 0.6091280390679233; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5628151335717523; train accuracy : 0.9884427569007714; \n",
      " validation loss : 0.6129355292108586; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.563270750741619; train accuracy : 0.9879298460299266; \n",
      " validation loss : 0.6091275484583923; validation accuracy : 0.9414225941422594\n",
      "Epoch 64:\t train loss : 0.5621299433173931; train accuracy : 0.9891363192787881; \n",
      " validation loss : 0.6243330973807044; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.568517543269097; train accuracy : 0.9824756420583042; \n",
      " validation loss : 0.6039432757977807; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5636915154664639; train accuracy : 0.9876372796555035; \n",
      " validation loss : 0.6047263289960292; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5646414406078502; train accuracy : 0.9865237460887883; \n",
      " validation loss : 0.6045653786095753; validation accuracy : 0.9456066945606695\n",
      "Epoch 68:\t train loss : 0.5623744017998312; train accuracy : 0.989012399702593; \n",
      " validation loss : 0.6208225578647528; validation accuracy : 0.9288702928870293\n",
      "Epoch 69:\t train loss : 0.5823422711051789; train accuracy : 0.9683763050280368; \n",
      " validation loss : 0.6318468973309374; validation accuracy : 0.9205020920502092\n",
      "Epoch 70:\t train loss : 0.5649910112563515; train accuracy : 0.9862879116453421; \n",
      " validation loss : 0.5851651352857706; validation accuracy : 0.9665271966527197\n",
      "Epoch 71:\t train loss : 0.5617944683882101; train accuracy : 0.9894668360234208; \n",
      " validation loss : 0.5806901350370764; validation accuracy : 0.9665271966527197\n",
      "Epoch 72:\t train loss : 0.5621343101624773; train accuracy : 0.9891862743579417; \n",
      " validation loss : 0.6127918921369292; validation accuracy : 0.9372384937238494\n",
      "Epoch 73:\t train loss : 0.5585580623476178; train accuracy : 0.9927609668824933; \n",
      " validation loss : 0.5882319302925485; validation accuracy : 0.9623430962343096\n",
      "Epoch 74:\t train loss : 0.5594798098672428; train accuracy : 0.9918023327860218; \n",
      " validation loss : 0.5908261428966525; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.561338249316694; train accuracy : 0.9900812060472753; \n",
      " validation loss : 0.6136795166639365; validation accuracy : 0.9330543933054394\n",
      "Epoch 76:\t train loss : 0.5599549152844724; train accuracy : 0.9913858468354039; \n",
      " validation loss : 0.6102932894948827; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5643371707120324; train accuracy : 0.9867508674370333; \n",
      " validation loss : 0.6094676950359582; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5662451289828523; train accuracy : 0.9848628365190991; \n",
      " validation loss : 0.6159336456860801; validation accuracy : 0.9330543933054394\n",
      "Epoch 79:\t train loss : 0.568884260478479; train accuracy : 0.9821056259487593; \n",
      " validation loss : 0.6060382501162282; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5604879647634957; train accuracy : 0.9908711933455188; \n",
      " validation loss : 0.6432020531337623; validation accuracy : 0.9079497907949791\n",
      "Epoch 81:\t train loss : 0.5596919008864666; train accuracy : 0.9915837309086403; \n",
      " validation loss : 0.5986844582647329; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5626137828313883; train accuracy : 0.9886131463180395; \n",
      " validation loss : 0.6145359380895065; validation accuracy : 0.9372384937238494\n",
      "Epoch 83:\t train loss : 0.5618963728317944; train accuracy : 0.9894306282722513; \n",
      " validation loss : 0.5957292789029489; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.567373515173186; train accuracy : 0.9836838579262059; \n",
      " validation loss : 0.6208075172084649; validation accuracy : 0.9330543933054394\n",
      "Epoch 85:\t train loss : 0.5821351026031124; train accuracy : 0.9688169940208804; \n",
      " validation loss : 0.5896790187298366; validation accuracy : 0.9623430962343096\n",
      "Epoch 86:\t train loss : 0.5601913778717239; train accuracy : 0.9910708200377955; \n",
      " validation loss : 0.5985574201175021; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5608683354581571; train accuracy : 0.9903944902258435; \n",
      " validation loss : 0.6009062413536227; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.5614205790437692; train accuracy : 0.9899005545401035; \n",
      " validation loss : 0.5993631495897486; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.559050315974707; train accuracy : 0.9922860063818582; \n",
      " validation loss : 0.5868771337677987; validation accuracy : 0.9623430962343096\n",
      "Epoch 90:\t train loss : 0.5610342007874898; train accuracy : 0.9901931209145265; \n",
      " validation loss : 0.5988449615132018; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5691304760249957; train accuracy : 0.9818750193624338; \n",
      " validation loss : 0.5965304681547952; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5607078988157396; train accuracy : 0.9906285820502494; \n",
      " validation loss : 0.580964066325201; validation accuracy : 0.9707112970711297\n",
      "Epoch 93:\t train loss : 0.556972347993629; train accuracy : 0.9945457960283776; \n",
      " validation loss : 0.6071373581066221; validation accuracy : 0.9456066945606695\n",
      "Epoch 94:\t train loss : 0.5574588830118308; train accuracy : 0.9938040211902475; \n",
      " validation loss : 0.6130075291459832; validation accuracy : 0.9372384937238494\n",
      "Epoch 95:\t train loss : 0.5605875268489025; train accuracy : 0.9907335264413396; \n",
      " validation loss : 0.5885238707734854; validation accuracy : 0.9623430962343096\n",
      "Epoch 96:\t train loss : 0.5562023695148371; train accuracy : 0.9951636512903126; \n",
      " validation loss : 0.5927089409143654; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97:\t train loss : 0.5594203645982068; train accuracy : 0.9918780399021035; \n",
      " validation loss : 0.6031907265653621; validation accuracy : 0.9497907949790795\n",
      "Epoch 98:\t train loss : 0.5600358497242771; train accuracy : 0.9912446946931441; \n",
      " validation loss : 0.6144357109133864; validation accuracy : 0.9372384937238494\n",
      "Epoch 99:\t train loss : 0.5609065905263582; train accuracy : 0.9903944902258435; \n",
      " validation loss : 0.5824761491608873; validation accuracy : 0.9707112970711297\n",
      "Epoch 100:\t train loss : 0.5594477981874008; train accuracy : 0.9919142476532731; \n",
      " validation loss : 0.587292070525093; validation accuracy : 0.9623430962343096\n",
      "Epoch 101:\t train loss : 0.5735971797114445; train accuracy : 0.9773310434028315; \n",
      " validation loss : 0.6551844816952541; validation accuracy : 0.895397489539749\n",
      "Epoch 102:\t train loss : 0.5820339535805927; train accuracy : 0.9690183633321974; \n",
      " validation loss : 0.5958497368496212; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5614230520987518; train accuracy : 0.989838594752006; \n",
      " validation loss : 0.5904342624048193; validation accuracy : 0.9623430962343096\n",
      "Epoch 104:\t train loss : 0.5564825308798435; train accuracy : 0.9948555949688652; \n",
      " validation loss : 0.578962643608911; validation accuracy : 0.9748953974895398\n",
      "Epoch 105:\t train loss : 0.5569820664051014; train accuracy : 0.9943908965581337; \n",
      " validation loss : 0.5891271066345076; validation accuracy : 0.9623430962343096\n",
      "Epoch 106:\t train loss : 0.5568449106281154; train accuracy : 0.9945303060813532; \n",
      " validation loss : 0.6026478995816954; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5568895693262754; train accuracy : 0.9944528563462313; \n",
      " validation loss : 0.6076999053818652; validation accuracy : 0.9414225941422594\n",
      "Epoch 108:\t train loss : 0.5572748535931525; train accuracy : 0.9941138201307351; \n",
      " validation loss : 0.6004630752641648; validation accuracy : 0.9497907949790795\n",
      "Epoch 109:\t train loss : 0.556902522273455; train accuracy : 0.9944855788593203; \n",
      " validation loss : 0.6211278520258573; validation accuracy : 0.9288702928870293\n",
      "Epoch 110:\t train loss : 0.5605296369410856; train accuracy : 0.9907662489544286; \n",
      " validation loss : 0.5876025514435147; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5587304735350995; train accuracy : 0.992576830137241; \n",
      " validation loss : 0.5962836624192194; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5768899991710917; train accuracy : 0.9740525961151213; \n",
      " validation loss : 0.58915185322635; validation accuracy : 0.9581589958158996\n",
      "Epoch 113:\t train loss : 0.5612785949026864; train accuracy : 0.9901329037454691; \n",
      " validation loss : 0.5870696685602935; validation accuracy : 0.9623430962343096\n",
      "Epoch 114:\t train loss : 0.5640682664207468; train accuracy : 0.9871725812447721; \n",
      " validation loss : 0.6070235591285587; validation accuracy : 0.9414225941422594\n",
      "Epoch 115:\t train loss : 0.5620878830057776; train accuracy : 0.9891707844109173; \n",
      " validation loss : 0.5994598641283035; validation accuracy : 0.9497907949790795\n",
      "Epoch 116:\t train loss : 0.5575278417570219; train accuracy : 0.9938160258991914; \n",
      " validation loss : 0.5964466229142942; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5559529772746249; train accuracy : 0.9955061727438892; \n",
      " validation loss : 0.5891964015333592; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.556563547340463; train accuracy : 0.9947334180117103; \n",
      " validation loss : 0.584546282699506; validation accuracy : 0.9665271966527197\n",
      "Epoch 119:\t train loss : 0.5607527166227089; train accuracy : 0.990423727500852; \n",
      " validation loss : 0.6193018702956703; validation accuracy : 0.9330543933054394\n",
      "Epoch 120:\t train loss : 0.5571411532094187; train accuracy : 0.9942842095480033; \n",
      " validation loss : 0.5852920739668193; validation accuracy : 0.9665271966527197\n",
      "Epoch 121:\t train loss : 0.5569753035162359; train accuracy : 0.9943754066111093; \n",
      " validation loss : 0.5848360591785862; validation accuracy : 0.9665271966527197\n",
      "Epoch 122:\t train loss : 0.5556211590963749; train accuracy : 0.995895164038539; \n",
      " validation loss : 0.5897714028540869; validation accuracy : 0.9623430962343096\n",
      "Epoch 123:\t train loss : 0.5588455143897836; train accuracy : 0.9925011230211592; \n",
      " validation loss : 0.5949944235609589; validation accuracy : 0.9581589958158996\n",
      "Epoch 124:\t train loss : 0.5614132546264688; train accuracy : 0.9897439124508194; \n",
      " validation loss : 0.5977323721012244; validation accuracy : 0.9539748953974896\n",
      "Epoch 125:\t train loss : 0.5616902565164764; train accuracy : 0.9896010176895195; \n",
      " validation loss : 0.5888208705604396; validation accuracy : 0.9623430962343096\n",
      "Epoch 126:\t train loss : 0.5753856216369068; train accuracy : 0.9755843582514948; \n",
      " validation loss : 0.6279222103565962; validation accuracy : 0.9246861924686193\n",
      "Epoch 127:\t train loss : 0.5612562436519498; train accuracy : 0.9900399640633228; \n",
      " validation loss : 0.6028545072303767; validation accuracy : 0.9456066945606695\n",
      "Epoch 128:\t train loss : 0.5575662497492279; train accuracy : 0.9937712986771585; \n",
      " validation loss : 0.5810613776368749; validation accuracy : 0.9707112970711297\n",
      "Epoch 129:\t train loss : 0.559725495756315; train accuracy : 0.9915355184485269; \n",
      " validation loss : 0.6312847954575647; validation accuracy : 0.9205020920502092\n",
      "Epoch 130:\t train loss : 0.5681752052995064; train accuracy : 0.9829111031940271; \n",
      " validation loss : 0.5994972752189308; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5592313323156941; train accuracy : 0.9919434849282815; \n",
      " validation loss : 0.5987716623307672; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5572197730934093; train accuracy : 0.9940501177235974; \n",
      " validation loss : 0.588208229829292; validation accuracy : 0.9623430962343096\n",
      "Epoch 133:\t train loss : 0.5573862656954388; train accuracy : 0.9940191378295486; \n",
      " validation loss : 0.585512948780586; validation accuracy : 0.9665271966527197\n",
      "Epoch 134:\t train loss : 0.5575383229985145; train accuracy : 0.9938040211902475; \n",
      " validation loss : 0.583233554422624; validation accuracy : 0.9665271966527197\n",
      "Epoch 135:\t train loss : 0.5604719865508068; train accuracy : 0.9909074010966883; \n",
      " validation loss : 0.5973363410755747; validation accuracy : 0.9539748953974896\n",
      "Epoch 136:\t train loss : 0.5590147402437788; train accuracy : 0.9923944360110288; \n",
      " validation loss : 0.5986420182611834; validation accuracy : 0.9539748953974896\n",
      "Epoch 137:\t train loss : 0.5549972454221583; train accuracy : 0.9964045896713033; \n",
      " validation loss : 0.6099788416173771; validation accuracy : 0.9414225941422594\n",
      "Epoch 138:\t train loss : 0.5580324214951614; train accuracy : 0.9932928529384429; \n",
      " validation loss : 0.5983810957080313; validation accuracy : 0.9539748953974896\n",
      "Epoch 139:\t train loss : 0.560624829799243; train accuracy : 0.9906250968121689; \n",
      " validation loss : 0.6075035490795642; validation accuracy : 0.9414225941422594\n",
      "Epoch 140:\t train loss : 0.5577316558636373; train accuracy : 0.9935664441277611; \n",
      " validation loss : 0.6042764332876557; validation accuracy : 0.9456066945606695\n",
      "Epoch 141:\t train loss : 0.5600470430725186; train accuracy : 0.9912946497722978; \n",
      " validation loss : 0.5823431431254014; validation accuracy : 0.9707112970711297\n",
      "Epoch 142:\t train loss : 0.5598811264098134; train accuracy : 0.991387589454444; \n",
      " validation loss : 0.5704053615044685; validation accuracy : 0.9790794979079498\n",
      "Epoch 143:\t train loss : 0.5588351420030302; train accuracy : 0.9924684005080703; \n",
      " validation loss : 0.5993056095508926; validation accuracy : 0.9497907949790795\n",
      "Epoch 144:\t train loss : 0.5582154166915434; train accuracy : 0.9931999132562966; \n",
      " validation loss : 0.5846308303899455; validation accuracy : 0.9665271966527197\n",
      "Epoch 145:\t train loss : 0.557841197230867; train accuracy : 0.9935561820378574; \n",
      " validation loss : 0.6227748151166019; validation accuracy : 0.9288702928870293\n",
      "Epoch 146:\t train loss : 0.5663093777373297; train accuracy : 0.984874841228043; \n",
      " validation loss : 0.5988372487843575; validation accuracy : 0.9539748953974896\n",
      "Epoch 147:\t train loss : 0.5613110889001568; train accuracy : 0.9900089841692742; \n",
      " validation loss : 0.5934003108582162; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148:\t train loss : 0.5574876922626383; train accuracy : 0.9938470057932401; \n",
      " validation loss : 0.5807652218282542; validation accuracy : 0.9707112970711297\n",
      "Epoch 149:\t train loss : 0.5578597152729766; train accuracy : 0.9934752470646551; \n",
      " validation loss : 0.6046176938452689; validation accuracy : 0.9456066945606695\n",
      "Epoch 150:\t train loss : 0.5670589849046889; train accuracy : 0.9842294913101397; \n",
      " validation loss : 0.5932692152591; validation accuracy : 0.9581589958158996\n",
      "Epoch 151:\t train loss : 0.5570497331189441; train accuracy : 0.994268719600979; \n",
      " validation loss : 0.5934579638772896; validation accuracy : 0.9581589958158996\n",
      "Epoch 152:\t train loss : 0.5558315705658334; train accuracy : 0.9955681325319867; \n",
      " validation loss : 0.5810667091626208; validation accuracy : 0.9707112970711297\n",
      "Epoch 153:\t train loss : 0.558026943910224; train accuracy : 0.9933375801604758; \n",
      " validation loss : 0.5879246101977662; validation accuracy : 0.9623430962343096\n",
      "Epoch 154:\t train loss : 0.556200891194454; train accuracy : 0.9951671365283931; \n",
      " validation loss : 0.5918896434164733; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5548402825451495; train accuracy : 0.9966077016016605; \n",
      " validation loss : 0.5900178168516738; validation accuracy : 0.9581589958158996\n",
      "Epoch 156:\t train loss : 0.5590887278163237; train accuracy : 0.9923135010378265; \n",
      " validation loss : 0.5976595124271432; validation accuracy : 0.9539748953974896\n",
      "Epoch 157:\t train loss : 0.5565276999550398; train accuracy : 0.9949038074289785; \n",
      " validation loss : 0.5797232418821643; validation accuracy : 0.9748953974895398\n",
      "Epoch 158:\t train loss : 0.5543479715475469; train accuracy : 0.997072400012392; \n",
      " validation loss : 0.5847446279426637; validation accuracy : 0.9665271966527197\n",
      "Epoch 159:\t train loss : 0.5657691813788112; train accuracy : 0.9855306468601878; \n",
      " validation loss : 0.5923402081201724; validation accuracy : 0.9581589958158996\n",
      "Epoch 160:\t train loss : 0.5587737014548236; train accuracy : 0.9925338455342483; \n",
      " validation loss : 0.5750381732042215; validation accuracy : 0.9748953974895398\n",
      "Epoch 161:\t train loss : 0.5580858341866416; train accuracy : 0.9932291505313052; \n",
      " validation loss : 0.6078457519318826; validation accuracy : 0.9414225941422594\n",
      "Epoch 162:\t train loss : 0.5611190721754951; train accuracy : 0.9901931209145265; \n",
      " validation loss : 0.6019813131002906; validation accuracy : 0.9497907949790795\n",
      "Epoch 163:\t train loss : 0.5629135017957236; train accuracy : 0.9883205799436166; \n",
      " validation loss : 0.5955201559999532; validation accuracy : 0.9539748953974896\n",
      "Epoch 164:\t train loss : 0.5564153171913443; train accuracy : 0.9949347873230273; \n",
      " validation loss : 0.571697260473328; validation accuracy : 0.9790794979079498\n",
      "Epoch 165:\t train loss : 0.5568511526883224; train accuracy : 0.9945010688063447; \n",
      " validation loss : 0.5847811052778179; validation accuracy : 0.9665271966527197\n",
      "Epoch 166:\t train loss : 0.5561470453897047; train accuracy : 0.9951826264754174; \n",
      " validation loss : 0.5996175420071655; validation accuracy : 0.9497907949790795\n",
      "Epoch 167:\t train loss : 0.5602560449150136; train accuracy : 0.9909813655937296; \n",
      " validation loss : 0.5922810163801744; validation accuracy : 0.9581589958158996\n",
      "Epoch 168:\t train loss : 0.5563763208474319; train accuracy : 0.995010494439109; \n",
      " validation loss : 0.5953538847180733; validation accuracy : 0.9581589958158996\n",
      "Epoch 169:\t train loss : 0.5590443400591588; train accuracy : 0.9922705164348338; \n",
      " validation loss : 0.5912738345410508; validation accuracy : 0.9581589958158996\n",
      "Epoch 170:\t train loss : 0.5575061908013168; train accuracy : 0.9937712986771585; \n",
      " validation loss : 0.6101686514710446; validation accuracy : 0.9414225941422594\n",
      "Epoch 171:\t train loss : 0.5567193135089242; train accuracy : 0.9946077558164751; \n",
      " validation loss : 0.5953632803513634; validation accuracy : 0.9539748953974896\n",
      "Epoch 172:\t train loss : 0.5583167081621269; train accuracy : 0.9930759936801016; \n",
      " validation loss : 0.6058659990712478; validation accuracy : 0.9456066945606695\n",
      "Epoch 173:\t train loss : 0.5580081090318145; train accuracy : 0.9933668174354844; \n",
      " validation loss : 0.6208343408818083; validation accuracy : 0.9288702928870293\n",
      "Epoch 174:\t train loss : 0.5756616645928203; train accuracy : 0.9755051658973326; \n",
      " validation loss : 0.6001945523871526; validation accuracy : 0.9497907949790795\n",
      "Epoch 175:\t train loss : 0.5657324652628092; train accuracy : 0.9855598841351962; \n",
      " validation loss : 0.5796075696182704; validation accuracy : 0.9707112970711297\n",
      "Epoch 176:\t train loss : 0.5605398815981253; train accuracy : 0.9907507590074042; \n",
      " validation loss : 0.6124572079423076; validation accuracy : 0.9372384937238494\n",
      "Epoch 177:\t train loss : 0.5580989070575809; train accuracy : 0.9932928529384429; \n",
      " validation loss : 0.5949407958998113; validation accuracy : 0.9539748953974896\n",
      "Epoch 178:\t train loss : 0.5581357511063005; train accuracy : 0.9932601304253539; \n",
      " validation loss : 0.5932342130408645; validation accuracy : 0.9581589958158996\n",
      "Epoch 179:\t train loss : 0.5577621324443003; train accuracy : 0.9936249186777781; \n",
      " validation loss : 0.613699294309106; validation accuracy : 0.9372384937238494\n",
      "Epoch 180:\t train loss : 0.5663708181645253; train accuracy : 0.9847836441649369; \n",
      " validation loss : 0.5826298362032483; validation accuracy : 0.9623430962343096\n",
      "Epoch 181:\t train loss : 0.5566620379967977; train accuracy : 0.9947626552867189; \n",
      " validation loss : 0.5905081731513719; validation accuracy : 0.9623430962343096\n",
      "Epoch 182:\t train loss : 0.5559679307540659; train accuracy : 0.9954614455218563; \n",
      " validation loss : 0.5796975998025528; validation accuracy : 0.9707112970711297\n",
      "Epoch 183:\t train loss : 0.5576543892335913; train accuracy : 0.9936783589950122; \n",
      " validation loss : 0.6076360178680009; validation accuracy : 0.9414225941422594\n",
      "Epoch 184:\t train loss : 0.5564376664899824; train accuracy : 0.9949467920319712; \n",
      " validation loss : 0.5818641201340404; validation accuracy : 0.9707112970711297\n",
      "Epoch 185:\t train loss : 0.5563549570471131; train accuracy : 0.9950414743331578; \n",
      " validation loss : 0.581136563518298; validation accuracy : 0.9707112970711297\n",
      "Epoch 186:\t train loss : 0.558500439723085; train accuracy : 0.9928746243687846; \n",
      " validation loss : 0.589007993194443; validation accuracy : 0.9623430962343096\n",
      "Epoch 187:\t train loss : 0.5591742853881742; train accuracy : 0.9919899547693547; \n",
      " validation loss : 0.5819654340617415; validation accuracy : 0.9707112970711297\n",
      "Epoch 188:\t train loss : 0.5564026625189247; train accuracy : 0.9949020648099384; \n",
      " validation loss : 0.5982673508144769; validation accuracy : 0.9539748953974896\n",
      "Epoch 189:\t train loss : 0.617443133712804; train accuracy : 0.932941889463738; \n",
      " validation loss : 0.6757508492166774; validation accuracy : 0.8744769874476988\n",
      "Epoch 190:\t train loss : 0.5998210970190136; train accuracy : 0.9506867855261935; \n",
      " validation loss : 0.6071254736999573; validation accuracy : 0.9456066945606695\n",
      "Epoch 191:\t train loss : 0.5675335408591156; train accuracy : 0.9836701105982217; \n",
      " validation loss : 0.5919607639593281; validation accuracy : 0.9581589958158996\n",
      "Epoch 192:\t train loss : 0.5660753574031446; train accuracy : 0.984940286254221; \n",
      " validation loss : 0.597783719080266; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 192\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5598811264098134; Train accuracy : 0.991387589454444; \n",
      " Validation loss : 0.5704053615044685; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 32 ! ---\n",
      "Epoch 1:\t train loss : 0.9606319105559623; train accuracy : 0.5687894676146847; \n",
      " validation loss : 0.8345669356474174; validation accuracy : 0.7125\n",
      "Epoch 2:\t train loss : 0.7666924784402283; train accuracy : 0.782643296271553; \n",
      " validation loss : 0.7526754116362678; validation accuracy : 0.7875\n",
      "Epoch 3:\t train loss : 0.7135994075502567; train accuracy : 0.8359086697524973; \n",
      " validation loss : 0.727694888318608; validation accuracy : 0.825\n",
      "Epoch 4:\t train loss : 0.674435958429594; train accuracy : 0.8755313712858688; \n",
      " validation loss : 0.6899511418319205; validation accuracy : 0.8625\n",
      "Epoch 5:\t train loss : 0.6478979071770924; train accuracy : 0.90241905659477; \n",
      " validation loss : 0.6705637479818167; validation accuracy : 0.8791666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\t train loss : 0.6339958744001573; train accuracy : 0.9167004676464974; \n",
      " validation loss : 0.6741512885157199; validation accuracy : 0.8791666666666667\n",
      "Epoch 7:\t train loss : 0.627277254484026; train accuracy : 0.9234079738499714; \n",
      " validation loss : 0.6798692952141521; validation accuracy : 0.875\n",
      "Epoch 8:\t train loss : 0.6159233192609779; train accuracy : 0.9348988157727302; \n",
      " validation loss : 0.6754915066322301; validation accuracy : 0.8791666666666667\n",
      "Epoch 9:\t train loss : 0.6043863195637512; train accuracy : 0.9466113523573201; \n",
      " validation loss : 0.6696421210339544; validation accuracy : 0.8833333333333333\n",
      "Epoch 10:\t train loss : 0.5999036818649034; train accuracy : 0.9509667080231596; \n",
      " validation loss : 0.6893693713048107; validation accuracy : 0.8666666666666667\n",
      "Epoch 11:\t train loss : 0.604533667032315; train accuracy : 0.9466183113825793; \n",
      " validation loss : 0.6584319404414234; validation accuracy : 0.8833333333333333\n",
      "Epoch 12:\t train loss : 0.5918852234972872; train accuracy : 0.9592678310110072; \n",
      " validation loss : 0.6682370390904654; validation accuracy : 0.8791666666666667\n",
      "Epoch 13:\t train loss : 0.6008533001535359; train accuracy : 0.950439810396386; \n",
      " validation loss : 0.6480536314820621; validation accuracy : 0.9041666666666667\n",
      "Epoch 14:\t train loss : 0.5862627693541191; train accuracy : 0.9653699020169243; \n",
      " validation loss : 0.6708600677543352; validation accuracy : 0.8791666666666667\n",
      "Epoch 15:\t train loss : 0.58594393531624; train accuracy : 0.9650254302665903; \n",
      " validation loss : 0.6673555346302389; validation accuracy : 0.8875\n",
      "Epoch 16:\t train loss : 0.5969465179987491; train accuracy : 0.9540202288922822; \n",
      " validation loss : 0.6577543610480521; validation accuracy : 0.8875\n",
      "Epoch 17:\t train loss : 0.5841300978865372; train accuracy : 0.9671966461474836; \n",
      " validation loss : 0.6633712638155885; validation accuracy : 0.8916666666666667\n",
      "Epoch 18:\t train loss : 0.5821366116299914; train accuracy : 0.9691382141948209; \n",
      " validation loss : 0.6537952740973091; validation accuracy : 0.8958333333333334\n",
      "Epoch 19:\t train loss : 0.589455962315572; train accuracy : 0.9618804479226315; \n",
      " validation loss : 0.6909138374676848; validation accuracy : 0.8583333333333333\n",
      "Epoch 20:\t train loss : 0.5861947516566646; train accuracy : 0.9648852556149392; \n",
      " validation loss : 0.6449435146741895; validation accuracy : 0.9041666666666667\n",
      "Epoch 21:\t train loss : 0.586340395493929; train accuracy : 0.9646456663167271; \n",
      " validation loss : 0.6442311137204921; validation accuracy : 0.9041666666666667\n",
      "Epoch 22:\t train loss : 0.5780129278997622; train accuracy : 0.9733434537443533; \n",
      " validation loss : 0.6432693642470945; validation accuracy : 0.9083333333333333\n",
      "Epoch 23:\t train loss : 0.5730846019217719; train accuracy : 0.9782982797289559; \n",
      " validation loss : 0.6604034755090432; validation accuracy : 0.8875\n",
      "Epoch 24:\t train loss : 0.5757308510452648; train accuracy : 0.9755385291404212; \n",
      " validation loss : 0.6579328757348403; validation accuracy : 0.8916666666666667\n",
      "Epoch 25:\t train loss : 0.5745630049191119; train accuracy : 0.9768945449195139; \n",
      " validation loss : 0.641761154081029; validation accuracy : 0.9041666666666667\n",
      "Epoch 26:\t train loss : 0.5733504285411616; train accuracy : 0.9780910001908761; \n",
      " validation loss : 0.6506012355439165; validation accuracy : 0.9\n",
      "Epoch 27:\t train loss : 0.574002462760571; train accuracy : 0.977435360596806; \n",
      " validation loss : 0.6396219891337777; validation accuracy : 0.9125\n",
      "Epoch 28:\t train loss : 0.6001291357906381; train accuracy : 0.950184811827957; \n",
      " validation loss : 0.6469830543944606; validation accuracy : 0.9041666666666667\n",
      "Epoch 29:\t train loss : 0.5818141712968046; train accuracy : 0.9692530381115989; \n",
      " validation loss : 0.6174796789551605; validation accuracy : 0.9333333333333333\n",
      "Epoch 30:\t train loss : 0.5706911280929327; train accuracy : 0.9807244941782783; \n",
      " validation loss : 0.6385441424644841; validation accuracy : 0.9125\n",
      "Epoch 31:\t train loss : 0.5746767496789389; train accuracy : 0.9765401317045238; \n",
      " validation loss : 0.6490372591876766; validation accuracy : 0.8958333333333334\n",
      "Epoch 32:\t train loss : 0.5678724518838263; train accuracy : 0.983428075491506; \n",
      " validation loss : 0.6530294297486126; validation accuracy : 0.9\n",
      "Epoch 33:\t train loss : 0.5724273664510833; train accuracy : 0.978698920754597; \n",
      " validation loss : 0.6693736632821923; validation accuracy : 0.8791666666666667\n",
      "Epoch 34:\t train loss : 0.5850391681144941; train accuracy : 0.9656696371763059; \n",
      " validation loss : 0.6516649448014115; validation accuracy : 0.8958333333333334\n",
      "Epoch 35:\t train loss : 0.574738129016348; train accuracy : 0.9761325316536235; \n",
      " validation loss : 0.6321087865926351; validation accuracy : 0.9125\n",
      "Epoch 36:\t train loss : 0.5669147034261341; train accuracy : 0.9845082156263918; \n",
      " validation loss : 0.6339280600445777; validation accuracy : 0.9125\n",
      "Epoch 37:\t train loss : 0.5636833015225411; train accuracy : 0.9876432565056945; \n",
      " validation loss : 0.6155267645201515; validation accuracy : 0.9375\n",
      "Epoch 38:\t train loss : 0.5695094431988991; train accuracy : 0.9815565947699942; \n",
      " validation loss : 0.6189395315982009; validation accuracy : 0.9291666666666667\n",
      "Epoch 39:\t train loss : 0.5690557229294962; train accuracy : 0.9820496914169371; \n",
      " validation loss : 0.6058482516278103; validation accuracy : 0.9416666666666667\n",
      "Epoch 40:\t train loss : 0.5671952382751884; train accuracy : 0.9840528965451422; \n",
      " validation loss : 0.6552431858355673; validation accuracy : 0.8958333333333334\n",
      "Epoch 41:\t train loss : 0.5933196025423388; train accuracy : 0.9570319956098492; \n",
      " validation loss : 0.6494319379262128; validation accuracy : 0.8875\n",
      "Epoch 42:\t train loss : 0.5765945128843832; train accuracy : 0.9746293821976204; \n",
      " validation loss : 0.6412097977711; validation accuracy : 0.9083333333333333\n",
      "Epoch 43:\t train loss : 0.5777991379677315; train accuracy : 0.9732664073932684; \n",
      " validation loss : 0.6380772723986489; validation accuracy : 0.9125\n",
      "Epoch 44:\t train loss : 0.56993010627106; train accuracy : 0.9812792279060889; \n",
      " validation loss : 0.627273787086763; validation accuracy : 0.925\n",
      "Epoch 45:\t train loss : 0.5715539718975163; train accuracy : 0.9795101442705351; \n",
      " validation loss : 0.6591371546096342; validation accuracy : 0.8875\n",
      "Epoch 46:\t train loss : 0.5857185592255929; train accuracy : 0.9651849907743209; \n",
      " validation loss : 0.6419153726501972; validation accuracy : 0.9041666666666667\n",
      "Epoch 47:\t train loss : 0.5747164343816082; train accuracy : 0.9762165370299676; \n",
      " validation loss : 0.6443739248352103; validation accuracy : 0.9041666666666667\n",
      "Epoch 48:\t train loss : 0.570026210106443; train accuracy : 0.9813085552268245; \n",
      " validation loss : 0.6209004970550293; validation accuracy : 0.9291666666666667\n",
      "Epoch 49:\t train loss : 0.5655038626171118; train accuracy : 0.9857772435897436; \n",
      " validation loss : 0.6160361008123953; validation accuracy : 0.9375\n",
      "Epoch 50:\t train loss : 0.5682412371337946; train accuracy : 0.9830990130113889; \n",
      " validation loss : 0.6415162487642025; validation accuracy : 0.9083333333333333\n",
      "Epoch 51:\t train loss : 0.5713930657238679; train accuracy : 0.9796528042883502; \n",
      " validation loss : 0.6493191047478575; validation accuracy : 0.9\n",
      "Epoch 52:\t train loss : 0.5667205765230641; train accuracy : 0.9845236248966088; \n",
      " validation loss : 0.6423616582078399; validation accuracy : 0.9083333333333333\n",
      "Epoch 53:\t train loss : 0.5912514284142962; train accuracy : 0.9592355212508749; \n",
      " validation loss : 0.6392545269963233; validation accuracy : 0.9083333333333333\n",
      "Epoch 54:\t train loss : 0.5737937179493452; train accuracy : 0.9774045420563721; \n",
      " validation loss : 0.627919182274279; validation accuracy : 0.925\n",
      "Epoch 55:\t train loss : 0.5641495931219321; train accuracy : 0.9871879374244449; \n",
      " validation loss : 0.6209805606681832; validation accuracy : 0.9291666666666667\n",
      "Epoch 56:\t train loss : 0.5640850090968854; train accuracy : 0.9871024408284024; \n",
      " validation loss : 0.6274063038507876; validation accuracy : 0.9208333333333333\n",
      "Epoch 57:\t train loss : 0.5618639887355905; train accuracy : 0.9894754684418146; \n",
      " validation loss : 0.6446663401292116; validation accuracy : 0.9041666666666667\n",
      "Epoch 58:\t train loss : 0.5631251098882658; train accuracy : 0.9881741307183305; \n",
      " validation loss : 0.6273193649095367; validation accuracy : 0.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59:\t train loss : 0.5658544510793162; train accuracy : 0.9852155508366737; \n",
      " validation loss : 0.628888893825344; validation accuracy : 0.9208333333333333\n",
      "Epoch 60:\t train loss : 0.5677443612541964; train accuracy : 0.9831899774129923; \n",
      " validation loss : 0.6341165862655469; validation accuracy : 0.9166666666666666\n",
      "Epoch 61:\t train loss : 0.5735569022108594; train accuracy : 0.9775964123242349; \n",
      " validation loss : 0.6152054160097559; validation accuracy : 0.9375\n",
      "Epoch 62:\t train loss : 0.5628964294405087; train accuracy : 0.9882750365845899; \n",
      " validation loss : 0.6264008246269781; validation accuracy : 0.925\n",
      "Epoch 63:\t train loss : 0.5727293205595907; train accuracy : 0.9783052387542152; \n",
      " validation loss : 0.6397936798114927; validation accuracy : 0.9125\n",
      "Epoch 64:\t train loss : 0.5630453982865522; train accuracy : 0.9883043639053254; \n",
      " validation loss : 0.6155932730948714; validation accuracy : 0.9375\n",
      "Epoch 65:\t train loss : 0.5682807778411816; train accuracy : 0.9828663827384361; \n",
      " validation loss : 0.6274881340188926; validation accuracy : 0.925\n",
      "Epoch 66:\t train loss : 0.5641009321908775; train accuracy : 0.9870716222879684; \n",
      " validation loss : 0.6302000399597588; validation accuracy : 0.9208333333333333\n",
      "Epoch 67:\t train loss : 0.5617488619260443; train accuracy : 0.9894754684418146; \n",
      " validation loss : 0.6404612645472673; validation accuracy : 0.9083333333333333\n",
      "Epoch 68:\t train loss : 0.5607163020939085; train accuracy : 0.9905710178469174; \n",
      " validation loss : 0.606399663925184; validation accuracy : 0.9458333333333333\n",
      "Epoch 69:\t train loss : 0.5614817028078847; train accuracy : 0.9898005543360692; \n",
      " validation loss : 0.618990447592734; validation accuracy : 0.9333333333333333\n",
      "Epoch 70:\t train loss : 0.5684867582842885; train accuracy : 0.9825651563593562; \n",
      " validation loss : 0.6328229525914737; validation accuracy : 0.9125\n",
      "Epoch 71:\t train loss : 0.5647259451903145; train accuracy : 0.9864721519692053; \n",
      " validation loss : 0.6319868351822093; validation accuracy : 0.9125\n",
      "Epoch 72:\t train loss : 0.5610559547042877; train accuracy : 0.990309060253229; \n",
      " validation loss : 0.6231529531822524; validation accuracy : 0.9291666666666667\n",
      "Epoch 73:\t train loss : 0.5599239990549655; train accuracy : 0.9913877091684163; \n",
      " validation loss : 0.6168256891025197; validation accuracy : 0.9333333333333333\n",
      "Epoch 74:\t train loss : 0.5637459318618943; train accuracy : 0.9875900696697844; \n",
      " validation loss : 0.6489582742091037; validation accuracy : 0.9041666666666667\n",
      "Epoch 75:\t train loss : 0.5640226133916517; train accuracy : 0.9871879374244449; \n",
      " validation loss : 0.631636746344423; validation accuracy : 0.9166666666666666\n",
      "Epoch 76:\t train loss : 0.5618095806522745; train accuracy : 0.9894854099064707; \n",
      " validation loss : 0.6274434806806429; validation accuracy : 0.9208333333333333\n",
      "Epoch 77:\t train loss : 0.5651936720342913; train accuracy : 0.9859790553222625; \n",
      " validation loss : 0.6587854449808704; validation accuracy : 0.8916666666666667\n",
      "Epoch 78:\t train loss : 0.5618608925132917; train accuracy : 0.9894068723356875; \n",
      " validation loss : 0.6261118133414995; validation accuracy : 0.9208333333333333\n",
      "Epoch 79:\t train loss : 0.5615412802876928; train accuracy : 0.9897697357956353; \n",
      " validation loss : 0.6324787135452257; validation accuracy : 0.9208333333333333\n",
      "Epoch 80:\t train loss : 0.5621506920558604; train accuracy : 0.9890917279060889; \n",
      " validation loss : 0.6333837532356287; validation accuracy : 0.9166666666666666\n",
      "Epoch 81:\t train loss : 0.563878177790671; train accuracy : 0.9872664749952281; \n",
      " validation loss : 0.637478815066419; validation accuracy : 0.9166666666666666\n",
      "Epoch 82:\t train loss : 0.5667626641402604; train accuracy : 0.9843541229242222; \n",
      " validation loss : 0.627223842514727; validation accuracy : 0.9208333333333333\n",
      "Epoch 83:\t train loss : 0.5603074522372176; train accuracy : 0.9911481198702042; \n",
      " validation loss : 0.6103395074895881; validation accuracy : 0.9416666666666667\n",
      "Epoch 84:\t train loss : 0.565277346900581; train accuracy : 0.9859551958070879; \n",
      " validation loss : 0.6288505256516993; validation accuracy : 0.9208333333333333\n",
      "Epoch 85:\t train loss : 0.5597571225816985; train accuracy : 0.9915880296812368; \n",
      " validation loss : 0.6216853179073456; validation accuracy : 0.9291666666666667\n",
      "Epoch 86:\t train loss : 0.5599676728543296; train accuracy : 0.9914100774638926; \n",
      " validation loss : 0.6194573395716703; validation accuracy : 0.9333333333333333\n",
      "Epoch 87:\t train loss : 0.5604576890956281; train accuracy : 0.9908623027613412; \n",
      " validation loss : 0.6233272838146994; validation accuracy : 0.9291666666666667\n",
      "Epoch 88:\t train loss : 0.5620305006222341; train accuracy : 0.9892612298784755; \n",
      " validation loss : 0.6293368908159093; validation accuracy : 0.9208333333333333\n",
      "Epoch 89:\t train loss : 0.5609927125832428; train accuracy : 0.9903229783037475; \n",
      " validation loss : 0.6260400164896669; validation accuracy : 0.9291666666666667\n",
      "Epoch 90:\t train loss : 0.5626092590033043; train accuracy : 0.9886672273652732; \n",
      " validation loss : 0.6257705994628714; validation accuracy : 0.925\n",
      "Epoch 91:\t train loss : 0.5671281769836487; train accuracy : 0.9840906741108354; \n",
      " validation loss : 0.6400541795937695; validation accuracy : 0.9083333333333333\n",
      "Epoch 92:\t train loss : 0.5611219511089541; train accuracy : 0.990064003149456; \n",
      " validation loss : 0.6163009597720569; validation accuracy : 0.9333333333333333\n",
      "Epoch 93:\t train loss : 0.5577029720519115; train accuracy : 0.9936667899408284; \n",
      " validation loss : 0.6127655991364104; validation accuracy : 0.9375\n",
      "Epoch 94:\t train loss : 0.5568165842616289; train accuracy : 0.9946152056690208; \n",
      " validation loss : 0.6385075285228479; validation accuracy : 0.9083333333333333\n",
      "Epoch 95:\t train loss : 0.557605599429669; train accuracy : 0.9937592455621301; \n",
      " validation loss : 0.6167094855505301; validation accuracy : 0.9333333333333333\n",
      "Epoch 96:\t train loss : 0.5625065077876408; train accuracy : 0.9887442737163581; \n",
      " validation loss : 0.5999567097805321; validation accuracy : 0.9458333333333333\n",
      "Epoch 97:\t train loss : 0.5581531071456426; train accuracy : 0.9931513249984093; \n",
      " validation loss : 0.627528409580011; validation accuracy : 0.9208333333333333\n",
      "Epoch 98:\t train loss : 0.5585760672644249; train accuracy : 0.9929117357001972; \n",
      " validation loss : 0.6182128631675721; validation accuracy : 0.9333333333333333\n",
      "Epoch 99:\t train loss : 0.5588960270609719; train accuracy : 0.9924355395431698; \n",
      " validation loss : 0.6395231609413075; validation accuracy : 0.9083333333333333\n",
      "Epoch 100:\t train loss : 0.5607738484209546; train accuracy : 0.9905163397913088; \n",
      " validation loss : 0.6445472101788582; validation accuracy : 0.9083333333333333\n",
      "Epoch 101:\t train loss : 0.5737171270041687; train accuracy : 0.9773429049755042; \n",
      " validation loss : 0.6260112941537734; validation accuracy : 0.925\n",
      "Epoch 102:\t train loss : 0.5596475782507244; train accuracy : 0.9915865384615384; \n",
      " validation loss : 0.6245313219875385; validation accuracy : 0.9291666666666667\n",
      "Epoch 103:\t train loss : 0.5592797639606808; train accuracy : 0.9919563609467456; \n",
      " validation loss : 0.6327309559303692; validation accuracy : 0.9166666666666666\n",
      "Epoch 104:\t train loss : 0.5582417164805192; train accuracy : 0.9930812376725838; \n",
      " validation loss : 0.6239213428090234; validation accuracy : 0.9291666666666667\n",
      "Epoch 105:\t train loss : 0.5582202377641378; train accuracy : 0.9931050971877585; \n",
      " validation loss : 0.651913121197506; validation accuracy : 0.9\n",
      "Epoch 106:\t train loss : 0.567365856402936; train accuracy : 0.9839127218934911; \n",
      " validation loss : 0.6157158546280785; validation accuracy : 0.9375\n",
      "Epoch 107:\t train loss : 0.5625819336468174; train accuracy : 0.9887219054208819; \n",
      " validation loss : 0.6192100997855946; validation accuracy : 0.9333333333333333\n",
      "Epoch 108:\t train loss : 0.5610082209341485; train accuracy : 0.9902404641471019; \n",
      " validation loss : 0.623302411001491; validation accuracy : 0.925\n",
      "Epoch 109:\t train loss : 0.5596900597062695; train accuracy : 0.9916327662721893; \n",
      " validation loss : 0.628294056533363; validation accuracy : 0.925\n",
      "Epoch 110:\t train loss : 0.5630948501107356; train accuracy : 0.9881964990138067; \n",
      " validation loss : 0.5938708573301453; validation accuracy : 0.9583333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111:\t train loss : 0.5601048223218833; train accuracy : 0.9912321252465484; \n",
      " validation loss : 0.6387657646724154; validation accuracy : 0.9125\n",
      "Epoch 112:\t train loss : 0.5591033724839033; train accuracy : 0.9921189038938729; \n",
      " validation loss : 0.5970465886756956; validation accuracy : 0.95\n",
      "Epoch 113:\t train loss : 0.5574678969331938; train accuracy : 0.9938909699688235; \n",
      " validation loss : 0.6260720664763543; validation accuracy : 0.925\n",
      "Epoch 114:\t train loss : 0.5626235689216756; train accuracy : 0.9885747717439715; \n",
      " validation loss : 0.628848975930602; validation accuracy : 0.9208333333333333\n",
      "Epoch 115:\t train loss : 0.5594998711517639; train accuracy : 0.9917868589743589; \n",
      " validation loss : 0.6307550083561076; validation accuracy : 0.9208333333333333\n",
      "Epoch 116:\t train loss : 0.5627091615857751; train accuracy : 0.9885215849080613; \n",
      " validation loss : 0.6255102059490814; validation accuracy : 0.925\n",
      "Epoch 117:\t train loss : 0.5584440457038122; train accuracy : 0.9928809171597633; \n",
      " validation loss : 0.5930278428680472; validation accuracy : 0.9625\n",
      "Epoch 118:\t train loss : 0.5571902194381493; train accuracy : 0.9941991553731628; \n",
      " validation loss : 0.6105690125936492; validation accuracy : 0.9416666666666667\n",
      "Epoch 119:\t train loss : 0.5580365279009759; train accuracy : 0.9932969674556212; \n",
      " validation loss : 0.6217509979331606; validation accuracy : 0.9291666666666667\n",
      "Epoch 120:\t train loss : 0.5567683343395498; train accuracy : 0.9945913461538461; \n",
      " validation loss : 0.6056287336973413; validation accuracy : 0.9458333333333333\n",
      "Epoch 121:\t train loss : 0.5575783692614712; train accuracy : 0.9938139236177388; \n",
      " validation loss : 0.7278364454743058; validation accuracy : 0.825\n",
      "Epoch 122:\t train loss : 0.5678960833765522; train accuracy : 0.9834211164662467; \n",
      " validation loss : 0.631232893148226; validation accuracy : 0.9166666666666666\n",
      "Epoch 123:\t train loss : 0.5613251700259219; train accuracy : 0.9901002894954508; \n",
      " validation loss : 0.617026259131474; validation accuracy : 0.9333333333333333\n",
      "Epoch 124:\t train loss : 0.559097412016312; train accuracy : 0.9921512136540052; \n",
      " validation loss : 0.6165229283378674; validation accuracy : 0.9333333333333333\n",
      "Epoch 125:\t train loss : 0.5599921422750864; train accuracy : 0.9912574759814213; \n",
      " validation loss : 0.607584242231365; validation accuracy : 0.9416666666666667\n",
      "Epoch 126:\t train loss : 0.5572225453894097; train accuracy : 0.9942145646433798; \n",
      " validation loss : 0.6138890760617853; validation accuracy : 0.9375\n",
      "Epoch 127:\t train loss : 0.5589059863796121; train accuracy : 0.9924270892982121; \n",
      " validation loss : 0.614688403030444; validation accuracy : 0.9375\n",
      "Epoch 128:\t train loss : 0.5642783686181894; train accuracy : 0.9869190208054972; \n",
      " validation loss : 0.627499014313141; validation accuracy : 0.925\n",
      "Epoch 129:\t train loss : 0.5642098536271991; train accuracy : 0.987011476426799; \n",
      " validation loss : 0.6397003760549324; validation accuracy : 0.9083333333333333\n",
      "Epoch 130:\t train loss : 0.562725923641478; train accuracy : 0.9886055902844054; \n",
      " validation loss : 0.6004762138674787; validation accuracy : 0.95\n",
      "Epoch 131:\t train loss : 0.5627890097619113; train accuracy : 0.9884823161226697; \n",
      " validation loss : 0.6242528441949908; validation accuracy : 0.925\n",
      "Epoch 132:\t train loss : 0.5616480866718211; train accuracy : 0.9895694152828148; \n",
      " validation loss : 0.6212962001013295; validation accuracy : 0.9291666666666667\n",
      "Epoch 133:\t train loss : 0.5622087501039778; train accuracy : 0.9890285996055227; \n",
      " validation loss : 0.6267593302313278; validation accuracy : 0.925\n",
      "Epoch 134:\t train loss : 0.5569162281046611; train accuracy : 0.9944695632118089; \n",
      " validation loss : 0.6137087859350762; validation accuracy : 0.9375\n",
      "Epoch 135:\t train loss : 0.5593300146394414; train accuracy : 0.9919563609467456; \n",
      " validation loss : 0.6175075434110895; validation accuracy : 0.9333333333333333\n",
      "Epoch 136:\t train loss : 0.5579744241672414; train accuracy : 0.9933740138067061; \n",
      " validation loss : 0.6527813823580313; validation accuracy : 0.8958333333333334\n",
      "Epoch 137:\t train loss : 0.5595921840912069; train accuracy : 0.9917098126232742; \n",
      " validation loss : 0.6223598431795535; validation accuracy : 0.9291666666666667\n",
      "Epoch 138:\t train loss : 0.5605902384391683; train accuracy : 0.9905849358974359; \n",
      " validation loss : 0.6310530476279699; validation accuracy : 0.9166666666666666\n",
      "Epoch 139:\t train loss : 0.5589720909474882; train accuracy : 0.9923107741617357; \n",
      " validation loss : 0.6228390183355774; validation accuracy : 0.9291666666666667\n",
      "Epoch 140:\t train loss : 0.5579804983588658; train accuracy : 0.9933670547814468; \n",
      " validation loss : 0.6184119601587071; validation accuracy : 0.9333333333333333\n",
      "Epoch 141:\t train loss : 0.557630211633971; train accuracy : 0.9937284270216963; \n",
      " validation loss : 0.6263937480835959; validation accuracy : 0.925\n",
      "Epoch 142:\t train loss : 0.5573569707461041; train accuracy : 0.9940057938856016; \n",
      " validation loss : 0.6185823996560397; validation accuracy : 0.9333333333333333\n",
      "Epoch 143:\t train loss : 0.5565753539632264; train accuracy : 0.9947847076414074; \n",
      " validation loss : 0.6136820529950805; validation accuracy : 0.9375\n",
      "Epoch 144:\t train loss : 0.5564551005828952; train accuracy : 0.9948995315581853; \n",
      " validation loss : 0.6148693717810156; validation accuracy : 0.9375\n",
      "Epoch 145:\t train loss : 0.5571506761151592; train accuracy : 0.994221523668639; \n",
      " validation loss : 0.6304998231941905; validation accuracy : 0.9208333333333333\n",
      "Epoch 146:\t train loss : 0.5575420677402235; train accuracy : 0.9937284270216963; \n",
      " validation loss : 0.6232492404820495; validation accuracy : 0.925\n",
      "Epoch 147:\t train loss : 0.5597024802818241; train accuracy : 0.9915949887064961; \n",
      " validation loss : 0.5962169249077449; validation accuracy : 0.9541666666666667\n",
      "Epoch 148:\t train loss : 0.5596415093348408; train accuracy : 0.9916804853025386; \n",
      " validation loss : 0.6195943770893414; validation accuracy : 0.9291666666666667\n",
      "Epoch 149:\t train loss : 0.558075465530528; train accuracy : 0.9932507396449703; \n",
      " validation loss : 0.6224583342079265; validation accuracy : 0.925\n",
      "Epoch 150:\t train loss : 0.5576768693536818; train accuracy : 0.9935897435897436; \n",
      " validation loss : 0.6071337183071618; validation accuracy : 0.9458333333333333\n",
      "Epoch 151:\t train loss : 0.555864913017524; train accuracy : 0.9955467209072978; \n",
      " validation loss : 0.6152581883372801; validation accuracy : 0.9375\n",
      "Epoch 152:\t train loss : 0.5570367470272155; train accuracy : 0.9943000612394223; \n",
      " validation loss : 0.6344985252888441; validation accuracy : 0.9166666666666666\n",
      "Epoch 153:\t train loss : 0.5598431368542282; train accuracy : 0.9914170364891519; \n",
      " validation loss : 0.605921170338063; validation accuracy : 0.9458333333333333\n",
      "Epoch 154:\t train loss : 0.5626618584580325; train accuracy : 0.9886672273652732; \n",
      " validation loss : 0.6024526861007932; validation accuracy : 0.95\n",
      "Epoch 155:\t train loss : 0.5597448863104034; train accuracy : 0.9916188482216708; \n",
      " validation loss : 0.593752590270768; validation accuracy : 0.9541666666666667\n",
      "Epoch 156:\t train loss : 0.5582792261562765; train accuracy : 0.9930742786473246; \n",
      " validation loss : 0.617885074470772; validation accuracy : 0.9333333333333333\n",
      "Epoch 157:\t train loss : 0.5558485064150971; train accuracy : 0.9955621301775148; \n",
      " validation loss : 0.6181155489343713; validation accuracy : 0.9333333333333333\n",
      "Epoch 158:\t train loss : 0.557307220348649; train accuracy : 0.9940982495069034; \n",
      " validation loss : 0.6425635987577079; validation accuracy : 0.9083333333333333\n",
      "Epoch 159:\t train loss : 0.555816738583503; train accuracy : 0.9955159023668639; \n",
      " validation loss : 0.6149606709756839; validation accuracy : 0.9375\n",
      "Epoch 160:\t train loss : 0.5588289176251943; train accuracy : 0.9925265039447732; \n",
      " validation loss : 0.625553664483652; validation accuracy : 0.925\n",
      "Epoch 161:\t train loss : 0.5579070044292861; train accuracy : 0.9935519660240504; \n",
      " validation loss : 0.6209238992772214; validation accuracy : 0.9291666666666667\n",
      "Epoch 162:\t train loss : 0.5574721820989408; train accuracy : 0.993867110453649; \n",
      " validation loss : 0.624635834075845; validation accuracy : 0.925\n",
      "Epoch 163:\t train loss : 0.5566758567703008; train accuracy : 0.9946544744544124; \n",
      " validation loss : 0.6159535917055764; validation accuracy : 0.9333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164:\t train loss : 0.5629444295246842; train accuracy : 0.9883128141502832; \n",
      " validation loss : 0.6171330045165141; validation accuracy : 0.9333333333333333\n",
      "Epoch 165:\t train loss : 0.5601674960375221; train accuracy : 0.9910094364382516; \n",
      " validation loss : 0.598373317037632; validation accuracy : 0.9541666666666667\n",
      "Epoch 166:\t train loss : 0.5633456414850638; train accuracy : 0.987942991665076; \n",
      " validation loss : 0.5962979835764574; validation accuracy : 0.9583333333333334\n",
      "Epoch 167:\t train loss : 0.5565073624642213; train accuracy : 0.9948841222879684; \n",
      " validation loss : 0.6045459605304336; validation accuracy : 0.95\n",
      "Early stopping at epoch 167\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5584440457038122; Train accuracy : 0.9928809171597633; \n",
      " Validation loss : 0.5930278428680472; Validation accuracy : 0.9625\n",
      "--- Let's train model 33 ! ---\n",
      "Epoch 1:\t train loss : 0.9738856844546012; train accuracy : 0.5523829734502308; \n",
      " validation loss : 0.8616745995224303; validation accuracy : 0.6610878661087866\n",
      "Epoch 2:\t train loss : 0.7782124985864906; train accuracy : 0.7714659685863874; \n",
      " validation loss : 0.7530100864330527; validation accuracy : 0.803347280334728\n",
      "Epoch 3:\t train loss : 0.7210999920068532; train accuracy : 0.8293348616747731; \n",
      " validation loss : 0.7448573256975861; validation accuracy : 0.8075313807531381\n",
      "Epoch 4:\t train loss : 0.7086325216084696; train accuracy : 0.8415778060039034; \n",
      " validation loss : 0.6681339552289034; validation accuracy : 0.895397489539749\n",
      "Epoch 5:\t train loss : 0.6894930618876667; train accuracy : 0.8601908361473404; \n",
      " validation loss : 0.6778022576133085; validation accuracy : 0.8744769874476988\n",
      "Epoch 6:\t train loss : 0.6722316461017248; train accuracy : 0.8782750394993649; \n",
      " validation loss : 0.6790473160519946; validation accuracy : 0.8744769874476988\n",
      "Epoch 7:\t train loss : 0.6600944885099738; train accuracy : 0.8906034883360698; \n",
      " validation loss : 0.6897920697668284; validation accuracy : 0.8493723849372385\n",
      "Epoch 8:\t train loss : 0.6486280637989588; train accuracy : 0.9019672232720964; \n",
      " validation loss : 0.6455730825834441; validation accuracy : 0.899581589958159\n",
      "Epoch 9:\t train loss : 0.6455386951615715; train accuracy : 0.905620682177267; \n",
      " validation loss : 0.6541706479086529; validation accuracy : 0.895397489539749\n",
      "Epoch 10:\t train loss : 0.6165867250039501; train accuracy : 0.9349223953654079; \n",
      " validation loss : 0.6432516920539245; validation accuracy : 0.9079497907949791\n",
      "Epoch 11:\t train loss : 0.6084652557309329; train accuracy : 0.9432132346107376; \n",
      " validation loss : 0.625759075334233; validation accuracy : 0.9288702928870293\n",
      "Epoch 12:\t train loss : 0.6033395094384542; train accuracy : 0.9483890455094643; \n",
      " validation loss : 0.6480228231928403; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.6059067531016603; train accuracy : 0.9454230304532358; \n",
      " validation loss : 0.6188537549181392; validation accuracy : 0.9288702928870293\n",
      "Epoch 14:\t train loss : 0.5928849724862316; train accuracy : 0.9584922085566467; \n",
      " validation loss : 0.6759843774208787; validation accuracy : 0.8702928870292888\n",
      "Epoch 15:\t train loss : 0.5993740228245485; train accuracy : 0.9517621363734936; \n",
      " validation loss : 0.6303223158207815; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5912577947907385; train accuracy : 0.9600337680845131; \n",
      " validation loss : 0.6231691115788021; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5947147599440806; train accuracy : 0.9568642151243842; \n",
      " validation loss : 0.6015242285887702; validation accuracy : 0.9539748953974896\n",
      "Epoch 18:\t train loss : 0.5856995871350491; train accuracy : 0.9655732829393724; \n",
      " validation loss : 0.6196992192361153; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5806919981916229; train accuracy : 0.9707955636791722; \n",
      " validation loss : 0.6429412292886298; validation accuracy : 0.9079497907949791\n",
      "Epoch 20:\t train loss : 0.5857390694259126; train accuracy : 0.9654781746646427; \n",
      " validation loss : 0.6271409567611418; validation accuracy : 0.9246861924686193\n",
      "Epoch 21:\t train loss : 0.5918869915498678; train accuracy : 0.959061619009263; \n",
      " validation loss : 0.6631246809723501; validation accuracy : 0.8870292887029289\n",
      "Epoch 22:\t train loss : 0.5890404569749149; train accuracy : 0.9621654945940085; \n",
      " validation loss : 0.6000577516829915; validation accuracy : 0.9497907949790795\n",
      "Epoch 23:\t train loss : 0.5794333179618705; train accuracy : 0.9718990675051892; \n",
      " validation loss : 0.6009323974016322; validation accuracy : 0.9539748953974896\n",
      "Epoch 24:\t train loss : 0.5815749692495131; train accuracy : 0.9696936088478577; \n",
      " validation loss : 0.6513742218868237; validation accuracy : 0.899581589958159\n",
      "Epoch 25:\t train loss : 0.5895914114868811; train accuracy : 0.9611608166300071; \n",
      " validation loss : 0.5973593300390972; validation accuracy : 0.9581589958158996\n",
      "Epoch 26:\t train loss : 0.5803776370910081; train accuracy : 0.9706967378171567; \n",
      " validation loss : 0.5963173317131992; validation accuracy : 0.9539748953974896\n",
      "Epoch 27:\t train loss : 0.5772207615360228; train accuracy : 0.9740211902475293; \n",
      " validation loss : 0.5972646035247375; validation accuracy : 0.9539748953974896\n",
      "Epoch 28:\t train loss : 0.5811568562173894; train accuracy : 0.9700343876823941; \n",
      " validation loss : 0.6233013327318584; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5801444845365162; train accuracy : 0.9708147712134825; \n",
      " validation loss : 0.5956067183560766; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.5743712919286499; train accuracy : 0.9769082065739335; \n",
      " validation loss : 0.602613933903623; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5788297347635537; train accuracy : 0.972013383314229; \n",
      " validation loss : 0.6070014723106419; validation accuracy : 0.9456066945606695\n",
      "Epoch 32:\t train loss : 0.5710352987129488; train accuracy : 0.9803897270671335; \n",
      " validation loss : 0.594890020265586; validation accuracy : 0.9539748953974896\n",
      "Epoch 33:\t train loss : 0.5714136010221299; train accuracy : 0.979851296508566; \n",
      " validation loss : 0.5985767118581122; validation accuracy : 0.9581589958158996\n",
      "Epoch 34:\t train loss : 0.5711115000570485; train accuracy : 0.9799442361907122; \n",
      " validation loss : 0.5796728205349315; validation accuracy : 0.9748953974895398\n",
      "Epoch 35:\t train loss : 0.5731565794923446; train accuracy : 0.9778626971095759; \n",
      " validation loss : 0.5803021661689615; validation accuracy : 0.9707112970711297\n",
      "Epoch 36:\t train loss : 0.5708249154150814; train accuracy : 0.980263638898355; \n",
      " validation loss : 0.5957394076440811; validation accuracy : 0.9539748953974896\n",
      "Epoch 37:\t train loss : 0.5731026497017988; train accuracy : 0.9781127048545494; \n",
      " validation loss : 0.5979534601742114; validation accuracy : 0.9497907949790795\n",
      "Epoch 38:\t train loss : 0.5735216669269471; train accuracy : 0.9776731001579975; \n",
      " validation loss : 0.6030649979959534; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5710703527343687; train accuracy : 0.9801028532482419; \n",
      " validation loss : 0.588802070903659; validation accuracy : 0.9623430962343096\n",
      "Epoch 40:\t train loss : 0.5734540465542446; train accuracy : 0.9775742742959819; \n",
      " validation loss : 0.6383081302247136; validation accuracy : 0.9079497907949791\n",
      "Epoch 41:\t train loss : 0.5713010612074583; train accuracy : 0.9801514916818984; \n",
      " validation loss : 0.6098257735622026; validation accuracy : 0.9414225941422594\n",
      "Epoch 42:\t train loss : 0.5655770915025061; train accuracy : 0.9858031537532141; \n",
      " validation loss : 0.6022574712105845; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5775699259020062; train accuracy : 0.9733455187583259; \n",
      " validation loss : 0.6048339435031166; validation accuracy : 0.9456066945606695\n",
      "Epoch 44:\t train loss : 0.5757327190695654; train accuracy : 0.9753127420304223; \n",
      " validation loss : 0.6002679686021964; validation accuracy : 0.9497907949790795\n",
      "Epoch 45:\t train loss : 0.5660522518882002; train accuracy : 0.9852978716812788; \n",
      " validation loss : 0.5772016176345276; validation accuracy : 0.9748953974895398\n",
      "Epoch 46:\t train loss : 0.5655914850746135; train accuracy : 0.98585767836674; \n",
      " validation loss : 0.5718099337854752; validation accuracy : 0.9832635983263598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47:\t train loss : 0.5669953912190591; train accuracy : 0.9841110319402707; \n",
      " validation loss : 0.5941135806949333; validation accuracy : 0.9581589958158996\n",
      "Epoch 48:\t train loss : 0.5642440450827267; train accuracy : 0.9871197992502866; \n",
      " validation loss : 0.6935875159026035; validation accuracy : 0.8451882845188284\n",
      "Epoch 49:\t train loss : 0.5704356748518978; train accuracy : 0.9806781498807274; \n",
      " validation loss : 0.5889594761017427; validation accuracy : 0.9623430962343096\n",
      "Epoch 50:\t train loss : 0.5914379749437912; train accuracy : 0.9590631680039654; \n",
      " validation loss : 0.6320311703956415; validation accuracy : 0.9163179916317992\n",
      "Epoch 51:\t train loss : 0.5765695650815279; train accuracy : 0.9744490225843427; \n",
      " validation loss : 0.5997208377234068; validation accuracy : 0.9581589958158996\n",
      "Epoch 52:\t train loss : 0.5675269625332849; train accuracy : 0.9838786827349051; \n",
      " validation loss : 0.605694896215705; validation accuracy : 0.9372384937238494\n",
      "Epoch 53:\t train loss : 0.5805698991777453; train accuracy : 0.9703692803370613; \n",
      " validation loss : 0.5831551477697609; validation accuracy : 0.9665271966527197\n",
      "Epoch 54:\t train loss : 0.5657037772633807; train accuracy : 0.9856290467486601; \n",
      " validation loss : 0.5989898756152454; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5648055890325466; train accuracy : 0.986521577496205; \n",
      " validation loss : 0.5779303470131937; validation accuracy : 0.9707112970711297\n",
      "Epoch 56:\t train loss : 0.5690477314714728; train accuracy : 0.9818959695157843; \n",
      " validation loss : 0.6039115898904251; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5639580199818341; train accuracy : 0.9873756931751293; \n",
      " validation loss : 0.5844091719725814; validation accuracy : 0.9623430962343096\n",
      "Epoch 58:\t train loss : 0.5622464993980824; train accuracy : 0.9891821307971127; \n",
      " validation loss : 0.5696691047265398; validation accuracy : 0.9790794979079498\n",
      "Epoch 59:\t train loss : 0.5610671631289968; train accuracy : 0.9903128969298925; \n",
      " validation loss : 0.5839806247775375; validation accuracy : 0.9707112970711297\n",
      "Epoch 60:\t train loss : 0.5645063854546711; train accuracy : 0.986632175717959; \n",
      " validation loss : 0.5934374486133155; validation accuracy : 0.9581589958158996\n",
      "Epoch 61:\t train loss : 0.5806438373340693; train accuracy : 0.9703036029616778; \n",
      " validation loss : 0.6016776885435771; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5671275660295838; train accuracy : 0.9840586759193284; \n",
      " validation loss : 0.5888231951940653; validation accuracy : 0.9623430962343096\n",
      "Epoch 63:\t train loss : 0.5617773396552748; train accuracy : 0.9894978159174695; \n",
      " validation loss : 0.5954707215069528; validation accuracy : 0.9581589958158996\n",
      "Epoch 64:\t train loss : 0.5611399800579403; train accuracy : 0.9902605409089501; \n",
      " validation loss : 0.5782222237004467; validation accuracy : 0.9748953974895398\n",
      "Epoch 65:\t train loss : 0.5605813445315753; train accuracy : 0.9908550450757458; \n",
      " validation loss : 0.582429193994396; validation accuracy : 0.9707112970711297\n",
      "Epoch 66:\t train loss : 0.562763427822103; train accuracy : 0.9885411567892438; \n",
      " validation loss : 0.6003263222170947; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.5646706703232075; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.5912031479331624; validation accuracy : 0.9623430962343096\n",
      "Epoch 68:\t train loss : 0.5634479396396836; train accuracy : 0.9878750890671953; \n",
      " validation loss : 0.5842658531906147; validation accuracy : 0.9665271966527197\n",
      "Epoch 69:\t train loss : 0.5630687162347506; train accuracy : 0.9882099817218625; \n",
      " validation loss : 0.5895113868248828; validation accuracy : 0.9623430962343096\n",
      "Epoch 70:\t train loss : 0.5632448859411353; train accuracy : 0.9880048948232597; \n",
      " validation loss : 0.5753886985108078; validation accuracy : 0.9748953974895398\n",
      "Epoch 71:\t train loss : 0.5646330842159524; train accuracy : 0.9867406053471297; \n",
      " validation loss : 0.5957930527715056; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5623848392856943; train accuracy : 0.9889807614857957; \n",
      " validation loss : 0.5850966319498125; validation accuracy : 0.9665271966527197\n",
      "Epoch 73:\t train loss : 0.5616093307860499; train accuracy : 0.9897066204033582; \n",
      " validation loss : 0.5989154537545895; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5636387585165309; train accuracy : 0.987695095882772; \n",
      " validation loss : 0.573818863798316; validation accuracy : 0.9748953974895398\n",
      "Epoch 75:\t train loss : 0.5696144357635328; train accuracy : 0.9814969484804362; \n",
      " validation loss : 0.6192062490881275; validation accuracy : 0.9288702928870293\n",
      "Epoch 76:\t train loss : 0.567149556789691; train accuracy : 0.9840335822051488; \n",
      " validation loss : 0.5789285287690247; validation accuracy : 0.9707112970711297\n",
      "Epoch 77:\t train loss : 0.5647159545431185; train accuracy : 0.9867539267015707; \n",
      " validation loss : 0.5915321012595679; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5664341497076069; train accuracy : 0.984804361969082; \n",
      " validation loss : 0.6413725612058142; validation accuracy : 0.9079497907949791\n",
      "Epoch 79:\t train loss : 0.5638357248910723; train accuracy : 0.9874066730691781; \n",
      " validation loss : 0.5763939402143405; validation accuracy : 0.9748953974895398\n",
      "Epoch 80:\t train loss : 0.5632291259254677; train accuracy : 0.9880299885374392; \n",
      " validation loss : 0.5776037919141473; validation accuracy : 0.9748953974895398\n",
      "Epoch 81:\t train loss : 0.5650747275400516; train accuracy : 0.9862951144707085; \n",
      " validation loss : 0.6126380751517098; validation accuracy : 0.9372384937238494\n",
      "Epoch 82:\t train loss : 0.5726267851456055; train accuracy : 0.9785560271383872; \n",
      " validation loss : 0.5968194492154788; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5671957037707297; train accuracy : 0.9840239784379937; \n",
      " validation loss : 0.5946649789236945; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5687279070207927; train accuracy : 0.9824204591220298; \n",
      " validation loss : 0.5967771976057682; validation accuracy : 0.9539748953974896\n",
      "Epoch 85:\t train loss : 0.5782188293603109; train accuracy : 0.9727163171101955; \n",
      " validation loss : 0.5796721838633927; validation accuracy : 0.9748953974895398\n",
      "Epoch 86:\t train loss : 0.5625911887513196; train accuracy : 0.9887329223334056; \n",
      " validation loss : 0.5791677675824612; validation accuracy : 0.9707112970711297\n",
      "Epoch 87:\t train loss : 0.5624622844923354; train accuracy : 0.9887580160475851; \n",
      " validation loss : 0.593159463243512; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5659923691578778; train accuracy : 0.9852535704327892; \n",
      " validation loss : 0.588613428641265; validation accuracy : 0.9623430962343096\n",
      "Epoch 89:\t train loss : 0.5616371173156741; train accuracy : 0.9896932990489172; \n",
      " validation loss : 0.5807298766642093; validation accuracy : 0.9707112970711297\n",
      "Epoch 90:\t train loss : 0.56375842304149; train accuracy : 0.987447256730382; \n",
      " validation loss : 0.587885492092082; validation accuracy : 0.9623430962343096\n",
      "Epoch 91:\t train loss : 0.5602996108675703; train accuracy : 0.9910409244400384; \n",
      " validation loss : 0.5926452464010113; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.56489133133991; train accuracy : 0.9863084358251495; \n",
      " validation loss : 0.608907946278099; validation accuracy : 0.9414225941422594\n",
      "Epoch 93:\t train loss : 0.5640928249814083; train accuracy : 0.9871625515040738; \n",
      " validation loss : 0.5880634231142831; validation accuracy : 0.9623430962343096\n",
      "Epoch 94:\t train loss : 0.5642783415345836; train accuracy : 0.9869980482666749; \n",
      " validation loss : 0.5880009141471289; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5621954640522097; train accuracy : 0.9890833049350971; \n",
      " validation loss : 0.587524022098874; validation accuracy : 0.9623430962343096\n",
      "Epoch 96:\t train loss : 0.5629707955086469; train accuracy : 0.9884268409802038; \n",
      " validation loss : 0.597406746674658; validation accuracy : 0.9497907949790795\n",
      "Epoch 97:\t train loss : 0.5664652635546259; train accuracy : 0.9846590662659934; \n",
      " validation loss : 0.5778989343069785; validation accuracy : 0.9748953974895398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98:\t train loss : 0.562018658924637; train accuracy : 0.9893680101614053; \n",
      " validation loss : 0.579601940886481; validation accuracy : 0.9707112970711297\n",
      "Epoch 99:\t train loss : 0.5637468288806874; train accuracy : 0.9874627466774064; \n",
      " validation loss : 0.5758017140413492; validation accuracy : 0.9707112970711297\n",
      "Epoch 100:\t train loss : 0.5605238747847284; train accuracy : 0.9908528764831624; \n",
      " validation loss : 0.5678601730342274; validation accuracy : 0.9790794979079498\n",
      "Epoch 101:\t train loss : 0.5600861109911249; train accuracy : 0.991226803804331; \n",
      " validation loss : 0.5976775228557005; validation accuracy : 0.9539748953974896\n",
      "Epoch 102:\t train loss : 0.5614995168080736; train accuracy : 0.9897766349639084; \n",
      " validation loss : 0.581387395025259; validation accuracy : 0.9665271966527197\n",
      "Epoch 103:\t train loss : 0.5626286313778381; train accuracy : 0.9886554725982837; \n",
      " validation loss : 0.5861189130638323; validation accuracy : 0.9623430962343096\n",
      "Epoch 104:\t train loss : 0.5635850102274702; train accuracy : 0.9877105858297964; \n",
      " validation loss : 0.5817985985845087; validation accuracy : 0.9707112970711297\n",
      "Epoch 105:\t train loss : 0.5615627196660973; train accuracy : 0.9898150500325289; \n",
      " validation loss : 0.5781657423987251; validation accuracy : 0.9748953974895398\n",
      "Epoch 106:\t train loss : 0.5658288120934136; train accuracy : 0.9853096440410174; \n",
      " validation loss : 0.5824918204124729; validation accuracy : 0.9665271966527197\n",
      "Epoch 107:\t train loss : 0.559696961829627; train accuracy : 0.9916973883949317; \n",
      " validation loss : 0.5660750855868889; validation accuracy : 0.9874476987447699\n",
      "Epoch 108:\t train loss : 0.5641727636630882; train accuracy : 0.9870504042876174; \n",
      " validation loss : 0.5755626160148357; validation accuracy : 0.9748953974895398\n",
      "Epoch 109:\t train loss : 0.5629022944868128; train accuracy : 0.9884172372130487; \n",
      " validation loss : 0.5845467668879544; validation accuracy : 0.9665271966527197\n",
      "Epoch 110:\t train loss : 0.5587854808083752; train accuracy : 0.9925995229096316; \n",
      " validation loss : 0.5816016847639275; validation accuracy : 0.9707112970711297\n",
      "Epoch 111:\t train loss : 0.5612073704337207; train accuracy : 0.9901617150469345; \n",
      " validation loss : 0.577574156981001; validation accuracy : 0.9748953974895398\n",
      "Epoch 112:\t train loss : 0.5727773021329344; train accuracy : 0.9783797515412497; \n",
      " validation loss : 0.6045639993460561; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5646561935048993; train accuracy : 0.9865739335171474; \n",
      " validation loss : 0.5878055445280531; validation accuracy : 0.9623430962343096\n",
      "Epoch 114:\t train loss : 0.5611612820874596; train accuracy : 0.990136621332755; \n",
      " validation loss : 0.580611412858664; validation accuracy : 0.9707112970711297\n",
      "Epoch 115:\t train loss : 0.5623683030282656; train accuracy : 0.9889225192849841; \n",
      " validation loss : 0.5723797420408728; validation accuracy : 0.9790794979079498\n",
      "Epoch 116:\t train loss : 0.5596444560371259; train accuracy : 0.9916605223210136; \n",
      " validation loss : 0.595814694723165; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5603482515959474; train accuracy : 0.9910040583661204; \n",
      " validation loss : 0.5727990407666048; validation accuracy : 0.9790794979079498\n",
      "Epoch 118:\t train loss : 0.5658449635494412; train accuracy : 0.9852882679141237; \n",
      " validation loss : 0.5787772433119002; validation accuracy : 0.9707112970711297\n",
      "Epoch 119:\t train loss : 0.5601818543313742; train accuracy : 0.9911552402490783; \n",
      " validation loss : 0.5907334776743884; validation accuracy : 0.9623430962343096\n",
      "Epoch 120:\t train loss : 0.5645821901152209; train accuracy : 0.986595309644041; \n",
      " validation loss : 0.583268586830589; validation accuracy : 0.9665271966527197\n",
      "Epoch 121:\t train loss : 0.561250634387181; train accuracy : 0.990086433904396; \n",
      " validation loss : 0.5808185611962067; validation accuracy : 0.9707112970711297\n",
      "Epoch 122:\t train loss : 0.5608123158958206; train accuracy : 0.9905201524210787; \n",
      " validation loss : 0.5807863776170635; validation accuracy : 0.9665271966527197\n",
      "Epoch 123:\t train loss : 0.5722690736341031; train accuracy : 0.9788230738250875; \n",
      " validation loss : 0.5844128381664079; validation accuracy : 0.9665271966527197\n",
      "Epoch 124:\t train loss : 0.561711344106753; train accuracy : 0.9897648626041698; \n",
      " validation loss : 0.5724177041447118; validation accuracy : 0.9790794979079498\n",
      "Epoch 125:\t train loss : 0.5601334101453906; train accuracy : 0.9912732736454041; \n",
      " validation loss : 0.5726277296041459; validation accuracy : 0.9790794979079498\n",
      "Epoch 126:\t train loss : 0.5598663841926004; train accuracy : 0.991465039189566; \n",
      " validation loss : 0.5805008978171039; validation accuracy : 0.9707112970711297\n",
      "Epoch 127:\t train loss : 0.5614313705709402; train accuracy : 0.9899160444871279; \n",
      " validation loss : 0.5890209145909016; validation accuracy : 0.9623430962343096\n",
      "Epoch 128:\t train loss : 0.5582597990789524; train accuracy : 0.9931106911614362; \n",
      " validation loss : 0.5688118916258901; validation accuracy : 0.9832635983263598\n",
      "Epoch 129:\t train loss : 0.5604056109666045; train accuracy : 0.9908919111496639; \n",
      " validation loss : 0.591286547717281; validation accuracy : 0.9623430962343096\n",
      "Epoch 130:\t train loss : 0.5594872321113676; train accuracy : 0.99175346200316; \n",
      " validation loss : 0.5852024141890075; validation accuracy : 0.9665271966527197\n",
      "Epoch 131:\t train loss : 0.559418606058016; train accuracy : 0.9920013011555501; \n",
      " validation loss : 0.5902969892045676; validation accuracy : 0.9623430962343096\n",
      "Epoch 132:\t train loss : 0.5609360990542853; train accuracy : 0.9903903466650144; \n",
      " validation loss : 0.5868826751555251; validation accuracy : 0.9623430962343096\n",
      "Epoch 133:\t train loss : 0.5611003025569331; train accuracy : 0.9902819170358438; \n",
      " validation loss : 0.5912312114795615; validation accuracy : 0.9623430962343096\n",
      "Epoch 134:\t train loss : 0.5651369429151116; train accuracy : 0.9861343288205955; \n",
      " validation loss : 0.6084917802782854; validation accuracy : 0.9414225941422594\n",
      "Epoch 135:\t train loss : 0.5635764185285589; train accuracy : 0.9876582298088541; \n",
      " validation loss : 0.585050167426895; validation accuracy : 0.9665271966527197\n",
      "Epoch 136:\t train loss : 0.5625075030669329; train accuracy : 0.9888413519625763; \n",
      " validation loss : 0.574430911120436; validation accuracy : 0.9748953974895398\n",
      "Epoch 137:\t train loss : 0.5631068840630682; train accuracy : 0.9881288143994548; \n",
      " validation loss : 0.5838580038922787; validation accuracy : 0.9665271966527197\n",
      "Epoch 138:\t train loss : 0.5597528933256086; train accuracy : 0.9916295424269649; \n",
      " validation loss : 0.5792097510791767; validation accuracy : 0.9707112970711297\n",
      "Epoch 139:\t train loss : 0.560078706461065; train accuracy : 0.9912481799312246; \n",
      " validation loss : 0.5868273941627666; validation accuracy : 0.9623430962343096\n",
      "Epoch 140:\t train loss : 0.5597689499044965; train accuracy : 0.9915366027448186; \n",
      " validation loss : 0.5848769067336332; validation accuracy : 0.9665271966527197\n",
      "Epoch 141:\t train loss : 0.5628268052754759; train accuracy : 0.9885625329161374; \n",
      " validation loss : 0.6103999473311137; validation accuracy : 0.9414225941422594\n",
      "Epoch 142:\t train loss : 0.56219950843691; train accuracy : 0.9889652715387713; \n",
      " validation loss : 0.5929344750731941; validation accuracy : 0.9581589958158996\n",
      "Epoch 143:\t train loss : 0.5766028513916626; train accuracy : 0.9744202112828774; \n",
      " validation loss : 0.585135979461819; validation accuracy : 0.9665271966527197\n",
      "Epoch 144:\t train loss : 0.5624621449066273; train accuracy : 0.9888103720685275; \n",
      " validation loss : 0.5929351027411878; validation accuracy : 0.9581589958158996\n",
      "Epoch 145:\t train loss : 0.5589779945328578; train accuracy : 0.9924195297252083; \n",
      " validation loss : 0.5815324371699667; validation accuracy : 0.9707112970711297\n",
      "Epoch 146:\t train loss : 0.5588700058379423; train accuracy : 0.9924969794603302; \n",
      " validation loss : 0.5687494188521253; validation accuracy : 0.9832635983263598\n",
      "Epoch 147:\t train loss : 0.5574559462750821; train accuracy : 0.9939220545865733; \n",
      " validation loss : 0.5751263722840659; validation accuracy : 0.9748953974895398\n",
      "Epoch 148:\t train loss : 0.5570960522579126; train accuracy : 0.9943498869233867; \n",
      " validation loss : 0.5701645878118431; validation accuracy : 0.9832635983263598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149:\t train loss : 0.5582726950203785; train accuracy : 0.993054617553208; \n",
      " validation loss : 0.5894362145387498; validation accuracy : 0.9623430962343096\n",
      "Epoch 150:\t train loss : 0.5622631624266144; train accuracy : 0.9889129155178289; \n",
      " validation loss : 0.6274385350839234; validation accuracy : 0.9205020920502092\n",
      "Epoch 151:\t train loss : 0.5613568605943882; train accuracy : 0.9898327085721367; \n",
      " validation loss : 0.580729121348058; validation accuracy : 0.9707112970711297\n",
      "Epoch 152:\t train loss : 0.5568303218654901; train accuracy : 0.9945261625205242; \n",
      " validation loss : 0.5870382614082633; validation accuracy : 0.9623430962343096\n",
      "Epoch 153:\t train loss : 0.5577305996035352; train accuracy : 0.993618141825955; \n",
      " validation loss : 0.5917444307079546; validation accuracy : 0.9581589958158996\n",
      "Epoch 154:\t train loss : 0.5563811423030829; train accuracy : 0.9949812571641005; \n",
      " validation loss : 0.5915668334186568; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5572964967428999; train accuracy : 0.9940865578239723; \n",
      " validation loss : 0.5847294214222917; validation accuracy : 0.9665271966527197\n",
      "Epoch 156:\t train loss : 0.5583070367728348; train accuracy : 0.9930332414263143; \n",
      " validation loss : 0.6167558441378324; validation accuracy : 0.9330543933054394\n",
      "Epoch 157:\t train loss : 0.5602373757922666; train accuracy : 0.9910468106199076; \n",
      " validation loss : 0.5796165197855908; validation accuracy : 0.9707112970711297\n",
      "Early stopping at epoch 157\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.559696961829627; Train accuracy : 0.9916973883949317; \n",
      " Validation loss : 0.5660750855868889; Validation accuracy : 0.9874476987447699\n",
      "--- Let's train model 34 ! ---\n",
      "Epoch 1:\t train loss : 0.8898616692114896; train accuracy : 0.6509712196784287; \n",
      " validation loss : 0.7639509363447474; validation accuracy : 0.7866108786610879\n",
      "Epoch 2:\t train loss : 0.7197222826547026; train accuracy : 0.8313116887140246; \n",
      " validation loss : 0.7150758649601117; validation accuracy : 0.8326359832635983\n",
      "Epoch 3:\t train loss : 0.6889754362925016; train accuracy : 0.8607927754887078; \n",
      " validation loss : 0.6854478730012442; validation accuracy : 0.8661087866108786\n",
      "Epoch 4:\t train loss : 0.6634212014819831; train accuracy : 0.8866262895380898; \n",
      " validation loss : 0.7032323344546262; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.646690003694358; train accuracy : 0.903779547073949; \n",
      " validation loss : 0.7003220291358555; validation accuracy : 0.8368200836820083\n",
      "Epoch 6:\t train loss : 0.6315687697402042; train accuracy : 0.9190585210198581; \n",
      " validation loss : 0.6542344430809988; validation accuracy : 0.891213389121339\n",
      "Epoch 7:\t train loss : 0.6175077855048544; train accuracy : 0.933177917531522; \n",
      " validation loss : 0.6476979006777054; validation accuracy : 0.9037656903765691\n",
      "Epoch 8:\t train loss : 0.6137721022488601; train accuracy : 0.9368527525635862; \n",
      " validation loss : 0.6649764469814273; validation accuracy : 0.891213389121339\n",
      "Epoch 9:\t train loss : 0.6059379836339712; train accuracy : 0.9452792837448496; \n",
      " validation loss : 0.6436524936430738; validation accuracy : 0.9121338912133892\n",
      "Epoch 10:\t train loss : 0.5972862478785442; train accuracy : 0.9536401375507296; \n",
      " validation loss : 0.6322492544790365; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.6025064785478597; train accuracy : 0.9484953065460516; \n",
      " validation loss : 0.6343682723985999; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.5961496857617405; train accuracy : 0.9551116825180458; \n",
      " validation loss : 0.624539287497268; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.5950691747389041; train accuracy : 0.9559614610118033; \n",
      " validation loss : 0.6366336175916979; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5975951405683945; train accuracy : 0.9532934725363239; \n",
      " validation loss : 0.6286925414165465; validation accuracy : 0.9246861924686193\n",
      "Epoch 15:\t train loss : 0.5931776293097666; train accuracy : 0.9581241674153474; \n",
      " validation loss : 0.6391482518687154; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.5938521893498122; train accuracy : 0.9566046036122556; \n",
      " validation loss : 0.6378454416960431; validation accuracy : 0.9163179916317992\n",
      "Epoch 17:\t train loss : 0.5912882771243887; train accuracy : 0.9598921899687103; \n",
      " validation loss : 0.6626037566136418; validation accuracy : 0.8786610878661087\n",
      "Epoch 18:\t train loss : 0.5997510012405218; train accuracy : 0.9509523219430589; \n",
      " validation loss : 0.6289113081626602; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.5841810125304377; train accuracy : 0.9669401158648038; \n",
      " validation loss : 0.639613980065575; validation accuracy : 0.9121338912133892\n",
      "Epoch 20:\t train loss : 0.584329538952342; train accuracy : 0.9669614919916973; \n",
      " validation loss : 0.6368625135033384; validation accuracy : 0.9079497907949791\n",
      "Epoch 21:\t train loss : 0.5840654047975617; train accuracy : 0.9670720902134514; \n",
      " validation loss : 0.659012239805335; validation accuracy : 0.8870292887029289\n",
      "Epoch 22:\t train loss : 0.5868072046331012; train accuracy : 0.9642566374423; \n",
      " validation loss : 0.6221241251363102; validation accuracy : 0.9288702928870293\n",
      "Epoch 23:\t train loss : 0.5826798002555259; train accuracy : 0.9685724464822331; \n",
      " validation loss : 0.6330340793510677; validation accuracy : 0.9163179916317992\n",
      "Epoch 24:\t train loss : 0.5884640580136673; train accuracy : 0.962364695312742; \n",
      " validation loss : 0.6523325623720753; validation accuracy : 0.895397489539749\n",
      "Epoch 25:\t train loss : 0.5940159959769932; train accuracy : 0.9566783357600916; \n",
      " validation loss : 0.6150854861693287; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5802586287528766; train accuracy : 0.9710161405247995; \n",
      " validation loss : 0.607837484873257; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5804128314414955; train accuracy : 0.970625174261904; \n",
      " validation loss : 0.6145616240724174; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5723352434429178; train accuracy : 0.9788636574862914; \n",
      " validation loss : 0.6162977891860194; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.5733223123030706; train accuracy : 0.9780175965798197; \n",
      " validation loss : 0.6130935128376935; validation accuracy : 0.9330543933054394\n",
      "Epoch 30:\t train loss : 0.5791373337723786; train accuracy : 0.9718798599708789; \n",
      " validation loss : 0.6106677047670326; validation accuracy : 0.9372384937238494\n",
      "Epoch 31:\t train loss : 0.5727657975079469; train accuracy : 0.9785597447256731; \n",
      " validation loss : 0.6267700532205029; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.5782980736631804; train accuracy : 0.9727259208773505; \n",
      " validation loss : 0.6135785810059052; validation accuracy : 0.9414225941422594\n",
      "Epoch 33:\t train loss : 0.5829748406027343; train accuracy : 0.9680789367700362; \n",
      " validation loss : 0.6283320966305666; validation accuracy : 0.9246861924686193\n",
      "Epoch 34:\t train loss : 0.5803756786161697; train accuracy : 0.9708981071284736; \n",
      " validation loss : 0.6150740293400833; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5719273620546471; train accuracy : 0.9792685647015087; \n",
      " validation loss : 0.6147280268722586; validation accuracy : 0.9330543933054394\n",
      "Epoch 36:\t train loss : 0.5754552932426331; train accuracy : 0.9756417485052201; \n",
      " validation loss : 0.6180164760376081; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5744774855833249; train accuracy : 0.9767415347439512; \n",
      " validation loss : 0.6157398357662054; validation accuracy : 0.9372384937238494\n",
      "Epoch 38:\t train loss : 0.5717741080813694; train accuracy : 0.9795820812292821; \n",
      " validation loss : 0.6193949616245467; validation accuracy : 0.9288702928870293\n",
      "Epoch 39:\t train loss : 0.5746588940020411; train accuracy : 0.9765888038662908; \n",
      " validation loss : 0.6129563566100574; validation accuracy : 0.9330543933054394\n",
      "Epoch 40:\t train loss : 0.5759421366056044; train accuracy : 0.9751305802534155; \n",
      " validation loss : 0.6249123539051492; validation accuracy : 0.9246861924686193\n",
      "Epoch 41:\t train loss : 0.5703385886089988; train accuracy : 0.9808832367793302; \n",
      " validation loss : 0.611174016770845; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:\t train loss : 0.5753850417673984; train accuracy : 0.9757037082933177; \n",
      " validation loss : 0.6078826558638786; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5764270746731259; train accuracy : 0.9746039220545866; \n",
      " validation loss : 0.6173265301514956; validation accuracy : 0.9288702928870293\n",
      "Epoch 44:\t train loss : 0.5699615821989583; train accuracy : 0.9813826326713962; \n",
      " validation loss : 0.5979270908906146; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5710425558314131; train accuracy : 0.9800910808885034; \n",
      " validation loss : 0.6054124706708918; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5659342045164772; train accuracy : 0.9852727779670993; \n",
      " validation loss : 0.5839755160523044; validation accuracy : 0.9707112970711297\n",
      "Epoch 47:\t train loss : 0.5658674900429513; train accuracy : 0.9854431673843675; \n",
      " validation loss : 0.6152361655755414; validation accuracy : 0.9330543933054394\n",
      "Epoch 48:\t train loss : 0.5651569088943256; train accuracy : 0.9860413891384492; \n",
      " validation loss : 0.5963343265127222; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5659244188348235; train accuracy : 0.9854217912574739; \n",
      " validation loss : 0.5961534217562767; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.582102912704176; train accuracy : 0.9687022522382973; \n",
      " validation loss : 0.6309263386170016; validation accuracy : 0.9205020920502092\n",
      "Epoch 51:\t train loss : 0.5767346665568771; train accuracy : 0.9743058954738375; \n",
      " validation loss : 0.6112364166628432; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5732938699758123; train accuracy : 0.9775779918832678; \n",
      " validation loss : 0.5876741837023175; validation accuracy : 0.9581589958158996\n",
      "Epoch 53:\t train loss : 0.5670931114034089; train accuracy : 0.9840586759193284; \n",
      " validation loss : 0.5977797426146022; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.5677326656592111; train accuracy : 0.9835475076675237; \n",
      " validation loss : 0.6096085678724601; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.5677771430956512; train accuracy : 0.9833675144831004; \n",
      " validation loss : 0.619267006317645; validation accuracy : 0.9288702928870293\n",
      "Epoch 56:\t train loss : 0.5717904658843599; train accuracy : 0.9793571671984882; \n",
      " validation loss : 0.627143844043101; validation accuracy : 0.9246861924686193\n",
      "Epoch 57:\t train loss : 0.572724132676725; train accuracy : 0.9782942470336752; \n",
      " validation loss : 0.6178976652019319; validation accuracy : 0.9330543933054394\n",
      "Epoch 58:\t train loss : 0.5749515389395035; train accuracy : 0.975994299699495; \n",
      " validation loss : 0.6235784487654598; validation accuracy : 0.9246861924686193\n",
      "Epoch 59:\t train loss : 0.5665623191209914; train accuracy : 0.9844982806158803; \n",
      " validation loss : 0.6057644906795453; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5640089113285988; train accuracy : 0.9872245112921714; \n",
      " validation loss : 0.6104947496748643; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5607010168152619; train accuracy : 0.9906750518913225; \n",
      " validation loss : 0.6066900667650742; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5671452492597493; train accuracy : 0.9840026023111; \n",
      " validation loss : 0.5985292945090741; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5601587365008422; train accuracy : 0.9912732736454041; \n",
      " validation loss : 0.574922679383965; validation accuracy : 0.9748953974895398\n",
      "Epoch 64:\t train loss : 0.561548175044031; train accuracy : 0.9896932990489172; \n",
      " validation loss : 0.6002796162776188; validation accuracy : 0.9497907949790795\n",
      "Epoch 65:\t train loss : 0.5614518795912662; train accuracy : 0.989811332445243; \n",
      " validation loss : 0.6154340113909201; validation accuracy : 0.9330543933054394\n",
      "Epoch 66:\t train loss : 0.5576544263124354; train accuracy : 0.9938600947984758; \n",
      " validation loss : 0.6007682253564564; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.5631221499762858; train accuracy : 0.9881074382725611; \n",
      " validation loss : 0.6060968271393244; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5626853834760918; train accuracy : 0.9886533040057003; \n",
      " validation loss : 0.6001088143635382; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5670091590200691; train accuracy : 0.9841243532947117; \n",
      " validation loss : 0.5893970249206799; validation accuracy : 0.9623430962343096\n",
      "Epoch 70:\t train loss : 0.5700041685071696; train accuracy : 0.9811983023018062; \n",
      " validation loss : 0.6406766593777098; validation accuracy : 0.9079497907949791\n",
      "Epoch 71:\t train loss : 0.5707347873805223; train accuracy : 0.980437745902909; \n",
      " validation loss : 0.5898289028532762; validation accuracy : 0.9623430962343096\n",
      "Epoch 72:\t train loss : 0.5595262512963597; train accuracy : 0.9917940456643638; \n",
      " validation loss : 0.5811301460482028; validation accuracy : 0.9707112970711297\n",
      "Epoch 73:\t train loss : 0.558021118307864; train accuracy : 0.9933334365996468; \n",
      " validation loss : 0.6100075138573567; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5609302610818535; train accuracy : 0.9903940642523003; \n",
      " validation loss : 0.6061200734406772; validation accuracy : 0.9414225941422594\n",
      "Epoch 75:\t train loss : 0.5623185460360509; train accuracy : 0.9889844790730816; \n",
      " validation loss : 0.6025066952134914; validation accuracy : 0.9497907949790795\n",
      "Epoch 76:\t train loss : 0.5658399345616282; train accuracy : 0.9851857244648223; \n",
      " validation loss : 0.5966514765019668; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5611140795872874; train accuracy : 0.9901329037454691; \n",
      " validation loss : 0.6091660118996562; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5659625041810172; train accuracy : 0.9850618048886273; \n",
      " validation loss : 0.6537313627755847; validation accuracy : 0.895397489539749\n",
      "Epoch 79:\t train loss : 0.576050240231963; train accuracy : 0.974904117227919; \n",
      " validation loss : 0.6291117286227615; validation accuracy : 0.9246861924686193\n",
      "Epoch 80:\t train loss : 0.5667137227807832; train accuracy : 0.9843433811456365; \n",
      " validation loss : 0.5987037565233497; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5657305616275857; train accuracy : 0.9854180736701881; \n",
      " validation loss : 0.5989738790838441; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5616105986538619; train accuracy : 0.9896911304563338; \n",
      " validation loss : 0.5947414105488957; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5644102704667574; train accuracy : 0.9867443229344156; \n",
      " validation loss : 0.6220414509007837; validation accuracy : 0.9246861924686193\n",
      "Epoch 84:\t train loss : 0.5633825771323008; train accuracy : 0.9878286192261222; \n",
      " validation loss : 0.6070041059962148; validation accuracy : 0.9456066945606695\n",
      "Epoch 85:\t train loss : 0.5586834570201367; train accuracy : 0.992527959354379; \n",
      " validation loss : 0.5965755920013283; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5721311710416628; train accuracy : 0.9790399330834288; \n",
      " validation loss : 0.5938395692324115; validation accuracy : 0.9581589958158996\n",
      "Epoch 87:\t train loss : 0.5659557476134871; train accuracy : 0.9853598314693763; \n",
      " validation loss : 0.6079986613288314; validation accuracy : 0.9414225941422594\n",
      "Epoch 88:\t train loss : 0.5646348779272435; train accuracy : 0.9864153164596177; \n",
      " validation loss : 0.5779751659031871; validation accuracy : 0.9707112970711297\n",
      "Epoch 89:\t train loss : 0.5607190982637; train accuracy : 0.9905666222621519; \n",
      " validation loss : 0.5988659632739336; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5649790363987293; train accuracy : 0.9862294370953252; \n",
      " validation loss : 0.6054686335390109; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5618444623126021; train accuracy : 0.9893584063942501; \n",
      " validation loss : 0.6097492270614937; validation accuracy : 0.9414225941422594\n",
      "Epoch 92:\t train loss : 0.5577202210636317; train accuracy : 0.9936122556460857; \n",
      " validation loss : 0.5899135494149832; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93:\t train loss : 0.560614410342518; train accuracy : 0.9907215217323957; \n",
      " validation loss : 0.6003700857659624; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.559725097632045; train accuracy : 0.9915579788717123; \n",
      " validation loss : 0.6060669636168179; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5593807136278987; train accuracy : 0.991964435081632; \n",
      " validation loss : 0.5987819275932775; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5594722396416528; train accuracy : 0.9919142476532731; \n",
      " validation loss : 0.6031628256806629; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.559557554272736; train accuracy : 0.9917748381300536; \n",
      " validation loss : 0.600432020999531; validation accuracy : 0.9497907949790795\n",
      "Epoch 98:\t train loss : 0.5576869344720656; train accuracy : 0.9936122556460857; \n",
      " validation loss : 0.5818238291289174; validation accuracy : 0.9665271966527197\n",
      "Epoch 99:\t train loss : 0.5578961161294982; train accuracy : 0.9934883360698906; \n",
      " validation loss : 0.5881838473366218; validation accuracy : 0.9623430962343096\n",
      "Epoch 100:\t train loss : 0.5574323460571827; train accuracy : 0.9937767588834846; \n",
      " validation loss : 0.6067655760074829; validation accuracy : 0.9414225941422594\n",
      "Epoch 101:\t train loss : 0.5647657012418342; train accuracy : 0.9863378667244957; \n",
      " validation loss : 0.6240520669544452; validation accuracy : 0.9246861924686193\n",
      "Epoch 102:\t train loss : 0.5625705598258768; train accuracy : 0.9887115462065119; \n",
      " validation loss : 0.6037523101924548; validation accuracy : 0.9456066945606695\n",
      "Epoch 103:\t train loss : 0.5645949500616757; train accuracy : 0.9867811890083336; \n",
      " validation loss : 0.6175100048997487; validation accuracy : 0.9330543933054394\n",
      "Epoch 104:\t train loss : 0.563469236328296; train accuracy : 0.9877511694910004; \n",
      " validation loss : 0.6173252384527665; validation accuracy : 0.9288702928870293\n",
      "Epoch 105:\t train loss : 0.5657602566747525; train accuracy : 0.9853465101149355; \n",
      " validation loss : 0.6089533730238585; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.5592062652334284; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.6020852999667742; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5594203079526503; train accuracy : 0.9919762074413705; \n",
      " validation loss : 0.5998919312642089; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.559788951643578; train accuracy : 0.9915269989776635; \n",
      " validation loss : 0.5949982218533268; validation accuracy : 0.9539748953974896\n",
      "Epoch 109:\t train loss : 0.5636870947095969; train accuracy : 0.987447256730382; \n",
      " validation loss : 0.6013642028757241; validation accuracy : 0.9456066945606695\n",
      "Epoch 110:\t train loss : 0.5636736753842015; train accuracy : 0.9876486260416989; \n",
      " validation loss : 0.594488779197968; validation accuracy : 0.9539748953974896\n",
      "Epoch 111:\t train loss : 0.558275275903817; train accuracy : 0.9931379534681991; \n",
      " validation loss : 0.6098664111122936; validation accuracy : 0.9372384937238494\n",
      "Epoch 112:\t train loss : 0.5592818769243303; train accuracy : 0.9920610923510641; \n",
      " validation loss : 0.6152007741792154; validation accuracy : 0.9372384937238494\n",
      "Epoch 113:\t train loss : 0.5594079848319602; train accuracy : 0.9918832677592243; \n",
      " validation loss : 0.607761202245175; validation accuracy : 0.9414225941422594\n",
      "Early stopping at epoch 113\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5601587365008422; Train accuracy : 0.9912732736454041; \n",
      " Validation loss : 0.574922679383965; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 35 ! ---\n",
      "Epoch 1:\t train loss : 0.9583673695688955; train accuracy : 0.5713906874438489; \n",
      " validation loss : 0.8187427172285672; validation accuracy : 0.7196652719665272\n",
      "Epoch 2:\t train loss : 0.7737520836411959; train accuracy : 0.7759565042287555; \n",
      " validation loss : 0.7219838232203898; validation accuracy : 0.8242677824267782\n",
      "Epoch 3:\t train loss : 0.6992304961532827; train accuracy : 0.851026054090895; \n",
      " validation loss : 0.6705046699159846; validation accuracy : 0.8870292887029289\n",
      "Epoch 4:\t train loss : 0.669649842838081; train accuracy : 0.8814393258775055; \n",
      " validation loss : 0.6722971737591823; validation accuracy : 0.8828451882845189\n",
      "Epoch 5:\t train loss : 0.6466169986661308; train accuracy : 0.9038938628829889; \n",
      " validation loss : 0.6767601516656537; validation accuracy : 0.8661087866108786\n",
      "Epoch 6:\t train loss : 0.6272312621131653; train accuracy : 0.9241568821834629; \n",
      " validation loss : 0.6459846814282898; validation accuracy : 0.9037656903765691\n",
      "Epoch 7:\t train loss : 0.6218668067851633; train accuracy : 0.9290789677499303; \n",
      " validation loss : 0.6490474039653413; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6158690921819244; train accuracy : 0.9353833761888535; \n",
      " validation loss : 0.6269372004296584; validation accuracy : 0.9246861924686193\n",
      "Epoch 9:\t train loss : 0.6083585561784972; train accuracy : 0.9431379534681992; \n",
      " validation loss : 0.6680078295788262; validation accuracy : 0.8744769874476988\n",
      "Epoch 10:\t train loss : 0.5996532531819511; train accuracy : 0.9516537067443229; \n",
      " validation loss : 0.6485982509212678; validation accuracy : 0.899581589958159\n",
      "Epoch 11:\t train loss : 0.5993770530458099; train accuracy : 0.9519362433780476; \n",
      " validation loss : 0.6362509855283065; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.598323609391905; train accuracy : 0.9526562161157409; \n",
      " validation loss : 0.6158101824199782; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.5967249366821004; train accuracy : 0.9542324731249419; \n",
      " validation loss : 0.629937147187154; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5984690070605854; train accuracy : 0.9524725053440317; \n",
      " validation loss : 0.62492771980704; validation accuracy : 0.9288702928870293\n",
      "Epoch 15:\t train loss : 0.5959267158079006; train accuracy : 0.954966386814957; \n",
      " validation loss : 0.6345663796632681; validation accuracy : 0.9163179916317992\n",
      "Epoch 16:\t train loss : 0.5907588471208065; train accuracy : 0.9601208215867901; \n",
      " validation loss : 0.6367090330985631; validation accuracy : 0.9121338912133892\n",
      "Epoch 17:\t train loss : 0.5884210495355731; train accuracy : 0.9628758635645466; \n",
      " validation loss : 0.6281526092729517; validation accuracy : 0.9163179916317992\n",
      "Epoch 18:\t train loss : 0.5897892203403434; train accuracy : 0.9613290374546919; \n",
      " validation loss : 0.6177512513077641; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5808345752602075; train accuracy : 0.9704835961461011; \n",
      " validation loss : 0.6280153725372944; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5818741924952483; train accuracy : 0.9691338021623966; \n",
      " validation loss : 0.6293746601478789; validation accuracy : 0.9163179916317992\n",
      "Epoch 21:\t train loss : 0.5787282586315983; train accuracy : 0.9727819944855789; \n",
      " validation loss : 0.6167324121391502; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5924770100350631; train accuracy : 0.9581749744415874; \n",
      " validation loss : 0.6208679224859823; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5832371136907821; train accuracy : 0.9678193252579076; \n",
      " validation loss : 0.6249557547770437; validation accuracy : 0.9288702928870293\n",
      "Epoch 24:\t train loss : 0.5832080526398579; train accuracy : 0.967834815204932; \n",
      " validation loss : 0.6381011592053419; validation accuracy : 0.9163179916317992\n",
      "Epoch 25:\t train loss : 0.5789463748361908; train accuracy : 0.9726388673750735; \n",
      " validation loss : 0.6271865396597913; validation accuracy : 0.9246861924686193\n",
      "Epoch 26:\t train loss : 0.5753025766466966; train accuracy : 0.9760872393816413; \n",
      " validation loss : 0.6137951135441847; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5812873972554234; train accuracy : 0.9698794882121503; \n",
      " validation loss : 0.6194785178620758; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5861147315482953; train accuracy : 0.9647767898633787; \n",
      " validation loss : 0.6821537921326519; validation accuracy : 0.8661087866108786\n",
      "Epoch 29:\t train loss : 0.5784228513717506; train accuracy : 0.9728188605594968; \n",
      " validation loss : 0.6151641160880874; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:\t train loss : 0.5781582085212957; train accuracy : 0.9729118002416431; \n",
      " validation loss : 0.6334386697707831; validation accuracy : 0.9163179916317992\n",
      "Epoch 31:\t train loss : 0.575312614826648; train accuracy : 0.9756999907060318; \n",
      " validation loss : 0.6002883556438586; validation accuracy : 0.9497907949790795\n",
      "Epoch 32:\t train loss : 0.5747450844660064; train accuracy : 0.9766213327550419; \n",
      " validation loss : 0.6413094652480452; validation accuracy : 0.899581589958159\n",
      "Epoch 33:\t train loss : 0.5796683860940254; train accuracy : 0.9714151615601475; \n",
      " validation loss : 0.5902981697528527; validation accuracy : 0.9581589958158996\n",
      "Epoch 34:\t train loss : 0.5744085861542559; train accuracy : 0.9764686018773816; \n",
      " validation loss : 0.6132993275084625; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5734003103555131; train accuracy : 0.9776303479042102; \n",
      " validation loss : 0.579484512090365; validation accuracy : 0.9707112970711297\n",
      "Epoch 36:\t train loss : 0.5785921670221762; train accuracy : 0.9723792558629449; \n",
      " validation loss : 0.609033586857018; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.5702992228108211; train accuracy : 0.9809355928002726; \n",
      " validation loss : 0.610200543794954; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.566548614182102; train accuracy : 0.9849298305399795; \n",
      " validation loss : 0.5904827881268876; validation accuracy : 0.9581589958158996\n",
      "Epoch 39:\t train loss : 0.5687081389671444; train accuracy : 0.9825930171318814; \n",
      " validation loss : 0.5776369594723014; validation accuracy : 0.9707112970711297\n",
      "Epoch 40:\t train loss : 0.5773777278018354; train accuracy : 0.9738508008302612; \n",
      " validation loss : 0.6208676408988177; validation accuracy : 0.9246861924686193\n",
      "Epoch 41:\t train loss : 0.5717386061040232; train accuracy : 0.9794677654202423; \n",
      " validation loss : 0.6262350950025112; validation accuracy : 0.9246861924686193\n",
      "Epoch 42:\t train loss : 0.5694222766652786; train accuracy : 0.9818745933888906; \n",
      " validation loss : 0.6124277549472413; validation accuracy : 0.9372384937238494\n",
      "Epoch 43:\t train loss : 0.5792576881212121; train accuracy : 0.971738281855076; \n",
      " validation loss : 0.6154173935343809; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5978534359708564; train accuracy : 0.9526450633538833; \n",
      " validation loss : 0.6390170639769273; validation accuracy : 0.9163179916317992\n",
      "Epoch 45:\t train loss : 0.5754918889619475; train accuracy : 0.9755546950029431; \n",
      " validation loss : 0.5865643863648264; validation accuracy : 0.9665271966527197\n",
      "Epoch 46:\t train loss : 0.5682382715895652; train accuracy : 0.9829861519873602; \n",
      " validation loss : 0.5943208745480952; validation accuracy : 0.9581589958158996\n",
      "Epoch 47:\t train loss : 0.5714825504151786; train accuracy : 0.9796344372502246; \n",
      " validation loss : 0.5958113368404221; validation accuracy : 0.9539748953974896\n",
      "Epoch 48:\t train loss : 0.5694959118853097; train accuracy : 0.981601660522321; \n",
      " validation loss : 0.6006714490921619; validation accuracy : 0.9497907949790795\n",
      "Epoch 49:\t train loss : 0.563229878905016; train accuracy : 0.9880454784844636; \n",
      " validation loss : 0.5735445281181306; validation accuracy : 0.9748953974895398\n",
      "Epoch 50:\t train loss : 0.5645599923618729; train accuracy : 0.986833545029276; \n",
      " validation loss : 0.5824860161574884; validation accuracy : 0.9665271966527197\n",
      "Epoch 51:\t train loss : 0.5656853865099937; train accuracy : 0.9856851203568884; \n",
      " validation loss : 0.5988596503135534; validation accuracy : 0.9497907949790795\n",
      "Epoch 52:\t train loss : 0.5706495604833509; train accuracy : 0.9806295114470709; \n",
      " validation loss : 0.6085144195082937; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.5697247361086477; train accuracy : 0.9814371572849221; \n",
      " validation loss : 0.5984989318270428; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.5670586873360045; train accuracy : 0.9840704482790669; \n",
      " validation loss : 0.594707955986602; validation accuracy : 0.9581589958158996\n",
      "Epoch 55:\t train loss : 0.5726014829109377; train accuracy : 0.9782868118591035; \n",
      " validation loss : 0.5723251648174579; validation accuracy : 0.9790794979079498\n",
      "Epoch 56:\t train loss : 0.5738606504619155; train accuracy : 0.9771405557792993; \n",
      " validation loss : 0.5966855819205202; validation accuracy : 0.9539748953974896\n",
      "Epoch 57:\t train loss : 0.579025461758345; train accuracy : 0.971902785092475; \n",
      " validation loss : 0.6112762444979735; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5703335294047038; train accuracy : 0.9806781498807274; \n",
      " validation loss : 0.6005529649601723; validation accuracy : 0.9497907949790795\n",
      "Epoch 59:\t train loss : 0.5671683407571024; train accuracy : 0.9840490721521732; \n",
      " validation loss : 0.5957785536437185; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5705496373518656; train accuracy : 0.9805638340716875; \n",
      " validation loss : 0.6128202712069395; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.564576592646084; train accuracy : 0.9866668731992937; \n",
      " validation loss : 0.6181756525241215; validation accuracy : 0.9330543933054394\n",
      "Epoch 62:\t train loss : 0.5650282543404085; train accuracy : 0.9861519873602033; \n",
      " validation loss : 0.5982042031973018; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.5645280197741689; train accuracy : 0.9868025651352272; \n",
      " validation loss : 0.5943895674274015; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5657806296317387; train accuracy : 0.9855633693732767; \n",
      " validation loss : 0.6011342842965626; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.5667025593966388; train accuracy : 0.9844673007218315; \n",
      " validation loss : 0.5990594263325794; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5705927468768354; train accuracy : 0.9804804981566964; \n",
      " validation loss : 0.6019001586615917; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5687488423918399; train accuracy : 0.9820877350599461; \n",
      " validation loss : 0.5959091761675579; validation accuracy : 0.9581589958158996\n",
      "Epoch 68:\t train loss : 0.5657107539891096; train accuracy : 0.9856194429815051; \n",
      " validation loss : 0.591141490153491; validation accuracy : 0.9623430962343096\n",
      "Epoch 69:\t train loss : 0.5675074186177782; train accuracy : 0.9837061247250535; \n",
      " validation loss : 0.6046114474096657; validation accuracy : 0.9456066945606695\n",
      "Epoch 70:\t train loss : 0.5904098884939875; train accuracy : 0.9604519966541715; \n",
      " validation loss : 0.5884645498362736; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5665017059627229; train accuracy : 0.9846184826047895; \n",
      " validation loss : 0.5948349971633304; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.564155677279201; train accuracy : 0.9870909879488212; \n",
      " validation loss : 0.5955069619764373; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5636454245337827; train accuracy : 0.9876582298088541; \n",
      " validation loss : 0.6010664110976404; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5746361050737357; train accuracy : 0.9764088106818675; \n",
      " validation loss : 0.6587555910248767; validation accuracy : 0.8870292887029289\n",
      "Epoch 75:\t train loss : 0.5664447900231546; train accuracy : 0.984606710245051; \n",
      " validation loss : 0.59721662873928; validation accuracy : 0.9539748953974896\n",
      "Epoch 76:\t train loss : 0.5620933086247214; train accuracy : 0.989311936553177; \n",
      " validation loss : 0.5844959195641537; validation accuracy : 0.9665271966527197\n",
      "Epoch 77:\t train loss : 0.5605844562979497; train accuracy : 0.9907466154465752; \n",
      " validation loss : 0.58808678006071; validation accuracy : 0.9623430962343096\n",
      "Epoch 78:\t train loss : 0.5632680597097055; train accuracy : 0.9880454784844636; \n",
      " validation loss : 0.5870093727121523; validation accuracy : 0.9665271966527197\n",
      "Epoch 79:\t train loss : 0.5633754529025282; train accuracy : 0.9879798011090802; \n",
      " validation loss : 0.5693333764726894; validation accuracy : 0.9790794979079498\n",
      "Epoch 80:\t train loss : 0.5680408306132575; train accuracy : 0.9833247622293132; \n",
      " validation loss : 0.6121797822973253; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81:\t train loss : 0.5694122428512476; train accuracy : 0.9818089160135073; \n",
      " validation loss : 0.6114405371975368; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5635405504924416; train accuracy : 0.9877629418507389; \n",
      " validation loss : 0.5891752634182583; validation accuracy : 0.9623430962343096\n",
      "Epoch 83:\t train loss : 0.5626826421449393; train accuracy : 0.9885817404504477; \n",
      " validation loss : 0.6050894169351073; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5750928826418507; train accuracy : 0.975796647975464; \n",
      " validation loss : 0.6027886220689935; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5807586148960255; train accuracy : 0.970299885374392; \n",
      " validation loss : 0.6075216301294134; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.5653866949159876; train accuracy : 0.9859602218160414; \n",
      " validation loss : 0.5725153026997866; validation accuracy : 0.9748953974895398\n",
      "Epoch 87:\t train loss : 0.5597209062961087; train accuracy : 0.9916354286068342; \n",
      " validation loss : 0.5758712923161096; validation accuracy : 0.9790794979079498\n",
      "Epoch 88:\t train loss : 0.5603044010689011; train accuracy : 0.9909944545989653; \n",
      " validation loss : 0.6008434114543757; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.5640930288194168; train accuracy : 0.9870445181077481; \n",
      " validation loss : 0.5766402078007417; validation accuracy : 0.9748953974895398\n",
      "Epoch 90:\t train loss : 0.5698530186669912; train accuracy : 0.9810477400167291; \n",
      " validation loss : 0.628689259998564; validation accuracy : 0.9246861924686193\n",
      "Epoch 91:\t train loss : 0.5746453899064383; train accuracy : 0.9764339043960469; \n",
      " validation loss : 0.6044375065588019; validation accuracy : 0.9456066945606695\n",
      "Epoch 92:\t train loss : 0.5718578485964031; train accuracy : 0.9793091483627125; \n",
      " validation loss : 0.5811362052989042; validation accuracy : 0.9707112970711297\n",
      "Epoch 93:\t train loss : 0.562457955506069; train accuracy : 0.9888664456767557; \n",
      " validation loss : 0.5765029259464733; validation accuracy : 0.9748953974895398\n",
      "Epoch 94:\t train loss : 0.5623459540461747; train accuracy : 0.9889689891260572; \n",
      " validation loss : 0.5997439142798525; validation accuracy : 0.9497907949790795\n",
      "Epoch 95:\t train loss : 0.5605526563781215; train accuracy : 0.9908860249697946; \n",
      " validation loss : 0.5941171271123667; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.5628061464070047; train accuracy : 0.9885064593079091; \n",
      " validation loss : 0.5980329765905893; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5642854166261002; train accuracy : 0.9870231419808544; \n",
      " validation loss : 0.5846247688623561; validation accuracy : 0.9665271966527197\n",
      "Epoch 98:\t train loss : 0.5623053540928724; train accuracy : 0.9889844790730815; \n",
      " validation loss : 0.5832929193484518; validation accuracy : 0.9665271966527197\n",
      "Epoch 99:\t train loss : 0.5606637526452065; train accuracy : 0.9906536757644289; \n",
      " validation loss : 0.5831884347084316; validation accuracy : 0.9707112970711297\n",
      "Epoch 100:\t train loss : 0.5638212496775765; train accuracy : 0.9873484308683664; \n",
      " validation loss : 0.593370125515861; validation accuracy : 0.9581589958158996\n",
      "Epoch 101:\t train loss : 0.5589146334289774; train accuracy : 0.9923826636512904; \n",
      " validation loss : 0.6038469656297206; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5586040703205193; train accuracy : 0.9927448186127203; \n",
      " validation loss : 0.6223163412127553; validation accuracy : 0.9288702928870293\n",
      "Epoch 103:\t train loss : 0.5601948496595208; train accuracy : 0.9910313206728832; \n",
      " validation loss : 0.5858321474969267; validation accuracy : 0.9665271966527197\n",
      "Epoch 104:\t train loss : 0.5675233661239661; train accuracy : 0.9837141794975062; \n",
      " validation loss : 0.5975961292494014; validation accuracy : 0.9539748953974896\n",
      "Epoch 105:\t train loss : 0.56058346029058; train accuracy : 0.9905452461352582; \n",
      " validation loss : 0.5958839269542173; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5572880503424562; train accuracy : 0.9940149942687195; \n",
      " validation loss : 0.6135953359393673; validation accuracy : 0.9372384937238494\n",
      "Epoch 107:\t train loss : 0.5601509520073243; train accuracy : 0.991088943275814; \n",
      " validation loss : 0.6062414380199976; validation accuracy : 0.9456066945606695\n",
      "Epoch 108:\t train loss : 0.5638943652361601; train accuracy : 0.9872901886675548; \n",
      " validation loss : 0.6408910008945808; validation accuracy : 0.9079497907949791\n",
      "Epoch 109:\t train loss : 0.5601939957320375; train accuracy : 0.9911087704080052; \n",
      " validation loss : 0.5894877785355309; validation accuracy : 0.9623430962343096\n",
      "Epoch 110:\t train loss : 0.5575900823696746; train accuracy : 0.9937516651693051; \n",
      " validation loss : 0.5964283205635936; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.5570859927896706; train accuracy : 0.994278323368134; \n",
      " validation loss : 0.5905753140624591; validation accuracy : 0.9623430962343096\n",
      "Epoch 112:\t train loss : 0.5644341392499376; train accuracy : 0.9867907927754888; \n",
      " validation loss : 0.5811929220605402; validation accuracy : 0.9707112970711297\n",
      "Epoch 113:\t train loss : 0.560160061837952; train accuracy : 0.9911338641221847; \n",
      " validation loss : 0.5931310280410581; validation accuracy : 0.9581589958158996\n",
      "Epoch 114:\t train loss : 0.5591925504113039; train accuracy : 0.9922240465937606; \n",
      " validation loss : 0.6116410325976599; validation accuracy : 0.9372384937238494\n",
      "Epoch 115:\t train loss : 0.560840570306996; train accuracy : 0.9902546547290808; \n",
      " validation loss : 0.5917330189314973; validation accuracy : 0.9623430962343096\n",
      "Epoch 116:\t train loss : 0.5601961993563922; train accuracy : 0.9910969980482667; \n",
      " validation loss : 0.6028472447462566; validation accuracy : 0.9497907949790795\n",
      "Epoch 117:\t train loss : 0.5601423652947578; train accuracy : 0.9911958239102823; \n",
      " validation loss : 0.5874951655666937; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5619427628683806; train accuracy : 0.9891703584373741; \n",
      " validation loss : 0.5794785445576291; validation accuracy : 0.9748953974895398\n",
      "Epoch 119:\t train loss : 0.5608312158606011; train accuracy : 0.9903807428978593; \n",
      " validation loss : 0.5894650727852512; validation accuracy : 0.9623430962343096\n",
      "Epoch 120:\t train loss : 0.5597153142750225; train accuracy : 0.9916295424269649; \n",
      " validation loss : 0.5788284010525669; validation accuracy : 0.9748953974895398\n",
      "Epoch 121:\t train loss : 0.5593008656844217; train accuracy : 0.9919799250286564; \n",
      " validation loss : 0.6116236920288699; validation accuracy : 0.9372384937238494\n",
      "Epoch 122:\t train loss : 0.5573026228600865; train accuracy : 0.994067350289662; \n",
      " validation loss : 0.6121681076566485; validation accuracy : 0.9372384937238494\n",
      "Epoch 123:\t train loss : 0.5567909814473562; train accuracy : 0.9945630285944422; \n",
      " validation loss : 0.5888884309632212; validation accuracy : 0.9623430962343096\n",
      "Epoch 124:\t train loss : 0.5619738136004357; train accuracy : 0.9892846742464141; \n",
      " validation loss : 0.6060899870448511; validation accuracy : 0.9372384937238494\n",
      "Epoch 125:\t train loss : 0.5629720191678789; train accuracy : 0.9883205799436166; \n",
      " validation loss : 0.5963058526264667; validation accuracy : 0.9539748953974896\n",
      "Epoch 126:\t train loss : 0.5635325361405464; train accuracy : 0.9876176461476501; \n",
      " validation loss : 0.5949080792373924; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.5591235021277062; train accuracy : 0.9921311069116143; \n",
      " validation loss : 0.5988997947098482; validation accuracy : 0.9497907949790795\n",
      "Epoch 128:\t train loss : 0.5624371101403537; train accuracy : 0.9888007683013724; \n",
      " validation loss : 0.592722976183796; validation accuracy : 0.9581589958158996\n",
      "Epoch 129:\t train loss : 0.5576403422981492; train accuracy : 0.9936838192013383; \n",
      " validation loss : 0.5807106676625124; validation accuracy : 0.9665271966527197\n",
      "Early stopping at epoch 129\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5633754529025282; Train accuracy : 0.9879798011090802; \n",
      " Validation loss : 0.5693333764726894; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 36 ! ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t train loss : 0.9504168382212476; train accuracy : 0.5721187149539949; \n",
      " validation loss : 0.8448481431388621; validation accuracy : 0.698744769874477\n",
      "Epoch 2:\t train loss : 0.7722138717086128; train accuracy : 0.7759131323770873; \n",
      " validation loss : 0.7996485634792355; validation accuracy : 0.7322175732217573\n",
      "Epoch 3:\t train loss : 0.7217968991301642; train accuracy : 0.8275823290684345; \n",
      " validation loss : 0.7468040917286999; validation accuracy : 0.8158995815899581\n",
      "Epoch 4:\t train loss : 0.6897684159550004; train accuracy : 0.8605486539236036; \n",
      " validation loss : 0.7370588695680418; validation accuracy : 0.8158995815899581\n",
      "Epoch 5:\t train loss : 0.6655636227815884; train accuracy : 0.8848759255243347; \n",
      " validation loss : 0.7239325949128523; validation accuracy : 0.8326359832635983\n",
      "Epoch 6:\t train loss : 0.6478422152734605; train accuracy : 0.9029083924532978; \n",
      " validation loss : 0.6876284862937487; validation accuracy : 0.8619246861924686\n",
      "Epoch 7:\t train loss : 0.6420838129916953; train accuracy : 0.9086669351590818; \n",
      " validation loss : 0.7034671752800521; validation accuracy : 0.8451882845188284\n",
      "Epoch 8:\t train loss : 0.6393658356553648; train accuracy : 0.9115208029988537; \n",
      " validation loss : 0.6764510116536325; validation accuracy : 0.8702928870292888\n",
      "Epoch 9:\t train loss : 0.6261615269500662; train accuracy : 0.924367855261935; \n",
      " validation loss : 0.690675900434445; validation accuracy : 0.8619246861924686\n",
      "Epoch 10:\t train loss : 0.6130928626591239; train accuracy : 0.937772545617894; \n",
      " validation loss : 0.6561214876247692; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.6063955961447617; train accuracy : 0.9442842095480033; \n",
      " validation loss : 0.6969615560727564; validation accuracy : 0.8493723849372385\n",
      "Epoch 12:\t train loss : 0.5970349455375524; train accuracy : 0.9541320982682239; \n",
      " validation loss : 0.6820997275154856; validation accuracy : 0.8535564853556485\n",
      "Epoch 13:\t train loss : 0.589276317451459; train accuracy : 0.9621153071656495; \n",
      " validation loss : 0.6773099348159195; validation accuracy : 0.8786610878661087\n",
      "Epoch 14:\t train loss : 0.588226505453072; train accuracy : 0.9631841135103317; \n",
      " validation loss : 0.6589833006866431; validation accuracy : 0.8870292887029289\n",
      "Epoch 15:\t train loss : 0.5912254557355606; train accuracy : 0.9601325939465287; \n",
      " validation loss : 0.647373218221878; validation accuracy : 0.899581589958159\n",
      "Epoch 16:\t train loss : 0.5937798534739862; train accuracy : 0.9573134235880914; \n",
      " validation loss : 0.6624839635583748; validation accuracy : 0.8870292887029289\n",
      "Epoch 17:\t train loss : 0.5921504464598438; train accuracy : 0.958933981845782; \n",
      " validation loss : 0.6624699955880915; validation accuracy : 0.8828451882845189\n",
      "Epoch 18:\t train loss : 0.5830936319991411; train accuracy : 0.9681991387589455; \n",
      " validation loss : 0.6758490583198596; validation accuracy : 0.8661087866108786\n",
      "Epoch 19:\t train loss : 0.5809714262242608; train accuracy : 0.970189287152638; \n",
      " validation loss : 0.6296482458627793; validation accuracy : 0.9246861924686193\n",
      "Epoch 20:\t train loss : 0.5851097971986192; train accuracy : 0.9659509278478268; \n",
      " validation loss : 0.6726468431803546; validation accuracy : 0.8786610878661087\n",
      "Epoch 21:\t train loss : 0.5789868907926339; train accuracy : 0.9724065181697078; \n",
      " validation loss : 0.6442993664473985; validation accuracy : 0.9079497907949791\n",
      "Epoch 22:\t train loss : 0.5745193652572114; train accuracy : 0.9767009510827473; \n",
      " validation loss : 0.6784746616199611; validation accuracy : 0.8744769874476988\n",
      "Epoch 23:\t train loss : 0.5766833009061593; train accuracy : 0.974730010223365; \n",
      " validation loss : 0.6388838178559723; validation accuracy : 0.9121338912133892\n",
      "Epoch 24:\t train loss : 0.5751542338135314; train accuracy : 0.9763660584280802; \n",
      " validation loss : 0.6437561520569622; validation accuracy : 0.9037656903765691\n",
      "Epoch 25:\t train loss : 0.5725514313270044; train accuracy : 0.9786083831593296; \n",
      " validation loss : 0.6478094896868872; validation accuracy : 0.9037656903765691\n",
      "Epoch 26:\t train loss : 0.5718184940524398; train accuracy : 0.9795842498218656; \n",
      " validation loss : 0.6279241367054613; validation accuracy : 0.9246861924686193\n",
      "Epoch 27:\t train loss : 0.573116337684627; train accuracy : 0.978023482759689; \n",
      " validation loss : 0.6755555104376161; validation accuracy : 0.8744769874476988\n",
      "Epoch 28:\t train loss : 0.5762152667520454; train accuracy : 0.9746717680225534; \n",
      " validation loss : 0.6405669866627297; validation accuracy : 0.9037656903765691\n",
      "Epoch 29:\t train loss : 0.5780228899313086; train accuracy : 0.9732002230552371; \n",
      " validation loss : 0.6353376028561631; validation accuracy : 0.9163179916317992\n",
      "Epoch 30:\t train loss : 0.5737725458340522; train accuracy : 0.9776052541900306; \n",
      " validation loss : 0.6286188984877352; validation accuracy : 0.9205020920502092\n",
      "Epoch 31:\t train loss : 0.5695462555838936; train accuracy : 0.9817934260664829; \n",
      " validation loss : 0.6283981654138973; validation accuracy : 0.9205020920502092\n",
      "Epoch 32:\t train loss : 0.5733271218363137; train accuracy : 0.9777970197341925; \n",
      " validation loss : 0.6171474545291363; validation accuracy : 0.9330543933054394\n",
      "Epoch 33:\t train loss : 0.5747740825290509; train accuracy : 0.9765209578983239; \n",
      " validation loss : 0.6601712401333085; validation accuracy : 0.8870292887029289\n",
      "Epoch 34:\t train loss : 0.5729845682302052; train accuracy : 0.9781223086217045; \n",
      " validation loss : 0.6176274191267082; validation accuracy : 0.9288702928870293\n",
      "Epoch 35:\t train loss : 0.5703988146571485; train accuracy : 0.9806412838068094; \n",
      " validation loss : 0.644832635778598; validation accuracy : 0.9079497907949791\n",
      "Epoch 36:\t train loss : 0.5731251054253936; train accuracy : 0.9778029059140618; \n",
      " validation loss : 0.6676530584246241; validation accuracy : 0.8870292887029289\n",
      "Epoch 37:\t train loss : 0.5681332713213824; train accuracy : 0.9830171318814089; \n",
      " validation loss : 0.6455508949147278; validation accuracy : 0.899581589958159\n",
      "Epoch 38:\t train loss : 0.5671345544798069; train accuracy : 0.9841073143529849; \n",
      " validation loss : 0.6253257489290962; validation accuracy : 0.9246861924686193\n",
      "Epoch 39:\t train loss : 0.569694408721005; train accuracy : 0.981601660522321; \n",
      " validation loss : 0.6327350509025704; validation accuracy : 0.9163179916317992\n",
      "Epoch 40:\t train loss : 0.5680109913679777; train accuracy : 0.9832649710337991; \n",
      " validation loss : 0.6123391085085824; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5665802461034807; train accuracy : 0.9846222001920754; \n",
      " validation loss : 0.6493338527999979; validation accuracy : 0.899581589958159\n",
      "Epoch 42:\t train loss : 0.568580372356996; train accuracy : 0.9825892995445955; \n",
      " validation loss : 0.6381877631522949; validation accuracy : 0.9121338912133892\n",
      "Epoch 43:\t train loss : 0.566993917006313; train accuracy : 0.9842755351776697; \n",
      " validation loss : 0.6155414892322425; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5659871899480671; train accuracy : 0.9850367111744478; \n",
      " validation loss : 0.6655203933993782; validation accuracy : 0.8828451882845189\n",
      "Epoch 45:\t train loss : 0.5649755796051242; train accuracy : 0.9861770810743827; \n",
      " validation loss : 0.6080892924568071; validation accuracy : 0.9456066945606695\n",
      "Epoch 46:\t train loss : 0.5684000111272365; train accuracy : 0.9828777223581895; \n",
      " validation loss : 0.6342979867962345; validation accuracy : 0.9163179916317992\n",
      "Epoch 47:\t train loss : 0.5658552966322737; train accuracy : 0.9853620000619598; \n",
      " validation loss : 0.6299881964663078; validation accuracy : 0.9163179916317992\n",
      "Epoch 48:\t train loss : 0.569110392473022; train accuracy : 0.981963815483751; \n",
      " validation loss : 0.6728720643040769; validation accuracy : 0.8702928870292888\n",
      "Epoch 49:\t train loss : 0.5810203843290401; train accuracy : 0.9698042070696118; \n",
      " validation loss : 0.616145910314975; validation accuracy : 0.9330543933054394\n",
      "Epoch 50:\t train loss : 0.5655706881122936; train accuracy : 0.9858112085256668; \n",
      " validation loss : 0.645158573024641; validation accuracy : 0.9037656903765691\n",
      "Epoch 51:\t train loss : 0.5653920770738796; train accuracy : 0.9858731683137644; \n",
      " validation loss : 0.6255743752297644; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:\t train loss : 0.5628482767276828; train accuracy : 0.9885684190960067; \n",
      " validation loss : 0.6082372841814145; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.573580209695979; train accuracy : 0.9772062331546826; \n",
      " validation loss : 0.6407596884161786; validation accuracy : 0.9121338912133892\n",
      "Epoch 54:\t train loss : 0.5671528401694965; train accuracy : 0.9841382942470337; \n",
      " validation loss : 0.6490964700192058; validation accuracy : 0.9037656903765691\n",
      "Epoch 55:\t train loss : 0.5646083871644373; train accuracy : 0.9865798196970167; \n",
      " validation loss : 0.6520371697857541; validation accuracy : 0.895397489539749\n",
      "Epoch 56:\t train loss : 0.563466320453854; train accuracy : 0.987772545617894; \n",
      " validation loss : 0.6291732053603807; validation accuracy : 0.9246861924686193\n",
      "Epoch 57:\t train loss : 0.5643823209734392; train accuracy : 0.9868586387434555; \n",
      " validation loss : 0.6265865449853162; validation accuracy : 0.9246861924686193\n",
      "Epoch 58:\t train loss : 0.5620893058468056; train accuracy : 0.9892499767650794; \n",
      " validation loss : 0.6208892640105943; validation accuracy : 0.9288702928870293\n",
      "Epoch 59:\t train loss : 0.5620470797903542; train accuracy : 0.989275070479259; \n",
      " validation loss : 0.6192900430786358; validation accuracy : 0.9330543933054394\n",
      "Epoch 60:\t train loss : 0.560427156639687; train accuracy : 0.9907156355525264; \n",
      " validation loss : 0.611296572606315; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5685818945382132; train accuracy : 0.9826453731528239; \n",
      " validation loss : 0.6575645359810115; validation accuracy : 0.891213389121339\n",
      "Epoch 62:\t train loss : 0.5648075522561623; train accuracy : 0.9863223767774714; \n",
      " validation loss : 0.6145020825311944; validation accuracy : 0.9330543933054394\n",
      "Epoch 63:\t train loss : 0.5605817017992596; train accuracy : 0.9906440719972738; \n",
      " validation loss : 0.6210284998168717; validation accuracy : 0.9288702928870293\n",
      "Epoch 64:\t train loss : 0.5597946513457104; train accuracy : 0.991552092691843; \n",
      " validation loss : 0.6174765298653451; validation accuracy : 0.9330543933054394\n",
      "Epoch 65:\t train loss : 0.561703877125564; train accuracy : 0.9895538895256978; \n",
      " validation loss : 0.6539299666729845; validation accuracy : 0.899581589958159\n",
      "Epoch 66:\t train loss : 0.5602409186363757; train accuracy : 0.9910697357415038; \n",
      " validation loss : 0.6481249100547554; validation accuracy : 0.9037656903765691\n",
      "Epoch 67:\t train loss : 0.5618092738188594; train accuracy : 0.9894609498435515; \n",
      " validation loss : 0.6482898379002078; validation accuracy : 0.899581589958159\n",
      "Epoch 68:\t train loss : 0.5658122604016993; train accuracy : 0.9854121874903188; \n",
      " validation loss : 0.6089797615945259; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5611463975543982; train accuracy : 0.990039964063323; \n",
      " validation loss : 0.6225008535780198; validation accuracy : 0.9288702928870293\n",
      "Epoch 70:\t train loss : 0.5627684520938786; train accuracy : 0.9884444995198116; \n",
      " validation loss : 0.644447958579961; validation accuracy : 0.9037656903765691\n",
      "Epoch 71:\t train loss : 0.5638408489574482; train accuracy : 0.9874627466774064; \n",
      " validation loss : 0.6289738856772821; validation accuracy : 0.9246861924686193\n",
      "Epoch 72:\t train loss : 0.5656094321246078; train accuracy : 0.9856851203568884; \n",
      " validation loss : 0.6257507042828013; validation accuracy : 0.9246861924686193\n",
      "Epoch 73:\t train loss : 0.5619855281049334; train accuracy : 0.9892189968710307; \n",
      " validation loss : 0.6243297601257147; validation accuracy : 0.9246861924686193\n",
      "Epoch 74:\t train loss : 0.5638454540761362; train accuracy : 0.9874413705505127; \n",
      " validation loss : 0.6238676364026604; validation accuracy : 0.9288702928870293\n",
      "Epoch 75:\t train loss : 0.5580169091666263; train accuracy : 0.9933644164936956; \n",
      " validation loss : 0.6142619092386491; validation accuracy : 0.9372384937238494\n",
      "Epoch 76:\t train loss : 0.5608716812567909; train accuracy : 0.9903844604851452; \n",
      " validation loss : 0.6362514010949298; validation accuracy : 0.9163179916317992\n",
      "Epoch 77:\t train loss : 0.5590946329228165; train accuracy : 0.9923479661699557; \n",
      " validation loss : 0.6125745700938793; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5602743547216429; train accuracy : 0.9910099445459897; \n",
      " validation loss : 0.6454945710862406; validation accuracy : 0.9037656903765691\n",
      "Epoch 79:\t train loss : 0.5642676590219705; train accuracy : 0.9869264847114223; \n",
      " validation loss : 0.6189048994971372; validation accuracy : 0.9330543933054394\n",
      "Epoch 80:\t train loss : 0.5630325413853011; train accuracy : 0.9881693980606586; \n",
      " validation loss : 0.6240888435574432; validation accuracy : 0.9246861924686193\n",
      "Epoch 81:\t train loss : 0.5628378104141807; train accuracy : 0.9884032962607268; \n",
      " validation loss : 0.621020479315022; validation accuracy : 0.9288702928870293\n",
      "Epoch 82:\t train loss : 0.5685572704202216; train accuracy : 0.982728709067815; \n",
      " validation loss : 0.6283169068349097; validation accuracy : 0.9246861924686193\n",
      "Epoch 83:\t train loss : 0.5606501671556284; train accuracy : 0.9906691657114532; \n",
      " validation loss : 0.6578044104174516; validation accuracy : 0.891213389121339\n",
      "Epoch 84:\t train loss : 0.5599204045084694; train accuracy : 0.991263669878249; \n",
      " validation loss : 0.601918684290893; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5599222458447021; train accuracy : 0.991313857306608; \n",
      " validation loss : 0.5885657267142931; validation accuracy : 0.9623430962343096\n",
      "Epoch 86:\t train loss : 0.5589842229218526; train accuracy : 0.9923944360110288; \n",
      " validation loss : 0.6034380848263706; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.560566699153205; train accuracy : 0.9907215217323957; \n",
      " validation loss : 0.6077240677737786; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5708249128389569; train accuracy : 0.9803742371201091; \n",
      " validation loss : 0.6581973343132832; validation accuracy : 0.891213389121339\n",
      "Epoch 89:\t train loss : 0.5655581048737859; train accuracy : 0.9856408191083986; \n",
      " validation loss : 0.6121279746602241; validation accuracy : 0.9372384937238494\n",
      "Epoch 90:\t train loss : 0.5584437584613171; train accuracy : 0.9929056042628334; \n",
      " validation loss : 0.6168280281269645; validation accuracy : 0.9372384937238494\n",
      "Epoch 91:\t train loss : 0.5618071238050304; train accuracy : 0.9894432913039437; \n",
      " validation loss : 0.6611043153386146; validation accuracy : 0.891213389121339\n",
      "Epoch 92:\t train loss : 0.5629815580003281; train accuracy : 0.9882837138696986; \n",
      " validation loss : 0.631445892579675; validation accuracy : 0.9205020920502092\n",
      "Epoch 93:\t train loss : 0.5610858257876005; train accuracy : 0.9900960376715512; \n",
      " validation loss : 0.6111458417532817; validation accuracy : 0.9372384937238494\n",
      "Epoch 94:\t train loss : 0.560378658972139; train accuracy : 0.9909538709377614; \n",
      " validation loss : 0.6071717171614671; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5572620979788583; train accuracy : 0.9941293100777595; \n",
      " validation loss : 0.634170583584002; validation accuracy : 0.9163179916317992\n",
      "Epoch 96:\t train loss : 0.5564114538834596; train accuracy : 0.9949812571641005; \n",
      " validation loss : 0.6158532252944754; validation accuracy : 0.9330543933054394\n",
      "Epoch 97:\t train loss : 0.5565432568897668; train accuracy : 0.9948145853341182; \n",
      " validation loss : 0.666633845135782; validation accuracy : 0.8828451882845189\n",
      "Epoch 98:\t train loss : 0.5609128740755545; train accuracy : 0.9902974069828682; \n",
      " validation loss : 0.6384392815043315; validation accuracy : 0.9121338912133892\n",
      "Epoch 99:\t train loss : 0.5610535498687546; train accuracy : 0.9900554540103473; \n",
      " validation loss : 0.6431647860335699; validation accuracy : 0.9037656903765691\n",
      "Epoch 100:\t train loss : 0.557694886983189; train accuracy : 0.9936646116670281; \n",
      " validation loss : 0.6154576281126215; validation accuracy : 0.9372384937238494\n",
      "Epoch 101:\t train loss : 0.57561247098685; train accuracy : 0.9753666470460671; \n",
      " validation loss : 0.6433453472755846; validation accuracy : 0.9079497907949791\n",
      "Epoch 102:\t train loss : 0.5742569333116857; train accuracy : 0.9767437033365346; \n",
      " validation loss : 0.6316651750310904; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103:\t train loss : 0.5671220070350672; train accuracy : 0.9840859382260913; \n",
      " validation loss : 0.6143345187810311; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.5639223757136554; train accuracy : 0.9872554911862201; \n",
      " validation loss : 0.6167345692597425; validation accuracy : 0.9330543933054394\n",
      "Epoch 105:\t train loss : 0.5609940194695731; train accuracy : 0.9902258434276154; \n",
      " validation loss : 0.5980157806624803; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5595576502698351; train accuracy : 0.991790328077078; \n",
      " validation loss : 0.6183854615929726; validation accuracy : 0.9330543933054394\n",
      "Epoch 107:\t train loss : 0.5584136449347609; train accuracy : 0.9928606834164627; \n",
      " validation loss : 0.6430468945974829; validation accuracy : 0.9079497907949791\n",
      "Epoch 108:\t train loss : 0.5611528526919181; train accuracy : 0.9901948635335667; \n",
      " validation loss : 0.6548528105893598; validation accuracy : 0.895397489539749\n",
      "Epoch 109:\t train loss : 0.5621105841777823; train accuracy : 0.9890891911149664; \n",
      " validation loss : 0.6181305953926093; validation accuracy : 0.9330543933054394\n",
      "Epoch 110:\t train loss : 0.5602566202445711; train accuracy : 0.9909228910437127; \n",
      " validation loss : 0.6136920197054329; validation accuracy : 0.9372384937238494\n",
      "Epoch 111:\t train loss : 0.5579454735095347; train accuracy : 0.9934263762817931; \n",
      " validation loss : 0.609375126642906; validation accuracy : 0.9414225941422594\n",
      "Epoch 112:\t train loss : 0.5551514431911746; train accuracy : 0.9961739830849778; \n",
      " validation loss : 0.6035352850447447; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5579101707643942; train accuracy : 0.9934012825676136; \n",
      " validation loss : 0.6064675601705958; validation accuracy : 0.9456066945606695\n",
      "Epoch 114:\t train loss : 0.558173248887998; train accuracy : 0.9931379534681991; \n",
      " validation loss : 0.6120432863551208; validation accuracy : 0.9372384937238494\n",
      "Epoch 115:\t train loss : 0.560118505864842; train accuracy : 0.9911434678893398; \n",
      " validation loss : 0.6023726328801489; validation accuracy : 0.9497907949790795\n",
      "Epoch 116:\t train loss : 0.5606148574044892; train accuracy : 0.9906440719972738; \n",
      " validation loss : 0.6394727185987797; validation accuracy : 0.9121338912133892\n",
      "Epoch 117:\t train loss : 0.5579362131055964; train accuracy : 0.9934263762817931; \n",
      " validation loss : 0.6211165992233417; validation accuracy : 0.9288702928870293\n",
      "Epoch 118:\t train loss : 0.5584382652528777; train accuracy : 0.9928436444747359; \n",
      " validation loss : 0.6058389598664652; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5568487480847746; train accuracy : 0.9945320487003935; \n",
      " validation loss : 0.6291299361436943; validation accuracy : 0.9205020920502092\n",
      "Epoch 120:\t train loss : 0.5640575775962929; train accuracy : 0.9873137333870318; \n",
      " validation loss : 0.6138595315705894; validation accuracy : 0.9372384937238494\n",
      "Epoch 121:\t train loss : 0.5574521064827761; train accuracy : 0.9939220545865733; \n",
      " validation loss : 0.6122490170407224; validation accuracy : 0.9372384937238494\n",
      "Epoch 122:\t train loss : 0.5570256404494013; train accuracy : 0.9942628334211097; \n",
      " validation loss : 0.6260973465342096; validation accuracy : 0.9246861924686193\n",
      "Epoch 123:\t train loss : 0.5588695313075701; train accuracy : 0.9922956101490132; \n",
      " validation loss : 0.60443930046319; validation accuracy : 0.9456066945606695\n",
      "Epoch 124:\t train loss : 0.5592052475756158; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.6383000469811976; validation accuracy : 0.9121338912133892\n",
      "Epoch 125:\t train loss : 0.5639162136873576; train accuracy : 0.987323337154187; \n",
      " validation loss : 0.6377682028946469; validation accuracy : 0.9121338912133892\n",
      "Epoch 126:\t train loss : 0.5612574813639233; train accuracy : 0.9899780042752254; \n",
      " validation loss : 0.644790140064582; validation accuracy : 0.9079497907949791\n",
      "Epoch 127:\t train loss : 0.5564568506905444; train accuracy : 0.9948728275349298; \n",
      " validation loss : 0.6181328905666247; validation accuracy : 0.9330543933054394\n",
      "Epoch 128:\t train loss : 0.557182079633689; train accuracy : 0.9941293100777595; \n",
      " validation loss : 0.6062814191566944; validation accuracy : 0.9456066945606695\n",
      "Epoch 129:\t train loss : 0.5559979503948481; train accuracy : 0.9954282970352242; \n",
      " validation loss : 0.5936760868276416; validation accuracy : 0.9581589958158996\n",
      "Epoch 130:\t train loss : 0.5562020806215253; train accuracy : 0.9952018340097277; \n",
      " validation loss : 0.6232326572313139; validation accuracy : 0.9288702928870293\n",
      "Epoch 131:\t train loss : 0.557889534736027; train accuracy : 0.9933953963877443; \n",
      " validation loss : 0.6324259105611952; validation accuracy : 0.9163179916317992\n",
      "Epoch 132:\t train loss : 0.5579746999038636; train accuracy : 0.993343040366802; \n",
      " validation loss : 0.6126871888195657; validation accuracy : 0.9372384937238494\n",
      "Epoch 133:\t train loss : 0.5573535114982313; train accuracy : 0.994030484215744; \n",
      " validation loss : 0.6411644677273568; validation accuracy : 0.9121338912133892\n",
      "Epoch 134:\t train loss : 0.5591099065060087; train accuracy : 0.9921156169645899; \n",
      " validation loss : 0.6107597494937466; validation accuracy : 0.9414225941422594\n",
      "Epoch 135:\t train loss : 0.5552059922929958; train accuracy : 0.9961835868521329; \n",
      " validation loss : 0.5940641980678226; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 135\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5599222458447021; Train accuracy : 0.991313857306608; \n",
      " Validation loss : 0.5885657267142931; Validation accuracy : 0.9623430962343096\n",
      "--- Let's train model 37 ! ---\n",
      "Epoch 1:\t train loss : 0.932742075957472; train accuracy : 0.5943127110505282; \n",
      " validation loss : 0.8204368700371568; validation accuracy : 0.7071129707112971\n",
      "Epoch 2:\t train loss : 0.7564622155414429; train accuracy : 0.792803060813532; \n",
      " validation loss : 0.8114592219167568; validation accuracy : 0.7364016736401674\n",
      "Epoch 3:\t train loss : 0.7199527649883235; train accuracy : 0.8304693453948387; \n",
      " validation loss : 0.7375090219501931; validation accuracy : 0.8075313807531381\n",
      "Epoch 4:\t train loss : 0.6949885066883803; train accuracy : 0.8548985408469904; \n",
      " validation loss : 0.7087606759472529; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.6810064850046972; train accuracy : 0.8690083335914991; \n",
      " validation loss : 0.7031396063621959; validation accuracy : 0.8451882845188284\n",
      "Epoch 6:\t train loss : 0.6567788285633392; train accuracy : 0.8935001084296291; \n",
      " validation loss : 0.6851504496077274; validation accuracy : 0.8744769874476988\n",
      "Epoch 7:\t train loss : 0.640723776833242; train accuracy : 0.9095278664146969; \n",
      " validation loss : 0.6652855400454136; validation accuracy : 0.891213389121339\n",
      "Epoch 8:\t train loss : 0.626905487834614; train accuracy : 0.9239843241736113; \n",
      " validation loss : 0.6665780227980014; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6137122207289244; train accuracy : 0.9377297933641067; \n",
      " validation loss : 0.6677272776354555; validation accuracy : 0.8786610878661087\n",
      "Epoch 10:\t train loss : 0.6151199676842468; train accuracy : 0.936081972799653; \n",
      " validation loss : 0.6255244659287866; validation accuracy : 0.9288702928870293\n",
      "Epoch 11:\t train loss : 0.6056690326636641; train accuracy : 0.9460537810960686; \n",
      " validation loss : 0.6497288164149264; validation accuracy : 0.9037656903765691\n",
      "Epoch 12:\t train loss : 0.6012365965496945; train accuracy : 0.9501062610365872; \n",
      " validation loss : 0.6449770391543357; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.5973035910930689; train accuracy : 0.9542848291458843; \n",
      " validation loss : 0.6319035139616707; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5901374507387697; train accuracy : 0.9607345332878962; \n",
      " validation loss : 0.6212887666669143; validation accuracy : 0.9330543933054394\n",
      "Epoch 15:\t train loss : 0.5892110196668251; train accuracy : 0.9620725549118622; \n",
      " validation loss : 0.6166766452903972; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5843350064990591; train accuracy : 0.9672211035038261; \n",
      " validation loss : 0.6390143515651233; validation accuracy : 0.9037656903765691\n",
      "Epoch 17:\t train loss : 0.5826262388686079; train accuracy : 0.9688940177824592; \n",
      " validation loss : 0.6158938380069655; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:\t train loss : 0.5877144346034618; train accuracy : 0.9634548777843179; \n",
      " validation loss : 0.6284823213530147; validation accuracy : 0.9121338912133892\n",
      "Epoch 19:\t train loss : 0.5826101658119339; train accuracy : 0.9688571517085411; \n",
      " validation loss : 0.6329390373196526; validation accuracy : 0.9163179916317992\n",
      "Epoch 20:\t train loss : 0.5913061543677797; train accuracy : 0.9599696397038322; \n",
      " validation loss : 0.6160742448556813; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5839788389403334; train accuracy : 0.9674807150159547; \n",
      " validation loss : 0.6378676626750461; validation accuracy : 0.9121338912133892\n",
      "Epoch 22:\t train loss : 0.5821249203471008; train accuracy : 0.9692347966169955; \n",
      " validation loss : 0.6086305745038775; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.5788750318935457; train accuracy : 0.9723129588896806; \n",
      " validation loss : 0.6308698220518852; validation accuracy : 0.9121338912133892\n",
      "Epoch 24:\t train loss : 0.5788463231130468; train accuracy : 0.9723231822547167; \n",
      " validation loss : 0.61683493898479; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5801154311479833; train accuracy : 0.9710898726726355; \n",
      " validation loss : 0.6196381801052014; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5803969697521142; train accuracy : 0.9706598717432386; \n",
      " validation loss : 0.6161459094975633; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5770084763205349; train accuracy : 0.9744202112828774; \n",
      " validation loss : 0.6169087940373059; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.572373144032343; train accuracy : 0.9789528795811518; \n",
      " validation loss : 0.6137447385975408; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.5766754912679757; train accuracy : 0.9745168685523096; \n",
      " validation loss : 0.6585396020264059; validation accuracy : 0.8870292887029289\n",
      "Epoch 30:\t train loss : 0.582285224748478; train accuracy : 0.9686173673286037; \n",
      " validation loss : 0.638907097831768; validation accuracy : 0.9121338912133892\n",
      "Epoch 31:\t train loss : 0.593567184502564; train accuracy : 0.9570383221289384; \n",
      " validation loss : 0.6219528663043106; validation accuracy : 0.9288702928870293\n",
      "Epoch 32:\t train loss : 0.5724293299344299; train accuracy : 0.9788918491898758; \n",
      " validation loss : 0.6511147820132378; validation accuracy : 0.895397489539749\n",
      "Epoch 33:\t train loss : 0.5746746828507003; train accuracy : 0.9764531119303572; \n",
      " validation loss : 0.6235631785635828; validation accuracy : 0.9205020920502092\n",
      "Epoch 34:\t train loss : 0.5707580708763799; train accuracy : 0.9804089346014436; \n",
      " validation loss : 0.598713738868944; validation accuracy : 0.9539748953974896\n",
      "Epoch 35:\t train loss : 0.5685134803908626; train accuracy : 0.9828312525171163; \n",
      " validation loss : 0.6058979529324939; validation accuracy : 0.9456066945606695\n",
      "Epoch 36:\t train loss : 0.5686726134762672; train accuracy : 0.9825989033117507; \n",
      " validation loss : 0.6065382333425476; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.5765283104402842; train accuracy : 0.9745227547321789; \n",
      " validation loss : 0.6080644864274967; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5736705693688391; train accuracy : 0.9776827039251526; \n",
      " validation loss : 0.6297964403852911; validation accuracy : 0.9163179916317992\n",
      "Epoch 39:\t train loss : 0.5699059484923624; train accuracy : 0.9813346138356207; \n",
      " validation loss : 0.6062723345981778; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.5785311625779964; train accuracy : 0.9723888596301; \n",
      " validation loss : 0.6109335852238288; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5718439328127972; train accuracy : 0.9791970011462561; \n",
      " validation loss : 0.6105043325192278; validation accuracy : 0.9372384937238494\n",
      "Epoch 42:\t train loss : 0.569516532745913; train accuracy : 0.9816849964373122; \n",
      " validation loss : 0.6215775368659937; validation accuracy : 0.9288702928870293\n",
      "Epoch 43:\t train loss : 0.5695476675145971; train accuracy : 0.9815102698348772; \n",
      " validation loss : 0.6031027039672218; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5670045979470972; train accuracy : 0.9841516156014747; \n",
      " validation loss : 0.5930920794235981; validation accuracy : 0.9623430962343096\n",
      "Epoch 45:\t train loss : 0.5660665833601378; train accuracy : 0.9851857244648223; \n",
      " validation loss : 0.5975043718542736; validation accuracy : 0.9581589958158996\n",
      "Epoch 46:\t train loss : 0.5653837444252339; train accuracy : 0.9857433625577; \n",
      " validation loss : 0.6191109097759994; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.5648696732221792; train accuracy : 0.9865392360358127; \n",
      " validation loss : 0.6049401448074854; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5719463400330221; train accuracy : 0.9790303293162738; \n",
      " validation loss : 0.6171812706930844; validation accuracy : 0.9330543933054394\n",
      "Epoch 49:\t train loss : 0.5674772801340339; train accuracy : 0.9836869171907432; \n",
      " validation loss : 0.6234610649594351; validation accuracy : 0.9246861924686193\n",
      "Epoch 50:\t train loss : 0.5682262741702754; train accuracy : 0.9827671241364354; \n",
      " validation loss : 0.6153084716400938; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.5693115564326044; train accuracy : 0.9819247808172497; \n",
      " validation loss : 0.6212295663876077; validation accuracy : 0.9288702928870293\n",
      "Epoch 52:\t train loss : 0.5668452658376866; train accuracy : 0.9843027974844326; \n",
      " validation loss : 0.5886762403562722; validation accuracy : 0.9665271966527197\n",
      "Epoch 53:\t train loss : 0.5622772177867441; train accuracy : 0.9889129155178289; \n",
      " validation loss : 0.5943035363324395; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.5671466952378008; train accuracy : 0.983992998543945; \n",
      " validation loss : 0.6292814446519598; validation accuracy : 0.9205020920502092\n",
      "Epoch 55:\t train loss : 0.5683336023694253; train accuracy : 0.9829375135537036; \n",
      " validation loss : 0.6211331595645576; validation accuracy : 0.9288702928870293\n",
      "Epoch 56:\t train loss : 0.5661328375123589; train accuracy : 0.9849976765079463; \n",
      " validation loss : 0.6051492105708579; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5636269682832438; train accuracy : 0.987695095882772; \n",
      " validation loss : 0.5927475428326601; validation accuracy : 0.9581589958158996\n",
      "Epoch 58:\t train loss : 0.5624414970731345; train accuracy : 0.9888317481954212; \n",
      " validation loss : 0.604663121904115; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5644344409953425; train accuracy : 0.9868431487964311; \n",
      " validation loss : 0.6179332033456053; validation accuracy : 0.9288702928870293\n",
      "Epoch 60:\t train loss : 0.5623615284673037; train accuracy : 0.9890213451469996; \n",
      " validation loss : 0.604540165527573; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5709311241561391; train accuracy : 0.9800061959788098; \n",
      " validation loss : 0.6119652344010783; validation accuracy : 0.9372384937238494\n",
      "Epoch 62:\t train loss : 0.5617383639738119; train accuracy : 0.9897029028160723; \n",
      " validation loss : 0.6273658988115182; validation accuracy : 0.9246861924686193\n",
      "Epoch 63:\t train loss : 0.5631253265956514; train accuracy : 0.9881443043464792; \n",
      " validation loss : 0.5960655933512977; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5626768514898868; train accuracy : 0.9883921434988693; \n",
      " validation loss : 0.5952296822144133; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.5636900338054739; train accuracy : 0.9875962700207566; \n",
      " validation loss : 0.5987585267066422; validation accuracy : 0.9539748953974896\n",
      "Epoch 66:\t train loss : 0.5606337064369544; train accuracy : 0.9906168096905108; \n",
      " validation loss : 0.5867670927490293; validation accuracy : 0.9665271966527197\n",
      "Epoch 67:\t train loss : 0.5604311446914215; train accuracy : 0.9908550450757458; \n",
      " validation loss : 0.5966093715171406; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5623722283204527; train accuracy : 0.9888082034759441; \n",
      " validation loss : 0.6153457907182495; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:\t train loss : 0.5736823504768531; train accuracy : 0.9772121193345519; \n",
      " validation loss : 0.6488106083994062; validation accuracy : 0.9037656903765691\n",
      "Epoch 70:\t train loss : 0.5636589245037527; train accuracy : 0.9877415657238452; \n",
      " validation loss : 0.6027621823535934; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5628006497960399; train accuracy : 0.988510176895195; \n",
      " validation loss : 0.6094514634156888; validation accuracy : 0.9414225941422594\n",
      "Epoch 72:\t train loss : 0.5642677028845506; train accuracy : 0.9868276588494067; \n",
      " validation loss : 0.6089373090323393; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5674594281403431; train accuracy : 0.9836212398153599; \n",
      " validation loss : 0.6381071571320155; validation accuracy : 0.9121338912133892\n",
      "Epoch 74:\t train loss : 0.5671421006961913; train accuracy : 0.9840586759193284; \n",
      " validation loss : 0.6256386133776067; validation accuracy : 0.9246861924686193\n",
      "Epoch 75:\t train loss : 0.5636530442915243; train accuracy : 0.9876176461476501; \n",
      " validation loss : 0.6028244028146958; validation accuracy : 0.9497907949790795\n",
      "Epoch 76:\t train loss : 0.5607193256751327; train accuracy : 0.990700145605502; \n",
      " validation loss : 0.6024741799738281; validation accuracy : 0.9497907949790795\n",
      "Epoch 77:\t train loss : 0.5616575721241244; train accuracy : 0.9897766349639084; \n",
      " validation loss : 0.5983240891141506; validation accuracy : 0.9539748953974896\n",
      "Epoch 78:\t train loss : 0.5611795343770726; train accuracy : 0.9901483936924935; \n",
      " validation loss : 0.6013674337336969; validation accuracy : 0.9456066945606695\n",
      "Epoch 79:\t train loss : 0.5614201450920242; train accuracy : 0.9899507419684624; \n",
      " validation loss : 0.606158230807874; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5668408523474817; train accuracy : 0.9843994547538647; \n",
      " validation loss : 0.6145756824225679; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.581329895946583; train accuracy : 0.9695195018433037; \n",
      " validation loss : 0.5969931936986039; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.561886288622663; train accuracy : 0.9894897611450169; \n",
      " validation loss : 0.6116406580958303; validation accuracy : 0.9372384937238494\n",
      "Epoch 83:\t train loss : 0.56227098930907; train accuracy : 0.9889903652529508; \n",
      " validation loss : 0.6059246003584543; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5597539080907147; train accuracy : 0.9915366027448186; \n",
      " validation loss : 0.6025231400484226; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5594036042576036; train accuracy : 0.9918832677592243; \n",
      " validation loss : 0.6114985959347322; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.5607928833820033; train accuracy : 0.9904966077016016; \n",
      " validation loss : 0.6029348383941545; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5645335814274723; train accuracy : 0.9867037392732116; \n",
      " validation loss : 0.6233863310923972; validation accuracy : 0.9288702928870293\n",
      "Epoch 88:\t train loss : 0.5612054464584534; train accuracy : 0.9900709439573716; \n",
      " validation loss : 0.5977957400277895; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5618552752361862; train accuracy : 0.9893525202143809; \n",
      " validation loss : 0.6013233556268582; validation accuracy : 0.9456066945606695\n",
      "Epoch 90:\t train loss : 0.5613478191326153; train accuracy : 0.9898481985191611; \n",
      " validation loss : 0.6006994355377954; validation accuracy : 0.9497907949790795\n",
      "Epoch 91:\t train loss : 0.5608955089377597; train accuracy : 0.9903593667709656; \n",
      " validation loss : 0.5947176521117576; validation accuracy : 0.9539748953974896\n",
      "Epoch 92:\t train loss : 0.5601300263972739; train accuracy : 0.9912113138573067; \n",
      " validation loss : 0.5888868599538758; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5620032337818547; train accuracy : 0.9892013383314229; \n",
      " validation loss : 0.5981122071586841; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.561462734716181; train accuracy : 0.9898946683602342; \n",
      " validation loss : 0.5883776021507291; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5615521332534876; train accuracy : 0.9897568078317172; \n",
      " validation loss : 0.6541479880053147; validation accuracy : 0.895397489539749\n",
      "Epoch 96:\t train loss : 0.5657776682588054; train accuracy : 0.9855339384739304; \n",
      " validation loss : 0.6415618420418907; validation accuracy : 0.9079497907949791\n",
      "Epoch 97:\t train loss : 0.5618656031279755; train accuracy : 0.9895170234517798; \n",
      " validation loss : 0.5813678478147724; validation accuracy : 0.9707112970711297\n",
      "Epoch 98:\t train loss : 0.5593945596770125; train accuracy : 0.9919526627218935; \n",
      " validation loss : 0.590101169783812; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5594899693462511; train accuracy : 0.9919083614734038; \n",
      " validation loss : 0.5992167755018926; validation accuracy : 0.9497907949790795\n",
      "Epoch 100:\t train loss : 0.5643903291080755; train accuracy : 0.9868800148703492; \n",
      " validation loss : 0.6101972756644367; validation accuracy : 0.9414225941422594\n",
      "Epoch 101:\t train loss : 0.5665259360949154; train accuracy : 0.9847055361070666; \n",
      " validation loss : 0.5767773766923456; validation accuracy : 0.9748953974895398\n",
      "Epoch 102:\t train loss : 0.5632703095948521; train accuracy : 0.9880256513522724; \n",
      " validation loss : 0.6491136339467457; validation accuracy : 0.9037656903765691\n",
      "Epoch 103:\t train loss : 0.568107918151113; train accuracy : 0.9830171318814089; \n",
      " validation loss : 0.6143920323089532; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.5605217487955707; train accuracy : 0.9907834815204932; \n",
      " validation loss : 0.609568030403413; validation accuracy : 0.9414225941422594\n",
      "Epoch 105:\t train loss : 0.5593421439664725; train accuracy : 0.9918656092196164; \n",
      " validation loss : 0.6170941944006714; validation accuracy : 0.9372384937238494\n",
      "Epoch 106:\t train loss : 0.560002773202637; train accuracy : 0.9913603271476812; \n",
      " validation loss : 0.6195694939428972; validation accuracy : 0.9330543933054394\n",
      "Epoch 107:\t train loss : 0.5679659143895901; train accuracy : 0.9831580903993309; \n",
      " validation loss : 0.6130901455937392; validation accuracy : 0.9414225941422594\n",
      "Epoch 108:\t train loss : 0.5588555373164613; train accuracy : 0.9924910932804609; \n",
      " validation loss : 0.5807692467482687; validation accuracy : 0.9707112970711297\n",
      "Epoch 109:\t train loss : 0.5607826569758745; train accuracy : 0.9905954335636172; \n",
      " validation loss : 0.5799717866923347; validation accuracy : 0.9707112970711297\n",
      "Epoch 110:\t train loss : 0.5591797797508433; train accuracy : 0.9921193345518758; \n",
      " validation loss : 0.5857285766623206; validation accuracy : 0.9665271966527197\n",
      "Epoch 111:\t train loss : 0.5611989062243079; train accuracy : 0.990086433904396; \n",
      " validation loss : 0.5967363905013211; validation accuracy : 0.9497907949790795\n",
      "Epoch 112:\t train loss : 0.5576477812989316; train accuracy : 0.9936993091483627; \n",
      " validation loss : 0.5884190001354114; validation accuracy : 0.9623430962343096\n",
      "Epoch 113:\t train loss : 0.5694172524262554; train accuracy : 0.9818008612410546; \n",
      " validation loss : 0.5933760708249247; validation accuracy : 0.9623430962343096\n",
      "Epoch 114:\t train loss : 0.5634213441140473; train accuracy : 0.9878190154589671; \n",
      " validation loss : 0.5931920574910193; validation accuracy : 0.9581589958158996\n",
      "Epoch 115:\t train loss : 0.5595261291357834; train accuracy : 0.9918560054524613; \n",
      " validation loss : 0.6134616729477508; validation accuracy : 0.9372384937238494\n",
      "Epoch 116:\t train loss : 0.5586026570766034; train accuracy : 0.9927507047925896; \n",
      " validation loss : 0.6096154953437292; validation accuracy : 0.9414225941422594\n",
      "Epoch 117:\t train loss : 0.5593932229245316; train accuracy : 0.9919548313144769; \n",
      " validation loss : 0.6068140955284359; validation accuracy : 0.9414225941422594\n",
      "Epoch 118:\t train loss : 0.563616702141724; train accuracy : 0.9876796059357477; \n",
      " validation loss : 0.597228584473603; validation accuracy : 0.9539748953974896\n",
      "Epoch 119:\t train loss : 0.5624216571626677; train accuracy : 0.988949781591747; \n",
      " validation loss : 0.5822108247856672; validation accuracy : 0.9707112970711297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120:\t train loss : 0.5591458400929754; train accuracy : 0.9921871805198426; \n",
      " validation loss : 0.592952090236748; validation accuracy : 0.9581589958158996\n",
      "Epoch 121:\t train loss : 0.5620545603283236; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.5812205778086962; validation accuracy : 0.9707112970711297\n",
      "Epoch 122:\t train loss : 0.562767377982225; train accuracy : 0.988473310821277; \n",
      " validation loss : 0.5869252934303282; validation accuracy : 0.9623430962343096\n",
      "Epoch 123:\t train loss : 0.5670044250134741; train accuracy : 0.9840763344589362; \n",
      " validation loss : 0.5967268047882521; validation accuracy : 0.9539748953974896\n",
      "Epoch 124:\t train loss : 0.5628198706428725; train accuracy : 0.9883670497846897; \n",
      " validation loss : 0.6058165228460934; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5596516350161845; train accuracy : 0.9916295424269649; \n",
      " validation loss : 0.5934000773132632; validation accuracy : 0.9581589958158996\n",
      "Epoch 126:\t train loss : 0.5600413167118602; train accuracy : 0.9912791598252734; \n",
      " validation loss : 0.5975742165771839; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.5569223176466328; train accuracy : 0.9944545989652716; \n",
      " validation loss : 0.5920143794225341; validation accuracy : 0.9581589958158996\n",
      "Epoch 128:\t train loss : 0.557761359823606; train accuracy : 0.9936026518789306; \n",
      " validation loss : 0.5841660004392695; validation accuracy : 0.9665271966527197\n",
      "Epoch 129:\t train loss : 0.5603338025994155; train accuracy : 0.9908218965891137; \n",
      " validation loss : 0.6113384207823516; validation accuracy : 0.9372384937238494\n",
      "Epoch 130:\t train loss : 0.5648558201419831; train accuracy : 0.9863223767774714; \n",
      " validation loss : 0.5886053194221338; validation accuracy : 0.9623430962343096\n",
      "Epoch 131:\t train loss : 0.557751396295918; train accuracy : 0.993618141825955; \n",
      " validation loss : 0.5910357387402845; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.5574424744872065; train accuracy : 0.9939375445335977; \n",
      " validation loss : 0.5990486201075814; validation accuracy : 0.9497907949790795\n",
      "Epoch 133:\t train loss : 0.5609885419396645; train accuracy : 0.9903652529508349; \n",
      " validation loss : 0.5868538486178699; validation accuracy : 0.9665271966527197\n",
      "Epoch 134:\t train loss : 0.5570297111988537; train accuracy : 0.9943151894420521; \n",
      " validation loss : 0.5894451822844374; validation accuracy : 0.9623430962343096\n",
      "Epoch 135:\t train loss : 0.5588375783959666; train accuracy : 0.9925338455342483; \n",
      " validation loss : 0.6005469174173239; validation accuracy : 0.9497907949790795\n",
      "Epoch 136:\t train loss : 0.5619080144489451; train accuracy : 0.9892382044053409; \n",
      " validation loss : 0.5922389163488129; validation accuracy : 0.9581589958158996\n",
      "Epoch 137:\t train loss : 0.5579765159469958; train accuracy : 0.9933179466526224; \n",
      " validation loss : 0.5887619916897222; validation accuracy : 0.9623430962343096\n",
      "Epoch 138:\t train loss : 0.5569110113814166; train accuracy : 0.9944700889122959; \n",
      " validation loss : 0.5848984868594068; validation accuracy : 0.9665271966527197\n",
      "Epoch 139:\t train loss : 0.557437666913793; train accuracy : 0.9939316583537284; \n",
      " validation loss : 0.5855304355988338; validation accuracy : 0.9665271966527197\n",
      "Epoch 140:\t train loss : 0.556588115579698; train accuracy : 0.9948728275349298; \n",
      " validation loss : 0.6031043705682445; validation accuracy : 0.9497907949790795\n",
      "Epoch 141:\t train loss : 0.5663082719778681; train accuracy : 0.984808079556368; \n",
      " validation loss : 0.6179151281765998; validation accuracy : 0.9330543933054394\n",
      "Epoch 142:\t train loss : 0.5629475425642624; train accuracy : 0.9883088075838781; \n",
      " validation loss : 0.6076513874699334; validation accuracy : 0.9456066945606695\n",
      "Epoch 143:\t train loss : 0.5580360823235055; train accuracy : 0.9933238328324917; \n",
      " validation loss : 0.5971936692331817; validation accuracy : 0.9539748953974896\n",
      "Epoch 144:\t train loss : 0.5578298647856069; train accuracy : 0.9934979398370457; \n",
      " validation loss : 0.5982731644476731; validation accuracy : 0.9497907949790795\n",
      "Epoch 145:\t train loss : 0.5602157507503346; train accuracy : 0.9912054276774374; \n",
      " validation loss : 0.5873326245506492; validation accuracy : 0.9623430962343096\n",
      "Epoch 146:\t train loss : 0.5569846922053769; train accuracy : 0.9943616592831253; \n",
      " validation loss : 0.6220876763950333; validation accuracy : 0.9288702928870293\n",
      "Epoch 147:\t train loss : 0.5567488310603953; train accuracy : 0.9946404783295641; \n",
      " validation loss : 0.6054926975713429; validation accuracy : 0.9456066945606695\n",
      "Epoch 148:\t train loss : 0.5625058301409975; train accuracy : 0.9887270361535363; \n",
      " validation loss : 0.6129476713014166; validation accuracy : 0.9372384937238494\n",
      "Epoch 149:\t train loss : 0.5620120345311612; train accuracy : 0.9892227144583166; \n",
      " validation loss : 0.6173743862570913; validation accuracy : 0.9330543933054394\n",
      "Epoch 150:\t train loss : 0.5592022373431136; train accuracy : 0.9921465968586387; \n",
      " validation loss : 0.6037974818572491; validation accuracy : 0.9497907949790795\n",
      "Epoch 151:\t train loss : 0.5584755055432411; train accuracy : 0.9929514545060256; \n",
      " validation loss : 0.6451162067039365; validation accuracy : 0.9079497907949791\n",
      "Early stopping at epoch 151\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5665259360949154; Train accuracy : 0.9847055361070666; \n",
      " Validation loss : 0.5767773766923456; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 38 ! ---\n",
      "Epoch 1:\t train loss : 0.9691683391985985; train accuracy : 0.5524288236934229; \n",
      " validation loss : 0.865900514701591; validation accuracy : 0.6778242677824268\n",
      "Epoch 2:\t train loss : 0.7868957614329418; train accuracy : 0.7612596424920227; \n",
      " validation loss : 0.7887966761970266; validation accuracy : 0.7447698744769874\n",
      "Epoch 3:\t train loss : 0.7181523860100291; train accuracy : 0.8324594937885312; \n",
      " validation loss : 0.730464746183934; validation accuracy : 0.8158995815899581\n",
      "Epoch 4:\t train loss : 0.6967008864784456; train accuracy : 0.8537758294866632; \n",
      " validation loss : 0.721255473219986; validation accuracy : 0.8326359832635983\n",
      "Epoch 5:\t train loss : 0.6706757306456674; train accuracy : 0.8795591561076861; \n",
      " validation loss : 0.6689910587204158; validation accuracy : 0.8828451882845189\n",
      "Epoch 6:\t train loss : 0.6576182792569888; train accuracy : 0.8927699123268998; \n",
      " validation loss : 0.6687619766628095; validation accuracy : 0.8828451882845189\n",
      "Epoch 7:\t train loss : 0.6361998921754763; train accuracy : 0.9153121224325412; \n",
      " validation loss : 0.6482354232737254; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6246551564032266; train accuracy : 0.9262923262802442; \n",
      " validation loss : 0.7035505550960159; validation accuracy : 0.8368200836820083\n",
      "Epoch 9:\t train loss : 0.6189846523620895; train accuracy : 0.9322581244772142; \n",
      " validation loss : 0.6576363867726498; validation accuracy : 0.895397489539749\n",
      "Epoch 10:\t train loss : 0.6172944309985868; train accuracy : 0.933379286842839; \n",
      " validation loss : 0.6332532328003041; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.6016911967869882; train accuracy : 0.9493766845317388; \n",
      " validation loss : 0.633469077839712; validation accuracy : 0.9205020920502092\n",
      "Epoch 12:\t train loss : 0.6042610671022147; train accuracy : 0.9469329904891726; \n",
      " validation loss : 0.629253329456502; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.5940907240608218; train accuracy : 0.9573540072492952; \n",
      " validation loss : 0.629382387372102; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.595250384850429; train accuracy : 0.9552783543480281; \n",
      " validation loss : 0.6474531976043287; validation accuracy : 0.9037656903765691\n",
      "Epoch 15:\t train loss : 0.5945112660124868; train accuracy : 0.956583227485362; \n",
      " validation loss : 0.620803232851993; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5944957294568475; train accuracy : 0.9565949998451005; \n",
      " validation loss : 0.6251637781657711; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.5975711847633669; train accuracy : 0.9533244524303727; \n",
      " validation loss : 0.6436954961295813; validation accuracy : 0.899581589958159\n",
      "Epoch 18:\t train loss : 0.5932858679074874; train accuracy : 0.9575900740419467; \n",
      " validation loss : 0.6406774283349301; validation accuracy : 0.9079497907949791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:\t train loss : 0.5879467845658064; train accuracy : 0.9631723411505932; \n",
      " validation loss : 0.6168150118671097; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.5833352641541586; train accuracy : 0.9678310976176462; \n",
      " validation loss : 0.61648751606431; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5848469886378627; train accuracy : 0.966369156417485; \n",
      " validation loss : 0.6239249102625087; validation accuracy : 0.9288702928870293\n",
      "Epoch 22:\t train loss : 0.5793439295024362; train accuracy : 0.9719978933672047; \n",
      " validation loss : 0.629273071448636; validation accuracy : 0.9163179916317992\n",
      "Epoch 23:\t train loss : 0.5810311664950792; train accuracy : 0.970189287152638; \n",
      " validation loss : 0.6214535143533154; validation accuracy : 0.9246861924686193\n",
      "Epoch 24:\t train loss : 0.5788868251958778; train accuracy : 0.9718931813253199; \n",
      " validation loss : 0.6197881769651973; validation accuracy : 0.9246861924686193\n",
      "Epoch 25:\t train loss : 0.5783190062117594; train accuracy : 0.9727665045385545; \n",
      " validation loss : 0.6173151170899355; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5741745941878867; train accuracy : 0.9770225223829735; \n",
      " validation loss : 0.6199937407832435; validation accuracy : 0.9288702928870293\n",
      "Epoch 27:\t train loss : 0.5767244183277821; train accuracy : 0.9742498218656092; \n",
      " validation loss : 0.6206289264275482; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.5727383639427883; train accuracy : 0.978623873106354; \n",
      " validation loss : 0.620155016279359; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5718651503899536; train accuracy : 0.979489141547136; \n",
      " validation loss : 0.6063449119892707; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.5850332710143401; train accuracy : 0.9659723039747204; \n",
      " validation loss : 0.6347944500389318; validation accuracy : 0.9163179916317992\n",
      "Epoch 31:\t train loss : 0.576497246776631; train accuracy : 0.9746503918956597; \n",
      " validation loss : 0.6124203554966808; validation accuracy : 0.9414225941422594\n",
      "Epoch 32:\t train loss : 0.5736714980682903; train accuracy : 0.9776325164967936; \n",
      " validation loss : 0.6175697294883948; validation accuracy : 0.9330543933054394\n",
      "Epoch 33:\t train loss : 0.5825318125721816; train accuracy : 0.9685842188419715; \n",
      " validation loss : 0.6422532322790244; validation accuracy : 0.9037656903765691\n",
      "Epoch 34:\t train loss : 0.5721114864546497; train accuracy : 0.9790421016760122; \n",
      " validation loss : 0.6095416019049339; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5745027354732839; train accuracy : 0.9764413395706186; \n",
      " validation loss : 0.6035529821780444; validation accuracy : 0.9456066945606695\n",
      "Epoch 36:\t train loss : 0.570184642003592; train accuracy : 0.9812144118467114; \n",
      " validation loss : 0.6175493105426776; validation accuracy : 0.9288702928870293\n",
      "Epoch 37:\t train loss : 0.579090631710976; train accuracy : 0.9720347594411227; \n",
      " validation loss : 0.6224958881386847; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5739868526637737; train accuracy : 0.9770785959912017; \n",
      " validation loss : 0.614273226423166; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5684428935290713; train accuracy : 0.9828718361783203; \n",
      " validation loss : 0.5976259530087661; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.5712094332092229; train accuracy : 0.97984757892128; \n",
      " validation loss : 0.6107109678267794; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5718662364928917; train accuracy : 0.9792124910932805; \n",
      " validation loss : 0.6219676309232294; validation accuracy : 0.9288702928870293\n",
      "Epoch 42:\t train loss : 0.5708285746411009; train accuracy : 0.9803063911521422; \n",
      " validation loss : 0.6252421998428375; validation accuracy : 0.9246861924686193\n",
      "Epoch 43:\t train loss : 0.5730238562505732; train accuracy : 0.9779556367917221; \n",
      " validation loss : 0.5988601102587607; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.573897094104077; train accuracy : 0.9772777967099352; \n",
      " validation loss : 0.6162940454185762; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5740495538126383; train accuracy : 0.976883112859754; \n",
      " validation loss : 0.6000298041285561; validation accuracy : 0.9497907949790795\n",
      "Epoch 46:\t train loss : 0.5670486951796595; train accuracy : 0.9840859382260913; \n",
      " validation loss : 0.6145839509506245; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.5638674713884246; train accuracy : 0.9874531429102512; \n",
      " validation loss : 0.5987005839248638; validation accuracy : 0.9497907949790795\n",
      "Epoch 48:\t train loss : 0.5615464263480076; train accuracy : 0.9898481985191611; \n",
      " validation loss : 0.5884262119079361; validation accuracy : 0.9623430962343096\n",
      "Epoch 49:\t train loss : 0.5647963707075793; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.6100332801125953; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5654253047554061; train accuracy : 0.9856717990024474; \n",
      " validation loss : 0.6150668853136405; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5673938268846298; train accuracy : 0.9836153536354906; \n",
      " validation loss : 0.6040453164789051; validation accuracy : 0.9456066945606695\n",
      "Epoch 52:\t train loss : 0.563318712391661; train accuracy : 0.9879776325164968; \n",
      " validation loss : 0.6368211471309916; validation accuracy : 0.9121338912133892\n",
      "Epoch 53:\t train loss : 0.5730307827481166; train accuracy : 0.9779674091514607; \n",
      " validation loss : 0.6240584994132112; validation accuracy : 0.9246861924686193\n",
      "Epoch 54:\t train loss : 0.5743054680408247; train accuracy : 0.976960562594876; \n",
      " validation loss : 0.6445022447874845; validation accuracy : 0.9037656903765691\n",
      "Epoch 55:\t train loss : 0.576362243541542; train accuracy : 0.9746739366151368; \n",
      " validation loss : 0.632972363597455; validation accuracy : 0.9163179916317992\n",
      "Epoch 56:\t train loss : 0.5680040251005153; train accuracy : 0.9830945816165308; \n",
      " validation loss : 0.6198541066249794; validation accuracy : 0.9330543933054394\n",
      "Epoch 57:\t train loss : 0.5664802343653641; train accuracy : 0.9847888720220577; \n",
      " validation loss : 0.600470318870421; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.569822839006112; train accuracy : 0.9813036339415719; \n",
      " validation loss : 0.6057881714859006; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5660391006141711; train accuracy : 0.9851488583909043; \n",
      " validation loss : 0.6235456264796082; validation accuracy : 0.9246861924686193\n",
      "Epoch 60:\t train loss : 0.5633729516226403; train accuracy : 0.9878441091731466; \n",
      " validation loss : 0.6360973510797266; validation accuracy : 0.9121338912133892\n",
      "Epoch 61:\t train loss : 0.5687322709461448; train accuracy : 0.9824963598624493; \n",
      " validation loss : 0.6005032629673581; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5641422406644788; train accuracy : 0.98712196784287; \n",
      " validation loss : 0.5912276481582681; validation accuracy : 0.9581589958158996\n",
      "Epoch 63:\t train loss : 0.5633064936202038; train accuracy : 0.988097834505406; \n",
      " validation loss : 0.5985917689321568; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5636542076701294; train accuracy : 0.9876154775550667; \n",
      " validation loss : 0.6194374311157679; validation accuracy : 0.9288702928870293\n",
      "Epoch 65:\t train loss : 0.5648823243311655; train accuracy : 0.9865002013693113; \n",
      " validation loss : 0.6049537508352115; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5672404404910678; train accuracy : 0.9839192663961089; \n",
      " validation loss : 0.6302901158517333; validation accuracy : 0.9205020920502092\n",
      "Epoch 67:\t train loss : 0.5755265194712638; train accuracy : 0.9754787942625236; \n",
      " validation loss : 0.6860159693932864; validation accuracy : 0.8619246861924686\n",
      "Epoch 68:\t train loss : 0.5948397863036103; train accuracy : 0.9558359924409059; \n",
      " validation loss : 0.6051469236701417; validation accuracy : 0.9414225941422594\n",
      "Epoch 69:\t train loss : 0.5712006762964145; train accuracy : 0.9800275721057033; \n",
      " validation loss : 0.6251464861392186; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70:\t train loss : 0.5694145786839389; train accuracy : 0.9818281235478175; \n",
      " validation loss : 0.6092199132261095; validation accuracy : 0.9414225941422594\n",
      "Epoch 71:\t train loss : 0.5695263505073879; train accuracy : 0.9814777409461259; \n",
      " validation loss : 0.6138181936160502; validation accuracy : 0.9372384937238494\n",
      "Epoch 72:\t train loss : 0.5668096833521671; train accuracy : 0.9843027974844326; \n",
      " validation loss : 0.611592860722168; validation accuracy : 0.9372384937238494\n",
      "Epoch 73:\t train loss : 0.5703253393895967; train accuracy : 0.9807652033830044; \n",
      " validation loss : 0.6089680827375422; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5698611254672292; train accuracy : 0.9813965736237182; \n",
      " validation loss : 0.6106232808309964; validation accuracy : 0.9414225941422594\n",
      "Epoch 75:\t train loss : 0.5658612874468174; train accuracy : 0.9852845503268379; \n",
      " validation loss : 0.5911028349330439; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5672731948229687; train accuracy : 0.9838477028408563; \n",
      " validation loss : 0.6061617720439301; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5686838100920814; train accuracy : 0.9824049691750054; \n",
      " validation loss : 0.6347154160730833; validation accuracy : 0.9163179916317992\n",
      "Epoch 78:\t train loss : 0.5826367798537094; train accuracy : 0.9682552123671737; \n",
      " validation loss : 0.5977857410447278; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5656207021768297; train accuracy : 0.985656309055423; \n",
      " validation loss : 0.6063482402404856; validation accuracy : 0.9414225941422594\n",
      "Epoch 80:\t train loss : 0.5624953839382008; train accuracy : 0.988835465782707; \n",
      " validation loss : 0.5993489107364326; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5633974663532993; train accuracy : 0.9877629418507389; \n",
      " validation loss : 0.6088154040723904; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5622675431860676; train accuracy : 0.989036835094024; \n",
      " validation loss : 0.593494574659974; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5638151584578605; train accuracy : 0.9873292233340561; \n",
      " validation loss : 0.5998629408534099; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5628096581241494; train accuracy : 0.9884444995198116; \n",
      " validation loss : 0.5913225130474614; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5623331443331929; train accuracy : 0.9888701632640416; \n",
      " validation loss : 0.6258501066744282; validation accuracy : 0.9246861924686193\n",
      "Epoch 86:\t train loss : 0.5661803914195453; train accuracy : 0.9850655224759132; \n",
      " validation loss : 0.6121493223697884; validation accuracy : 0.9372384937238494\n",
      "Epoch 87:\t train loss : 0.5714876083219639; train accuracy : 0.979764243006289; \n",
      " validation loss : 0.6122196361021182; validation accuracy : 0.9372384937238494\n",
      "Epoch 88:\t train loss : 0.5658757672628187; train accuracy : 0.9855206171194895; \n",
      " validation loss : 0.5989296430545445; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.5619575972519711; train accuracy : 0.989435856129372; \n",
      " validation loss : 0.6132225200988307; validation accuracy : 0.9330543933054394\n",
      "Epoch 90:\t train loss : 0.562839913622859; train accuracy : 0.9884172372130487; \n",
      " validation loss : 0.6177113913893889; validation accuracy : 0.9288702928870293\n",
      "Epoch 91:\t train loss : 0.5646839727673766; train accuracy : 0.9865178599089192; \n",
      " validation loss : 0.5948263498108556; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5641566453883095; train accuracy : 0.9871064778958456; \n",
      " validation loss : 0.6124061823458576; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5665120888048798; train accuracy : 0.9845971064778959; \n",
      " validation loss : 0.6004383235819395; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5656591850607422; train accuracy : 0.9856637442299947; \n",
      " validation loss : 0.6135594717200943; validation accuracy : 0.9372384937238494\n",
      "Epoch 95:\t train loss : 0.5628892982590104; train accuracy : 0.9884482171070975; \n",
      " validation loss : 0.6027490154120932; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5656805325975919; train accuracy : 0.9854239598500573; \n",
      " validation loss : 0.6095595013401213; validation accuracy : 0.9414225941422594\n",
      "Epoch 97:\t train loss : 0.5650692993714375; train accuracy : 0.9860782552123671; \n",
      " validation loss : 0.6132551648242833; validation accuracy : 0.9372384937238494\n",
      "Epoch 98:\t train loss : 0.564532617573089; train accuracy : 0.9866823631463181; \n",
      " validation loss : 0.6044172318023937; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 98\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5615464263480076; Train accuracy : 0.9898481985191611; \n",
      " Validation loss : 0.5884262119079361; Validation accuracy : 0.9623430962343096\n",
      "--- Let's train model 39 ! ---\n",
      "Epoch 1:\t train loss : 0.9541936348681758; train accuracy : 0.5738535890207256; \n",
      " validation loss : 0.9165781633440105; validation accuracy : 0.6234309623430963\n",
      "Epoch 2:\t train loss : 0.7646569332504307; train accuracy : 0.7844673007218316; \n",
      " validation loss : 0.7618975235694865; validation accuracy : 0.7782426778242678\n",
      "Epoch 3:\t train loss : 0.7003037372996046; train accuracy : 0.8495139254623749; \n",
      " validation loss : 0.6987752474899418; validation accuracy : 0.8535564853556485\n",
      "Epoch 4:\t train loss : 0.6778390670407093; train accuracy : 0.8730106261036588; \n",
      " validation loss : 0.6871719979329699; validation accuracy : 0.8661087866108786\n",
      "Epoch 5:\t train loss : 0.6550671132677478; train accuracy : 0.8954710492890114; \n",
      " validation loss : 0.6448162360788481; validation accuracy : 0.9037656903765691\n",
      "Epoch 6:\t train loss : 0.6409783524013187; train accuracy : 0.9098420025403513; \n",
      " validation loss : 0.6867381207028931; validation accuracy : 0.8577405857740585\n",
      "Epoch 7:\t train loss : 0.6331908044735023; train accuracy : 0.9178444189720871; \n",
      " validation loss : 0.6489206783135434; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6258269599033828; train accuracy : 0.924578828340407; \n",
      " validation loss : 0.649648266724936; validation accuracy : 0.895397489539749\n",
      "Epoch 9:\t train loss : 0.6169845889392771; train accuracy : 0.934052789739459; \n",
      " validation loss : 0.6192491469474611; validation accuracy : 0.9330543933054394\n",
      "Epoch 10:\t train loss : 0.6129495875452823; train accuracy : 0.9381576257009201; \n",
      " validation loss : 0.6747825228104447; validation accuracy : 0.8786610878661087\n",
      "Epoch 11:\t train loss : 0.6207576906209359; train accuracy : 0.9299169738839493; \n",
      " validation loss : 0.6617600540378412; validation accuracy : 0.891213389121339\n",
      "Epoch 12:\t train loss : 0.6088763208150412; train accuracy : 0.941877381579355; \n",
      " validation loss : 0.6267222892176738; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.5971307821058272; train accuracy : 0.9540679698875429; \n",
      " validation loss : 0.6189153061150177; validation accuracy : 0.9288702928870293\n",
      "Epoch 14:\t train loss : 0.5892770875999087; train accuracy : 0.9622894141702035; \n",
      " validation loss : 0.623823594540372; validation accuracy : 0.9205020920502092\n",
      "Epoch 15:\t train loss : 0.5908845147139044; train accuracy : 0.9604808079556367; \n",
      " validation loss : 0.6278273593802306; validation accuracy : 0.9246861924686193\n",
      "Epoch 16:\t train loss : 0.6038254128473799; train accuracy : 0.9470104402242945; \n",
      " validation loss : 0.620444452342014; validation accuracy : 0.9246861924686193\n",
      "Epoch 17:\t train loss : 0.5903403121650969; train accuracy : 0.9606629697326435; \n",
      " validation loss : 0.6235069061190859; validation accuracy : 0.9288702928870293\n",
      "Epoch 18:\t train loss : 0.5868341045682751; train accuracy : 0.964581926329812; \n",
      " validation loss : 0.6040312435851624; validation accuracy : 0.9497907949790795\n",
      "Epoch 19:\t train loss : 0.5840291850358056; train accuracy : 0.9673642306143313; \n",
      " validation loss : 0.6103654163864882; validation accuracy : 0.9456066945606695\n",
      "Epoch 20:\t train loss : 0.581597156705197; train accuracy : 0.9700130115555005; \n",
      " validation loss : 0.6172456567151828; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5802009340584923; train accuracy : 0.9709541807367019; \n",
      " validation loss : 0.6308531987188859; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:\t train loss : 0.5792295165473503; train accuracy : 0.9720731745097432; \n",
      " validation loss : 0.6302508131335457; validation accuracy : 0.9246861924686193\n",
      "Epoch 23:\t train loss : 0.5787723665820591; train accuracy : 0.972241395334428; \n",
      " validation loss : 0.624685660231876; validation accuracy : 0.9163179916317992\n",
      "Epoch 24:\t train loss : 0.5794927314282179; train accuracy : 0.971728678087921; \n",
      " validation loss : 0.6075527796281738; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.5737498437004063; train accuracy : 0.9775528981690883; \n",
      " validation loss : 0.6282359091327518; validation accuracy : 0.9163179916317992\n",
      "Epoch 26:\t train loss : 0.5813998701178947; train accuracy : 0.969786548530004; \n",
      " validation loss : 0.617120046623352; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5795947902298225; train accuracy : 0.9716608321199541; \n",
      " validation loss : 0.6197634731589232; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5704059140169754; train accuracy : 0.9811214721645652; \n",
      " validation loss : 0.6157911326621016; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.5765850251636424; train accuracy : 0.9744858886582608; \n",
      " validation loss : 0.6079528107078007; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5711041788472192; train accuracy : 0.9802075652901268; \n",
      " validation loss : 0.6251147432893966; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5681792335623633; train accuracy : 0.9832163326001425; \n",
      " validation loss : 0.6205738156609375; validation accuracy : 0.9288702928870293\n",
      "Epoch 32:\t train loss : 0.5708430349491129; train accuracy : 0.9804804981566964; \n",
      " validation loss : 0.6435767565788792; validation accuracy : 0.899581589958159\n",
      "Epoch 33:\t train loss : 0.5654786548130667; train accuracy : 0.9859831469376374; \n",
      " validation loss : 0.60623286748972; validation accuracy : 0.9456066945606695\n",
      "Epoch 34:\t train loss : 0.5721465779778506; train accuracy : 0.9790517054431674; \n",
      " validation loss : 0.6182274329386526; validation accuracy : 0.9330543933054394\n",
      "Epoch 35:\t train loss : 0.5701877192521922; train accuracy : 0.9810653985563369; \n",
      " validation loss : 0.6084755302336907; validation accuracy : 0.9456066945606695\n",
      "Epoch 36:\t train loss : 0.5702022844236535; train accuracy : 0.9807999008643391; \n",
      " validation loss : 0.6095995195922389; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.5690782156709802; train accuracy : 0.982188109916664; \n",
      " validation loss : 0.5996810011891502; validation accuracy : 0.9497907949790795\n",
      "Epoch 38:\t train loss : 0.5773094033094351; train accuracy : 0.9736494315189442; \n",
      " validation loss : 0.6336442416617434; validation accuracy : 0.9163179916317992\n",
      "Epoch 39:\t train loss : 0.5687433308929161; train accuracy : 0.9826704668670033; \n",
      " validation loss : 0.6227261510271913; validation accuracy : 0.9205020920502092\n",
      "Epoch 40:\t train loss : 0.5637396223731169; train accuracy : 0.9875962700207566; \n",
      " validation loss : 0.6123698496980174; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5681455881695642; train accuracy : 0.9830053595216705; \n",
      " validation loss : 0.5984587230803157; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5682715983258932; train accuracy : 0.9831816351188079; \n",
      " validation loss : 0.6213368886985547; validation accuracy : 0.9288702928870293\n",
      "Epoch 43:\t train loss : 0.5662147007159256; train accuracy : 0.9851178784968555; \n",
      " validation loss : 0.6222540447332293; validation accuracy : 0.9288702928870293\n",
      "Epoch 44:\t train loss : 0.5632050662322675; train accuracy : 0.9882933176368537; \n",
      " validation loss : 0.6200597780675386; validation accuracy : 0.9246861924686193\n",
      "Epoch 45:\t train loss : 0.5739702352863972; train accuracy : 0.976946621642554; \n",
      " validation loss : 0.660963598777799; validation accuracy : 0.8828451882845189\n",
      "Epoch 46:\t train loss : 0.5880553924657627; train accuracy : 0.962415502338982; \n",
      " validation loss : 0.6221867173782488; validation accuracy : 0.9246861924686193\n",
      "Epoch 47:\t train loss : 0.5634395607047112; train accuracy : 0.9878499953530159; \n",
      " validation loss : 0.6030919449081424; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5628977385272134; train accuracy : 0.9884268409802038; \n",
      " validation loss : 0.6172160756747055; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5616025400322103; train accuracy : 0.9896564329749992; \n",
      " validation loss : 0.6040921278633535; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5645830565571226; train accuracy : 0.9867502091142848; \n",
      " validation loss : 0.623057379503332; validation accuracy : 0.9246861924686193\n",
      "Epoch 51:\t train loss : 0.5611221349151743; train accuracy : 0.9901425075126243; \n",
      " validation loss : 0.608166238075967; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5627517769133463; train accuracy : 0.988423123392918; \n",
      " validation loss : 0.6308940463029495; validation accuracy : 0.9205020920502092\n",
      "Epoch 53:\t train loss : 0.5674742937546066; train accuracy : 0.9836212398153599; \n",
      " validation loss : 0.6320048240045857; validation accuracy : 0.9163179916317992\n",
      "Epoch 54:\t train loss : 0.5663723689170771; train accuracy : 0.9848545493974411; \n",
      " validation loss : 0.6083470947585161; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5672876082391552; train accuracy : 0.9840084884909693; \n",
      " validation loss : 0.6086823751242311; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.5802771246633782; train accuracy : 0.9707683013724093; \n",
      " validation loss : 0.6342948231434491; validation accuracy : 0.9163179916317992\n",
      "Epoch 57:\t train loss : 0.5672913024851098; train accuracy : 0.9840741658663528; \n",
      " validation loss : 0.5959843365296557; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.5641318039616849; train accuracy : 0.9871064778958456; \n",
      " validation loss : 0.6094468199151355; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5649169852187182; train accuracy : 0.9863106044177329; \n",
      " validation loss : 0.6010319590052642; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.561025726377888; train accuracy : 0.9903593667709656; \n",
      " validation loss : 0.6033577419737586; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5619698081254556; train accuracy : 0.9893525202143809; \n",
      " validation loss : 0.6246533443699034; validation accuracy : 0.9246861924686193\n",
      "Epoch 62:\t train loss : 0.5628042927197845; train accuracy : 0.9884850831810155; \n",
      " validation loss : 0.6481325551456112; validation accuracy : 0.899581589958159\n",
      "Epoch 63:\t train loss : 0.5658798971056701; train accuracy : 0.9851547445707736; \n",
      " validation loss : 0.6164988971336415; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.5641877109142969; train accuracy : 0.9870748784039158; \n",
      " validation loss : 0.6350344597589634; validation accuracy : 0.9163179916317992\n",
      "Epoch 65:\t train loss : 0.5822311123469394; train accuracy : 0.9687140245980359; \n",
      " validation loss : 0.6281238906317343; validation accuracy : 0.9246861924686193\n",
      "Epoch 66:\t train loss : 0.5590121741627133; train accuracy : 0.9924969794603302; \n",
      " validation loss : 0.6057829021723269; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5637709798778617; train accuracy : 0.9876176461476501; \n",
      " validation loss : 0.6102716852207526; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5647038540440267; train accuracy : 0.9865525573902537; \n",
      " validation loss : 0.6317887758793943; validation accuracy : 0.9163179916317992\n",
      "Epoch 69:\t train loss : 0.562622854533751; train accuracy : 0.9886805663124633; \n",
      " validation loss : 0.5988924222009506; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5642304274892375; train accuracy : 0.9868896186375042; \n",
      " validation loss : 0.6186458685483311; validation accuracy : 0.9330543933054394\n",
      "Epoch 71:\t train loss : 0.5748970670754935; train accuracy : 0.9759478298584219; \n",
      " validation loss : 0.6001971105673106; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5633274287242022; train accuracy : 0.9878654853000403; \n",
      " validation loss : 0.5963345746599091; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73:\t train loss : 0.5618304720892078; train accuracy : 0.9895015335047554; \n",
      " validation loss : 0.6143813787935197; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5621486308664915; train accuracy : 0.9892382044053409; \n",
      " validation loss : 0.6063866608994296; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5710500813726682; train accuracy : 0.9801824715759472; \n",
      " validation loss : 0.6070979054939639; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5614434104492224; train accuracy : 0.9898791784132098; \n",
      " validation loss : 0.5941694986283537; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5648948426756301; train accuracy : 0.9862796245236841; \n",
      " validation loss : 0.595138796426158; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5676466203282723; train accuracy : 0.983479661699557; \n",
      " validation loss : 0.6188224452043269; validation accuracy : 0.9288702928870293\n",
      "Epoch 79:\t train loss : 0.5724037330172934; train accuracy : 0.9785036711174447; \n",
      " validation loss : 0.6117660415586013; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.5595355931571432; train accuracy : 0.9917689519501843; \n",
      " validation loss : 0.6085159349841733; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.5610206820070622; train accuracy : 0.9902354471947706; \n",
      " validation loss : 0.6090385273969127; validation accuracy : 0.9372384937238494\n",
      "Epoch 82:\t train loss : 0.5622358816253445; train accuracy : 0.9891511509030639; \n",
      " validation loss : 0.627476789355129; validation accuracy : 0.9205020920502092\n",
      "Epoch 83:\t train loss : 0.5610969339607287; train accuracy : 0.9901734874066731; \n",
      " validation loss : 0.6366721267115565; validation accuracy : 0.9163179916317992\n",
      "Epoch 84:\t train loss : 0.5594588423563757; train accuracy : 0.991840515505437; \n",
      " validation loss : 0.6194107466700521; validation accuracy : 0.9288702928870293\n",
      "Epoch 85:\t train loss : 0.5591324080192619; train accuracy : 0.9921871805198426; \n",
      " validation loss : 0.6209891474457774; validation accuracy : 0.9288702928870293\n",
      "Epoch 86:\t train loss : 0.560149973785819; train accuracy : 0.9911183741751604; \n",
      " validation loss : 0.6206591164317151; validation accuracy : 0.9288702928870293\n",
      "Epoch 87:\t train loss : 0.5673453383642727; train accuracy : 0.9838845689147743; \n",
      " validation loss : 0.639793331460338; validation accuracy : 0.9121338912133892\n",
      "Epoch 88:\t train loss : 0.5619570474053677; train accuracy : 0.9894454598965271; \n",
      " validation loss : 0.6416064844119123; validation accuracy : 0.9079497907949791\n",
      "Epoch 89:\t train loss : 0.5619063452755444; train accuracy : 0.9894609498435515; \n",
      " validation loss : 0.6239150668255995; validation accuracy : 0.9288702928870293\n",
      "Epoch 90:\t train loss : 0.559718494392645; train accuracy : 0.9916236562470956; \n",
      " validation loss : 0.6144066950625928; validation accuracy : 0.9330543933054394\n",
      "Epoch 91:\t train loss : 0.5696861188917537; train accuracy : 0.9813906874438489; \n",
      " validation loss : 0.6282884301428395; validation accuracy : 0.9246861924686193\n",
      "Epoch 92:\t train loss : 0.5610473712358123; train accuracy : 0.9903438768239412; \n",
      " validation loss : 0.6098954131571356; validation accuracy : 0.9414225941422594\n",
      "Epoch 93:\t train loss : 0.5593432456987733; train accuracy : 0.9920610923510641; \n",
      " validation loss : 0.6005061455421004; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5778157016965713; train accuracy : 0.972992967564051; \n",
      " validation loss : 0.6313574272484046; validation accuracy : 0.9205020920502092\n",
      "Epoch 95:\t train loss : 0.575843197609018; train accuracy : 0.9752043124012516; \n",
      " validation loss : 0.6055147585522411; validation accuracy : 0.9456066945606695\n",
      "Epoch 96:\t train loss : 0.5642380243302175; train accuracy : 0.9869670683726262; \n",
      " validation loss : 0.6144118424590459; validation accuracy : 0.9372384937238494\n",
      "Epoch 97:\t train loss : 0.5611650816700015; train accuracy : 0.9902450509619257; \n",
      " validation loss : 0.6130057529877263; validation accuracy : 0.9372384937238494\n",
      "Epoch 98:\t train loss : 0.5674306891560976; train accuracy : 0.9837835744601754; \n",
      " validation loss : 0.6147519427554534; validation accuracy : 0.9372384937238494\n",
      "Epoch 99:\t train loss : 0.5617391450340858; train accuracy : 0.9895015335047554; \n",
      " validation loss : 0.6225258094925631; validation accuracy : 0.9288702928870293\n",
      "Epoch 100:\t train loss : 0.5606824621091006; train accuracy : 0.9907097493726571; \n",
      " validation loss : 0.6062797369965014; validation accuracy : 0.9456066945606695\n",
      "Epoch 101:\t train loss : 0.5664121606209757; train accuracy : 0.9848833606989064; \n",
      " validation loss : 0.6136372852867902; validation accuracy : 0.9372384937238494\n",
      "Epoch 102:\t train loss : 0.568948829654446; train accuracy : 0.9822073174509743; \n",
      " validation loss : 0.6243574267253238; validation accuracy : 0.9288702928870293\n",
      "Epoch 103:\t train loss : 0.5632473727988034; train accuracy : 0.9880764583785123; \n",
      " validation loss : 0.5998951758985781; validation accuracy : 0.9497907949790795\n",
      "Epoch 104:\t train loss : 0.5619390732142604; train accuracy : 0.9893370302673565; \n",
      " validation loss : 0.6015320064461133; validation accuracy : 0.9456066945606695\n",
      "Epoch 105:\t train loss : 0.5594326658241427; train accuracy : 0.991964435081632; \n",
      " validation loss : 0.6127429264843725; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.5590726263993654; train accuracy : 0.9922255955884631; \n",
      " validation loss : 0.6288979213568267; validation accuracy : 0.9205020920502092\n",
      "Epoch 107:\t train loss : 0.5595147195382921; train accuracy : 0.991840515505437; \n",
      " validation loss : 0.5898598843239344; validation accuracy : 0.9623430962343096\n",
      "Epoch 108:\t train loss : 0.557596866238913; train accuracy : 0.9937206852752564; \n",
      " validation loss : 0.6197151323268897; validation accuracy : 0.9330543933054394\n",
      "Epoch 109:\t train loss : 0.5624212824526953; train accuracy : 0.988885653211066; \n",
      " validation loss : 0.6301163072552151; validation accuracy : 0.9205020920502092\n",
      "Epoch 110:\t train loss : 0.5632629618720659; train accuracy : 0.9880358747173085; \n",
      " validation loss : 0.5923418836538323; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.5584943496564917; train accuracy : 0.9929712816382168; \n",
      " validation loss : 0.5994010278293092; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5586703741127355; train accuracy : 0.9926673688775984; \n",
      " validation loss : 0.6182196057239333; validation accuracy : 0.9330543933054394\n",
      "Epoch 113:\t train loss : 0.5581711415558986; train accuracy : 0.9931726509495338; \n",
      " validation loss : 0.602218205027046; validation accuracy : 0.9497907949790795\n",
      "Epoch 114:\t train loss : 0.5598626642606316; train accuracy : 0.9915675826388674; \n",
      " validation loss : 0.6022004014437928; validation accuracy : 0.9497907949790795\n",
      "Epoch 115:\t train loss : 0.5588616877552067; train accuracy : 0.9924195297252083; \n",
      " validation loss : 0.6125114378986346; validation accuracy : 0.9372384937238494\n",
      "Epoch 116:\t train loss : 0.5620161838334309; train accuracy : 0.9893038817807243; \n",
      " validation loss : 0.6361425584833487; validation accuracy : 0.9121338912133892\n",
      "Epoch 117:\t train loss : 0.5616448817225109; train accuracy : 0.9896468292078441; \n",
      " validation loss : 0.5898531247545243; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5587125272175258; train accuracy : 0.9926208990365253; \n",
      " validation loss : 0.606105698266473; validation accuracy : 0.9497907949790795\n",
      "Epoch 119:\t train loss : 0.5626059865839884; train accuracy : 0.9886554725982837; \n",
      " validation loss : 0.6095971702464648; validation accuracy : 0.9414225941422594\n",
      "Epoch 120:\t train loss : 0.5595690033406929; train accuracy : 0.9918073670188048; \n",
      " validation loss : 0.6146222253361816; validation accuracy : 0.9372384937238494\n",
      "Epoch 121:\t train loss : 0.568450274872117; train accuracy : 0.9826277146132161; \n",
      " validation loss : 0.6428069545268335; validation accuracy : 0.9079497907949791\n",
      "Epoch 122:\t train loss : 0.5643371362176399; train accuracy : 0.9869766721397812; \n",
      " validation loss : 0.593831010832024; validation accuracy : 0.9539748953974896\n",
      "Epoch 123:\t train loss : 0.5589829863861666; train accuracy : 0.9923767774714211; \n",
      " validation loss : 0.6276973555255018; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124:\t train loss : 0.5584922118415271; train accuracy : 0.9928377582948666; \n",
      " validation loss : 0.5963932663084216; validation accuracy : 0.9539748953974896\n",
      "Epoch 125:\t train loss : 0.5569138116681103; train accuracy : 0.9945047863936305; \n",
      " validation loss : 0.6153462324380131; validation accuracy : 0.9330543933054394\n",
      "Epoch 126:\t train loss : 0.5666052676966022; train accuracy : 0.9846280863719447; \n",
      " validation loss : 0.603970464505872; validation accuracy : 0.9456066945606695\n",
      "Epoch 127:\t train loss : 0.5615793909669484; train accuracy : 0.989724278942966; \n",
      " validation loss : 0.5954422240638365; validation accuracy : 0.9539748953974896\n",
      "Epoch 128:\t train loss : 0.5590557059698262; train accuracy : 0.9923516837572416; \n",
      " validation loss : 0.6183648368166926; validation accuracy : 0.9330543933054394\n",
      "Epoch 129:\t train loss : 0.5630125664550444; train accuracy : 0.9882682239226742; \n",
      " validation loss : 0.6141875284897629; validation accuracy : 0.9372384937238494\n",
      "Epoch 130:\t train loss : 0.5587507009850949; train accuracy : 0.9926054090895009; \n",
      " validation loss : 0.6014584787928676; validation accuracy : 0.9497907949790795\n",
      "Epoch 131:\t train loss : 0.5703520009206896; train accuracy : 0.9809606865144521; \n",
      " validation loss : 0.6233776144997831; validation accuracy : 0.9246861924686193\n",
      "Epoch 132:\t train loss : 0.5595254947760231; train accuracy : 0.991840515505437; \n",
      " validation loss : 0.6118926584653749; validation accuracy : 0.9372384937238494\n",
      "Epoch 133:\t train loss : 0.5642749624684593; train accuracy : 0.9870754980017968; \n",
      " validation loss : 0.6166389006398845; validation accuracy : 0.9330543933054394\n",
      "Epoch 134:\t train loss : 0.560420538337101; train accuracy : 0.9909362123981535; \n",
      " validation loss : 0.6023987235152058; validation accuracy : 0.9497907949790795\n",
      "Epoch 135:\t train loss : 0.5600741538460245; train accuracy : 0.9913042535394528; \n",
      " validation loss : 0.6100830085313349; validation accuracy : 0.9414225941422594\n",
      "Epoch 136:\t train loss : 0.5571421939159639; train accuracy : 0.9942628334211097; \n",
      " validation loss : 0.625594369224531; validation accuracy : 0.9246861924686193\n",
      "Epoch 137:\t train loss : 0.5621647986094114; train accuracy : 0.9891201710090152; \n",
      " validation loss : 0.6167016710066535; validation accuracy : 0.9330543933054394\n",
      "Epoch 138:\t train loss : 0.5607370684084332; train accuracy : 0.9905452461352582; \n",
      " validation loss : 0.6165714556347269; validation accuracy : 0.9330543933054394\n",
      "Epoch 139:\t train loss : 0.556632533164658; train accuracy : 0.9948049815669631; \n",
      " validation loss : 0.5998709562550998; validation accuracy : 0.9497907949790795\n",
      "Epoch 140:\t train loss : 0.5574811593788264; train accuracy : 0.9939006784596797; \n",
      " validation loss : 0.6060009812905838; validation accuracy : 0.9456066945606695\n",
      "Epoch 141:\t train loss : 0.5611577197370266; train accuracy : 0.9902022987081384; \n",
      " validation loss : 0.6124144640473516; validation accuracy : 0.9372384937238494\n",
      "Epoch 142:\t train loss : 0.5674245247638071; train accuracy : 0.9836928033706125; \n",
      " validation loss : 0.6038398031070606; validation accuracy : 0.9456066945606695\n",
      "Epoch 143:\t train loss : 0.5605321363175814; train accuracy : 0.9908336689488522; \n",
      " validation loss : 0.6113822169106448; validation accuracy : 0.9414225941422594\n",
      "Epoch 144:\t train loss : 0.5656268890870013; train accuracy : 0.9855361070665138; \n",
      " validation loss : 0.6064258034812087; validation accuracy : 0.9456066945606695\n",
      "Epoch 145:\t train loss : 0.5598138391262714; train accuracy : 0.9914628705969826; \n",
      " validation loss : 0.6054890338160133; validation accuracy : 0.9414225941422594\n",
      "Epoch 146:\t train loss : 0.5590004276309044; train accuracy : 0.9923885498311595; \n",
      " validation loss : 0.6040345750369368; validation accuracy : 0.9456066945606695\n",
      "Epoch 147:\t train loss : 0.5573676442793578; train accuracy : 0.9939995043216951; \n",
      " validation loss : 0.5990244309227473; validation accuracy : 0.9497907949790795\n",
      "Epoch 148:\t train loss : 0.5577639548945683; train accuracy : 0.9936432355401345; \n",
      " validation loss : 0.6204581255254632; validation accuracy : 0.9330543933054394\n",
      "Epoch 149:\t train loss : 0.5571234430394508; train accuracy : 0.9942569472412405; \n",
      " validation loss : 0.604793029909758; validation accuracy : 0.9456066945606695\n",
      "Epoch 150:\t train loss : 0.5604819667692041; train accuracy : 0.9907930852876483; \n",
      " validation loss : 0.598427952968316; validation accuracy : 0.9539748953974896\n",
      "Epoch 151:\t train loss : 0.5586331785168044; train accuracy : 0.9927138387186716; \n",
      " validation loss : 0.59333252218092; validation accuracy : 0.9581589958158996\n",
      "Epoch 152:\t train loss : 0.5679773772912665; train accuracy : 0.9831255615105796; \n",
      " validation loss : 0.6316051727004446; validation accuracy : 0.9205020920502092\n",
      "Epoch 153:\t train loss : 0.5631751476896346; train accuracy : 0.9880823445583816; \n",
      " validation loss : 0.6136606095984252; validation accuracy : 0.9372384937238494\n",
      "Epoch 154:\t train loss : 0.563409505151754; train accuracy : 0.9877917531522042; \n",
      " validation loss : 0.6198466574474769; validation accuracy : 0.9330543933054394\n",
      "Epoch 155:\t train loss : 0.5634899825914503; train accuracy : 0.9878286192261222; \n",
      " validation loss : 0.6078133861617986; validation accuracy : 0.9414225941422594\n",
      "Epoch 156:\t train loss : 0.5583193289634366; train accuracy : 0.9930236376591592; \n",
      " validation loss : 0.5866439511714004; validation accuracy : 0.9623430962343096\n",
      "Epoch 157:\t train loss : 0.5581400577532917; train accuracy : 0.9932559868645249; \n",
      " validation loss : 0.6006749730459927; validation accuracy : 0.9497907949790795\n",
      "Epoch 158:\t train loss : 0.5561830959488008; train accuracy : 0.9952077201895969; \n",
      " validation loss : 0.584947241412951; validation accuracy : 0.9665271966527197\n",
      "Epoch 159:\t train loss : 0.5560033095471065; train accuracy : 0.9953508473001023; \n",
      " validation loss : 0.6028944406003462; validation accuracy : 0.9497907949790795\n",
      "Epoch 160:\t train loss : 0.5649555832186571; train accuracy : 0.9864249202267729; \n",
      " validation loss : 0.6228093850834168; validation accuracy : 0.9288702928870293\n",
      "Epoch 161:\t train loss : 0.5591733467686658; train accuracy : 0.9922181604138913; \n",
      " validation loss : 0.6041080937713992; validation accuracy : 0.9456066945606695\n",
      "Epoch 162:\t train loss : 0.5578141760915497; train accuracy : 0.9935502958579882; \n",
      " validation loss : 0.6003813635382294; validation accuracy : 0.9497907949790795\n",
      "Epoch 163:\t train loss : 0.5632979799411834; train accuracy : 0.9880513646643329; \n",
      " validation loss : 0.6007927729378983; validation accuracy : 0.9497907949790795\n",
      "Epoch 164:\t train loss : 0.5575946041915715; train accuracy : 0.9937361752222807; \n",
      " validation loss : 0.6267682166755015; validation accuracy : 0.9246861924686193\n",
      "Epoch 165:\t train loss : 0.5581314607353239; train accuracy : 0.9932655906316801; \n",
      " validation loss : 0.6142235473368033; validation accuracy : 0.9372384937238494\n",
      "Epoch 166:\t train loss : 0.5578466146895462; train accuracy : 0.9935134297840701; \n",
      " validation loss : 0.6446863828662609; validation accuracy : 0.9079497907949791\n",
      "Epoch 167:\t train loss : 0.5616429586872899; train accuracy : 0.9897029028160723; \n",
      " validation loss : 0.6182737812448093; validation accuracy : 0.9330543933054394\n",
      "Epoch 168:\t train loss : 0.5620201313446204; train accuracy : 0.9893466340345116; \n",
      " validation loss : 0.6206907765682267; validation accuracy : 0.9288702928870293\n",
      "Epoch 169:\t train loss : 0.5601561331440852; train accuracy : 0.9910852256885282; \n",
      " validation loss : 0.6253198855993499; validation accuracy : 0.9246861924686193\n",
      "Epoch 170:\t train loss : 0.5597032846503268; train accuracy : 0.9916081663000712; \n",
      " validation loss : 0.624659361239515; validation accuracy : 0.9246861924686193\n",
      "Epoch 171:\t train loss : 0.5605718369791763; train accuracy : 0.990700145605502; \n",
      " validation loss : 0.6144088036433576; validation accuracy : 0.9372384937238494\n",
      "Epoch 172:\t train loss : 0.5621708515150652; train accuracy : 0.9891046810619908; \n",
      " validation loss : 0.6103563448402072; validation accuracy : 0.9414225941422594\n",
      "Epoch 173:\t train loss : 0.558418654212685; train accuracy : 0.9929344155642987; \n",
      " validation loss : 0.597891440246044; validation accuracy : 0.9539748953974896\n",
      "Epoch 174:\t train loss : 0.5583399863252954; train accuracy : 0.9930855974472567; \n",
      " validation loss : 0.5918498180495382; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175:\t train loss : 0.5578216866929829; train accuracy : 0.9936432355401345; \n",
      " validation loss : 0.6218563450272088; validation accuracy : 0.9288702928870293\n",
      "Epoch 176:\t train loss : 0.5610506154696449; train accuracy : 0.9902450509619257; \n",
      " validation loss : 0.6065651675864302; validation accuracy : 0.9456066945606695\n",
      "Epoch 177:\t train loss : 0.5582897468331738; train accuracy : 0.9931475572353542; \n",
      " validation loss : 0.6111805883632685; validation accuracy : 0.9414225941422594\n",
      "Epoch 178:\t train loss : 0.5588486200712222; train accuracy : 0.9924969794603302; \n",
      " validation loss : 0.6083349140696912; validation accuracy : 0.9414225941422594\n",
      "Epoch 179:\t train loss : 0.5657408001554313; train accuracy : 0.9853908113634251; \n",
      " validation loss : 0.6110546672750551; validation accuracy : 0.9372384937238494\n",
      "Epoch 180:\t train loss : 0.5595426442851413; train accuracy : 0.9918058180241024; \n",
      " validation loss : 0.6175033899645417; validation accuracy : 0.9330543933054394\n",
      "Epoch 181:\t train loss : 0.5583824834961227; train accuracy : 0.9929461879240373; \n",
      " validation loss : 0.6184771915296602; validation accuracy : 0.9330543933054394\n",
      "Epoch 182:\t train loss : 0.5591435714893366; train accuracy : 0.9921562006257938; \n",
      " validation loss : 0.6151204906729046; validation accuracy : 0.9372384937238494\n",
      "Epoch 183:\t train loss : 0.5581709410798996; train accuracy : 0.9932714768115493; \n",
      " validation loss : 0.6166775334827785; validation accuracy : 0.9330543933054394\n",
      "Epoch 184:\t train loss : 0.5565819222853575; train accuracy : 0.9948049815669631; \n",
      " validation loss : 0.5828620143523378; validation accuracy : 0.9665271966527197\n",
      "Epoch 185:\t train loss : 0.5571451946311717; train accuracy : 0.9942259673471917; \n",
      " validation loss : 0.5906968650154485; validation accuracy : 0.9623430962343096\n",
      "Epoch 186:\t train loss : 0.5589180726188063; train accuracy : 0.9923730598841352; \n",
      " validation loss : 0.608864390859768; validation accuracy : 0.9414225941422594\n",
      "Epoch 187:\t train loss : 0.569765631771502; train accuracy : 0.9814681371789709; \n",
      " validation loss : 0.6284638690121387; validation accuracy : 0.9205020920502092\n",
      "Epoch 188:\t train loss : 0.5637599368598951; train accuracy : 0.987584497661018; \n",
      " validation loss : 0.6464608310595796; validation accuracy : 0.899581589958159\n",
      "Epoch 189:\t train loss : 0.560000382836125; train accuracy : 0.9912326899842002; \n",
      " validation loss : 0.5839749489820635; validation accuracy : 0.9665271966527197\n",
      "Epoch 190:\t train loss : 0.5569641510442043; train accuracy : 0.9943808668174354; \n",
      " validation loss : 0.6145204093043786; validation accuracy : 0.9372384937238494\n",
      "Epoch 191:\t train loss : 0.5582600298406329; train accuracy : 0.9931165773413054; \n",
      " validation loss : 0.5932441286950676; validation accuracy : 0.9581589958158996\n",
      "Epoch 192:\t train loss : 0.5540983517048735; train accuracy : 0.9973202391647821; \n",
      " validation loss : 0.5997443907931395; validation accuracy : 0.9497907949790795\n",
      "Epoch 193:\t train loss : 0.5563081239178033; train accuracy : 0.9949812571641005; \n",
      " validation loss : 0.5829115882814468; validation accuracy : 0.9707112970711297\n",
      "Epoch 194:\t train loss : 0.5555124810197218; train accuracy : 0.9959143715728492; \n",
      " validation loss : 0.6110975119509023; validation accuracy : 0.9414225941422594\n",
      "Epoch 195:\t train loss : 0.5586009757123879; train accuracy : 0.9926983487716472; \n",
      " validation loss : 0.6100000833582081; validation accuracy : 0.9414225941422594\n",
      "Epoch 196:\t train loss : 0.5585119838803441; train accuracy : 0.992729328665696; \n",
      " validation loss : 0.6247963296963166; validation accuracy : 0.9246861924686193\n",
      "Epoch 197:\t train loss : 0.5591902230641711; train accuracy : 0.9922550264878094; \n",
      " validation loss : 0.6117111561781851; validation accuracy : 0.9372384937238494\n",
      "Epoch 198:\t train loss : 0.5548108609857542; train accuracy : 0.9966077016016605; \n",
      " validation loss : 0.5807292823402143; validation accuracy : 0.9707112970711297\n",
      "Epoch 199:\t train loss : 0.556139796541356; train accuracy : 0.995244586263515; \n",
      " validation loss : 0.6065659004988416; validation accuracy : 0.9414225941422594\n",
      "Epoch 200:\t train loss : 0.555608405165803; train accuracy : 0.9956975123145079; \n",
      " validation loss : 0.6168496960740525; validation accuracy : 0.9330543933054394\n",
      "Epoch 201:\t train loss : 0.5578685597809365; train accuracy : 0.9934942222497599; \n",
      " validation loss : 0.6089429671626932; validation accuracy : 0.9414225941422594\n",
      "Epoch 202:\t train loss : 0.5616860887966527; train accuracy : 0.9895848694197465; \n",
      " validation loss : 0.6188311692978476; validation accuracy : 0.9288702928870293\n",
      "Epoch 203:\t train loss : 0.5556559065148527; train accuracy : 0.9957343783884259; \n",
      " validation loss : 0.6128922453144575; validation accuracy : 0.9330543933054394\n",
      "Epoch 204:\t train loss : 0.5615711154026146; train accuracy : 0.9896778091018928; \n",
      " validation loss : 0.601252236196988; validation accuracy : 0.9497907949790795\n",
      "Epoch 205:\t train loss : 0.5565765870696181; train accuracy : 0.994841847640881; \n",
      " validation loss : 0.601785287448435; validation accuracy : 0.9497907949790795\n",
      "Epoch 206:\t train loss : 0.5553066245029874; train accuracy : 0.9960810434028315; \n",
      " validation loss : 0.6115881605986522; validation accuracy : 0.9372384937238494\n",
      "Epoch 207:\t train loss : 0.5542440504604567; train accuracy : 0.9971808296415626; \n",
      " validation loss : 0.5891857588578455; validation accuracy : 0.9623430962343096\n",
      "Epoch 208:\t train loss : 0.5557187818780484; train accuracy : 0.9957188884414016; \n",
      " validation loss : 0.6049783571773976; validation accuracy : 0.9456066945606695\n",
      "Epoch 209:\t train loss : 0.5583543738577024; train accuracy : 0.9929056042628334; \n",
      " validation loss : 0.5934156587588514; validation accuracy : 0.9581589958158996\n",
      "Epoch 210:\t train loss : 0.556918037948452; train accuracy : 0.9944081291241984; \n",
      " validation loss : 0.6127481976993999; validation accuracy : 0.9372384937238494\n",
      "Epoch 211:\t train loss : 0.5554004817101443; train accuracy : 0.9959977074878403; \n",
      " validation loss : 0.611034376206706; validation accuracy : 0.9414225941422594\n",
      "Epoch 212:\t train loss : 0.5553498546942994; train accuracy : 0.9960345735617584; \n",
      " validation loss : 0.6022457591140997; validation accuracy : 0.9497907949790795\n",
      "Epoch 213:\t train loss : 0.5551016299451007; train accuracy : 0.9962824127141485; \n",
      " validation loss : 0.6169431635636395; validation accuracy : 0.9330543933054394\n",
      "Epoch 214:\t train loss : 0.5549786174063189; train accuracy : 0.9964373121843924; \n",
      " validation loss : 0.5888220950551388; validation accuracy : 0.9623430962343096\n",
      "Epoch 215:\t train loss : 0.5552519281014158; train accuracy : 0.9961002509371418; \n",
      " validation loss : 0.584992952456994; validation accuracy : 0.9665271966527197\n",
      "Epoch 216:\t train loss : 0.5601531293887418; train accuracy : 0.9912364075714861; \n",
      " validation loss : 0.5917374616254446; validation accuracy : 0.9581589958158996\n",
      "Epoch 217:\t train loss : 0.5550777238567531; train accuracy : 0.9963598624492704; \n",
      " validation loss : 0.6108078905301183; validation accuracy : 0.9414225941422594\n",
      "Epoch 218:\t train loss : 0.559144040815417; train accuracy : 0.9922240465937606; \n",
      " validation loss : 0.6017691734420341; validation accuracy : 0.9497907949790795\n",
      "Epoch 219:\t train loss : 0.5630281335579592; train accuracy : 0.9882527339756498; \n",
      " validation loss : 0.5890910055397194; validation accuracy : 0.9623430962343096\n",
      "Epoch 220:\t train loss : 0.5576573074766938; train accuracy : 0.9936587254871588; \n",
      " validation loss : 0.6057029135223962; validation accuracy : 0.9456066945606695\n",
      "Epoch 221:\t train loss : 0.5553942192316302; train accuracy : 0.9959881037206852; \n",
      " validation loss : 0.6052743070259979; validation accuracy : 0.9456066945606695\n",
      "Epoch 222:\t train loss : 0.5547216804107308; train accuracy : 0.9966386814957092; \n",
      " validation loss : 0.591251175226406; validation accuracy : 0.9581589958158996\n",
      "Epoch 223:\t train loss : 0.5578248197825578; train accuracy : 0.9934942222497599; \n",
      " validation loss : 0.6154801501721164; validation accuracy : 0.9372384937238494\n",
      "Epoch 224:\t train loss : 0.556043603550822; train accuracy : 0.9953065460516125; \n",
      " validation loss : 0.6365719497518827; validation accuracy : 0.9163179916317992\n",
      "Epoch 225:\t train loss : 0.5540499717378624; train accuracy : 0.9973821989528796; \n",
      " validation loss : 0.6015750254332417; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226:\t train loss : 0.5548222924938668; train accuracy : 0.9966173053688157; \n",
      " validation loss : 0.5929975635996506; validation accuracy : 0.9581589958158996\n",
      "Epoch 227:\t train loss : 0.5616280364797728; train accuracy : 0.9896778091018928; \n",
      " validation loss : 0.6045468411123534; validation accuracy : 0.9456066945606695\n",
      "Epoch 228:\t train loss : 0.5654785481970493; train accuracy : 0.9857182688435205; \n",
      " validation loss : 0.594089068889507; validation accuracy : 0.9539748953974896\n",
      "Epoch 229:\t train loss : 0.559275821053242; train accuracy : 0.9920632609436476; \n",
      " validation loss : 0.6227041478209352; validation accuracy : 0.9288702928870293\n",
      "Epoch 230:\t train loss : 0.5580660020400218; train accuracy : 0.9933644164936956; \n",
      " validation loss : 0.6112691841368416; validation accuracy : 0.9414225941422594\n",
      "Epoch 231:\t train loss : 0.5554085188460895; train accuracy : 0.9959416338796121; \n",
      " validation loss : 0.6027046773940061; validation accuracy : 0.9456066945606695\n",
      "Epoch 232:\t train loss : 0.6130767295356728; train accuracy : 0.9374531429102513; \n",
      " validation loss : 0.6176001533865841; validation accuracy : 0.9288702928870293\n",
      "Epoch 233:\t train loss : 0.5814553754757414; train accuracy : 0.9695195018433037; \n",
      " validation loss : 0.6242279736756351; validation accuracy : 0.9246861924686193\n",
      "Epoch 234:\t train loss : 0.5779655494343504; train accuracy : 0.9729737600297407; \n",
      " validation loss : 0.6092282063536745; validation accuracy : 0.9414225941422594\n",
      "Epoch 235:\t train loss : 0.5653046011020428; train accuracy : 0.9858886582607888; \n",
      " validation loss : 0.6352570957696123; validation accuracy : 0.9163179916317992\n",
      "Epoch 236:\t train loss : 0.5674899250443551; train accuracy : 0.9836463335295393; \n",
      " validation loss : 0.5808546721674375; validation accuracy : 0.9707112970711297\n",
      "Epoch 237:\t train loss : 0.5592971382857584; train accuracy : 0.9919607174943461; \n",
      " validation loss : 0.5907485578961683; validation accuracy : 0.9623430962343096\n",
      "Epoch 238:\t train loss : 0.5610909930227598; train accuracy : 0.9901579974596487; \n",
      " validation loss : 0.584335269631618; validation accuracy : 0.9707112970711297\n",
      "Epoch 239:\t train loss : 0.5603325340391432; train accuracy : 0.990901514916819; \n",
      " validation loss : 0.5934613670822402; validation accuracy : 0.9581589958158996\n",
      "Epoch 240:\t train loss : 0.5577550741260857; train accuracy : 0.9936122556460857; \n",
      " validation loss : 0.609780280359633; validation accuracy : 0.9414225941422594\n",
      "Epoch 241:\t train loss : 0.5580377804632377; train accuracy : 0.9933275504197776; \n",
      " validation loss : 0.6007768931565985; validation accuracy : 0.9497907949790795\n",
      "Epoch 242:\t train loss : 0.5558987588597816; train accuracy : 0.995418693268069; \n",
      " validation loss : 0.6027700741961154; validation accuracy : 0.9456066945606695\n",
      "Epoch 243:\t train loss : 0.5572642565594377; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.5989070327975051; validation accuracy : 0.9497907949790795\n",
      "Epoch 244:\t train loss : 0.5574766151282636; train accuracy : 0.9938195111372718; \n",
      " validation loss : 0.603341350717934; validation accuracy : 0.9497907949790795\n",
      "Epoch 245:\t train loss : 0.5582545252701647; train accuracy : 0.993014033892004; \n",
      " validation loss : 0.5932177789421127; validation accuracy : 0.9581589958158996\n",
      "Epoch 246:\t train loss : 0.555763334760838; train accuracy : 0.9955234053099539; \n",
      " validation loss : 0.5887932411335145; validation accuracy : 0.9623430962343096\n",
      "Epoch 247:\t train loss : 0.5595631010671772; train accuracy : 0.9917283682889805; \n",
      " validation loss : 0.6044128153761014; validation accuracy : 0.9456066945606695\n",
      "Epoch 248:\t train loss : 0.5578987806259578; train accuracy : 0.9932928529384429; \n",
      " validation loss : 0.619043444364511; validation accuracy : 0.9330543933054394\n",
      "Early stopping at epoch 248\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5548108609857542; Train accuracy : 0.9966077016016605; \n",
      " Validation loss : 0.5807292823402143; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 40 ! ---\n",
      "Epoch 1:\t train loss : 0.9401290548281913; train accuracy : 0.5924746739366151; \n",
      " validation loss : 0.8015697776562264; validation accuracy : 0.7489539748953975\n",
      "Epoch 2:\t train loss : 0.7476038532524313; train accuracy : 0.8024325412807088; \n",
      " validation loss : 0.7428103975671781; validation accuracy : 0.8117154811715481\n",
      "Epoch 3:\t train loss : 0.7069314561848822; train accuracy : 0.8432603240496918; \n",
      " validation loss : 0.6973789699645196; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.6894950006375905; train accuracy : 0.8607174943461693; \n",
      " validation loss : 0.6817794989837473; validation accuracy : 0.8661087866108786\n",
      "Epoch 5:\t train loss : 0.681499467721732; train accuracy : 0.8684971653396946; \n",
      " validation loss : 0.7019526452646254; validation accuracy : 0.8451882845188284\n",
      "Epoch 6:\t train loss : 0.6673061447497622; train accuracy : 0.8820375476315871; \n",
      " validation loss : 0.6997204890533623; validation accuracy : 0.8451882845188284\n",
      "Epoch 7:\t train loss : 0.6615161032903127; train accuracy : 0.8884135196257629; \n",
      " validation loss : 0.6497611851989827; validation accuracy : 0.9037656903765691\n",
      "Epoch 8:\t train loss : 0.6393084894594483; train accuracy : 0.9110737631277301; \n",
      " validation loss : 0.6657037900430307; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6279154180190133; train accuracy : 0.9230821896589113; \n",
      " validation loss : 0.6394830048885035; validation accuracy : 0.9121338912133892\n",
      "Epoch 10:\t train loss : 0.6136826230987198; train accuracy : 0.9376176461476502; \n",
      " validation loss : 0.6452213291831758; validation accuracy : 0.9037656903765691\n",
      "Epoch 11:\t train loss : 0.6023586690232757; train accuracy : 0.9491598252733976; \n",
      " validation loss : 0.6165512522104867; validation accuracy : 0.9372384937238494\n",
      "Epoch 12:\t train loss : 0.5986731179918384; train accuracy : 0.9529681836488119; \n",
      " validation loss : 0.6288364424243249; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.5970383300905657; train accuracy : 0.9538591654016543; \n",
      " validation loss : 0.6147414180370008; validation accuracy : 0.9414225941422594\n",
      "Epoch 14:\t train loss : 0.5904898929822961; train accuracy : 0.9613696211158957; \n",
      " validation loss : 0.6202285942935863; validation accuracy : 0.9330543933054394\n",
      "Epoch 15:\t train loss : 0.5871551000356984; train accuracy : 0.9646091886365749; \n",
      " validation loss : 0.6333451687031252; validation accuracy : 0.9163179916317992\n",
      "Epoch 16:\t train loss : 0.5850481099470491; train accuracy : 0.966080733603891; \n",
      " validation loss : 0.598452439129977; validation accuracy : 0.9581589958158996\n",
      "Epoch 17:\t train loss : 0.5853819106284341; train accuracy : 0.9658366120387868; \n",
      " validation loss : 0.6034792305505791; validation accuracy : 0.9539748953974896\n",
      "Epoch 18:\t train loss : 0.5851016728433458; train accuracy : 0.966282102915208; \n",
      " validation loss : 0.6080053202444667; validation accuracy : 0.9456066945606695\n",
      "Epoch 19:\t train loss : 0.5873435374513809; train accuracy : 0.964041946776542; \n",
      " validation loss : 0.6000781369777757; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5839793104015287; train accuracy : 0.9671436537687041; \n",
      " validation loss : 0.6055050536428271; validation accuracy : 0.9456066945606695\n",
      "Epoch 21:\t train loss : 0.5803106950258127; train accuracy : 0.9707779051395644; \n",
      " validation loss : 0.5992822091643883; validation accuracy : 0.9497907949790795\n",
      "Epoch 22:\t train loss : 0.5798408001474225; train accuracy : 0.9714151615601475; \n",
      " validation loss : 0.6073732901074423; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.578847076705184; train accuracy : 0.9722110350382601; \n",
      " validation loss : 0.6150711591289229; validation accuracy : 0.9330543933054394\n",
      "Epoch 24:\t train loss : 0.5776312592837762; train accuracy : 0.9735874717308467; \n",
      " validation loss : 0.6057144065795212; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5829463714511744; train accuracy : 0.96834815204932; \n",
      " validation loss : 0.6179901148163126; validation accuracy : 0.9330543933054394\n",
      "Epoch 26:\t train loss : 0.5810407161745975; train accuracy : 0.9699259580532235; \n",
      " validation loss : 0.6121113820375657; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5809138508321852; train accuracy : 0.9704798785588153; \n",
      " validation loss : 0.6046697748224084; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:\t train loss : 0.5811918134961171; train accuracy : 0.9700306700951082; \n",
      " validation loss : 0.6372984981548805; validation accuracy : 0.9121338912133892\n",
      "Epoch 29:\t train loss : 0.5834425522388567; train accuracy : 0.9676724805601165; \n",
      " validation loss : 0.6065514924362765; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5762445890194298; train accuracy : 0.9747647077046997; \n",
      " validation loss : 0.6121180214568203; validation accuracy : 0.9330543933054394\n",
      "Epoch 31:\t train loss : 0.5816637511659662; train accuracy : 0.9692038167229468; \n",
      " validation loss : 0.5893213529574237; validation accuracy : 0.9623430962343096\n",
      "Epoch 32:\t train loss : 0.5726443985054445; train accuracy : 0.9785132748845999; \n",
      " validation loss : 0.6103899129299258; validation accuracy : 0.9414225941422594\n",
      "Epoch 33:\t train loss : 0.575855574968399; train accuracy : 0.975256668422194; \n",
      " validation loss : 0.6167287098835699; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.5855359752813845; train accuracy : 0.9650274172062332; \n",
      " validation loss : 0.6037854948876549; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.5712706162891573; train accuracy : 0.979764243006289; \n",
      " validation loss : 0.5993878678582951; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5669959515837583; train accuracy : 0.9843086836643019; \n",
      " validation loss : 0.614832096755047; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5670833131064594; train accuracy : 0.9843706434523994; \n",
      " validation loss : 0.5967844803204666; validation accuracy : 0.9581589958158996\n",
      "Epoch 38:\t train loss : 0.563738771409708; train accuracy : 0.987698813470058; \n",
      " validation loss : 0.6096620105021496; validation accuracy : 0.9414225941422594\n",
      "Epoch 39:\t train loss : 0.5665512172377546; train accuracy : 0.9848294556832615; \n",
      " validation loss : 0.6109309619835344; validation accuracy : 0.9372384937238494\n",
      "Epoch 40:\t train loss : 0.5827323001580491; train accuracy : 0.967935809659531; \n",
      " validation loss : 0.6039596649597192; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5676877085889163; train accuracy : 0.9835128101861892; \n",
      " validation loss : 0.6205293490894057; validation accuracy : 0.9288702928870293\n",
      "Epoch 42:\t train loss : 0.5671982236665749; train accuracy : 0.9840955419932463; \n",
      " validation loss : 0.6056243259964716; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5676517682943194; train accuracy : 0.9833365345890517; \n",
      " validation loss : 0.6178959371005663; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5674050403008406; train accuracy : 0.9838941726819295; \n",
      " validation loss : 0.5985713248439594; validation accuracy : 0.9497907949790795\n",
      "Epoch 45:\t train loss : 0.5646732047708368; train accuracy : 0.9864617863006908; \n",
      " validation loss : 0.61409410260792; validation accuracy : 0.9330543933054394\n",
      "Epoch 46:\t train loss : 0.5635606471737253; train accuracy : 0.9876235323275194; \n",
      " validation loss : 0.6239473321672716; validation accuracy : 0.9246861924686193\n",
      "Epoch 47:\t train loss : 0.5657086663176579; train accuracy : 0.9854527711515226; \n",
      " validation loss : 0.6433136718394327; validation accuracy : 0.9037656903765691\n",
      "Epoch 48:\t train loss : 0.5635141274074583; train accuracy : 0.9878905790142197; \n",
      " validation loss : 0.6094752572317196; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.578852474651049; train accuracy : 0.9721527928374485; \n",
      " validation loss : 0.6421162324273129; validation accuracy : 0.9079497907949791\n",
      "Epoch 50:\t train loss : 0.5749558248352794; train accuracy : 0.9762480250317543; \n",
      " validation loss : 0.6080866580958871; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5737660539751869; train accuracy : 0.977047616097153; \n",
      " validation loss : 0.5931946018760184; validation accuracy : 0.9623430962343096\n",
      "Epoch 52:\t train loss : 0.5741525094653922; train accuracy : 0.9764936955915611; \n",
      " validation loss : 0.6061062384752047; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.576050657374369; train accuracy : 0.9749254933548127; \n",
      " validation loss : 0.6142473218552003; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5669449154532203; train accuracy : 0.9842969113045633; \n",
      " validation loss : 0.5834530145308654; validation accuracy : 0.9623430962343096\n",
      "Epoch 55:\t train loss : 0.5674792537802367; train accuracy : 0.9836426159422534; \n",
      " validation loss : 0.5926067547468964; validation accuracy : 0.9581589958158996\n",
      "Epoch 56:\t train loss : 0.5697933334408757; train accuracy : 0.9815669630409865; \n",
      " validation loss : 0.5926275944276235; validation accuracy : 0.9623430962343096\n",
      "Epoch 57:\t train loss : 0.5664356108418993; train accuracy : 0.984881811704204; \n",
      " validation loss : 0.5908871217761744; validation accuracy : 0.9581589958158996\n",
      "Epoch 58:\t train loss : 0.5641006298287652; train accuracy : 0.9873447132810805; \n",
      " validation loss : 0.6188414277522878; validation accuracy : 0.9288702928870293\n",
      "Epoch 59:\t train loss : 0.5762039463049403; train accuracy : 0.9746968617367329; \n",
      " validation loss : 0.6077833156311563; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5708544553864228; train accuracy : 0.9803757861148115; \n",
      " validation loss : 0.6062266161605857; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5691271499574124; train accuracy : 0.9819173456426779; \n",
      " validation loss : 0.5991964519876213; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5649275400077184; train accuracy : 0.9862390408624803; \n",
      " validation loss : 0.6038784188284725; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5660646741826563; train accuracy : 0.9851333684438799; \n",
      " validation loss : 0.5939930227673688; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5653066710750324; train accuracy : 0.9859137519749682; \n",
      " validation loss : 0.6093686251938292; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.5659955028921138; train accuracy : 0.9853000402738623; \n",
      " validation loss : 0.6058890258796421; validation accuracy : 0.9456066945606695\n",
      "Epoch 66:\t train loss : 0.5640843922554145; train accuracy : 0.9873484308683664; \n",
      " validation loss : 0.5908983300801985; validation accuracy : 0.9581589958158996\n",
      "Epoch 67:\t train loss : 0.5692628187128457; train accuracy : 0.9819520431240125; \n",
      " validation loss : 0.6018188428842624; validation accuracy : 0.9497907949790795\n",
      "Epoch 68:\t train loss : 0.5678015843854682; train accuracy : 0.9834139843241736; \n",
      " validation loss : 0.5904111402637291; validation accuracy : 0.9623430962343096\n",
      "Epoch 69:\t train loss : 0.5648419180211104; train accuracy : 0.9864772762477152; \n",
      " validation loss : 0.5834449004416046; validation accuracy : 0.9665271966527197\n",
      "Epoch 70:\t train loss : 0.560744923310647; train accuracy : 0.9905452461352582; \n",
      " validation loss : 0.6023209470959607; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5613936011867439; train accuracy : 0.989962514328201; \n",
      " validation loss : 0.5978176215148236; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5707874302933879; train accuracy : 0.9802754112580935; \n",
      " validation loss : 0.592837642537921; validation accuracy : 0.9581589958158996\n",
      "Epoch 73:\t train loss : 0.5646288323027662; train accuracy : 0.9867096254530809; \n",
      " validation loss : 0.6157820780938016; validation accuracy : 0.9330543933054394\n",
      "Epoch 74:\t train loss : 0.5652956175024867; train accuracy : 0.9860066916571145; \n",
      " validation loss : 0.5767006601036715; validation accuracy : 0.9748953974895398\n",
      "Epoch 75:\t train loss : 0.5632507581320618; train accuracy : 0.9878905790142197; \n",
      " validation loss : 0.5949266147539038; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5665026932902038; train accuracy : 0.9846686700331485; \n",
      " validation loss : 0.6193023517410354; validation accuracy : 0.9330543933054394\n",
      "Epoch 77:\t train loss : 0.5649744052261071; train accuracy : 0.9863010006505778; \n",
      " validation loss : 0.6010709042324734; validation accuracy : 0.9456066945606695\n",
      "Epoch 78:\t train loss : 0.5642552535613256; train accuracy : 0.9869552960128877; \n",
      " validation loss : 0.6123900747447995; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79:\t train loss : 0.5805131995007055; train accuracy : 0.9703928250565383; \n",
      " validation loss : 0.6320243751317925; validation accuracy : 0.9163179916317992\n",
      "Epoch 80:\t train loss : 0.5673069293785366; train accuracy : 0.9838477028408563; \n",
      " validation loss : 0.6087336716782036; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.5645334788464683; train accuracy : 0.9866476656649834; \n",
      " validation loss : 0.597309873739753; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5693745260725419; train accuracy : 0.9818863657486291; \n",
      " validation loss : 0.5914573485809789; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5625179243876333; train accuracy : 0.9888199758356826; \n",
      " validation loss : 0.595771625678611; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5620720630346262; train accuracy : 0.9892809566591282; \n",
      " validation loss : 0.5857110932896741; validation accuracy : 0.9665271966527197\n",
      "Epoch 85:\t train loss : 0.5617654821550804; train accuracy : 0.989563493292853; \n",
      " validation loss : 0.5947880063267684; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.567449888674643; train accuracy : 0.9838380990737011; \n",
      " validation loss : 0.6007921004456279; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5678219581161505; train accuracy : 0.9834545679853774; \n",
      " validation loss : 0.6011820864794305; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5654581275245687; train accuracy : 0.9857898323987732; \n",
      " validation loss : 0.59400286446821; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5622942833401077; train accuracy : 0.9889091979305431; \n",
      " validation loss : 0.6048374165412675; validation accuracy : 0.9456066945606695\n",
      "Epoch 90:\t train loss : 0.5603512574082372; train accuracy : 0.9910158307258589; \n",
      " validation loss : 0.6039593573415972; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5587476444775221; train accuracy : 0.9927352148455653; \n",
      " validation loss : 0.5875112976781445; validation accuracy : 0.9623430962343096\n",
      "Epoch 92:\t train loss : 0.5614003432416184; train accuracy : 0.9899934942222498; \n",
      " validation loss : 0.5912722268585721; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5633711173702368; train accuracy : 0.9879274450881378; \n",
      " validation loss : 0.6021042915861236; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5625058686985481; train accuracy : 0.9887735059946094; \n",
      " validation loss : 0.6002115614407659; validation accuracy : 0.9497907949790795\n",
      "Epoch 95:\t train loss : 0.5630547989506011; train accuracy : 0.9882527339756498; \n",
      " validation loss : 0.5829389339899183; validation accuracy : 0.9665271966527197\n",
      "Epoch 96:\t train loss : 0.5592689030512848; train accuracy : 0.9922122742340221; \n",
      " validation loss : 0.5970632362218427; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5642216435649178; train accuracy : 0.9869825583196505; \n",
      " validation loss : 0.604168542387384; validation accuracy : 0.9456066945606695\n",
      "Epoch 98:\t train loss : 0.5641443069420409; train accuracy : 0.9869707859599121; \n",
      " validation loss : 0.6225147063113338; validation accuracy : 0.9288702928870293\n",
      "Epoch 99:\t train loss : 0.5640113839371887; train accuracy : 0.9872554911862201; \n",
      " validation loss : 0.5966350068062718; validation accuracy : 0.9539748953974896\n",
      "Epoch 100:\t train loss : 0.5654106216799136; train accuracy : 0.9856717990024474; \n",
      " validation loss : 0.6030194549573741; validation accuracy : 0.9456066945606695\n",
      "Epoch 101:\t train loss : 0.5590518868588916; train accuracy : 0.9923634561169801; \n",
      " validation loss : 0.5887054525947938; validation accuracy : 0.9665271966527197\n",
      "Epoch 102:\t train loss : 0.5590185061247374; train accuracy : 0.9923575699371108; \n",
      " validation loss : 0.6181462134840824; validation accuracy : 0.9288702928870293\n",
      "Epoch 103:\t train loss : 0.5812109113883919; train accuracy : 0.969813810836767; \n",
      " validation loss : 0.6149118665364119; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.5672263272916418; train accuracy : 0.983905945041668; \n",
      " validation loss : 0.6143805161334434; validation accuracy : 0.9372384937238494\n",
      "Epoch 105:\t train loss : 0.5654682477278008; train accuracy : 0.9857278726106756; \n",
      " validation loss : 0.5975518237585927; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5640426244141563; train accuracy : 0.987158833916788; \n",
      " validation loss : 0.5892907992305497; validation accuracy : 0.9623430962343096\n",
      "Epoch 107:\t train loss : 0.5649065577257295; train accuracy : 0.9863784503856997; \n",
      " validation loss : 0.600815138035263; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.5651259384879597; train accuracy : 0.9860125778369838; \n",
      " validation loss : 0.6045508913469255; validation accuracy : 0.9456066945606695\n",
      "Epoch 109:\t train loss : 0.5641090150473124; train accuracy : 0.98723628365191; \n",
      " validation loss : 0.5941055652270631; validation accuracy : 0.9581589958158996\n",
      "Epoch 110:\t train loss : 0.5589986644428295; train accuracy : 0.9923420799900864; \n",
      " validation loss : 0.5812389767812286; validation accuracy : 0.9707112970711297\n",
      "Epoch 111:\t train loss : 0.5620419604521081; train accuracy : 0.9892964466061526; \n",
      " validation loss : 0.5884054102426233; validation accuracy : 0.9623430962343096\n",
      "Epoch 112:\t train loss : 0.56078252725586; train accuracy : 0.990576226029307; \n",
      " validation loss : 0.5985213375130383; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5653494846912545; train accuracy : 0.9856445366956845; \n",
      " validation loss : 0.6114092278382306; validation accuracy : 0.9372384937238494\n",
      "Epoch 114:\t train loss : 0.5697104033277232; train accuracy : 0.9813612565445026; \n",
      " validation loss : 0.6564795097478612; validation accuracy : 0.895397489539749\n",
      "Epoch 115:\t train loss : 0.5744071323840662; train accuracy : 0.9766972334954614; \n",
      " validation loss : 0.5849716898115573; validation accuracy : 0.9665271966527197\n",
      "Epoch 116:\t train loss : 0.5638223689872744; train accuracy : 0.987447256730382; \n",
      " validation loss : 0.5976875831544531; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.563482110765564; train accuracy : 0.9877784317977633; \n",
      " validation loss : 0.5772627705253418; validation accuracy : 0.9748953974895398\n",
      "Epoch 118:\t train loss : 0.5616727005396892; train accuracy : 0.9895752656525915; \n",
      " validation loss : 0.590903218179614; validation accuracy : 0.9581589958158996\n",
      "Epoch 119:\t train loss : 0.5630429098859211; train accuracy : 0.9882409616159112; \n",
      " validation loss : 0.6213373812294946; validation accuracy : 0.9288702928870293\n",
      "Epoch 120:\t train loss : 0.5630380624733484; train accuracy : 0.9882062641345767; \n",
      " validation loss : 0.6063201099333078; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5627712038932715; train accuracy : 0.988547042969113; \n",
      " validation loss : 0.598737228944907; validation accuracy : 0.9497907949790795\n",
      "Epoch 122:\t train loss : 0.5613362781495923; train accuracy : 0.9898770098206264; \n",
      " validation loss : 0.6080619002974609; validation accuracy : 0.9414225941422594\n",
      "Epoch 123:\t train loss : 0.5626545607450038; train accuracy : 0.9886554725982837; \n",
      " validation loss : 0.5930035069715746; validation accuracy : 0.9581589958158996\n",
      "Epoch 124:\t train loss : 0.5610661494393239; train accuracy : 0.990250937141795; \n",
      " validation loss : 0.6036037951423718; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 124\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5652956175024867; Train accuracy : 0.9860066916571145; \n",
      " Validation loss : 0.5767006601036715; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 41 ! ---\n",
      "Epoch 1:\t train loss : 0.9602344315154546; train accuracy : 0.5627569007713994; \n",
      " validation loss : 0.8215176437801823; validation accuracy : 0.7322175732217573\n",
      "Epoch 2:\t train loss : 0.7524996941596594; train accuracy : 0.7971108150810124; \n",
      " validation loss : 0.6981434488911571; validation accuracy : 0.8451882845188284\n",
      "Epoch 3:\t train loss : 0.6994695784314549; train accuracy : 0.850238235385235; \n",
      " validation loss : 0.6791386842413806; validation accuracy : 0.8744769874476988\n",
      "Epoch 4:\t train loss : 0.6817781014813943; train accuracy : 0.8684891105672419; \n",
      " validation loss : 0.6713906961273378; validation accuracy : 0.8828451882845189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\t train loss : 0.6640579764335732; train accuracy : 0.885632764335946; \n",
      " validation loss : 0.6573885826598891; validation accuracy : 0.891213389121339\n",
      "Epoch 6:\t train loss : 0.6439766756205355; train accuracy : 0.9069918522878652; \n",
      " validation loss : 0.6350203666239337; validation accuracy : 0.9121338912133892\n",
      "Epoch 7:\t train loss : 0.6268233909824225; train accuracy : 0.9240580563214473; \n",
      " validation loss : 0.6183124859129359; validation accuracy : 0.9288702928870293\n",
      "Epoch 8:\t train loss : 0.6115741655146038; train accuracy : 0.9399042721273894; \n",
      " validation loss : 0.6166101931414426; validation accuracy : 0.9330543933054394\n",
      "Epoch 9:\t train loss : 0.622396568717558; train accuracy : 0.9282381734254469; \n",
      " validation loss : 0.6503396294402316; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.6197612140267144; train accuracy : 0.9307128473620621; \n",
      " validation loss : 0.6116238945057105; validation accuracy : 0.9456066945606695\n",
      "Epoch 11:\t train loss : 0.6093326887738773; train accuracy : 0.9416140524799406; \n",
      " validation loss : 0.608239375273544; validation accuracy : 0.9456066945606695\n",
      "Epoch 12:\t train loss : 0.6063107928946558; train accuracy : 0.944603612255646; \n",
      " validation loss : 0.5999279647724598; validation accuracy : 0.9539748953974896\n",
      "Epoch 13:\t train loss : 0.5957282550596693; train accuracy : 0.9550844202112829; \n",
      " validation loss : 0.602766206589272; validation accuracy : 0.9497907949790795\n",
      "Epoch 14:\t train loss : 0.5956095360936972; train accuracy : 0.9553808977973295; \n",
      " validation loss : 0.5936884913579921; validation accuracy : 0.9581589958158996\n",
      "Epoch 15:\t train loss : 0.5948471824464103; train accuracy : 0.9557777502400941; \n",
      " validation loss : 0.6110333851738873; validation accuracy : 0.9414225941422594\n",
      "Epoch 16:\t train loss : 0.5880782194096592; train accuracy : 0.9633117506738127; \n",
      " validation loss : 0.5914038355665755; validation accuracy : 0.9623430962343096\n",
      "Epoch 17:\t train loss : 0.5860100416618065; train accuracy : 0.9654493633631773; \n",
      " validation loss : 0.6025773836861656; validation accuracy : 0.9497907949790795\n",
      "Epoch 18:\t train loss : 0.5894763445762699; train accuracy : 0.9614957092846742; \n",
      " validation loss : 0.5973518613182062; validation accuracy : 0.9497907949790795\n",
      "Epoch 19:\t train loss : 0.5880926442046478; train accuracy : 0.9628758635645466; \n",
      " validation loss : 0.6037677413579186; validation accuracy : 0.9456066945606695\n",
      "Epoch 20:\t train loss : 0.5878715563149445; train accuracy : 0.9634297840701385; \n",
      " validation loss : 0.5941130428076753; validation accuracy : 0.9581589958158996\n",
      "Epoch 21:\t train loss : 0.5846033611233246; train accuracy : 0.9665528671891942; \n",
      " validation loss : 0.5943464328332091; validation accuracy : 0.9539748953974896\n",
      "Epoch 22:\t train loss : 0.5971634937764405; train accuracy : 0.9536497413178847; \n",
      " validation loss : 0.6143946710969224; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5926240162434283; train accuracy : 0.958071811394405; \n",
      " validation loss : 0.6082337975827719; validation accuracy : 0.9456066945606695\n",
      "Epoch 24:\t train loss : 0.587922943441237; train accuracy : 0.9631568512035689; \n",
      " validation loss : 0.6111089393455371; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.582341040628829; train accuracy : 0.9686285200904613; \n",
      " validation loss : 0.5916536654770022; validation accuracy : 0.9623430962343096\n",
      "Epoch 26:\t train loss : 0.5773798123831085; train accuracy : 0.9741451098237244; \n",
      " validation loss : 0.6034436664405111; validation accuracy : 0.9456066945606695\n",
      "Epoch 27:\t train loss : 0.57817009232431; train accuracy : 0.9730549273521485; \n",
      " validation loss : 0.5914780332363692; validation accuracy : 0.9581589958158996\n",
      "Epoch 28:\t train loss : 0.5826659642728754; train accuracy : 0.9684175470119892; \n",
      " validation loss : 0.6124174680691165; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5815727555324471; train accuracy : 0.969461259642492; \n",
      " validation loss : 0.607491302230586; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.5845238582910612; train accuracy : 0.9664775860466557; \n",
      " validation loss : 0.5897552117734398; validation accuracy : 0.9623430962343096\n",
      "Epoch 31:\t train loss : 0.5815296913184543; train accuracy : 0.9695910653985563; \n",
      " validation loss : 0.6022496316476416; validation accuracy : 0.9456066945606695\n",
      "Epoch 32:\t train loss : 0.5768564066664579; train accuracy : 0.9744896062455466; \n",
      " validation loss : 0.614086105847589; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5772739824877314; train accuracy : 0.9738102171690572; \n",
      " validation loss : 0.5952556772185101; validation accuracy : 0.9497907949790795\n",
      "Epoch 34:\t train loss : 0.5869684081976663; train accuracy : 0.9637919390315685; \n",
      " validation loss : 0.5881198377503685; validation accuracy : 0.9665271966527197\n",
      "Epoch 35:\t train loss : 0.5776638469840596; train accuracy : 0.9734635521546516; \n",
      " validation loss : 0.5906995787912871; validation accuracy : 0.9623430962343096\n",
      "Epoch 36:\t train loss : 0.57975047083272; train accuracy : 0.9712057374763778; \n",
      " validation loss : 0.6094214689855056; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.5752611399117632; train accuracy : 0.9758858700703243; \n",
      " validation loss : 0.6122975312424744; validation accuracy : 0.9372384937238494\n",
      "Epoch 38:\t train loss : 0.5795987547905359; train accuracy : 0.9716394559930605; \n",
      " validation loss : 0.5839498655785262; validation accuracy : 0.9707112970711297\n",
      "Epoch 39:\t train loss : 0.5729611433394558; train accuracy : 0.9779711267387465; \n",
      " validation loss : 0.6011015874770053; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.5762158037555046; train accuracy : 0.9750088292698039; \n",
      " validation loss : 0.6071123345910472; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5970281412681532; train accuracy : 0.9538938628829889; \n",
      " validation loss : 0.5932496485785355; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.5786955734563394; train accuracy : 0.9722959199479537; \n",
      " validation loss : 0.5999839668194779; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.5800364224939483; train accuracy : 0.9707469252455156; \n",
      " validation loss : 0.6030401405839209; validation accuracy : 0.9456066945606695\n",
      "Epoch 44:\t train loss : 0.5715643347435444; train accuracy : 0.9796809070912977; \n",
      " validation loss : 0.6066553452059746; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.5737710861008039; train accuracy : 0.9774289785928932; \n",
      " validation loss : 0.581343527843645; validation accuracy : 0.9707112970711297\n",
      "Epoch 46:\t train loss : 0.5769711172869706; train accuracy : 0.9739474580996933; \n",
      " validation loss : 0.6065376729922123; validation accuracy : 0.9414225941422594\n",
      "Epoch 47:\t train loss : 0.5754180317835315; train accuracy : 0.9755296012887636; \n",
      " validation loss : 0.5843008633001532; validation accuracy : 0.9748953974895398\n",
      "Epoch 48:\t train loss : 0.5761907791817665; train accuracy : 0.9747588215248304; \n",
      " validation loss : 0.5978617380847944; validation accuracy : 0.9581589958158996\n",
      "Epoch 49:\t train loss : 0.5675948191243723; train accuracy : 0.9835998636884662; \n",
      " validation loss : 0.5888138464541095; validation accuracy : 0.9623430962343096\n",
      "Epoch 50:\t train loss : 0.5684824949284873; train accuracy : 0.9826682982744199; \n",
      " validation loss : 0.6078349352938904; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5695791655119744; train accuracy : 0.9814991170730196; \n",
      " validation loss : 0.6118526886703252; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5673740516489092; train accuracy : 0.9837392732116856; \n",
      " validation loss : 0.5969590490722129; validation accuracy : 0.9539748953974896\n",
      "Epoch 53:\t train loss : 0.5719955748104576; train accuracy : 0.9790089531893801; \n",
      " validation loss : 0.5914348673140182; validation accuracy : 0.9623430962343096\n",
      "Epoch 54:\t train loss : 0.568689730643249; train accuracy : 0.9825428297035225; \n",
      " validation loss : 0.5797174669095411; validation accuracy : 0.9748953974895398\n",
      "Epoch 55:\t train loss : 0.5676978150508512; train accuracy : 0.98339260819728; \n",
      " validation loss : 0.593780182471821; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56:\t train loss : 0.577154089559018; train accuracy : 0.9736649214659686; \n",
      " validation loss : 0.6682227115448027; validation accuracy : 0.8870292887029289\n",
      "Epoch 57:\t train loss : 0.572406597368743; train accuracy : 0.9788444499519812; \n",
      " validation loss : 0.5984999824394299; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.56586088674801; train accuracy : 0.9854992409925958; \n",
      " validation loss : 0.6116847046687333; validation accuracy : 0.9372384937238494\n",
      "Epoch 59:\t train loss : 0.5652996949382976; train accuracy : 0.9860280677840082; \n",
      " validation loss : 0.5931077054985396; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5792212408429327; train accuracy : 0.9717345642677903; \n",
      " validation loss : 0.5877454500166612; validation accuracy : 0.9623430962343096\n",
      "Epoch 61:\t train loss : 0.5729757469791448; train accuracy : 0.9781377985687288; \n",
      " validation loss : 0.5898746818074603; validation accuracy : 0.9623430962343096\n",
      "Epoch 62:\t train loss : 0.5702980519001979; train accuracy : 0.9810904922705165; \n",
      " validation loss : 0.5907381773648896; validation accuracy : 0.9623430962343096\n",
      "Epoch 63:\t train loss : 0.5661531489899994; train accuracy : 0.9851761206976672; \n",
      " validation loss : 0.5761539044509975; validation accuracy : 0.9748953974895398\n",
      "Epoch 64:\t train loss : 0.571465996589697; train accuracy : 0.9797952229003377; \n",
      " validation loss : 0.5822250875267964; validation accuracy : 0.9707112970711297\n",
      "Epoch 65:\t train loss : 0.5684175977397067; train accuracy : 0.9828002726230677; \n",
      " validation loss : 0.5724081258088511; validation accuracy : 0.9790794979079498\n",
      "Epoch 66:\t train loss : 0.5638449764418325; train accuracy : 0.9872672635459587; \n",
      " validation loss : 0.5767248222318203; validation accuracy : 0.9748953974895398\n",
      "Epoch 67:\t train loss : 0.5636131213140293; train accuracy : 0.9875652901267078; \n",
      " validation loss : 0.5826219840706635; validation accuracy : 0.9707112970711297\n",
      "Epoch 68:\t train loss : 0.5676410164012108; train accuracy : 0.9833984943771492; \n",
      " validation loss : 0.6024271161856045; validation accuracy : 0.9497907949790795\n",
      "Epoch 69:\t train loss : 0.5721340127660617; train accuracy : 0.9791948325536727; \n",
      " validation loss : 0.5919132124555765; validation accuracy : 0.9623430962343096\n",
      "Epoch 70:\t train loss : 0.5684910676042509; train accuracy : 0.9826549769199789; \n",
      " validation loss : 0.5870223788213809; validation accuracy : 0.9665271966527197\n",
      "Epoch 71:\t train loss : 0.5655151709078051; train accuracy : 0.9856659128225782; \n",
      " validation loss : 0.5795673333425819; validation accuracy : 0.9665271966527197\n",
      "Epoch 72:\t train loss : 0.5663039781843273; train accuracy : 0.984881811704204; \n",
      " validation loss : 0.5821551016612597; validation accuracy : 0.9665271966527197\n",
      "Epoch 73:\t train loss : 0.582680375221523; train accuracy : 0.9682936274357942; \n",
      " validation loss : 0.5975723503762125; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5667774472731654; train accuracy : 0.9844518107748071; \n",
      " validation loss : 0.5946348639784774; validation accuracy : 0.9581589958158996\n",
      "Epoch 75:\t train loss : 0.5659608003020498; train accuracy : 0.9852845503268379; \n",
      " validation loss : 0.5818430562126636; validation accuracy : 0.9707112970711297\n",
      "Epoch 76:\t train loss : 0.5625024011037925; train accuracy : 0.9888007683013724; \n",
      " validation loss : 0.5855317047903935; validation accuracy : 0.9623430962343096\n",
      "Epoch 77:\t train loss : 0.5633725962515281; train accuracy : 0.9879119551411134; \n",
      " validation loss : 0.6147814518750117; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5728810238738747; train accuracy : 0.9782307382508751; \n",
      " validation loss : 0.6150397062297384; validation accuracy : 0.9330543933054394\n",
      "Epoch 79:\t train loss : 0.5642744257479487; train accuracy : 0.9869980482666749; \n",
      " validation loss : 0.5893482133462261; validation accuracy : 0.9623430962343096\n",
      "Epoch 80:\t train loss : 0.5590887886415722; train accuracy : 0.9923634561169801; \n",
      " validation loss : 0.5909219945807284; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5620206407315071; train accuracy : 0.9892691842993897; \n",
      " validation loss : 0.6002480775390104; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5622065217562429; train accuracy : 0.9891025124694074; \n",
      " validation loss : 0.5925213767323194; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.564118025584693; train accuracy : 0.986920598531553; \n",
      " validation loss : 0.5879313384779807; validation accuracy : 0.9665271966527197\n",
      "Epoch 84:\t train loss : 0.5678097763749097; train accuracy : 0.9833461383562069; \n",
      " validation loss : 0.5770472622103952; validation accuracy : 0.9748953974895398\n",
      "Epoch 85:\t train loss : 0.5633036605066881; train accuracy : 0.9879156727283993; \n",
      " validation loss : 0.6041545069134802; validation accuracy : 0.9456066945606695\n",
      "Epoch 86:\t train loss : 0.5657644701859804; train accuracy : 0.9854004151305803; \n",
      " validation loss : 0.6039265033755141; validation accuracy : 0.9414225941422594\n",
      "Epoch 87:\t train loss : 0.5763458907622225; train accuracy : 0.9744821710709749; \n",
      " validation loss : 0.576919319740271; validation accuracy : 0.9748953974895398\n",
      "Epoch 88:\t train loss : 0.5660502680877308; train accuracy : 0.9852225905387404; \n",
      " validation loss : 0.5874902896698917; validation accuracy : 0.9623430962343096\n",
      "Epoch 89:\t train loss : 0.5648552251184425; train accuracy : 0.9863688466185445; \n",
      " validation loss : 0.5849108956620743; validation accuracy : 0.9623430962343096\n",
      "Epoch 90:\t train loss : 0.5639079599613694; train accuracy : 0.9872901886675548; \n",
      " validation loss : 0.599424916063311; validation accuracy : 0.9497907949790795\n",
      "Epoch 91:\t train loss : 0.5625714825870284; train accuracy : 0.9886282102915208; \n",
      " validation loss : 0.5990444919894378; validation accuracy : 0.9497907949790795\n",
      "Epoch 92:\t train loss : 0.5677910747386685; train accuracy : 0.9834043805570185; \n",
      " validation loss : 0.5862180207641828; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5635668171224879; train accuracy : 0.9877880355649183; \n",
      " validation loss : 0.5957527519971642; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5672942602430459; train accuracy : 0.9839369249357167; \n",
      " validation loss : 0.5925228742648035; validation accuracy : 0.9581589958158996\n",
      "Epoch 95:\t train loss : 0.5694378804377213; train accuracy : 0.9817469562254098; \n",
      " validation loss : 0.5951162530923809; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.5756721865260914; train accuracy : 0.9753864741782583; \n",
      " validation loss : 0.5801535683528793; validation accuracy : 0.9707112970711297\n",
      "Epoch 97:\t train loss : 0.5636072855791227; train accuracy : 0.987608042380495; \n",
      " validation loss : 0.5776242378033974; validation accuracy : 0.9748953974895398\n",
      "Epoch 98:\t train loss : 0.5624109525172771; train accuracy : 0.9889556677716163; \n",
      " validation loss : 0.5846148986330467; validation accuracy : 0.9665271966527197\n",
      "Epoch 99:\t train loss : 0.5631217954075225; train accuracy : 0.9881288143994548; \n",
      " validation loss : 0.5816266299936408; validation accuracy : 0.9707112970711297\n",
      "Epoch 100:\t train loss : 0.5603752758970691; train accuracy : 0.9910932804609808; \n",
      " validation loss : 0.5818374506078293; validation accuracy : 0.9707112970711297\n",
      "Epoch 101:\t train loss : 0.5612177268320662; train accuracy : 0.9900591715976331; \n",
      " validation loss : 0.5932787625906786; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.5697641198642285; train accuracy : 0.9814157811580284; \n",
      " validation loss : 0.5955862831700272; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5802552956096869; train accuracy : 0.9707506428328015; \n",
      " validation loss : 0.7300232317577229; validation accuracy : 0.8158995815899581\n",
      "Epoch 104:\t train loss : 0.5742386457434471; train accuracy : 0.9768617367328604; \n",
      " validation loss : 0.5881242647697372; validation accuracy : 0.9623430962343096\n",
      "Epoch 105:\t train loss : 0.5641664997198357; train accuracy : 0.9868896186375042; \n",
      " validation loss : 0.5976249884797367; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5630106216635784; train accuracy : 0.9882623377428049; \n",
      " validation loss : 0.5799617687306579; validation accuracy : 0.9707112970711297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107:\t train loss : 0.5626891512168015; train accuracy : 0.988547042969113; \n",
      " validation loss : 0.5776844430090633; validation accuracy : 0.9748953974895398\n",
      "Epoch 108:\t train loss : 0.5608238145442918; train accuracy : 0.9904774001672915; \n",
      " validation loss : 0.6013384692871887; validation accuracy : 0.9497907949790795\n",
      "Epoch 109:\t train loss : 0.5606433098275918; train accuracy : 0.9907370116794201; \n",
      " validation loss : 0.588260197396743; validation accuracy : 0.9623430962343096\n",
      "Epoch 110:\t train loss : 0.5606973063951651; train accuracy : 0.9906440719972738; \n",
      " validation loss : 0.5851802906085525; validation accuracy : 0.9665271966527197\n",
      "Epoch 111:\t train loss : 0.5612489580414207; train accuracy : 0.9901521112797794; \n",
      " validation loss : 0.594714499847632; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5627647239266989; train accuracy : 0.9884364447473589; \n",
      " validation loss : 0.6028397606706586; validation accuracy : 0.9497907949790795\n",
      "Epoch 113:\t train loss : 0.5708263026032342; train accuracy : 0.9800777595340624; \n",
      " validation loss : 0.6070475243594655; validation accuracy : 0.9456066945606695\n",
      "Epoch 114:\t train loss : 0.5680660879586046; train accuracy : 0.9830481117754577; \n",
      " validation loss : 0.5871378869871595; validation accuracy : 0.9623430962343096\n",
      "Epoch 115:\t train loss : 0.5626776996920038; train accuracy : 0.9884984045354565; \n",
      " validation loss : 0.5886305608447567; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 115\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5684175977397067; Train accuracy : 0.9828002726230677; \n",
      " Validation loss : 0.5724081258088511; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 42 ! ---\n",
      "Epoch 1:\t train loss : 0.9677102002861014; train accuracy : 0.550715945351467; \n",
      " validation loss : 0.8311187842911434; validation accuracy : 0.7322175732217573\n",
      "Epoch 2:\t train loss : 0.7845258374868614; train accuracy : 0.7630490411722792; \n",
      " validation loss : 0.7749726613190574; validation accuracy : 0.7656903765690377\n",
      "Epoch 3:\t train loss : 0.7128113921198204; train accuracy : 0.8382954862294371; \n",
      " validation loss : 0.7492042150059831; validation accuracy : 0.803347280334728\n",
      "Epoch 4:\t train loss : 0.682353791867888; train accuracy : 0.8680148083893553; \n",
      " validation loss : 0.7138295621880708; validation accuracy : 0.8284518828451883\n",
      "Epoch 5:\t train loss : 0.6655518903376509; train accuracy : 0.8848198519161065; \n",
      " validation loss : 0.6857596106062325; validation accuracy : 0.8786610878661087\n",
      "Epoch 6:\t train loss : 0.655584939228745; train accuracy : 0.8950512717246507; \n",
      " validation loss : 0.7020913170190208; validation accuracy : 0.8451882845188284\n",
      "Epoch 7:\t train loss : 0.6409072638323257; train accuracy : 0.9096796678955358; \n",
      " validation loss : 0.6735024213632546; validation accuracy : 0.8744769874476988\n",
      "Epoch 8:\t train loss : 0.6347388102442088; train accuracy : 0.9159376064933858; \n",
      " validation loss : 0.6714742817549492; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6196147600026367; train accuracy : 0.9318863657486292; \n",
      " validation loss : 0.6430518407364543; validation accuracy : 0.9121338912133892\n",
      "Epoch 10:\t train loss : 0.6180561017341835; train accuracy : 0.9332634220390966; \n",
      " validation loss : 0.639223070487979; validation accuracy : 0.9205020920502092\n",
      "Epoch 11:\t train loss : 0.6046522375787213; train accuracy : 0.9461857554447164; \n",
      " validation loss : 0.6698993618685216; validation accuracy : 0.8744769874476988\n",
      "Epoch 12:\t train loss : 0.6006509929428165; train accuracy : 0.9507243099228601; \n",
      " validation loss : 0.6506452770453327; validation accuracy : 0.899581589958159\n",
      "Epoch 13:\t train loss : 0.6023404286264796; train accuracy : 0.9487570866507636; \n",
      " validation loss : 0.6671368397849029; validation accuracy : 0.8828451882845189\n",
      "Epoch 14:\t train loss : 0.5947601920455188; train accuracy : 0.9561265838470833; \n",
      " validation loss : 0.6473595463808073; validation accuracy : 0.9037656903765691\n",
      "Epoch 15:\t train loss : 0.5952256904165762; train accuracy : 0.9559599120171008; \n",
      " validation loss : 0.6630944351105229; validation accuracy : 0.8828451882845189\n",
      "Epoch 16:\t train loss : 0.5907124484029457; train accuracy : 0.9605721986430806; \n",
      " validation loss : 0.6337175392281573; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.5889419996967463; train accuracy : 0.9619449177483813; \n",
      " validation loss : 0.6223993351937616; validation accuracy : 0.9288702928870293\n",
      "Epoch 18:\t train loss : 0.5858967636845105; train accuracy : 0.9650487933331268; \n",
      " validation loss : 0.622362402978131; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5821680576145015; train accuracy : 0.9690548034325722; \n",
      " validation loss : 0.6614901660985789; validation accuracy : 0.8828451882845189\n",
      "Epoch 20:\t train loss : 0.5909531421523917; train accuracy : 0.9599216208680567; \n",
      " validation loss : 0.617978507422849; validation accuracy : 0.9288702928870293\n",
      "Epoch 21:\t train loss : 0.590993204283813; train accuracy : 0.9601149354069209; \n",
      " validation loss : 0.6431497508096226; validation accuracy : 0.9121338912133892\n",
      "Epoch 22:\t train loss : 0.5936186041721504; train accuracy : 0.957297933641067; \n",
      " validation loss : 0.6500191207781396; validation accuracy : 0.899581589958159\n",
      "Epoch 23:\t train loss : 0.58246565659214; train accuracy : 0.9687044208308807; \n",
      " validation loss : 0.6183567807559534; validation accuracy : 0.9330543933054394\n",
      "Epoch 24:\t train loss : 0.5782941671255005; train accuracy : 0.9730784720716255; \n",
      " validation loss : 0.6372794284718012; validation accuracy : 0.9121338912133892\n",
      "Epoch 25:\t train loss : 0.586871127327413; train accuracy : 0.9641252826915332; \n",
      " validation loss : 0.6203073531104102; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5831505100713661; train accuracy : 0.9679822795006041; \n",
      " validation loss : 0.6273460554079495; validation accuracy : 0.9246861924686193\n",
      "Epoch 27:\t train loss : 0.5780978013644432; train accuracy : 0.9729855323894793; \n",
      " validation loss : 0.6152080366341677; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5759218840886485; train accuracy : 0.9754890176275597; \n",
      " validation loss : 0.6226486518784464; validation accuracy : 0.9246861924686193\n",
      "Epoch 29:\t train loss : 0.5781217049463966; train accuracy : 0.9730725858917563; \n",
      " validation loss : 0.647715755451327; validation accuracy : 0.899581589958159\n",
      "Epoch 30:\t train loss : 0.5775410782389538; train accuracy : 0.9736457139316583; \n",
      " validation loss : 0.6240574374176213; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5813450443013447; train accuracy : 0.9697887171225874; \n",
      " validation loss : 0.6336603008859543; validation accuracy : 0.9121338912133892\n",
      "Epoch 32:\t train loss : 0.578565411375255; train accuracy : 0.9725363239257722; \n",
      " validation loss : 0.6052461892244737; validation accuracy : 0.9497907949790795\n",
      "Epoch 33:\t train loss : 0.5724556552053104; train accuracy : 0.9787766039840143; \n",
      " validation loss : 0.6199973199405302; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.5787001064353481; train accuracy : 0.9722029802658075; \n",
      " validation loss : 0.6375641744862667; validation accuracy : 0.9163179916317992\n",
      "Epoch 35:\t train loss : 0.611524550667377; train accuracy : 0.9385058397100282; \n",
      " validation loss : 0.8372063701156747; validation accuracy : 0.7071129707112971\n",
      "Epoch 36:\t train loss : 0.6279962001934394; train accuracy : 0.9218163511880789; \n",
      " validation loss : 0.6307509708759347; validation accuracy : 0.9246861924686193\n",
      "Epoch 37:\t train loss : 0.5899155977163734; train accuracy : 0.9610368970538121; \n",
      " validation loss : 0.6197051516259644; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5786343392535931; train accuracy : 0.9723349546144552; \n",
      " validation loss : 0.6042056658148351; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5716466094667548; train accuracy : 0.9797952229003377; \n",
      " validation loss : 0.6174847782666341; validation accuracy : 0.9330543933054394\n",
      "Epoch 40:\t train loss : 0.5743893287294476; train accuracy : 0.9765946900461601; \n",
      " validation loss : 0.6125948384341845; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.584964587317133; train accuracy : 0.9659627002075653; \n",
      " validation loss : 0.6258298343774974; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:\t train loss : 0.5746182823623769; train accuracy : 0.9764435081632021; \n",
      " validation loss : 0.6084200052278766; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.570614078103529; train accuracy : 0.9804959881037207; \n",
      " validation loss : 0.6213871515445285; validation accuracy : 0.9288702928870293\n",
      "Epoch 44:\t train loss : 0.5724122206253918; train accuracy : 0.9786644567675579; \n",
      " validation loss : 0.6252618220491337; validation accuracy : 0.9246861924686193\n",
      "Epoch 45:\t train loss : 0.5745797795185098; train accuracy : 0.9765113541311689; \n",
      " validation loss : 0.6061501604507139; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5772054019066041; train accuracy : 0.9741104123423898; \n",
      " validation loss : 0.6144520714916146; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.5756476523339987; train accuracy : 0.975380587998389; \n",
      " validation loss : 0.6100997330555931; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.566702993879141; train accuracy : 0.984730629821246; \n",
      " validation loss : 0.6054869258025438; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.5730413070520333; train accuracy : 0.9779423154372812; \n",
      " validation loss : 0.6314725469997988; validation accuracy : 0.9163179916317992\n",
      "Epoch 50:\t train loss : 0.581491541728307; train accuracy : 0.9693277362991418; \n",
      " validation loss : 0.7126086582661464; validation accuracy : 0.8326359832635983\n",
      "Epoch 51:\t train loss : 0.5945591580195975; train accuracy : 0.9562718795501719; \n",
      " validation loss : 0.6099254181788535; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5729269832889687; train accuracy : 0.9781997583568264; \n",
      " validation loss : 0.6042622917906498; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5675656373100361; train accuracy : 0.9836928033706125; \n",
      " validation loss : 0.5958718659518494; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.5717189291854823; train accuracy : 0.9795068000867437; \n",
      " validation loss : 0.6057987270461893; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.567311800627114; train accuracy : 0.9839369249357167; \n",
      " validation loss : 0.5989287482830078; validation accuracy : 0.9539748953974896\n",
      "Epoch 56:\t train loss : 0.5645708888016059; train accuracy : 0.9867406053471297; \n",
      " validation loss : 0.6069599900535431; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5676285309238545; train accuracy : 0.9835592800272623; \n",
      " validation loss : 0.6309062964838433; validation accuracy : 0.9205020920502092\n",
      "Epoch 58:\t train loss : 0.5693912861692044; train accuracy : 0.9818302921404009; \n",
      " validation loss : 0.6216669905985331; validation accuracy : 0.9288702928870293\n",
      "Epoch 59:\t train loss : 0.5707802762411726; train accuracy : 0.9803432572260603; \n",
      " validation loss : 0.6017873614794662; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5630456349080538; train accuracy : 0.9883360698906409; \n",
      " validation loss : 0.5867095443029627; validation accuracy : 0.9665271966527197\n",
      "Epoch 61:\t train loss : 0.5675751999227014; train accuracy : 0.9836831996034574; \n",
      " validation loss : 0.6348263077836673; validation accuracy : 0.9163179916317992\n",
      "Epoch 62:\t train loss : 0.5638811494958949; train accuracy : 0.9875247064655039; \n",
      " validation loss : 0.6103005816154502; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5690618872285945; train accuracy : 0.9819851916106447; \n",
      " validation loss : 0.6016680440434671; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5660723019101501; train accuracy : 0.9850463149416029; \n",
      " validation loss : 0.6237202017573346; validation accuracy : 0.9288702928870293\n",
      "Epoch 65:\t train loss : 0.569990119205487; train accuracy : 0.9811369621115896; \n",
      " validation loss : 0.6157011593572569; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.5666763334628918; train accuracy : 0.9846494624988382; \n",
      " validation loss : 0.6171646779588896; validation accuracy : 0.9330543933054394\n",
      "Epoch 67:\t train loss : 0.5637208966182669; train accuracy : 0.9874221630162024; \n",
      " validation loss : 0.6110252839161545; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5667630353932754; train accuracy : 0.9843492673255058; \n",
      " validation loss : 0.6156481763427047; validation accuracy : 0.9288702928870293\n",
      "Epoch 69:\t train loss : 0.5814827009556386; train accuracy : 0.9695349917903281; \n",
      " validation loss : 0.6201592661169637; validation accuracy : 0.9288702928870293\n",
      "Epoch 70:\t train loss : 0.5689107930400645; train accuracy : 0.9821246011338641; \n",
      " validation loss : 0.6116382887127153; validation accuracy : 0.9414225941422594\n",
      "Epoch 71:\t train loss : 0.5618546662362214; train accuracy : 0.9895752656525915; \n",
      " validation loss : 0.5964435743226055; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5717930763386659; train accuracy : 0.9795687598748413; \n",
      " validation loss : 0.6043297181634211; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5709191328975942; train accuracy : 0.9802850150252487; \n",
      " validation loss : 0.6049781523103626; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5807012040181804; train accuracy : 0.9701140060100994; \n",
      " validation loss : 0.6035184273771093; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.564464823660503; train accuracy : 0.9867870751882029; \n",
      " validation loss : 0.5948501314252364; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.569302270088655; train accuracy : 0.9817683323523033; \n",
      " validation loss : 0.5960343915004154; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5683661958862263; train accuracy : 0.9828777223581896; \n",
      " validation loss : 0.6253107508927984; validation accuracy : 0.9246861924686193\n",
      "Epoch 78:\t train loss : 0.5677646517842729; train accuracy : 0.9834412466309366; \n",
      " validation loss : 0.6172764061216276; validation accuracy : 0.9372384937238494\n",
      "Epoch 79:\t train loss : 0.5649675163476008; train accuracy : 0.986347470491651; \n",
      " validation loss : 0.6100833433699171; validation accuracy : 0.9414225941422594\n",
      "Epoch 80:\t train loss : 0.5654465588908203; train accuracy : 0.985656309055423; \n",
      " validation loss : 0.6067173596778436; validation accuracy : 0.9456066945606695\n",
      "Epoch 81:\t train loss : 0.5642639616519417; train accuracy : 0.9870290281607237; \n",
      " validation loss : 0.5965132220956029; validation accuracy : 0.9581589958158996\n",
      "Epoch 82:\t train loss : 0.5647204771067054; train accuracy : 0.9863843365655689; \n",
      " validation loss : 0.5924196698120765; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5609974164174322; train accuracy : 0.9902723132686886; \n",
      " validation loss : 0.6144517586988302; validation accuracy : 0.9372384937238494\n",
      "Epoch 84:\t train loss : 0.5633094241492815; train accuracy : 0.9879739149292109; \n",
      " validation loss : 0.5931767192280049; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5630467769732882; train accuracy : 0.9882682239226742; \n",
      " validation loss : 0.5932002797309524; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5644525871764886; train accuracy : 0.986920598531553; \n",
      " validation loss : 0.6349280799468043; validation accuracy : 0.9163179916317992\n",
      "Epoch 87:\t train loss : 0.5651642567273547; train accuracy : 0.9859912017100901; \n",
      " validation loss : 0.6046848667027187; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5691041239442738; train accuracy : 0.9821592986151988; \n",
      " validation loss : 0.6520523169677049; validation accuracy : 0.899581589958159\n",
      "Epoch 89:\t train loss : 0.563075906392665; train accuracy : 0.9882121503144459; \n",
      " validation loss : 0.5993838419983768; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5625729367228173; train accuracy : 0.9887152637937978; \n",
      " validation loss : 0.596680943158193; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5651023106612071; train accuracy : 0.9860066916571145; \n",
      " validation loss : 0.6007429681857078; validation accuracy : 0.9497907949790795\n",
      "Epoch 92:\t train loss : 0.5617438241108066; train accuracy : 0.9895383995786734; \n",
      " validation loss : 0.5869240326029092; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93:\t train loss : 0.5631173818746628; train accuracy : 0.9881597942935035; \n",
      " validation loss : 0.5904902275257605; validation accuracy : 0.9623430962343096\n",
      "Epoch 94:\t train loss : 0.5669631610040045; train accuracy : 0.9843396635583507; \n",
      " validation loss : 0.6261293448818662; validation accuracy : 0.9246861924686193\n",
      "Epoch 95:\t train loss : 0.5629552476370732; train accuracy : 0.988299203816723; \n",
      " validation loss : 0.5951593551395049; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5712484256680895; train accuracy : 0.979937730412962; \n",
      " validation loss : 0.7021376211752467; validation accuracy : 0.8451882845188284\n",
      "Epoch 97:\t train loss : 0.6132018398332058; train accuracy : 0.9372539421915177; \n",
      " validation loss : 0.6046787027137902; validation accuracy : 0.9456066945606695\n",
      "Epoch 98:\t train loss : 0.5724447225069161; train accuracy : 0.9785715170854116; \n",
      " validation loss : 0.5986475401442065; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5691463252126493; train accuracy : 0.9819947953777998; \n",
      " validation loss : 0.6221805322402482; validation accuracy : 0.9288702928870293\n",
      "Epoch 100:\t train loss : 0.5659626549658557; train accuracy : 0.9852690603798135; \n",
      " validation loss : 0.6425156744364661; validation accuracy : 0.9079497907949791\n",
      "Epoch 101:\t train loss : 0.5651896369089029; train accuracy : 0.9859041482078131; \n",
      " validation loss : 0.6019630478427032; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.563182768950331; train accuracy : 0.988010781003129; \n",
      " validation loss : 0.5975115225231505; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.5623776168577905; train accuracy : 0.9890058551999752; \n",
      " validation loss : 0.6164177132720348; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.5627108078270542; train accuracy : 0.9885625329161374; \n",
      " validation loss : 0.5916641105784433; validation accuracy : 0.9581589958158996\n",
      "Epoch 105:\t train loss : 0.5609499580711956; train accuracy : 0.9903497630038105; \n",
      " validation loss : 0.6169273697494051; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.5605246898880695; train accuracy : 0.9908764212026395; \n",
      " validation loss : 0.5983615900212551; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.5602095929717698; train accuracy : 0.9911183741751604; \n",
      " validation loss : 0.6104975590610152; validation accuracy : 0.9372384937238494\n",
      "Epoch 108:\t train loss : 0.5607908319831191; train accuracy : 0.9905046624740543; \n",
      " validation loss : 0.6015587409427097; validation accuracy : 0.9497907949790795\n",
      "Epoch 109:\t train loss : 0.5621546215913257; train accuracy : 0.9891570370829332; \n",
      " validation loss : 0.6005880345905392; validation accuracy : 0.9497907949790795\n",
      "Epoch 110:\t train loss : 0.5621292939679642; train accuracy : 0.9892035069240063; \n",
      " validation loss : 0.5887130495516263; validation accuracy : 0.9623430962343096\n",
      "Early stopping at epoch 110\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5630456349080538; Train accuracy : 0.9883360698906409; \n",
      " Validation loss : 0.5867095443029627; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 43 ! ---\n",
      "Epoch 1:\t train loss : 0.9259966751385984; train accuracy : 0.6048362999528343; \n",
      " validation loss : 0.8130807546740537; validation accuracy : 0.7333333333333333\n",
      "Epoch 2:\t train loss : 0.7409587885763709; train accuracy : 0.8094211608138239; \n",
      " validation loss : 0.7687782790341079; validation accuracy : 0.7791666666666667\n",
      "Epoch 3:\t train loss : 0.7094882303474842; train accuracy : 0.8405579361761427; \n",
      " validation loss : 0.7475839076588767; validation accuracy : 0.8\n",
      "Epoch 4:\t train loss : 0.6942963283733796; train accuracy : 0.8555923591458708; \n",
      " validation loss : 0.8393237631868947; validation accuracy : 0.6958333333333333\n",
      "Epoch 5:\t train loss : 0.6819692202193859; train accuracy : 0.8681720183732099; \n",
      " validation loss : 0.7412545907032327; validation accuracy : 0.8125\n",
      "Epoch 6:\t train loss : 0.6641921666302933; train accuracy : 0.8863861107537947; \n",
      " validation loss : 0.7338988321123082; validation accuracy : 0.8083333333333333\n",
      "Epoch 7:\t train loss : 0.6572304293995289; train accuracy : 0.8928992072935426; \n",
      " validation loss : 0.6965389998967975; validation accuracy : 0.8583333333333333\n",
      "Epoch 8:\t train loss : 0.643565431354077; train accuracy : 0.9072964904382128; \n",
      " validation loss : 0.7317353125627332; validation accuracy : 0.8208333333333333\n",
      "Epoch 9:\t train loss : 0.6443719630202467; train accuracy : 0.9061816632364291; \n",
      " validation loss : 0.7601155413816352; validation accuracy : 0.7833333333333333\n",
      "Epoch 10:\t train loss : 0.6321271751160824; train accuracy : 0.9185402329345682; \n",
      " validation loss : 0.6818301332023349; validation accuracy : 0.8708333333333333\n",
      "Epoch 11:\t train loss : 0.6230542156653545; train accuracy : 0.9278578166538033; \n",
      " validation loss : 0.677620072246146; validation accuracy : 0.875\n",
      "Epoch 12:\t train loss : 0.6162557632426914; train accuracy : 0.9348951633650631; \n",
      " validation loss : 0.7072715682192785; validation accuracy : 0.8375\n",
      "Epoch 13:\t train loss : 0.6133627237218233; train accuracy : 0.9376018351770861; \n",
      " validation loss : 0.7383009893900261; validation accuracy : 0.8125\n",
      "Epoch 14:\t train loss : 0.5987920011757527; train accuracy : 0.9526620519252208; \n",
      " validation loss : 0.7032248536163087; validation accuracy : 0.8458333333333333\n",
      "Epoch 15:\t train loss : 0.614176347093951; train accuracy : 0.9364102966083526; \n",
      " validation loss : 0.695991830504493; validation accuracy : 0.85\n",
      "Epoch 16:\t train loss : 0.5933622179681329; train accuracy : 0.957659680237544; \n",
      " validation loss : 0.670426155962057; validation accuracy : 0.875\n",
      "Epoch 17:\t train loss : 0.5926309792323263; train accuracy : 0.9587075106122974; \n",
      " validation loss : 0.640508781735739; validation accuracy : 0.9083333333333333\n",
      "Epoch 18:\t train loss : 0.5829414091121093; train accuracy : 0.9685081414544207; \n",
      " validation loss : 0.6274268765732576; validation accuracy : 0.925\n",
      "Epoch 19:\t train loss : 0.5797908185102684; train accuracy : 0.9717899810264986; \n",
      " validation loss : 0.6562870490327237; validation accuracy : 0.8875\n",
      "Epoch 20:\t train loss : 0.6041353186356552; train accuracy : 0.9463955037089443; \n",
      " validation loss : 0.7027526694606189; validation accuracy : 0.8416666666666667\n",
      "Epoch 21:\t train loss : 0.5796413650705087; train accuracy : 0.9720060457936712; \n",
      " validation loss : 0.6464430012304345; validation accuracy : 0.9083333333333333\n",
      "Epoch 22:\t train loss : 0.579235887776843; train accuracy : 0.972098501414973; \n",
      " validation loss : 0.6650085097643805; validation accuracy : 0.8833333333333333\n",
      "Epoch 23:\t train loss : 0.5801993514342875; train accuracy : 0.971204428758254; \n",
      " validation loss : 0.6916815099605589; validation accuracy : 0.8625\n",
      "Epoch 24:\t train loss : 0.5778534785458048; train accuracy : 0.9737935211388389; \n",
      " validation loss : 0.6770492537713323; validation accuracy : 0.8791666666666667\n",
      "Epoch 25:\t train loss : 0.5848241576317427; train accuracy : 0.966623185725924; \n",
      " validation loss : 0.6421461441492953; validation accuracy : 0.9125\n",
      "Epoch 26:\t train loss : 0.5758267239965343; train accuracy : 0.9755759717219793; \n",
      " validation loss : 0.6292213527508987; validation accuracy : 0.9166666666666666\n",
      "Epoch 27:\t train loss : 0.5776261346481336; train accuracy : 0.9734545171940657; \n",
      " validation loss : 0.6484541319303797; validation accuracy : 0.9\n",
      "Epoch 28:\t train loss : 0.5779224216380131; train accuracy : 0.973362061572764; \n",
      " validation loss : 0.6571221707983784; validation accuracy : 0.8916666666666667\n",
      "Epoch 29:\t train loss : 0.5888252299200979; train accuracy : 0.9619695861204013; \n",
      " validation loss : 0.6476000567093821; validation accuracy : 0.8958333333333334\n",
      "Epoch 30:\t train loss : 0.5945659431788863; train accuracy : 0.95641152934997; \n",
      " validation loss : 0.7023926560936294; validation accuracy : 0.8416666666666667\n",
      "Epoch 31:\t train loss : 0.576675668036771; train accuracy : 0.9745331661092531; \n",
      " validation loss : 0.6137398366047659; validation accuracy : 0.9375\n",
      "Epoch 32:\t train loss : 0.5722524642126506; train accuracy : 0.9790276482505789; \n",
      " validation loss : 0.646929215023814; validation accuracy : 0.8958333333333334\n",
      "Epoch 33:\t train loss : 0.575887467019589; train accuracy : 0.974851736021782; \n",
      " validation loss : 0.639121090664226; validation accuracy : 0.9166666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:\t train loss : 0.5709163015036193; train accuracy : 0.9803216919646686; \n",
      " validation loss : 0.644881702213599; validation accuracy : 0.9041666666666667\n",
      "Epoch 35:\t train loss : 0.5661736397578986; train accuracy : 0.9852684026884487; \n",
      " validation loss : 0.6167267817024554; validation accuracy : 0.9333333333333333\n",
      "Epoch 36:\t train loss : 0.5690611365126585; train accuracy : 0.9824381217305549; \n",
      " validation loss : 0.6407117397619422; validation accuracy : 0.9083333333333333\n",
      "Epoch 37:\t train loss : 0.5694370510196646; train accuracy : 0.981750064316954; \n",
      " validation loss : 0.6508072025542596; validation accuracy : 0.9\n",
      "Epoch 38:\t train loss : 0.5717204496456779; train accuracy : 0.9795307944215762; \n",
      " validation loss : 0.6452003884684052; validation accuracy : 0.9041666666666667\n",
      "Epoch 39:\t train loss : 0.5690860738259933; train accuracy : 0.9819091817811508; \n",
      " validation loss : 0.6216800504250741; validation accuracy : 0.925\n",
      "Epoch 40:\t train loss : 0.569933643018964; train accuracy : 0.9813082202426893; \n",
      " validation loss : 0.6328073499447268; validation accuracy : 0.9166666666666666\n",
      "Epoch 41:\t train loss : 0.5646669810697961; train accuracy : 0.9865008093216705; \n",
      " validation loss : 0.6171099183742622; validation accuracy : 0.9333333333333333\n",
      "Epoch 42:\t train loss : 0.5797577899861925; train accuracy : 0.9711123081210874; \n",
      " validation loss : 0.6357359755409564; validation accuracy : 0.9125\n",
      "Epoch 43:\t train loss : 0.578765989850501; train accuracy : 0.9725095269488037; \n",
      " validation loss : 0.6424796825173035; validation accuracy : 0.9125\n",
      "Epoch 44:\t train loss : 0.5711763872040749; train accuracy : 0.9802757991381528; \n",
      " validation loss : 0.6138047218965365; validation accuracy : 0.9375\n",
      "Epoch 45:\t train loss : 0.5642350567536542; train accuracy : 0.9870250594931824; \n",
      " validation loss : 0.6331053150538453; validation accuracy : 0.9166666666666666\n",
      "Epoch 46:\t train loss : 0.5634338289023141; train accuracy : 0.9878618498627905; \n",
      " validation loss : 0.6513038781809966; validation accuracy : 0.9\n",
      "Epoch 47:\t train loss : 0.5691251902366925; train accuracy : 0.9821342911199725; \n",
      " validation loss : 0.6754655870346932; validation accuracy : 0.875\n",
      "Epoch 48:\t train loss : 0.5758405769080266; train accuracy : 0.9749696504373553; \n",
      " validation loss : 0.6298788444032551; validation accuracy : 0.925\n",
      "Epoch 49:\t train loss : 0.5677902456192385; train accuracy : 0.9834859521053083; \n",
      " validation loss : 0.6396888796845511; validation accuracy : 0.9083333333333333\n",
      "Epoch 50:\t train loss : 0.5628236486310619; train accuracy : 0.9884886051796586; \n",
      " validation loss : 0.6547654701641414; validation accuracy : 0.8958333333333334\n",
      "Epoch 51:\t train loss : 0.5625823904155374; train accuracy : 0.9887093597247234; \n",
      " validation loss : 0.6487698814171423; validation accuracy : 0.8916666666666667\n",
      "Epoch 52:\t train loss : 0.5649243666011365; train accuracy : 0.986280389760741; \n",
      " validation loss : 0.6274541412726822; validation accuracy : 0.925\n",
      "Epoch 53:\t train loss : 0.5626175083002644; train accuracy : 0.9888895811894348; \n",
      " validation loss : 0.6256261170282679; validation accuracy : 0.925\n",
      "Epoch 54:\t train loss : 0.5715233399248787; train accuracy : 0.9795515634379556; \n",
      " validation loss : 0.6335300702433889; validation accuracy : 0.9166666666666666\n",
      "Epoch 55:\t train loss : 0.5674168692149814; train accuracy : 0.9837428849369694; \n",
      " validation loss : 0.6229599145995218; validation accuracy : 0.9291666666666667\n",
      "Epoch 56:\t train loss : 0.5646822076617841; train accuracy : 0.9865778556727554; \n",
      " validation loss : 0.633966470250995; validation accuracy : 0.9166666666666666\n",
      "Epoch 57:\t train loss : 0.5823736733738382; train accuracy : 0.9683691230383329; \n",
      " validation loss : 0.6905495243222554; validation accuracy : 0.8583333333333333\n",
      "Epoch 58:\t train loss : 0.5730360372650827; train accuracy : 0.9778974117785781; \n",
      " validation loss : 0.6694117376579168; validation accuracy : 0.8875\n",
      "Epoch 59:\t train loss : 0.5655186394848641; train accuracy : 0.9856228159034388; \n",
      " validation loss : 0.6237561063775744; validation accuracy : 0.9291666666666667\n",
      "Epoch 60:\t train loss : 0.5623874102557131; train accuracy : 0.9889461935082754; \n",
      " validation loss : 0.6308541852790156; validation accuracy : 0.9166666666666666\n",
      "Epoch 61:\t train loss : 0.5634748463910341; train accuracy : 0.9878775941171426; \n",
      " validation loss : 0.6183815902391203; validation accuracy : 0.9375\n",
      "Epoch 62:\t train loss : 0.5702288220427413; train accuracy : 0.9807119484821198; \n",
      " validation loss : 0.7347343813037328; validation accuracy : 0.8166666666666667\n",
      "Epoch 63:\t train loss : 0.6403425993144566; train accuracy : 0.9089975398765114; \n",
      " validation loss : 0.6485097760882029; validation accuracy : 0.9041666666666667\n",
      "Epoch 64:\t train loss : 0.5788083281791616; train accuracy : 0.9718465933453392; \n",
      " validation loss : 0.6290836139759243; validation accuracy : 0.9166666666666666\n",
      "Epoch 65:\t train loss : 0.5672210846715293; train accuracy : 0.9841277817082583; \n",
      " validation loss : 0.632363770088055; validation accuracy : 0.9166666666666666\n",
      "Epoch 66:\t train loss : 0.5661723652482186; train accuracy : 0.9850114698567876; \n",
      " validation loss : 0.640771198404511; validation accuracy : 0.9125\n",
      "Epoch 67:\t train loss : 0.5647631926496367; train accuracy : 0.9863775351599349; \n",
      " validation loss : 0.6381178842106873; validation accuracy : 0.9125\n",
      "Epoch 68:\t train loss : 0.5634105551695988; train accuracy : 0.9879650249764171; \n",
      " validation loss : 0.6202978483112876; validation accuracy : 0.9291666666666667\n",
      "Epoch 69:\t train loss : 0.5665545283303369; train accuracy : 0.9846620814038247; \n",
      " validation loss : 0.6299933229968067; validation accuracy : 0.9166666666666666\n",
      "Epoch 70:\t train loss : 0.5671027592006842; train accuracy : 0.9840919384057971; \n",
      " validation loss : 0.6265525022758585; validation accuracy : 0.925\n",
      "Epoch 71:\t train loss : 0.5620900247216937; train accuracy : 0.9892336098962353; \n",
      " validation loss : 0.6162824119716033; validation accuracy : 0.9333333333333333\n",
      "Epoch 72:\t train loss : 0.5632275062695422; train accuracy : 0.9881703702512649; \n",
      " validation loss : 0.6434873537624733; validation accuracy : 0.9041666666666667\n",
      "Epoch 73:\t train loss : 0.5672792128947451; train accuracy : 0.9840353260869565; \n",
      " validation loss : 0.6454697655047361; validation accuracy : 0.9\n",
      "Epoch 74:\t train loss : 0.5668382331104733; train accuracy : 0.9842410063459395; \n",
      " validation loss : 0.6208365583060865; validation accuracy : 0.9291666666666667\n",
      "Epoch 75:\t train loss : 0.565238073557996; train accuracy : 0.9858948230211817; \n",
      " validation loss : 0.6402622245595928; validation accuracy : 0.9083333333333333\n",
      "Epoch 76:\t train loss : 0.5624016826424995; train accuracy : 0.9888946059514622; \n",
      " validation loss : 0.6435761439230929; validation accuracy : 0.9041666666666667\n",
      "Epoch 77:\t train loss : 0.5637527279474778; train accuracy : 0.987564048966641; \n",
      " validation loss : 0.6450955384371411; validation accuracy : 0.9041666666666667\n",
      "Epoch 78:\t train loss : 0.5684690702444465; train accuracy : 0.9826742855458366; \n",
      " validation loss : 0.6347969601951289; validation accuracy : 0.9125\n",
      "Epoch 79:\t train loss : 0.5638316149054543; train accuracy : 0.9873844974701999; \n",
      " validation loss : 0.6231830546440817; validation accuracy : 0.9291666666666667\n",
      "Epoch 80:\t train loss : 0.5602537800455073; train accuracy : 0.9911601036574907; \n",
      " validation loss : 0.6288365690270866; validation accuracy : 0.925\n",
      "Epoch 81:\t train loss : 0.5642027891246029; train accuracy : 0.986891400823257; \n",
      " validation loss : 0.6319712029448253; validation accuracy : 0.9166666666666666\n",
      "Early stopping at epoch 81\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.576675668036771; Train accuracy : 0.9745331661092531; \n",
      " Validation loss : 0.6137398366047659; Validation accuracy : 0.9375\n",
      "--- Let's train model 44 ! ---\n",
      "Epoch 1:\t train loss : 0.9605989918439833; train accuracy : 0.5600880216239661; \n",
      " validation loss : 0.8664926719857944; validation accuracy : 0.6610878661087866\n",
      "Epoch 2:\t train loss : 0.7710840111289439; train accuracy : 0.7771972489854084; \n",
      " validation loss : 0.7462894679151855; validation accuracy : 0.8075313807531381\n",
      "Epoch 3:\t train loss : 0.7132439308495725; train accuracy : 0.8374945785185415; \n",
      " validation loss : 0.7136924687328686; validation accuracy : 0.8326359832635983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\t train loss : 0.6933257605232234; train accuracy : 0.857144544440658; \n",
      " validation loss : 0.7017155644698839; validation accuracy : 0.8535564853556485\n",
      "Epoch 5:\t train loss : 0.6739065883418753; train accuracy : 0.8765999179032807; \n",
      " validation loss : 0.6917213353375397; validation accuracy : 0.8535564853556485\n",
      "Epoch 6:\t train loss : 0.660575911748038; train accuracy : 0.8902552743269618; \n",
      " validation loss : 0.6777866144970044; validation accuracy : 0.8661087866108786\n",
      "Epoch 7:\t train loss : 0.6465289258266047; train accuracy : 0.9039793673905635; \n",
      " validation loss : 0.6588674745892755; validation accuracy : 0.891213389121339\n",
      "Epoch 8:\t train loss : 0.6339010000466757; train accuracy : 0.9169839524148827; \n",
      " validation loss : 0.6589984048939657; validation accuracy : 0.895397489539749\n",
      "Epoch 9:\t train loss : 0.6293463202131083; train accuracy : 0.9216206744322935; \n",
      " validation loss : 0.6675650496082521; validation accuracy : 0.8828451882845189\n",
      "Epoch 10:\t train loss : 0.6202847749672733; train accuracy : 0.9309800876731001; \n",
      " validation loss : 0.6620211724829718; validation accuracy : 0.8786610878661087\n",
      "Epoch 11:\t train loss : 0.6078521764001977; train accuracy : 0.943273877753338; \n",
      " validation loss : 0.6395458805319949; validation accuracy : 0.9037656903765691\n",
      "Epoch 12:\t train loss : 0.6027411225060118; train accuracy : 0.9484612673874655; \n",
      " validation loss : 0.621628813532114; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.6041974560081306; train accuracy : 0.9464355695653521; \n",
      " validation loss : 0.646378558777681; validation accuracy : 0.895397489539749\n",
      "Epoch 14:\t train loss : 0.598335982182039; train accuracy : 0.9531496871030701; \n",
      " validation loss : 0.6479984113608408; validation accuracy : 0.9037656903765691\n",
      "Epoch 15:\t train loss : 0.5992690295924687; train accuracy : 0.9519000356268782; \n",
      " validation loss : 0.600537666575442; validation accuracy : 0.9539748953974896\n",
      "Epoch 16:\t train loss : 0.5956122290422896; train accuracy : 0.9551494392639177; \n",
      " validation loss : 0.6223676597361414; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5887258466956717; train accuracy : 0.9625348523808048; \n",
      " validation loss : 0.6388884902993184; validation accuracy : 0.9079497907949791\n",
      "Epoch 18:\t train loss : 0.597382667965194; train accuracy : 0.9537520524179808; \n",
      " validation loss : 0.6256454469057824; validation accuracy : 0.9246861924686193\n",
      "Epoch 19:\t train loss : 0.5838498023439126; train accuracy : 0.9672335341863131; \n",
      " validation loss : 0.6232708302855181; validation accuracy : 0.9246861924686193\n",
      "Epoch 20:\t train loss : 0.5820151436531622; train accuracy : 0.9693246770346046; \n",
      " validation loss : 0.631620195290984; validation accuracy : 0.9205020920502092\n",
      "Epoch 21:\t train loss : 0.5810000757996239; train accuracy : 0.9700801992007188; \n",
      " validation loss : 0.6168648207288421; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5814776694952971; train accuracy : 0.9696172434090276; \n",
      " validation loss : 0.6113096466452321; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.5802199334411815; train accuracy : 0.9710285712072865; \n",
      " validation loss : 0.6295134918381317; validation accuracy : 0.9205020920502092\n",
      "Epoch 24:\t train loss : 0.580181412954515; train accuracy : 0.9709958486941974; \n",
      " validation loss : 0.630085953157563; validation accuracy : 0.9205020920502092\n",
      "Epoch 25:\t train loss : 0.585641177688128; train accuracy : 0.9655278973945909; \n",
      " validation loss : 0.6273772039667425; validation accuracy : 0.9205020920502092\n",
      "Epoch 26:\t train loss : 0.5801927647935928; train accuracy : 0.9708649586418414; \n",
      " validation loss : 0.6034521838974833; validation accuracy : 0.9456066945606695\n",
      "Epoch 27:\t train loss : 0.5900246852831441; train accuracy : 0.9607724836581059; \n",
      " validation loss : 0.6258554509083832; validation accuracy : 0.9205020920502092\n",
      "Epoch 28:\t train loss : 0.5749524236178498; train accuracy : 0.9762779206295115; \n",
      " validation loss : 0.6071120706692152; validation accuracy : 0.9456066945606695\n",
      "Epoch 29:\t train loss : 0.5744566535507574; train accuracy : 0.9767908315003563; \n",
      " validation loss : 0.6243573277299851; validation accuracy : 0.9246861924686193\n",
      "Epoch 30:\t train loss : 0.5711851079475367; train accuracy : 0.980152150004647; \n",
      " validation loss : 0.6221050457586027; validation accuracy : 0.9288702928870293\n",
      "Epoch 31:\t train loss : 0.5712856589346675; train accuracy : 0.979983503206419; \n",
      " validation loss : 0.6091479739502114; validation accuracy : 0.9414225941422594\n",
      "Epoch 32:\t train loss : 0.5719400499571252; train accuracy : 0.9792847129712816; \n",
      " validation loss : 0.6196056298915993; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5721779725793672; train accuracy : 0.9789249589516403; \n",
      " validation loss : 0.6249226392134067; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.585912926212889; train accuracy : 0.9648945521856315; \n",
      " validation loss : 0.6100410235476819; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5714484262888201; train accuracy : 0.9798233758790545; \n",
      " validation loss : 0.6063227799187633; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.5715602608138105; train accuracy : 0.9797958812230863; \n",
      " validation loss : 0.6128880672283885; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5678781217678256; train accuracy : 0.983405038879767; \n",
      " validation loss : 0.6148714355513737; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5861367287995077; train accuracy : 0.9645553223457976; \n",
      " validation loss : 0.6368063879518118; validation accuracy : 0.9079497907949791\n",
      "Epoch 39:\t train loss : 0.5859574692545136; train accuracy : 0.9646999597261378; \n",
      " validation loss : 0.6612257159087515; validation accuracy : 0.8870292887029289\n",
      "Epoch 40:\t train loss : 0.5732005149183566; train accuracy : 0.9777976780569411; \n",
      " validation loss : 0.6045113725944962; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.576092203755252; train accuracy : 0.9751041698937389; \n",
      " validation loss : 0.6198480538551764; validation accuracy : 0.9246861924686193\n",
      "Epoch 42:\t train loss : 0.5754273319446522; train accuracy : 0.9757822423247312; \n",
      " validation loss : 0.6344996601407802; validation accuracy : 0.9163179916317992\n",
      "Epoch 43:\t train loss : 0.5696188606313544; train accuracy : 0.9814687955017194; \n",
      " validation loss : 0.6211594837863625; validation accuracy : 0.9246861924686193\n",
      "Epoch 44:\t train loss : 0.5690014719588121; train accuracy : 0.9822105703398495; \n",
      " validation loss : 0.6223854315909515; validation accuracy : 0.9246861924686193\n",
      "Epoch 45:\t train loss : 0.5809847779037918; train accuracy : 0.9700544471637907; \n",
      " validation loss : 0.6096782840616407; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5688994048119232; train accuracy : 0.9823672124291335; \n",
      " validation loss : 0.6141177028211393; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.5680127965447963; train accuracy : 0.9831227345952477; \n",
      " validation loss : 0.625475392856271; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5689709107312257; train accuracy : 0.9823087378791164; \n",
      " validation loss : 0.6140099888292605; validation accuracy : 0.9372384937238494\n",
      "Epoch 49:\t train loss : 0.5670581911782193; train accuracy : 0.9840591018928715; \n",
      " validation loss : 0.6044267372952654; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5662364313447202; train accuracy : 0.9850796957774405; \n",
      " validation loss : 0.6194693085427275; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.5670682699230576; train accuracy : 0.9840711066018154; \n",
      " validation loss : 0.5959167462293954; validation accuracy : 0.9623430962343096\n",
      "Epoch 52:\t train loss : 0.5654785562643189; train accuracy : 0.9857285309334242; \n",
      " validation loss : 0.600826217919905; validation accuracy : 0.9497907949790795\n",
      "Epoch 53:\t train loss : 0.5657926048175018; train accuracy : 0.9852930697977013; \n",
      " validation loss : 0.5997032939032695; validation accuracy : 0.9456066945606695\n",
      "Epoch 54:\t train loss : 0.5631937049831409; train accuracy : 0.9882688822454228; \n",
      " validation loss : 0.6219120184066727; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55:\t train loss : 0.5654192294182141; train accuracy : 0.9855753740822206; \n",
      " validation loss : 0.6402097449918712; validation accuracy : 0.9079497907949791\n",
      "Epoch 56:\t train loss : 0.5667563120229482; train accuracy : 0.9844600978964652; \n",
      " validation loss : 0.6167050478779569; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.5676515775255624; train accuracy : 0.983573685677995; \n",
      " validation loss : 0.6242044638858232; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.5643565456801639; train accuracy : 0.9868455497382199; \n",
      " validation loss : 0.6212482444478025; validation accuracy : 0.9246861924686193\n",
      "Epoch 59:\t train loss : 0.5670165328028072; train accuracy : 0.984165788903002; \n",
      " validation loss : 0.6087319594924523; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5653452115090448; train accuracy : 0.9857887481024815; \n",
      " validation loss : 0.6281362426669644; validation accuracy : 0.9205020920502092\n",
      "Epoch 61:\t train loss : 0.566980262704366; train accuracy : 0.9842122587440751; \n",
      " validation loss : 0.6200360605788402; validation accuracy : 0.9288702928870293\n",
      "Epoch 62:\t train loss : 0.5637419636901636; train accuracy : 0.9875580873013414; \n",
      " validation loss : 0.6153132452207596; validation accuracy : 0.9330543933054394\n",
      "Epoch 63:\t train loss : 0.562981772162619; train accuracy : 0.98832909941448; \n",
      " validation loss : 0.6067177322962675; validation accuracy : 0.9414225941422594\n",
      "Epoch 64:\t train loss : 0.5645954348379655; train accuracy : 0.9865649880727408; \n",
      " validation loss : 0.6111447062333681; validation accuracy : 0.9372384937238494\n",
      "Epoch 65:\t train loss : 0.5630810048349887; train accuracy : 0.9882224124043496; \n",
      " validation loss : 0.6159550102446085; validation accuracy : 0.9330543933054394\n",
      "Epoch 66:\t train loss : 0.5629378468241419; train accuracy : 0.9882104076954057; \n",
      " validation loss : 0.6106438712148279; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5640071977900578; train accuracy : 0.9870778989435857; \n",
      " validation loss : 0.5992155291177688; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5648064602536839; train accuracy : 0.9865305229406115; \n",
      " validation loss : 0.5998964066633669; validation accuracy : 0.9539748953974896\n",
      "Epoch 69:\t train loss : 0.5735576392103429; train accuracy : 0.977517116391462; \n",
      " validation loss : 0.6505649504505424; validation accuracy : 0.899581589958159\n",
      "Epoch 70:\t train loss : 0.5742803130820213; train accuracy : 0.9766514219771368; \n",
      " validation loss : 0.6080879796451868; validation accuracy : 0.9456066945606695\n",
      "Epoch 71:\t train loss : 0.5764222815124683; train accuracy : 0.9746239815359832; \n",
      " validation loss : 0.6151213750741612; validation accuracy : 0.9330543933054394\n",
      "Epoch 72:\t train loss : 0.5649104813779335; train accuracy : 0.986241441804269; \n",
      " validation loss : 0.623746002558054; validation accuracy : 0.9288702928870293\n",
      "Epoch 73:\t train loss : 0.5649131887868057; train accuracy : 0.9863034015923665; \n",
      " validation loss : 0.6171444588075644; validation accuracy : 0.9330543933054394\n",
      "Epoch 74:\t train loss : 0.5622567697250336; train accuracy : 0.9889814198085443; \n",
      " validation loss : 0.6078191553558205; validation accuracy : 0.9414225941422594\n",
      "Epoch 75:\t train loss : 0.5618610486109067; train accuracy : 0.9894633507853403; \n",
      " validation loss : 0.6056057077929868; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5635933369504027; train accuracy : 0.9875563446823011; \n",
      " validation loss : 0.6076155829188175; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5609998744108857; train accuracy : 0.9903480203847703; \n",
      " validation loss : 0.62484222758079; validation accuracy : 0.9288702928870293\n",
      "Epoch 78:\t train loss : 0.5654980159682567; train accuracy : 0.985726788314384; \n",
      " validation loss : 0.6070103414314936; validation accuracy : 0.9456066945606695\n",
      "Epoch 79:\t train loss : 0.5645033694712634; train accuracy : 0.9868110846060907; \n",
      " validation loss : 0.6142471642129304; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.5614794339013618; train accuracy : 0.9898660894079743; \n",
      " validation loss : 0.6134652222270937; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.5654964877933564; train accuracy : 0.9857560255893925; \n",
      " validation loss : 0.6476502573536576; validation accuracy : 0.899581589958159\n",
      "Epoch 82:\t train loss : 0.5697814712027905; train accuracy : 0.9813001487034915; \n",
      " validation loss : 0.6183290537162272; validation accuracy : 0.9330543933054394\n",
      "Epoch 83:\t train loss : 0.5636092093767455; train accuracy : 0.987743966665634; \n",
      " validation loss : 0.5925994592156804; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5610646898147241; train accuracy : 0.9902515954645436; \n",
      " validation loss : 0.6015359558051536; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5641107938349271; train accuracy : 0.9871725812447721; \n",
      " validation loss : 0.5996825300251354; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5623247285168507; train accuracy : 0.9889831624275846; \n",
      " validation loss : 0.6260891519941177; validation accuracy : 0.9205020920502092\n",
      "Epoch 87:\t train loss : 0.5630442726467645; train accuracy : 0.9881794278013569; \n",
      " validation loss : 0.6071452387891169; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5607000575606157; train accuracy : 0.9906733092722823; \n",
      " validation loss : 0.6139568890171916; validation accuracy : 0.9372384937238494\n",
      "Epoch 89:\t train loss : 0.5594843254061364; train accuracy : 0.9918608073360389; \n",
      " validation loss : 0.6441504897875212; validation accuracy : 0.9079497907949791\n",
      "Epoch 90:\t train loss : 0.5608869779857666; train accuracy : 0.9902688280306081; \n",
      " validation loss : 0.6053983669024104; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5616852767799254; train accuracy : 0.9897111899377304; \n",
      " validation loss : 0.6246976958723917; validation accuracy : 0.9246861924686193\n",
      "Epoch 92:\t train loss : 0.5641810005586422; train accuracy : 0.9870641516156015; \n",
      " validation loss : 0.6109605404841483; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5626425571410743; train accuracy : 0.9886578735400725; \n",
      " validation loss : 0.6091787924501945; validation accuracy : 0.9414225941422594\n",
      "Epoch 94:\t train loss : 0.5622191325429344; train accuracy : 0.9890296322686576; \n",
      " validation loss : 0.6047137406724176; validation accuracy : 0.9497907949790795\n",
      "Epoch 95:\t train loss : 0.5627842117837497; train accuracy : 0.9884719941757799; \n",
      " validation loss : 0.604000854783089; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5612698047137609; train accuracy : 0.9899452817621364; \n",
      " validation loss : 0.5963683282874367; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5717693047813376; train accuracy : 0.9793484153784194; \n",
      " validation loss : 0.6263994728867958; validation accuracy : 0.9246861924686193\n",
      "Epoch 98:\t train loss : 0.5653682893417368; train accuracy : 0.9858541931286595; \n",
      " validation loss : 0.6069577645535629; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5633040532700119; train accuracy : 0.9880847455001703; \n",
      " validation loss : 0.6263258300346798; validation accuracy : 0.9205020920502092\n",
      "Epoch 100:\t train loss : 0.5631529145709202; train accuracy : 0.9882861148114873; \n",
      " validation loss : 0.6237838915058226; validation accuracy : 0.9246861924686193\n",
      "Epoch 101:\t train loss : 0.5644807270043842; train accuracy : 0.9866544425168066; \n",
      " validation loss : 0.6030995410607903; validation accuracy : 0.9497907949790795\n",
      "Epoch 102:\t train loss : 0.5614157946929381; train accuracy : 0.9899125592490474; \n",
      " validation loss : 0.6025001222071287; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.5601974141348524; train accuracy : 0.991198224852071; \n",
      " validation loss : 0.6157729298717496; validation accuracy : 0.9330543933054394\n",
      "Epoch 104:\t train loss : 0.5609164774060138; train accuracy : 0.9903790002788191; \n",
      " validation loss : 0.6159361841181235; validation accuracy : 0.9330543933054394\n",
      "Epoch 105:\t train loss : 0.5628992552548434; train accuracy : 0.9882878574305276; \n",
      " validation loss : 0.6190298601444969; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106:\t train loss : 0.5725090648040472; train accuracy : 0.978357058768859; \n",
      " validation loss : 0.5940192125400766; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.56181872080286; train accuracy : 0.9895528052294061; \n",
      " validation loss : 0.6229313174725163; validation accuracy : 0.9288702928870293\n",
      "Epoch 108:\t train loss : 0.559887142337383; train accuracy : 0.9913978515443477; \n",
      " validation loss : 0.6094682548478001; validation accuracy : 0.9414225941422594\n",
      "Epoch 109:\t train loss : 0.5607267511414007; train accuracy : 0.9905201524210787; \n",
      " validation loss : 0.6208747997005344; validation accuracy : 0.9288702928870293\n",
      "Epoch 110:\t train loss : 0.5596545779434784; train accuracy : 0.9917093931038756; \n",
      " validation loss : 0.594415824912069; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.559968172424088; train accuracy : 0.991387589454444; \n",
      " validation loss : 0.6078320675146499; validation accuracy : 0.9414225941422594\n",
      "Epoch 112:\t train loss : 0.5618599860107782; train accuracy : 0.9893531785371295; \n",
      " validation loss : 0.6160868610756952; validation accuracy : 0.9330543933054394\n",
      "Epoch 113:\t train loss : 0.5603467605679382; train accuracy : 0.9909951129217138; \n",
      " validation loss : 0.5990506139028339; validation accuracy : 0.9497907949790795\n",
      "Epoch 114:\t train loss : 0.5634585721581014; train accuracy : 0.9877542287555376; \n",
      " validation loss : 0.6348379311631711; validation accuracy : 0.9205020920502092\n",
      "Epoch 115:\t train loss : 0.5713981079269354; train accuracy : 0.9797064267790204; \n",
      " validation loss : 0.5977781910119142; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5617860388501469; train accuracy : 0.9894496034573562; \n",
      " validation loss : 0.6030100716937687; validation accuracy : 0.9414225941422594\n",
      "Epoch 117:\t train loss : 0.561889389035082; train accuracy : 0.9894496034573562; \n",
      " validation loss : 0.6142831665486258; validation accuracy : 0.9372384937238494\n",
      "Epoch 118:\t train loss : 0.560950891984798; train accuracy : 0.9902705706496484; \n",
      " validation loss : 0.6132465710537893; validation accuracy : 0.9372384937238494\n",
      "Epoch 119:\t train loss : 0.5599602450373913; train accuracy : 0.9913841042163636; \n",
      " validation loss : 0.613585476005167; validation accuracy : 0.9372384937238494\n",
      "Epoch 120:\t train loss : 0.5611432994824556; train accuracy : 0.9901001812323802; \n",
      " validation loss : 0.6080962943567785; validation accuracy : 0.9414225941422594\n",
      "Epoch 121:\t train loss : 0.5620232364717079; train accuracy : 0.9891725270299575; \n",
      " validation loss : 0.5994876505277491; validation accuracy : 0.9497907949790795\n",
      "Epoch 122:\t train loss : 0.5626598195962899; train accuracy : 0.9885821664239908; \n",
      " validation loss : 0.6225549244011663; validation accuracy : 0.9288702928870293\n",
      "Epoch 123:\t train loss : 0.5599653841040448; train accuracy : 0.9914408361473404; \n",
      " validation loss : 0.605771576195638; validation accuracy : 0.9414225941422594\n",
      "Epoch 124:\t train loss : 0.5601243797280807; train accuracy : 0.9911672449580222; \n",
      " validation loss : 0.6205143591975827; validation accuracy : 0.9288702928870293\n",
      "Epoch 125:\t train loss : 0.5598628798421756; train accuracy : 0.9913686142693392; \n",
      " validation loss : 0.6022934383984054; validation accuracy : 0.9497907949790795\n",
      "Epoch 126:\t train loss : 0.5679561608272241; train accuracy : 0.9831744322934416; \n",
      " validation loss : 0.6056745432658808; validation accuracy : 0.9456066945606695\n",
      "Epoch 127:\t train loss : 0.5631361803042737; train accuracy : 0.9882241550233898; \n",
      " validation loss : 0.6243461539190404; validation accuracy : 0.9246861924686193\n",
      "Epoch 128:\t train loss : 0.5603282414636525; train accuracy : 0.9910295780538431; \n",
      " validation loss : 0.6041365163246201; validation accuracy : 0.9497907949790795\n",
      "Epoch 129:\t train loss : 0.5591970421487863; train accuracy : 0.9920364246104278; \n",
      " validation loss : 0.6067901764470293; validation accuracy : 0.9414225941422594\n",
      "Epoch 130:\t train loss : 0.557676044410964; train accuracy : 0.9936318891539391; \n",
      " validation loss : 0.6074538175911972; validation accuracy : 0.9456066945606695\n",
      "Epoch 131:\t train loss : 0.5583686542967867; train accuracy : 0.9929778261408346; \n",
      " validation loss : 0.6022217137256889; validation accuracy : 0.9456066945606695\n",
      "Epoch 132:\t train loss : 0.5591597188069132; train accuracy : 0.9922205613556802; \n",
      " validation loss : 0.594599099554421; validation accuracy : 0.9581589958158996\n",
      "Epoch 133:\t train loss : 0.5588716163374101; train accuracy : 0.9923617134979398; \n",
      " validation loss : 0.5971634711959931; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 133\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5636092093767455; Train accuracy : 0.987743966665634; \n",
      " Validation loss : 0.5925994592156804; Validation accuracy : 0.9581589958158996\n",
      "--- Let's train model 45 ! ---\n",
      "Epoch 1:\t train loss : 0.9562415207831861; train accuracy : 0.5722906533659655; \n",
      " validation loss : 0.8812845212387869; validation accuracy : 0.6652719665271967\n",
      "Epoch 2:\t train loss : 0.7721055726529602; train accuracy : 0.7770593884568915; \n",
      " validation loss : 0.7515700681221726; validation accuracy : 0.7949790794979079\n",
      "Epoch 3:\t train loss : 0.7020642900457783; train accuracy : 0.8481817900182781; \n",
      " validation loss : 0.7460695234370974; validation accuracy : 0.799163179916318\n",
      "Epoch 4:\t train loss : 0.6722492878142512; train accuracy : 0.8789234486818055; \n",
      " validation loss : 0.7143983499369828; validation accuracy : 0.8284518828451883\n",
      "Epoch 5:\t train loss : 0.6545233880975521; train accuracy : 0.8960788748102482; \n",
      " validation loss : 0.6888214288770433; validation accuracy : 0.8535564853556485\n",
      "Epoch 6:\t train loss : 0.6365640867933412; train accuracy : 0.9145605502029183; \n",
      " validation loss : 0.6970168536784737; validation accuracy : 0.8410041841004184\n",
      "Epoch 7:\t train loss : 0.6277830024322355; train accuracy : 0.9236627528733852; \n",
      " validation loss : 0.7218774393387487; validation accuracy : 0.8200836820083682\n",
      "Epoch 8:\t train loss : 0.6200396359455608; train accuracy : 0.9310263638898355; \n",
      " validation loss : 0.6676703673951416; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6066243283727633; train accuracy : 0.9448979212491093; \n",
      " validation loss : 0.654971751620179; validation accuracy : 0.895397489539749\n",
      "Epoch 10:\t train loss : 0.600690818991281; train accuracy : 0.9504721335853031; \n",
      " validation loss : 0.6573629024165685; validation accuracy : 0.895397489539749\n",
      "Epoch 11:\t train loss : 0.5934597054762786; train accuracy : 0.9583159329595092; \n",
      " validation loss : 0.669572784118219; validation accuracy : 0.8828451882845189\n",
      "Epoch 12:\t train loss : 0.5921674257561479; train accuracy : 0.9594429815050033; \n",
      " validation loss : 0.6541718619738455; validation accuracy : 0.895397489539749\n",
      "Epoch 13:\t train loss : 0.5880119179593711; train accuracy : 0.9634607639641872; \n",
      " validation loss : 0.637551237700145; validation accuracy : 0.899581589958159\n",
      "Epoch 14:\t train loss : 0.587563414853777; train accuracy : 0.9639793673905636; \n",
      " validation loss : 0.6410616676799823; validation accuracy : 0.9121338912133892\n",
      "Epoch 15:\t train loss : 0.5899274121414999; train accuracy : 0.9611815731590198; \n",
      " validation loss : 0.6146625636485907; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5920247290502686; train accuracy : 0.9589804516868552; \n",
      " validation loss : 0.6256395645132031; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.58326964438613; train accuracy : 0.967949131013972; \n",
      " validation loss : 0.6206895296223541; validation accuracy : 0.9288702928870293\n",
      "Epoch 18:\t train loss : 0.5772772111815083; train accuracy : 0.9742941231140989; \n",
      " validation loss : 0.6183368624926587; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.584764704766904; train accuracy : 0.9662895380897797; \n",
      " validation loss : 0.6308194552183681; validation accuracy : 0.9163179916317992\n",
      "Epoch 20:\t train loss : 0.5803934270618598; train accuracy : 0.971037516651693; \n",
      " validation loss : 0.6177203677819786; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5776469415359116; train accuracy : 0.973680411412993; \n",
      " validation loss : 0.6082120602127161; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5788933907148308; train accuracy : 0.9724988382539732; \n",
      " validation loss : 0.7542883328187859; validation accuracy : 0.7949790794979079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:\t train loss : 0.5935533600327149; train accuracy : 0.95752222807398; \n",
      " validation loss : 0.637258358693677; validation accuracy : 0.9121338912133892\n",
      "Epoch 24:\t train loss : 0.5833576765698584; train accuracy : 0.9680206945692246; \n",
      " validation loss : 0.618797428527176; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5823111531136775; train accuracy : 0.9689169429040553; \n",
      " validation loss : 0.6467721367082918; validation accuracy : 0.9037656903765691\n",
      "Epoch 26:\t train loss : 0.5792391994353782; train accuracy : 0.9721041544037919; \n",
      " validation loss : 0.6150821333145786; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5735438661846151; train accuracy : 0.9776244617243409; \n",
      " validation loss : 0.6448037078135617; validation accuracy : 0.9037656903765691\n",
      "Epoch 28:\t train loss : 0.5775844468055833; train accuracy : 0.973854518417547; \n",
      " validation loss : 0.6638999059307673; validation accuracy : 0.8786610878661087\n",
      "Epoch 29:\t train loss : 0.5752022244948686; train accuracy : 0.9760172248210911; \n",
      " validation loss : 0.6665958422484238; validation accuracy : 0.8786610878661087\n",
      "Epoch 30:\t train loss : 0.5734284682525933; train accuracy : 0.9776554416183897; \n",
      " validation loss : 0.6120492955675028; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5757618979383433; train accuracy : 0.9755680163573841; \n",
      " validation loss : 0.6377339903571391; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.570409682855936; train accuracy : 0.980914216673379; \n",
      " validation loss : 0.6007849233868706; validation accuracy : 0.9497907949790795\n",
      "Epoch 33:\t train loss : 0.5714746905289966; train accuracy : 0.9798144304346479; \n",
      " validation loss : 0.6122574266391402; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5699778641787464; train accuracy : 0.9812645992750705; \n",
      " validation loss : 0.6353718841162797; validation accuracy : 0.9163179916317992\n",
      "Epoch 35:\t train loss : 0.57235630273302; train accuracy : 0.9786158183339013; \n",
      " validation loss : 0.6143424946695394; validation accuracy : 0.9330543933054394\n",
      "Epoch 36:\t train loss : 0.567339013203021; train accuracy : 0.9840122060782552; \n",
      " validation loss : 0.6148280270465977; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5678486927905758; train accuracy : 0.9832996685151337; \n",
      " validation loss : 0.6051242604131358; validation accuracy : 0.9456066945606695\n",
      "Epoch 38:\t train loss : 0.5677889519378161; train accuracy : 0.9834347408531863; \n",
      " validation loss : 0.6597224957317714; validation accuracy : 0.891213389121339\n",
      "Epoch 39:\t train loss : 0.5816124494913715; train accuracy : 0.9691108770408006; \n",
      " validation loss : 0.6228095627273824; validation accuracy : 0.9288702928870293\n",
      "Epoch 40:\t train loss : 0.5690666547761672; train accuracy : 0.9822441835248923; \n",
      " validation loss : 0.590374438979524; validation accuracy : 0.9623430962343096\n",
      "Epoch 41:\t train loss : 0.567349124057848; train accuracy : 0.983841816660987; \n",
      " validation loss : 0.6215986997613062; validation accuracy : 0.9288702928870293\n",
      "Epoch 42:\t train loss : 0.561791640627632; train accuracy : 0.98953623098609; \n",
      " validation loss : 0.6022197345227319; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.5622072907895748; train accuracy : 0.9892072245112922; \n",
      " validation loss : 0.6615262617912249; validation accuracy : 0.891213389121339\n",
      "Epoch 44:\t train loss : 0.5658176115749027; train accuracy : 0.9854741472784163; \n",
      " validation loss : 0.6149396106399755; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5778363324751294; train accuracy : 0.9732327519439884; \n",
      " validation loss : 0.6151456211116424; validation accuracy : 0.9330543933054394\n",
      "Epoch 46:\t train loss : 0.5735792973240114; train accuracy : 0.9775587843489575; \n",
      " validation loss : 0.5974714259818491; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5678839020645569; train accuracy : 0.9832590848539298; \n",
      " validation loss : 0.6025557161542314; validation accuracy : 0.9497907949790795\n",
      "Epoch 48:\t train loss : 0.5727351505814278; train accuracy : 0.9783583754143561; \n",
      " validation loss : 0.6489266040072672; validation accuracy : 0.899581589958159\n",
      "Epoch 49:\t train loss : 0.5736120766270653; train accuracy : 0.9772799653025187; \n",
      " validation loss : 0.6030076365782239; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5632210009424721; train accuracy : 0.9880609684314879; \n",
      " validation loss : 0.598175836846625; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5613587939871615; train accuracy : 0.9899758356826419; \n",
      " validation loss : 0.5949658555853632; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5611463503696351; train accuracy : 0.9902760308559745; \n",
      " validation loss : 0.5943412436313528; validation accuracy : 0.9581589958158996\n",
      "Epoch 53:\t train loss : 0.5669840561537479; train accuracy : 0.9843374949657672; \n",
      " validation loss : 0.617827893325451; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5655346417458316; train accuracy : 0.985843737414418; \n",
      " validation loss : 0.6218505197518004; validation accuracy : 0.9246861924686193\n",
      "Epoch 55:\t train loss : 0.5669886252537717; train accuracy : 0.9842984602992658; \n",
      " validation loss : 0.6023990279751187; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.561568105301196; train accuracy : 0.9897626940115865; \n",
      " validation loss : 0.6002235894034685; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5620784609416816; train accuracy : 0.9892227144583166; \n",
      " validation loss : 0.6186973031494898; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.5669983849510538; train accuracy : 0.9841729917283683; \n",
      " validation loss : 0.617771929552827; validation accuracy : 0.9330543933054394\n",
      "Epoch 59:\t train loss : 0.5658223358813106; train accuracy : 0.9854159050776047; \n",
      " validation loss : 0.5952602776015198; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5614838914194591; train accuracy : 0.9898268223922674; \n",
      " validation loss : 0.6007576017362325; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5610756297164651; train accuracy : 0.9901189627931473; \n",
      " validation loss : 0.6122591897143143; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5665852246849531; train accuracy : 0.9845233743300598; \n",
      " validation loss : 0.5944439465358794; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.5598496510161334; train accuracy : 0.9915056228507698; \n",
      " validation loss : 0.6024291910070567; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5698609564035166; train accuracy : 0.9811598872331857; \n",
      " validation loss : 0.6324423927678164; validation accuracy : 0.9079497907949791\n",
      "Epoch 65:\t train loss : 0.5859747501905944; train accuracy : 0.9648201617150469; \n",
      " validation loss : 0.6180008315075476; validation accuracy : 0.9288702928870293\n",
      "Epoch 66:\t train loss : 0.5660542502853753; train accuracy : 0.9851584621580595; \n",
      " validation loss : 0.6090132421929232; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5650175849805072; train accuracy : 0.9862545308095046; \n",
      " validation loss : 0.6064833150945967; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5612816184357446; train accuracy : 0.9900724929520741; \n",
      " validation loss : 0.6048125960493594; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5637210284592764; train accuracy : 0.9874664642646922; \n",
      " validation loss : 0.6175900562486915; validation accuracy : 0.9330543933054394\n",
      "Epoch 70:\t train loss : 0.5614267505352947; train accuracy : 0.9898209362123982; \n",
      " validation loss : 0.5916489948459478; validation accuracy : 0.9581589958158996\n",
      "Epoch 71:\t train loss : 0.5697205109327688; train accuracy : 0.9812918615818333; \n",
      " validation loss : 0.6164938655003757; validation accuracy : 0.9372384937238494\n",
      "Epoch 72:\t train loss : 0.5674818960124524; train accuracy : 0.9836057498683355; \n",
      " validation loss : 0.6053487218457739; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5631358045862; train accuracy : 0.9881133244524304; \n",
      " validation loss : 0.5907588016014844; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74:\t train loss : 0.5622312755614303; train accuracy : 0.9892440905852102; \n",
      " validation loss : 0.6001446265454417; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.5599899785111295; train accuracy : 0.9913891384491464; \n",
      " validation loss : 0.6162353875784463; validation accuracy : 0.9372384937238494\n",
      "Epoch 76:\t train loss : 0.5615379453041561; train accuracy : 0.9898150500325289; \n",
      " validation loss : 0.5901349011779505; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5622712746110913; train accuracy : 0.9891083986492766; \n",
      " validation loss : 0.6012680473237971; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5585953590790208; train accuracy : 0.9927950060410793; \n",
      " validation loss : 0.5931890510339312; validation accuracy : 0.9623430962343096\n",
      "Epoch 79:\t train loss : 0.5715506764626956; train accuracy : 0.9795777440441154; \n",
      " validation loss : 0.6116013328425826; validation accuracy : 0.9414225941422594\n",
      "Epoch 80:\t train loss : 0.5667231460953377; train accuracy : 0.9844731869017008; \n",
      " validation loss : 0.6110334300599405; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.5608931120352534; train accuracy : 0.9904656278075529; \n",
      " validation loss : 0.62011849298907; validation accuracy : 0.9288702928870293\n",
      "Epoch 82:\t train loss : 0.5824064387025971; train accuracy : 0.968609312556151; \n",
      " validation loss : 0.6133159783864612; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5652142849916357; train accuracy : 0.9859425632764336; \n",
      " validation loss : 0.6322014398126283; validation accuracy : 0.9205020920502092\n",
      "Epoch 84:\t train loss : 0.5642450240345487; train accuracy : 0.9871064778958456; \n",
      " validation loss : 0.5858457314862489; validation accuracy : 0.9665271966527197\n",
      "Epoch 85:\t train loss : 0.5619587169093373; train accuracy : 0.989398990055454; \n",
      " validation loss : 0.6038096617418726; validation accuracy : 0.9456066945606695\n",
      "Epoch 86:\t train loss : 0.5617265429845416; train accuracy : 0.9895015335047554; \n",
      " validation loss : 0.6030555046297151; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.560029575358263; train accuracy : 0.9911840515505437; \n",
      " validation loss : 0.6091713824098591; validation accuracy : 0.9414225941422594\n",
      "Epoch 88:\t train loss : 0.5651452899314708; train accuracy : 0.9860200130115555; \n",
      " validation loss : 0.6202215872852056; validation accuracy : 0.9288702928870293\n",
      "Epoch 89:\t train loss : 0.5610767931176341; train accuracy : 0.9902819170358437; \n",
      " validation loss : 0.6004116490969803; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5588297341573559; train accuracy : 0.9925124694073546; \n",
      " validation loss : 0.5988893801093975; validation accuracy : 0.9497907949790795\n",
      "Epoch 91:\t train loss : 0.5600431995192114; train accuracy : 0.9912577836983797; \n",
      " validation loss : 0.6050832294422329; validation accuracy : 0.9497907949790795\n",
      "Epoch 92:\t train loss : 0.5623269795870548; train accuracy : 0.9890058551999752; \n",
      " validation loss : 0.61377609630803; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5612524087909723; train accuracy : 0.9900591715976331; \n",
      " validation loss : 0.61567656051277; validation accuracy : 0.9330543933054394\n",
      "Epoch 94:\t train loss : 0.5601047882172399; train accuracy : 0.9912828774125593; \n",
      " validation loss : 0.611325413523118; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.5616983479205081; train accuracy : 0.9896195669010812; \n",
      " validation loss : 0.6163016336278728; validation accuracy : 0.9330543933054394\n",
      "Epoch 96:\t train loss : 0.5599374726195973; train accuracy : 0.9913603271476812; \n",
      " validation loss : 0.5890164498371357; validation accuracy : 0.9623430962343096\n",
      "Epoch 97:\t train loss : 0.570795465578411; train accuracy : 0.9802267728244369; \n",
      " validation loss : 0.6299189930332586; validation accuracy : 0.9205020920502092\n",
      "Epoch 98:\t train loss : 0.5693402265284205; train accuracy : 0.9819808544254779; \n",
      " validation loss : 0.6001052154255218; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5771063664767921; train accuracy : 0.9738198209362124; \n",
      " validation loss : 0.6088928218254226; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5638170379961678; train accuracy : 0.9875652901267078; \n",
      " validation loss : 0.6000648600637895; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.5611510960652569; train accuracy : 0.9901403389200409; \n",
      " validation loss : 0.6041366692083655; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5623524960020311; train accuracy : 0.9889438954118777; \n",
      " validation loss : 0.6174519958123077; validation accuracy : 0.9330543933054394\n",
      "Epoch 103:\t train loss : 0.5593059040311178; train accuracy : 0.9921097307847208; \n",
      " validation loss : 0.6009979164375633; validation accuracy : 0.9497907949790795\n",
      "Epoch 104:\t train loss : 0.5576855089234982; train accuracy : 0.9936683292543139; \n",
      " validation loss : 0.5983843901249641; validation accuracy : 0.9497907949790795\n",
      "Epoch 105:\t train loss : 0.5590759367091386; train accuracy : 0.9922587440750953; \n",
      " validation loss : 0.6016485360385774; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.5618578239769962; train accuracy : 0.9894144800024783; \n",
      " validation loss : 0.5943916803225348; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5598182946393; train accuracy : 0.9914842467238761; \n",
      " validation loss : 0.6094046104543815; validation accuracy : 0.9414225941422594\n",
      "Epoch 108:\t train loss : 0.5770119846483914; train accuracy : 0.973766845317389; \n",
      " validation loss : 0.6583339120350213; validation accuracy : 0.899581589958159\n",
      "Epoch 109:\t train loss : 0.5924799055928106; train accuracy : 0.9578667244958022; \n",
      " validation loss : 0.6525089709448176; validation accuracy : 0.899581589958159\n",
      "Epoch 110:\t train loss : 0.6919519688436623; train accuracy : 0.8566681123950556; \n",
      " validation loss : 0.7078620169239221; validation accuracy : 0.8368200836820083\n",
      "Epoch 111:\t train loss : 0.6128724573830289; train accuracy : 0.9374023358840112; \n",
      " validation loss : 0.6517355904336611; validation accuracy : 0.895397489539749\n",
      "Epoch 112:\t train loss : 0.602806086212735; train accuracy : 0.9477480715015955; \n",
      " validation loss : 0.6361538637031041; validation accuracy : 0.9163179916317992\n",
      "Epoch 113:\t train loss : 0.5826685414109712; train accuracy : 0.9683165525573902; \n",
      " validation loss : 0.6127131539831294; validation accuracy : 0.9414225941422594\n",
      "Epoch 114:\t train loss : 0.5749799446433558; train accuracy : 0.9761470305771555; \n",
      " validation loss : 0.5987548391250022; validation accuracy : 0.9497907949790795\n",
      "Epoch 115:\t train loss : 0.5748631950766423; train accuracy : 0.9760887883763437; \n",
      " validation loss : 0.616281550929925; validation accuracy : 0.9330543933054394\n",
      "Epoch 116:\t train loss : 0.5706224777970383; train accuracy : 0.9806140215000465; \n",
      " validation loss : 0.6304841715394712; validation accuracy : 0.9205020920502092\n",
      "Epoch 117:\t train loss : 0.5673850693739637; train accuracy : 0.9839112116236562; \n",
      " validation loss : 0.6216402606291649; validation accuracy : 0.9246861924686193\n",
      "Epoch 118:\t train loss : 0.5692689874657288; train accuracy : 0.9819653644784535; \n",
      " validation loss : 0.6110194260647372; validation accuracy : 0.9414225941422594\n",
      "Epoch 119:\t train loss : 0.5647959236307398; train accuracy : 0.9864323554013446; \n",
      " validation loss : 0.6165012668506414; validation accuracy : 0.9372384937238494\n",
      "Epoch 120:\t train loss : 0.5648596450089453; train accuracy : 0.9864419591684996; \n",
      " validation loss : 0.6124722740519176; validation accuracy : 0.9372384937238494\n",
      "Epoch 121:\t train loss : 0.5662335219700472; train accuracy : 0.9850500325288888; \n",
      " validation loss : 0.6160558068863253; validation accuracy : 0.9330543933054394\n",
      "Epoch 122:\t train loss : 0.5663331260230562; train accuracy : 0.9848855292914899; \n",
      " validation loss : 0.6061014882107201; validation accuracy : 0.9456066945606695\n",
      "Epoch 123:\t train loss : 0.5656735738814637; train accuracy : 0.9854623749186778; \n",
      " validation loss : 0.6056217643813093; validation accuracy : 0.9414225941422594\n",
      "Epoch 124:\t train loss : 0.5635375367884969; train accuracy : 0.9878072430992286; \n",
      " validation loss : 0.5997681866059384; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125:\t train loss : 0.5699249443057153; train accuracy : 0.9811406796988754; \n",
      " validation loss : 0.6307143241155471; validation accuracy : 0.9163179916317992\n",
      "Epoch 126:\t train loss : 0.5747657978108683; train accuracy : 0.9763195885870071; \n",
      " validation loss : 0.6178331693827295; validation accuracy : 0.9330543933054394\n",
      "Epoch 127:\t train loss : 0.5667251768283564; train accuracy : 0.9845698441711329; \n",
      " validation loss : 0.6075909522898216; validation accuracy : 0.9414225941422594\n",
      "Epoch 128:\t train loss : 0.5627646294530892; train accuracy : 0.9885662505034233; \n",
      " validation loss : 0.6063465133821309; validation accuracy : 0.9456066945606695\n",
      "Epoch 129:\t train loss : 0.5634685826674135; train accuracy : 0.9878611481148735; \n",
      " validation loss : 0.6169650085787517; validation accuracy : 0.9330543933054394\n",
      "Epoch 130:\t train loss : 0.5624166147722515; train accuracy : 0.9888701632640416; \n",
      " validation loss : 0.6027962339384341; validation accuracy : 0.9497907949790795\n",
      "Epoch 131:\t train loss : 0.5662950299774956; train accuracy : 0.9848604355773103; \n",
      " validation loss : 0.61718478315051; validation accuracy : 0.9288702928870293\n",
      "Epoch 132:\t train loss : 0.5622809924504393; train accuracy : 0.9890715325753586; \n",
      " validation loss : 0.589777656745761; validation accuracy : 0.9623430962343096\n",
      "Epoch 133:\t train loss : 0.567489546374896; train accuracy : 0.9838086681743549; \n",
      " validation loss : 0.6152553138557728; validation accuracy : 0.9330543933054394\n",
      "Epoch 134:\t train loss : 0.5635973732718038; train accuracy : 0.987772545617894; \n",
      " validation loss : 0.5852631751216252; validation accuracy : 0.9665271966527197\n",
      "Epoch 135:\t train loss : 0.5630010568948913; train accuracy : 0.9882527339756498; \n",
      " validation loss : 0.6017920974793354; validation accuracy : 0.9497907949790795\n",
      "Epoch 136:\t train loss : 0.5619961821764314; train accuracy : 0.9891452647231946; \n",
      " validation loss : 0.6114460506010385; validation accuracy : 0.9372384937238494\n",
      "Epoch 137:\t train loss : 0.5622127055951573; train accuracy : 0.9891511509030639; \n",
      " validation loss : 0.5790858940445304; validation accuracy : 0.9748953974895398\n",
      "Epoch 138:\t train loss : 0.5595736149814853; train accuracy : 0.9918154217912575; \n",
      " validation loss : 0.5968554400878033; validation accuracy : 0.9539748953974896\n",
      "Epoch 139:\t train loss : 0.5613903818576201; train accuracy : 0.9899699495027727; \n",
      " validation loss : 0.6219021566785363; validation accuracy : 0.9288702928870293\n",
      "Epoch 140:\t train loss : 0.5644213950688688; train accuracy : 0.9869921620868056; \n",
      " validation loss : 0.6093061544238391; validation accuracy : 0.9414225941422594\n",
      "Epoch 141:\t train loss : 0.5624038936633093; train accuracy : 0.988798599708789; \n",
      " validation loss : 0.613069862369578; validation accuracy : 0.9372384937238494\n",
      "Epoch 142:\t train loss : 0.5610030057840807; train accuracy : 0.9902797484432603; \n",
      " validation loss : 0.6185812480955547; validation accuracy : 0.9330543933054394\n",
      "Epoch 143:\t train loss : 0.5650051866029115; train accuracy : 0.9862678521639456; \n",
      " validation loss : 0.6072530553008132; validation accuracy : 0.9456066945606695\n",
      "Epoch 144:\t train loss : 0.5621115238236273; train accuracy : 0.9892691842993897; \n",
      " validation loss : 0.6336130606175018; validation accuracy : 0.9163179916317992\n",
      "Epoch 145:\t train loss : 0.5605973065236376; train accuracy : 0.9907311254995508; \n",
      " validation loss : 0.6172497694552045; validation accuracy : 0.9330543933054394\n",
      "Epoch 146:\t train loss : 0.5615808895250899; train accuracy : 0.9897199417577992; \n",
      " validation loss : 0.592358208466597; validation accuracy : 0.9581589958158996\n",
      "Epoch 147:\t train loss : 0.5631817312834275; train accuracy : 0.9880513646643329; \n",
      " validation loss : 0.6008786027881646; validation accuracy : 0.9497907949790795\n",
      "Epoch 148:\t train loss : 0.5666431140065262; train accuracy : 0.9844245484680443; \n",
      " validation loss : 0.5870613657170245; validation accuracy : 0.9623430962343096\n",
      "Epoch 149:\t train loss : 0.5627632217231078; train accuracy : 0.9884615384615385; \n",
      " validation loss : 0.6068592183298638; validation accuracy : 0.9414225941422594\n",
      "Epoch 150:\t train loss : 0.5649053879118736; train accuracy : 0.986347470491651; \n",
      " validation loss : 0.6017076536979982; validation accuracy : 0.9497907949790795\n",
      "Epoch 151:\t train loss : 0.5619421241466224; train accuracy : 0.9893156541404629; \n",
      " validation loss : 0.5932898192009533; validation accuracy : 0.9581589958158996\n",
      "Epoch 152:\t train loss : 0.5605362182827757; train accuracy : 0.9908550450757458; \n",
      " validation loss : 0.6028117709604602; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.5617984387657378; train accuracy : 0.9894705536107067; \n",
      " validation loss : 0.5918160997273098; validation accuracy : 0.9581589958158996\n",
      "Epoch 154:\t train loss : 0.5595953597753004; train accuracy : 0.9918132531986741; \n",
      " validation loss : 0.5813801098931357; validation accuracy : 0.9707112970711297\n",
      "Epoch 155:\t train loss : 0.5608231897555707; train accuracy : 0.9904715139874222; \n",
      " validation loss : 0.5917512084485088; validation accuracy : 0.9581589958158996\n",
      "Epoch 156:\t train loss : 0.5640842528099436; train accuracy : 0.9872533225936367; \n",
      " validation loss : 0.5918698376405577; validation accuracy : 0.9581589958158996\n",
      "Epoch 157:\t train loss : 0.560047308410952; train accuracy : 0.9913020849468694; \n",
      " validation loss : 0.5913250991273461; validation accuracy : 0.9581589958158996\n",
      "Epoch 158:\t train loss : 0.5621587756574171; train accuracy : 0.989187397379101; \n",
      " validation loss : 0.5978813029955108; validation accuracy : 0.9497907949790795\n",
      "Epoch 159:\t train loss : 0.5603596628669276; train accuracy : 0.9909362123981535; \n",
      " validation loss : 0.581379733433095; validation accuracy : 0.9707112970711297\n",
      "Epoch 160:\t train loss : 0.5594687806241715; train accuracy : 0.9919061928808204; \n",
      " validation loss : 0.6013495807151701; validation accuracy : 0.9497907949790795\n",
      "Epoch 161:\t train loss : 0.5589252285813787; train accuracy : 0.9925530530685585; \n",
      " validation loss : 0.6014313281567204; validation accuracy : 0.9497907949790795\n",
      "Epoch 162:\t train loss : 0.5615929496282601; train accuracy : 0.9896778091018928; \n",
      " validation loss : 0.5959933334195882; validation accuracy : 0.9581589958158996\n",
      "Epoch 163:\t train loss : 0.560327613438335; train accuracy : 0.9910815081012423; \n",
      " validation loss : 0.6061971253641066; validation accuracy : 0.9456066945606695\n",
      "Epoch 164:\t train loss : 0.5645980369707869; train accuracy : 0.9867539267015707; \n",
      " validation loss : 0.6010925717418913; validation accuracy : 0.9456066945606695\n",
      "Epoch 165:\t train loss : 0.5621022656120427; train accuracy : 0.9892691842993897; \n",
      " validation loss : 0.6015818164737281; validation accuracy : 0.9497907949790795\n",
      "Epoch 166:\t train loss : 0.5606450898675215; train accuracy : 0.9905607360822826; \n",
      " validation loss : 0.5897068516542655; validation accuracy : 0.9581589958158996\n",
      "Epoch 167:\t train loss : 0.5595832748165571; train accuracy : 0.9917261996963971; \n",
      " validation loss : 0.5884123817540398; validation accuracy : 0.9623430962343096\n",
      "Epoch 168:\t train loss : 0.5592906053139298; train accuracy : 0.9920765822980885; \n",
      " validation loss : 0.6016170117357136; validation accuracy : 0.9456066945606695\n",
      "Epoch 169:\t train loss : 0.5693039398448242; train accuracy : 0.9819830230180613; \n",
      " validation loss : 0.623022426043188; validation accuracy : 0.9246861924686193\n",
      "Epoch 170:\t train loss : 0.5605139787034029; train accuracy : 0.9907444468539918; \n",
      " validation loss : 0.610083025900182; validation accuracy : 0.9414225941422594\n",
      "Epoch 171:\t train loss : 0.5598441035488341; train accuracy : 0.9915462065119737; \n",
      " validation loss : 0.6004476898349939; validation accuracy : 0.9497907949790795\n",
      "Epoch 172:\t train loss : 0.5639520717169082; train accuracy : 0.9872650949533752; \n",
      " validation loss : 0.5927667654532126; validation accuracy : 0.9581589958158996\n",
      "Epoch 173:\t train loss : 0.5590545129835145; train accuracy : 0.9922956101490132; \n",
      " validation loss : 0.5915860674406581; validation accuracy : 0.9539748953974896\n",
      "Epoch 174:\t train loss : 0.5621810468206572; train accuracy : 0.9891821307971127; \n",
      " validation loss : 0.595820365287548; validation accuracy : 0.9539748953974896\n",
      "Epoch 175:\t train loss : 0.5598789313597677; train accuracy : 0.9913795346819914; \n",
      " validation loss : 0.604121258993355; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176:\t train loss : 0.557267467938846; train accuracy : 0.9941581213792249; \n",
      " validation loss : 0.6022014310596061; validation accuracy : 0.9497907949790795\n",
      "Epoch 177:\t train loss : 0.5640298792695121; train accuracy : 0.987209021345147; \n",
      " validation loss : 0.6098355190077374; validation accuracy : 0.9414225941422594\n",
      "Epoch 178:\t train loss : 0.5615545998580068; train accuracy : 0.9897338827101211; \n",
      " validation loss : 0.6099097356891474; validation accuracy : 0.9372384937238494\n",
      "Epoch 179:\t train loss : 0.5588355492621859; train accuracy : 0.9925103008147712; \n",
      " validation loss : 0.6016874151159927; validation accuracy : 0.9497907949790795\n",
      "Epoch 180:\t train loss : 0.562932937697788; train accuracy : 0.9883493912450819; \n",
      " validation loss : 0.5965539129417812; validation accuracy : 0.9539748953974896\n",
      "Epoch 181:\t train loss : 0.5585285648545257; train accuracy : 0.9928222683478423; \n",
      " validation loss : 0.5864791895354504; validation accuracy : 0.9665271966527197\n",
      "Epoch 182:\t train loss : 0.5583096015668473; train accuracy : 0.9930738250875182; \n",
      " validation loss : 0.5861998900748118; validation accuracy : 0.9665271966527197\n",
      "Epoch 183:\t train loss : 0.558932267444489; train accuracy : 0.9923826636512904; \n",
      " validation loss : 0.5916615409086403; validation accuracy : 0.9581589958158996\n",
      "Epoch 184:\t train loss : 0.5641416403201958; train accuracy : 0.9872650949533752; \n",
      " validation loss : 0.5882714780777634; validation accuracy : 0.9623430962343096\n",
      "Epoch 185:\t train loss : 0.5592464294796395; train accuracy : 0.9920669785309334; \n",
      " validation loss : 0.5952474869846579; validation accuracy : 0.9581589958158996\n",
      "Epoch 186:\t train loss : 0.5575762037487172; train accuracy : 0.9938136249574027; \n",
      " validation loss : 0.5922172167088502; validation accuracy : 0.9581589958158996\n",
      "Epoch 187:\t train loss : 0.5585685078978955; train accuracy : 0.9927795160940549; \n",
      " validation loss : 0.6003272191531778; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 187\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5622127055951573; Train accuracy : 0.9891511509030639; \n",
      " Validation loss : 0.5790858940445304; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 46 ! ---\n",
      "Epoch 1:\t train loss : 0.9463645839055334; train accuracy : 0.5759172217231017; \n",
      " validation loss : 0.8274243704401826; validation accuracy : 0.7196652719665272\n",
      "Epoch 2:\t train loss : 0.7454807804653693; train accuracy : 0.8033647882524242; \n",
      " validation loss : 0.7193617979962599; validation accuracy : 0.8284518828451883\n",
      "Epoch 3:\t train loss : 0.6935065456987597; train accuracy : 0.8566857709346634; \n",
      " validation loss : 0.6838396148071786; validation accuracy : 0.8661087866108786\n",
      "Epoch 4:\t train loss : 0.6661944987445252; train accuracy : 0.8842759688961863; \n",
      " validation loss : 0.6962227772550476; validation accuracy : 0.8451882845188284\n",
      "Epoch 5:\t train loss : 0.6441494372895671; train accuracy : 0.9065987174323864; \n",
      " validation loss : 0.6820504445921859; validation accuracy : 0.8661087866108786\n",
      "Epoch 6:\t train loss : 0.6253206020261887; train accuracy : 0.9261797453452709; \n",
      " validation loss : 0.638028782398755; validation accuracy : 0.9079497907949791\n",
      "Epoch 7:\t train loss : 0.6132004422017879; train accuracy : 0.938487933331268; \n",
      " validation loss : 0.6615633683523938; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6078101550620001; train accuracy : 0.9436113882090523; \n",
      " validation loss : 0.6357056026736364; validation accuracy : 0.9163179916317992\n",
      "Epoch 9:\t train loss : 0.604164631993274; train accuracy : 0.9470183091173828; \n",
      " validation loss : 0.615978360654135; validation accuracy : 0.9414225941422594\n",
      "Epoch 10:\t train loss : 0.5999983226985031; train accuracy : 0.9514074165866353; \n",
      " validation loss : 0.6222052130177566; validation accuracy : 0.9288702928870293\n",
      "Epoch 11:\t train loss : 0.6106986540118269; train accuracy : 0.9396987515102698; \n",
      " validation loss : 0.6286116067113797; validation accuracy : 0.9163179916317992\n",
      "Epoch 12:\t train loss : 0.5988557935419373; train accuracy : 0.9527831717215527; \n",
      " validation loss : 0.6483426311935521; validation accuracy : 0.899581589958159\n",
      "Epoch 13:\t train loss : 0.5981740297335636; train accuracy : 0.9527002695250782; \n",
      " validation loss : 0.6122971271946636; validation accuracy : 0.9414225941422594\n",
      "Epoch 14:\t train loss : 0.5895956390132066; train accuracy : 0.9616589113665232; \n",
      " validation loss : 0.6178244378023584; validation accuracy : 0.9414225941422594\n",
      "Epoch 15:\t train loss : 0.588480963377432; train accuracy : 0.9628935221041544; \n",
      " validation loss : 0.6243364483895208; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.5883626718756599; train accuracy : 0.9631186839741008; \n",
      " validation loss : 0.6040096769919335; validation accuracy : 0.9539748953974896\n",
      "Epoch 17:\t train loss : 0.5904398487798062; train accuracy : 0.9607613618761424; \n",
      " validation loss : 0.6004263232948904; validation accuracy : 0.9497907949790795\n",
      "Epoch 18:\t train loss : 0.5855122532837893; train accuracy : 0.9656071129836736; \n",
      " validation loss : 0.6266038221493844; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.5856910700686156; train accuracy : 0.9656406951888225; \n",
      " validation loss : 0.6212403842390759; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.5843239616505596; train accuracy : 0.9669209083304935; \n",
      " validation loss : 0.6154759372245767; validation accuracy : 0.9372384937238494\n",
      "Epoch 21:\t train loss : 0.5822779853048542; train accuracy : 0.968736949719632; \n",
      " validation loss : 0.6107081956401044; validation accuracy : 0.9372384937238494\n",
      "Epoch 22:\t train loss : 0.5909597129686076; train accuracy : 0.9600717494346169; \n",
      " validation loss : 0.624166762703753; validation accuracy : 0.9288702928870293\n",
      "Epoch 23:\t train loss : 0.5911224860733024; train accuracy : 0.9596661606617305; \n",
      " validation loss : 0.6138411962649114; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5804708352142897; train accuracy : 0.9706995879674092; \n",
      " validation loss : 0.6005260281546639; validation accuracy : 0.9539748953974896\n",
      "Epoch 25:\t train loss : 0.5807729321850844; train accuracy : 0.970313206728833; \n",
      " validation loss : 0.6123030960227944; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5765466400577548; train accuracy : 0.9748827411010255; \n",
      " validation loss : 0.6368651917770065; validation accuracy : 0.9163179916317992\n",
      "Epoch 27:\t train loss : 0.5722529707398014; train accuracy : 0.9791014591530097; \n",
      " validation loss : 0.596042368379211; validation accuracy : 0.9539748953974896\n",
      "Epoch 28:\t train loss : 0.5710386579910247; train accuracy : 0.9803524272746987; \n",
      " validation loss : 0.6271732156087367; validation accuracy : 0.9205020920502092\n",
      "Epoch 29:\t train loss : 0.5720510931015944; train accuracy : 0.9793811456364819; \n",
      " validation loss : 0.6130588473784426; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5756326463943768; train accuracy : 0.9754558691409275; \n",
      " validation loss : 0.6020294863626904; validation accuracy : 0.9539748953974896\n",
      "Epoch 31:\t train loss : 0.5741954667403718; train accuracy : 0.9769274141082438; \n",
      " validation loss : 0.608829727701377; validation accuracy : 0.9414225941422594\n",
      "Epoch 32:\t train loss : 0.5750171885126025; train accuracy : 0.9759888472381425; \n",
      " validation loss : 0.6115440510991128; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5709837692911228; train accuracy : 0.9801401530406766; \n",
      " validation loss : 0.6105462373436679; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5658257826231946; train accuracy : 0.9855926143932587; \n",
      " validation loss : 0.6124364853937926; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5737758132200442; train accuracy : 0.97720078069333; \n",
      " validation loss : 0.6124690212001608; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.5684319295625486; train accuracy : 0.9826796369156418; \n",
      " validation loss : 0.6164476098758208; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5691202972447523; train accuracy : 0.9820181542179126; \n",
      " validation loss : 0.6127043009900922; validation accuracy : 0.9372384937238494\n",
      "Epoch 38:\t train loss : 0.5743057879123619; train accuracy : 0.9769592614393259; \n",
      " validation loss : 0.604716305395874; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39:\t train loss : 0.5669698216075937; train accuracy : 0.9843014963288825; \n",
      " validation loss : 0.6097344174526788; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5651294773067794; train accuracy : 0.986155704947489; \n",
      " validation loss : 0.5915807981434014; validation accuracy : 0.9581589958158996\n",
      "Epoch 41:\t train loss : 0.5655982559576368; train accuracy : 0.9855105796338176; \n",
      " validation loss : 0.6072675173862023; validation accuracy : 0.9414225941422594\n",
      "Epoch 42:\t train loss : 0.5667409944368615; train accuracy : 0.9845192230242572; \n",
      " validation loss : 0.6048239959131428; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5666263033363997; train accuracy : 0.9846112952693702; \n",
      " validation loss : 0.6063866373689469; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5643384897309593; train accuracy : 0.987064159360575; \n",
      " validation loss : 0.6012488827528911; validation accuracy : 0.9497907949790795\n",
      "Epoch 45:\t train loss : 0.5802028387164211; train accuracy : 0.9708180550822516; \n",
      " validation loss : 0.6549180511081072; validation accuracy : 0.895397489539749\n",
      "Epoch 46:\t train loss : 0.5735183038781225; train accuracy : 0.977786548530004; \n",
      " validation loss : 0.598589078533919; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5663816532085462; train accuracy : 0.9849018866755476; \n",
      " validation loss : 0.6047516004377319; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5715301653656187; train accuracy : 0.9797374144180427; \n",
      " validation loss : 0.6206184565535349; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5732875983592348; train accuracy : 0.9776964589981102; \n",
      " validation loss : 0.6238346764377741; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.565134454030604; train accuracy : 0.986197589764243; \n",
      " validation loss : 0.610728018650652; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5630640957436605; train accuracy : 0.9880509309458162; \n",
      " validation loss : 0.6020656993344804; validation accuracy : 0.9497907949790795\n",
      "Epoch 52:\t train loss : 0.5709381545821876; train accuracy : 0.9802695250782242; \n",
      " validation loss : 0.6248288738505213; validation accuracy : 0.9246861924686193\n",
      "Epoch 53:\t train loss : 0.5689833821396395; train accuracy : 0.9821329037454692; \n",
      " validation loss : 0.6404858029745091; validation accuracy : 0.9121338912133892\n",
      "Epoch 54:\t train loss : 0.564947345614143; train accuracy : 0.9863716967687971; \n",
      " validation loss : 0.5944143070895989; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5622797546968639; train accuracy : 0.9892172619969639; \n",
      " validation loss : 0.6063210362857209; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5619053218136871; train accuracy : 0.9893001641934385; \n",
      " validation loss : 0.596120794054639; validation accuracy : 0.9581589958158996\n",
      "Epoch 57:\t train loss : 0.5645032545559144; train accuracy : 0.9866258558195731; \n",
      " validation loss : 0.6080761322590037; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.561313454892198; train accuracy : 0.990048266674928; \n",
      " validation loss : 0.6220905610229207; validation accuracy : 0.9288702928870293\n",
      "Epoch 59:\t train loss : 0.5619087427897493; train accuracy : 0.9893939713126181; \n",
      " validation loss : 0.5983400135882343; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5658713746400298; train accuracy : 0.9854996747111124; \n",
      " validation loss : 0.5907966740773146; validation accuracy : 0.9581589958158996\n",
      "Epoch 61:\t train loss : 0.5618770335222067; train accuracy : 0.9894149137209951; \n",
      " validation loss : 0.6146809635376527; validation accuracy : 0.9372384937238494\n",
      "Epoch 62:\t train loss : 0.5773175364344045; train accuracy : 0.9736234703677313; \n",
      " validation loss : 0.6188467509594014; validation accuracy : 0.9330543933054394\n",
      "Epoch 63:\t train loss : 0.5674753855959215; train accuracy : 0.9836262585581957; \n",
      " validation loss : 0.5899474791080417; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.5710218238925584; train accuracy : 0.9801355680163574; \n",
      " validation loss : 0.6014466819688393; validation accuracy : 0.9497907949790795\n",
      "Epoch 65:\t train loss : 0.5654428637676958; train accuracy : 0.9856600266427089; \n",
      " validation loss : 0.6156313935864317; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.5608900647120254; train accuracy : 0.9904874376529632; \n",
      " validation loss : 0.6114569096523096; validation accuracy : 0.9414225941422594\n",
      "Epoch 67:\t train loss : 0.5630888627764811; train accuracy : 0.9881384181666099; \n",
      " validation loss : 0.6109272094325968; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5729604912663248; train accuracy : 0.9781528547972366; \n",
      " validation loss : 0.6013343664061671; validation accuracy : 0.9497907949790795\n",
      "Epoch 69:\t train loss : 0.5668023329325931; train accuracy : 0.9845028656401995; \n",
      " validation loss : 0.5923553104915015; validation accuracy : 0.9581589958158996\n",
      "Epoch 70:\t train loss : 0.571495836587816; train accuracy : 0.9797101521112798; \n",
      " validation loss : 0.6139958332626796; validation accuracy : 0.9330543933054394\n",
      "Epoch 71:\t train loss : 0.5636849195070327; train accuracy : 0.9875087827999628; \n",
      " validation loss : 0.6053144358224982; validation accuracy : 0.9456066945606695\n",
      "Epoch 72:\t train loss : 0.5645918657142165; train accuracy : 0.9868163202081849; \n",
      " validation loss : 0.592618289267935; validation accuracy : 0.9581589958158996\n",
      "Epoch 73:\t train loss : 0.5621681665573456; train accuracy : 0.9892063570742589; \n",
      " validation loss : 0.6050807625633272; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.562649168308178; train accuracy : 0.9886914712351684; \n",
      " validation loss : 0.6084480284050222; validation accuracy : 0.9414225941422594\n",
      "Epoch 75:\t train loss : 0.5622415056670131; train accuracy : 0.9891142848291459; \n",
      " validation loss : 0.6135848391918984; validation accuracy : 0.9330543933054394\n",
      "Epoch 76:\t train loss : 0.5609833751980157; train accuracy : 0.9903744229994733; \n",
      " validation loss : 0.5932978337938086; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5651170808072403; train accuracy : 0.9863206419034047; \n",
      " validation loss : 0.5856328461411325; validation accuracy : 0.9623430962343096\n",
      "Epoch 78:\t train loss : 0.5677638828969165; train accuracy : 0.9834805291365903; \n",
      " validation loss : 0.6144137560307554; validation accuracy : 0.9372384937238494\n",
      "Epoch 79:\t train loss : 0.5668376468072429; train accuracy : 0.9843542860683416; \n",
      " validation loss : 0.5867424164489718; validation accuracy : 0.9623430962343096\n",
      "Epoch 80:\t train loss : 0.5630454808431712; train accuracy : 0.988220452926051; \n",
      " validation loss : 0.5998644964153182; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5706951194678466; train accuracy : 0.9803251649679358; \n",
      " validation loss : 0.585828055893454; validation accuracy : 0.9665271966527197\n",
      "Epoch 82:\t train loss : 0.5615034223012711; train accuracy : 0.9895953406239351; \n",
      " validation loss : 0.5835442517401123; validation accuracy : 0.9665271966527197\n",
      "Epoch 83:\t train loss : 0.5620415717123647; train accuracy : 0.9891515846215806; \n",
      " validation loss : 0.5911436343625913; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.558749674890935; train accuracy : 0.9925484680442392; \n",
      " validation loss : 0.5974847887884848; validation accuracy : 0.9539748953974896\n",
      "Epoch 85:\t train loss : 0.5591210972517029; train accuracy : 0.992109297066204; \n",
      " validation loss : 0.6000859976607306; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5579943981681519; train accuracy : 0.9934058675919328; \n",
      " validation loss : 0.5829446793595245; validation accuracy : 0.9707112970711297\n",
      "Epoch 87:\t train loss : 0.5603049326387813; train accuracy : 0.9910978654853; \n",
      " validation loss : 0.5973659806080994; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5577919396813265; train accuracy : 0.9934778648657021; \n",
      " validation loss : 0.5878943531198947; validation accuracy : 0.9623430962343096\n",
      "Epoch 89:\t train loss : 0.5628136375716034; train accuracy : 0.9884619721800552; \n",
      " validation loss : 0.6110873700368045; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90:\t train loss : 0.5609358436923636; train accuracy : 0.9903643855138016; \n",
      " validation loss : 0.5819080111081039; validation accuracy : 0.9707112970711297\n",
      "Epoch 91:\t train loss : 0.5586251093967203; train accuracy : 0.9928063446823012; \n",
      " validation loss : 0.592583780482159; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5656676358265704; train accuracy : 0.9854586573313919; \n",
      " validation loss : 0.5977086281963379; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5620124572132059; train accuracy : 0.9892482418910127; \n",
      " validation loss : 0.5983129001930897; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5587698875475883; train accuracy : 0.9925229406115431; \n",
      " validation loss : 0.5896115954501202; validation accuracy : 0.9581589958158996\n",
      "Epoch 95:\t train loss : 0.5591534297375657; train accuracy : 0.9921967842869978; \n",
      " validation loss : 0.5998989991027692; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5579764165255611; train accuracy : 0.9933903776449085; \n",
      " validation loss : 0.5890090495947077; validation accuracy : 0.9623430962343096\n",
      "Epoch 97:\t train loss : 0.5582722784180881; train accuracy : 0.9929566591282257; \n",
      " validation loss : 0.6096373264867367; validation accuracy : 0.9414225941422594\n",
      "Epoch 98:\t train loss : 0.5602937149478727; train accuracy : 0.9908901762755972; \n",
      " validation loss : 0.6054832561233185; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5603007092047393; train accuracy : 0.9910505282071935; \n",
      " validation loss : 0.5868744785289186; validation accuracy : 0.9665271966527197\n",
      "Epoch 100:\t train loss : 0.5567605418990142; train accuracy : 0.9946751758108987; \n",
      " validation loss : 0.6000410382572623; validation accuracy : 0.9456066945606695\n",
      "Epoch 101:\t train loss : 0.5577605338346452; train accuracy : 0.9935498621394715; \n",
      " validation loss : 0.5895057669416783; validation accuracy : 0.9623430962343096\n",
      "Epoch 102:\t train loss : 0.5588468866807932; train accuracy : 0.9924710183091173; \n",
      " validation loss : 0.5807324917580121; validation accuracy : 0.9707112970711297\n",
      "Epoch 103:\t train loss : 0.5698340344174699; train accuracy : 0.9814266860807336; \n",
      " validation loss : 0.5950749563101654; validation accuracy : 0.9539748953974896\n",
      "Epoch 104:\t train loss : 0.5613150922889897; train accuracy : 0.9898486322376777; \n",
      " validation loss : 0.5938310237187628; validation accuracy : 0.9539748953974896\n",
      "Epoch 105:\t train loss : 0.5572911324965293; train accuracy : 0.9939480157377861; \n",
      " validation loss : 0.5994181389274622; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5570086362834985; train accuracy : 0.9942532296539546; \n",
      " validation loss : 0.5972866601871779; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.5576319509891647; train accuracy : 0.9936382167972986; \n",
      " validation loss : 0.6067548866923708; validation accuracy : 0.9456066945606695\n",
      "Epoch 108:\t train loss : 0.5577859962470975; train accuracy : 0.9935243347067753; \n",
      " validation loss : 0.5731946848354453; validation accuracy : 0.9790794979079498\n",
      "Epoch 109:\t train loss : 0.5639747890545305; train accuracy : 0.9872509061619009; \n",
      " validation loss : 0.5897164313279514; validation accuracy : 0.9623430962343096\n",
      "Epoch 110:\t train loss : 0.5627366639157966; train accuracy : 0.9884946869481707; \n",
      " validation loss : 0.5894894583864834; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5574029655194269; train accuracy : 0.9938496235942873; \n",
      " validation loss : 0.5745560291689077; validation accuracy : 0.9790794979079498\n",
      "Epoch 112:\t train loss : 0.5625968300478714; train accuracy : 0.9886596239040862; \n",
      " validation loss : 0.5997615471840417; validation accuracy : 0.9497907949790795\n",
      "Epoch 113:\t train loss : 0.5579992097712178; train accuracy : 0.9933694352365314; \n",
      " validation loss : 0.5924020597841271; validation accuracy : 0.9581589958158996\n",
      "Epoch 114:\t train loss : 0.5561568849959614; train accuracy : 0.9952072864710803; \n",
      " validation loss : 0.5982486200852135; validation accuracy : 0.9539748953974896\n",
      "Epoch 115:\t train loss : 0.556237732532137; train accuracy : 0.9951817590383841; \n",
      " validation loss : 0.5846160757255581; validation accuracy : 0.9665271966527197\n",
      "Epoch 116:\t train loss : 0.5573267737856004; train accuracy : 0.9940045230645311; \n",
      " validation loss : 0.6036616654817096; validation accuracy : 0.9497907949790795\n",
      "Epoch 117:\t train loss : 0.5567317484744293; train accuracy : 0.994717928064686; \n",
      " validation loss : 0.5932130561077535; validation accuracy : 0.9581589958158996\n",
      "Epoch 118:\t train loss : 0.5556613838837405; train accuracy : 0.9957092846742464; \n",
      " validation loss : 0.5892018737132237; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.5587131130513631; train accuracy : 0.9925065832274853; \n",
      " validation loss : 0.6044845596266684; validation accuracy : 0.9497907949790795\n",
      "Epoch 120:\t train loss : 0.5703507805139688; train accuracy : 0.9807870132284148; \n",
      " validation loss : 0.5825198458695665; validation accuracy : 0.9707112970711297\n",
      "Epoch 121:\t train loss : 0.5608862013839059; train accuracy : 0.9904054028935221; \n",
      " validation loss : 0.6037555280357249; validation accuracy : 0.9497907949790795\n",
      "Epoch 122:\t train loss : 0.5563609066376113; train accuracy : 0.995099724278943; \n",
      " validation loss : 0.590838705681694; validation accuracy : 0.9581589958158996\n",
      "Epoch 123:\t train loss : 0.5592424723434233; train accuracy : 0.9919598500573128; \n",
      " validation loss : 0.5847572779386332; validation accuracy : 0.9665271966527197\n",
      "Epoch 124:\t train loss : 0.5577000965114415; train accuracy : 0.9935607670621767; \n",
      " validation loss : 0.5838665845121934; validation accuracy : 0.9665271966527197\n",
      "Epoch 125:\t train loss : 0.5598307971557891; train accuracy : 0.9914331918584839; \n",
      " validation loss : 0.5949622689901602; validation accuracy : 0.9539748953974896\n",
      "Epoch 126:\t train loss : 0.5593941239461017; train accuracy : 0.9918924378078627; \n",
      " validation loss : 0.5972840432819673; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.5670497892249846; train accuracy : 0.9842203290064748; \n",
      " validation loss : 0.5929589603811309; validation accuracy : 0.9581589958158996\n",
      "Epoch 128:\t train loss : 0.5590969770413496; train accuracy : 0.9923143839648069; \n",
      " validation loss : 0.5930466839352304; validation accuracy : 0.9581589958158996\n",
      "Epoch 129:\t train loss : 0.5593836333125911; train accuracy : 0.9919334551875832; \n",
      " validation loss : 0.5993079643705834; validation accuracy : 0.9497907949790795\n",
      "Epoch 130:\t train loss : 0.5581474339288743; train accuracy : 0.9931844233092723; \n",
      " validation loss : 0.6096128387513247; validation accuracy : 0.9414225941422594\n",
      "Epoch 131:\t train loss : 0.5601141941160811; train accuracy : 0.991091545586914; \n",
      " validation loss : 0.6080565834529044; validation accuracy : 0.9414225941422594\n",
      "Epoch 132:\t train loss : 0.5567226224214757; train accuracy : 0.9945785185414666; \n",
      " validation loss : 0.5880287064939109; validation accuracy : 0.9623430962343096\n",
      "Epoch 133:\t train loss : 0.5549451790154897; train accuracy : 0.9963853898819666; \n",
      " validation loss : 0.6031002078430227; validation accuracy : 0.9456066945606695\n",
      "Epoch 134:\t train loss : 0.5553239961016176; train accuracy : 0.9960446110474303; \n",
      " validation loss : 0.5959756964124179; validation accuracy : 0.9539748953974896\n",
      "Epoch 135:\t train loss : 0.5543095729492764; train accuracy : 0.9971134173921125; \n",
      " validation loss : 0.5849131843930313; validation accuracy : 0.9665271966527197\n",
      "Epoch 136:\t train loss : 0.5551736007582225; train accuracy : 0.9961530406766008; \n",
      " validation loss : 0.5916753450497939; validation accuracy : 0.9581589958158996\n",
      "Epoch 137:\t train loss : 0.555825031621971; train accuracy : 0.9955279903342731; \n",
      " validation loss : 0.601128641901807; validation accuracy : 0.9497907949790795\n",
      "Epoch 138:\t train loss : 0.5581115573585894; train accuracy : 0.9931425384925183; \n",
      " validation loss : 0.5939558243171783; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5612008825872389; train accuracy : 0.9901329037454691; \n",
      " validation loss : 0.5962099163051847; validation accuracy : 0.9539748953974896\n",
      "Epoch 140:\t train loss : 0.5568339733335808; train accuracy : 0.9945320487003935; \n",
      " validation loss : 0.5861012938505653; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141:\t train loss : 0.5558913994912646; train accuracy : 0.9953986182967254; \n",
      " validation loss : 0.5917399152216994; validation accuracy : 0.9581589958158996\n",
      "Epoch 142:\t train loss : 0.5595639957361043; train accuracy : 0.9917576133089625; \n",
      " validation loss : 0.5982093800090247; validation accuracy : 0.9539748953974896\n",
      "Epoch 143:\t train loss : 0.5586152745777577; train accuracy : 0.9927397998698845; \n",
      " validation loss : 0.5959900633912655; validation accuracy : 0.9539748953974896\n",
      "Epoch 144:\t train loss : 0.5591082569238184; train accuracy : 0.9922131416710555; \n",
      " validation loss : 0.5814384849063654; validation accuracy : 0.9665271966527197\n",
      "Epoch 145:\t train loss : 0.5586221086291587; train accuracy : 0.992579447938288; \n",
      " validation loss : 0.5925707664879739; validation accuracy : 0.9581589958158996\n",
      "Epoch 146:\t train loss : 0.5555677074684351; train accuracy : 0.9958277517890889; \n",
      " validation loss : 0.6025622752578226; validation accuracy : 0.9497907949790795\n",
      "Epoch 147:\t train loss : 0.5702801656046976; train accuracy : 0.9808937079835187; \n",
      " validation loss : 0.611475652664715; validation accuracy : 0.9414225941422594\n",
      "Epoch 148:\t train loss : 0.5658670688402171; train accuracy : 0.9853720375476316; \n",
      " validation loss : 0.5894761306806522; validation accuracy : 0.9623430962343096\n",
      "Epoch 149:\t train loss : 0.5570142885709438; train accuracy : 0.9943243594906905; \n",
      " validation loss : 0.6021404562690983; validation accuracy : 0.9497907949790795\n",
      "Epoch 150:\t train loss : 0.5573250695412729; train accuracy : 0.9940464078812851; \n",
      " validation loss : 0.6035447086292914; validation accuracy : 0.9456066945606695\n",
      "Epoch 151:\t train loss : 0.5556631202400186; train accuracy : 0.9957239071842374; \n",
      " validation loss : 0.5981921026288498; validation accuracy : 0.9539748953974896\n",
      "Epoch 152:\t train loss : 0.5558460839904261; train accuracy : 0.9955535177669692; \n",
      " validation loss : 0.5950104585703918; validation accuracy : 0.9539748953974896\n",
      "Epoch 153:\t train loss : 0.556298889807763; train accuracy : 0.9951361566343443; \n",
      " validation loss : 0.5953233962774217; validation accuracy : 0.9539748953974896\n",
      "Epoch 154:\t train loss : 0.5554385500689183; train accuracy : 0.9958897115771864; \n",
      " validation loss : 0.5894013934854664; validation accuracy : 0.9623430962343096\n",
      "Epoch 155:\t train loss : 0.5580035855821147; train accuracy : 0.9933803401592366; \n",
      " validation loss : 0.5885610836330568; validation accuracy : 0.9623430962343096\n",
      "Epoch 156:\t train loss : 0.5622117697788471; train accuracy : 0.9890531924780818; \n",
      " validation loss : 0.5895263977546189; validation accuracy : 0.9623430962343096\n",
      "Epoch 157:\t train loss : 0.5562983318214644; train accuracy : 0.9950323120294928; \n",
      " validation loss : 0.5933372661493072; validation accuracy : 0.9581589958158996\n",
      "Epoch 158:\t train loss : 0.5549759027214544; train accuracy : 0.9964682920784411; \n",
      " validation loss : 0.5847194631848843; validation accuracy : 0.9665271966527197\n",
      "Early stopping at epoch 158\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5577859962470975; Train accuracy : 0.9935243347067753; \n",
      " Validation loss : 0.5731946848354453; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 47 ! ---\n",
      "Epoch 1:\t train loss : 0.9232820318641829; train accuracy : 0.6084921885696183; \n",
      " validation loss : 0.793485974815309; validation accuracy : 0.7333333333333333\n",
      "Epoch 2:\t train loss : 0.7396831918596514; train accuracy : 0.8099105680413412; \n",
      " validation loss : 0.7318899948511145; validation accuracy : 0.8166666666666667\n",
      "Epoch 3:\t train loss : 0.6941725677335564; train accuracy : 0.85653251040075; \n",
      " validation loss : 0.7234606502148034; validation accuracy : 0.8208333333333333\n",
      "Epoch 4:\t train loss : 0.6680991241755603; train accuracy : 0.8826160821626764; \n",
      " validation loss : 0.6542748506416313; validation accuracy : 0.9125\n",
      "Epoch 5:\t train loss : 0.6529563688061336; train accuracy : 0.8977863366675027; \n",
      " validation loss : 0.6798813454515871; validation accuracy : 0.8625\n",
      "Epoch 6:\t train loss : 0.6368409148800934; train accuracy : 0.914014104845955; \n",
      " validation loss : 0.6537948217934267; validation accuracy : 0.8958333333333334\n",
      "Epoch 7:\t train loss : 0.6377312350077915; train accuracy : 0.9127721109000259; \n",
      " validation loss : 0.6645550626016964; validation accuracy : 0.8791666666666667\n",
      "Epoch 8:\t train loss : 0.625136317238377; train accuracy : 0.9258469253454508; \n",
      " validation loss : 0.6387688464259483; validation accuracy : 0.9166666666666666\n",
      "Epoch 9:\t train loss : 0.612772596702849; train accuracy : 0.9383008427530533; \n",
      " validation loss : 0.6638758426062275; validation accuracy : 0.875\n",
      "Epoch 10:\t train loss : 0.6156919473444684; train accuracy : 0.9352521213732288; \n",
      " validation loss : 0.6421119439858389; validation accuracy : 0.9083333333333333\n",
      "Epoch 11:\t train loss : 0.6043357216037475; train accuracy : 0.9467949300903713; \n",
      " validation loss : 0.6337771000070032; validation accuracy : 0.9208333333333333\n",
      "Epoch 12:\t train loss : 0.6082380591455738; train accuracy : 0.9424550466747081; \n",
      " validation loss : 0.6574362419400507; validation accuracy : 0.8916666666666667\n",
      "Epoch 13:\t train loss : 0.6042417100564036; train accuracy : 0.9467456620653196; \n",
      " validation loss : 0.6073761284048199; validation accuracy : 0.9416666666666667\n",
      "Epoch 14:\t train loss : 0.5969620113696759; train accuracy : 0.9541808366370226; \n",
      " validation loss : 0.6177598305626214; validation accuracy : 0.9333333333333333\n",
      "Epoch 15:\t train loss : 0.5897394430316115; train accuracy : 0.9615455569335501; \n",
      " validation loss : 0.6285530874240013; validation accuracy : 0.925\n",
      "Epoch 16:\t train loss : 0.5876844335765208; train accuracy : 0.9636563870048338; \n",
      " validation loss : 0.6171887714996825; validation accuracy : 0.9375\n",
      "Epoch 17:\t train loss : 0.5903113903803406; train accuracy : 0.9608372166463964; \n",
      " validation loss : 0.61852874601724; validation accuracy : 0.9291666666666667\n",
      "Epoch 18:\t train loss : 0.5846741512480302; train accuracy : 0.9663530368790655; \n",
      " validation loss : 0.6114669733353516; validation accuracy : 0.9375\n",
      "Epoch 19:\t train loss : 0.5824047868945155; train accuracy : 0.9691089482925581; \n",
      " validation loss : 0.6028530174384769; validation accuracy : 0.95\n",
      "Epoch 20:\t train loss : 0.584713723919009; train accuracy : 0.9664107993911951; \n",
      " validation loss : 0.6138540897402062; validation accuracy : 0.9375\n",
      "Epoch 21:\t train loss : 0.5813573544824032; train accuracy : 0.9697735169874752; \n",
      " validation loss : 0.6350940278501062; validation accuracy : 0.9166666666666666\n",
      "Epoch 22:\t train loss : 0.5793764304518022; train accuracy : 0.9720829181860973; \n",
      " validation loss : 0.6126171631590225; validation accuracy : 0.9333333333333333\n",
      "Epoch 23:\t train loss : 0.5831191430529908; train accuracy : 0.9682189259170798; \n",
      " validation loss : 0.631141210400684; validation accuracy : 0.9166666666666666\n",
      "Epoch 24:\t train loss : 0.5776380580188295; train accuracy : 0.9739023373830384; \n",
      " validation loss : 0.623582682822075; validation accuracy : 0.925\n",
      "Epoch 25:\t train loss : 0.5789649114157902; train accuracy : 0.9721998423023458; \n",
      " validation loss : 0.6324540214950561; validation accuracy : 0.9208333333333333\n",
      "Epoch 26:\t train loss : 0.5820865865181563; train accuracy : 0.9689807315052531; \n",
      " validation loss : 0.625270211607804; validation accuracy : 0.9291666666666667\n",
      "Epoch 27:\t train loss : 0.5817433258158836; train accuracy : 0.9690567821483856; \n",
      " validation loss : 0.6437538597545239; validation accuracy : 0.9125\n",
      "Epoch 28:\t train loss : 0.5750313550580366; train accuracy : 0.9762173349496177; \n",
      " validation loss : 0.619680588318647; validation accuracy : 0.9333333333333333\n",
      "Epoch 29:\t train loss : 0.5704142439730434; train accuracy : 0.980772778466775; \n",
      " validation loss : 0.6080260232227134; validation accuracy : 0.9458333333333333\n",
      "Epoch 30:\t train loss : 0.5712256158779773; train accuracy : 0.9800264628256262; \n",
      " validation loss : 0.5976565992816595; validation accuracy : 0.9541666666666667\n",
      "Epoch 31:\t train loss : 0.568348976896976; train accuracy : 0.9828160523820041; \n",
      " validation loss : 0.5986230274512728; validation accuracy : 0.9541666666666667\n",
      "Epoch 32:\t train loss : 0.5720865865135771; train accuracy : 0.9791181523191449; \n",
      " validation loss : 0.6070507685783842; validation accuracy : 0.9416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:\t train loss : 0.5746537962607171; train accuracy : 0.9763398554338234; \n",
      " validation loss : 0.6353150585827947; validation accuracy : 0.9125\n",
      "Epoch 34:\t train loss : 0.568860444175962; train accuracy : 0.9823865311412893; \n",
      " validation loss : 0.6072237747683799; validation accuracy : 0.9416666666666667\n",
      "Epoch 35:\t train loss : 0.5687824710588598; train accuracy : 0.9825034552575379; \n",
      " validation loss : 0.6310204406037575; validation accuracy : 0.9166666666666666\n",
      "Epoch 36:\t train loss : 0.56866791476824; train accuracy : 0.9826893346218304; \n",
      " validation loss : 0.6125583275234291; validation accuracy : 0.9375\n",
      "Epoch 37:\t train loss : 0.5639581784279288; train accuracy : 0.9874052739771888; \n",
      " validation loss : 0.5950309005474689; validation accuracy : 0.95\n",
      "Epoch 38:\t train loss : 0.563908079070047; train accuracy : 0.9875151026983487; \n",
      " validation loss : 0.594339154193147; validation accuracy : 0.9541666666666667\n",
      "Epoch 39:\t train loss : 0.5650815075965638; train accuracy : 0.986333669448528; \n",
      " validation loss : 0.6117355605755908; validation accuracy : 0.9333333333333333\n",
      "Epoch 40:\t train loss : 0.5733131950878165; train accuracy : 0.9775649603407388; \n",
      " validation loss : 0.614663930167117; validation accuracy : 0.9333333333333333\n",
      "Epoch 41:\t train loss : 0.57313989407449; train accuracy : 0.9781408865646196; \n",
      " validation loss : 0.6257925445410741; validation accuracy : 0.925\n",
      "Epoch 42:\t train loss : 0.5715079035263925; train accuracy : 0.9795687598748413; \n",
      " validation loss : 0.5982782955212134; validation accuracy : 0.9541666666666667\n",
      "Epoch 43:\t train loss : 0.5697060502206243; train accuracy : 0.98145013885988; \n",
      " validation loss : 0.6210018439782419; validation accuracy : 0.9333333333333333\n",
      "Epoch 44:\t train loss : 0.5658153489871247; train accuracy : 0.9855633693732767; \n",
      " validation loss : 0.5988114779792617; validation accuracy : 0.9583333333333334\n",
      "Epoch 45:\t train loss : 0.5691726174507773; train accuracy : 0.9820894239638475; \n",
      " validation loss : 0.6098252950017702; validation accuracy : 0.9416666666666667\n",
      "Epoch 46:\t train loss : 0.57753770513246; train accuracy : 0.9731869017007961; \n",
      " validation loss : 0.5945685433456093; validation accuracy : 0.9583333333333334\n",
      "Epoch 47:\t train loss : 0.5665341005840733; train accuracy : 0.9846748460249298; \n",
      " validation loss : 0.5960216583948157; validation accuracy : 0.9541666666666667\n",
      "Epoch 48:\t train loss : 0.5653078114296612; train accuracy : 0.9859239353659475; \n",
      " validation loss : 0.6050489529223211; validation accuracy : 0.9458333333333333\n",
      "Epoch 49:\t train loss : 0.5658242068364544; train accuracy : 0.9853915808640192; \n",
      " validation loss : 0.6023315773981378; validation accuracy : 0.95\n",
      "Epoch 50:\t train loss : 0.5637267774725961; train accuracy : 0.9874376529632268; \n",
      " validation loss : 0.6175815711621814; validation accuracy : 0.9291666666666667\n",
      "Epoch 51:\t train loss : 0.5637524743364851; train accuracy : 0.987589754249492; \n",
      " validation loss : 0.6138147540957296; validation accuracy : 0.9375\n",
      "Epoch 52:\t train loss : 0.5678549340168403; train accuracy : 0.9832229882806058; \n",
      " validation loss : 0.6131367110176135; validation accuracy : 0.9375\n",
      "Epoch 53:\t train loss : 0.5657561247505887; train accuracy : 0.9855943492673255; \n",
      " validation loss : 0.6160656363776655; validation accuracy : 0.9333333333333333\n",
      "Epoch 54:\t train loss : 0.5667734174736359; train accuracy : 0.9844129160175047; \n",
      " validation loss : 0.6149167326489183; validation accuracy : 0.9333333333333333\n",
      "Epoch 55:\t train loss : 0.5684330761739738; train accuracy : 0.9826019913076414; \n",
      " validation loss : 0.5921443816489067; validation accuracy : 0.9583333333333334\n",
      "Epoch 56:\t train loss : 0.5672932811229736; train accuracy : 0.9840017828429349; \n",
      " validation loss : 0.6207390342693961; validation accuracy : 0.9333333333333333\n",
      "Epoch 57:\t train loss : 0.5688895101442251; train accuracy : 0.9823330658402697; \n",
      " validation loss : 0.6411782312430779; validation accuracy : 0.9083333333333333\n",
      "Epoch 58:\t train loss : 0.5746281140754491; train accuracy : 0.9763567444728372; \n",
      " validation loss : 0.6139930442451625; validation accuracy : 0.9375\n",
      "Epoch 59:\t train loss : 0.567399487644999; train accuracy : 0.9837919190445401; \n",
      " validation loss : 0.6147634467376069; validation accuracy : 0.9375\n",
      "Epoch 60:\t train loss : 0.5624347961568822; train accuracy : 0.9888726216685371; \n",
      " validation loss : 0.6108957363145817; validation accuracy : 0.9375\n",
      "Epoch 61:\t train loss : 0.5657702173693243; train accuracy : 0.9855788593203011; \n",
      " validation loss : 0.6178662270863485; validation accuracy : 0.9333333333333333\n",
      "Epoch 62:\t train loss : 0.5655437487047228; train accuracy : 0.9856225309773957; \n",
      " validation loss : 0.6197186529358992; validation accuracy : 0.9333333333333333\n",
      "Epoch 63:\t train loss : 0.5693789435568668; train accuracy : 0.9816134328820596; \n",
      " validation loss : 0.604864513816791; validation accuracy : 0.9458333333333333\n",
      "Epoch 64:\t train loss : 0.5670194817864974; train accuracy : 0.9840242682499059; \n",
      " validation loss : 0.6020292581064007; validation accuracy : 0.9458333333333333\n",
      "Epoch 65:\t train loss : 0.5667743473943752; train accuracy : 0.9844002242544588; \n",
      " validation loss : 0.6071144288760338; validation accuracy : 0.9416666666666667\n",
      "Epoch 66:\t train loss : 0.565453748832968; train accuracy : 0.9857013798045069; \n",
      " validation loss : 0.6040442774854714; validation accuracy : 0.9458333333333333\n",
      "Epoch 67:\t train loss : 0.5640543059035004; train accuracy : 0.9870912777607332; \n",
      " validation loss : 0.6243189228518535; validation accuracy : 0.925\n",
      "Epoch 68:\t train loss : 0.5651557745017575; train accuracy : 0.9861154110981972; \n",
      " validation loss : 0.6185305824762943; validation accuracy : 0.9291666666666667\n",
      "Epoch 69:\t train loss : 0.5669141730958134; train accuracy : 0.9840411572889195; \n",
      " validation loss : 0.6030917863582184; validation accuracy : 0.9458333333333333\n",
      "Epoch 70:\t train loss : 0.5650141015436383; train accuracy : 0.9861182092821759; \n",
      " validation loss : 0.6066100100707907; validation accuracy : 0.9458333333333333\n",
      "Epoch 71:\t train loss : 0.5624798494620856; train accuracy : 0.9888303491034319; \n",
      " validation loss : 0.5911619620311571; validation accuracy : 0.9625\n",
      "Epoch 72:\t train loss : 0.5618782837622625; train accuracy : 0.98944435061645; \n",
      " validation loss : 0.6057719746237861; validation accuracy : 0.9458333333333333\n",
      "Epoch 73:\t train loss : 0.5617243609106783; train accuracy : 0.9896203364016753; \n",
      " validation loss : 0.5811639460320233; validation accuracy : 0.9708333333333333\n",
      "Epoch 74:\t train loss : 0.5644596435660196; train accuracy : 0.98690679748843; \n",
      " validation loss : 0.6106049794363255; validation accuracy : 0.9416666666666667\n",
      "Epoch 75:\t train loss : 0.5624384252962286; train accuracy : 0.9888303491034319; \n",
      " validation loss : 0.6007110842036874; validation accuracy : 0.95\n",
      "Epoch 76:\t train loss : 0.5637307289879399; train accuracy : 0.9876995829706521; \n",
      " validation loss : 0.5993665255570299; validation accuracy : 0.9541666666666667\n",
      "Epoch 77:\t train loss : 0.5629884943906538; train accuracy : 0.9882868018655893; \n",
      " validation loss : 0.6161324860978161; validation accuracy : 0.9333333333333333\n",
      "Epoch 78:\t train loss : 0.5615261297115087; train accuracy : 0.9897907258189435; \n",
      " validation loss : 0.5859439398876372; validation accuracy : 0.9625\n",
      "Epoch 79:\t train loss : 0.563194486603962; train accuracy : 0.9880361645292205; \n",
      " validation loss : 0.6047763556161888; validation accuracy : 0.9416666666666667\n",
      "Epoch 80:\t train loss : 0.561240258058226; train accuracy : 0.9901160147064555; \n",
      " validation loss : 0.5982558646724904; validation accuracy : 0.95\n",
      "Epoch 81:\t train loss : 0.5616417582956085; train accuracy : 0.9896330281647211; \n",
      " validation loss : 0.6235865811866124; validation accuracy : 0.925\n",
      "Epoch 82:\t train loss : 0.5636673324078999; train accuracy : 0.9875897542494921; \n",
      " validation loss : 0.6200953885315885; validation accuracy : 0.9333333333333333\n",
      "Epoch 83:\t train loss : 0.5644405125008947; train accuracy : 0.9867546962021648; \n",
      " validation loss : 0.5878159003937655; validation accuracy : 0.9666666666666667\n",
      "Epoch 84:\t train loss : 0.5638111940625751; train accuracy : 0.9874996127513244; \n",
      " validation loss : 0.6023383791258883; validation accuracy : 0.95\n",
      "Epoch 85:\t train loss : 0.5637467447745004; train accuracy : 0.9874827237123107; \n",
      " validation loss : 0.5957615885504827; validation accuracy : 0.9541666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86:\t train loss : 0.5637857609201739; train accuracy : 0.9873982785172423; \n",
      " validation loss : 0.62378756129281; validation accuracy : 0.9291666666666667\n",
      "Epoch 87:\t train loss : 0.5628766324785633; train accuracy : 0.988459989466836; \n",
      " validation loss : 0.606463889469573; validation accuracy : 0.9458333333333333\n",
      "Epoch 88:\t train loss : 0.5674209857563894; train accuracy : 0.9837004783895252; \n",
      " validation loss : 0.6182629267757166; validation accuracy : 0.9333333333333333\n",
      "Epoch 89:\t train loss : 0.5689623639376613; train accuracy : 0.982293591459143; \n",
      " validation loss : 0.6024190130104953; validation accuracy : 0.95\n",
      "Epoch 90:\t train loss : 0.5612811905107837; train accuracy : 0.9899470243811767; \n",
      " validation loss : 0.5917755086286098; validation accuracy : 0.9583333333333334\n",
      "Epoch 91:\t train loss : 0.5600451165124672; train accuracy : 0.9912777607332841; \n",
      " validation loss : 0.6058484557669359; validation accuracy : 0.9458333333333333\n",
      "Epoch 92:\t train loss : 0.5589724756157038; train accuracy : 0.9924704866541615; \n",
      " validation loss : 0.6070503028693015; validation accuracy : 0.9458333333333333\n",
      "Epoch 93:\t train loss : 0.5599830895241993; train accuracy : 0.9913679022314518; \n",
      " validation loss : 0.6153121034053405; validation accuracy : 0.9333333333333333\n",
      "Epoch 94:\t train loss : 0.5612376132151119; train accuracy : 0.9901469946005043; \n",
      " validation loss : 0.5914565026135424; validation accuracy : 0.9625\n",
      "Epoch 95:\t train loss : 0.5632550456029949; train accuracy : 0.9880206745821961; \n",
      " validation loss : 0.6196570103722021; validation accuracy : 0.9333333333333333\n",
      "Epoch 96:\t train loss : 0.5656357332924172; train accuracy : 0.9856380209244201; \n",
      " validation loss : 0.6095598905375322; validation accuracy : 0.9416666666666667\n",
      "Epoch 97:\t train loss : 0.5630072857331699; train accuracy : 0.9883656506927004; \n",
      " validation loss : 0.602489214449411; validation accuracy : 0.9541666666666667\n",
      "Epoch 98:\t train loss : 0.5602247923881882; train accuracy : 0.9911369521180754; \n",
      " validation loss : 0.6062653746840657; validation accuracy : 0.9458333333333333\n",
      "Epoch 99:\t train loss : 0.5685328637560051; train accuracy : 0.982673844674806; \n",
      " validation loss : 0.6000210410487088; validation accuracy : 0.95\n",
      "Epoch 100:\t train loss : 0.5643403711228521; train accuracy : 0.9869574646054711; \n",
      " validation loss : 0.6115509793733487; validation accuracy : 0.9375\n",
      "Epoch 101:\t train loss : 0.580764825282296; train accuracy : 0.9700650277969598; \n",
      " validation loss : 0.6220190581526598; validation accuracy : 0.9208333333333333\n",
      "Epoch 102:\t train loss : 0.5778669190427371; train accuracy : 0.9730700775196898; \n",
      " validation loss : 0.6146982602053765; validation accuracy : 0.9375\n",
      "Epoch 103:\t train loss : 0.5658886798015302; train accuracy : 0.9852958429978944; \n",
      " validation loss : 0.6059872000312494; validation accuracy : 0.9458333333333333\n",
      "Epoch 104:\t train loss : 0.5672268380676366; train accuracy : 0.9838778632667399; \n",
      " validation loss : 0.5902039422348191; validation accuracy : 0.9625\n",
      "Epoch 105:\t train loss : 0.5653712034723632; train accuracy : 0.98585767836674; \n",
      " validation loss : 0.6048041655875784; validation accuracy : 0.9458333333333333\n",
      "Epoch 106:\t train loss : 0.5639526771091333; train accuracy : 0.9871884147188474; \n",
      " validation loss : 0.596377448284495; validation accuracy : 0.9541666666666667\n",
      "Epoch 107:\t train loss : 0.5613511391444128; train accuracy : 0.9898991554481141; \n",
      " validation loss : 0.5971555563746922; validation accuracy : 0.9541666666666667\n",
      "Epoch 108:\t train loss : 0.5609509286706154; train accuracy : 0.9904089246079294; \n",
      " validation loss : 0.6102392297324519; validation accuracy : 0.9416666666666667\n",
      "Epoch 109:\t train loss : 0.5624497883110123; train accuracy : 0.9888458390504562; \n",
      " validation loss : 0.5914346517131784; validation accuracy : 0.9583333333333334\n",
      "Epoch 110:\t train loss : 0.559637007625977; train accuracy : 0.991666408500883; \n",
      " validation loss : 0.6092942400912247; validation accuracy : 0.9375\n",
      "Epoch 111:\t train loss : 0.5706749910239066; train accuracy : 0.9805601164844017; \n",
      " validation loss : 0.5946731655520455; validation accuracy : 0.9541666666666667\n",
      "Epoch 112:\t train loss : 0.5672498759619153; train accuracy : 0.9838862578186757; \n",
      " validation loss : 0.6187302351736792; validation accuracy : 0.9333333333333333\n",
      "Epoch 113:\t train loss : 0.5605412922905849; train accuracy : 0.9907511025344551; \n",
      " validation loss : 0.5974232289345836; validation accuracy : 0.9541666666666667\n",
      "Epoch 114:\t train loss : 0.5590045665784367; train accuracy : 0.992440905852102; \n",
      " validation loss : 0.599132262265989; validation accuracy : 0.9541666666666667\n",
      "Epoch 115:\t train loss : 0.5596361755317468; train accuracy : 0.9916185395678204; \n",
      " validation loss : 0.6118785541969991; validation accuracy : 0.9375\n",
      "Epoch 116:\t train loss : 0.560332615621751; train accuracy : 0.9909693608847858; \n",
      " validation loss : 0.5972460537852889; validation accuracy : 0.95\n",
      "Epoch 117:\t train loss : 0.5630366488758616; train accuracy : 0.9881656804733728; \n",
      " validation loss : 0.6117835962047379; validation accuracy : 0.9375\n",
      "Epoch 118:\t train loss : 0.5674097978240176; train accuracy : 0.9837947172285186; \n",
      " validation loss : 0.5961256069140777; validation accuracy : 0.9583333333333334\n",
      "Epoch 119:\t train loss : 0.5611639579281014; train accuracy : 0.9902216461516475; \n",
      " validation loss : 0.6094314453065094; validation accuracy : 0.9416666666666667\n",
      "Epoch 120:\t train loss : 0.562316475877972; train accuracy : 0.9891077690578814; \n",
      " validation loss : 0.6280631474572559; validation accuracy : 0.9208333333333333\n",
      "Epoch 121:\t train loss : 0.5613814344075571; train accuracy : 0.9898512865150517; \n",
      " validation loss : 0.6159244198940355; validation accuracy : 0.9333333333333333\n",
      "Epoch 122:\t train loss : 0.5604299613348309; train accuracy : 0.9908116632305634; \n",
      " validation loss : 0.6060026289490719; validation accuracy : 0.9458333333333333\n",
      "Epoch 123:\t train loss : 0.561889592458239; train accuracy : 0.9893724972492852; \n",
      " validation loss : 0.6038399436310531; validation accuracy : 0.9458333333333333\n",
      "Early stopping at epoch 123\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5617243609106783; Train accuracy : 0.9896203364016753; \n",
      " Validation loss : 0.5811639460320233; Validation accuracy : 0.9708333333333333\n",
      "--- Let's train model 48 ! ---\n",
      "Epoch 1:\t train loss : 0.9704901673952749; train accuracy : 0.5541584311781653; \n",
      " validation loss : 0.8340938838969194; validation accuracy : 0.7280334728033473\n",
      "Epoch 2:\t train loss : 0.7926268014910026; train accuracy : 0.7542581864370024; \n",
      " validation loss : 0.7370772566363679; validation accuracy : 0.8117154811715481\n",
      "Epoch 3:\t train loss : 0.717862926067576; train accuracy : 0.8317565599925648; \n",
      " validation loss : 0.7041656863417418; validation accuracy : 0.8535564853556485\n",
      "Epoch 4:\t train loss : 0.6875726666033076; train accuracy : 0.8626862666129682; \n",
      " validation loss : 0.6668744187388573; validation accuracy : 0.8870292887029289\n",
      "Epoch 5:\t train loss : 0.6671085369060517; train accuracy : 0.8835843737414418; \n",
      " validation loss : 0.66021436002382; validation accuracy : 0.895397489539749\n",
      "Epoch 6:\t train loss : 0.6507450567533033; train accuracy : 0.8994770593884569; \n",
      " validation loss : 0.6478829186320256; validation accuracy : 0.9079497907949791\n",
      "Epoch 7:\t train loss : 0.6429011503328783; train accuracy : 0.9075008519470863; \n",
      " validation loss : 0.6323054260757967; validation accuracy : 0.9246861924686193\n",
      "Epoch 8:\t train loss : 0.6384579592395245; train accuracy : 0.9118535270609375; \n",
      " validation loss : 0.6485396482929506; validation accuracy : 0.895397489539749\n",
      "Epoch 9:\t train loss : 0.6233981445950255; train accuracy : 0.9276266303169243; \n",
      " validation loss : 0.6375220148578683; validation accuracy : 0.9163179916317992\n",
      "Epoch 10:\t train loss : 0.6107892634796019; train accuracy : 0.9402487685492116; \n",
      " validation loss : 0.6057951557891252; validation accuracy : 0.9414225941422594\n",
      "Epoch 11:\t train loss : 0.6041517808844257; train accuracy : 0.9474537625081322; \n",
      " validation loss : 0.6207951700025471; validation accuracy : 0.9288702928870293\n",
      "Epoch 12:\t train loss : 0.6036191218041272; train accuracy : 0.9476898293007838; \n",
      " validation loss : 0.6044548220022629; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\t train loss : 0.6027156677747973; train accuracy : 0.9483639517952849; \n",
      " validation loss : 0.6103346729871425; validation accuracy : 0.9330543933054394\n",
      "Epoch 14:\t train loss : 0.5962033067598785; train accuracy : 0.9548889370798351; \n",
      " validation loss : 0.6072218257006479; validation accuracy : 0.9456066945606695\n",
      "Epoch 15:\t train loss : 0.5957898732106822; train accuracy : 0.9551640385389882; \n",
      " validation loss : 0.6046402401007293; validation accuracy : 0.9414225941422594\n",
      "Epoch 16:\t train loss : 0.59206075982197; train accuracy : 0.9592261222466619; \n",
      " validation loss : 0.5993785707086939; validation accuracy : 0.9497907949790795\n",
      "Epoch 17:\t train loss : 0.59844599055787; train accuracy : 0.9524805601164844; \n",
      " validation loss : 0.5940956049442835; validation accuracy : 0.9539748953974896\n",
      "Epoch 18:\t train loss : 0.587981964802739; train accuracy : 0.9633021469066576; \n",
      " validation loss : 0.6098901129847929; validation accuracy : 0.9372384937238494\n",
      "Epoch 19:\t train loss : 0.5912588726969399; train accuracy : 0.9597372904984665; \n",
      " validation loss : 0.6183061218657958; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.5887031767780043; train accuracy : 0.9624811797143654; \n",
      " validation loss : 0.6024504548935385; validation accuracy : 0.9414225941422594\n",
      "Epoch 21:\t train loss : 0.5877896072908492; train accuracy : 0.9636193810217168; \n",
      " validation loss : 0.620414526452004; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5839549453729097; train accuracy : 0.9669017007961833; \n",
      " validation loss : 0.5995218061126122; validation accuracy : 0.9497907949790795\n",
      "Epoch 23:\t train loss : 0.5807757433769863; train accuracy : 0.9707233805260386; \n",
      " validation loss : 0.5959904386472599; validation accuracy : 0.9539748953974896\n",
      "Epoch 24:\t train loss : 0.5832334939015194; train accuracy : 0.9679667895535797; \n",
      " validation loss : 0.5933360971884987; validation accuracy : 0.9623430962343096\n",
      "Epoch 25:\t train loss : 0.5758852625448065; train accuracy : 0.9756225409709098; \n",
      " validation loss : 0.5801902066147185; validation accuracy : 0.9707112970711297\n",
      "Epoch 26:\t train loss : 0.578536526749383; train accuracy : 0.9726735648564082; \n",
      " validation loss : 0.588069626699575; validation accuracy : 0.9623430962343096\n",
      "Epoch 27:\t train loss : 0.575435521950797; train accuracy : 0.9757272530127947; \n",
      " validation loss : 0.5938502320600931; validation accuracy : 0.9581589958158996\n",
      "Epoch 28:\t train loss : 0.5776877433933221; train accuracy : 0.9737327674339353; \n",
      " validation loss : 0.5924480837625108; validation accuracy : 0.9581589958158996\n",
      "Epoch 29:\t train loss : 0.5753584418722372; train accuracy : 0.9759611512128629; \n",
      " validation loss : 0.6010150772825755; validation accuracy : 0.9497907949790795\n",
      "Epoch 30:\t train loss : 0.5771734871152684; train accuracy : 0.9738972706713344; \n",
      " validation loss : 0.594527534532507; validation accuracy : 0.9539748953974896\n",
      "Epoch 31:\t train loss : 0.583363988018658; train accuracy : 0.9675036401375507; \n",
      " validation loss : 0.6155387399992228; validation accuracy : 0.9330543933054394\n",
      "Epoch 32:\t train loss : 0.582879884184654; train accuracy : 0.967862077511695; \n",
      " validation loss : 0.6088044591066665; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.5815051239304019; train accuracy : 0.9696663465410948; \n",
      " validation loss : 0.6016870014987658; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5747979824067517; train accuracy : 0.9764995817714304; \n",
      " validation loss : 0.6042162918756662; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.570919106374881; train accuracy : 0.9802695250782242; \n",
      " validation loss : 0.5826153894960902; validation accuracy : 0.9748953974895398\n",
      "Epoch 36:\t train loss : 0.5722822026853727; train accuracy : 0.978912295919948; \n",
      " validation loss : 0.5852743780271746; validation accuracy : 0.9665271966527197\n",
      "Epoch 37:\t train loss : 0.5694124304203854; train accuracy : 0.9819151770500945; \n",
      " validation loss : 0.5767770361303624; validation accuracy : 0.9790794979079498\n",
      "Epoch 38:\t train loss : 0.5715833537086382; train accuracy : 0.9796093435360451; \n",
      " validation loss : 0.5756223797494233; validation accuracy : 0.9790794979079498\n",
      "Epoch 39:\t train loss : 0.5737827356263228; train accuracy : 0.9774407509526317; \n",
      " validation loss : 0.6254438421140491; validation accuracy : 0.9246861924686193\n",
      "Epoch 40:\t train loss : 0.5727233334566593; train accuracy : 0.9783642615942254; \n",
      " validation loss : 0.5657509601014548; validation accuracy : 0.9874476987447699\n",
      "Epoch 41:\t train loss : 0.5721808920121614; train accuracy : 0.9791638526596239; \n",
      " validation loss : 0.5937985800898361; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.5787052950972978; train accuracy : 0.9722184702128319; \n",
      " validation loss : 0.5812004132086999; validation accuracy : 0.9707112970711297\n",
      "Epoch 43:\t train loss : 0.5745976953424962; train accuracy : 0.9764589981102265; \n",
      " validation loss : 0.5751952331142126; validation accuracy : 0.9707112970711297\n",
      "Epoch 44:\t train loss : 0.5701110771835878; train accuracy : 0.9810712847362062; \n",
      " validation loss : 0.5783502457394946; validation accuracy : 0.9748953974895398\n",
      "Epoch 45:\t train loss : 0.5679795642155815; train accuracy : 0.9831661451717835; \n",
      " validation loss : 0.5908760168954166; validation accuracy : 0.9623430962343096\n",
      "Epoch 46:\t train loss : 0.5670720611920347; train accuracy : 0.9843706434523994; \n",
      " validation loss : 0.5733451631703766; validation accuracy : 0.9748953974895398\n",
      "Epoch 47:\t train loss : 0.5676091510765059; train accuracy : 0.9835416214876546; \n",
      " validation loss : 0.588069376043736; validation accuracy : 0.9581589958158996\n",
      "Epoch 48:\t train loss : 0.5751780909525828; train accuracy : 0.9757368567799498; \n",
      " validation loss : 0.5930898888436371; validation accuracy : 0.9581589958158996\n",
      "Epoch 49:\t train loss : 0.5700241129043108; train accuracy : 0.9811679420056384; \n",
      " validation loss : 0.599954705696978; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5750505161377522; train accuracy : 0.9759537160382912; \n",
      " validation loss : 0.5841552877988183; validation accuracy : 0.9707112970711297\n",
      "Epoch 51:\t train loss : 0.5679929139695647; train accuracy : 0.9831661451717835; \n",
      " validation loss : 0.5782828016518502; validation accuracy : 0.9748953974895398\n",
      "Epoch 52:\t train loss : 0.5678154345812576; train accuracy : 0.9832959509278478; \n",
      " validation loss : 0.5815055796795816; validation accuracy : 0.9665271966527197\n",
      "Epoch 53:\t train loss : 0.5677796703054061; train accuracy : 0.983429474271198; \n",
      " validation loss : 0.6079721580628024; validation accuracy : 0.9372384937238494\n",
      "Epoch 54:\t train loss : 0.5656171685536787; train accuracy : 0.9856910065367577; \n",
      " validation loss : 0.5900896054572481; validation accuracy : 0.9623430962343096\n",
      "Epoch 55:\t train loss : 0.5642866485513766; train accuracy : 0.9869419746584467; \n",
      " validation loss : 0.5893294642618595; validation accuracy : 0.9581589958158996\n",
      "Epoch 56:\t train loss : 0.5661091869163879; train accuracy : 0.9852263081260262; \n",
      " validation loss : 0.6099344020500185; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.5658143389584127; train accuracy : 0.9853310201679111; \n",
      " validation loss : 0.574959822489311; validation accuracy : 0.9748953974895398\n",
      "Epoch 58:\t train loss : 0.5690924643981876; train accuracy : 0.981839895907556; \n",
      " validation loss : 0.5844498811119603; validation accuracy : 0.9665271966527197\n",
      "Epoch 59:\t train loss : 0.5712680724176582; train accuracy : 0.9796809070912977; \n",
      " validation loss : 0.5840352257863344; validation accuracy : 0.9665271966527197\n",
      "Epoch 60:\t train loss : 0.5715302316941868; train accuracy : 0.9796573623718207; \n",
      " validation loss : 0.6020377912646117; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5660505642383526; train accuracy : 0.985092784782676; \n",
      " validation loss : 0.5872521061000644; validation accuracy : 0.9623430962343096\n",
      "Epoch 62:\t train loss : 0.5713855263318036; train accuracy : 0.9796285510703553; \n",
      " validation loss : 0.6062209825483919; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5716712290407243; train accuracy : 0.9793652219709409; \n",
      " validation loss : 0.580203182350774; validation accuracy : 0.9748953974895398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:\t train loss : 0.5647616716427191; train accuracy : 0.9864153164596177; \n",
      " validation loss : 0.5847886111368509; validation accuracy : 0.9665271966527197\n",
      "Epoch 65:\t train loss : 0.5671384394819032; train accuracy : 0.9840837696335079; \n",
      " validation loss : 0.5877438248168847; validation accuracy : 0.9665271966527197\n",
      "Epoch 66:\t train loss : 0.5690499076737403; train accuracy : 0.9821438086681744; \n",
      " validation loss : 0.5848247364215117; validation accuracy : 0.9665271966527197\n",
      "Epoch 67:\t train loss : 0.566476648295846; train accuracy : 0.9846745562130178; \n",
      " validation loss : 0.5859038387269297; validation accuracy : 0.9665271966527197\n",
      "Epoch 68:\t train loss : 0.5624627880729809; train accuracy : 0.9888082034759441; \n",
      " validation loss : 0.5781485578272088; validation accuracy : 0.9748953974895398\n",
      "Epoch 69:\t train loss : 0.5646774704745028; train accuracy : 0.9864905976021562; \n",
      " validation loss : 0.6013659231594716; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5799465597937813; train accuracy : 0.9709659530964404; \n",
      " validation loss : 0.5835910935229803; validation accuracy : 0.9665271966527197\n",
      "Epoch 71:\t train loss : 0.5706531347568574; train accuracy : 0.9804612906223861; \n",
      " validation loss : 0.5870479550749587; validation accuracy : 0.9623430962343096\n",
      "Epoch 72:\t train loss : 0.5647857361309873; train accuracy : 0.986242758449766; \n",
      " validation loss : 0.5769293839230372; validation accuracy : 0.9707112970711297\n",
      "Epoch 73:\t train loss : 0.5677172686457563; train accuracy : 0.9833771182502555; \n",
      " validation loss : 0.5804018444244227; validation accuracy : 0.9665271966527197\n",
      "Epoch 74:\t train loss : 0.5629595240450722; train accuracy : 0.9883456736577961; \n",
      " validation loss : 0.5799498567578891; validation accuracy : 0.9707112970711297\n",
      "Epoch 75:\t train loss : 0.5616040818195621; train accuracy : 0.9897921249109328; \n",
      " validation loss : 0.5806196786449166; validation accuracy : 0.9707112970711297\n",
      "Epoch 76:\t train loss : 0.5619993044503158; train accuracy : 0.9891976207441371; \n",
      " validation loss : 0.5788263168537331; validation accuracy : 0.9748953974895398\n",
      "Epoch 77:\t train loss : 0.5656746585571837; train accuracy : 0.9855590321881099; \n",
      " validation loss : 0.5810265739278805; validation accuracy : 0.9707112970711297\n",
      "Epoch 78:\t train loss : 0.5654766240332405; train accuracy : 0.9856792341770191; \n",
      " validation loss : 0.5913227091368127; validation accuracy : 0.9581589958158996\n",
      "Epoch 79:\t train loss : 0.5768294590125059; train accuracy : 0.9741413922364386; \n",
      " validation loss : 0.5924840173620114; validation accuracy : 0.9581589958158996\n",
      "Epoch 80:\t train loss : 0.5651816389278724; train accuracy : 0.9860008054772452; \n",
      " validation loss : 0.5825035284799621; validation accuracy : 0.9665271966527197\n",
      "Epoch 81:\t train loss : 0.5632597014308516; train accuracy : 0.987896465194089; \n",
      " validation loss : 0.5824854942978658; validation accuracy : 0.9707112970711297\n",
      "Epoch 82:\t train loss : 0.560877542373488; train accuracy : 0.9904832863471607; \n",
      " validation loss : 0.5887945460625805; validation accuracy : 0.9623430962343096\n",
      "Epoch 83:\t train loss : 0.5692248797521726; train accuracy : 0.9820508689860281; \n",
      " validation loss : 0.5951562116374152; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.5738151755073366; train accuracy : 0.9769450726478516; \n",
      " validation loss : 0.5856373314989635; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.5825433314016306; train accuracy : 0.9683828495306546; \n",
      " validation loss : 0.5995868435978734; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5685727164638504; train accuracy : 0.9825155673967595; \n",
      " validation loss : 0.5856733866105013; validation accuracy : 0.9665271966527197\n",
      "Epoch 87:\t train loss : 0.5673967895323456; train accuracy : 0.983667709656433; \n",
      " validation loss : 0.5837537649766121; validation accuracy : 0.9665271966527197\n",
      "Epoch 88:\t train loss : 0.564500887507779; train accuracy : 0.9866978530933425; \n",
      " validation loss : 0.5710356990528342; validation accuracy : 0.9790794979079498\n",
      "Epoch 89:\t train loss : 0.5637507693309117; train accuracy : 0.9875262554602063; \n",
      " validation loss : 0.5781996316171016; validation accuracy : 0.9707112970711297\n",
      "Epoch 90:\t train loss : 0.5677627416558755; train accuracy : 0.9835261315406302; \n",
      " validation loss : 0.5983509462576967; validation accuracy : 0.9539748953974896\n",
      "Early stopping at epoch 90\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5727233334566593; Train accuracy : 0.9783642615942254; \n",
      " Validation loss : 0.5657509601014548; Validation accuracy : 0.9874476987447699\n",
      "--- Let's train model 49 ! ---\n",
      "Epoch 1:\t train loss : 0.9539498413296196; train accuracy : 0.5715183246073299; \n",
      " validation loss : 0.854876339367364; validation accuracy : 0.6903765690376569\n",
      "Epoch 2:\t train loss : 0.7717273938360416; train accuracy : 0.7774162768363332; \n",
      " validation loss : 0.7424901349249283; validation accuracy : 0.8075313807531381\n",
      "Epoch 3:\t train loss : 0.7279310823733911; train accuracy : 0.8220951702345178; \n",
      " validation loss : 0.7267035448453747; validation accuracy : 0.8117154811715481\n",
      "Epoch 4:\t train loss : 0.703486525958571; train accuracy : 0.8462536014126831; \n",
      " validation loss : 0.6783956658525871; validation accuracy : 0.8786610878661087\n",
      "Epoch 5:\t train loss : 0.6855625267011775; train accuracy : 0.8644409678118901; \n",
      " validation loss : 0.6843839512925074; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.673194991923245; train accuracy : 0.8774717308466805; \n",
      " validation loss : 0.6832727613804128; validation accuracy : 0.8619246861924686\n",
      "Epoch 7:\t train loss : 0.6593971149310192; train accuracy : 0.8913528919731094; \n",
      " validation loss : 0.6403630863297325; validation accuracy : 0.9163179916317992\n",
      "Epoch 8:\t train loss : 0.6406438487765485; train accuracy : 0.9099408284023669; \n",
      " validation loss : 0.6503058434119472; validation accuracy : 0.899581589958159\n",
      "Epoch 9:\t train loss : 0.6315604986282394; train accuracy : 0.9192540041513058; \n",
      " validation loss : 0.6590701820946829; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.6305959300097747; train accuracy : 0.9203618451624895; \n",
      " validation loss : 0.629770366354032; validation accuracy : 0.9205020920502092\n",
      "Epoch 11:\t train loss : 0.6104237526230657; train accuracy : 0.9405821122091762; \n",
      " validation loss : 0.6476221996835653; validation accuracy : 0.895397489539749\n",
      "Epoch 12:\t train loss : 0.6060400147397242; train accuracy : 0.9456532110660182; \n",
      " validation loss : 0.6200150512191938; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.5957166698082222; train accuracy : 0.9558263886737507; \n",
      " validation loss : 0.6111227842883659; validation accuracy : 0.9456066945606695\n",
      "Epoch 14:\t train loss : 0.5964399017214876; train accuracy : 0.954755413736485; \n",
      " validation loss : 0.598815740794158; validation accuracy : 0.9581589958158996\n",
      "Epoch 15:\t train loss : 0.5985270394896792; train accuracy : 0.9527321168561603; \n",
      " validation loss : 0.6103423863733453; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5958174852041341; train accuracy : 0.9552569782211345; \n",
      " validation loss : 0.6155259376570045; validation accuracy : 0.9330543933054394\n",
      "Epoch 17:\t train loss : 0.5882232900858752; train accuracy : 0.9630601939341368; \n",
      " validation loss : 0.6032923465722738; validation accuracy : 0.9539748953974896\n",
      "Epoch 18:\t train loss : 0.5857753190706082; train accuracy : 0.9655326992781684; \n",
      " validation loss : 0.5857498942694618; validation accuracy : 0.9665271966527197\n",
      "Epoch 19:\t train loss : 0.5836429351965007; train accuracy : 0.9676644257876638; \n",
      " validation loss : 0.5847415803246646; validation accuracy : 0.9707112970711297\n",
      "Epoch 20:\t train loss : 0.5893822618670674; train accuracy : 0.961650608754918; \n",
      " validation loss : 0.6026349983322644; validation accuracy : 0.9497907949790795\n",
      "Epoch 21:\t train loss : 0.5849404291813067; train accuracy : 0.9664989621735494; \n",
      " validation loss : 0.58036617206703; validation accuracy : 0.9665271966527197\n",
      "Epoch 22:\t train loss : 0.5787855862436478; train accuracy : 0.9724721955450912; \n",
      " validation loss : 0.6039075820871138; validation accuracy : 0.9497907949790795\n",
      "Epoch 23:\t train loss : 0.5800485156370679; train accuracy : 0.9713414294123114; \n",
      " validation loss : 0.5974109994812186; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:\t train loss : 0.5745749051571725; train accuracy : 0.9767784008178692; \n",
      " validation loss : 0.6217984835578875; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5751475580395268; train accuracy : 0.9762266489048608; \n",
      " validation loss : 0.6087490879248596; validation accuracy : 0.9414225941422594\n",
      "Epoch 26:\t train loss : 0.5751788917950138; train accuracy : 0.9761064469159515; \n",
      " validation loss : 0.6033286616948471; validation accuracy : 0.9539748953974896\n",
      "Epoch 27:\t train loss : 0.5768013821824921; train accuracy : 0.9742690293999194; \n",
      " validation loss : 0.6039678848632861; validation accuracy : 0.9456066945606695\n",
      "Epoch 28:\t train loss : 0.572718270481569; train accuracy : 0.9782366244307444; \n",
      " validation loss : 0.5955260457190354; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5731294839554807; train accuracy : 0.9779770129186158; \n",
      " validation loss : 0.6176670373947649; validation accuracy : 0.9330543933054394\n",
      "Epoch 30:\t train loss : 0.5693514413133833; train accuracy : 0.9821224325412807; \n",
      " validation loss : 0.7018868086689433; validation accuracy : 0.8368200836820083\n",
      "Epoch 31:\t train loss : 0.5836631311237885; train accuracy : 0.9674534527091917; \n",
      " validation loss : 0.6048648757639109; validation accuracy : 0.9414225941422594\n",
      "Epoch 32:\t train loss : 0.5727421282604228; train accuracy : 0.9784048452554293; \n",
      " validation loss : 0.6039162961469329; validation accuracy : 0.9414225941422594\n",
      "Epoch 33:\t train loss : 0.5764635243278811; train accuracy : 0.9745633383933827; \n",
      " validation loss : 0.6045636552234643; validation accuracy : 0.9456066945606695\n",
      "Epoch 34:\t train loss : 0.572788115746897; train accuracy : 0.9785036711174447; \n",
      " validation loss : 0.6208789357029478; validation accuracy : 0.9163179916317992\n",
      "Epoch 35:\t train loss : 0.5717602462165913; train accuracy : 0.9792899408284024; \n",
      " validation loss : 0.6425183958919529; validation accuracy : 0.9037656903765691\n",
      "Epoch 36:\t train loss : 0.5705669841469133; train accuracy : 0.9805173642306143; \n",
      " validation loss : 0.5945188178081346; validation accuracy : 0.9581589958158996\n",
      "Epoch 37:\t train loss : 0.5744360060248319; train accuracy : 0.9766817435484371; \n",
      " validation loss : 0.6029828663112011; validation accuracy : 0.9456066945606695\n",
      "Epoch 38:\t train loss : 0.5701951231536992; train accuracy : 0.9810226463025497; \n",
      " validation loss : 0.609977410334672; validation accuracy : 0.9414225941422594\n",
      "Epoch 39:\t train loss : 0.5689316061411929; train accuracy : 0.9823414603922055; \n",
      " validation loss : 0.6101407854058736; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5684151004802087; train accuracy : 0.9827169367080765; \n",
      " validation loss : 0.6006468062954996; validation accuracy : 0.9497907949790795\n",
      "Epoch 41:\t train loss : 0.5682335747577512; train accuracy : 0.9828563462312959; \n",
      " validation loss : 0.5949951058390541; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5702009873146339; train accuracy : 0.981189318132532; \n",
      " validation loss : 0.5998203640777269; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.5712532974299785; train accuracy : 0.9798726726354596; \n",
      " validation loss : 0.5951038571695146; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.5655454187108465; train accuracy : 0.9859137519749682; \n",
      " validation loss : 0.5847692227679332; validation accuracy : 0.9665271966527197\n",
      "Epoch 45:\t train loss : 0.5734141307647848; train accuracy : 0.9776789863378668; \n",
      " validation loss : 0.5953541405948878; validation accuracy : 0.9539748953974896\n",
      "Epoch 46:\t train loss : 0.5704627866886962; train accuracy : 0.9806471699866787; \n",
      " validation loss : 0.6005660075858018; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.568384087235221; train accuracy : 0.9827132191207906; \n",
      " validation loss : 0.6052138744818967; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5670460680104293; train accuracy : 0.984318287431457; \n",
      " validation loss : 0.5837193033974004; validation accuracy : 0.9707112970711297\n",
      "Epoch 49:\t train loss : 0.5664902099996175; train accuracy : 0.984730629821246; \n",
      " validation loss : 0.6095785950916883; validation accuracy : 0.9330543933054394\n",
      "Epoch 50:\t train loss : 0.5655316489918392; train accuracy : 0.9857994361659284; \n",
      " validation loss : 0.6118798211825041; validation accuracy : 0.9330543933054394\n",
      "Epoch 51:\t train loss : 0.578244841149281; train accuracy : 0.9728712165804393; \n",
      " validation loss : 0.607504077728886; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5684333346611719; train accuracy : 0.9828061588029369; \n",
      " validation loss : 0.5956223039636319; validation accuracy : 0.9497907949790795\n",
      "Epoch 53:\t train loss : 0.5734729830537155; train accuracy : 0.9775005421481459; \n",
      " validation loss : 0.5935118943604722; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5662518378200665; train accuracy : 0.9849437714923015; \n",
      " validation loss : 0.5844104816989731; validation accuracy : 0.9623430962343096\n",
      "Epoch 55:\t train loss : 0.5682782952912915; train accuracy : 0.9828563462312959; \n",
      " validation loss : 0.5881038022047611; validation accuracy : 0.9665271966527197\n",
      "Epoch 56:\t train loss : 0.5650624170024651; train accuracy : 0.9862235509154559; \n",
      " validation loss : 0.597561651520187; validation accuracy : 0.9539748953974896\n",
      "Epoch 57:\t train loss : 0.5671862091133332; train accuracy : 0.983828495306546; \n",
      " validation loss : 0.6050761792210445; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5673119645483861; train accuracy : 0.9838690789677499; \n",
      " validation loss : 0.6116549048573834; validation accuracy : 0.9372384937238494\n",
      "Epoch 59:\t train loss : 0.565827930089306; train accuracy : 0.9854180736701881; \n",
      " validation loss : 0.5960103319497962; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5674088261263474; train accuracy : 0.9838690789677499; \n",
      " validation loss : 0.6006839086438528; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5636613394694315; train accuracy : 0.9877143034170823; \n",
      " validation loss : 0.6015402886751287; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5744481557175025; train accuracy : 0.9765674277393971; \n",
      " validation loss : 0.5893635905315557; validation accuracy : 0.9623430962343096\n",
      "Epoch 63:\t train loss : 0.5651074302731435; train accuracy : 0.9861188388735711; \n",
      " validation loss : 0.5983695901146481; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5638117265140119; train accuracy : 0.9874627466774064; \n",
      " validation loss : 0.5895141394428526; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.563235652263093; train accuracy : 0.9880668546113572; \n",
      " validation loss : 0.6078343472205064; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5628969315588579; train accuracy : 0.9883515598376653; \n",
      " validation loss : 0.5956464003507798; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5640665389591407; train accuracy : 0.9871684376839431; \n",
      " validation loss : 0.5946399996455057; validation accuracy : 0.9581589958158996\n",
      "Epoch 68:\t train loss : 0.5651765066780717; train accuracy : 0.9860996313392608; \n",
      " validation loss : 0.5830891801332977; validation accuracy : 0.9707112970711297\n",
      "Epoch 69:\t train loss : 0.5643136101189528; train accuracy : 0.9869590136001735; \n",
      " validation loss : 0.6386250516684165; validation accuracy : 0.9079497907949791\n",
      "Epoch 70:\t train loss : 0.5662777984533409; train accuracy : 0.9847424021809845; \n",
      " validation loss : 0.5980490125593553; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5633280764711698; train accuracy : 0.9879952910561046; \n",
      " validation loss : 0.5861268465358742; validation accuracy : 0.9665271966527197\n",
      "Early stopping at epoch 71\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5849404291813067; Train accuracy : 0.9664989621735494; \n",
      " Validation loss : 0.58036617206703; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 50 ! ---\n",
      "Epoch 1:\t train loss : 0.92416283499648; train accuracy : 0.6015805941943678; \n",
      " validation loss : 0.8251694824575174; validation accuracy : 0.7071129707112971\n",
      "Epoch 2:\t train loss : 0.747183061542461; train accuracy : 0.8040236686390533; \n",
      " validation loss : 0.7566888821432857; validation accuracy : 0.7866108786610879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\t train loss : 0.7018897855873965; train accuracy : 0.8478462777657301; \n",
      " validation loss : 0.7062757526615592; validation accuracy : 0.8410041841004184\n",
      "Epoch 4:\t train loss : 0.6815009938425349; train accuracy : 0.8683208897425571; \n",
      " validation loss : 0.6645362171443893; validation accuracy : 0.8870292887029289\n",
      "Epoch 5:\t train loss : 0.6666403109158298; train accuracy : 0.8834604541652468; \n",
      " validation loss : 0.6816322359428347; validation accuracy : 0.8702928870292888\n",
      "Epoch 6:\t train loss : 0.6600930092388946; train accuracy : 0.8897087889959416; \n",
      " validation loss : 0.6711119455570411; validation accuracy : 0.8744769874476988\n",
      "Epoch 7:\t train loss : 0.6424445550133536; train accuracy : 0.9080157377861767; \n",
      " validation loss : 0.6788585047198787; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6360743277665514; train accuracy : 0.9150968121689024; \n",
      " validation loss : 0.6528455377397191; validation accuracy : 0.8870292887029289\n",
      "Epoch 9:\t train loss : 0.6176346266589416; train accuracy : 0.9329839833947768; \n",
      " validation loss : 0.6335040392609906; validation accuracy : 0.9037656903765691\n",
      "Epoch 10:\t train loss : 0.6059768259461278; train accuracy : 0.9454245794479383; \n",
      " validation loss : 0.6235345747904587; validation accuracy : 0.9330543933054394\n",
      "Epoch 11:\t train loss : 0.603340578689966; train accuracy : 0.9481508101242294; \n",
      " validation loss : 0.6425761257827837; validation accuracy : 0.9037656903765691\n",
      "Epoch 12:\t train loss : 0.599325913867789; train accuracy : 0.9518411351033179; \n",
      " validation loss : 0.6245117784926911; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.590199616018777; train accuracy : 0.9609802038477029; \n",
      " validation loss : 0.6114419763325862; validation accuracy : 0.9372384937238494\n",
      "Epoch 14:\t train loss : 0.587854838317399; train accuracy : 0.9638768239412621; \n",
      " validation loss : 0.6090811212238922; validation accuracy : 0.9497907949790795\n",
      "Epoch 15:\t train loss : 0.5998887452516515; train accuracy : 0.9511035038260169; \n",
      " validation loss : 0.6233379188949302; validation accuracy : 0.9246861924686193\n",
      "Epoch 16:\t train loss : 0.5846341500972304; train accuracy : 0.9669887542984603; \n",
      " validation loss : 0.6118915865153536; validation accuracy : 0.9372384937238494\n",
      "Epoch 17:\t train loss : 0.5802467378994098; train accuracy : 0.9711224015613866; \n",
      " validation loss : 0.6096869179048953; validation accuracy : 0.9414225941422594\n",
      "Epoch 18:\t train loss : 0.5786607192350862; train accuracy : 0.9724272746987205; \n",
      " validation loss : 0.6312382573744783; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.5788256908518444; train accuracy : 0.9726345301899068; \n",
      " validation loss : 0.6179480193453925; validation accuracy : 0.9246861924686193\n",
      "Epoch 20:\t train loss : 0.5853722356615336; train accuracy : 0.965530530685585; \n",
      " validation loss : 0.6020558794679128; validation accuracy : 0.9497907949790795\n",
      "Epoch 21:\t train loss : 0.5760365120975957; train accuracy : 0.9751770500944886; \n",
      " validation loss : 0.5990794921366069; validation accuracy : 0.9539748953974896\n",
      "Epoch 22:\t train loss : 0.570711064453915; train accuracy : 0.9809083304935097; \n",
      " validation loss : 0.6018606109431028; validation accuracy : 0.9456066945606695\n",
      "Epoch 23:\t train loss : 0.578439609926324; train accuracy : 0.9729694228445739; \n",
      " validation loss : 0.5910854431425376; validation accuracy : 0.9581589958158996\n",
      "Epoch 24:\t train loss : 0.5777407541096102; train accuracy : 0.9732423557111435; \n",
      " validation loss : 0.6228591675719125; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5768800075878986; train accuracy : 0.9745884321075622; \n",
      " validation loss : 0.5981242205937167; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5691953380806274; train accuracy : 0.9822500697047616; \n",
      " validation loss : 0.605194120294006; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5756786739758637; train accuracy : 0.9754868490349763; \n",
      " validation loss : 0.6109870607285327; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.5693901459117057; train accuracy : 0.9820022305523715; \n",
      " validation loss : 0.5883478268818143; validation accuracy : 0.9665271966527197\n",
      "Epoch 29:\t train loss : 0.5675891265395071; train accuracy : 0.9839384739304191; \n",
      " validation loss : 0.6083951471433705; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5687236752725681; train accuracy : 0.9826896744013136; \n",
      " validation loss : 0.6068639382569309; validation accuracy : 0.9372384937238494\n",
      "Epoch 31:\t train loss : 0.5696276783063214; train accuracy : 0.9815898881625825; \n",
      " validation loss : 0.5916197850170901; validation accuracy : 0.9581589958158996\n",
      "Epoch 32:\t train loss : 0.5761355858620618; train accuracy : 0.9748923448681805; \n",
      " validation loss : 0.6124680670296297; validation accuracy : 0.9414225941422594\n",
      "Epoch 33:\t train loss : 0.5729098230315952; train accuracy : 0.9783032312029493; \n",
      " validation loss : 0.6028719703034806; validation accuracy : 0.9497907949790795\n",
      "Epoch 34:\t train loss : 0.5713153995922777; train accuracy : 0.9798667864555903; \n",
      " validation loss : 0.5947531320488618; validation accuracy : 0.9539748953974896\n",
      "Epoch 35:\t train loss : 0.5637419767409411; train accuracy : 0.9875011617460269; \n",
      " validation loss : 0.5915517463069566; validation accuracy : 0.9581589958158996\n",
      "Epoch 36:\t train loss : 0.5669785605570015; train accuracy : 0.9843898509867096; \n",
      " validation loss : 0.6088057900859338; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5658641958721408; train accuracy : 0.9855376560612162; \n",
      " validation loss : 0.604795468198407; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5714462949119566; train accuracy : 0.9796936088478577; \n",
      " validation loss : 0.6183676028642686; validation accuracy : 0.9288702928870293\n",
      "Epoch 39:\t train loss : 0.5763623623600711; train accuracy : 0.9747625391121162; \n",
      " validation loss : 0.6017236077172448; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.5706179772863161; train accuracy : 0.9806353976269401; \n",
      " validation loss : 0.6085318094272512; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5650416918865898; train accuracy : 0.9863164905976022; \n",
      " validation loss : 0.5952951581672978; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5648420255917347; train accuracy : 0.9864404101737972; \n",
      " validation loss : 0.6013449634170083; validation accuracy : 0.9539748953974896\n",
      "Epoch 43:\t train loss : 0.5623349345098136; train accuracy : 0.9890021376126894; \n",
      " validation loss : 0.5774930707993898; validation accuracy : 0.9748953974895398\n",
      "Epoch 44:\t train loss : 0.5622235551242266; train accuracy : 0.9889689891260571; \n",
      " validation loss : 0.5959905203089355; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5628190703125744; train accuracy : 0.988587626630317; \n",
      " validation loss : 0.5855395695061137; validation accuracy : 0.9665271966527197\n",
      "Epoch 46:\t train loss : 0.5706649794859007; train accuracy : 0.9803993308342885; \n",
      " validation loss : 0.5910767750031138; validation accuracy : 0.9581589958158996\n",
      "Epoch 47:\t train loss : 0.5622308096100346; train accuracy : 0.989073701167942; \n",
      " validation loss : 0.6111361200272475; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.5958637095747381; train accuracy : 0.9548424672387621; \n",
      " validation loss : 0.6655983488856669; validation accuracy : 0.8828451882845189\n",
      "Epoch 49:\t train loss : 0.597174017820288; train accuracy : 0.9533826946311844; \n",
      " validation loss : 0.5984245876566183; validation accuracy : 0.9539748953974896\n",
      "Epoch 50:\t train loss : 0.5758111610963487; train accuracy : 0.975357043278912; \n",
      " validation loss : 0.5850644677885231; validation accuracy : 0.9665271966527197\n",
      "Epoch 51:\t train loss : 0.5715157303568814; train accuracy : 0.9796942284457387; \n",
      " validation loss : 0.5911332090945671; validation accuracy : 0.9623430962343096\n",
      "Epoch 52:\t train loss : 0.5689177877799394; train accuracy : 0.9821843923293783; \n",
      " validation loss : 0.5842835471251465; validation accuracy : 0.9665271966527197\n",
      "Epoch 53:\t train loss : 0.572226705538209; train accuracy : 0.9789624833483069; \n",
      " validation loss : 0.5873565660026535; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54:\t train loss : 0.5655997624034194; train accuracy : 0.9856910065367577; \n",
      " validation loss : 0.5726603805863328; validation accuracy : 0.9790794979079498\n",
      "Epoch 55:\t train loss : 0.5660484246644366; train accuracy : 0.9850345425818644; \n",
      " validation loss : 0.6026433661874758; validation accuracy : 0.9497907949790795\n",
      "Epoch 56:\t train loss : 0.5648112382870362; train accuracy : 0.9864596177081074; \n",
      " validation loss : 0.6008272091227014; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5692195078368565; train accuracy : 0.9819734192509062; \n",
      " validation loss : 0.5836630500767146; validation accuracy : 0.9665271966527197\n",
      "Epoch 58:\t train loss : 0.5683725684827626; train accuracy : 0.9826026208990365; \n",
      " validation loss : 0.6031025440295406; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5662045737160525; train accuracy : 0.9848155147309396; \n",
      " validation loss : 0.5969392231489736; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.567331903861206; train accuracy : 0.9838263267139626; \n",
      " validation loss : 0.5904497267813069; validation accuracy : 0.9623430962343096\n",
      "Epoch 61:\t train loss : 0.5679092558835942; train accuracy : 0.9832318225471669; \n",
      " validation loss : 0.5812989633986124; validation accuracy : 0.9665271966527197\n",
      "Epoch 62:\t train loss : 0.5631331567149586; train accuracy : 0.9881362495740265; \n",
      " validation loss : 0.6155191311353793; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5685853545724385; train accuracy : 0.9825000774497351; \n",
      " validation loss : 0.5992278400883995; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5649658099967081; train accuracy : 0.9861770810743827; \n",
      " validation loss : 0.5906220179677731; validation accuracy : 0.9623430962343096\n",
      "Epoch 65:\t train loss : 0.5642864037165463; train accuracy : 0.9869707859599121; \n",
      " validation loss : 0.5965799984476255; validation accuracy : 0.9581589958158996\n",
      "Epoch 66:\t train loss : 0.5623608894924397; train accuracy : 0.9889129155178289; \n",
      " validation loss : 0.5807914339744892; validation accuracy : 0.9707112970711297\n",
      "Epoch 67:\t train loss : 0.5611078041562905; train accuracy : 0.9902819170358438; \n",
      " validation loss : 0.5979860632613115; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.561243742409482; train accuracy : 0.9901211313857307; \n",
      " validation loss : 0.5810015146826184; validation accuracy : 0.9707112970711297\n",
      "Epoch 69:\t train loss : 0.5618543924545514; train accuracy : 0.9894181975897642; \n",
      " validation loss : 0.5991202910182559; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5632620158703644; train accuracy : 0.9879348802627095; \n",
      " validation loss : 0.6004300928746465; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5666804265568529; train accuracy : 0.9844710183091174; \n",
      " validation loss : 0.574302817171374; validation accuracy : 0.9748953974895398\n",
      "Epoch 72:\t train loss : 0.565065344877844; train accuracy : 0.9861306112333096; \n",
      " validation loss : 0.5946390473869524; validation accuracy : 0.9539748953974896\n",
      "Epoch 73:\t train loss : 0.5638005387420664; train accuracy : 0.9873949007094396; \n",
      " validation loss : 0.5965793693143608; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5656175081277252; train accuracy : 0.9855419932463831; \n",
      " validation loss : 0.6180491501816271; validation accuracy : 0.9330543933054394\n",
      "Epoch 75:\t train loss : 0.562694546909316; train accuracy : 0.9885448743765296; \n",
      " validation loss : 0.5796295124293062; validation accuracy : 0.9707112970711297\n",
      "Epoch 76:\t train loss : 0.5650446524659061; train accuracy : 0.9862405898571827; \n",
      " validation loss : 0.6081034025869686; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5739511607307832; train accuracy : 0.9771383871867159; \n",
      " validation loss : 0.6384026176586494; validation accuracy : 0.9121338912133892\n",
      "Epoch 78:\t train loss : 0.5952467062094374; train accuracy : 0.9553514668979832; \n",
      " validation loss : 0.6186479112454706; validation accuracy : 0.9330543933054394\n",
      "Epoch 79:\t train loss : 0.5695250608150543; train accuracy : 0.9816128132841786; \n",
      " validation loss : 0.6050572100980794; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.56458367190035; train accuracy : 0.9864655038879767; \n",
      " validation loss : 0.5850508351451522; validation accuracy : 0.9665271966527197\n",
      "Epoch 81:\t train loss : 0.5633093597540617; train accuracy : 0.9877201895969516; \n",
      " validation loss : 0.5775412891747592; validation accuracy : 0.9748953974895398\n",
      "Epoch 82:\t train loss : 0.5601651996766612; train accuracy : 0.9912054276774374; \n",
      " validation loss : 0.5769206539082072; validation accuracy : 0.9748953974895398\n",
      "Epoch 83:\t train loss : 0.559635345596469; train accuracy : 0.9917822733046253; \n",
      " validation loss : 0.598521646074536; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5868620008795846; train accuracy : 0.9640670404907216; \n",
      " validation loss : 0.5925240286317993; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5655653804763203; train accuracy : 0.9856076706217665; \n",
      " validation loss : 0.5969893738912979; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5651654157012843; train accuracy : 0.9861343288205955; \n",
      " validation loss : 0.5974137769405876; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5674291431385021; train accuracy : 0.9834951516465814; \n",
      " validation loss : 0.604453049758335; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5651433443337662; train accuracy : 0.9858127575203692; \n",
      " validation loss : 0.5828118913481629; validation accuracy : 0.9665271966527197\n",
      "Epoch 89:\t train loss : 0.5624238566942725; train accuracy : 0.9888664456767557; \n",
      " validation loss : 0.5975316619089013; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.562587662080374; train accuracy : 0.9886244927042349; \n",
      " validation loss : 0.5730253559415577; validation accuracy : 0.9790794979079498\n",
      "Epoch 91:\t train loss : 0.5622929334452003; train accuracy : 0.9890427212738933; \n",
      " validation loss : 0.5849721242687285; validation accuracy : 0.9665271966527197\n",
      "Epoch 92:\t train loss : 0.564930985976652; train accuracy : 0.9863084358251495; \n",
      " validation loss : 0.5961804037716116; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5605853496804963; train accuracy : 0.9907311254995508; \n",
      " validation loss : 0.6015992775534624; validation accuracy : 0.9456066945606695\n",
      "Epoch 94:\t train loss : 0.560622231478798; train accuracy : 0.9905548499024134; \n",
      " validation loss : 0.5885465692684579; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5631891471545922; train accuracy : 0.9880337061247251; \n",
      " validation loss : 0.5902304472707296; validation accuracy : 0.9623430962343096\n",
      "Epoch 96:\t train loss : 0.5614306649659108; train accuracy : 0.9899426871960098; \n",
      " validation loss : 0.6042483665953784; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.5604272074650949; train accuracy : 0.9907562192137302; \n",
      " validation loss : 0.5881839462893101; validation accuracy : 0.9623430962343096\n",
      "Epoch 98:\t train loss : 0.5611715529249695; train accuracy : 0.9900666067722048; \n",
      " validation loss : 0.6048539952290352; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5589110828075009; train accuracy : 0.9923361938102172; \n",
      " validation loss : 0.5650101883545287; validation accuracy : 0.9832635983263598\n",
      "Epoch 100:\t train loss : 0.5631359800454977; train accuracy : 0.9880203847702841; \n",
      " validation loss : 0.574110064978626; validation accuracy : 0.9748953974895398\n",
      "Epoch 101:\t train loss : 0.5589955116227427; train accuracy : 0.9923052139161684; \n",
      " validation loss : 0.586829082265765; validation accuracy : 0.9665271966527197\n",
      "Epoch 102:\t train loss : 0.5591696746725279; train accuracy : 0.992165804392949; \n",
      " validation loss : 0.581171981153035; validation accuracy : 0.9707112970711297\n",
      "Epoch 103:\t train loss : 0.5603589549335828; train accuracy : 0.9908373865361381; \n",
      " validation loss : 0.5987473050838271; validation accuracy : 0.9497907949790795\n",
      "Epoch 104:\t train loss : 0.5584245820855858; train accuracy : 0.9929653954583475; \n",
      " validation loss : 0.5725965778066255; validation accuracy : 0.9790794979079498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105:\t train loss : 0.5622888091310789; train accuracy : 0.9889748753059264; \n",
      " validation loss : 0.5918705579130188; validation accuracy : 0.9581589958158996\n",
      "Epoch 106:\t train loss : 0.5630104713473247; train accuracy : 0.9882099817218625; \n",
      " validation loss : 0.5786578776536615; validation accuracy : 0.9707112970711297\n",
      "Epoch 107:\t train loss : 0.5592125456045652; train accuracy : 0.9921252207317451; \n",
      " validation loss : 0.5890948329755245; validation accuracy : 0.9623430962343096\n",
      "Epoch 108:\t train loss : 0.5640298945835851; train accuracy : 0.9872400012391958; \n",
      " validation loss : 0.5905388486545438; validation accuracy : 0.9623430962343096\n",
      "Epoch 109:\t train loss : 0.5606402304926358; train accuracy : 0.990663279531584; \n",
      " validation loss : 0.5839499712493585; validation accuracy : 0.9665271966527197\n",
      "Epoch 110:\t train loss : 0.5622143153150514; train accuracy : 0.9889807614857957; \n",
      " validation loss : 0.5919105160711139; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.5606992202892123; train accuracy : 0.990585829796462; \n",
      " validation loss : 0.5977522652557382; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5571308434103072; train accuracy : 0.9941330276650454; \n",
      " validation loss : 0.5868190240478736; validation accuracy : 0.9623430962343096\n",
      "Epoch 113:\t train loss : 0.5628586198422473; train accuracy : 0.988510176895195; \n",
      " validation loss : 0.5782290752237378; validation accuracy : 0.9748953974895398\n",
      "Epoch 114:\t train loss : 0.5599526316565923; train accuracy : 0.9913485547879426; \n",
      " validation loss : 0.584574367821945; validation accuracy : 0.9665271966527197\n",
      "Epoch 115:\t train loss : 0.5588587530612463; train accuracy : 0.9925626568357137; \n",
      " validation loss : 0.574401711770277; validation accuracy : 0.9748953974895398\n",
      "Epoch 116:\t train loss : 0.5594807894563374; train accuracy : 0.9918522878651755; \n",
      " validation loss : 0.5959436631532651; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5621763182934435; train accuracy : 0.9890523250410483; \n",
      " validation loss : 0.5932279681464083; validation accuracy : 0.9581589958158996\n",
      "Epoch 118:\t train loss : 0.5582264039844403; train accuracy : 0.9931165773413054; \n",
      " validation loss : 0.5871451928078757; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.5566262553406773; train accuracy : 0.9946906657579231; \n",
      " validation loss : 0.5790380345915115; validation accuracy : 0.9707112970711297\n",
      "Epoch 120:\t train loss : 0.5627984349983567; train accuracy : 0.9884850831810155; \n",
      " validation loss : 0.5837852213815404; validation accuracy : 0.9665271966527197\n",
      "Epoch 121:\t train loss : 0.5652905185767415; train accuracy : 0.9859735431704824; \n",
      " validation loss : 0.609542791933871; validation accuracy : 0.9456066945606695\n",
      "Epoch 122:\t train loss : 0.5607831953679288; train accuracy : 0.9905179838284953; \n",
      " validation loss : 0.5844312404392353; validation accuracy : 0.9665271966527197\n",
      "Epoch 123:\t train loss : 0.5579658443428012; train accuracy : 0.9933991139750302; \n",
      " validation loss : 0.5823801698549864; validation accuracy : 0.9707112970711297\n",
      "Epoch 124:\t train loss : 0.556202550893191; train accuracy : 0.9952114377768828; \n",
      " validation loss : 0.5796738957655373; validation accuracy : 0.9707112970711297\n",
      "Epoch 125:\t train loss : 0.5560425449295092; train accuracy : 0.9953375259456613; \n",
      " validation loss : 0.577579531128288; validation accuracy : 0.9707112970711297\n",
      "Epoch 126:\t train loss : 0.55717729456429; train accuracy : 0.9943093032621828; \n",
      " validation loss : 0.5877301469316579; validation accuracy : 0.9623430962343096\n",
      "Epoch 127:\t train loss : 0.5631110461001599; train accuracy : 0.9882446792031971; \n",
      " validation loss : 0.6219454338034321; validation accuracy : 0.9288702928870293\n",
      "Epoch 128:\t train loss : 0.5864907822264088; train accuracy : 0.964169583940023; \n",
      " validation loss : 0.5891524306554052; validation accuracy : 0.9581589958158996\n",
      "Epoch 129:\t train loss : 0.5592349577439744; train accuracy : 0.9921038446048515; \n",
      " validation loss : 0.5792639170167537; validation accuracy : 0.9707112970711297\n",
      "Epoch 130:\t train loss : 0.5580118873706593; train accuracy : 0.9932228383778927; \n",
      " validation loss : 0.571783527720572; validation accuracy : 0.9790794979079498\n",
      "Epoch 131:\t train loss : 0.5571454641719553; train accuracy : 0.9942414572942161; \n",
      " validation loss : 0.596289461186162; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5561410436231867; train accuracy : 0.9952792837448495; \n",
      " validation loss : 0.5854830616350666; validation accuracy : 0.9665271966527197\n",
      "Epoch 133:\t train loss : 0.5611574324483662; train accuracy : 0.9900570030050497; \n",
      " validation loss : 0.5942296280500249; validation accuracy : 0.9581589958158996\n",
      "Epoch 134:\t train loss : 0.5588749522336347; train accuracy : 0.9924136435453391; \n",
      " validation loss : 0.5931458403475764; validation accuracy : 0.9539748953974896\n",
      "Epoch 135:\t train loss : 0.5582150097736868; train accuracy : 0.9931822547166889; \n",
      " validation loss : 0.6481049045623023; validation accuracy : 0.9037656903765691\n",
      "Epoch 136:\t train loss : 0.5633511224668373; train accuracy : 0.9879060689612441; \n",
      " validation loss : 0.5870703136340498; validation accuracy : 0.9623430962343096\n",
      "Epoch 137:\t train loss : 0.5589390966171109; train accuracy : 0.9923420799900864; \n",
      " validation loss : 0.5911773972241856; validation accuracy : 0.9539748953974896\n",
      "Epoch 138:\t train loss : 0.5583295869032413; train accuracy : 0.9930081477121349; \n",
      " validation loss : 0.5795423349335531; validation accuracy : 0.9665271966527197\n",
      "Epoch 139:\t train loss : 0.5659240727488297; train accuracy : 0.9853251339880418; \n",
      " validation loss : 0.5652981103624436; validation accuracy : 0.9874476987447699\n",
      "Epoch 140:\t train loss : 0.557803182715694; train accuracy : 0.9934957712444623; \n",
      " validation loss : 0.5790315498423321; validation accuracy : 0.9707112970711297\n",
      "Epoch 141:\t train loss : 0.556064153191069; train accuracy : 0.9953508473001023; \n",
      " validation loss : 0.594213633138429; validation accuracy : 0.9581589958158996\n",
      "Epoch 142:\t train loss : 0.5596919419128153; train accuracy : 0.9916450323739893; \n",
      " validation loss : 0.5641099660489987; validation accuracy : 0.9874476987447699\n",
      "Epoch 143:\t train loss : 0.5588378942995098; train accuracy : 0.9925663744229994; \n",
      " validation loss : 0.5888942029453883; validation accuracy : 0.9623430962343096\n",
      "Epoch 144:\t train loss : 0.5563069550307368; train accuracy : 0.995143591808916; \n",
      " validation loss : 0.5787983696621405; validation accuracy : 0.9748953974895398\n",
      "Epoch 145:\t train loss : 0.5594210711602339; train accuracy : 0.9919334551875832; \n",
      " validation loss : 0.5913896938130254; validation accuracy : 0.9623430962343096\n",
      "Epoch 146:\t train loss : 0.5571165843603235; train accuracy : 0.9942724371882649; \n",
      " validation loss : 0.5849762677926234; validation accuracy : 0.9665271966527197\n",
      "Epoch 147:\t train loss : 0.5584592858269238; train accuracy : 0.992866569596332; \n",
      " validation loss : 0.6103187596454144; validation accuracy : 0.9414225941422594\n",
      "Epoch 148:\t train loss : 0.5624788823763249; train accuracy : 0.988711546206512; \n",
      " validation loss : 0.5798991756243881; validation accuracy : 0.9707112970711297\n",
      "Epoch 149:\t train loss : 0.5651899515274903; train accuracy : 0.9860429381331516; \n",
      " validation loss : 0.6117747758006722; validation accuracy : 0.9372384937238494\n",
      "Epoch 150:\t train loss : 0.5655376189759542; train accuracy : 0.9856637442299947; \n",
      " validation loss : 0.576336273741797; validation accuracy : 0.9748953974895398\n",
      "Epoch 151:\t train loss : 0.5585014457478038; train accuracy : 0.9928746243687846; \n",
      " validation loss : 0.5587150113742149; validation accuracy : 0.9916317991631799\n",
      "Epoch 152:\t train loss : 0.5565838752460588; train accuracy : 0.9948588865826079; \n",
      " validation loss : 0.5694775537306498; validation accuracy : 0.9790794979079498\n",
      "Epoch 153:\t train loss : 0.5557252774595426; train accuracy : 0.9956724186003284; \n",
      " validation loss : 0.581215825874932; validation accuracy : 0.9707112970711297\n",
      "Epoch 154:\t train loss : 0.5610650999677458; train accuracy : 0.9901521112797794; \n",
      " validation loss : 0.6104486226771557; validation accuracy : 0.9372384937238494\n",
      "Epoch 155:\t train loss : 0.5603274509139584; train accuracy : 0.9909613061123331; \n",
      " validation loss : 0.5891174830809492; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156:\t train loss : 0.5618544771864858; train accuracy : 0.9894705536107067; \n",
      " validation loss : 0.5737394364853919; validation accuracy : 0.9748953974895398\n",
      "Epoch 157:\t train loss : 0.5570621912564274; train accuracy : 0.9943536045106726; \n",
      " validation loss : 0.5761784267227827; validation accuracy : 0.9748953974895398\n",
      "Epoch 158:\t train loss : 0.5642954437167211; train accuracy : 0.9868800148703492; \n",
      " validation loss : 0.5719906314032378; validation accuracy : 0.9790794979079498\n",
      "Epoch 159:\t train loss : 0.5646982506458542; train accuracy : 0.9864788252424177; \n",
      " validation loss : 0.5845280124754562; validation accuracy : 0.9665271966527197\n",
      "Epoch 160:\t train loss : 0.5604730606386626; train accuracy : 0.9908860249697946; \n",
      " validation loss : 0.5724370289426649; validation accuracy : 0.9790794979079498\n",
      "Epoch 161:\t train loss : 0.5562229540372875; train accuracy : 0.9951553641686546; \n",
      " validation loss : 0.5665599717780094; validation accuracy : 0.9832635983263598\n",
      "Epoch 162:\t train loss : 0.5621866978634804; train accuracy : 0.9889962514328201; \n",
      " validation loss : 0.5877031876177682; validation accuracy : 0.9623430962343096\n",
      "Epoch 163:\t train loss : 0.5561063912938582; train accuracy : 0.9952637937978251; \n",
      " validation loss : 0.5857944541115921; validation accuracy : 0.9665271966527197\n",
      "Epoch 164:\t train loss : 0.5568463937254594; train accuracy : 0.9945726323615973; \n",
      " validation loss : 0.5844452503486327; validation accuracy : 0.9665271966527197\n",
      "Epoch 165:\t train loss : 0.5561438064722178; train accuracy : 0.9951126119148672; \n",
      " validation loss : 0.5828490200367259; validation accuracy : 0.9665271966527197\n",
      "Epoch 166:\t train loss : 0.5586878490060333; train accuracy : 0.99265559651786; \n",
      " validation loss : 0.5828270585363451; validation accuracy : 0.9707112970711297\n",
      "Epoch 167:\t train loss : 0.5577581049425734; train accuracy : 0.9935791071594535; \n",
      " validation loss : 0.5921638665324563; validation accuracy : 0.9497907949790795\n",
      "Epoch 168:\t train loss : 0.5562736292924579; train accuracy : 0.9950373307723287; \n",
      " validation loss : 0.5925512894119535; validation accuracy : 0.9581589958158996\n",
      "Epoch 169:\t train loss : 0.5563197388419748; train accuracy : 0.9950469345394839; \n",
      " validation loss : 0.5888479493286588; validation accuracy : 0.9623430962343096\n",
      "Epoch 170:\t train loss : 0.5581994884745556; train accuracy : 0.9931165773413055; \n",
      " validation loss : 0.5639973054593665; validation accuracy : 0.9874476987447699\n",
      "Epoch 171:\t train loss : 0.5595546105884783; train accuracy : 0.9917571795904457; \n",
      " validation loss : 0.5839877587744994; validation accuracy : 0.9665271966527197\n",
      "Epoch 172:\t train loss : 0.5576920745670805; train accuracy : 0.9936432355401345; \n",
      " validation loss : 0.5831340474955989; validation accuracy : 0.9665271966527197\n",
      "Epoch 173:\t train loss : 0.5647441150144586; train accuracy : 0.9866300071253756; \n",
      " validation loss : 0.6412713877540369; validation accuracy : 0.9079497907949791\n",
      "Epoch 174:\t train loss : 0.582863583438923; train accuracy : 0.9679026611728988; \n",
      " validation loss : 0.5920496945490967; validation accuracy : 0.9581589958158996\n",
      "Epoch 175:\t train loss : 0.5651270112080484; train accuracy : 0.9860104092444004; \n",
      " validation loss : 0.5741994736252847; validation accuracy : 0.9790794979079498\n",
      "Epoch 176:\t train loss : 0.5575783233701112; train accuracy : 0.9937671551163295; \n",
      " validation loss : 0.5869516475061388; validation accuracy : 0.9623430962343096\n",
      "Epoch 177:\t train loss : 0.5562835557035115; train accuracy : 0.9950218408253043; \n",
      " validation loss : 0.5834917626430824; validation accuracy : 0.9665271966527197\n",
      "Epoch 178:\t train loss : 0.5551613475248743; train accuracy : 0.9962920164813036; \n",
      " validation loss : 0.5775799911309534; validation accuracy : 0.9748953974895398\n",
      "Epoch 179:\t train loss : 0.5556598857904794; train accuracy : 0.9958332042504414; \n",
      " validation loss : 0.584172668678299; validation accuracy : 0.9665271966527197\n",
      "Epoch 180:\t train loss : 0.5546618144257661; train accuracy : 0.9967161312308311; \n",
      " validation loss : 0.5777940807613208; validation accuracy : 0.9748953974895398\n",
      "Epoch 181:\t train loss : 0.5585597185529761; train accuracy : 0.9927816846866384; \n",
      " validation loss : 0.5769610225626004; validation accuracy : 0.9748953974895398\n",
      "Epoch 182:\t train loss : 0.5552567085562302; train accuracy : 0.9961275132439047; \n",
      " validation loss : 0.5833508092965881; validation accuracy : 0.9665271966527197\n",
      "Epoch 183:\t train loss : 0.5566405954363098; train accuracy : 0.9947740016729143; \n",
      " validation loss : 0.5865445724891597; validation accuracy : 0.9665271966527197\n",
      "Epoch 184:\t train loss : 0.5571083688022123; train accuracy : 0.9942569472412405; \n",
      " validation loss : 0.5844484903780509; validation accuracy : 0.9665271966527197\n",
      "Epoch 185:\t train loss : 0.5575152869330059; train accuracy : 0.9938040211902475; \n",
      " validation loss : 0.572385846856397; validation accuracy : 0.9790794979079498\n",
      "Epoch 186:\t train loss : 0.556054508068351; train accuracy : 0.9953043774590291; \n",
      " validation loss : 0.5947053466804527; validation accuracy : 0.9581589958158996\n",
      "Epoch 187:\t train loss : 0.5557041192066364; train accuracy : 0.9956665324204591; \n",
      " validation loss : 0.579376980145007; validation accuracy : 0.9707112970711297\n",
      "Epoch 188:\t train loss : 0.5576860490741372; train accuracy : 0.9935967656990613; \n",
      " validation loss : 0.5871388809315781; validation accuracy : 0.9623430962343096\n",
      "Epoch 189:\t train loss : 0.5567672165273628; train accuracy : 0.9945512562347036; \n",
      " validation loss : 0.5846006420738687; validation accuracy : 0.9665271966527197\n",
      "Epoch 190:\t train loss : 0.5558451156198887; train accuracy : 0.9955175191300846; \n",
      " validation loss : 0.5826351300072679; validation accuracy : 0.9665271966527197\n",
      "Epoch 191:\t train loss : 0.557103443760921; train accuracy : 0.9942163635800365; \n",
      " validation loss : 0.5965918579949615; validation accuracy : 0.9539748953974896\n",
      "Epoch 192:\t train loss : 0.556046025498012; train accuracy : 0.9953471297128164; \n",
      " validation loss : 0.5723715209428648; validation accuracy : 0.9790794979079498\n",
      "Epoch 193:\t train loss : 0.5575741122704376; train accuracy : 0.9937671551163295; \n",
      " validation loss : 0.5828226125183281; validation accuracy : 0.9665271966527197\n",
      "Epoch 194:\t train loss : 0.555297059880001; train accuracy : 0.9960810434028315; \n",
      " validation loss : 0.589020224711904; validation accuracy : 0.9665271966527197\n",
      "Epoch 195:\t train loss : 0.5566681881920907; train accuracy : 0.9947489079587347; \n",
      " validation loss : 0.5693478976852804; validation accuracy : 0.9832635983263598\n",
      "Epoch 196:\t train loss : 0.5773339950147539; train accuracy : 0.9736045106725735; \n",
      " validation loss : 0.5771264005239003; validation accuracy : 0.9748953974895398\n",
      "Epoch 197:\t train loss : 0.5654770079793239; train accuracy : 0.9857470801449859; \n",
      " validation loss : 0.6057390960006895; validation accuracy : 0.9456066945606695\n",
      "Epoch 198:\t train loss : 0.5594942267980599; train accuracy : 0.9917940456643638; \n",
      " validation loss : 0.6024234545756357; validation accuracy : 0.9456066945606695\n",
      "Epoch 199:\t train loss : 0.5570833130409814; train accuracy : 0.994278323368134; \n",
      " validation loss : 0.5753860978175008; validation accuracy : 0.9748953974895398\n",
      "Epoch 200:\t train loss : 0.5554194157390321; train accuracy : 0.9959667275937916; \n",
      " validation loss : 0.5623037533339043; validation accuracy : 0.9916317991631799\n",
      "Epoch 201:\t train loss : 0.554579283190761; train accuracy : 0.9968400508070262; \n",
      " validation loss : 0.5720266349301844; validation accuracy : 0.9790794979079498\n",
      "Early stopping at epoch 201\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5585014457478038; Train accuracy : 0.9928746243687846; \n",
      " Validation loss : 0.5587150113742149; Validation accuracy : 0.9916317991631799\n",
      "--- Let's train model 51 ! ---\n",
      "Epoch 1:\t train loss : 0.9415558259203041; train accuracy : 0.5878335760091701; \n",
      " validation loss : 0.8732569413319826; validation accuracy : 0.6569037656903766\n",
      "Epoch 2:\t train loss : 0.7638012169984328; train accuracy : 0.7857765110443322; \n",
      " validation loss : 0.7739170725937466; validation accuracy : 0.7782426778242678\n",
      "Epoch 3:\t train loss : 0.7053163744940452; train accuracy : 0.8456206821772669; \n",
      " validation loss : 0.7283761070693556; validation accuracy : 0.8158995815899581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\t train loss : 0.6786074296524794; train accuracy : 0.8713739583010626; \n",
      " validation loss : 0.6931683475243027; validation accuracy : 0.8535564853556485\n",
      "Epoch 5:\t train loss : 0.6575791451269728; train accuracy : 0.8931571610025094; \n",
      " validation loss : 0.6895572732971215; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6393998386186561; train accuracy : 0.9114839369249357; \n",
      " validation loss : 0.6763251115814509; validation accuracy : 0.8702928870292888\n",
      "Epoch 7:\t train loss : 0.6261572316834523; train accuracy : 0.9244703987112364; \n",
      " validation loss : 0.694449671245396; validation accuracy : 0.8451882845188284\n",
      "Epoch 8:\t train loss : 0.6128578319958041; train accuracy : 0.9382202050868986; \n",
      " validation loss : 0.6579847095066162; validation accuracy : 0.891213389121339\n",
      "Epoch 9:\t train loss : 0.6120670801720676; train accuracy : 0.939311936553177; \n",
      " validation loss : 0.6577136399222844; validation accuracy : 0.8870292887029289\n",
      "Epoch 10:\t train loss : 0.6068331437147528; train accuracy : 0.9442200811673224; \n",
      " validation loss : 0.6479087674235295; validation accuracy : 0.9037656903765691\n",
      "Epoch 11:\t train loss : 0.6029559455457985; train accuracy : 0.9481006226958704; \n",
      " validation loss : 0.6623398612912033; validation accuracy : 0.891213389121339\n",
      "Epoch 12:\t train loss : 0.5962327250884923; train accuracy : 0.9549840453545649; \n",
      " validation loss : 0.6289771896514634; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.5955534499439402; train accuracy : 0.955731280399021; \n",
      " validation loss : 0.6448594826782; validation accuracy : 0.9079497907949791\n",
      "Epoch 14:\t train loss : 0.5895275362782784; train accuracy : 0.961815111992317; \n",
      " validation loss : 0.6321430642173647; validation accuracy : 0.9205020920502092\n",
      "Epoch 15:\t train loss : 0.5956923635676944; train accuracy : 0.9554001053316398; \n",
      " validation loss : 0.6406609138410084; validation accuracy : 0.9121338912133892\n",
      "Epoch 16:\t train loss : 0.5925905558354599; train accuracy : 0.9582177266953747; \n",
      " validation loss : 0.6401205011315549; validation accuracy : 0.9079497907949791\n",
      "Epoch 17:\t train loss : 0.5857567486960328; train accuracy : 0.9655599615849314; \n",
      " validation loss : 0.6485023321071676; validation accuracy : 0.895397489539749\n",
      "Epoch 18:\t train loss : 0.5920154735048241; train accuracy : 0.9589030019517333; \n",
      " validation loss : 0.6274505561954453; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.58383856076612; train accuracy : 0.9672985532389479; \n",
      " validation loss : 0.622699682095349; validation accuracy : 0.9246861924686193\n",
      "Epoch 20:\t train loss : 0.5793412193541709; train accuracy : 0.9720480807955637; \n",
      " validation loss : 0.6393095464838592; validation accuracy : 0.9121338912133892\n",
      "Epoch 21:\t train loss : 0.5852003477725822; train accuracy : 0.9657046376901391; \n",
      " validation loss : 0.6685073725049333; validation accuracy : 0.8786610878661087\n",
      "Epoch 22:\t train loss : 0.5863325662178869; train accuracy : 0.9647544843396636; \n",
      " validation loss : 0.6286555004085977; validation accuracy : 0.9163179916317992\n",
      "Epoch 23:\t train loss : 0.5749829553926403; train accuracy : 0.9763158709997212; \n",
      " validation loss : 0.6114247096756387; validation accuracy : 0.9414225941422594\n",
      "Epoch 24:\t train loss : 0.5769680582168574; train accuracy : 0.9742653118126336; \n",
      " validation loss : 0.640216377534472; validation accuracy : 0.9079497907949791\n",
      "Epoch 25:\t train loss : 0.576548719243836; train accuracy : 0.9745980358747173; \n",
      " validation loss : 0.6321929141435644; validation accuracy : 0.9205020920502092\n",
      "Epoch 26:\t train loss : 0.5835811008601371; train accuracy : 0.9674224728151429; \n",
      " validation loss : 0.6250589984153705; validation accuracy : 0.9246861924686193\n",
      "Epoch 27:\t train loss : 0.5766236097382447; train accuracy : 0.974280801759658; \n",
      " validation loss : 0.6365303893456917; validation accuracy : 0.9121338912133892\n",
      "Epoch 28:\t train loss : 0.5737406362371993; train accuracy : 0.9772180055144212; \n",
      " validation loss : 0.6476500133046376; validation accuracy : 0.899581589958159\n",
      "Epoch 29:\t train loss : 0.5693438493601993; train accuracy : 0.9817063725642058; \n",
      " validation loss : 0.6222901981515877; validation accuracy : 0.9246861924686193\n",
      "Epoch 30:\t train loss : 0.5656476496058953; train accuracy : 0.9858886582607888; \n",
      " validation loss : 0.6174673038410982; validation accuracy : 0.9330543933054394\n",
      "Epoch 31:\t train loss : 0.5720270731539931; train accuracy : 0.9790613092103225; \n",
      " validation loss : 0.6507749663278308; validation accuracy : 0.899581589958159\n",
      "Epoch 32:\t train loss : 0.5789744365612125; train accuracy : 0.971839276309675; \n",
      " validation loss : 0.6269359719969292; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5664580141660092; train accuracy : 0.984767495895164; \n",
      " validation loss : 0.6409676006373086; validation accuracy : 0.9037656903765691\n",
      "Epoch 34:\t train loss : 0.5669157922328555; train accuracy : 0.9845351466897984; \n",
      " validation loss : 0.6376259723908261; validation accuracy : 0.9121338912133892\n",
      "Epoch 35:\t train loss : 0.5709184162562051; train accuracy : 0.9803779547073949; \n",
      " validation loss : 0.6719916440401329; validation accuracy : 0.8828451882845189\n",
      "Epoch 36:\t train loss : 0.5863023770610403; train accuracy : 0.9641983952414883; \n",
      " validation loss : 0.6372220437918156; validation accuracy : 0.9121338912133892\n",
      "Epoch 37:\t train loss : 0.5711974449426385; train accuracy : 0.9799442361907122; \n",
      " validation loss : 0.6183912456130092; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5720591241085761; train accuracy : 0.9789934632423557; \n",
      " validation loss : 0.6307550766164166; validation accuracy : 0.9163179916317992\n",
      "Epoch 39:\t train loss : 0.5744661162568013; train accuracy : 0.9764029245019982; \n",
      " validation loss : 0.6245517978142376; validation accuracy : 0.9205020920502092\n",
      "Epoch 40:\t train loss : 0.5691543545270094; train accuracy : 0.9818494996747111; \n",
      " validation loss : 0.6247796764507633; validation accuracy : 0.9246861924686193\n",
      "Epoch 41:\t train loss : 0.5665896260150515; train accuracy : 0.9847925896093436; \n",
      " validation loss : 0.6232541862424295; validation accuracy : 0.9246861924686193\n",
      "Epoch 42:\t train loss : 0.5619503227614037; train accuracy : 0.9893060503733078; \n",
      " validation loss : 0.6351592367119338; validation accuracy : 0.9163179916317992\n",
      "Epoch 43:\t train loss : 0.5649560154818696; train accuracy : 0.9861380464078813; \n",
      " validation loss : 0.6353046097836512; validation accuracy : 0.9163179916317992\n",
      "Epoch 44:\t train loss : 0.5701790148281675; train accuracy : 0.9808544254778648; \n",
      " validation loss : 0.6226281505831595; validation accuracy : 0.9288702928870293\n",
      "Epoch 45:\t train loss : 0.5631617194189132; train accuracy : 0.9880823445583816; \n",
      " validation loss : 0.6258128341417346; validation accuracy : 0.9246861924686193\n",
      "Epoch 46:\t train loss : 0.5606503840955478; train accuracy : 0.9906536757644289; \n",
      " validation loss : 0.61840528412131; validation accuracy : 0.9288702928870293\n",
      "Epoch 47:\t train loss : 0.5655222345571046; train accuracy : 0.9858459060070015; \n",
      " validation loss : 0.612185728879285; validation accuracy : 0.9372384937238494\n",
      "Epoch 48:\t train loss : 0.5692928403435619; train accuracy : 0.9817565599925648; \n",
      " validation loss : 0.6497488968005314; validation accuracy : 0.899581589958159\n",
      "Epoch 49:\t train loss : 0.5655450557069011; train accuracy : 0.9857064964837821; \n",
      " validation loss : 0.603737179553311; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5650172508210364; train accuracy : 0.9862759069363983; \n",
      " validation loss : 0.5915441467715044; validation accuracy : 0.9581589958158996\n",
      "Epoch 51:\t train loss : 0.5729658261086071; train accuracy : 0.9780197651724031; \n",
      " validation loss : 0.6009291688835612; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5670328789852878; train accuracy : 0.9840918244059605; \n",
      " validation loss : 0.6171055197879848; validation accuracy : 0.9330543933054394\n",
      "Epoch 53:\t train loss : 0.5624503574817322; train accuracy : 0.9887639022274544; \n",
      " validation loss : 0.606412938842445; validation accuracy : 0.9456066945606695\n",
      "Epoch 54:\t train loss : 0.5603641664895215; train accuracy : 0.9909420985780228; \n",
      " validation loss : 0.6199380828787278; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55:\t train loss : 0.5589806034561603; train accuracy : 0.9925493354812727; \n",
      " validation loss : 0.6083765962292226; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.567001318825494; train accuracy : 0.9841943678552619; \n",
      " validation loss : 0.608014402384492; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5602811982692362; train accuracy : 0.9910003407788345; \n",
      " validation loss : 0.622368446067694; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.5632228527722614; train accuracy : 0.9880609684314879; \n",
      " validation loss : 0.5974263053906744; validation accuracy : 0.9539748953974896\n",
      "Epoch 59:\t train loss : 0.5588048662382166; train accuracy : 0.9925338455342483; \n",
      " validation loss : 0.6078826004090896; validation accuracy : 0.9372384937238494\n",
      "Epoch 60:\t train loss : 0.56087796023662; train accuracy : 0.9905548499024134; \n",
      " validation loss : 0.60426824333573; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5627794772640244; train accuracy : 0.9884909693608848; \n",
      " validation loss : 0.6447486705697613; validation accuracy : 0.9037656903765691\n",
      "Epoch 62:\t train loss : 0.5630268212140902; train accuracy : 0.988212150314446; \n",
      " validation loss : 0.6058408377776581; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5653974709864457; train accuracy : 0.9858245298801078; \n",
      " validation loss : 0.6355002129054702; validation accuracy : 0.9121338912133892\n",
      "Epoch 64:\t train loss : 0.559014345580125; train accuracy : 0.9924852071005917; \n",
      " validation loss : 0.6117715771866162; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.5612557064873395; train accuracy : 0.9899780042752254; \n",
      " validation loss : 0.6295236413481596; validation accuracy : 0.9205020920502092\n",
      "Epoch 66:\t train loss : 0.599031704464027; train accuracy : 0.9515660336441649; \n",
      " validation loss : 0.6402661005946816; validation accuracy : 0.9079497907949791\n",
      "Epoch 67:\t train loss : 0.5861306106298371; train accuracy : 0.9645568326156324; \n",
      " validation loss : 0.6191767588996117; validation accuracy : 0.9288702928870293\n",
      "Epoch 68:\t train loss : 0.5713438353892732; train accuracy : 0.9796654171442734; \n",
      " validation loss : 0.6143035299933546; validation accuracy : 0.9330543933054394\n",
      "Epoch 69:\t train loss : 0.566497743287702; train accuracy : 0.9847055361070666; \n",
      " validation loss : 0.6021868447558569; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5630238962864627; train accuracy : 0.9882431302084946; \n",
      " validation loss : 0.6131051966568367; validation accuracy : 0.9372384937238494\n",
      "Epoch 71:\t train loss : 0.5602684842248871; train accuracy : 0.9909634747049165; \n",
      " validation loss : 0.6151296708741905; validation accuracy : 0.9330543933054394\n",
      "Epoch 72:\t train loss : 0.55937336132281; train accuracy : 0.9919393413674525; \n",
      " validation loss : 0.6169447209113433; validation accuracy : 0.9330543933054394\n",
      "Epoch 73:\t train loss : 0.5634639115468613; train accuracy : 0.9877880355649183; \n",
      " validation loss : 0.6042446783948203; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5669497074542763; train accuracy : 0.9841324080671644; \n",
      " validation loss : 0.616027537470593; validation accuracy : 0.9330543933054394\n",
      "Epoch 75:\t train loss : 0.5620664232828155; train accuracy : 0.9891821307971127; \n",
      " validation loss : 0.6108602754788309; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5609088128526754; train accuracy : 0.9903342730567861; \n",
      " validation loss : 0.6060332213215399; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5648474799320237; train accuracy : 0.9863843365655689; \n",
      " validation loss : 0.6151488486129507; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5592919706316554; train accuracy : 0.9918928715263794; \n",
      " validation loss : 0.5909377464390444; validation accuracy : 0.9581589958158996\n",
      "Epoch 79:\t train loss : 0.5600432465964416; train accuracy : 0.9913042535394528; \n",
      " validation loss : 0.6033804183694528; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5626626216993362; train accuracy : 0.9885721366832926; \n",
      " validation loss : 0.6167335858251095; validation accuracy : 0.9288702928870293\n",
      "Epoch 81:\t train loss : 0.5609978948289726; train accuracy : 0.9903128969298924; \n",
      " validation loss : 0.6050652125984449; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5615583700788016; train accuracy : 0.9896136807212119; \n",
      " validation loss : 0.6049380096157552; validation accuracy : 0.9456066945606695\n",
      "Epoch 83:\t train loss : 0.5747079013689271; train accuracy : 0.9760503733077233; \n",
      " validation loss : 0.6081694132305862; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5603070470594967; train accuracy : 0.9910313206728832; \n",
      " validation loss : 0.6055500084488902; validation accuracy : 0.9456066945606695\n",
      "Epoch 85:\t train loss : 0.5612147934181753; train accuracy : 0.9899876080423805; \n",
      " validation loss : 0.6054498327409003; validation accuracy : 0.9456066945606695\n",
      "Epoch 86:\t train loss : 0.5576539259298149; train accuracy : 0.9937110815081013; \n",
      " validation loss : 0.601221043507601; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5563923421703126; train accuracy : 0.9949502772700517; \n",
      " validation loss : 0.594474992832437; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5579208405359382; train accuracy : 0.9933799064407199; \n",
      " validation loss : 0.612219428557216; validation accuracy : 0.9372384937238494\n",
      "Epoch 89:\t train loss : 0.5586783797748834; train accuracy : 0.9926887450044921; \n",
      " validation loss : 0.6070026235043712; validation accuracy : 0.9414225941422594\n",
      "Epoch 90:\t train loss : 0.5909230071046785; train accuracy : 0.9595160940549583; \n",
      " validation loss : 0.6595688767352668; validation accuracy : 0.891213389121339\n",
      "Epoch 91:\t train loss : 0.5786866550429025; train accuracy : 0.9721373028904241; \n",
      " validation loss : 0.6285602460880049; validation accuracy : 0.9205020920502092\n",
      "Epoch 92:\t train loss : 0.5597447472884401; train accuracy : 0.9915734688187366; \n",
      " validation loss : 0.5881647406974345; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5624542491220159; train accuracy : 0.9887329223334056; \n",
      " validation loss : 0.6086755113509162; validation accuracy : 0.9456066945606695\n",
      "Epoch 94:\t train loss : 0.5578394078821444; train accuracy : 0.9934787323027355; \n",
      " validation loss : 0.6104991030725307; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.5608355256839435; train accuracy : 0.9905046624740543; \n",
      " validation loss : 0.595311536713435; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.5576924696937895; train accuracy : 0.9936336317729794; \n",
      " validation loss : 0.5917683098034185; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5598278739901069; train accuracy : 0.9914724743641377; \n",
      " validation loss : 0.6265304123166827; validation accuracy : 0.9246861924686193\n",
      "Epoch 98:\t train loss : 0.5619982639382938; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.604659114567718; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.556341076479304; train accuracy : 0.9950779144335327; \n",
      " validation loss : 0.6103360546776885; validation accuracy : 0.9330543933054394\n",
      "Epoch 100:\t train loss : 0.5560309904483193; train accuracy : 0.9953220359986369; \n",
      " validation loss : 0.5938984674697277; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5697568227147877; train accuracy : 0.9813906874438489; \n",
      " validation loss : 0.611884801221666; validation accuracy : 0.9372384937238494\n",
      "Epoch 102:\t train loss : 0.5653477813622241; train accuracy : 0.9857802286316181; \n",
      " validation loss : 0.6183385735977092; validation accuracy : 0.9330543933054394\n",
      "Epoch 103:\t train loss : 0.5596055051590374; train accuracy : 0.9917689519501843; \n",
      " validation loss : 0.5851726740992441; validation accuracy : 0.9665271966527197\n",
      "Epoch 104:\t train loss : 0.5644080512530479; train accuracy : 0.9867966789553579; \n",
      " validation loss : 0.5946952454601331; validation accuracy : 0.9581589958158996\n",
      "Epoch 105:\t train loss : 0.5571850900574202; train accuracy : 0.9941293100777595; \n",
      " validation loss : 0.6091272329470967; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106:\t train loss : 0.5633896821932572; train accuracy : 0.9878035255119427; \n",
      " validation loss : 0.6016837058579732; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5650256186717687; train accuracy : 0.9862988320579944; \n",
      " validation loss : 0.6124043302416168; validation accuracy : 0.9414225941422594\n",
      "Epoch 108:\t train loss : 0.5797986888799872; train accuracy : 0.9710678769478608; \n",
      " validation loss : 0.664274676180116; validation accuracy : 0.8828451882845189\n",
      "Epoch 109:\t train loss : 0.5737532997644517; train accuracy : 0.9771058582979646; \n",
      " validation loss : 0.6077149640922895; validation accuracy : 0.9414225941422594\n",
      "Epoch 110:\t train loss : 0.5665556609740114; train accuracy : 0.9846745562130178; \n",
      " validation loss : 0.60982835588746; validation accuracy : 0.9414225941422594\n",
      "Epoch 111:\t train loss : 0.5593331232811533; train accuracy : 0.9919858112085257; \n",
      " validation loss : 0.6179363222235797; validation accuracy : 0.9330543933054394\n",
      "Epoch 112:\t train loss : 0.5583726341280948; train accuracy : 0.9928997180829642; \n",
      " validation loss : 0.5885390212143988; validation accuracy : 0.9581589958158996\n",
      "Epoch 113:\t train loss : 0.5621178635386355; train accuracy : 0.9891260571888844; \n",
      " validation loss : 0.608141550372031; validation accuracy : 0.9414225941422594\n",
      "Epoch 114:\t train loss : 0.5584103688750816; train accuracy : 0.9929056042628334; \n",
      " validation loss : 0.5837581741078809; validation accuracy : 0.9665271966527197\n",
      "Epoch 115:\t train loss : 0.568975874847534; train accuracy : 0.9820567551658973; \n",
      " validation loss : 0.6077534686445413; validation accuracy : 0.9456066945606695\n",
      "Epoch 116:\t train loss : 0.5603566815322218; train accuracy : 0.9909228910437127; \n",
      " validation loss : 0.5968632919922017; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5563452341254514; train accuracy : 0.9950896867932711; \n",
      " validation loss : 0.5863467726582362; validation accuracy : 0.9665271966527197\n",
      "Epoch 118:\t train loss : 0.5566813780845578; train accuracy : 0.9947430217788655; \n",
      " validation loss : 0.587509319786132; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.5561057081455529; train accuracy : 0.9952541900306701; \n",
      " validation loss : 0.5972279866518477; validation accuracy : 0.9539748953974896\n",
      "Epoch 120:\t train loss : 0.5567667167167734; train accuracy : 0.9946404783295641; \n",
      " validation loss : 0.5754687106264297; validation accuracy : 0.9748953974895398\n",
      "Epoch 121:\t train loss : 0.5589108485042282; train accuracy : 0.992367173704266; \n",
      " validation loss : 0.6300291094763655; validation accuracy : 0.9163179916317992\n",
      "Epoch 122:\t train loss : 0.5645213719259453; train accuracy : 0.9865488398029679; \n",
      " validation loss : 0.6101201062482413; validation accuracy : 0.9372384937238494\n",
      "Epoch 123:\t train loss : 0.559860368771325; train accuracy : 0.9914126831686235; \n",
      " validation loss : 0.5889875215124833; validation accuracy : 0.9623430962343096\n",
      "Epoch 124:\t train loss : 0.5594666498409808; train accuracy : 0.9918928715263794; \n",
      " validation loss : 0.6015648164269418; validation accuracy : 0.9497907949790795\n",
      "Epoch 125:\t train loss : 0.5630788610043043; train accuracy : 0.988010781003129; \n",
      " validation loss : 0.5858209322107943; validation accuracy : 0.9623430962343096\n",
      "Epoch 126:\t train loss : 0.5594412452288675; train accuracy : 0.9917165959292419; \n",
      " validation loss : 0.6000302076109785; validation accuracy : 0.9497907949790795\n",
      "Epoch 127:\t train loss : 0.5583879404541535; train accuracy : 0.9928377582948666; \n",
      " validation loss : 0.6082568220183291; validation accuracy : 0.9414225941422594\n",
      "Epoch 128:\t train loss : 0.5580371118934105; train accuracy : 0.9932773629914186; \n",
      " validation loss : 0.5856398299903975; validation accuracy : 0.9665271966527197\n",
      "Epoch 129:\t train loss : 0.5577398192498427; train accuracy : 0.9935444096781189; \n",
      " validation loss : 0.6204886344784446; validation accuracy : 0.9288702928870293\n",
      "Epoch 130:\t train loss : 0.5582379195186764; train accuracy : 0.9931106911614362; \n",
      " validation loss : 0.6391930281470333; validation accuracy : 0.9121338912133892\n",
      "Epoch 131:\t train loss : 0.5654996724047053; train accuracy : 0.9857027788964962; \n",
      " validation loss : 0.5955862442316083; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5588925296159151; train accuracy : 0.9924446234393878; \n",
      " validation loss : 0.6101106450407333; validation accuracy : 0.9414225941422594\n",
      "Epoch 133:\t train loss : 0.5576620335396225; train accuracy : 0.9937612689364602; \n",
      " validation loss : 0.6013566687099202; validation accuracy : 0.9497907949790795\n",
      "Epoch 134:\t train loss : 0.5581973495887352; train accuracy : 0.9931999132562966; \n",
      " validation loss : 0.6138551315350411; validation accuracy : 0.9372384937238494\n",
      "Epoch 135:\t train loss : 0.5573930569766274; train accuracy : 0.9939220545865733; \n",
      " validation loss : 0.6075430422348901; validation accuracy : 0.9414225941422594\n",
      "Epoch 136:\t train loss : 0.55661406777173; train accuracy : 0.9947371355989962; \n",
      " validation loss : 0.6023835101631423; validation accuracy : 0.9497907949790795\n",
      "Epoch 137:\t train loss : 0.5562950106259281; train accuracy : 0.995093404380557; \n",
      " validation loss : 0.5943950534747761; validation accuracy : 0.9539748953974896\n",
      "Epoch 138:\t train loss : 0.561587033395546; train accuracy : 0.9896136807212119; \n",
      " validation loss : 0.6276486170926575; validation accuracy : 0.9205020920502092\n",
      "Epoch 139:\t train loss : 0.5605862558851047; train accuracy : 0.990613092103225; \n",
      " validation loss : 0.5865368457170379; validation accuracy : 0.9665271966527197\n",
      "Epoch 140:\t train loss : 0.5569362076432459; train accuracy : 0.9944022429443291; \n",
      " validation loss : 0.6283107344946521; validation accuracy : 0.9205020920502092\n",
      "Epoch 141:\t train loss : 0.5568285491262183; train accuracy : 0.9944855788593203; \n",
      " validation loss : 0.614618620167646; validation accuracy : 0.9372384937238494\n",
      "Epoch 142:\t train loss : 0.5620461064992421; train accuracy : 0.9891725270299575; \n",
      " validation loss : 0.5934750583511896; validation accuracy : 0.9581589958158996\n",
      "Epoch 143:\t train loss : 0.5568363692149693; train accuracy : 0.9945416524675486; \n",
      " validation loss : 0.6079683586260954; validation accuracy : 0.9456066945606695\n",
      "Epoch 144:\t train loss : 0.5763729924427838; train accuracy : 0.9747204064562099; \n",
      " validation loss : 0.6243822034982947; validation accuracy : 0.9246861924686193\n",
      "Epoch 145:\t train loss : 0.5594637649730696; train accuracy : 0.9917689519501843; \n",
      " validation loss : 0.600921835052016; validation accuracy : 0.9497907949790795\n",
      "Epoch 146:\t train loss : 0.5609501024049567; train accuracy : 0.9902819170358437; \n",
      " validation loss : 0.6141806415451816; validation accuracy : 0.9372384937238494\n",
      "Epoch 147:\t train loss : 0.5589673922556194; train accuracy : 0.9922336503609157; \n",
      " validation loss : 0.6045957464613494; validation accuracy : 0.9456066945606695\n",
      "Epoch 148:\t train loss : 0.556191301775773; train accuracy : 0.9951981164224418; \n",
      " validation loss : 0.5809304674171156; validation accuracy : 0.9707112970711297\n",
      "Epoch 149:\t train loss : 0.5571754246190989; train accuracy : 0.9941138201307351; \n",
      " validation loss : 0.600392953829059; validation accuracy : 0.9497907949790795\n",
      "Epoch 150:\t train loss : 0.5549249149831357; train accuracy : 0.996435143591809; \n",
      " validation loss : 0.586300456459268; validation accuracy : 0.9665271966527197\n",
      "Epoch 151:\t train loss : 0.5565418619416362; train accuracy : 0.9948300752811425; \n",
      " validation loss : 0.6073213775886808; validation accuracy : 0.9456066945606695\n",
      "Epoch 152:\t train loss : 0.5569567479573354; train accuracy : 0.994392639177174; \n",
      " validation loss : 0.597219444358112; validation accuracy : 0.9539748953974896\n",
      "Epoch 153:\t train loss : 0.5561810742299325; train accuracy : 0.9951553641686546; \n",
      " validation loss : 0.5966235920691196; validation accuracy : 0.9539748953974896\n",
      "Epoch 154:\t train loss : 0.5589223662319084; train accuracy : 0.9924254159050776; \n",
      " validation loss : 0.5945638126439841; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5596597272348803; train accuracy : 0.991465039189566; \n",
      " validation loss : 0.6244137193949776; validation accuracy : 0.9205020920502092\n",
      "Epoch 156:\t train loss : 0.5603327420545727; train accuracy : 0.9909074010966883; \n",
      " validation loss : 0.5995582395635666; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157:\t train loss : 0.5622390460213271; train accuracy : 0.988949781591747; \n",
      " validation loss : 0.5966762067442376; validation accuracy : 0.9539748953974896\n",
      "Epoch 158:\t train loss : 0.5702754128938745; train accuracy : 0.9808045478484464; \n",
      " validation loss : 0.8189701771726141; validation accuracy : 0.7322175732217573\n",
      "Epoch 159:\t train loss : 0.6339588785343817; train accuracy : 0.9156668422193996; \n",
      " validation loss : 0.6163439868754689; validation accuracy : 0.9330543933054394\n",
      "Epoch 160:\t train loss : 0.5732701114907638; train accuracy : 0.9776923076923077; \n",
      " validation loss : 0.6231156192530869; validation accuracy : 0.9246861924686193\n",
      "Epoch 161:\t train loss : 0.5666467702112205; train accuracy : 0.9844635831345457; \n",
      " validation loss : 0.6037538179896123; validation accuracy : 0.9456066945606695\n",
      "Epoch 162:\t train loss : 0.5668662401177694; train accuracy : 0.9842135753895722; \n",
      " validation loss : 0.6033685670982969; validation accuracy : 0.9497907949790795\n",
      "Epoch 163:\t train loss : 0.5647895164543681; train accuracy : 0.9863415843117816; \n",
      " validation loss : 0.605636850904785; validation accuracy : 0.9414225941422594\n",
      "Epoch 164:\t train loss : 0.5610449336568986; train accuracy : 0.9901019238514204; \n",
      " validation loss : 0.6027467559310093; validation accuracy : 0.9497907949790795\n",
      "Epoch 165:\t train loss : 0.5627228946601682; train accuracy : 0.9885005731280398; \n",
      " validation loss : 0.6232805190417559; validation accuracy : 0.9205020920502092\n",
      "Epoch 166:\t train loss : 0.5601020997946031; train accuracy : 0.991102884228136; \n",
      " validation loss : 0.6078666967124442; validation accuracy : 0.9456066945606695\n",
      "Epoch 167:\t train loss : 0.5584165222017011; train accuracy : 0.992890114315809; \n",
      " validation loss : 0.5985518010062465; validation accuracy : 0.9497907949790795\n",
      "Epoch 168:\t train loss : 0.5573786426353268; train accuracy : 0.9939744106075157; \n",
      " validation loss : 0.5881583281846245; validation accuracy : 0.9623430962343096\n",
      "Epoch 169:\t train loss : 0.5582215873795824; train accuracy : 0.9931475572353542; \n",
      " validation loss : 0.62105215577712; validation accuracy : 0.9288702928870293\n",
      "Epoch 170:\t train loss : 0.5589030467481592; train accuracy : 0.9924446234393879; \n",
      " validation loss : 0.6014036587764453; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 170\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5567667167167734; Train accuracy : 0.9946404783295641; \n",
      " Validation loss : 0.5754687106264297; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 52 ! ---\n",
      "Epoch 1:\t train loss : 0.9171337218790335; train accuracy : 0.6211446771045591; \n",
      " validation loss : 0.7826183757072702; validation accuracy : 0.7615062761506276\n",
      "Epoch 2:\t train loss : 0.721808195456947; train accuracy : 0.8297307047726026; \n",
      " validation loss : 0.7119819098840328; validation accuracy : 0.8410041841004184\n",
      "Epoch 3:\t train loss : 0.6680195606543707; train accuracy : 0.8829708519171058; \n",
      " validation loss : 0.6662019711465941; validation accuracy : 0.8870292887029289\n",
      "Epoch 4:\t train loss : 0.6537752983186751; train accuracy : 0.8974159770309069; \n",
      " validation loss : 0.6877382722833145; validation accuracy : 0.8577405857740585\n",
      "Epoch 5:\t train loss : 0.6382912704639867; train accuracy : 0.9127509246499023; \n",
      " validation loss : 0.6527838167221862; validation accuracy : 0.9037656903765691\n",
      "Epoch 6:\t train loss : 0.6270699128902963; train accuracy : 0.923598184778079; \n",
      " validation loss : 0.6472502658445848; validation accuracy : 0.9037656903765691\n",
      "Epoch 7:\t train loss : 0.6137295939446215; train accuracy : 0.937579910637996; \n",
      " validation loss : 0.655408649822499; validation accuracy : 0.891213389121339\n",
      "Epoch 8:\t train loss : 0.6099437902646281; train accuracy : 0.9409849007993812; \n",
      " validation loss : 0.6304043982758686; validation accuracy : 0.9246861924686193\n",
      "Epoch 9:\t train loss : 0.6032427067511652; train accuracy : 0.9476962451369062; \n",
      " validation loss : 0.6382044027430668; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.606475260308935; train accuracy : 0.9441208655582527; \n",
      " validation loss : 0.6326255375164488; validation accuracy : 0.9079497907949791\n",
      "Epoch 11:\t train loss : 0.605921808254418; train accuracy : 0.9447742415172553; \n",
      " validation loss : 0.6418805969549475; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.5936801538297289; train accuracy : 0.9575689377593941; \n",
      " validation loss : 0.6192861728379011; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.5881286812042618; train accuracy : 0.9632762337243129; \n",
      " validation loss : 0.6469913656877166; validation accuracy : 0.895397489539749\n",
      "Epoch 14:\t train loss : 0.5877118246345279; train accuracy : 0.9632368592783284; \n",
      " validation loss : 0.6400234645149545; validation accuracy : 0.9121338912133892\n",
      "Epoch 15:\t train loss : 0.5928402231678391; train accuracy : 0.9581955311003159; \n",
      " validation loss : 0.6315525399604642; validation accuracy : 0.9163179916317992\n",
      "Epoch 16:\t train loss : 0.583602329396743; train accuracy : 0.9677528284143591; \n",
      " validation loss : 0.6610641240337536; validation accuracy : 0.8828451882845189\n",
      "Epoch 17:\t train loss : 0.5797691030583692; train accuracy : 0.9715394708833966; \n",
      " validation loss : 0.6236823115709117; validation accuracy : 0.9288702928870293\n",
      "Epoch 18:\t train loss : 0.5822694426888558; train accuracy : 0.968696316090857; \n",
      " validation loss : 0.6453967697398043; validation accuracy : 0.9037656903765691\n",
      "Epoch 19:\t train loss : 0.5867332678014284; train accuracy : 0.9640873073375379; \n",
      " validation loss : 0.6193461342059705; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5771945580169657; train accuracy : 0.9740318533271907; \n",
      " validation loss : 0.606253495400434; validation accuracy : 0.9456066945606695\n",
      "Epoch 21:\t train loss : 0.5742674735522689; train accuracy : 0.9770439984450092; \n",
      " validation loss : 0.5975389031128487; validation accuracy : 0.9539748953974896\n",
      "Epoch 22:\t train loss : 0.5708202267558588; train accuracy : 0.9803658425681733; \n",
      " validation loss : 0.6042617691735894; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.5732233027365112; train accuracy : 0.9779522090163484; \n",
      " validation loss : 0.612695210758311; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5689635630895429; train accuracy : 0.9824288037063945; \n",
      " validation loss : 0.6090770237920359; validation accuracy : 0.9372384937238494\n",
      "Epoch 25:\t train loss : 0.5664145849576877; train accuracy : 0.9848297454951737; \n",
      " validation loss : 0.5994267773954335; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5693963962749127; train accuracy : 0.9816501090792076; \n",
      " validation loss : 0.631758496282333; validation accuracy : 0.9205020920502092\n",
      "Epoch 27:\t train loss : 0.5813684599450597; train accuracy : 0.9699664917468563; \n",
      " validation loss : 0.6249125146616937; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.5792784812490026; train accuracy : 0.9716323106304009; \n",
      " validation loss : 0.6102845290884383; validation accuracy : 0.9414225941422594\n",
      "Epoch 29:\t train loss : 0.5702587726916444; train accuracy : 0.9810178194351866; \n",
      " validation loss : 0.6390980330779226; validation accuracy : 0.9163179916317992\n",
      "Epoch 30:\t train loss : 0.573069353320071; train accuracy : 0.9783873266250204; \n",
      " validation loss : 0.6261325464273345; validation accuracy : 0.9163179916317992\n",
      "Epoch 31:\t train loss : 0.5702262745802779; train accuracy : 0.9809262788450296; \n",
      " validation loss : 0.6298102232940962; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.5646572586165423; train accuracy : 0.9867927714913022; \n",
      " validation loss : 0.6268249121864148; validation accuracy : 0.9246861924686193\n",
      "Epoch 33:\t train loss : 0.5674909618431365; train accuracy : 0.9840059801189028; \n",
      " validation loss : 0.6123734832200466; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.5635450656326709; train accuracy : 0.9880079828191504; \n",
      " validation loss : 0.6244381467418099; validation accuracy : 0.9246861924686193\n",
      "Epoch 35:\t train loss : 0.5624907331205009; train accuracy : 0.9887979701173938; \n",
      " validation loss : 0.6092395674477653; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.567917463613182; train accuracy : 0.9834201603159549; \n",
      " validation loss : 0.610171227518566; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:\t train loss : 0.5710921060223123; train accuracy : 0.9798264926062985; \n",
      " validation loss : 0.600051522165379; validation accuracy : 0.9497907949790795\n",
      "Epoch 38:\t train loss : 0.5716210539527494; train accuracy : 0.9793645923795457; \n",
      " validation loss : 0.6155389203792734; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5649278442410275; train accuracy : 0.9863195785934928; \n",
      " validation loss : 0.6072604430357542; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.562578729954236; train accuracy : 0.9887191212902826; \n",
      " validation loss : 0.6083837840917388; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5618027826459944; train accuracy : 0.9892443803971223; \n",
      " validation loss : 0.5925651662739726; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.5631205322047416; train accuracy : 0.9883797415477356; \n",
      " validation loss : 0.594562629251868; validation accuracy : 0.9539748953974896\n",
      "Epoch 43:\t train loss : 0.5650308529043934; train accuracy : 0.9860520522181104; \n",
      " validation loss : 0.629014127452268; validation accuracy : 0.9205020920502092\n",
      "Epoch 44:\t train loss : 0.5745436524928641; train accuracy : 0.9763595426568157; \n",
      " validation loss : 0.613191244665319; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5664112665172568; train accuracy : 0.9848001646931142; \n",
      " validation loss : 0.5862512231455459; validation accuracy : 0.9665271966527197\n",
      "Epoch 46:\t train loss : 0.559795206551779; train accuracy : 0.9914890236236682; \n",
      " validation loss : 0.6115593130234038; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.5613729833436502; train accuracy : 0.9898217057129922; \n",
      " validation loss : 0.6041191400122742; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5586403077835825; train accuracy : 0.9926859468205135; \n",
      " validation loss : 0.5965770521430749; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.564310120697819; train accuracy : 0.9869997371705763; \n",
      " validation loss : 0.6069653043736771; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5674706401423446; train accuracy : 0.9835567716551957; \n",
      " validation loss : 0.619243896077254; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.5597000711330263; train accuracy : 0.9916495194618692; \n",
      " validation loss : 0.6125526230986805; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5614110475390522; train accuracy : 0.9897936239380641; \n",
      " validation loss : 0.6224042022325472; validation accuracy : 0.9288702928870293\n",
      "Epoch 53:\t train loss : 0.5698645313458888; train accuracy : 0.981299436665604; \n",
      " validation loss : 0.6056335254056401; validation accuracy : 0.9456066945606695\n",
      "Epoch 54:\t train loss : 0.5582914632254368; train accuracy : 0.9929182960258792; \n",
      " validation loss : 0.6023988376272046; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.561834603381548; train accuracy : 0.9893274265002013; \n",
      " validation loss : 0.6030886948874828; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5582812242634249; train accuracy : 0.9930422156020743; \n",
      " validation loss : 0.6138110868324903; validation accuracy : 0.9330543933054394\n",
      "Epoch 57:\t train loss : 0.556555090172846; train accuracy : 0.9946559682765885; \n",
      " validation loss : 0.6110783455604156; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5608893035238002; train accuracy : 0.9903920355689158; \n",
      " validation loss : 0.6119463060858744; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5573358595391688; train accuracy : 0.9939730115155264; \n",
      " validation loss : 0.6173338879260809; validation accuracy : 0.9330543933054394\n",
      "Epoch 60:\t train loss : 0.5607470076094668; train accuracy : 0.9904357072260103; \n",
      " validation loss : 0.608893790239864; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.560816473662277; train accuracy : 0.9904399045019782; \n",
      " validation loss : 0.5942880755448668; validation accuracy : 0.9581589958158996\n",
      "Epoch 62:\t train loss : 0.5571194097132507; train accuracy : 0.9942166533919486; \n",
      " validation loss : 0.6235635354699411; validation accuracy : 0.9246861924686193\n",
      "Epoch 63:\t train loss : 0.5946251390517565; train accuracy : 0.955818573745639; \n",
      " validation loss : 0.6211944681443379; validation accuracy : 0.9288702928870293\n",
      "Epoch 64:\t train loss : 0.5750937719310008; train accuracy : 0.9759456112982674; \n",
      " validation loss : 0.6378457843934346; validation accuracy : 0.9121338912133892\n",
      "Epoch 65:\t train loss : 0.568699061908875; train accuracy : 0.9823372631162376; \n",
      " validation loss : 0.6079624469696464; validation accuracy : 0.9456066945606695\n",
      "Epoch 66:\t train loss : 0.5582517082051347; train accuracy : 0.9930591046410879; \n",
      " validation loss : 0.6095359465857669; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5573263844736351; train accuracy : 0.9938322029003177; \n",
      " validation loss : 0.6317473305534232; validation accuracy : 0.9205020920502092\n",
      "Epoch 68:\t train loss : 0.5595623255809729; train accuracy : 0.9915988523448283; \n",
      " validation loss : 0.6316124718016716; validation accuracy : 0.9205020920502092\n",
      "Epoch 69:\t train loss : 0.5695365197048159; train accuracy : 0.9814994068849316; \n",
      " validation loss : 0.618360225448751; validation accuracy : 0.9330543933054394\n",
      "Epoch 70:\t train loss : 0.560249152440161; train accuracy : 0.9909496736617935; \n",
      " validation loss : 0.6086286494477319; validation accuracy : 0.9414225941422594\n",
      "Epoch 71:\t train loss : 0.5566355825133646; train accuracy : 0.9947461097747562; \n",
      " validation loss : 0.6242437039232308; validation accuracy : 0.9246861924686193\n",
      "Epoch 72:\t train loss : 0.5555732958351159; train accuracy : 0.9958163152114278; \n",
      " validation loss : 0.6041030101881256; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5571353674056898; train accuracy : 0.9942927040350812; \n",
      " validation loss : 0.6114887799419753; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5556221595736105; train accuracy : 0.9958332042504414; \n",
      " validation loss : 0.6006824705827397; validation accuracy : 0.9497907949790795\n",
      "Epoch 75:\t train loss : 0.5621954877002355; train accuracy : 0.9888726216685371; \n",
      " validation loss : 0.5945538479338288; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5593423333913465; train accuracy : 0.9919410302713538; \n",
      " validation loss : 0.621487315624873; validation accuracy : 0.9246861924686193\n",
      "Epoch 77:\t train loss : 0.5631455168010238; train accuracy : 0.9880192754902068; \n",
      " validation loss : 0.5898306387350087; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5590392261967677; train accuracy : 0.9921719803847303; \n",
      " validation loss : 0.59400086893722; validation accuracy : 0.9581589958158996\n",
      "Epoch 79:\t train loss : 0.5578483238687589; train accuracy : 0.9933956861996565; \n",
      " validation loss : 0.6135114698091136; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.5570457948219449; train accuracy : 0.9942828104560141; \n",
      " validation loss : 0.5928647733149484; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.5711540259716256; train accuracy : 0.979929325867512; \n",
      " validation loss : 0.6330961856945505; validation accuracy : 0.9163179916317992\n",
      "Epoch 82:\t train loss : 0.5765567355526418; train accuracy : 0.9742824906635593; \n",
      " validation loss : 0.6089300552293996; validation accuracy : 0.9456066945606695\n",
      "Epoch 83:\t train loss : 0.5650475417003767; train accuracy : 0.9861632800312597; \n",
      " validation loss : 0.5925894566587723; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5574980832189474; train accuracy : 0.9938645818863557; \n",
      " validation loss : 0.5952573858371812; validation accuracy : 0.9539748953974896\n",
      "Epoch 85:\t train loss : 0.5559350151308424; train accuracy : 0.9954741372849021; \n",
      " validation loss : 0.5825278016186203; validation accuracy : 0.9665271966527197\n",
      "Epoch 86:\t train loss : 0.5549916056433544; train accuracy : 0.9963514678973346; \n",
      " validation loss : 0.6057313387661993; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.5544897638737792; train accuracy : 0.9968541416620613; \n",
      " validation loss : 0.5921715751994563; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88:\t train loss : 0.5575345987283498; train accuracy : 0.993756152257185; \n",
      " validation loss : 0.5973888698815945; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5576866250157168; train accuracy : 0.99374206140215; \n",
      " validation loss : 0.5913998881572532; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5569565067456237; train accuracy : 0.9944208208872442; \n",
      " validation loss : 0.6064961135779224; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5636649165108627; train accuracy : 0.9875263953694052; \n",
      " validation loss : 0.6015234277477335; validation accuracy : 0.9497907949790795\n",
      "Epoch 92:\t train loss : 0.5888766444982766; train accuracy : 0.9618736440050407; \n",
      " validation loss : 0.6106353939109984; validation accuracy : 0.9414225941422594\n",
      "Epoch 93:\t train loss : 0.5631236850654523; train accuracy : 0.9881741749604507; \n",
      " validation loss : 0.6021164852427154; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5634948264455776; train accuracy : 0.9878361943098929; \n",
      " validation loss : 0.6217043394666412; validation accuracy : 0.9288702928870293\n",
      "Epoch 95:\t train loss : 0.5584911636800266; train accuracy : 0.9928366490147894; \n",
      " validation loss : 0.5994427328395825; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5665631951802079; train accuracy : 0.9846325734598246; \n",
      " validation loss : 0.5973576482357674; validation accuracy : 0.9497907949790795\n",
      "Epoch 97:\t train loss : 0.5578709263062611; train accuracy : 0.9935069140128057; \n",
      " validation loss : 0.6024322013415031; validation accuracy : 0.9497907949790795\n",
      "Epoch 98:\t train loss : 0.5570961560786186; train accuracy : 0.9944194217952549; \n",
      " validation loss : 0.5955495909334054; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5564553220242208; train accuracy : 0.9949291909550702; \n",
      " validation loss : 0.6280329397495938; validation accuracy : 0.9246861924686193\n",
      "Epoch 100:\t train loss : 0.5603377383015494; train accuracy : 0.99096096633285; \n",
      " validation loss : 0.600336279124832; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5652589725513784; train accuracy : 0.9858492838148042; \n",
      " validation loss : 0.603149324472357; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5628352299323377; train accuracy : 0.9883656506927004; \n",
      " validation loss : 0.5965685248148505; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5598777715390648; train accuracy : 0.9914439528745844; \n",
      " validation loss : 0.6106477229082364; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.5597749382227805; train accuracy : 0.9915551806877336; \n",
      " validation loss : 0.6124119699112345; validation accuracy : 0.9414225941422594\n",
      "Epoch 105:\t train loss : 0.5586844571241057; train accuracy : 0.9926803504525563; \n",
      " validation loss : 0.6149289928848599; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.5622878669238498; train accuracy : 0.9890640974007869; \n",
      " validation loss : 0.6181908008513619; validation accuracy : 0.9330543933054394\n",
      "Epoch 107:\t train loss : 0.5562297814958248; train accuracy : 0.9951474493054008; \n",
      " validation loss : 0.6171817416324904; validation accuracy : 0.9330543933054394\n",
      "Epoch 108:\t train loss : 0.5567382739440455; train accuracy : 0.9945729221735093; \n",
      " validation loss : 0.5984656115379966; validation accuracy : 0.9539748953974896\n",
      "Epoch 109:\t train loss : 0.5558309387744735; train accuracy : 0.9954882281399372; \n",
      " validation loss : 0.637939715696283; validation accuracy : 0.9163179916317992\n",
      "Epoch 110:\t train loss : 0.5716069361315377; train accuracy : 0.979398370457573; \n",
      " validation loss : 0.6010180446466489; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.560465033411374; train accuracy : 0.9908891129656853; \n",
      " validation loss : 0.6061907505256373; validation accuracy : 0.9414225941422594\n",
      "Epoch 112:\t train loss : 0.5565506412345079; train accuracy : 0.9947334180117103; \n",
      " validation loss : 0.5948230541326461; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5572538449156257; train accuracy : 0.9940208804485888; \n",
      " validation loss : 0.6312137732863089; validation accuracy : 0.9205020920502092\n",
      "Epoch 114:\t train loss : 0.5570218902047741; train accuracy : 0.9943278812050979; \n",
      " validation loss : 0.6107870798167261; validation accuracy : 0.9372384937238494\n",
      "Epoch 115:\t train loss : 0.5554178379094941; train accuracy : 0.9960345735617584; \n",
      " validation loss : 0.5894788982699437; validation accuracy : 0.9623430962343096\n",
      "Epoch 116:\t train loss : 0.5569372419587403; train accuracy : 0.9944672907283173; \n",
      " validation loss : 0.6150099798157096; validation accuracy : 0.9372384937238494\n",
      "Epoch 117:\t train loss : 0.5555478215603723; train accuracy : 0.9958627850525009; \n",
      " validation loss : 0.5963661843049459; validation accuracy : 0.9539748953974896\n",
      "Epoch 118:\t train loss : 0.5596518182686642; train accuracy : 0.9916903929349852; \n",
      " validation loss : 0.647039389311494; validation accuracy : 0.9037656903765691\n",
      "Epoch 119:\t train loss : 0.5602769310977885; train accuracy : 0.9910609014749427; \n",
      " validation loss : 0.6200661244916342; validation accuracy : 0.9288702928870293\n",
      "Epoch 120:\t train loss : 0.5563291250228026; train accuracy : 0.9950235297292057; \n",
      " validation loss : 0.6059655957384104; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5582966190455744; train accuracy : 0.9930183311031141; \n",
      " validation loss : 0.6077935155745763; validation accuracy : 0.9456066945606695\n",
      "Epoch 122:\t train loss : 0.5709980344885266; train accuracy : 0.9801152052318045; \n",
      " validation loss : 0.6323585028117283; validation accuracy : 0.9163179916317992\n",
      "Epoch 123:\t train loss : 0.5602626956769317; train accuracy : 0.9910567041989748; \n",
      " validation loss : 0.6162432981066903; validation accuracy : 0.9330543933054394\n",
      "Epoch 124:\t train loss : 0.5594152249168597; train accuracy : 0.9919424293633432; \n",
      " validation loss : 0.6010553374742976; validation accuracy : 0.9497907949790795\n",
      "Epoch 125:\t train loss : 0.5578251166700556; train accuracy : 0.9935083131047949; \n",
      " validation loss : 0.606710175241145; validation accuracy : 0.9456066945606695\n",
      "Epoch 126:\t train loss : 0.5711876153723451; train accuracy : 0.9800560436276856; \n",
      " validation loss : 0.6145956984739829; validation accuracy : 0.9372384937238494\n",
      "Epoch 127:\t train loss : 0.5648657819430104; train accuracy : 0.9864097200916605; \n",
      " validation loss : 0.6101144741854381; validation accuracy : 0.9414225941422594\n",
      "Epoch 128:\t train loss : 0.5629585621670262; train accuracy : 0.9884009277978592; \n",
      " validation loss : 0.6391243420934083; validation accuracy : 0.9121338912133892\n",
      "Epoch 129:\t train loss : 0.5587145214387597; train accuracy : 0.9925930071383672; \n",
      " validation loss : 0.6265840213741147; validation accuracy : 0.9246861924686193\n",
      "Epoch 130:\t train loss : 0.556007159716319; train accuracy : 0.9953643085637421; \n",
      " validation loss : 0.5811522771981456; validation accuracy : 0.9707112970711297\n",
      "Epoch 131:\t train loss : 0.558509364108215; train accuracy : 0.9927957755416734; \n",
      " validation loss : 0.6055448702182482; validation accuracy : 0.9456066945606695\n",
      "Epoch 132:\t train loss : 0.5609753394366951; train accuracy : 0.9902723132686886; \n",
      " validation loss : 0.6030043655464846; validation accuracy : 0.9456066945606695\n",
      "Epoch 133:\t train loss : 0.555235370012736; train accuracy : 0.9961261141519154; \n",
      " validation loss : 0.5977884215032596; validation accuracy : 0.9539748953974896\n",
      "Epoch 134:\t train loss : 0.5557537148942964; train accuracy : 0.9956008550450758; \n",
      " validation loss : 0.5961603562403597; validation accuracy : 0.9539748953974896\n",
      "Epoch 135:\t train loss : 0.5602021414246056; train accuracy : 0.9909989416868452; \n",
      " validation loss : 0.6054716285022277; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.5573289934593753; train accuracy : 0.9939434307134669; \n",
      " validation loss : 0.6126529385495691; validation accuracy : 0.9330543933054394\n",
      "Epoch 137:\t train loss : 0.5563148807195574; train accuracy : 0.99501083796616; \n",
      " validation loss : 0.613616812930215; validation accuracy : 0.9372384937238494\n",
      "Epoch 138:\t train loss : 0.5554311101048433; train accuracy : 0.995881173118646; \n",
      " validation loss : 0.5812466722109771; validation accuracy : 0.9707112970711297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139:\t train loss : 0.5608284150115388; train accuracy : 0.9904103236999188; \n",
      " validation loss : 0.5891546573351544; validation accuracy : 0.9623430962343096\n",
      "Epoch 140:\t train loss : 0.5583737730342393; train accuracy : 0.9929042051708441; \n",
      " validation loss : 0.5872315815662079; validation accuracy : 0.9623430962343096\n",
      "Epoch 141:\t train loss : 0.5718212996881343; train accuracy : 0.9793659914715349; \n",
      " validation loss : 0.6034561116933167; validation accuracy : 0.9497907949790795\n",
      "Epoch 142:\t train loss : 0.5561590710895961; train accuracy : 0.9952276972245013; \n",
      " validation loss : 0.606364185983903; validation accuracy : 0.9456066945606695\n",
      "Epoch 143:\t train loss : 0.5558380233439951; train accuracy : 0.9955670769670484; \n",
      " validation loss : 0.6140586263352237; validation accuracy : 0.9372384937238494\n",
      "Epoch 144:\t train loss : 0.5567879036024759; train accuracy : 0.9945785185414666; \n",
      " validation loss : 0.6155028953433831; validation accuracy : 0.9330543933054394\n",
      "Epoch 145:\t train loss : 0.568689594174612; train accuracy : 0.9825414306115331; \n",
      " validation loss : 0.6267963690002999; validation accuracy : 0.9246861924686193\n",
      "Epoch 146:\t train loss : 0.5587891470103875; train accuracy : 0.9924535976151477; \n",
      " validation loss : 0.5988171148392593; validation accuracy : 0.9539748953974896\n",
      "Epoch 147:\t train loss : 0.5564574412204656; train accuracy : 0.9948869183899649; \n",
      " validation loss : 0.5993603009826897; validation accuracy : 0.9497907949790795\n",
      "Epoch 148:\t train loss : 0.5561885718740469; train accuracy : 0.995134757542355; \n",
      " validation loss : 0.5868670847839302; validation accuracy : 0.9665271966527197\n",
      "Epoch 149:\t train loss : 0.5578132899129615; train accuracy : 0.9935716719848818; \n",
      " validation loss : 0.6027253300181263; validation accuracy : 0.9456066945606695\n",
      "Epoch 150:\t train loss : 0.5570068916420002; train accuracy : 0.9944025327562411; \n",
      " validation loss : 0.6109079549425145; validation accuracy : 0.9372384937238494\n",
      "Epoch 151:\t train loss : 0.5566925346657414; train accuracy : 0.9946067002515367; \n",
      " validation loss : 0.6102301460954219; validation accuracy : 0.9414225941422594\n",
      "Epoch 152:\t train loss : 0.555220287660573; train accuracy : 0.9961894730320022; \n",
      " validation loss : 0.6000630650523145; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.5618515107877242; train accuracy : 0.9894471488004285; \n",
      " validation loss : 0.6226694061712607; validation accuracy : 0.9288702928870293\n",
      "Epoch 154:\t train loss : 0.559165630588397; train accuracy : 0.9920832379785519; \n",
      " validation loss : 0.6058572181350744; validation accuracy : 0.9456066945606695\n",
      "Epoch 155:\t train loss : 0.5570956387571044; train accuracy : 0.9942828104560141; \n",
      " validation loss : 0.6062911776857353; validation accuracy : 0.9456066945606695\n",
      "Epoch 156:\t train loss : 0.5539830607298474; train accuracy : 0.9974582495960121; \n",
      " validation loss : 0.5943662887713791; validation accuracy : 0.9581589958158996\n",
      "Epoch 157:\t train loss : 0.57760150036023; train accuracy : 0.9733436000035977; \n",
      " validation loss : 0.677881353682966; validation accuracy : 0.8702928870292888\n",
      "Epoch 158:\t train loss : 0.6078905934876006; train accuracy : 0.9427774374430994; \n",
      " validation loss : 0.6310550778509059; validation accuracy : 0.9163179916317992\n",
      "Epoch 159:\t train loss : 0.5726883465042821; train accuracy : 0.9783888256521518; \n",
      " validation loss : 0.6488677755442762; validation accuracy : 0.899581589958159\n",
      "Epoch 160:\t train loss : 0.5655537457642569; train accuracy : 0.9855436821502844; \n",
      " validation loss : 0.5882458797510122; validation accuracy : 0.9623430962343096\n",
      "Epoch 161:\t train loss : 0.5613146520104285; train accuracy : 0.9900287713274085; \n",
      " validation loss : 0.598704371990496; validation accuracy : 0.9497907949790795\n",
      "Epoch 162:\t train loss : 0.5620255955920707; train accuracy : 0.989169728845979; \n",
      " validation loss : 0.6151921482347094; validation accuracy : 0.9372384937238494\n",
      "Epoch 163:\t train loss : 0.5604198930442426; train accuracy : 0.9908398449406335; \n",
      " validation loss : 0.598914593847616; validation accuracy : 0.9539748953974896\n",
      "Epoch 164:\t train loss : 0.558595324638475; train accuracy : 0.9926732550574677; \n",
      " validation loss : 0.6163889112882104; validation accuracy : 0.9330543933054394\n",
      "Epoch 165:\t train loss : 0.558310045905717; train accuracy : 0.9929929475770225; \n",
      " validation loss : 0.6065608577465265; validation accuracy : 0.9456066945606695\n",
      "Epoch 166:\t train loss : 0.5570269803822744; train accuracy : 0.9944222199792334; \n",
      " validation loss : 0.6028370437919424; validation accuracy : 0.9456066945606695\n",
      "Epoch 167:\t train loss : 0.5588680248011891; train accuracy : 0.9923578597490229; \n",
      " validation loss : 0.599379666536557; validation accuracy : 0.9539748953974896\n",
      "Epoch 168:\t train loss : 0.5581638226384639; train accuracy : 0.9931661351782692; \n",
      " validation loss : 0.6026782416010174; validation accuracy : 0.9456066945606695\n",
      "Epoch 169:\t train loss : 0.5584612892788448; train accuracy : 0.9928718261848061; \n",
      " validation loss : 0.6052938704573336; validation accuracy : 0.9456066945606695\n",
      "Epoch 170:\t train loss : 0.5580801010909886; train accuracy : 0.9931999132562966; \n",
      " validation loss : 0.6099181065346502; validation accuracy : 0.9414225941422594\n",
      "Epoch 171:\t train loss : 0.5563221418181576; train accuracy : 0.9950882877012819; \n",
      " validation loss : 0.5933332407514978; validation accuracy : 0.9581589958158996\n",
      "Epoch 172:\t train loss : 0.5565253048475173; train accuracy : 0.9948517412199482; \n",
      " validation loss : 0.5983203578586032; validation accuracy : 0.9497907949790795\n",
      "Epoch 173:\t train loss : 0.5579398603747613; train accuracy : 0.9933337264115589; \n",
      " validation loss : 0.5939384859168678; validation accuracy : 0.9581589958158996\n",
      "Epoch 174:\t train loss : 0.5582390271435218; train accuracy : 0.9930844881671795; \n",
      " validation loss : 0.6146251556367925; validation accuracy : 0.9330543933054394\n",
      "Epoch 175:\t train loss : 0.5616784780762731; train accuracy : 0.9896766998218156; \n",
      " validation loss : 0.6196445771861692; validation accuracy : 0.9288702928870293\n",
      "Epoch 176:\t train loss : 0.5602077834615808; train accuracy : 0.9911693311041134; \n",
      " validation loss : 0.6017456093968614; validation accuracy : 0.9497907949790795\n",
      "Epoch 177:\t train loss : 0.5594999239147153; train accuracy : 0.9918508887731862; \n",
      " validation loss : 0.5941539640268739; validation accuracy : 0.9581589958158996\n",
      "Epoch 178:\t train loss : 0.5579187974785687; train accuracy : 0.9934125752386701; \n",
      " validation loss : 0.6078562359756445; validation accuracy : 0.9414225941422594\n",
      "Epoch 179:\t train loss : 0.5565130001661259; train accuracy : 0.9949643681250868; \n",
      " validation loss : 0.6187531355328255; validation accuracy : 0.9330543933054394\n",
      "Epoch 180:\t train loss : 0.5579340190068238; train accuracy : 0.9933393227795161; \n",
      " validation loss : 0.6046438020118285; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 180\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.556007159716319; Train accuracy : 0.9953643085637421; \n",
      " Validation loss : 0.5811522771981456; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 53 ! ---\n",
      "Epoch 1:\t train loss : 0.9557304828555577; train accuracy : 0.5667576442888566; \n",
      " validation loss : 0.8444224326700264; validation accuracy : 0.694560669456067\n",
      "Epoch 2:\t train loss : 0.7557430530602413; train accuracy : 0.7940230490411723; \n",
      " validation loss : 0.7221216022231769; validation accuracy : 0.8284518828451883\n",
      "Epoch 3:\t train loss : 0.6846825896379124; train accuracy : 0.8656287369497196; \n",
      " validation loss : 0.6886581454921816; validation accuracy : 0.8493723849372385\n",
      "Epoch 4:\t train loss : 0.6543901003230576; train accuracy : 0.8962492642275164; \n",
      " validation loss : 0.6810525149339379; validation accuracy : 0.8702928870292888\n",
      "Epoch 5:\t train loss : 0.6411619244589105; train accuracy : 0.9096251432820099; \n",
      " validation loss : 0.6330467498804968; validation accuracy : 0.9205020920502092\n",
      "Epoch 6:\t train loss : 0.6272586400304406; train accuracy : 0.9236745252331237; \n",
      " validation loss : 0.6486303726750643; validation accuracy : 0.9037656903765691\n",
      "Epoch 7:\t train loss : 0.6111961963244134; train accuracy : 0.9404634592149694; \n",
      " validation loss : 0.6027824793616564; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\t train loss : 0.6097374255960917; train accuracy : 0.941515226617925; \n",
      " validation loss : 0.6123485978588283; validation accuracy : 0.9372384937238494\n",
      "Epoch 9:\t train loss : 0.5962341422066612; train accuracy : 0.9550534403172342; \n",
      " validation loss : 0.6151430803175821; validation accuracy : 0.9330543933054394\n",
      "Epoch 10:\t train loss : 0.5924658987344749; train accuracy : 0.9590151491681899; \n",
      " validation loss : 0.6011864591237313; validation accuracy : 0.9497907949790795\n",
      "Epoch 11:\t train loss : 0.5946119662248387; train accuracy : 0.9568443879921931; \n",
      " validation loss : 0.6000953589286658; validation accuracy : 0.9497907949790795\n",
      "Epoch 12:\t train loss : 0.5977408623189753; train accuracy : 0.9533628674989931; \n",
      " validation loss : 0.6472835152950677; validation accuracy : 0.899581589958159\n",
      "Epoch 13:\t train loss : 0.6107310590189313; train accuracy : 0.9401056414387062; \n",
      " validation loss : 0.5848549396094206; validation accuracy : 0.9665271966527197\n",
      "Epoch 14:\t train loss : 0.5964286561276361; train accuracy : 0.9540524799405186; \n",
      " validation loss : 0.6137102519411449; validation accuracy : 0.9372384937238494\n",
      "Epoch 15:\t train loss : 0.5835127723420105; train accuracy : 0.9679816599027231; \n",
      " validation loss : 0.617217824548057; validation accuracy : 0.9330543933054394\n",
      "Epoch 16:\t train loss : 0.58670353869576; train accuracy : 0.9641150593264971; \n",
      " validation loss : 0.6008196776382799; validation accuracy : 0.9497907949790795\n",
      "Epoch 17:\t train loss : 0.5813412504512142; train accuracy : 0.9699237894606401; \n",
      " validation loss : 0.6026591205283549; validation accuracy : 0.9497907949790795\n",
      "Epoch 18:\t train loss : 0.5773095776320822; train accuracy : 0.9738486322376777; \n",
      " validation loss : 0.6204155027114131; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5868588315036827; train accuracy : 0.9641172279190805; \n",
      " validation loss : 0.6153347302405253; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.578051769452669; train accuracy : 0.9732445243037269; \n",
      " validation loss : 0.6172903065692784; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5764255829484707; train accuracy : 0.9747817466464265; \n",
      " validation loss : 0.6010448986559973; validation accuracy : 0.9497907949790795\n",
      "Epoch 22:\t train loss : 0.5739900307898305; train accuracy : 0.9774924873756932; \n",
      " validation loss : 0.6374532937719566; validation accuracy : 0.9037656903765691\n",
      "Epoch 23:\t train loss : 0.6202600437775788; train accuracy : 0.9300077449735122; \n",
      " validation loss : 0.6501498144481497; validation accuracy : 0.899581589958159\n",
      "Epoch 24:\t train loss : 0.5963259824847591; train accuracy : 0.9544824808699154; \n",
      " validation loss : 0.6096552675086568; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.579832792070963; train accuracy : 0.9713141671055485; \n",
      " validation loss : 0.6020624884396812; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5772595869505925; train accuracy : 0.9738058799838905; \n",
      " validation loss : 0.6125981823849826; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5738568119947014; train accuracy : 0.9772313268688622; \n",
      " validation loss : 0.5889217035504172; validation accuracy : 0.9623430962343096\n",
      "Epoch 28:\t train loss : 0.5712018979954283; train accuracy : 0.9799281266458069; \n",
      " validation loss : 0.6040660762091924; validation accuracy : 0.9456066945606695\n",
      "Epoch 29:\t train loss : 0.5807308399515065; train accuracy : 0.9704467300721832; \n",
      " validation loss : 0.6127244989332644; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5849774002547516; train accuracy : 0.9658985718268843; \n",
      " validation loss : 0.5936019127741503; validation accuracy : 0.9539748953974896\n",
      "Epoch 31:\t train loss : 0.567676436223081; train accuracy : 0.9836729762384213; \n",
      " validation loss : 0.5983127696911051; validation accuracy : 0.9539748953974896\n",
      "Epoch 32:\t train loss : 0.5669044201384965; train accuracy : 0.9844710183091174; \n",
      " validation loss : 0.5881482931739066; validation accuracy : 0.9623430962343096\n",
      "Epoch 33:\t train loss : 0.5738192621591512; train accuracy : 0.9774054338734162; \n",
      " validation loss : 0.6129451020726363; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.5701078875961353; train accuracy : 0.9812859754019642; \n",
      " validation loss : 0.6207633900952056; validation accuracy : 0.9288702928870293\n",
      "Epoch 35:\t train loss : 0.5680723960922611; train accuracy : 0.9830496607701602; \n",
      " validation loss : 0.5922036889101142; validation accuracy : 0.9581589958158996\n",
      "Epoch 36:\t train loss : 0.5715821814715489; train accuracy : 0.9795371603829115; \n",
      " validation loss : 0.6363485938123916; validation accuracy : 0.9163179916317992\n",
      "Epoch 37:\t train loss : 0.5693180168988848; train accuracy : 0.9818532172619969; \n",
      " validation loss : 0.607405216607101; validation accuracy : 0.9456066945606695\n",
      "Epoch 38:\t train loss : 0.5673350561742455; train accuracy : 0.9838802317296075; \n",
      " validation loss : 0.6158515090211281; validation accuracy : 0.9330543933054394\n",
      "Epoch 39:\t train loss : 0.5705237600943972; train accuracy : 0.9806834164627157; \n",
      " validation loss : 0.6218652074553904; validation accuracy : 0.9330543933054394\n",
      "Epoch 40:\t train loss : 0.5715495152012293; train accuracy : 0.9796654171442734; \n",
      " validation loss : 0.6075263958000959; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5678596191593277; train accuracy : 0.9834369094457697; \n",
      " validation loss : 0.5991695881003603; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5678745930883099; train accuracy : 0.9832724062083708; \n",
      " validation loss : 0.6105777409235802; validation accuracy : 0.9414225941422594\n",
      "Epoch 43:\t train loss : 0.5700417625627329; train accuracy : 0.9813206728832987; \n",
      " validation loss : 0.5762140131989796; validation accuracy : 0.9748953974895398\n",
      "Epoch 44:\t train loss : 0.5704522760391432; train accuracy : 0.9806818674680132; \n",
      " validation loss : 0.6108066498895394; validation accuracy : 0.9414225941422594\n",
      "Epoch 45:\t train loss : 0.568458178840123; train accuracy : 0.9826373183803712; \n",
      " validation loss : 0.622024371319489; validation accuracy : 0.9288702928870293\n",
      "Epoch 46:\t train loss : 0.570430433112598; train accuracy : 0.9806663775209888; \n",
      " validation loss : 0.5953292583532545; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5677565162156464; train accuracy : 0.9835047554137365; \n",
      " validation loss : 0.6142729864813619; validation accuracy : 0.9372384937238494\n",
      "Epoch 48:\t train loss : 0.5756736433401769; train accuracy : 0.9753666470460671; \n",
      " validation loss : 0.5886254387237554; validation accuracy : 0.9623430962343096\n",
      "Epoch 49:\t train loss : 0.5710305952377458; train accuracy : 0.9801589268564701; \n",
      " validation loss : 0.5787995526032604; validation accuracy : 0.9748953974895398\n",
      "Epoch 50:\t train loss : 0.5737792815901823; train accuracy : 0.9774481861272034; \n",
      " validation loss : 0.6091406515774677; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5662610753312514; train accuracy : 0.9851231450788438; \n",
      " validation loss : 0.6085613246557944; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5681999128350518; train accuracy : 0.9830614331298987; \n",
      " validation loss : 0.607411409952383; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.5638880415043285; train accuracy : 0.9874295981907741; \n",
      " validation loss : 0.6038220833922368; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.5774047372814466; train accuracy : 0.9735911893181325; \n",
      " validation loss : 0.6091793395858801; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5648272688054641; train accuracy : 0.9865194089036216; \n",
      " validation loss : 0.5948039489809916; validation accuracy : 0.9581589958158996\n",
      "Epoch 56:\t train loss : 0.58722328524651; train accuracy : 0.9634025217633756; \n",
      " validation loss : 0.6133138966035359; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.5649139819804605; train accuracy : 0.9865039189565972; \n",
      " validation loss : 0.6106167660231262; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5685323183954405; train accuracy : 0.9826933919885994; \n",
      " validation loss : 0.619508918451359; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59:\t train loss : 0.5628895068654769; train accuracy : 0.9885485919638155; \n",
      " validation loss : 0.5743933713740949; validation accuracy : 0.9790794979079498\n",
      "Epoch 60:\t train loss : 0.5634090629606564; train accuracy : 0.9877313423588091; \n",
      " validation loss : 0.6123446922305261; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5639982451374442; train accuracy : 0.9875129341057653; \n",
      " validation loss : 0.6094306458900959; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.56608661851759; train accuracy : 0.9850537501161746; \n",
      " validation loss : 0.8005709162780327; validation accuracy : 0.7447698744769874\n",
      "Epoch 63:\t train loss : 0.7089567517028712; train accuracy : 0.8393915548808824; \n",
      " validation loss : 0.6798839393371587; validation accuracy : 0.8744769874476988\n",
      "Epoch 64:\t train loss : 0.5926781831901486; train accuracy : 0.9580296787384988; \n",
      " validation loss : 0.5947120156018381; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.5791360149069894; train accuracy : 0.9721388518851265; \n",
      " validation loss : 0.6013496101834771; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5716188560706993; train accuracy : 0.979562254097091; \n",
      " validation loss : 0.6007795507277268; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.5698016271436035; train accuracy : 0.9814483100467797; \n",
      " validation loss : 0.6106832490359818; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5697672263427301; train accuracy : 0.9816673378977044; \n",
      " validation loss : 0.596218275528704; validation accuracy : 0.9497907949790795\n",
      "Epoch 69:\t train loss : 0.5691251544734689; train accuracy : 0.9820059481396574; \n",
      " validation loss : 0.590188948680975; validation accuracy : 0.9581589958158996\n",
      "Epoch 70:\t train loss : 0.5674297160482602; train accuracy : 0.9836943523653149; \n",
      " validation loss : 0.623464231050687; validation accuracy : 0.9288702928870293\n",
      "Epoch 71:\t train loss : 0.5884382655625973; train accuracy : 0.9623978437993742; \n",
      " validation loss : 0.5912194489131195; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5643031986992055; train accuracy : 0.9869648997800428; \n",
      " validation loss : 0.626115015883909; validation accuracy : 0.9246861924686193\n",
      "Epoch 73:\t train loss : 0.5692132278530132; train accuracy : 0.9818841971560457; \n",
      " validation loss : 0.6136770727405108; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5685847539500442; train accuracy : 0.9826218284333468; \n",
      " validation loss : 0.5975969162297335; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.5673657538701927; train accuracy : 0.9837894606400446; \n",
      " validation loss : 0.5919789261155993; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5676432386084406; train accuracy : 0.9837584807459958; \n",
      " validation loss : 0.5841544298944927; validation accuracy : 0.9665271966527197\n",
      "Epoch 77:\t train loss : 0.5632461504266777; train accuracy : 0.9879931224635212; \n",
      " validation loss : 0.5978007797060043; validation accuracy : 0.9539748953974896\n",
      "Epoch 78:\t train loss : 0.5620859736952055; train accuracy : 0.9890891911149664; \n",
      " validation loss : 0.5942570313364121; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5630254879810669; train accuracy : 0.9883397874779268; \n",
      " validation loss : 0.5967704306292408; validation accuracy : 0.9539748953974896\n",
      "Epoch 80:\t train loss : 0.5606235150030143; train accuracy : 0.9906205272777967; \n",
      " validation loss : 0.5954055409065604; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.5607649550238826; train accuracy : 0.9906285820502494; \n",
      " validation loss : 0.5847524536533737; validation accuracy : 0.9665271966527197\n",
      "Epoch 82:\t train loss : 0.5620599301257114; train accuracy : 0.9892168282784473; \n",
      " validation loss : 0.5904323659435431; validation accuracy : 0.9623430962343096\n",
      "Epoch 83:\t train loss : 0.5653199577612534; train accuracy : 0.9860280677840082; \n",
      " validation loss : 0.6135069829673823; validation accuracy : 0.9330543933054394\n",
      "Epoch 84:\t train loss : 0.5627112222898704; train accuracy : 0.9887388085132749; \n",
      " validation loss : 0.5969325357285618; validation accuracy : 0.9539748953974896\n",
      "Epoch 85:\t train loss : 0.5634300932420345; train accuracy : 0.9877629418507389; \n",
      " validation loss : 0.6002451801963239; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5615770553945232; train accuracy : 0.9895848694197465; \n",
      " validation loss : 0.6134040493206571; validation accuracy : 0.9372384937238494\n",
      "Epoch 87:\t train loss : 0.5643802973266568; train accuracy : 0.9868564701508721; \n",
      " validation loss : 0.6025118872836396; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5652108882825; train accuracy : 0.9860162954242696; \n",
      " validation loss : 0.5868798347144053; validation accuracy : 0.9665271966527197\n",
      "Epoch 89:\t train loss : 0.570033212993836; train accuracy : 0.9811716595929242; \n",
      " validation loss : 0.6065603443162373; validation accuracy : 0.9456066945606695\n",
      "Epoch 90:\t train loss : 0.5631668215197494; train accuracy : 0.9879680287493416; \n",
      " validation loss : 0.6150203698356369; validation accuracy : 0.9330543933054394\n",
      "Epoch 91:\t train loss : 0.5686128171017945; train accuracy : 0.9824322314817683; \n",
      " validation loss : 0.6018329127192441; validation accuracy : 0.9497907949790795\n",
      "Epoch 92:\t train loss : 0.5626688086731427; train accuracy : 0.9885993989900554; \n",
      " validation loss : 0.5876083363583992; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5622859061895339; train accuracy : 0.9889401778245919; \n",
      " validation loss : 0.5978860767388888; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5631256361115868; train accuracy : 0.9882313578487562; \n",
      " validation loss : 0.5853786165814298; validation accuracy : 0.9665271966527197\n",
      "Epoch 95:\t train loss : 0.5645980954330297; train accuracy : 0.9866107995910653; \n",
      " validation loss : 0.5897894280845402; validation accuracy : 0.9623430962343096\n",
      "Epoch 96:\t train loss : 0.5622109498369972; train accuracy : 0.9889956318349391; \n",
      " validation loss : 0.6117929653943646; validation accuracy : 0.9414225941422594\n",
      "Epoch 97:\t train loss : 0.5718539526611207; train accuracy : 0.9793357910715945; \n",
      " validation loss : 0.6319926249513343; validation accuracy : 0.9246861924686193\n",
      "Epoch 98:\t train loss : 0.5761915228186932; train accuracy : 0.9748517612069767; \n",
      " validation loss : 0.5975469946122415; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5622214040530458; train accuracy : 0.9890486074537626; \n",
      " validation loss : 0.6020308914597728; validation accuracy : 0.9497907949790795\n",
      "Epoch 100:\t train loss : 0.5633967383531748; train accuracy : 0.987782149385049; \n",
      " validation loss : 0.6021925183167677; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.5627882113182596; train accuracy : 0.9884754794138604; \n",
      " validation loss : 0.5849842270150912; validation accuracy : 0.9665271966527197\n",
      "Epoch 102:\t train loss : 0.5605856804966916; train accuracy : 0.9907407292667059; \n",
      " validation loss : 0.5885670346643447; validation accuracy : 0.9665271966527197\n",
      "Epoch 103:\t train loss : 0.5604068568821484; train accuracy : 0.9908336689488522; \n",
      " validation loss : 0.6055998502674371; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.5598373230751427; train accuracy : 0.9914901329037454; \n",
      " validation loss : 0.6061614981478795; validation accuracy : 0.9456066945606695\n",
      "Epoch 105:\t train loss : 0.5595190032353109; train accuracy : 0.9918250255584126; \n",
      " validation loss : 0.5912195958328375; validation accuracy : 0.9581589958158996\n",
      "Epoch 106:\t train loss : 0.5628430240948414; train accuracy : 0.9884674246414077; \n",
      " validation loss : 0.5889318376378797; validation accuracy : 0.9623430962343096\n",
      "Epoch 107:\t train loss : 0.5627365086714443; train accuracy : 0.9885507605563989; \n",
      " validation loss : 0.5931414818251783; validation accuracy : 0.9581589958158996\n",
      "Epoch 108:\t train loss : 0.5646487221392722; train accuracy : 0.9865525573902537; \n",
      " validation loss : 0.618006366232953; validation accuracy : 0.9330543933054394\n",
      "Epoch 109:\t train loss : 0.5616869001838932; train accuracy : 0.9896623191548685; \n",
      " validation loss : 0.5888049679889398; validation accuracy : 0.9623430962343096\n",
      "Early stopping at epoch 109\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5628895068654769; Train accuracy : 0.9885485919638155; \n",
      " Validation loss : 0.5743933713740949; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 54 ! ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t train loss : 0.936140201880452; train accuracy : 0.5845162489544286; \n",
      " validation loss : 0.8343589393335111; validation accuracy : 0.694560669456067\n",
      "Epoch 2:\t train loss : 0.7540128811474829; train accuracy : 0.7940115864803743; \n",
      " validation loss : 0.7652939981864175; validation accuracy : 0.7698744769874477\n",
      "Epoch 3:\t train loss : 0.7008646161042752; train accuracy : 0.8499364912172; \n",
      " validation loss : 0.7105045165650984; validation accuracy : 0.8451882845188284\n",
      "Epoch 4:\t train loss : 0.6707944817260882; train accuracy : 0.8800582422008116; \n",
      " validation loss : 0.6650079538705085; validation accuracy : 0.891213389121339\n",
      "Epoch 5:\t train loss : 0.655298467031534; train accuracy : 0.8955419932463831; \n",
      " validation loss : 0.6734459338527519; validation accuracy : 0.8744769874476988\n",
      "Epoch 6:\t train loss : 0.6369515212942198; train accuracy : 0.9140029121100406; \n",
      " validation loss : 0.6339086173486099; validation accuracy : 0.9121338912133892\n",
      "Epoch 7:\t train loss : 0.6259334663690503; train accuracy : 0.9251092041265219; \n",
      " validation loss : 0.61312908342604; validation accuracy : 0.9414225941422594\n",
      "Epoch 8:\t train loss : 0.6171669471965006; train accuracy : 0.9342049010192385; \n",
      " validation loss : 0.6214373855278651; validation accuracy : 0.9330543933054394\n",
      "Epoch 9:\t train loss : 0.6100853734950696; train accuracy : 0.9411320053285418; \n",
      " validation loss : 0.6229366204357674; validation accuracy : 0.9288702928870293\n",
      "Epoch 10:\t train loss : 0.6013281774416512; train accuracy : 0.9502958579881656; \n",
      " validation loss : 0.6316290876843081; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.5931235891369633; train accuracy : 0.9582050249388147; \n",
      " validation loss : 0.6410363723031767; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.5945529672204661; train accuracy : 0.9564329749992255; \n",
      " validation loss : 0.6342807195036789; validation accuracy : 0.9163179916317992\n",
      "Epoch 13:\t train loss : 0.5895906312636076; train accuracy : 0.9617181449239444; \n",
      " validation loss : 0.6005852508307441; validation accuracy : 0.9456066945606695\n",
      "Epoch 14:\t train loss : 0.5816518115663302; train accuracy : 0.970036246476037; \n",
      " validation loss : 0.6140750813739154; validation accuracy : 0.9330543933054394\n",
      "Epoch 15:\t train loss : 0.5917128512416897; train accuracy : 0.9593946528702871; \n",
      " validation loss : 0.6318780517268238; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.582797713260908; train accuracy : 0.968660739180272; \n",
      " validation loss : 0.5990682460666887; validation accuracy : 0.9497907949790795\n",
      "Epoch 17:\t train loss : 0.5782054138848819; train accuracy : 0.9732457634994889; \n",
      " validation loss : 0.5944784825979398; validation accuracy : 0.9581589958158996\n",
      "Epoch 18:\t train loss : 0.5797646446862023; train accuracy : 0.9716812788500263; \n",
      " validation loss : 0.6101279697991939; validation accuracy : 0.9414225941422594\n",
      "Epoch 19:\t train loss : 0.588599741635582; train accuracy : 0.9624182905294464; \n",
      " validation loss : 0.6023140894374615; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5821035954288387; train accuracy : 0.9690479878558815; \n",
      " validation loss : 0.6134777659609714; validation accuracy : 0.9372384937238494\n",
      "Epoch 21:\t train loss : 0.5749776335307265; train accuracy : 0.9763189689891261; \n",
      " validation loss : 0.6076207676579743; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5724544501767391; train accuracy : 0.978623873106354; \n",
      " validation loss : 0.5965445701927047; validation accuracy : 0.9581589958158996\n",
      "Epoch 23:\t train loss : 0.5700461754085812; train accuracy : 0.9813315158462158; \n",
      " validation loss : 0.6016197343304445; validation accuracy : 0.9497907949790795\n",
      "Epoch 24:\t train loss : 0.5667272994592489; train accuracy : 0.9845689147743115; \n",
      " validation loss : 0.598507140647357; validation accuracy : 0.9539748953974896\n",
      "Epoch 25:\t train loss : 0.5720249392901274; train accuracy : 0.9792868428389975; \n",
      " validation loss : 0.5960086281087327; validation accuracy : 0.9539748953974896\n",
      "Epoch 26:\t train loss : 0.583951713542555; train accuracy : 0.9671860962235509; \n",
      " validation loss : 0.6340016176365456; validation accuracy : 0.9163179916317992\n",
      "Epoch 27:\t train loss : 0.5802122385243017; train accuracy : 0.9707921558908269; \n",
      " validation loss : 0.615597469841396; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5676987833636931; train accuracy : 0.9835217943554633; \n",
      " validation loss : 0.5985737896943173; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5669731345359216; train accuracy : 0.9842033520245361; \n",
      " validation loss : 0.5952379344066264; validation accuracy : 0.9581589958158996\n",
      "Epoch 30:\t train loss : 0.5665338391399583; train accuracy : 0.9848167539267015; \n",
      " validation loss : 0.6064906936343325; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5655706660184658; train accuracy : 0.9858483843985254; \n",
      " validation loss : 0.6041867558574613; validation accuracy : 0.9456066945606695\n",
      "Epoch 32:\t train loss : 0.5875086129639445; train accuracy : 0.9632919235416215; \n",
      " validation loss : 0.5982023242202903; validation accuracy : 0.9539748953974896\n",
      "Epoch 33:\t train loss : 0.5683168967710162; train accuracy : 0.9829455683261563; \n",
      " validation loss : 0.5977587593061877; validation accuracy : 0.9539748953974896\n",
      "Epoch 34:\t train loss : 0.5623874740957621; train accuracy : 0.9891446451253136; \n",
      " validation loss : 0.6090344696539276; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5710142603708119; train accuracy : 0.9800954180736702; \n",
      " validation loss : 0.5930421926242542; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5626661079275305; train accuracy : 0.9887759843861333; \n",
      " validation loss : 0.6048351350570743; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.5630899285242816; train accuracy : 0.9882555221661142; \n",
      " validation loss : 0.6157741848310956; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5662851125625908; train accuracy : 0.9847269122339601; \n",
      " validation loss : 0.5909419662512414; validation accuracy : 0.9581589958158996\n",
      "Epoch 39:\t train loss : 0.5769128408571865; train accuracy : 0.9741503764057127; \n",
      " validation loss : 0.6096080090738545; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.5717659485036084; train accuracy : 0.979274450881378; \n",
      " validation loss : 0.5985238521850182; validation accuracy : 0.9497907949790795\n",
      "Epoch 41:\t train loss : 0.5648578175029917; train accuracy : 0.9863936305337836; \n",
      " validation loss : 0.6174539987914935; validation accuracy : 0.9246861924686193\n",
      "Epoch 42:\t train loss : 0.5674158929830643; train accuracy : 0.9837696335078534; \n",
      " validation loss : 0.6042648971601636; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5608864953937407; train accuracy : 0.9904581926329812; \n",
      " validation loss : 0.6137073498904543; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5664481326934585; train accuracy : 0.9847393041915796; \n",
      " validation loss : 0.6104064587557719; validation accuracy : 0.9414225941422594\n",
      "Epoch 45:\t train loss : 0.5638784184354823; train accuracy : 0.9872176957154807; \n",
      " validation loss : 0.617201163184158; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.565928579910162; train accuracy : 0.9852225905387404; \n",
      " validation loss : 0.5975369972776815; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5621107430691618; train accuracy : 0.9892251928498405; \n",
      " validation loss : 0.6092875033651965; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.571765923038495; train accuracy : 0.9792558629449487; \n",
      " validation loss : 0.5900816131442441; validation accuracy : 0.9623430962343096\n",
      "Epoch 49:\t train loss : 0.5643416430558394; train accuracy : 0.9869729545524955; \n",
      " validation loss : 0.613038867234272; validation accuracy : 0.9372384937238494\n",
      "Epoch 50:\t train loss : 0.5648663029913562; train accuracy : 0.9862635149787787; \n",
      " validation loss : 0.5996906085519154; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5848854035360662; train accuracy : 0.9658632547476688; \n",
      " validation loss : 0.6411794516587057; validation accuracy : 0.9037656903765691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:\t train loss : 0.5893281253125636; train accuracy : 0.9613185042907153; \n",
      " validation loss : 0.6066773597363371; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5677841489978591; train accuracy : 0.9833854828216487; \n",
      " validation loss : 0.5934637666926436; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5613215766301145; train accuracy : 0.9900771399361814; \n",
      " validation loss : 0.6052460856268373; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5624323957178641; train accuracy : 0.9886985346510115; \n",
      " validation loss : 0.5991332085320912; validation accuracy : 0.9497907949790795\n",
      "Epoch 56:\t train loss : 0.5638644784441664; train accuracy : 0.987409771058583; \n",
      " validation loss : 0.6145152636624251; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.5699941322339804; train accuracy : 0.9812014002912111; \n",
      " validation loss : 0.6142297652007936; validation accuracy : 0.9372384937238494\n",
      "Epoch 58:\t train loss : 0.5608028856985897; train accuracy : 0.9904581926329812; \n",
      " validation loss : 0.616127792175803; validation accuracy : 0.9330543933054394\n",
      "Epoch 59:\t train loss : 0.5625524955449913; train accuracy : 0.9886675547569628; \n",
      " validation loss : 0.6174663528790899; validation accuracy : 0.9330543933054394\n",
      "Epoch 60:\t train loss : 0.563652640232458; train accuracy : 0.987608042380495; \n",
      " validation loss : 0.6121444814000153; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5588442549578253; train accuracy : 0.9923944360110288; \n",
      " validation loss : 0.5969382615853142; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5603167869062705; train accuracy : 0.9911862201431271; \n",
      " validation loss : 0.6073609127834348; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5635229240761539; train accuracy : 0.9878249016388364; \n",
      " validation loss : 0.6538632587688098; validation accuracy : 0.895397489539749\n",
      "Epoch 64:\t train loss : 0.5680785776003283; train accuracy : 0.982926980389727; \n",
      " validation loss : 0.6425204145266268; validation accuracy : 0.9037656903765691\n",
      "Epoch 65:\t train loss : 0.5684006772763872; train accuracy : 0.982728709067815; \n",
      " validation loss : 0.6061584894252434; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5653757490766288; train accuracy : 0.9858607763561449; \n",
      " validation loss : 0.6070719373505271; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5690097201560705; train accuracy : 0.9820347594411227; \n",
      " validation loss : 0.5843370581014229; validation accuracy : 0.9665271966527197\n",
      "Epoch 68:\t train loss : 0.5618148228937145; train accuracy : 0.9894079742247281; \n",
      " validation loss : 0.6064721703754649; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5585669866497956; train accuracy : 0.9928281545277116; \n",
      " validation loss : 0.602859762341614; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5612659579750543; train accuracy : 0.9898974565506986; \n",
      " validation loss : 0.6021317716003641; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5605422350829397; train accuracy : 0.9906037981350103; \n",
      " validation loss : 0.6057651691098533; validation accuracy : 0.9456066945606695\n",
      "Epoch 72:\t train loss : 0.5601475932195634; train accuracy : 0.9910313206728832; \n",
      " validation loss : 0.5879481463514388; validation accuracy : 0.9623430962343096\n",
      "Epoch 73:\t train loss : 0.5562749551202153; train accuracy : 0.995043216952198; \n",
      " validation loss : 0.6142151740954132; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5585770145746951; train accuracy : 0.9928436444747358; \n",
      " validation loss : 0.6053967415778001; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5581250863778108; train accuracy : 0.9930790916695065; \n",
      " validation loss : 0.6099416861625148; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.560858334231279; train accuracy : 0.9904086248025031; \n",
      " validation loss : 0.5937586679366896; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5588756607028393; train accuracy : 0.9924780817249605; \n",
      " validation loss : 0.6076731189518939; validation accuracy : 0.9456066945606695\n",
      "Epoch 78:\t train loss : 0.556175886032518; train accuracy : 0.9952600762105394; \n",
      " validation loss : 0.599538346873276; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5573264516527444; train accuracy : 0.9941200161095449; \n",
      " validation loss : 0.5992476730151342; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5610685928239147; train accuracy : 0.9901545896713033; \n",
      " validation loss : 0.5971859233911482; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.5840049307741908; train accuracy : 0.9667306917810341; \n",
      " validation loss : 0.6062103116941905; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5652885243561333; train accuracy : 0.985907246197218; \n",
      " validation loss : 0.6013610761357335; validation accuracy : 0.9497907949790795\n",
      "Epoch 83:\t train loss : 0.5617129800423157; train accuracy : 0.98961244152545; \n",
      " validation loss : 0.6034421284415947; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5599648984693848; train accuracy : 0.9912512779206295; \n",
      " validation loss : 0.6134307610656634; validation accuracy : 0.9372384937238494\n",
      "Epoch 85:\t train loss : 0.5571980511640772; train accuracy : 0.9941107221413302; \n",
      " validation loss : 0.6096946792489351; validation accuracy : 0.9456066945606695\n",
      "Epoch 86:\t train loss : 0.5610539664799201; train accuracy : 0.9901236097772546; \n",
      " validation loss : 0.5924778287487678; validation accuracy : 0.9581589958158996\n",
      "Epoch 87:\t train loss : 0.5574488663071036; train accuracy : 0.9938721769571548; \n",
      " validation loss : 0.5965732017597253; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5570352926506648; train accuracy : 0.9943151894420521; \n",
      " validation loss : 0.590640918548107; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5553966918859059; train accuracy : 0.9959323399113975; \n",
      " validation loss : 0.6128717972304737; validation accuracy : 0.9372384937238494\n",
      "Epoch 90:\t train loss : 0.5564380016101468; train accuracy : 0.9948294556832615; \n",
      " validation loss : 0.5976453933377485; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.556217730400658; train accuracy : 0.9952105083800613; \n",
      " validation loss : 0.6163152912178161; validation accuracy : 0.9330543933054394\n",
      "Epoch 92:\t train loss : 0.5613181421803912; train accuracy : 0.9898107128473621; \n",
      " validation loss : 0.5944830050874473; validation accuracy : 0.9581589958158996\n",
      "Epoch 93:\t train loss : 0.5572967223739125; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.5936556139681888; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5590706875591028; train accuracy : 0.9922302425725704; \n",
      " validation loss : 0.5868633840342752; validation accuracy : 0.9665271966527197\n",
      "Epoch 95:\t train loss : 0.5569562669027556; train accuracy : 0.9944824808699154; \n",
      " validation loss : 0.5850545089732572; validation accuracy : 0.9665271966527197\n",
      "Epoch 96:\t train loss : 0.5596642622785893; train accuracy : 0.9915455869140928; \n",
      " validation loss : 0.5930281702027411; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5605088065624902; train accuracy : 0.9906037981350103; \n",
      " validation loss : 0.6093560709548888; validation accuracy : 0.9414225941422594\n",
      "Epoch 98:\t train loss : 0.5604215149291626; train accuracy : 0.9908206573933517; \n",
      " validation loss : 0.5905796264967731; validation accuracy : 0.9623430962343096\n",
      "Epoch 99:\t train loss : 0.5560450609268495; train accuracy : 0.9952569782211345; \n",
      " validation loss : 0.5952451957055978; validation accuracy : 0.9539748953974896\n",
      "Epoch 100:\t train loss : 0.5573296389964508; train accuracy : 0.9938876669041792; \n",
      " validation loss : 0.5863274655946553; validation accuracy : 0.9665271966527197\n",
      "Epoch 101:\t train loss : 0.5684289173289989; train accuracy : 0.982703925152576; \n",
      " validation loss : 0.5762071856917883; validation accuracy : 0.9707112970711297\n",
      "Epoch 102:\t train loss : 0.5615163562632556; train accuracy : 0.9897673409956937; \n",
      " validation loss : 0.6053414573216829; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103:\t train loss : 0.5583454870356519; train accuracy : 0.9930605037330772; \n",
      " validation loss : 0.5930900106801279; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.5572421501684797; train accuracy : 0.994067350289662; \n",
      " validation loss : 0.6129106692844805; validation accuracy : 0.9372384937238494\n",
      "Epoch 105:\t train loss : 0.5572493218173384; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.6063173730089426; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.5556212721506734; train accuracy : 0.9956752067907928; \n",
      " validation loss : 0.5893608706854472; validation accuracy : 0.9623430962343096\n",
      "Epoch 107:\t train loss : 0.5578876742375534; train accuracy : 0.9934973202391648; \n",
      " validation loss : 0.6023221202976863; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.5626470112748697; train accuracy : 0.988587007032436; \n",
      " validation loss : 0.5828100950007475; validation accuracy : 0.9707112970711297\n",
      "Epoch 109:\t train loss : 0.557809104797554; train accuracy : 0.9934942222497599; \n",
      " validation loss : 0.5985710434949774; validation accuracy : 0.9539748953974896\n",
      "Epoch 110:\t train loss : 0.5545177528013003; train accuracy : 0.996871030701075; \n",
      " validation loss : 0.5793885911615024; validation accuracy : 0.9707112970711297\n",
      "Epoch 111:\t train loss : 0.5552678809502408; train accuracy : 0.9961553951485486; \n",
      " validation loss : 0.5822551555720186; validation accuracy : 0.9707112970711297\n",
      "Epoch 112:\t train loss : 0.557231382093004; train accuracy : 0.9941262120883546; \n",
      " validation loss : 0.5896325599904179; validation accuracy : 0.9581589958158996\n",
      "Epoch 113:\t train loss : 0.5820036967386363; train accuracy : 0.9688652064809938; \n",
      " validation loss : 0.621885218938207; validation accuracy : 0.9246861924686193\n",
      "Epoch 114:\t train loss : 0.5700349355024644; train accuracy : 0.9809411691812014; \n",
      " validation loss : 0.5953325340703172; validation accuracy : 0.9539748953974896\n",
      "Epoch 115:\t train loss : 0.5652109032914213; train accuracy : 0.986059047678057; \n",
      " validation loss : 0.5895459303476961; validation accuracy : 0.9623430962343096\n",
      "Epoch 116:\t train loss : 0.5602600135285986; train accuracy : 0.9910653985563369; \n",
      " validation loss : 0.5936322246157926; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5564877474633211; train accuracy : 0.9948480436196908; \n",
      " validation loss : 0.5958035699828987; validation accuracy : 0.9539748953974896\n",
      "Epoch 118:\t train loss : 0.5600660237212286; train accuracy : 0.9913473155921807; \n",
      " validation loss : 0.5960353244403801; validation accuracy : 0.9539748953974896\n",
      "Epoch 119:\t train loss : 0.5560081043374829; train accuracy : 0.9953375259456613; \n",
      " validation loss : 0.5861692089610991; validation accuracy : 0.9665271966527197\n",
      "Epoch 120:\t train loss : 0.5570943832980491; train accuracy : 0.9942904055268131; \n",
      " validation loss : 0.5975545229175705; validation accuracy : 0.9539748953974896\n",
      "Epoch 121:\t train loss : 0.5571769489719938; train accuracy : 0.9942284457387156; \n",
      " validation loss : 0.6013919452358624; validation accuracy : 0.9497907949790795\n",
      "Epoch 122:\t train loss : 0.5592412548464935; train accuracy : 0.9921465968586387; \n",
      " validation loss : 0.6025630421681617; validation accuracy : 0.9497907949790795\n",
      "Epoch 123:\t train loss : 0.5586837960445024; train accuracy : 0.992642275163419; \n",
      " validation loss : 0.6048497200428089; validation accuracy : 0.9497907949790795\n",
      "Epoch 124:\t train loss : 0.5629120531434254; train accuracy : 0.9883484618482605; \n",
      " validation loss : 0.6115728452727076; validation accuracy : 0.9414225941422594\n",
      "Epoch 125:\t train loss : 0.5569758045929729; train accuracy : 0.9944050311347935; \n",
      " validation loss : 0.5911890830060257; validation accuracy : 0.9581589958158996\n",
      "Epoch 126:\t train loss : 0.5552285902595849; train accuracy : 0.9961801790637876; \n",
      " validation loss : 0.5908830049174438; validation accuracy : 0.9581589958158996\n",
      "Epoch 127:\t train loss : 0.5577717361872634; train accuracy : 0.993515908175594; \n",
      " validation loss : 0.5904415486540163; validation accuracy : 0.9623430962343096\n",
      "Epoch 128:\t train loss : 0.5563602833622517; train accuracy : 0.9950246290157687; \n",
      " validation loss : 0.5895777143476818; validation accuracy : 0.9623430962343096\n",
      "Epoch 129:\t train loss : 0.5567959416731686; train accuracy : 0.9946559682765885; \n",
      " validation loss : 0.5836740306398582; validation accuracy : 0.9665271966527197\n",
      "Epoch 130:\t train loss : 0.556734593780276; train accuracy : 0.9946218903931349; \n",
      " validation loss : 0.6183083997779777; validation accuracy : 0.9330543933054394\n",
      "Epoch 131:\t train loss : 0.5563757285977866; train accuracy : 0.9949719631958859; \n",
      " validation loss : 0.5971973328302124; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5910007770923066; train accuracy : 0.959524768425292; \n",
      " validation loss : 0.6440868628836528; validation accuracy : 0.9079497907949791\n",
      "Epoch 133:\t train loss : 0.580999304201723; train accuracy : 0.9697760153660274; \n",
      " validation loss : 0.6048923984615512; validation accuracy : 0.9456066945606695\n",
      "Epoch 134:\t train loss : 0.5634030839777177; train accuracy : 0.9878527835434803; \n",
      " validation loss : 0.6155527205352423; validation accuracy : 0.9330543933054394\n",
      "Epoch 135:\t train loss : 0.5597064963438283; train accuracy : 0.9916818984479073; \n",
      " validation loss : 0.587859083921259; validation accuracy : 0.9623430962343096\n",
      "Epoch 136:\t train loss : 0.5567676868088459; train accuracy : 0.9946002044673007; \n",
      " validation loss : 0.6015002647580306; validation accuracy : 0.9497907949790795\n",
      "Epoch 137:\t train loss : 0.5557850697227271; train accuracy : 0.9956163449921002; \n",
      " validation loss : 0.5962383302839555; validation accuracy : 0.9539748953974896\n",
      "Epoch 138:\t train loss : 0.5559108908144148; train accuracy : 0.995467641500666; \n",
      " validation loss : 0.5920064031635438; validation accuracy : 0.9623430962343096\n",
      "Epoch 139:\t train loss : 0.5565381664486594; train accuracy : 0.9948077697574275; \n",
      " validation loss : 0.5808504282149586; validation accuracy : 0.9707112970711297\n",
      "Epoch 140:\t train loss : 0.5567370290590117; train accuracy : 0.9946249883825398; \n",
      " validation loss : 0.5728822584401488; validation accuracy : 0.9790794979079498\n",
      "Epoch 141:\t train loss : 0.5554493936453457; train accuracy : 0.9959230459431828; \n",
      " validation loss : 0.5924258064876224; validation accuracy : 0.9581589958158996\n",
      "Epoch 142:\t train loss : 0.5574354621114023; train accuracy : 0.9938876669041792; \n",
      " validation loss : 0.5872050109355103; validation accuracy : 0.9623430962343096\n",
      "Epoch 143:\t train loss : 0.5574940773330341; train accuracy : 0.9938814709253694; \n",
      " validation loss : 0.5870688370967758; validation accuracy : 0.9623430962343096\n",
      "Epoch 144:\t train loss : 0.5570505911471604; train accuracy : 0.994268719600979; \n",
      " validation loss : 0.5908741853475367; validation accuracy : 0.9623430962343096\n",
      "Epoch 145:\t train loss : 0.5609921082475984; train accuracy : 0.9901979615229716; \n",
      " validation loss : 0.5946874246983116; validation accuracy : 0.9581589958158996\n",
      "Epoch 146:\t train loss : 0.5586139178103275; train accuracy : 0.9926794510362774; \n",
      " validation loss : 0.6038301902316336; validation accuracy : 0.9456066945606695\n",
      "Epoch 147:\t train loss : 0.5556808265048883; train accuracy : 0.9956597168437684; \n",
      " validation loss : 0.5942900613589251; validation accuracy : 0.9581589958158996\n",
      "Epoch 148:\t train loss : 0.557489187895426; train accuracy : 0.9938164131478671; \n",
      " validation loss : 0.6099906920134281; validation accuracy : 0.9414225941422594\n",
      "Epoch 149:\t train loss : 0.5563227915109508; train accuracy : 0.9950277270051736; \n",
      " validation loss : 0.5847172694596328; validation accuracy : 0.9623430962343096\n",
      "Epoch 150:\t train loss : 0.5550024085120524; train accuracy : 0.9964528021314167; \n",
      " validation loss : 0.5922088098574418; validation accuracy : 0.9581589958158996\n",
      "Epoch 151:\t train loss : 0.5856776377282975; train accuracy : 0.9652405588772887; \n",
      " validation loss : 0.6010133776889562; validation accuracy : 0.9497907949790795\n",
      "Epoch 152:\t train loss : 0.5716228395516697; train accuracy : 0.9795439759596022; \n",
      " validation loss : 0.6094798764228551; validation accuracy : 0.9414225941422594\n",
      "Epoch 153:\t train loss : 0.5681471061838715; train accuracy : 0.983004430124849; \n",
      " validation loss : 0.5913615544880166; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154:\t train loss : 0.5649090358543726; train accuracy : 0.9863223767774715; \n",
      " validation loss : 0.5842631666882594; validation accuracy : 0.9665271966527197\n",
      "Epoch 155:\t train loss : 0.5616189365384754; train accuracy : 0.9898293007837913; \n",
      " validation loss : 0.5935781327018037; validation accuracy : 0.9581589958158996\n",
      "Epoch 156:\t train loss : 0.5597636322199369; train accuracy : 0.9914464512531367; \n",
      " validation loss : 0.6022804088422832; validation accuracy : 0.9497907949790795\n",
      "Epoch 157:\t train loss : 0.5586422996716232; train accuracy : 0.9927011369621116; \n",
      " validation loss : 0.5762566829483158; validation accuracy : 0.9707112970711297\n",
      "Epoch 158:\t train loss : 0.5610310007978663; train accuracy : 0.9901390997242789; \n",
      " validation loss : 0.5879035829014558; validation accuracy : 0.9623430962343096\n",
      "Epoch 159:\t train loss : 0.5586134179929284; train accuracy : 0.9926577651104433; \n",
      " validation loss : 0.5888393895884838; validation accuracy : 0.9623430962343096\n",
      "Epoch 160:\t train loss : 0.558689747452178; train accuracy : 0.9926577651104433; \n",
      " validation loss : 0.5874196099067248; validation accuracy : 0.9623430962343096\n",
      "Epoch 161:\t train loss : 0.5572698584770581; train accuracy : 0.9941509960035937; \n",
      " validation loss : 0.588679250342958; validation accuracy : 0.9623430962343096\n",
      "Epoch 162:\t train loss : 0.5576024802851623; train accuracy : 0.9937947272220329; \n",
      " validation loss : 0.6022691830930006; validation accuracy : 0.9497907949790795\n",
      "Epoch 163:\t train loss : 0.556220616503981; train accuracy : 0.9952136063694662; \n",
      " validation loss : 0.5989228892562343; validation accuracy : 0.9497907949790795\n",
      "Epoch 164:\t train loss : 0.5587648523271036; train accuracy : 0.9925803153753214; \n",
      " validation loss : 0.6099927834281709; validation accuracy : 0.9414225941422594\n",
      "Epoch 165:\t train loss : 0.5593981047665135; train accuracy : 0.9919359335791071; \n",
      " validation loss : 0.581117063266754; validation accuracy : 0.9707112970711297\n",
      "Epoch 166:\t train loss : 0.5613494675835362; train accuracy : 0.989962514328201; \n",
      " validation loss : 0.6039787163724791; validation accuracy : 0.9456066945606695\n",
      "Epoch 167:\t train loss : 0.5586427684292498; train accuracy : 0.9926856470150872; \n",
      " validation loss : 0.5843174930476102; validation accuracy : 0.9665271966527197\n",
      "Epoch 168:\t train loss : 0.5560707659616247; train accuracy : 0.9952290963164906; \n",
      " validation loss : 0.596059926972469; validation accuracy : 0.9539748953974896\n",
      "Epoch 169:\t train loss : 0.5573261091162544; train accuracy : 0.9941448000247839; \n",
      " validation loss : 0.5808567321984949; validation accuracy : 0.9707112970711297\n",
      "Epoch 170:\t train loss : 0.5586997814039028; train accuracy : 0.9925710214071067; \n",
      " validation loss : 0.6030394128545228; validation accuracy : 0.9497907949790795\n",
      "Epoch 171:\t train loss : 0.5560661062833182; train accuracy : 0.995343721924471; \n",
      " validation loss : 0.5990488764305184; validation accuracy : 0.9539748953974896\n",
      "Epoch 172:\t train loss : 0.5574061870319534; train accuracy : 0.9939558226710865; \n",
      " validation loss : 0.596131708655476; validation accuracy : 0.9539748953974896\n",
      "Epoch 173:\t train loss : 0.5567772251578745; train accuracy : 0.994544440658013; \n",
      " validation loss : 0.5851383839986435; validation accuracy : 0.9665271966527197\n",
      "Epoch 174:\t train loss : 0.556125230877158; train accuracy : 0.9953127420304222; \n",
      " validation loss : 0.6013510512072804; validation accuracy : 0.9497907949790795\n",
      "Epoch 175:\t train loss : 0.554997977203838; train accuracy : 0.9964187242479631; \n",
      " validation loss : 0.5950251390869803; validation accuracy : 0.9581589958158996\n",
      "Epoch 176:\t train loss : 0.5581797900681645; train accuracy : 0.9931131695529601; \n",
      " validation loss : 0.5855674280659786; validation accuracy : 0.9623430962343096\n",
      "Epoch 177:\t train loss : 0.558587846757995; train accuracy : 0.9927569007713993; \n",
      " validation loss : 0.6059645827538908; validation accuracy : 0.9456066945606695\n",
      "Epoch 178:\t train loss : 0.5588779090593811; train accuracy : 0.9924223179156727; \n",
      " validation loss : 0.5889846890109265; validation accuracy : 0.9623430962343096\n",
      "Epoch 179:\t train loss : 0.5586608625562336; train accuracy : 0.9927569007713993; \n",
      " validation loss : 0.5809250520866228; validation accuracy : 0.9707112970711297\n",
      "Epoch 180:\t train loss : 0.5571551145564997; train accuracy : 0.9942222497599058; \n",
      " validation loss : 0.6027720063994019; validation accuracy : 0.9456066945606695\n",
      "Epoch 181:\t train loss : 0.5569489689993876; train accuracy : 0.9942966015056228; \n",
      " validation loss : 0.5736981706410867; validation accuracy : 0.9790794979079498\n",
      "Epoch 182:\t train loss : 0.557944206742308; train accuracy : 0.9933826946311843; \n",
      " validation loss : 0.6011492630816121; validation accuracy : 0.9497907949790795\n",
      "Epoch 183:\t train loss : 0.557536283589732; train accuracy : 0.9938071191796524; \n",
      " validation loss : 0.5770903520699924; validation accuracy : 0.9748953974895398\n",
      "Epoch 184:\t train loss : 0.5583226350603719; train accuracy : 0.9929582700827163; \n",
      " validation loss : 0.5854676782737974; validation accuracy : 0.9665271966527197\n",
      "Epoch 185:\t train loss : 0.5562922458361446; train accuracy : 0.9950277270051736; \n",
      " validation loss : 0.588615381319754; validation accuracy : 0.9623430962343096\n",
      "Epoch 186:\t train loss : 0.5562051734670858; train accuracy : 0.9951950184330369; \n",
      " validation loss : 0.5954396344556722; validation accuracy : 0.9539748953974896\n",
      "Epoch 187:\t train loss : 0.5593995702263792; train accuracy : 0.9918553858545803; \n",
      " validation loss : 0.6305429863815186; validation accuracy : 0.9205020920502092\n",
      "Epoch 188:\t train loss : 0.5738501251080103; train accuracy : 0.9773691873973791; \n",
      " validation loss : 0.5931115490859709; validation accuracy : 0.9581589958158996\n",
      "Epoch 189:\t train loss : 0.5585652005160455; train accuracy : 0.9927816846866384; \n",
      " validation loss : 0.5988742925364091; validation accuracy : 0.9497907949790795\n",
      "Epoch 190:\t train loss : 0.5585165761012633; train accuracy : 0.9928777223581895; \n",
      " validation loss : 0.5937156131119649; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 190\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5567370290590117; Train accuracy : 0.9946249883825398; \n",
      " Validation loss : 0.5728822584401488; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 55 ! ---\n",
      "Epoch 1:\t train loss : 0.9571142263126123; train accuracy : 0.5710557947891818; \n",
      " validation loss : 0.8500478682031738; validation accuracy : 0.6778242677824268\n",
      "Epoch 2:\t train loss : 0.7676278089661027; train accuracy : 0.7806375662195235; \n",
      " validation loss : 0.7228380718321258; validation accuracy : 0.8158995815899581\n",
      "Epoch 3:\t train loss : 0.7079827457951083; train accuracy : 0.8411013352334334; \n",
      " validation loss : 0.7083053474767653; validation accuracy : 0.8451882845188284\n",
      "Epoch 4:\t train loss : 0.6736698370849793; train accuracy : 0.8764766566498342; \n",
      " validation loss : 0.6712806000245405; validation accuracy : 0.8744769874476988\n",
      "Epoch 5:\t train loss : 0.6463562452027307; train accuracy : 0.9046160042132656; \n",
      " validation loss : 0.7010948002890303; validation accuracy : 0.8451882845188284\n",
      "Epoch 6:\t train loss : 0.6302783121760992; train accuracy : 0.9210183091173828; \n",
      " validation loss : 0.6293754637963548; validation accuracy : 0.9288702928870293\n",
      "Epoch 7:\t train loss : 0.6183945797089941; train accuracy : 0.9327318070572198; \n",
      " validation loss : 0.6657053909471781; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6050295868479917; train accuracy : 0.9462381114656588; \n",
      " validation loss : 0.6399615731670678; validation accuracy : 0.9121338912133892\n",
      "Epoch 9:\t train loss : 0.6066856864929249; train accuracy : 0.9440806716441029; \n",
      " validation loss : 0.6464762890342611; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.5962816649278101; train accuracy : 0.9551020787508907; \n",
      " validation loss : 0.6151840920097161; validation accuracy : 0.9330543933054394\n",
      "Epoch 11:\t train loss : 0.5966885691459818; train accuracy : 0.9545909104990861; \n",
      " validation loss : 0.6332246010746307; validation accuracy : 0.9079497907949791\n",
      "Epoch 12:\t train loss : 0.590010260000334; train accuracy : 0.9613909972427894; \n",
      " validation loss : 0.6344146018211962; validation accuracy : 0.9121338912133892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\t train loss : 0.5910032062925163; train accuracy : 0.9602100436816506; \n",
      " validation loss : 0.6261663093345602; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5861414695361657; train accuracy : 0.9652346726974194; \n",
      " validation loss : 0.6174485737669845; validation accuracy : 0.9288702928870293\n",
      "Epoch 15:\t train loss : 0.5897082999802008; train accuracy : 0.961362185941324; \n",
      " validation loss : 0.6174131681656525; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5922887803251938; train accuracy : 0.9589280956659129; \n",
      " validation loss : 0.625593490394905; validation accuracy : 0.9246861924686193\n",
      "Epoch 17:\t train loss : 0.583372143334778; train accuracy : 0.967935809659531; \n",
      " validation loss : 0.6156126996453993; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.5802220370908413; train accuracy : 0.9706075157222962; \n",
      " validation loss : 0.6160817242112475; validation accuracy : 0.9372384937238494\n",
      "Epoch 19:\t train loss : 0.5883738586940843; train accuracy : 0.9627888100622696; \n",
      " validation loss : 0.6169499136198907; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5899997205684235; train accuracy : 0.9609963133926082; \n",
      " validation loss : 0.601477662144186; validation accuracy : 0.9456066945606695\n",
      "Epoch 21:\t train loss : 0.5952847014920861; train accuracy : 0.9556612658384708; \n",
      " validation loss : 0.613739721524072; validation accuracy : 0.9414225941422594\n",
      "Epoch 22:\t train loss : 0.5844480886968765; train accuracy : 0.966520338300443; \n",
      " validation loss : 0.6165004257766332; validation accuracy : 0.9288702928870293\n",
      "Epoch 23:\t train loss : 0.5806126325454842; train accuracy : 0.9707432076582299; \n",
      " validation loss : 0.5851648874796925; validation accuracy : 0.9707112970711297\n",
      "Epoch 24:\t train loss : 0.5786141710553125; train accuracy : 0.9724743641376746; \n",
      " validation loss : 0.581304395097493; validation accuracy : 0.9707112970711297\n",
      "Epoch 25:\t train loss : 0.5767629586242161; train accuracy : 0.9745227547321789; \n",
      " validation loss : 0.5980989199046727; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5783219766706102; train accuracy : 0.9730725858917563; \n",
      " validation loss : 0.6078025202592315; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.578295837786921; train accuracy : 0.9730859072461973; \n",
      " validation loss : 0.6108209496508052; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.5719048505755893; train accuracy : 0.979361504383655; \n",
      " validation loss : 0.602047610847523; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5692863494199218; train accuracy : 0.9819055732829394; \n",
      " validation loss : 0.589110373578971; validation accuracy : 0.9623430962343096\n",
      "Epoch 30:\t train loss : 0.5775809030528621; train accuracy : 0.9734133647262926; \n",
      " validation loss : 0.5985777561824804; validation accuracy : 0.9539748953974896\n",
      "Epoch 31:\t train loss : 0.573788992582827; train accuracy : 0.9776148579571858; \n",
      " validation loss : 0.6156561250218067; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5692138054995036; train accuracy : 0.9821902785092474; \n",
      " validation loss : 0.597258543457745; validation accuracy : 0.9497907949790795\n",
      "Epoch 33:\t train loss : 0.5727191188700438; train accuracy : 0.9785538585458038; \n",
      " validation loss : 0.6021097895136202; validation accuracy : 0.9456066945606695\n",
      "Epoch 34:\t train loss : 0.5719939082178883; train accuracy : 0.9790244431364045; \n",
      " validation loss : 0.6057143450970912; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.5762066672166711; train accuracy : 0.9748229499055113; \n",
      " validation loss : 0.6011974565710059; validation accuracy : 0.9456066945606695\n",
      "Epoch 36:\t train loss : 0.5711466310639619; train accuracy : 0.9800991356609561; \n",
      " validation loss : 0.6001201793150234; validation accuracy : 0.9539748953974896\n",
      "Epoch 37:\t train loss : 0.5704637055931505; train accuracy : 0.9808950091390688; \n",
      " validation loss : 0.6028059096891615; validation accuracy : 0.9456066945606695\n",
      "Epoch 38:\t train loss : 0.5747389961192112; train accuracy : 0.976145481582453; \n",
      " validation loss : 0.6261425559521016; validation accuracy : 0.9246861924686193\n",
      "Epoch 39:\t train loss : 0.5658534593030464; train accuracy : 0.9853155302208867; \n",
      " validation loss : 0.6076317066957877; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.5696512514462562; train accuracy : 0.9815706806282722; \n",
      " validation loss : 0.6196162720799089; validation accuracy : 0.9288702928870293\n",
      "Epoch 41:\t train loss : 0.5774656174608956; train accuracy : 0.9733978747792682; \n",
      " validation loss : 0.6097927901891935; validation accuracy : 0.9372384937238494\n",
      "Epoch 42:\t train loss : 0.5672914503730833; train accuracy : 0.983828495306546; \n",
      " validation loss : 0.5883261638996334; validation accuracy : 0.9665271966527197\n",
      "Epoch 43:\t train loss : 0.5684143744517449; train accuracy : 0.982728709067815; \n",
      " validation loss : 0.6001879825959867; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.5640054124406649; train accuracy : 0.9876272499148053; \n",
      " validation loss : 0.598614209365553; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5700935958366224; train accuracy : 0.9810189287152637; \n",
      " validation loss : 0.586852014417222; validation accuracy : 0.9665271966527197\n",
      "Epoch 46:\t train loss : 0.5648128891979884; train accuracy : 0.9862759069363983; \n",
      " validation loss : 0.5971523461168117; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5653107246712455; train accuracy : 0.9859698255831965; \n",
      " validation loss : 0.5891766753340555; validation accuracy : 0.9623430962343096\n",
      "Epoch 48:\t train loss : 0.5686423076733472; train accuracy : 0.9825000774497351; \n",
      " validation loss : 0.5905576380998288; validation accuracy : 0.9623430962343096\n",
      "Epoch 49:\t train loss : 0.5642488994931232; train accuracy : 0.9868992224046593; \n",
      " validation loss : 0.5984595985866203; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5628494815017553; train accuracy : 0.9884541032869668; \n",
      " validation loss : 0.6080929698207356; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5653569995961926; train accuracy : 0.9858459060070015; \n",
      " validation loss : 0.6152398519524297; validation accuracy : 0.9330543933054394\n",
      "Epoch 52:\t train loss : 0.5757172794443463; train accuracy : 0.9751947086340965; \n",
      " validation loss : 0.6059891787571413; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5668095722488804; train accuracy : 0.9844363208277828; \n",
      " validation loss : 0.6035050161735951; validation accuracy : 0.9414225941422594\n",
      "Epoch 54:\t train loss : 0.5646060247519689; train accuracy : 0.9866476656649834; \n",
      " validation loss : 0.6247901881434094; validation accuracy : 0.9205020920502092\n",
      "Epoch 55:\t train loss : 0.5661168050485595; train accuracy : 0.9851451408036185; \n",
      " validation loss : 0.6053913752384573; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.565300892149609; train accuracy : 0.9859698255831965; \n",
      " validation loss : 0.6083229810455142; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5653040026938779; train accuracy : 0.9857374763778308; \n",
      " validation loss : 0.5814056893468722; validation accuracy : 0.9665271966527197\n",
      "Epoch 58:\t train loss : 0.5635093583464457; train accuracy : 0.987695095882772; \n",
      " validation loss : 0.5995430271921827; validation accuracy : 0.9497907949790795\n",
      "Epoch 59:\t train loss : 0.5673533914344127; train accuracy : 0.9837392732116856; \n",
      " validation loss : 0.6016941607819737; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5645206088937366; train accuracy : 0.9868645249233248; \n",
      " validation loss : 0.5786862922844386; validation accuracy : 0.9748953974895398\n",
      "Epoch 61:\t train loss : 0.5654306373331333; train accuracy : 0.9858304160599771; \n",
      " validation loss : 0.6135563726397271; validation accuracy : 0.9372384937238494\n",
      "Epoch 62:\t train loss : 0.5688285830037166; train accuracy : 0.9821592986151987; \n",
      " validation loss : 0.5839108597630248; validation accuracy : 0.9665271966527197\n",
      "Epoch 63:\t train loss : 0.5697176592711318; train accuracy : 0.9810712847362062; \n",
      " validation loss : 0.580383429507411; validation accuracy : 0.9707112970711297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:\t train loss : 0.5623460193821967; train accuracy : 0.9888974255708045; \n",
      " validation loss : 0.5949495575118184; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.565020099850711; train accuracy : 0.9860996313392608; \n",
      " validation loss : 0.5882113679548813; validation accuracy : 0.9623430962343096\n",
      "Epoch 66:\t train loss : 0.5664765234917258; train accuracy : 0.9846959323399114; \n",
      " validation loss : 0.5967858118862354; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5610948364816907; train accuracy : 0.9901483936924935; \n",
      " validation loss : 0.5961962722879915; validation accuracy : 0.9581589958158996\n",
      "Epoch 68:\t train loss : 0.5617519371571456; train accuracy : 0.9894027076427399; \n",
      " validation loss : 0.5972933047750274; validation accuracy : 0.9539748953974896\n",
      "Epoch 69:\t train loss : 0.573950642096193; train accuracy : 0.9769915424889247; \n",
      " validation loss : 0.5950512237433148; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5657306434136942; train accuracy : 0.9855419932463831; \n",
      " validation loss : 0.5730607814140023; validation accuracy : 0.9790794979079498\n",
      "Epoch 71:\t train loss : 0.5621139463778129; train accuracy : 0.9891570370829331; \n",
      " validation loss : 0.5888545993774466; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5617003989172057; train accuracy : 0.9896158493137953; \n",
      " validation loss : 0.5986788587934471; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5652219732737523; train accuracy : 0.985994919297376; \n",
      " validation loss : 0.609817225586748; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5615840163488699; train accuracy : 0.9896991852287865; \n",
      " validation loss : 0.5765407389292146; validation accuracy : 0.9748953974895398\n",
      "Epoch 75:\t train loss : 0.5601094158375021; train accuracy : 0.9913352334335016; \n",
      " validation loss : 0.5948931751994812; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5629866555763582; train accuracy : 0.9882372440286255; \n",
      " validation loss : 0.5923312569987954; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5659858077177232; train accuracy : 0.9853406239350662; \n",
      " validation loss : 0.6053223101099694; validation accuracy : 0.9456066945606695\n",
      "Epoch 78:\t train loss : 0.5667823223274238; train accuracy : 0.9843374949657672; \n",
      " validation loss : 0.6120884130027174; validation accuracy : 0.9372384937238494\n",
      "Epoch 79:\t train loss : 0.5601722258438447; train accuracy : 0.9911552402490783; \n",
      " validation loss : 0.581445172491112; validation accuracy : 0.9707112970711297\n",
      "Epoch 80:\t train loss : 0.5652770190695672; train accuracy : 0.9859862449270423; \n",
      " validation loss : 0.6361270331425375; validation accuracy : 0.9163179916317992\n",
      "Epoch 81:\t train loss : 0.5658062262316794; train accuracy : 0.9854394497970816; \n",
      " validation loss : 0.5797524246010042; validation accuracy : 0.9707112970711297\n",
      "Epoch 82:\t train loss : 0.562579899176343; train accuracy : 0.98874841228043; \n",
      " validation loss : 0.5849744458589661; validation accuracy : 0.9665271966527197\n",
      "Epoch 83:\t train loss : 0.5622194697677775; train accuracy : 0.9891511509030639; \n",
      " validation loss : 0.5748820046353673; validation accuracy : 0.9790794979079498\n",
      "Epoch 84:\t train loss : 0.5652098920704582; train accuracy : 0.9860221816041389; \n",
      " validation loss : 0.6154358945854773; validation accuracy : 0.9372384937238494\n",
      "Epoch 85:\t train loss : 0.5655344902322754; train accuracy : 0.9856194429815051; \n",
      " validation loss : 0.5973386605806076; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5605440209647926; train accuracy : 0.990814461414542; \n",
      " validation loss : 0.5927783694560482; validation accuracy : 0.9581589958158996\n",
      "Epoch 87:\t train loss : 0.5614951692791323; train accuracy : 0.989637225440689; \n",
      " validation loss : 0.588519739925657; validation accuracy : 0.9623430962343096\n",
      "Epoch 88:\t train loss : 0.5597390806392137; train accuracy : 0.9914997366709006; \n",
      " validation loss : 0.6031789659652315; validation accuracy : 0.9414225941422594\n",
      "Epoch 89:\t train loss : 0.5659265478324068; train accuracy : 0.9851968772266799; \n",
      " validation loss : 0.5901509383506; validation accuracy : 0.9581589958158996\n",
      "Epoch 90:\t train loss : 0.567655985745901; train accuracy : 0.9834214194987453; \n",
      " validation loss : 0.6286292682014291; validation accuracy : 0.9205020920502092\n",
      "Epoch 91:\t train loss : 0.5624731661334131; train accuracy : 0.988785278354348; \n",
      " validation loss : 0.6045633215782124; validation accuracy : 0.9456066945606695\n",
      "Epoch 92:\t train loss : 0.5595815442593454; train accuracy : 0.9916509185538586; \n",
      " validation loss : 0.5806927188455172; validation accuracy : 0.9707112970711297\n",
      "Epoch 93:\t train loss : 0.5607495371699729; train accuracy : 0.9905821122091762; \n",
      " validation loss : 0.5803292137503575; validation accuracy : 0.9707112970711297\n",
      "Epoch 94:\t train loss : 0.560428808311269; train accuracy : 0.9908609312556151; \n",
      " validation loss : 0.5990280799509162; validation accuracy : 0.9497907949790795\n",
      "Epoch 95:\t train loss : 0.5599799287352627; train accuracy : 0.991226803804331; \n",
      " validation loss : 0.5779610540895138; validation accuracy : 0.9748953974895398\n",
      "Epoch 96:\t train loss : 0.5590685173798521; train accuracy : 0.9922085566467362; \n",
      " validation loss : 0.5856572740753924; validation accuracy : 0.9665271966527197\n",
      "Epoch 97:\t train loss : 0.5581679294624203; train accuracy : 0.9931379534681991; \n",
      " validation loss : 0.5815983542426966; validation accuracy : 0.9707112970711297\n",
      "Epoch 98:\t train loss : 0.5604203060673392; train accuracy : 0.9908764212026395; \n",
      " validation loss : 0.5852207984263063; validation accuracy : 0.9665271966527197\n",
      "Epoch 99:\t train loss : 0.5588436691613634; train accuracy : 0.9925124694073546; \n",
      " validation loss : 0.5654626787352148; validation accuracy : 0.9874476987447699\n",
      "Epoch 100:\t train loss : 0.5592047629294532; train accuracy : 0.9921967842869978; \n",
      " validation loss : 0.5835861365940179; validation accuracy : 0.9665271966527197\n",
      "Epoch 101:\t train loss : 0.5666290366330087; train accuracy : 0.9844886768487252; \n",
      " validation loss : 0.5760221033749893; validation accuracy : 0.9748953974895398\n",
      "Epoch 102:\t train loss : 0.565034764207815; train accuracy : 0.9862235509154559; \n",
      " validation loss : 0.5867727512792725; validation accuracy : 0.9665271966527197\n",
      "Epoch 103:\t train loss : 0.5650622191127402; train accuracy : 0.9862021747885622; \n",
      " validation loss : 0.613010109058691; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.570362349433821; train accuracy : 0.9807593172031351; \n",
      " validation loss : 0.6002508372472927; validation accuracy : 0.9497907949790795\n",
      "Epoch 105:\t train loss : 0.5643950482978288; train accuracy : 0.9868586387434555; \n",
      " validation loss : 0.5933852200554075; validation accuracy : 0.9581589958158996\n",
      "Epoch 106:\t train loss : 0.5651942982554312; train accuracy : 0.9860413891384492; \n",
      " validation loss : 0.5988603743916134; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.5620364915272594; train accuracy : 0.9892499767650794; \n",
      " validation loss : 0.5821929624740944; validation accuracy : 0.9707112970711297\n",
      "Epoch 108:\t train loss : 0.5596438611836992; train accuracy : 0.9917416896434215; \n",
      " validation loss : 0.5791016370595349; validation accuracy : 0.9748953974895398\n",
      "Epoch 109:\t train loss : 0.5599654694731468; train accuracy : 0.9913566095603953; \n",
      " validation loss : 0.5867437256484497; validation accuracy : 0.9623430962343096\n",
      "Epoch 110:\t train loss : 0.5598677365986733; train accuracy : 0.9914030794014684; \n",
      " validation loss : 0.5955505107073001; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.5585295556849453; train accuracy : 0.9927757985067691; \n",
      " validation loss : 0.5900166371512153; validation accuracy : 0.9581589958158996\n",
      "Epoch 112:\t train loss : 0.5579201316144969; train accuracy : 0.9934728461228662; \n",
      " validation loss : 0.5871159680798999; validation accuracy : 0.9665271966527197\n",
      "Epoch 113:\t train loss : 0.5619060103240157; train accuracy : 0.9892899408284024; \n",
      " validation loss : 0.6608873476080634; validation accuracy : 0.8870292887029289\n",
      "Epoch 114:\t train loss : 0.5627239106696508; train accuracy : 0.988547042969113; \n",
      " validation loss : 0.6056821144979789; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115:\t train loss : 0.5582195624425502; train accuracy : 0.9931844233092723; \n",
      " validation loss : 0.5803641981180871; validation accuracy : 0.9707112970711297\n",
      "Epoch 116:\t train loss : 0.5594636656479216; train accuracy : 0.9919083614734038; \n",
      " validation loss : 0.5990019786237056; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5597430196881397; train accuracy : 0.9915424889246879; \n",
      " validation loss : 0.590254787875992; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5626935886554867; train accuracy : 0.9885411567892438; \n",
      " validation loss : 0.6208517590642106; validation accuracy : 0.9288702928870293\n",
      "Epoch 119:\t train loss : 0.5634707718103419; train accuracy : 0.9878558815328852; \n",
      " validation loss : 0.6093844034444151; validation accuracy : 0.9414225941422594\n",
      "Epoch 120:\t train loss : 0.5623627730333329; train accuracy : 0.9888391833699929; \n",
      " validation loss : 0.6303861785048986; validation accuracy : 0.9205020920502092\n",
      "Epoch 121:\t train loss : 0.5616827779445981; train accuracy : 0.9895848694197465; \n",
      " validation loss : 0.5897981263433919; validation accuracy : 0.9581589958158996\n",
      "Epoch 122:\t train loss : 0.5587880231793231; train accuracy : 0.9924756033334365; \n",
      " validation loss : 0.6015342461475457; validation accuracy : 0.9456066945606695\n",
      "Epoch 123:\t train loss : 0.5603092930672716; train accuracy : 0.9910542457944794; \n",
      " validation loss : 0.6192855960193332; validation accuracy : 0.9288702928870293\n",
      "Epoch 124:\t train loss : 0.5639062132690499; train accuracy : 0.9872672635459586; \n",
      " validation loss : 0.5876665901344081; validation accuracy : 0.9623430962343096\n",
      "Epoch 125:\t train loss : 0.5654227778482149; train accuracy : 0.9857337587905449; \n",
      " validation loss : 0.6005096650862276; validation accuracy : 0.9497907949790795\n",
      "Epoch 126:\t train loss : 0.5581478051399184; train accuracy : 0.9932618730443942; \n",
      " validation loss : 0.5733478910197289; validation accuracy : 0.9790794979079498\n",
      "Epoch 127:\t train loss : 0.5588021982495467; train accuracy : 0.9924814895133058; \n",
      " validation loss : 0.6081177769295434; validation accuracy : 0.9414225941422594\n",
      "Epoch 128:\t train loss : 0.5621448757587392; train accuracy : 0.9891570370829332; \n",
      " validation loss : 0.5873659899795443; validation accuracy : 0.9623430962343096\n",
      "Epoch 129:\t train loss : 0.5596758879151463; train accuracy : 0.9915734688187366; \n",
      " validation loss : 0.5870413001761826; validation accuracy : 0.9623430962343096\n",
      "Epoch 130:\t train loss : 0.5596094963602367; train accuracy : 0.991790328077078; \n",
      " validation loss : 0.594475622476319; validation accuracy : 0.9581589958158996\n",
      "Epoch 131:\t train loss : 0.5581056919780948; train accuracy : 0.9932095170234517; \n",
      " validation loss : 0.5766434888129961; validation accuracy : 0.9748953974895398\n",
      "Epoch 132:\t train loss : 0.5588741186123949; train accuracy : 0.9924040397781839; \n",
      " validation loss : 0.6120403997473033; validation accuracy : 0.9372384937238494\n",
      "Epoch 133:\t train loss : 0.5574167580844837; train accuracy : 0.9940149942687196; \n",
      " validation loss : 0.5831184086376556; validation accuracy : 0.9665271966527197\n",
      "Epoch 134:\t train loss : 0.5584766447391357; train accuracy : 0.9928067784008179; \n",
      " validation loss : 0.5835983178242232; validation accuracy : 0.9665271966527197\n",
      "Epoch 135:\t train loss : 0.5602875253359121; train accuracy : 0.9910313206728832; \n",
      " validation loss : 0.5814779538283965; validation accuracy : 0.9707112970711297\n",
      "Epoch 136:\t train loss : 0.5593319236452711; train accuracy : 0.9920322810495988; \n",
      " validation loss : 0.5826316916183432; validation accuracy : 0.9665271966527197\n",
      "Epoch 137:\t train loss : 0.5627251585808911; train accuracy : 0.9886458688311286; \n",
      " validation loss : 0.6048105003098547; validation accuracy : 0.9456066945606695\n",
      "Epoch 138:\t train loss : 0.5602042863631994; train accuracy : 0.9911397503020539; \n",
      " validation loss : 0.6078118483535743; validation accuracy : 0.9414225941422594\n",
      "Epoch 139:\t train loss : 0.5581338739904496; train accuracy : 0.9931999132562966; \n",
      " validation loss : 0.5808045570614091; validation accuracy : 0.9707112970711297\n",
      "Epoch 140:\t train loss : 0.5606696992146852; train accuracy : 0.9906846556584776; \n",
      " validation loss : 0.5847940759098134; validation accuracy : 0.9665271966527197\n",
      "Epoch 141:\t train loss : 0.5604328219094705; train accuracy : 0.9908609312556151; \n",
      " validation loss : 0.6043092484112402; validation accuracy : 0.9456066945606695\n",
      "Epoch 142:\t train loss : 0.5598262994713896; train accuracy : 0.9914030794014684; \n",
      " validation loss : 0.5959827485467656; validation accuracy : 0.9539748953974896\n",
      "Epoch 143:\t train loss : 0.5614165252097917; train accuracy : 0.9898850645930791; \n",
      " validation loss : 0.6095358033567209; validation accuracy : 0.9414225941422594\n",
      "Epoch 144:\t train loss : 0.5589991473289531; train accuracy : 0.9923014963288825; \n",
      " validation loss : 0.6031964277773003; validation accuracy : 0.9456066945606695\n",
      "Epoch 145:\t train loss : 0.5581042763614442; train accuracy : 0.9931534434152235; \n",
      " validation loss : 0.58892562238706; validation accuracy : 0.9623430962343096\n",
      "Epoch 146:\t train loss : 0.5559638524356774; train accuracy : 0.9953471297128164; \n",
      " validation loss : 0.5902011316273313; validation accuracy : 0.9623430962343096\n",
      "Epoch 147:\t train loss : 0.5583209034996022; train accuracy : 0.9929365841568821; \n",
      " validation loss : 0.5690720403440386; validation accuracy : 0.9790794979079498\n",
      "Epoch 148:\t train loss : 0.5582540010226853; train accuracy : 0.9931940270764273; \n",
      " validation loss : 0.5908283328640163; validation accuracy : 0.9581589958158996\n",
      "Epoch 149:\t train loss : 0.5582334430567297; train accuracy : 0.9930893150345426; \n",
      " validation loss : 0.586557945435382; validation accuracy : 0.9665271966527197\n",
      "Early stopping at epoch 149\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5588436691613634; Train accuracy : 0.9925124694073546; \n",
      " Validation loss : 0.5654626787352148; Validation accuracy : 0.9874476987447699\n",
      "--- Let's train model 56 ! ---\n",
      "Epoch 1:\t train loss : 0.9286146461000446; train accuracy : 0.5984417113293472; \n",
      " validation loss : 0.813009924363752; validation accuracy : 0.7364016736401674\n",
      "Epoch 2:\t train loss : 0.7578561252650318; train accuracy : 0.7904117227919081; \n",
      " validation loss : 0.7348023345564133; validation accuracy : 0.8200836820083682\n",
      "Epoch 3:\t train loss : 0.6878430808223736; train accuracy : 0.8630131044951826; \n",
      " validation loss : 0.6856199384654215; validation accuracy : 0.8661087866108786\n",
      "Epoch 4:\t train loss : 0.6611623862481811; train accuracy : 0.8898540846990304; \n",
      " validation loss : 0.6825417719364982; validation accuracy : 0.8619246861924686\n",
      "Epoch 5:\t train loss : 0.6445017081559031; train accuracy : 0.9066451872734596; \n",
      " validation loss : 0.6632032520504936; validation accuracy : 0.8870292887029289\n",
      "Epoch 6:\t train loss : 0.6313862822691015; train accuracy : 0.9200656773753834; \n",
      " validation loss : 0.6604964612178829; validation accuracy : 0.8870292887029289\n",
      "Epoch 7:\t train loss : 0.6187266614705828; train accuracy : 0.9325691626134639; \n",
      " validation loss : 0.6782241434896685; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6171367096035207; train accuracy : 0.9344496421822237; \n",
      " validation loss : 0.6261977703116353; validation accuracy : 0.9288702928870293\n",
      "Epoch 9:\t train loss : 0.6097796462971941; train accuracy : 0.9414232163326002; \n",
      " validation loss : 0.6487517198818693; validation accuracy : 0.9037656903765691\n",
      "Epoch 10:\t train loss : 0.6034114286815022; train accuracy : 0.9478081724960501; \n",
      " validation loss : 0.6236156398477665; validation accuracy : 0.9246861924686193\n",
      "Epoch 11:\t train loss : 0.602734085109355; train accuracy : 0.9483379286842839; \n",
      " validation loss : 0.6208319362283132; validation accuracy : 0.9288702928870293\n",
      "Epoch 12:\t train loss : 0.5899771679950712; train accuracy : 0.9615322655596518; \n",
      " validation loss : 0.6244877089386006; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.5921819554732176; train accuracy : 0.9590445800675361; \n",
      " validation loss : 0.6162191698414007; validation accuracy : 0.9372384937238494\n",
      "Epoch 14:\t train loss : 0.5823649578671077; train accuracy : 0.9690541838346913; \n",
      " validation loss : 0.6240055734830798; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\t train loss : 0.583783098491451; train accuracy : 0.967635304687258; \n",
      " validation loss : 0.6124470602235822; validation accuracy : 0.9414225941422594\n",
      "Epoch 16:\t train loss : 0.585883343711865; train accuracy : 0.9653582824746739; \n",
      " validation loss : 0.6218933748438288; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5797805972154916; train accuracy : 0.9714241457294216; \n",
      " validation loss : 0.6162127405812448; validation accuracy : 0.9372384937238494\n",
      "Epoch 18:\t train loss : 0.5827661604345749; train accuracy : 0.9685244276464574; \n",
      " validation loss : 0.595167042865718; validation accuracy : 0.9623430962343096\n",
      "Epoch 19:\t train loss : 0.5789679504311345; train accuracy : 0.9723039747204064; \n",
      " validation loss : 0.6720023162208447; validation accuracy : 0.8786610878661087\n",
      "Epoch 20:\t train loss : 0.5877955228260171; train accuracy : 0.963155612007807; \n",
      " validation loss : 0.6321022725912719; validation accuracy : 0.9163179916317992\n",
      "Epoch 21:\t train loss : 0.5789100187667029; train accuracy : 0.9724309922860064; \n",
      " validation loss : 0.6247970960267883; validation accuracy : 0.9288702928870293\n",
      "Epoch 22:\t train loss : 0.5748569590914872; train accuracy : 0.9765172403110381; \n",
      " validation loss : 0.6187139217557778; validation accuracy : 0.9246861924686193\n",
      "Epoch 23:\t train loss : 0.578740197946878; train accuracy : 0.9726075776820843; \n",
      " validation loss : 0.6053244072327629; validation accuracy : 0.9456066945606695\n",
      "Epoch 24:\t train loss : 0.5819202288911924; train accuracy : 0.9691842993896961; \n",
      " validation loss : 0.6039965243277629; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5698067719888567; train accuracy : 0.9814709253694353; \n",
      " validation loss : 0.5996408362598126; validation accuracy : 0.9497907949790795\n",
      "Epoch 26:\t train loss : 0.569919473099435; train accuracy : 0.9815979429350352; \n",
      " validation loss : 0.610238371328307; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5727403593148062; train accuracy : 0.9784751696149199; \n",
      " validation loss : 0.5928447512753927; validation accuracy : 0.9581589958158996\n",
      "Epoch 28:\t train loss : 0.6281637589707026; train accuracy : 0.9215000464698411; \n",
      " validation loss : 0.6666672435085288; validation accuracy : 0.8870292887029289\n",
      "Epoch 29:\t train loss : 0.581061636274431; train accuracy : 0.9697202515567397; \n",
      " validation loss : 0.5969879306454768; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.5658474185476826; train accuracy : 0.9855107035533939; \n",
      " validation loss : 0.6013624983598468; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5673205185602009; train accuracy : 0.9839710028191704; \n",
      " validation loss : 0.6122710891241585; validation accuracy : 0.9330543933054394\n",
      "Epoch 32:\t train loss : 0.5704828264827857; train accuracy : 0.9804207069611822; \n",
      " validation loss : 0.5910528275007718; validation accuracy : 0.9623430962343096\n",
      "Epoch 33:\t train loss : 0.5657704384901733; train accuracy : 0.9854580377335109; \n",
      " validation loss : 0.6161929273724654; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.565159069208575; train accuracy : 0.9861922612224666; \n",
      " validation loss : 0.5959652251465609; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.5649780842390137; train accuracy : 0.9862263391059203; \n",
      " validation loss : 0.5943783671919405; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5700955022173426; train accuracy : 0.981024814895133; \n",
      " validation loss : 0.5935034769063914; validation accuracy : 0.9623430962343096\n",
      "Epoch 37:\t train loss : 0.569187682326111; train accuracy : 0.9818674680132594; \n",
      " validation loss : 0.6243909797791808; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5675132975147263; train accuracy : 0.9836333219740389; \n",
      " validation loss : 0.611620969429222; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5649783717731003; train accuracy : 0.986282102915208; \n",
      " validation loss : 0.6054356495035633; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5639221373000264; train accuracy : 0.9874996127513244; \n",
      " validation loss : 0.6077571415663057; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5656139050262072; train accuracy : 0.9855602713838719; \n",
      " validation loss : 0.5988587835206631; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.560898392659103; train accuracy : 0.9903931348554788; \n",
      " validation loss : 0.6041049489950266; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5624509088182789; train accuracy : 0.9887821803649431; \n",
      " validation loss : 0.6109350725578148; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.57427558333791; train accuracy : 0.9767929613680721; \n",
      " validation loss : 0.6016053038265544; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.5623002338072836; train accuracy : 0.9888937079835187; \n",
      " validation loss : 0.5912951593272971; validation accuracy : 0.9623430962343096\n",
      "Epoch 46:\t train loss : 0.5620327513123419; train accuracy : 0.9890486074537626; \n",
      " validation loss : 0.5968034261318524; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5767542535016226; train accuracy : 0.9743331577806004; \n",
      " validation loss : 0.612905405907065; validation accuracy : 0.9372384937238494\n",
      "Epoch 48:\t train loss : 0.566765437749293; train accuracy : 0.9843179776325165; \n",
      " validation loss : 0.5815775806794721; validation accuracy : 0.9707112970711297\n",
      "Epoch 49:\t train loss : 0.5626365028345053; train accuracy : 0.9885126552867189; \n",
      " validation loss : 0.6121426690969968; validation accuracy : 0.9330543933054394\n",
      "Epoch 50:\t train loss : 0.5631176010068071; train accuracy : 0.9881966603674215; \n",
      " validation loss : 0.5938338012437144; validation accuracy : 0.9581589958158996\n",
      "Epoch 51:\t train loss : 0.5607370706886186; train accuracy : 0.9904024288236934; \n",
      " validation loss : 0.586423303003269; validation accuracy : 0.9665271966527197\n",
      "Epoch 52:\t train loss : 0.5580883773221872; train accuracy : 0.9931968152668917; \n",
      " validation loss : 0.5926873070373553; validation accuracy : 0.9581589958158996\n",
      "Epoch 53:\t train loss : 0.5564453919612972; train accuracy : 0.9949347873230273; \n",
      " validation loss : 0.5963627612320712; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5570681406669054; train accuracy : 0.9941819758976425; \n",
      " validation loss : 0.6001923886639184; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5593328161708642; train accuracy : 0.9919978933672047; \n",
      " validation loss : 0.6128908799769528; validation accuracy : 0.9372384937238494\n",
      "Epoch 56:\t train loss : 0.5608586740254798; train accuracy : 0.9903993308342885; \n",
      " validation loss : 0.6117144999928928; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5612128728933694; train accuracy : 0.9901205117878497; \n",
      " validation loss : 0.6108070669138511; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5628972910874527; train accuracy : 0.9882957960283776; \n",
      " validation loss : 0.5955327810175293; validation accuracy : 0.9539748953974896\n",
      "Epoch 59:\t train loss : 0.5773419187598887; train accuracy : 0.9735989342916447; \n",
      " validation loss : 0.6011770534556536; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5623243523890602; train accuracy : 0.9887573964497042; \n",
      " validation loss : 0.5983602804891188; validation accuracy : 0.9539748953974896\n",
      "Epoch 61:\t train loss : 0.5577559595957691; train accuracy : 0.9934291644722575; \n",
      " validation loss : 0.5961921640333077; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5633307934206672; train accuracy : 0.9878249016388364; \n",
      " validation loss : 0.6073620906246812; validation accuracy : 0.9414225941422594\n",
      "Epoch 63:\t train loss : 0.5642270297106224; train accuracy : 0.9870380123299978; \n",
      " validation loss : 0.6069801861306449; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5563618505485219; train accuracy : 0.9950463149416029; \n",
      " validation loss : 0.6046918040742353; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.557286689946015; train accuracy : 0.9940642523002571; \n",
      " validation loss : 0.5991654078761615; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66:\t train loss : 0.5579809554083253; train accuracy : 0.9933238328324917; \n",
      " validation loss : 0.6082287263887267; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5652317636612931; train accuracy : 0.9860094798475789; \n",
      " validation loss : 0.6079729172780182; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5561286633045491; train accuracy : 0.9952600762105394; \n",
      " validation loss : 0.5890300978455828; validation accuracy : 0.9623430962343096\n",
      "Epoch 69:\t train loss : 0.5578284108362123; train accuracy : 0.993543790080238; \n",
      " validation loss : 0.6024828876879512; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5589922360077457; train accuracy : 0.9921527928374485; \n",
      " validation loss : 0.594020013789701; validation accuracy : 0.9581589958158996\n",
      "Epoch 71:\t train loss : 0.5578485011757077; train accuracy : 0.9935499860590477; \n",
      " validation loss : 0.6131756438497187; validation accuracy : 0.9372384937238494\n",
      "Epoch 72:\t train loss : 0.5600834015522393; train accuracy : 0.9911924161219369; \n",
      " validation loss : 0.6024473530435824; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5623819601262167; train accuracy : 0.9888534341212553; \n",
      " validation loss : 0.6106320339952493; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5587340895505778; train accuracy : 0.9925214535766288; \n",
      " validation loss : 0.6049468892219246; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.586293192779501; train accuracy : 0.9644412776108305; \n",
      " validation loss : 0.618014733836122; validation accuracy : 0.9330543933054394\n",
      "Epoch 76:\t train loss : 0.5792890512560845; train accuracy : 0.9715511632950216; \n",
      " validation loss : 0.600836973480199; validation accuracy : 0.9497907949790795\n",
      "Epoch 77:\t train loss : 0.5584144969428845; train accuracy : 0.9929056042628334; \n",
      " validation loss : 0.6005596125874576; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5586131549542741; train accuracy : 0.9927352148455653; \n",
      " validation loss : 0.5989496867178191; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5578294279316915; train accuracy : 0.9935097121967843; \n",
      " validation loss : 0.5994988651009553; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5573929589968716; train accuracy : 0.9939031568512036; \n",
      " validation loss : 0.5871093543124196; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5554063906828792; train accuracy : 0.9959881037206852; \n",
      " validation loss : 0.5970038967484194; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5561863610329217; train accuracy : 0.9951733325072029; \n",
      " validation loss : 0.6071936026998931; validation accuracy : 0.9456066945606695\n",
      "Epoch 83:\t train loss : 0.5580339274818825; train accuracy : 0.9933455187583259; \n",
      " validation loss : 0.5929842169681142; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5556566898019804; train accuracy : 0.995817714303417; \n",
      " validation loss : 0.5910960087382346; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5568363267483007; train accuracy : 0.9944607949440812; \n",
      " validation loss : 0.6211561690273761; validation accuracy : 0.9288702928870293\n",
      "Epoch 86:\t train loss : 0.5606160444726012; train accuracy : 0.9906719539019176; \n",
      " validation loss : 0.5882373465015829; validation accuracy : 0.9623430962343096\n",
      "Epoch 87:\t train loss : 0.5594491654923803; train accuracy : 0.9919545215155364; \n",
      " validation loss : 0.5919902842531316; validation accuracy : 0.9581589958158996\n",
      "Epoch 88:\t train loss : 0.5582857007371851; train accuracy : 0.9930171318814089; \n",
      " validation loss : 0.6055552638426391; validation accuracy : 0.9456066945606695\n",
      "Epoch 89:\t train loss : 0.559394707065768; train accuracy : 0.9918615818333901; \n",
      " validation loss : 0.5826813203264322; validation accuracy : 0.9665271966527197\n",
      "Epoch 90:\t train loss : 0.5610943541871964; train accuracy : 0.9900988258620156; \n",
      " validation loss : 0.5915101224406294; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.559362967645626; train accuracy : 0.9919731094519657; \n",
      " validation loss : 0.602431404699902; validation accuracy : 0.9497907949790795\n",
      "Epoch 92:\t train loss : 0.5577592333875965; train accuracy : 0.993565476006072; \n",
      " validation loss : 0.615105860647504; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5870390818573015; train accuracy : 0.964131478670343; \n",
      " validation loss : 0.5933912405047643; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5579605565524223; train accuracy : 0.993391988599399; \n",
      " validation loss : 0.5901932877065751; validation accuracy : 0.9581589958158996\n",
      "Epoch 95:\t train loss : 0.5578050974078818; train accuracy : 0.9935716719848818; \n",
      " validation loss : 0.6018216552786312; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5577347464429104; train accuracy : 0.9936615136776232; \n",
      " validation loss : 0.5989747945487143; validation accuracy : 0.9497907949790795\n",
      "Epoch 97:\t train loss : 0.5709977357151459; train accuracy : 0.9801945537346263; \n",
      " validation loss : 0.6182827595038597; validation accuracy : 0.9330543933054394\n",
      "Epoch 98:\t train loss : 0.5605731043986254; train accuracy : 0.9908702252238297; \n",
      " validation loss : 0.5991678062437448; validation accuracy : 0.9539748953974896\n",
      "Early stopping at epoch 98\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.566765437749293; Train accuracy : 0.9843179776325165; \n",
      " Validation loss : 0.5815775806794721; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 57 ! ---\n",
      "Epoch 1:\t train loss : 0.9450238301763997; train accuracy : 0.5790625484060844; \n",
      " validation loss : 0.8230944506669827; validation accuracy : 0.7238493723849372\n",
      "Epoch 2:\t train loss : 0.755861982223722; train accuracy : 0.7942604169893739; \n",
      " validation loss : 0.70937764016244; validation accuracy : 0.8368200836820083\n",
      "Epoch 3:\t train loss : 0.7018511270529466; train accuracy : 0.847617584187862; \n",
      " validation loss : 0.7050680225970578; validation accuracy : 0.8368200836820083\n",
      "Epoch 4:\t train loss : 0.6889106563727272; train accuracy : 0.8608459989466836; \n",
      " validation loss : 0.6747855055593082; validation accuracy : 0.8702928870292888\n",
      "Epoch 5:\t train loss : 0.6654810254614669; train accuracy : 0.8849647139006784; \n",
      " validation loss : 0.6798454256598127; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6515186601679342; train accuracy : 0.8990732054896372; \n",
      " validation loss : 0.6792329955001513; validation accuracy : 0.8702928870292888\n",
      "Epoch 7:\t train loss : 0.6415725876200176; train accuracy : 0.9082951764304966; \n",
      " validation loss : 0.6695605548982334; validation accuracy : 0.8744769874476988\n",
      "Epoch 8:\t train loss : 0.62467696512225; train accuracy : 0.9259181511199231; \n",
      " validation loss : 0.6646936179545895; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6176327876890151; train accuracy : 0.9335721676631866; \n",
      " validation loss : 0.6475332941976318; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.6117093646594558; train accuracy : 0.9390126088168779; \n",
      " validation loss : 0.648787582334907; validation accuracy : 0.895397489539749\n",
      "Epoch 11:\t train loss : 0.6057339801898809; train accuracy : 0.9453743920195793; \n",
      " validation loss : 0.6342045270972793; validation accuracy : 0.9163179916317992\n",
      "Epoch 12:\t train loss : 0.6020289460584631; train accuracy : 0.9492841785681093; \n",
      " validation loss : 0.618926956145391; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.5943118557901709; train accuracy : 0.9567348430868367; \n",
      " validation loss : 0.6404572133540181; validation accuracy : 0.9037656903765691\n",
      "Epoch 14:\t train loss : 0.5875377127248294; train accuracy : 0.9638447287710276; \n",
      " validation loss : 0.6370130437374917; validation accuracy : 0.9121338912133892\n",
      "Epoch 15:\t train loss : 0.5953876809434143; train accuracy : 0.9555868521329657; \n",
      " validation loss : 0.6244897986992917; validation accuracy : 0.9246861924686193\n",
      "Epoch 16:\t train loss : 0.590722830273769; train accuracy : 0.9604214504786394; \n",
      " validation loss : 0.6281977782100803; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.5806955829752152; train accuracy : 0.9707942625236221; \n",
      " validation loss : 0.6339291106655067; validation accuracy : 0.9121338912133892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:\t train loss : 0.5856806210429283; train accuracy : 0.9652187490318783; \n",
      " validation loss : 0.6370136791653928; validation accuracy : 0.9079497907949791\n",
      "Epoch 19:\t train loss : 0.579776052839654; train accuracy : 0.9717919390315685; \n",
      " validation loss : 0.6124881100774128; validation accuracy : 0.9372384937238494\n",
      "Epoch 20:\t train loss : 0.582624719641917; train accuracy : 0.9684188481675393; \n",
      " validation loss : 0.6223942844348271; validation accuracy : 0.9163179916317992\n",
      "Epoch 21:\t train loss : 0.5948619050145367; train accuracy : 0.9561981474023359; \n",
      " validation loss : 0.6413786459353186; validation accuracy : 0.9121338912133892\n",
      "Epoch 22:\t train loss : 0.5881436226106357; train accuracy : 0.9629262368722699; \n",
      " validation loss : 0.6334972067745507; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.5850638172245256; train accuracy : 0.9661326559063168; \n",
      " validation loss : 0.6409950531662525; validation accuracy : 0.9037656903765691\n",
      "Epoch 24:\t train loss : 0.5761318103096892; train accuracy : 0.9751934074785464; \n",
      " validation loss : 0.6208252925799473; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5810062697892114; train accuracy : 0.9702977167818087; \n",
      " validation loss : 0.6255484774448191; validation accuracy : 0.9246861924686193\n",
      "Epoch 26:\t train loss : 0.5764163670072205; train accuracy : 0.9751113727191053; \n",
      " validation loss : 0.6049272946596866; validation accuracy : 0.9497907949790795\n",
      "Epoch 27:\t train loss : 0.5783419340400564; train accuracy : 0.9730038724867561; \n",
      " validation loss : 0.6229633372305335; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.5755830487209971; train accuracy : 0.975683633321974; \n",
      " validation loss : 0.6254689944145273; validation accuracy : 0.9246861924686193\n",
      "Epoch 29:\t train loss : 0.5889627529611787; train accuracy : 0.9615166516930512; \n",
      " validation loss : 0.6075430928240569; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.5706424612531856; train accuracy : 0.9806513212924812; \n",
      " validation loss : 0.6126192803119727; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5740613333287157; train accuracy : 0.9775014095851792; \n",
      " validation loss : 0.6236274632878823; validation accuracy : 0.9246861924686193\n",
      "Epoch 32:\t train loss : 0.5748850538886606; train accuracy : 0.9763560209424084; \n",
      " validation loss : 0.6219907020111614; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5743713749974217; train accuracy : 0.9769802038477028; \n",
      " validation loss : 0.6329904092708801; validation accuracy : 0.9205020920502092\n",
      "Epoch 34:\t train loss : 0.5728015820966639; train accuracy : 0.9785300659871743; \n",
      " validation loss : 0.6263488937173767; validation accuracy : 0.9205020920502092\n",
      "Epoch 35:\t train loss : 0.5741498315888202; train accuracy : 0.9768370767371976; \n",
      " validation loss : 0.6141580391658783; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.5728154084603977; train accuracy : 0.9782813593977508; \n",
      " validation loss : 0.6100063162441418; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5729751025440449; train accuracy : 0.9782202670466867; \n",
      " validation loss : 0.6252604724764276; validation accuracy : 0.9246861924686193\n",
      "Epoch 38:\t train loss : 0.5715297958249395; train accuracy : 0.9795214225967347; \n",
      " validation loss : 0.62911809620409; validation accuracy : 0.9205020920502092\n",
      "Epoch 39:\t train loss : 0.5688057958921863; train accuracy : 0.9825210198581121; \n",
      " validation loss : 0.6252923425142313; validation accuracy : 0.9246861924686193\n",
      "Epoch 40:\t train loss : 0.5774760664976109; train accuracy : 0.973664487747452; \n",
      " validation loss : 0.590492375185047; validation accuracy : 0.9623430962343096\n",
      "Epoch 41:\t train loss : 0.5702247528412887; train accuracy : 0.9811688094426717; \n",
      " validation loss : 0.592853915775326; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.5766697378089385; train accuracy : 0.9746730691781034; \n",
      " validation loss : 0.6110002343641449; validation accuracy : 0.9372384937238494\n",
      "Epoch 43:\t train loss : 0.5690841408304934; train accuracy : 0.9823606679265157; \n",
      " validation loss : 0.6086463068140651; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5675688983271607; train accuracy : 0.9836007311254995; \n",
      " validation loss : 0.6211886311149832; validation accuracy : 0.9288702928870293\n",
      "Epoch 45:\t train loss : 0.5668992247588422; train accuracy : 0.9844317358034635; \n",
      " validation loss : 0.6013578380280952; validation accuracy : 0.9456066945606695\n",
      "Epoch 46:\t train loss : 0.5681899222282422; train accuracy : 0.9828982310480499; \n",
      " validation loss : 0.5968364701421252; validation accuracy : 0.9581589958158996\n",
      "Epoch 47:\t train loss : 0.5778923186297764; train accuracy : 0.9730549273521485; \n",
      " validation loss : 0.6472644145016143; validation accuracy : 0.899581589958159\n",
      "Epoch 48:\t train loss : 0.5794101482666395; train accuracy : 0.9713728430248768; \n",
      " validation loss : 0.6512629602771773; validation accuracy : 0.899581589958159\n",
      "Epoch 49:\t train loss : 0.5825098316058537; train accuracy : 0.9681572539421915; \n",
      " validation loss : 0.5888167250247179; validation accuracy : 0.9581589958158996\n",
      "Epoch 50:\t train loss : 0.5646077248249413; train accuracy : 0.9867707178041452; \n",
      " validation loss : 0.6242461076605768; validation accuracy : 0.9205020920502092\n",
      "Epoch 51:\t train loss : 0.5647207835774751; train accuracy : 0.9865119737290499; \n",
      " validation loss : 0.6029517892754469; validation accuracy : 0.9456066945606695\n",
      "Epoch 52:\t train loss : 0.5653786134939864; train accuracy : 0.9858003036029617; \n",
      " validation loss : 0.603111140136066; validation accuracy : 0.9497907949790795\n",
      "Epoch 53:\t train loss : 0.5712766075705675; train accuracy : 0.9797428668793953; \n",
      " validation loss : 0.6137090296365523; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5780572448489756; train accuracy : 0.9730047399237894; \n",
      " validation loss : 0.6266896716594974; validation accuracy : 0.9246861924686193\n",
      "Epoch 55:\t train loss : 0.5700620865346443; train accuracy : 0.9809820626413458; \n",
      " validation loss : 0.6166916519720487; validation accuracy : 0.9288702928870293\n",
      "Epoch 56:\t train loss : 0.5661152662844315; train accuracy : 0.9849583940022925; \n",
      " validation loss : 0.608890085386207; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5662433460205754; train accuracy : 0.9849328665695963; \n",
      " validation loss : 0.6036412128747701; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5693677910264938; train accuracy : 0.9819014219771368; \n",
      " validation loss : 0.6225855657421807; validation accuracy : 0.9288702928870293\n",
      "Epoch 59:\t train loss : 0.5664287971382775; train accuracy : 0.9847105548499024; \n",
      " validation loss : 0.5884479491291288; validation accuracy : 0.9665271966527197\n",
      "Epoch 60:\t train loss : 0.5647429601537277; train accuracy : 0.9864454289166331; \n",
      " validation loss : 0.5982172534481536; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5678015925618083; train accuracy : 0.9834240218098455; \n",
      " validation loss : 0.6005858035494084; validation accuracy : 0.9456066945606695\n",
      "Epoch 62:\t train loss : 0.5760249251523227; train accuracy : 0.9747660088602497; \n",
      " validation loss : 0.6055008186788122; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5652251077553755; train accuracy : 0.9860016729142786; \n",
      " validation loss : 0.620973492472571; validation accuracy : 0.9288702928870293\n",
      "Epoch 64:\t train loss : 0.5689357087969863; train accuracy : 0.9821547135908795; \n",
      " validation loss : 0.615690011662761; validation accuracy : 0.9330543933054394\n",
      "Epoch 65:\t train loss : 0.5639533412766075; train accuracy : 0.987374825738096; \n",
      " validation loss : 0.6019699622314119; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5654991485321298; train accuracy : 0.9856454041327178; \n",
      " validation loss : 0.6190500879864381; validation accuracy : 0.9288702928870293\n",
      "Epoch 67:\t train loss : 0.562906344869122; train accuracy : 0.988241395334428; \n",
      " validation loss : 0.6593353583442177; validation accuracy : 0.891213389121339\n",
      "Epoch 68:\t train loss : 0.5778623122882011; train accuracy : 0.9731605068310666; \n",
      " validation loss : 0.604724517585797; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:\t train loss : 0.563579927781148; train accuracy : 0.987714737135599; \n",
      " validation loss : 0.5971355709728463; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5627696460565546; train accuracy : 0.9885985315530221; \n",
      " validation loss : 0.6021478285639928; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5625979986067057; train accuracy : 0.9887178661048979; \n",
      " validation loss : 0.6163561865638633; validation accuracy : 0.9288702928870293\n",
      "Epoch 72:\t train loss : 0.5669362450722049; train accuracy : 0.9843078162272685; \n",
      " validation loss : 0.6160727209279101; validation accuracy : 0.9330543933054394\n",
      "Epoch 73:\t train loss : 0.567105802748904; train accuracy : 0.9841265218872951; \n",
      " validation loss : 0.6205871232133953; validation accuracy : 0.9330543933054394\n",
      "Epoch 74:\t train loss : 0.5614699020441989; train accuracy : 0.9898996871030701; \n",
      " validation loss : 0.5931925313786611; validation accuracy : 0.9581589958158996\n",
      "Epoch 75:\t train loss : 0.5674029128990309; train accuracy : 0.9838531553022088; \n",
      " validation loss : 0.6027854350066366; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5639426973878374; train accuracy : 0.9872973760029741; \n",
      " validation loss : 0.5991259205624319; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5642803775847756; train accuracy : 0.9869511447070851; \n",
      " validation loss : 0.614162608070585; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5892384909570786; train accuracy : 0.9613390749403637; \n",
      " validation loss : 0.6377183171035584; validation accuracy : 0.9121338912133892\n",
      "Epoch 79:\t train loss : 0.5767147833411385; train accuracy : 0.9742648780941169; \n",
      " validation loss : 0.6228407756785446; validation accuracy : 0.9246861924686193\n",
      "Epoch 80:\t train loss : 0.5675827402353957; train accuracy : 0.98357433625577; \n",
      " validation loss : 0.59314658804317; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.5620797812552805; train accuracy : 0.9893110691161436; \n",
      " validation loss : 0.6113128691319958; validation accuracy : 0.9372384937238494\n",
      "Epoch 82:\t train loss : 0.5602897618166746; train accuracy : 0.9909475510393755; \n",
      " validation loss : 0.6075550592575225; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5629494140272201; train accuracy : 0.9884181046500821; \n",
      " validation loss : 0.6052156705644284; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5620582223299129; train accuracy : 0.9892955791691193; \n",
      " validation loss : 0.5785998369181254; validation accuracy : 0.9707112970711297\n",
      "Epoch 85:\t train loss : 0.5626168791426271; train accuracy : 0.9884800644381796; \n",
      " validation loss : 0.5835976406402664; validation accuracy : 0.9665271966527197\n",
      "Epoch 86:\t train loss : 0.5646764709385343; train accuracy : 0.986600328386877; \n",
      " validation loss : 0.6190664315480706; validation accuracy : 0.9330543933054394\n",
      "Epoch 87:\t train loss : 0.5626044926771528; train accuracy : 0.9887333560519223; \n",
      " validation loss : 0.5915275931799909; validation accuracy : 0.9581589958158996\n",
      "Epoch 88:\t train loss : 0.5636059007789834; train accuracy : 0.9877110195483132; \n",
      " validation loss : 0.5958672619393475; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5631010681237596; train accuracy : 0.9881174757582329; \n",
      " validation loss : 0.5912234567643235; validation accuracy : 0.9581589958158996\n",
      "Epoch 90:\t train loss : 0.5746084792967221; train accuracy : 0.9762576287989095; \n",
      " validation loss : 0.6178452978750869; validation accuracy : 0.9372384937238494\n",
      "Epoch 91:\t train loss : 0.5728900545959396; train accuracy : 0.9782767743734316; \n",
      " validation loss : 0.6226217201462952; validation accuracy : 0.9246861924686193\n",
      "Epoch 92:\t train loss : 0.5659836924651944; train accuracy : 0.9851807057219865; \n",
      " validation loss : 0.6147772830139036; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5607360739388103; train accuracy : 0.9905766597478236; \n",
      " validation loss : 0.6012653856095821; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5602367175498963; train accuracy : 0.9911807676817745; \n",
      " validation loss : 0.5995405797281766; validation accuracy : 0.9497907949790795\n",
      "Epoch 95:\t train loss : 0.5618415248822111; train accuracy : 0.9894249512066668; \n",
      " validation loss : 0.5991115252583142; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5601316587836738; train accuracy : 0.9911962576287989; \n",
      " validation loss : 0.6151054788596685; validation accuracy : 0.9372384937238494\n",
      "Epoch 97:\t train loss : 0.5646162928499509; train accuracy : 0.9867288329873912; \n",
      " validation loss : 0.616422664617528; validation accuracy : 0.9372384937238494\n",
      "Epoch 98:\t train loss : 0.5625614904002201; train accuracy : 0.9886604913411197; \n",
      " validation loss : 0.607352048754259; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5601080555928668; train accuracy : 0.9911908051674463; \n",
      " validation loss : 0.6041530886554404; validation accuracy : 0.9456066945606695\n",
      "Epoch 100:\t train loss : 0.5645361221712; train accuracy : 0.9868008302611605; \n",
      " validation loss : 0.6305642532857683; validation accuracy : 0.9205020920502092\n",
      "Epoch 101:\t train loss : 0.5659059924729423; train accuracy : 0.9852836828898045; \n",
      " validation loss : 0.5954285432600238; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.5632921039726475; train accuracy : 0.9879743486477276; \n",
      " validation loss : 0.59655480829289; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5599264976469216; train accuracy : 0.9914286068341647; \n",
      " validation loss : 0.6065697989458398; validation accuracy : 0.9456066945606695\n",
      "Epoch 104:\t train loss : 0.5629125294753969; train accuracy : 0.9883452399392794; \n",
      " validation loss : 0.6032325043249832; validation accuracy : 0.9497907949790795\n",
      "Epoch 105:\t train loss : 0.5614810068033453; train accuracy : 0.9897866724495802; \n",
      " validation loss : 0.5845702834993033; validation accuracy : 0.9665271966527197\n",
      "Epoch 106:\t train loss : 0.5628678656140846; train accuracy : 0.9884080671644103; \n",
      " validation loss : 0.6050119200923127; validation accuracy : 0.9456066945606695\n",
      "Epoch 107:\t train loss : 0.5596941163056137; train accuracy : 0.9916454660925059; \n",
      " validation loss : 0.5981698960028666; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5610125680729038; train accuracy : 0.9902823507543604; \n",
      " validation loss : 0.6192961648116899; validation accuracy : 0.9288702928870293\n",
      "Epoch 109:\t train loss : 0.594663944989445; train accuracy : 0.956212150314446; \n",
      " validation loss : 0.743520293274756; validation accuracy : 0.8075313807531381\n",
      "Epoch 110:\t train loss : 0.6419360961247139; train accuracy : 0.907964435081632; \n",
      " validation loss : 0.6830772275748703; validation accuracy : 0.8619246861924686\n",
      "Epoch 111:\t train loss : 0.5863162165067283; train accuracy : 0.964309427181759; \n",
      " validation loss : 0.6302453007045604; validation accuracy : 0.9163179916317992\n",
      "Epoch 112:\t train loss : 0.5706444681151445; train accuracy : 0.9804562718795502; \n",
      " validation loss : 0.6250637515260619; validation accuracy : 0.9288702928870293\n",
      "Epoch 113:\t train loss : 0.5674045307586024; train accuracy : 0.983864060224914; \n",
      " validation loss : 0.6096331397483093; validation accuracy : 0.9372384937238494\n",
      "Epoch 114:\t train loss : 0.5704599756370232; train accuracy : 0.9808426531181264; \n",
      " validation loss : 0.6385550326696644; validation accuracy : 0.9121338912133892\n",
      "Epoch 115:\t train loss : 0.5690126678841992; train accuracy : 0.9821291861581833; \n",
      " validation loss : 0.6191355097372717; validation accuracy : 0.9288702928870293\n",
      "Epoch 116:\t train loss : 0.5666158349964848; train accuracy : 0.984642275163419; \n",
      " validation loss : 0.6020091884918649; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5650306525047673; train accuracy : 0.9862021747885622; \n",
      " validation loss : 0.607249087235977; validation accuracy : 0.9414225941422594\n",
      "Epoch 118:\t train loss : 0.5635303031980405; train accuracy : 0.9877101521112798; \n",
      " validation loss : 0.6059666354153468; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5668600479205891; train accuracy : 0.9843752284767187; \n",
      " validation loss : 0.604346237613385; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120:\t train loss : 0.5650590201200879; train accuracy : 0.986197589764243; \n",
      " validation loss : 0.6005384743684389; validation accuracy : 0.9539748953974896\n",
      "Epoch 121:\t train loss : 0.5632887238252766; train accuracy : 0.9879688961863751; \n",
      " validation loss : 0.606930683681071; validation accuracy : 0.9414225941422594\n",
      "Epoch 122:\t train loss : 0.5638162584693209; train accuracy : 0.9875397626940116; \n",
      " validation loss : 0.6121218706884464; validation accuracy : 0.9372384937238494\n",
      "Epoch 123:\t train loss : 0.562416555395444; train accuracy : 0.9889803277672791; \n",
      " validation loss : 0.5904571320067976; validation accuracy : 0.9623430962343096\n",
      "Epoch 124:\t train loss : 0.5638335991965808; train accuracy : 0.9873857306608012; \n",
      " validation loss : 0.6136028623693102; validation accuracy : 0.9414225941422594\n",
      "Epoch 125:\t train loss : 0.5685846425633234; train accuracy : 0.9826030546175533; \n",
      " validation loss : 0.603068385452461; validation accuracy : 0.9497907949790795\n",
      "Epoch 126:\t train loss : 0.5654336043240322; train accuracy : 0.9857437962762168; \n",
      " validation loss : 0.5971470302069387; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.5675688363420464; train accuracy : 0.9837074258806034; \n",
      " validation loss : 0.6067612412744345; validation accuracy : 0.9456066945606695\n",
      "Epoch 128:\t train loss : 0.5664279148001257; train accuracy : 0.9847980420706961; \n",
      " validation loss : 0.5968380748122019; validation accuracy : 0.9539748953974896\n",
      "Epoch 129:\t train loss : 0.5633161615011115; train accuracy : 0.9880199510517674; \n",
      " validation loss : 0.5984874546275664; validation accuracy : 0.9539748953974896\n",
      "Epoch 130:\t train loss : 0.5633442693242142; train accuracy : 0.9878851265528672; \n",
      " validation loss : 0.601895758352451; validation accuracy : 0.9497907949790795\n",
      "Epoch 131:\t train loss : 0.5630599817238423; train accuracy : 0.9881438706279625; \n",
      " validation loss : 0.6038347131881936; validation accuracy : 0.9456066945606695\n",
      "Epoch 132:\t train loss : 0.5618746678290201; train accuracy : 0.9894869109947644; \n",
      " validation loss : 0.5996018033031195; validation accuracy : 0.9539748953974896\n",
      "Epoch 133:\t train loss : 0.5636038568540566; train accuracy : 0.9876946621642554; \n",
      " validation loss : 0.5987718294182712; validation accuracy : 0.9539748953974896\n",
      "Epoch 134:\t train loss : 0.5612012238135939; train accuracy : 0.9900345116019703; \n",
      " validation loss : 0.5939869606458753; validation accuracy : 0.9539748953974896\n",
      "Early stopping at epoch 134\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5620582223299129; Train accuracy : 0.9892955791691193; \n",
      " Validation loss : 0.5785998369181254; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 58 ! ---\n",
      "Epoch 1:\t train loss : 0.9573391723643889; train accuracy : 0.5619814740233589; \n",
      " validation loss : 0.8421275193292528; validation accuracy : 0.6903765690376569\n",
      "Epoch 2:\t train loss : 0.7840090325043871; train accuracy : 0.7632017720499396; \n",
      " validation loss : 0.7813936025815876; validation accuracy : 0.7615062761506276\n",
      "Epoch 3:\t train loss : 0.7162493645671668; train accuracy : 0.833453018990675; \n",
      " validation loss : 0.7269266167850252; validation accuracy : 0.8368200836820083\n",
      "Epoch 4:\t train loss : 0.6871327563625146; train accuracy : 0.8632519594782986; \n",
      " validation loss : 0.7077868203203669; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.675734261763433; train accuracy : 0.8746953127420304; \n",
      " validation loss : 0.6873542000667904; validation accuracy : 0.8577405857740585\n",
      "Epoch 6:\t train loss : 0.6604874597869805; train accuracy : 0.8898076148579572; \n",
      " validation loss : 0.6633815514860382; validation accuracy : 0.8870292887029289\n",
      "Epoch 7:\t train loss : 0.6491272762273165; train accuracy : 0.9012023296880325; \n",
      " validation loss : 0.6583850712848436; validation accuracy : 0.895397489539749\n",
      "Epoch 8:\t train loss : 0.6388058100608787; train accuracy : 0.9118578642461043; \n",
      " validation loss : 0.6605213945170528; validation accuracy : 0.8870292887029289\n",
      "Epoch 9:\t train loss : 0.6332216951300034; train accuracy : 0.9175485609839215; \n",
      " validation loss : 0.6285251967059864; validation accuracy : 0.9246861924686193\n",
      "Epoch 10:\t train loss : 0.6249704714053891; train accuracy : 0.9260060720592336; \n",
      " validation loss : 0.6396027040525406; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.6105036345518633; train accuracy : 0.9407717091607547; \n",
      " validation loss : 0.636228182487909; validation accuracy : 0.9163179916317992\n",
      "Epoch 12:\t train loss : 0.6238954507311796; train accuracy : 0.9267533071036897; \n",
      " validation loss : 0.6385490647964603; validation accuracy : 0.9163179916317992\n",
      "Epoch 13:\t train loss : 0.6032063949376426; train accuracy : 0.9480615880293689; \n",
      " validation loss : 0.6438556441483496; validation accuracy : 0.9037656903765691\n",
      "Epoch 14:\t train loss : 0.5924336571547208; train accuracy : 0.959135351157099; \n",
      " validation loss : 0.6233688981289358; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5905789668123513; train accuracy : 0.9610619907679916; \n",
      " validation loss : 0.6087823845229187; validation accuracy : 0.9414225941422594\n",
      "Epoch 16:\t train loss : 0.5930525105182318; train accuracy : 0.9579522290033768; \n",
      " validation loss : 0.6407333109321893; validation accuracy : 0.9079497907949791\n",
      "Epoch 17:\t train loss : 0.586266060543703; train accuracy : 0.9649595712382664; \n",
      " validation loss : 0.6050279989266772; validation accuracy : 0.9539748953974896\n",
      "Epoch 18:\t train loss : 0.5841294719345639; train accuracy : 0.9671126738746554; \n",
      " validation loss : 0.6319378048063395; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.5851896463721651; train accuracy : 0.9659701353821369; \n",
      " validation loss : 0.6281676350828227; validation accuracy : 0.9205020920502092\n",
      "Epoch 20:\t train loss : 0.5842143854766981; train accuracy : 0.9668028749341677; \n",
      " validation loss : 0.6140691866314278; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5849436842004; train accuracy : 0.9661736732860373; \n",
      " validation loss : 0.617751833656101; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.584008904495278; train accuracy : 0.9669518882245423; \n",
      " validation loss : 0.6148821836459819; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5822713697040874; train accuracy : 0.9689847888720221; \n",
      " validation loss : 0.5970143520175706; validation accuracy : 0.9539748953974896\n",
      "Epoch 24:\t train loss : 0.5773602996719872; train accuracy : 0.9739747204064562; \n",
      " validation loss : 0.6075671436210296; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.5757391805533529; train accuracy : 0.9755989962514329; \n",
      " validation loss : 0.6151793393021552; validation accuracy : 0.9330543933054394\n",
      "Epoch 26:\t train loss : 0.5804203751232349; train accuracy : 0.9709328046098082; \n",
      " validation loss : 0.6094259577495857; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.578348735888949; train accuracy : 0.973066699711887; \n",
      " validation loss : 0.603482475431225; validation accuracy : 0.9456066945606695\n",
      "Epoch 28:\t train loss : 0.5845769059515783; train accuracy : 0.9665491496019084; \n",
      " validation loss : 0.6324676172009993; validation accuracy : 0.9163179916317992\n",
      "Epoch 29:\t train loss : 0.5752737181119782; train accuracy : 0.975994299699495; \n",
      " validation loss : 0.5989289181684099; validation accuracy : 0.9497907949790795\n",
      "Epoch 30:\t train loss : 0.5745104942463697; train accuracy : 0.9765519377923727; \n",
      " validation loss : 0.6215245478865894; validation accuracy : 0.9288702928870293\n",
      "Epoch 31:\t train loss : 0.5740529129724257; train accuracy : 0.9771870256203724; \n",
      " validation loss : 0.6102882995202398; validation accuracy : 0.9288702928870293\n",
      "Epoch 32:\t train loss : 0.5754229244645215; train accuracy : 0.9758276278695127; \n",
      " validation loss : 0.6142606195687493; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5733805579092649; train accuracy : 0.9778781870566002; \n",
      " validation loss : 0.6026118111960043; validation accuracy : 0.9497907949790795\n",
      "Epoch 34:\t train loss : 0.573289161215118; train accuracy : 0.9778413209826823; \n",
      " validation loss : 0.6221368129575509; validation accuracy : 0.9246861924686193\n",
      "Epoch 35:\t train loss : 0.5685017828423504; train accuracy : 0.9830171318814089; \n",
      " validation loss : 0.5882085935901706; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36:\t train loss : 0.5703098450298217; train accuracy : 0.9808020694569225; \n",
      " validation loss : 0.6061190013251714; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.5723718622791955; train accuracy : 0.9787360203228105; \n",
      " validation loss : 0.6014222216418175; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5677142563495274; train accuracy : 0.9836986895504818; \n",
      " validation loss : 0.6026677139165149; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5711889585085831; train accuracy : 0.9800430620527277; \n",
      " validation loss : 0.5975807992144927; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5673628066896832; train accuracy : 0.9837451593915548; \n",
      " validation loss : 0.6020123647255461; validation accuracy : 0.9539748953974896\n",
      "Epoch 41:\t train loss : 0.5682767681359373; train accuracy : 0.9832185011927259; \n",
      " validation loss : 0.5977782846755684; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5644586644719751; train accuracy : 0.9869419746584467; \n",
      " validation loss : 0.597650414079263; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.566440700862004; train accuracy : 0.9848700393444655; \n",
      " validation loss : 0.6028468413468484; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5729757072438183; train accuracy : 0.9781223086217045; \n",
      " validation loss : 0.6112407361249445; validation accuracy : 0.9330543933054394\n",
      "Epoch 45:\t train loss : 0.572678552100559; train accuracy : 0.9786136497413179; \n",
      " validation loss : 0.6245265638159206; validation accuracy : 0.9288702928870293\n",
      "Epoch 46:\t train loss : 0.568955887065793; train accuracy : 0.9822212584032962; \n",
      " validation loss : 0.5983897471625901; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.562991150022132; train accuracy : 0.9882409616159112; \n",
      " validation loss : 0.6151065096877876; validation accuracy : 0.9330543933054394\n",
      "Epoch 48:\t train loss : 0.5686329018958016; train accuracy : 0.982366554106385; \n",
      " validation loss : 0.6028763787122718; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.5680390048391507; train accuracy : 0.9833114408748722; \n",
      " validation loss : 0.5943757175310235; validation accuracy : 0.9539748953974896\n",
      "Epoch 50:\t train loss : 0.5694485441273678; train accuracy : 0.9817624461724341; \n",
      " validation loss : 0.5945947132525855; validation accuracy : 0.9539748953974896\n",
      "Epoch 51:\t train loss : 0.5641638415508428; train accuracy : 0.9870696118219275; \n",
      " validation loss : 0.5930710393597833; validation accuracy : 0.9581589958158996\n",
      "Epoch 52:\t train loss : 0.5649303511901131; train accuracy : 0.9863880541528548; \n",
      " validation loss : 0.5939003942916118; validation accuracy : 0.9539748953974896\n",
      "Epoch 53:\t train loss : 0.5622157300407729; train accuracy : 0.9888701632640416; \n",
      " validation loss : 0.5881735318723023; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5609250356502864; train accuracy : 0.9904368165060875; \n",
      " validation loss : 0.5940165476463597; validation accuracy : 0.9581589958158996\n",
      "Epoch 55:\t train loss : 0.5593787126181149; train accuracy : 0.991964435081632; \n",
      " validation loss : 0.5917880550075455; validation accuracy : 0.9581589958158996\n",
      "Epoch 56:\t train loss : 0.5670342859086783; train accuracy : 0.9840955419932463; \n",
      " validation loss : 0.6002073361347844; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5620334760716159; train accuracy : 0.9893370302673565; \n",
      " validation loss : 0.5832172093891492; validation accuracy : 0.9707112970711297\n",
      "Epoch 58:\t train loss : 0.5628993910633102; train accuracy : 0.9883611636048205; \n",
      " validation loss : 0.6017090544360009; validation accuracy : 0.9497907949790795\n",
      "Epoch 59:\t train loss : 0.5668446288203468; train accuracy : 0.9843647572725301; \n",
      " validation loss : 0.6063070352798277; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5742685191554687; train accuracy : 0.976873509092599; \n",
      " validation loss : 0.5922315691790365; validation accuracy : 0.9581589958158996\n",
      "Epoch 61:\t train loss : 0.5597314104347563; train accuracy : 0.9915734688187366; \n",
      " validation loss : 0.5939212704993024; validation accuracy : 0.9581589958158996\n",
      "Epoch 62:\t train loss : 0.5695928011559919; train accuracy : 0.981276371634809; \n",
      " validation loss : 0.5952599385185615; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.5618160000271617; train accuracy : 0.9894336875367886; \n",
      " validation loss : 0.602272942407531; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5630614166699491; train accuracy : 0.9883515598376653; \n",
      " validation loss : 0.5918988645042895; validation accuracy : 0.9581589958158996\n",
      "Epoch 65:\t train loss : 0.5694352521784081; train accuracy : 0.9816710554849902; \n",
      " validation loss : 0.6395410986949768; validation accuracy : 0.9079497907949791\n",
      "Epoch 66:\t train loss : 0.5864382654693204; train accuracy : 0.9644329130394375; \n",
      " validation loss : 0.6521379856294952; validation accuracy : 0.899581589958159\n",
      "Epoch 67:\t train loss : 0.5690983064113573; train accuracy : 0.9819793054307754; \n",
      " validation loss : 0.5969134923157299; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5661916679505857; train accuracy : 0.985069240063199; \n",
      " validation loss : 0.6194078455249642; validation accuracy : 0.9288702928870293\n",
      "Epoch 69:\t train loss : 0.5625875455790865; train accuracy : 0.9886458688311286; \n",
      " validation loss : 0.5921364430019759; validation accuracy : 0.9581589958158996\n",
      "Epoch 70:\t train loss : 0.5603010015258607; train accuracy : 0.9910777905139564; \n",
      " validation loss : 0.5888872025740389; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5612298894553929; train accuracy : 0.9900709439573716; \n",
      " validation loss : 0.5938347184838079; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5595128530481764; train accuracy : 0.9918058180241024; \n",
      " validation loss : 0.6000649803138127; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5584784154613351; train accuracy : 0.9929210942098577; \n",
      " validation loss : 0.5828336516910477; validation accuracy : 0.9707112970711297\n",
      "Epoch 74:\t train loss : 0.5577432626931927; train accuracy : 0.9936801016140525; \n",
      " validation loss : 0.5861278836602377; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.5602067591233305; train accuracy : 0.9911242603550295; \n",
      " validation loss : 0.5977720059892218; validation accuracy : 0.9539748953974896\n",
      "Epoch 76:\t train loss : 0.564950904162029; train accuracy : 0.9861519873602033; \n",
      " validation loss : 0.6079428011242813; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5608509311578771; train accuracy : 0.9904619102202671; \n",
      " validation loss : 0.589802673499795; validation accuracy : 0.9623430962343096\n",
      "Epoch 78:\t train loss : 0.5640794244519461; train accuracy : 0.9872517735989343; \n",
      " validation loss : 0.606461311878544; validation accuracy : 0.9456066945606695\n",
      "Epoch 79:\t train loss : 0.5590680589156841; train accuracy : 0.9921716905728183; \n",
      " validation loss : 0.6020501318666837; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5591285683813129; train accuracy : 0.9923169862759069; \n",
      " validation loss : 0.6001181857252873; validation accuracy : 0.9497907949790795\n",
      "Epoch 81:\t train loss : 0.5611529859596265; train accuracy : 0.9899721180953561; \n",
      " validation loss : 0.5938825720572214; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5651877112546146; train accuracy : 0.9861151212862852; \n",
      " validation loss : 0.5928327871055915; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5639024350377689; train accuracy : 0.9873292233340561; \n",
      " validation loss : 0.5994459521024573; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.561267752983841; train accuracy : 0.9899934942222498; \n",
      " validation loss : 0.580834594342799; validation accuracy : 0.9707112970711297\n",
      "Epoch 85:\t train loss : 0.556802335228366; train accuracy : 0.994594008488491; \n",
      " validation loss : 0.5930372535258372; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5620552183928229; train accuracy : 0.9893001641934385; \n",
      " validation loss : 0.5908831586428358; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87:\t train loss : 0.5662145852993319; train accuracy : 0.9848759255243347; \n",
      " validation loss : 0.6130343545135294; validation accuracy : 0.9330543933054394\n",
      "Epoch 88:\t train loss : 0.5655020270467209; train accuracy : 0.9855419932463831; \n",
      " validation loss : 0.5851613341341314; validation accuracy : 0.9665271966527197\n",
      "Epoch 89:\t train loss : 0.5611054543350681; train accuracy : 0.9901793735865423; \n",
      " validation loss : 0.591991228027363; validation accuracy : 0.9581589958158996\n",
      "Epoch 90:\t train loss : 0.5578260439745191; train accuracy : 0.9934573561758419; \n",
      " validation loss : 0.5937663732003868; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5598747531867929; train accuracy : 0.9914960190836147; \n",
      " validation loss : 0.5734264863064567; validation accuracy : 0.9790794979079498\n",
      "Epoch 92:\t train loss : 0.5583951594490253; train accuracy : 0.992940301744168; \n",
      " validation loss : 0.5974333804287365; validation accuracy : 0.9497907949790795\n",
      "Epoch 93:\t train loss : 0.5563946299393465; train accuracy : 0.9948728275349298; \n",
      " validation loss : 0.609803519324756; validation accuracy : 0.9414225941422594\n",
      "Epoch 94:\t train loss : 0.5630413633978086; train accuracy : 0.9881347005793241; \n",
      " validation loss : 0.5853287649031111; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5638733409517122; train accuracy : 0.987332940921342; \n",
      " validation loss : 0.5947530967856844; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5635741118552219; train accuracy : 0.9876390222745438; \n",
      " validation loss : 0.5798336708363558; validation accuracy : 0.9707112970711297\n",
      "Epoch 97:\t train loss : 0.5742175665068183; train accuracy : 0.9767784008178693; \n",
      " validation loss : 0.6048452826894648; validation accuracy : 0.9456066945606695\n",
      "Epoch 98:\t train loss : 0.5607491570498344; train accuracy : 0.9904058366120387; \n",
      " validation loss : 0.5994617355164163; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5569048793244327; train accuracy : 0.9944545989652716; \n",
      " validation loss : 0.6053410658686516; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5573399320869415; train accuracy : 0.9940208804485888; \n",
      " validation loss : 0.601890261091664; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.5566010030647439; train accuracy : 0.9946500820967192; \n",
      " validation loss : 0.6058789777262288; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5633868423795274; train accuracy : 0.987859599120171; \n",
      " validation loss : 0.6237936006779132; validation accuracy : 0.9246861924686193\n",
      "Epoch 103:\t train loss : 0.5592278464437814; train accuracy : 0.9921620868056631; \n",
      " validation loss : 0.5781486259169147; validation accuracy : 0.9748953974895398\n",
      "Epoch 104:\t train loss : 0.5594763744482155; train accuracy : 0.9917438582360049; \n",
      " validation loss : 0.5851114721936101; validation accuracy : 0.9623430962343096\n",
      "Epoch 105:\t train loss : 0.5578997133902863; train accuracy : 0.9934012825676136; \n",
      " validation loss : 0.5968853408676331; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.5611932116782091; train accuracy : 0.9900960376715512; \n",
      " validation loss : 0.5867366624214126; validation accuracy : 0.9665271966527197\n",
      "Epoch 107:\t train loss : 0.5606355688254211; train accuracy : 0.9906846556584776; \n",
      " validation loss : 0.5911219052607748; validation accuracy : 0.9581589958158996\n",
      "Epoch 108:\t train loss : 0.5582464826327774; train accuracy : 0.9931261811084606; \n",
      " validation loss : 0.6033660485882449; validation accuracy : 0.9456066945606695\n",
      "Epoch 109:\t train loss : 0.5602300226361677; train accuracy : 0.9910468106199076; \n",
      " validation loss : 0.5950766759762364; validation accuracy : 0.9581589958158996\n",
      "Epoch 110:\t train loss : 0.5609814990050002; train accuracy : 0.99037485671799; \n",
      " validation loss : 0.5897743119632156; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5618858166083349; train accuracy : 0.9893525202143809; \n",
      " validation loss : 0.5961207558255486; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.558379834684217; train accuracy : 0.992940301744168; \n",
      " validation loss : 0.6102535021970058; validation accuracy : 0.9414225941422594\n",
      "Epoch 113:\t train loss : 0.5574492732582894; train accuracy : 0.9939006784596797; \n",
      " validation loss : 0.5814805306141206; validation accuracy : 0.9707112970711297\n",
      "Epoch 114:\t train loss : 0.5598489276919509; train accuracy : 0.9915269989776635; \n",
      " validation loss : 0.5918019174069479; validation accuracy : 0.9623430962343096\n",
      "Epoch 115:\t train loss : 0.5586376629786881; train accuracy : 0.9926983487716472; \n",
      " validation loss : 0.5758996451291316; validation accuracy : 0.9707112970711297\n",
      "Epoch 116:\t train loss : 0.5600723600345366; train accuracy : 0.9912326899842002; \n",
      " validation loss : 0.5862108175431292; validation accuracy : 0.9665271966527197\n",
      "Epoch 117:\t train loss : 0.5580159779201557; train accuracy : 0.9933179466526224; \n",
      " validation loss : 0.6047408070894643; validation accuracy : 0.9456066945606695\n",
      "Epoch 118:\t train loss : 0.5638415339901585; train accuracy : 0.987410390656464; \n",
      " validation loss : 0.6167690566208287; validation accuracy : 0.9330543933054394\n",
      "Epoch 119:\t train loss : 0.5578263288032718; train accuracy : 0.9936336317729794; \n",
      " validation loss : 0.5894802958974524; validation accuracy : 0.9623430962343096\n",
      "Epoch 120:\t train loss : 0.5660438366906676; train accuracy : 0.9850131664549707; \n",
      " validation loss : 0.5972136437025223; validation accuracy : 0.9539748953974896\n",
      "Epoch 121:\t train loss : 0.5594895045837356; train accuracy : 0.991676012268038; \n",
      " validation loss : 0.5899413347399977; validation accuracy : 0.9581589958158996\n",
      "Epoch 122:\t train loss : 0.5610076917908642; train accuracy : 0.9903283868769168; \n",
      " validation loss : 0.617779543630245; validation accuracy : 0.9330543933054394\n",
      "Epoch 123:\t train loss : 0.556495085868044; train accuracy : 0.9948669413550606; \n",
      " validation loss : 0.5950216854711913; validation accuracy : 0.9497907949790795\n",
      "Epoch 124:\t train loss : 0.5593939122243711; train accuracy : 0.9918928715263794; \n",
      " validation loss : 0.5848738089816868; validation accuracy : 0.9665271966527197\n",
      "Epoch 125:\t train loss : 0.5580320913909443; train accuracy : 0.9932714768115493; \n",
      " validation loss : 0.6018521867304506; validation accuracy : 0.9497907949790795\n",
      "Epoch 126:\t train loss : 0.5573183788104068; train accuracy : 0.9939995043216953; \n",
      " validation loss : 0.5903254674230058; validation accuracy : 0.9623430962343096\n",
      "Epoch 127:\t train loss : 0.5618745956587942; train accuracy : 0.9892499767650794; \n",
      " validation loss : 0.6069377628323371; validation accuracy : 0.9414225941422594\n",
      "Epoch 128:\t train loss : 0.5580343483844307; train accuracy : 0.9932869667585736; \n",
      " validation loss : 0.5895354233230403; validation accuracy : 0.9623430962343096\n",
      "Epoch 129:\t train loss : 0.5573817760434796; train accuracy : 0.9939685244276465; \n",
      " validation loss : 0.5902088128371229; validation accuracy : 0.9623430962343096\n",
      "Epoch 130:\t train loss : 0.5553577816831717; train accuracy : 0.9960345735617584; \n",
      " validation loss : 0.5851899079032302; validation accuracy : 0.9665271966527197\n",
      "Epoch 131:\t train loss : 0.5565047514845491; train accuracy : 0.9948979212491094; \n",
      " validation loss : 0.5959081022697027; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.560997050276451; train accuracy : 0.9901579974596487; \n",
      " validation loss : 0.6145054827486152; validation accuracy : 0.9330543933054394\n",
      "Epoch 133:\t train loss : 0.5603847553086941; train accuracy : 0.9909944545989653; \n",
      " validation loss : 0.5784489627951356; validation accuracy : 0.9748953974895398\n",
      "Epoch 134:\t train loss : 0.5580783950743787; train accuracy : 0.9933799064407199; \n",
      " validation loss : 0.5832908301077552; validation accuracy : 0.9665271966527197\n",
      "Epoch 135:\t train loss : 0.5579575152182221; train accuracy : 0.9933857926205892; \n",
      " validation loss : 0.5940692975800659; validation accuracy : 0.9581589958158996\n",
      "Epoch 136:\t train loss : 0.5603535603538703; train accuracy : 0.9908919111496639; \n",
      " validation loss : 0.5859360489677375; validation accuracy : 0.9665271966527197\n",
      "Epoch 137:\t train loss : 0.5635442354450992; train accuracy : 0.9876523436289848; \n",
      " validation loss : 0.5979293135426921; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138:\t train loss : 0.5558769822053299; train accuracy : 0.9954304656278076; \n",
      " validation loss : 0.5862694884114346; validation accuracy : 0.9623430962343096\n",
      "Epoch 139:\t train loss : 0.5598452029817107; train accuracy : 0.9915269989776635; \n",
      " validation loss : 0.6049693455945565; validation accuracy : 0.9414225941422594\n",
      "Epoch 140:\t train loss : 0.561323235918935; train accuracy : 0.9900244741162986; \n",
      " validation loss : 0.5933248418751939; validation accuracy : 0.9581589958158996\n",
      "Epoch 141:\t train loss : 0.5569274023207641; train accuracy : 0.9944545989652716; \n",
      " validation loss : 0.5851068842193237; validation accuracy : 0.9665271966527197\n",
      "Early stopping at epoch 141\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5598747531867929; Train accuracy : 0.9914960190836147; \n",
      " Validation loss : 0.5734264863064567; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 59 ! ---\n",
      "Epoch 1:\t train loss : 0.936434528163228; train accuracy : 0.5902692152792838; \n",
      " validation loss : 0.8288880226041718; validation accuracy : 0.7071129707112971\n",
      "Epoch 2:\t train loss : 0.7575548209818009; train accuracy : 0.7914185693484929; \n",
      " validation loss : 0.7264903199800935; validation accuracy : 0.8326359832635983\n",
      "Epoch 3:\t train loss : 0.6991595398679586; train accuracy : 0.8514359180891601; \n",
      " validation loss : 0.7173075467197898; validation accuracy : 0.8326359832635983\n",
      "Epoch 4:\t train loss : 0.6628022408292883; train accuracy : 0.8879890950772948; \n",
      " validation loss : 0.6826051832840798; validation accuracy : 0.8661087866108786\n",
      "Epoch 5:\t train loss : 0.6510940696198492; train accuracy : 0.8998017286780879; \n",
      " validation loss : 0.6682109339771852; validation accuracy : 0.8828451882845189\n",
      "Epoch 6:\t train loss : 0.63724065600125; train accuracy : 0.9131416710554849; \n",
      " validation loss : 0.6524200082033513; validation accuracy : 0.9037656903765691\n",
      "Epoch 7:\t train loss : 0.6233829261512989; train accuracy : 0.9279376684531739; \n",
      " validation loss : 0.6607607621514715; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6185082496807602; train accuracy : 0.9327054741472784; \n",
      " validation loss : 0.6574921479557388; validation accuracy : 0.895397489539749\n",
      "Epoch 9:\t train loss : 0.6089854743847745; train accuracy : 0.9421853217261997; \n",
      " validation loss : 0.6575576846517884; validation accuracy : 0.8828451882845189\n",
      "Epoch 10:\t train loss : 0.6040817520609614; train accuracy : 0.9470305771554262; \n",
      " validation loss : 0.6473494103772834; validation accuracy : 0.895397489539749\n",
      "Epoch 11:\t train loss : 0.6053532755185248; train accuracy : 0.9460175346200316; \n",
      " validation loss : 0.6614008509803442; validation accuracy : 0.8870292887029289\n",
      "Epoch 12:\t train loss : 0.607375852035272; train accuracy : 0.9435918089160135; \n",
      " validation loss : 0.6529685416918865; validation accuracy : 0.899581589958159\n",
      "Epoch 13:\t train loss : 0.5931388434634918; train accuracy : 0.9579943616592831; \n",
      " validation loss : 0.6631022220557846; validation accuracy : 0.8702928870292888\n",
      "Epoch 14:\t train loss : 0.5879314429205597; train accuracy : 0.9633445893615044; \n",
      " validation loss : 0.6296713592083515; validation accuracy : 0.9246861924686193\n",
      "Epoch 15:\t train loss : 0.590165118256326; train accuracy : 0.9608352179435546; \n",
      " validation loss : 0.6627113165122477; validation accuracy : 0.8744769874476988\n",
      "Epoch 16:\t train loss : 0.585752396070617; train accuracy : 0.9654698100932495; \n",
      " validation loss : 0.6277615888946833; validation accuracy : 0.9246861924686193\n",
      "Epoch 17:\t train loss : 0.5820415437904398; train accuracy : 0.9692307692307692; \n",
      " validation loss : 0.6097816275225835; validation accuracy : 0.9414225941422594\n",
      "Epoch 18:\t train loss : 0.5858163059745652; train accuracy : 0.9654729080826544; \n",
      " validation loss : 0.6242177038213448; validation accuracy : 0.9246861924686193\n",
      "Epoch 19:\t train loss : 0.5845990612825693; train accuracy : 0.9666222621518634; \n",
      " validation loss : 0.6281232766533722; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5844556845964666; train accuracy : 0.9666470460671025; \n",
      " validation loss : 0.5998679933427046; validation accuracy : 0.9539748953974896\n",
      "Epoch 21:\t train loss : 0.5742275799379409; train accuracy : 0.9770624864462963; \n",
      " validation loss : 0.6200595324967962; validation accuracy : 0.9246861924686193\n",
      "Epoch 22:\t train loss : 0.5748831313175442; train accuracy : 0.9764335945971064; \n",
      " validation loss : 0.6388052795884779; validation accuracy : 0.9079497907949791\n",
      "Epoch 23:\t train loss : 0.5822340215312747; train accuracy : 0.9690541838346913; \n",
      " validation loss : 0.7059173883699079; validation accuracy : 0.8410041841004184\n",
      "Epoch 24:\t train loss : 0.5817176990724849; train accuracy : 0.9695188822454227; \n",
      " validation loss : 0.6282657260454516; validation accuracy : 0.9246861924686193\n",
      "Epoch 25:\t train loss : 0.5704402786739626; train accuracy : 0.9808482294990551; \n",
      " validation loss : 0.6336132159846781; validation accuracy : 0.9121338912133892\n",
      "Epoch 26:\t train loss : 0.5684900908090247; train accuracy : 0.9827349050466248; \n",
      " validation loss : 0.6276767532329081; validation accuracy : 0.9205020920502092\n",
      "Epoch 27:\t train loss : 0.5657918002261596; train accuracy : 0.9855168995322036; \n",
      " validation loss : 0.6109113132681074; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.5669984676420818; train accuracy : 0.9844202112828774; \n",
      " validation loss : 0.6306798384361341; validation accuracy : 0.9205020920502092\n",
      "Epoch 29:\t train loss : 0.6039732752702915; train accuracy : 0.9464915269989777; \n",
      " validation loss : 0.6114990493265389; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5736494174816562; train accuracy : 0.9775581647510766; \n",
      " validation loss : 0.6228512078144367; validation accuracy : 0.9288702928870293\n",
      "Epoch 31:\t train loss : 0.5662704373108466; train accuracy : 0.985157532761238; \n",
      " validation loss : 0.6035874565386591; validation accuracy : 0.9497907949790795\n",
      "Epoch 32:\t train loss : 0.5738066237978541; train accuracy : 0.9774559311007156; \n",
      " validation loss : 0.6361375851130736; validation accuracy : 0.9121338912133892\n",
      "Epoch 33:\t train loss : 0.5650507757192321; train accuracy : 0.9864029245019982; \n",
      " validation loss : 0.6215431581512091; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.5776779327609923; train accuracy : 0.973267449425323; \n",
      " validation loss : 0.615055450031289; validation accuracy : 0.9330543933054394\n",
      "Epoch 35:\t train loss : 0.5691748399509394; train accuracy : 0.9819542117165959; \n",
      " validation loss : 0.6497446340244168; validation accuracy : 0.899581589958159\n",
      "Epoch 36:\t train loss : 0.5689477225683427; train accuracy : 0.9822454227206543; \n",
      " validation loss : 0.6157893029600036; validation accuracy : 0.9288702928870293\n",
      "Epoch 37:\t train loss : 0.5643896002080415; train accuracy : 0.9869017007961833; \n",
      " validation loss : 0.6296588492410028; validation accuracy : 0.9205020920502092\n",
      "Epoch 38:\t train loss : 0.5647788909367265; train accuracy : 0.9865609219616469; \n",
      " validation loss : 0.6222255855052492; validation accuracy : 0.9246861924686193\n",
      "Epoch 39:\t train loss : 0.570350615201422; train accuracy : 0.9807397998698845; \n",
      " validation loss : 0.6200461976871641; validation accuracy : 0.9288702928870293\n",
      "Epoch 40:\t train loss : 0.5688833911270375; train accuracy : 0.9825087518200688; \n",
      " validation loss : 0.608335059423358; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5659867831037224; train accuracy : 0.9852132965705257; \n",
      " validation loss : 0.6263690325046966; validation accuracy : 0.9246861924686193\n",
      "Epoch 42:\t train loss : 0.5778276876571105; train accuracy : 0.9731466278385328; \n",
      " validation loss : 0.6069778533573669; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.569972758246011; train accuracy : 0.9811208525666842; \n",
      " validation loss : 0.629644515291484; validation accuracy : 0.9205020920502092\n",
      "Epoch 44:\t train loss : 0.5642682478282246; train accuracy : 0.9869791505313051; \n",
      " validation loss : 0.6065061718643106; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.5622549389642979; train accuracy : 0.9889308838563772; \n",
      " validation loss : 0.6243033598741493; validation accuracy : 0.9246861924686193\n",
      "Epoch 46:\t train loss : 0.5607998434808615; train accuracy : 0.9905201524210787; \n",
      " validation loss : 0.6247123504289622; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47:\t train loss : 0.5645700108235209; train accuracy : 0.9866290777285541; \n",
      " validation loss : 0.6316899276039236; validation accuracy : 0.9163179916317992\n",
      "Epoch 48:\t train loss : 0.5747327618589583; train accuracy : 0.976396418724248; \n",
      " validation loss : 0.6104464886289008; validation accuracy : 0.9372384937238494\n",
      "Epoch 49:\t train loss : 0.579949068671392; train accuracy : 0.9710245050961925; \n",
      " validation loss : 0.6268946770170397; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5766362156124405; train accuracy : 0.9744849592614393; \n",
      " validation loss : 0.613585623487278; validation accuracy : 0.9372384937238494\n",
      "Epoch 51:\t train loss : 0.5666055411995481; train accuracy : 0.9847238142445552; \n",
      " validation loss : 0.6105162364203869; validation accuracy : 0.9330543933054394\n",
      "Epoch 52:\t train loss : 0.5629071159245024; train accuracy : 0.9883980296787385; \n",
      " validation loss : 0.6148739947566897; validation accuracy : 0.9330543933054394\n",
      "Epoch 53:\t train loss : 0.5601198511764605; train accuracy : 0.9912946497722978; \n",
      " validation loss : 0.6065532042012146; validation accuracy : 0.9414225941422594\n",
      "Epoch 54:\t train loss : 0.5611227094450606; train accuracy : 0.9902413333746398; \n",
      " validation loss : 0.6108454420232197; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5647396636014873; train accuracy : 0.9864617863006908; \n",
      " validation loss : 0.6043404301354025; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5602408119517761; train accuracy : 0.9912481799312246; \n",
      " validation loss : 0.6114800381784743; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5617408873408715; train accuracy : 0.9895659716843769; \n",
      " validation loss : 0.6159523767421599; validation accuracy : 0.9330543933054394\n",
      "Epoch 58:\t train loss : 0.5747339590173146; train accuracy : 0.9763096750209115; \n",
      " validation loss : 0.6340904057517488; validation accuracy : 0.9205020920502092\n",
      "Epoch 59:\t train loss : 0.569534395408231; train accuracy : 0.9816444127761083; \n",
      " validation loss : 0.6148312884551539; validation accuracy : 0.9372384937238494\n",
      "Epoch 60:\t train loss : 0.5620408910898537; train accuracy : 0.9892468787756746; \n",
      " validation loss : 0.6075830177956819; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5586440625552402; train accuracy : 0.9927754887078286; \n",
      " validation loss : 0.6093929434891624; validation accuracy : 0.9456066945606695\n",
      "Epoch 62:\t train loss : 0.563668542333726; train accuracy : 0.9877443539143096; \n",
      " validation loss : 0.6027227493497909; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5653455255665377; train accuracy : 0.9858607763561449; \n",
      " validation loss : 0.636909916814033; validation accuracy : 0.9121338912133892\n",
      "Epoch 64:\t train loss : 0.5649421345544696; train accuracy : 0.9863595526503299; \n",
      " validation loss : 0.6225248230710716; validation accuracy : 0.9246861924686193\n",
      "Epoch 65:\t train loss : 0.5672050943199308; train accuracy : 0.9841197063106044; \n",
      " validation loss : 0.6339151137600566; validation accuracy : 0.9163179916317992\n",
      "Epoch 66:\t train loss : 0.5635969535883574; train accuracy : 0.9877195699990706; \n",
      " validation loss : 0.6490293946594335; validation accuracy : 0.9037656903765691\n",
      "Epoch 67:\t train loss : 0.5628562562460757; train accuracy : 0.9885963010006505; \n",
      " validation loss : 0.6119743278400716; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.6380426475924695; train accuracy : 0.9114067969887543; \n",
      " validation loss : 0.6573384837185215; validation accuracy : 0.899581589958159\n",
      "Epoch 69:\t train loss : 0.5917876303889587; train accuracy : 0.9588277208091949; \n",
      " validation loss : 0.65330074464797; validation accuracy : 0.891213389121339\n",
      "Epoch 70:\t train loss : 0.5932701272503974; train accuracy : 0.9574646054710493; \n",
      " validation loss : 0.6324620185841882; validation accuracy : 0.9205020920502092\n",
      "Early stopping at epoch 70\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5844556845964666; Train accuracy : 0.9666470460671025; \n",
      " Validation loss : 0.5998679933427046; Validation accuracy : 0.9539748953974896\n",
      "--- Let's train model 60 ! ---\n",
      "Epoch 1:\t train loss : 0.9426195792232516; train accuracy : 0.5889587657610211; \n",
      " validation loss : 0.7667199118678157; validation accuracy : 0.8158995815899581\n",
      "Epoch 2:\t train loss : 0.7425971731277892; train accuracy : 0.8076737197558784; \n",
      " validation loss : 0.7005964712114299; validation accuracy : 0.8493723849372385\n",
      "Epoch 3:\t train loss : 0.7014177310865342; train accuracy : 0.8483317327054741; \n",
      " validation loss : 0.7050974865947763; validation accuracy : 0.8493723849372385\n",
      "Epoch 4:\t train loss : 0.6823772067448182; train accuracy : 0.8663465410948294; \n",
      " validation loss : 0.6814798970450515; validation accuracy : 0.8744769874476988\n",
      "Epoch 5:\t train loss : 0.6722400254389171; train accuracy : 0.8775054989311937; \n",
      " validation loss : 0.6821175158092736; validation accuracy : 0.8702928870292888\n",
      "Epoch 6:\t train loss : 0.6559435881985821; train accuracy : 0.8945537346262276; \n",
      " validation loss : 0.6519799442430823; validation accuracy : 0.899581589958159\n",
      "Epoch 7:\t train loss : 0.6446511313784464; train accuracy : 0.9055454010347285; \n",
      " validation loss : 0.6422108501145979; validation accuracy : 0.9121338912133892\n",
      "Epoch 8:\t train loss : 0.6362031600419454; train accuracy : 0.9145636481923232; \n",
      " validation loss : 0.6376875698263204; validation accuracy : 0.9121338912133892\n",
      "Epoch 9:\t train loss : 0.6292422408758173; train accuracy : 0.9213854208618607; \n",
      " validation loss : 0.6406096738946387; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.6113059009672972; train accuracy : 0.9400941788779082; \n",
      " validation loss : 0.693813934125357; validation accuracy : 0.8577405857740585\n",
      "Epoch 11:\t train loss : 0.6169295160850763; train accuracy : 0.9339322779516094; \n",
      " validation loss : 0.6444493960020851; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.6048820356231707; train accuracy : 0.9458161653087146; \n",
      " validation loss : 0.6276173108433564; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.5964177562871494; train accuracy : 0.9547104928901143; \n",
      " validation loss : 0.6151927015269344; validation accuracy : 0.9372384937238494\n",
      "Epoch 14:\t train loss : 0.5985156974096549; train accuracy : 0.952616252052418; \n",
      " validation loss : 0.6148249285885711; validation accuracy : 0.9372384937238494\n",
      "Epoch 15:\t train loss : 0.5904055865599414; train accuracy : 0.9608135320177205; \n",
      " validation loss : 0.6177245491101424; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5887991508709969; train accuracy : 0.962604169893739; \n",
      " validation loss : 0.6237509083834156; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5892801187065889; train accuracy : 0.9617181449239444; \n",
      " validation loss : 0.6338303917270615; validation accuracy : 0.9163179916317992\n",
      "Epoch 18:\t train loss : 0.5915999535574337; train accuracy : 0.9594968865206481; \n",
      " validation loss : 0.6031467810688421; validation accuracy : 0.9456066945606695\n",
      "Epoch 19:\t train loss : 0.5924204891133524; train accuracy : 0.9586294494872828; \n",
      " validation loss : 0.633653926131324; validation accuracy : 0.9163179916317992\n",
      "Epoch 20:\t train loss : 0.58447980741374; train accuracy : 0.9668422193996097; \n",
      " validation loss : 0.6192876622282951; validation accuracy : 0.9288702928870293\n",
      "Epoch 21:\t train loss : 0.5873561015159705; train accuracy : 0.9637566219523529; \n",
      " validation loss : 0.6294549105508715; validation accuracy : 0.9121338912133892\n",
      "Epoch 22:\t train loss : 0.5809276315922194; train accuracy : 0.9702190278509247; \n",
      " validation loss : 0.6091538866899538; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.5848928704178145; train accuracy : 0.9660956039530345; \n",
      " validation loss : 0.6074191275960257; validation accuracy : 0.9456066945606695\n",
      "Epoch 24:\t train loss : 0.5795346822684003; train accuracy : 0.9717246507016946; \n",
      " validation loss : 0.6141402921708669; validation accuracy : 0.9372384937238494\n",
      "Epoch 25:\t train loss : 0.5805148569932626; train accuracy : 0.9707797639332073; \n",
      " validation loss : 0.6365297906248787; validation accuracy : 0.9163179916317992\n",
      "Epoch 26:\t train loss : 0.5815837308817945; train accuracy : 0.9693484928281545; \n",
      " validation loss : 0.6227869398182017; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:\t train loss : 0.5748345060630076; train accuracy : 0.9761981474023359; \n",
      " validation loss : 0.594892120736804; validation accuracy : 0.9581589958158996\n",
      "Epoch 28:\t train loss : 0.574246714043536; train accuracy : 0.9767898633786672; \n",
      " validation loss : 0.6149301570182603; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.579091766348576; train accuracy : 0.9720251556739676; \n",
      " validation loss : 0.6206320116040455; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.581762148451722; train accuracy : 0.9691471235168375; \n",
      " validation loss : 0.6244374369277362; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5764611813288965; train accuracy : 0.9746336627528733; \n",
      " validation loss : 0.6079114819618101; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5783879647877566; train accuracy : 0.9729700424424549; \n",
      " validation loss : 0.6200817722069342; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5835489454338234; train accuracy : 0.9673626816196289; \n",
      " validation loss : 0.6191481528617029; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.5856761272789597; train accuracy : 0.9651600111527618; \n",
      " validation loss : 0.6027867390785003; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5730913130157712; train accuracy : 0.9779763933207348; \n",
      " validation loss : 0.6012460256971469; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5727894076342882; train accuracy : 0.97859599120171; \n",
      " validation loss : 0.5937208469402957; validation accuracy : 0.9581589958158996\n",
      "Epoch 37:\t train loss : 0.5726310941015348; train accuracy : 0.9787477926825491; \n",
      " validation loss : 0.6042976424648383; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5787481560878358; train accuracy : 0.9720468415998017; \n",
      " validation loss : 0.6115034863585718; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5762619178295371; train accuracy : 0.9745500170389417; \n",
      " validation loss : 0.6032472350044258; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.5730320786584805; train accuracy : 0.9783109761764615; \n",
      " validation loss : 0.6004824607023072; validation accuracy : 0.9497907949790795\n",
      "Epoch 41:\t train loss : 0.5696073790564585; train accuracy : 0.9816630007125375; \n",
      " validation loss : 0.6023657115379174; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.570370524048747; train accuracy : 0.980900895318938; \n",
      " validation loss : 0.6043380232089548; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5700107410041862; train accuracy : 0.9811146565878744; \n",
      " validation loss : 0.599844989420313; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5681387216762379; train accuracy : 0.9831221537222343; \n",
      " validation loss : 0.6023568140633855; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.5667593638409829; train accuracy : 0.984379937420614; \n",
      " validation loss : 0.5976034433367575; validation accuracy : 0.9497907949790795\n",
      "Epoch 46:\t train loss : 0.5750375893855267; train accuracy : 0.9764119086712724; \n",
      " validation loss : 0.5930700142419367; validation accuracy : 0.9581589958158996\n",
      "Epoch 47:\t train loss : 0.5707132325462588; train accuracy : 0.9804640788128505; \n",
      " validation loss : 0.5961665083392685; validation accuracy : 0.9539748953974896\n",
      "Epoch 48:\t train loss : 0.5708392365365962; train accuracy : 0.9801171039995044; \n",
      " validation loss : 0.6175665210894418; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5803207595300711; train accuracy : 0.9705474147278417; \n",
      " validation loss : 0.6239877825125562; validation accuracy : 0.9205020920502092\n",
      "Epoch 50:\t train loss : 0.5853060190741404; train accuracy : 0.9654914960190836; \n",
      " validation loss : 0.6163200715349129; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.5806102031863428; train accuracy : 0.9703460454165247; \n",
      " validation loss : 0.5889702841541872; validation accuracy : 0.9623430962343096\n",
      "Epoch 52:\t train loss : 0.5842316871380004; train accuracy : 0.9666129681836488; \n",
      " validation loss : 0.5948266129633942; validation accuracy : 0.9539748953974896\n",
      "Epoch 53:\t train loss : 0.574310780221607; train accuracy : 0.9766473558660429; \n",
      " validation loss : 0.5952047805714079; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.5724553905403665; train accuracy : 0.9785185414665882; \n",
      " validation loss : 0.5892902744299622; validation accuracy : 0.9623430962343096\n",
      "Epoch 55:\t train loss : 0.5759771262140124; train accuracy : 0.9753771802100437; \n",
      " validation loss : 0.6040745874103176; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5683892544437977; train accuracy : 0.9827503949936491; \n",
      " validation loss : 0.6039996956714245; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5658570609194874; train accuracy : 0.9852783543480281; \n",
      " validation loss : 0.5972063213726695; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.5666475378342408; train accuracy : 0.9846153846153847; \n",
      " validation loss : 0.5894608473585066; validation accuracy : 0.9623430962343096\n",
      "Epoch 59:\t train loss : 0.5661784313798276; train accuracy : 0.9851265528671892; \n",
      " validation loss : 0.588884553588316; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5663117965471091; train accuracy : 0.9849902413333746; \n",
      " validation loss : 0.6133336470517217; validation accuracy : 0.9288702928870293\n",
      "Epoch 61:\t train loss : 0.5665801275070999; train accuracy : 0.9846680504352675; \n",
      " validation loss : 0.5757629128787463; validation accuracy : 0.9748953974895398\n",
      "Epoch 62:\t train loss : 0.5695883569205615; train accuracy : 0.9816165308714644; \n",
      " validation loss : 0.6284078620604702; validation accuracy : 0.9246861924686193\n",
      "Epoch 63:\t train loss : 0.5794535522864832; train accuracy : 0.9715108894327581; \n",
      " validation loss : 0.6143922403566436; validation accuracy : 0.9372384937238494\n",
      "Epoch 64:\t train loss : 0.5748846562098712; train accuracy : 0.9762508132222187; \n",
      " validation loss : 0.601333416790288; validation accuracy : 0.9497907949790795\n",
      "Epoch 65:\t train loss : 0.5723641676337579; train accuracy : 0.9787508906719539; \n",
      " validation loss : 0.6094418178265999; validation accuracy : 0.9456066945606695\n",
      "Epoch 66:\t train loss : 0.568246623652697; train accuracy : 0.9828898045168686; \n",
      " validation loss : 0.6158090649116017; validation accuracy : 0.9330543933054394\n",
      "Epoch 67:\t train loss : 0.5639643602718389; train accuracy : 0.9873261253446514; \n",
      " validation loss : 0.5859754585662617; validation accuracy : 0.9665271966527197\n",
      "Epoch 68:\t train loss : 0.5640221884895026; train accuracy : 0.9870782861922612; \n",
      " validation loss : 0.6026822740716314; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5660350404370225; train accuracy : 0.9851823166764769; \n",
      " validation loss : 0.606975934870723; validation accuracy : 0.9414225941422594\n",
      "Epoch 70:\t train loss : 0.5682077942057256; train accuracy : 0.9829021964744881; \n",
      " validation loss : 0.602137197219066; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.564538485340051; train accuracy : 0.9867870751882029; \n",
      " validation loss : 0.5973657295229218; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5662759187210349; train accuracy : 0.9850367111744478; \n",
      " validation loss : 0.6363076173510577; validation accuracy : 0.9121338912133892\n",
      "Epoch 73:\t train loss : 0.568188526038054; train accuracy : 0.9830849778493758; \n",
      " validation loss : 0.6022480124568116; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5777430692862032; train accuracy : 0.9734068589485424; \n",
      " validation loss : 0.6083536421130715; validation accuracy : 0.9372384937238494\n",
      "Epoch 75:\t train loss : 0.5736986146090205; train accuracy : 0.9773784813655937; \n",
      " validation loss : 0.6599617243561213; validation accuracy : 0.891213389121339\n",
      "Epoch 76:\t train loss : 0.5781415900888298; train accuracy : 0.9726943213854209; \n",
      " validation loss : 0.6015063383815409; validation accuracy : 0.9497907949790795\n",
      "Epoch 77:\t train loss : 0.56659714670878; train accuracy : 0.9846370705412187; \n",
      " validation loss : 0.5924254644353649; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78:\t train loss : 0.5655156623058823; train accuracy : 0.9856284271507791; \n",
      " validation loss : 0.5944637359490985; validation accuracy : 0.9581589958158996\n",
      "Epoch 79:\t train loss : 0.5653353481006846; train accuracy : 0.9859289321230521; \n",
      " validation loss : 0.5863080487044522; validation accuracy : 0.9623430962343096\n",
      "Epoch 80:\t train loss : 0.5676779148085498; train accuracy : 0.9836147340376096; \n",
      " validation loss : 0.586912283580948; validation accuracy : 0.9665271966527197\n",
      "Epoch 81:\t train loss : 0.5692071874191674; train accuracy : 0.9818581740450447; \n",
      " validation loss : 0.6039340089194429; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5689665721964742; train accuracy : 0.9820595433563617; \n",
      " validation loss : 0.5764768927320443; validation accuracy : 0.9748953974895398\n",
      "Epoch 83:\t train loss : 0.5634613213099616; train accuracy : 0.9879705071408655; \n",
      " validation loss : 0.5952645725782066; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.566073152128786; train accuracy : 0.9852659623904086; \n",
      " validation loss : 0.6021932883765416; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5639942970140108; train accuracy : 0.9873261253446514; \n",
      " validation loss : 0.6092921543070519; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.5663286862740103; train accuracy : 0.9848136559372968; \n",
      " validation loss : 0.610963452332463; validation accuracy : 0.9372384937238494\n",
      "Epoch 87:\t train loss : 0.5670643588993681; train accuracy : 0.9842684098020384; \n",
      " validation loss : 0.6052261588023468; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5652640323890399; train accuracy : 0.9860714396356764; \n",
      " validation loss : 0.5937623309824016; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5661617239798825; train accuracy : 0.9850460051426624; \n",
      " validation loss : 0.6301630731484533; validation accuracy : 0.9163179916317992\n",
      "Epoch 90:\t train loss : 0.566619474548254; train accuracy : 0.9847857740326528; \n",
      " validation loss : 0.6299293517091321; validation accuracy : 0.9246861924686193\n",
      "Epoch 91:\t train loss : 0.5740257785045864; train accuracy : 0.9770810743827256; \n",
      " validation loss : 0.5886129285350018; validation accuracy : 0.9665271966527197\n",
      "Epoch 92:\t train loss : 0.566598870762302; train accuracy : 0.9846432665200285; \n",
      " validation loss : 0.5990841161723942; validation accuracy : 0.9497907949790795\n",
      "Epoch 93:\t train loss : 0.5703747303857448; train accuracy : 0.9807428978592894; \n",
      " validation loss : 0.5914186001400208; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5705980981326383; train accuracy : 0.9805074506645187; \n",
      " validation loss : 0.6045324765026219; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.5618890136102067; train accuracy : 0.9894482480869915; \n",
      " validation loss : 0.5775589223679221; validation accuracy : 0.9748953974895398\n",
      "Epoch 96:\t train loss : 0.5620510852418403; train accuracy : 0.989262368722699; \n",
      " validation loss : 0.5927003811600441; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5638069643998915; train accuracy : 0.9873571052387001; \n",
      " validation loss : 0.5915179524111625; validation accuracy : 0.9581589958158996\n",
      "Epoch 98:\t train loss : 0.5672737342722419; train accuracy : 0.983955512872146; \n",
      " validation loss : 0.602650219337042; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5686185333108319; train accuracy : 0.9826946311843614; \n",
      " validation loss : 0.5975129325269556; validation accuracy : 0.9539748953974896\n",
      "Epoch 100:\t train loss : 0.5656058252885835; train accuracy : 0.9857244648223303; \n",
      " validation loss : 0.584250015251028; validation accuracy : 0.9665271966527197\n",
      "Epoch 101:\t train loss : 0.5607575267195428; train accuracy : 0.9905821122091762; \n",
      " validation loss : 0.5891915466955927; validation accuracy : 0.9623430962343096\n",
      "Epoch 102:\t train loss : 0.5627667370952736; train accuracy : 0.9886427708417237; \n",
      " validation loss : 0.5853880842407166; validation accuracy : 0.9665271966527197\n",
      "Epoch 103:\t train loss : 0.5639876585916901; train accuracy : 0.9871960097896465; \n",
      " validation loss : 0.6117792345611358; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.5647157414125661; train accuracy : 0.9865980978345054; \n",
      " validation loss : 0.5923240356221263; validation accuracy : 0.9581589958158996\n",
      "Epoch 105:\t train loss : 0.5620270669050678; train accuracy : 0.9893769943306794; \n",
      " validation loss : 0.5823924451338327; validation accuracy : 0.9707112970711297\n",
      "Epoch 106:\t train loss : 0.5626190599387557; train accuracy : 0.9885529291489823; \n",
      " validation loss : 0.5998850567668479; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5674252492588457; train accuracy : 0.9837944174230924; \n",
      " validation loss : 0.5967723192673449; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5661290485489947; train accuracy : 0.9851885126552867; \n",
      " validation loss : 0.5946770584122683; validation accuracy : 0.9581589958158996\n",
      "Epoch 109:\t train loss : 0.5629367717374317; train accuracy : 0.9882957960283776; \n",
      " validation loss : 0.5898736133976931; validation accuracy : 0.9581589958158996\n",
      "Epoch 110:\t train loss : 0.5619922083559344; train accuracy : 0.9894451500975867; \n",
      " validation loss : 0.601525138074639; validation accuracy : 0.9456066945606695\n",
      "Epoch 111:\t train loss : 0.5661420244011834; train accuracy : 0.9851389448248087; \n",
      " validation loss : 0.5991011106074393; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 111\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5665801275070999; Train accuracy : 0.9846680504352675; \n",
      " Validation loss : 0.5757629128787463; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 61 ! ---\n",
      "Epoch 1:\t train loss : 0.9418375053767364; train accuracy : 0.5824297530902445; \n",
      " validation loss : 0.8595255905483746; validation accuracy : 0.6736401673640168\n",
      "Epoch 2:\t train loss : 0.7569964336088247; train accuracy : 0.7918095356113882; \n",
      " validation loss : 0.779808242347296; validation accuracy : 0.7698744769874477\n",
      "Epoch 3:\t train loss : 0.6992799678802615; train accuracy : 0.8509560395303448; \n",
      " validation loss : 0.7314812775596502; validation accuracy : 0.8200836820083682\n",
      "Epoch 4:\t train loss : 0.6709047177407955; train accuracy : 0.8794079742247282; \n",
      " validation loss : 0.6832435717762916; validation accuracy : 0.8702928870292888\n",
      "Epoch 5:\t train loss : 0.6505390708235034; train accuracy : 0.8999299854394498; \n",
      " validation loss : 0.6901093044812295; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6356040730811326; train accuracy : 0.915155054369714; \n",
      " validation loss : 0.6703742248389357; validation accuracy : 0.8786610878661087\n",
      "Epoch 7:\t train loss : 0.6227101595323079; train accuracy : 0.9284181666098702; \n",
      " validation loss : 0.6926402306284191; validation accuracy : 0.8493723849372385\n",
      "Epoch 8:\t train loss : 0.6160588491635492; train accuracy : 0.9347166888689241; \n",
      " validation loss : 0.6676636958906171; validation accuracy : 0.8786610878661087\n",
      "Epoch 9:\t train loss : 0.600827104138403; train accuracy : 0.9510068465565847; \n",
      " validation loss : 0.6581012675381905; validation accuracy : 0.895397489539749\n",
      "Epoch 10:\t train loss : 0.5955966853713739; train accuracy : 0.9560410793395087; \n",
      " validation loss : 0.6574227658421227; validation accuracy : 0.895397489539749\n",
      "Epoch 11:\t train loss : 0.5990022048262209; train accuracy : 0.9520948604355773; \n",
      " validation loss : 0.6572920006508761; validation accuracy : 0.8870292887029289\n",
      "Epoch 12:\t train loss : 0.5889139277461117; train accuracy : 0.9623882400322191; \n",
      " validation loss : 0.6302079576056521; validation accuracy : 0.9246861924686193\n",
      "Epoch 13:\t train loss : 0.5838863894497588; train accuracy : 0.9678465875646706; \n",
      " validation loss : 0.6273028546789534; validation accuracy : 0.9163179916317992\n",
      "Epoch 14:\t train loss : 0.5855294428830021; train accuracy : 0.9659177793611946; \n",
      " validation loss : 0.6685849713911174; validation accuracy : 0.8786610878661087\n",
      "Epoch 15:\t train loss : 0.5895556662589201; train accuracy : 0.9620047089438954; \n",
      " validation loss : 0.6450654228407775; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.5824101131371752; train accuracy : 0.9691979305430776; \n",
      " validation loss : 0.6297759771459245; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:\t train loss : 0.5802757539752885; train accuracy : 0.9709947643979058; \n",
      " validation loss : 0.646583138182125; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.5738147314044869; train accuracy : 0.9775101459153009; \n",
      " validation loss : 0.6107150379349275; validation accuracy : 0.9414225941422594\n",
      "Epoch 19:\t train loss : 0.5749568683639633; train accuracy : 0.976484091824406; \n",
      " validation loss : 0.6421752157890663; validation accuracy : 0.9037656903765691\n",
      "Epoch 20:\t train loss : 0.5732651388170669; train accuracy : 0.9781009324948109; \n",
      " validation loss : 0.6417938583594933; validation accuracy : 0.9037656903765691\n",
      "Epoch 21:\t train loss : 0.5764407200241107; train accuracy : 0.9746327333560519; \n",
      " validation loss : 0.6466655894901395; validation accuracy : 0.9037656903765691\n",
      "Epoch 22:\t train loss : 0.5779575229986398; train accuracy : 0.9731847331082127; \n",
      " validation loss : 0.6325832243881102; validation accuracy : 0.9163179916317992\n",
      "Epoch 23:\t train loss : 0.5790749229915715; train accuracy : 0.972090833049351; \n",
      " validation loss : 0.6251979537761149; validation accuracy : 0.9246861924686193\n",
      "Epoch 24:\t train loss : 0.5827873093458961; train accuracy : 0.9681659902723133; \n",
      " validation loss : 0.6203907854188844; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.571441898676871; train accuracy : 0.9800740419467765; \n",
      " validation loss : 0.6260344992464361; validation accuracy : 0.9246861924686193\n",
      "Epoch 26:\t train loss : 0.5696423928663125; train accuracy : 0.9815706806282722; \n",
      " validation loss : 0.6301124416875944; validation accuracy : 0.9205020920502092\n",
      "Epoch 27:\t train loss : 0.5696961752916183; train accuracy : 0.9815920567551659; \n",
      " validation loss : 0.6387146487026047; validation accuracy : 0.9121338912133892\n",
      "Epoch 28:\t train loss : 0.585744958813309; train accuracy : 0.9650930945816165; \n",
      " validation loss : 0.6822211587702943; validation accuracy : 0.8661087866108786\n",
      "Epoch 29:\t train loss : 0.5904881837369114; train accuracy : 0.9602794386443199; \n",
      " validation loss : 0.6381820188268003; validation accuracy : 0.9121338912133892\n",
      "Epoch 30:\t train loss : 0.5741989912308266; train accuracy : 0.9769546764150067; \n",
      " validation loss : 0.6159551169169014; validation accuracy : 0.9330543933054394\n",
      "Epoch 31:\t train loss : 0.5732413622525495; train accuracy : 0.9779615229715914; \n",
      " validation loss : 0.6277280978974984; validation accuracy : 0.9205020920502092\n",
      "Epoch 32:\t train loss : 0.5686912619429051; train accuracy : 0.982664580687134; \n",
      " validation loss : 0.6346867594423629; validation accuracy : 0.9163179916317992\n",
      "Epoch 33:\t train loss : 0.5779770959209868; train accuracy : 0.9732274853620001; \n",
      " validation loss : 0.6269489890590908; validation accuracy : 0.9246861924686193\n",
      "Epoch 34:\t train loss : 0.5744595382409479; train accuracy : 0.9765925214535767; \n",
      " validation loss : 0.6448868925622835; validation accuracy : 0.9037656903765691\n",
      "Epoch 35:\t train loss : 0.5698374450116552; train accuracy : 0.9814563648192324; \n",
      " validation loss : 0.6213960715110123; validation accuracy : 0.9288702928870293\n",
      "Epoch 36:\t train loss : 0.5677164521890765; train accuracy : 0.9834914340592955; \n",
      " validation loss : 0.6205388879669322; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5690601173976404; train accuracy : 0.9823392917996221; \n",
      " validation loss : 0.6349401088893016; validation accuracy : 0.9079497907949791\n",
      "Epoch 38:\t train loss : 0.5770886252497429; train accuracy : 0.9741333374639859; \n",
      " validation loss : 0.613955577722521; validation accuracy : 0.9288702928870293\n",
      "Epoch 39:\t train loss : 0.5755914585872335; train accuracy : 0.9754270578394622; \n",
      " validation loss : 0.6270305213783502; validation accuracy : 0.9205020920502092\n",
      "Epoch 40:\t train loss : 0.5799953559704538; train accuracy : 0.9707992812664581; \n",
      " validation loss : 0.6320738514314714; validation accuracy : 0.9163179916317992\n",
      "Epoch 41:\t train loss : 0.5690211444091943; train accuracy : 0.9817912574738994; \n",
      " validation loss : 0.6028855742794818; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.5749781655084352; train accuracy : 0.9761123330958208; \n",
      " validation loss : 0.6361546306843366; validation accuracy : 0.9163179916317992\n",
      "Epoch 43:\t train loss : 0.5683040684131475; train accuracy : 0.9828932123052139; \n",
      " validation loss : 0.6186566746009894; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5651489017878701; train accuracy : 0.9862235509154559; \n",
      " validation loss : 0.6343906877028184; validation accuracy : 0.9163179916317992\n",
      "Epoch 45:\t train loss : 0.5630269939966067; train accuracy : 0.9883766535518449; \n",
      " validation loss : 0.6048137665048148; validation accuracy : 0.9456066945606695\n",
      "Epoch 46:\t train loss : 0.5619467814734563; train accuracy : 0.9893370302673565; \n",
      " validation loss : 0.6212118683527004; validation accuracy : 0.9288702928870293\n",
      "Epoch 47:\t train loss : 0.5615834893524386; train accuracy : 0.9897707487840391; \n",
      " validation loss : 0.5986816967928807; validation accuracy : 0.9539748953974896\n",
      "Epoch 48:\t train loss : 0.5743355321265854; train accuracy : 0.9766272189349112; \n",
      " validation loss : 0.6016382118978358; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5634915883999715; train accuracy : 0.987608042380495; \n",
      " validation loss : 0.604782672979787; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5628449389319623; train accuracy : 0.988510176895195; \n",
      " validation loss : 0.597338069174351; validation accuracy : 0.9581589958158996\n",
      "Epoch 51:\t train loss : 0.5623423967618101; train accuracy : 0.9890987948821215; \n",
      " validation loss : 0.6374474905907982; validation accuracy : 0.9121338912133892\n",
      "Epoch 52:\t train loss : 0.5636557830793836; train accuracy : 0.9875925524334707; \n",
      " validation loss : 0.62494605515065; validation accuracy : 0.9246861924686193\n",
      "Epoch 53:\t train loss : 0.5689595547172811; train accuracy : 0.9822832181913937; \n",
      " validation loss : 0.5855536500203027; validation accuracy : 0.9665271966527197\n",
      "Epoch 54:\t train loss : 0.5650620853050553; train accuracy : 0.9861962886086929; \n",
      " validation loss : 0.6369827935833691; validation accuracy : 0.9121338912133892\n",
      "Epoch 55:\t train loss : 0.5784732011719604; train accuracy : 0.9725827937668453; \n",
      " validation loss : 0.6166953415145028; validation accuracy : 0.9330543933054394\n",
      "Epoch 56:\t train loss : 0.5644304489368906; train accuracy : 0.9869958796740915; \n",
      " validation loss : 0.6322293307387539; validation accuracy : 0.9246861924686193\n",
      "Epoch 57:\t train loss : 0.564670137902748; train accuracy : 0.9867037392732116; \n",
      " validation loss : 0.6151618298348911; validation accuracy : 0.9330543933054394\n",
      "Epoch 58:\t train loss : 0.5725907544509612; train accuracy : 0.9785848384398526; \n",
      " validation loss : 0.6339058768577178; validation accuracy : 0.9121338912133892\n",
      "Epoch 59:\t train loss : 0.5621183882786032; train accuracy : 0.989123888596301; \n",
      " validation loss : 0.5941509297502962; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5965532013320736; train accuracy : 0.9539573716657889; \n",
      " validation loss : 0.6402868267250613; validation accuracy : 0.9121338912133892\n",
      "Epoch 61:\t train loss : 0.5795564918531176; train accuracy : 0.9711924161219369; \n",
      " validation loss : 0.606820184628986; validation accuracy : 0.9456066945606695\n",
      "Epoch 62:\t train loss : 0.5738413389432974; train accuracy : 0.9773242665510083; \n",
      " validation loss : 0.6109573579369721; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5668640652202646; train accuracy : 0.9843529849127916; \n",
      " validation loss : 0.6255682490814716; validation accuracy : 0.9205020920502092\n",
      "Epoch 64:\t train loss : 0.5655296983390816; train accuracy : 0.9855670869605626; \n",
      " validation loss : 0.6463898121318632; validation accuracy : 0.9079497907949791\n",
      "Epoch 65:\t train loss : 0.5675181205072323; train accuracy : 0.9837643669258651; \n",
      " validation loss : 0.6130503906060265; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.5664021702225116; train accuracy : 0.9847690448898665; \n",
      " validation loss : 0.6130583395884467; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5659645175536285; train accuracy : 0.985179838284953; \n",
      " validation loss : 0.6108322552031056; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68:\t train loss : 0.5601031611625406; train accuracy : 0.9912209176244617; \n",
      " validation loss : 0.6111652569172212; validation accuracy : 0.9372384937238494\n",
      "Epoch 69:\t train loss : 0.5672778712682295; train accuracy : 0.9840218098454103; \n",
      " validation loss : 0.652794374511437; validation accuracy : 0.891213389121339\n",
      "Epoch 70:\t train loss : 0.564253711804327; train accuracy : 0.9869221475262555; \n",
      " validation loss : 0.6527094481431356; validation accuracy : 0.895397489539749\n",
      "Epoch 71:\t train loss : 0.5665828234635019; train accuracy : 0.984418662288175; \n",
      " validation loss : 0.6040230329713642; validation accuracy : 0.9456066945606695\n",
      "Epoch 72:\t train loss : 0.5631099306612741; train accuracy : 0.9881347005793241; \n",
      " validation loss : 0.6321696068144577; validation accuracy : 0.9163179916317992\n",
      "Epoch 73:\t train loss : 0.5630895611432867; train accuracy : 0.9881554571083366; \n",
      " validation loss : 0.6059520413223042; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.5631069289245074; train accuracy : 0.9881325319867406; \n",
      " validation loss : 0.6215383549309391; validation accuracy : 0.9288702928870293\n",
      "Epoch 75:\t train loss : 0.56014319161561; train accuracy : 0.9911648440162335; \n",
      " validation loss : 0.6129911280945999; validation accuracy : 0.9372384937238494\n",
      "Epoch 76:\t train loss : 0.5654742134936538; train accuracy : 0.9857898323987732; \n",
      " validation loss : 0.6077889904403098; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5626125907205209; train accuracy : 0.9886554725982837; \n",
      " validation loss : 0.6105763287701991; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5599992212390261; train accuracy : 0.9912865949998451; \n",
      " validation loss : 0.6072813973118941; validation accuracy : 0.9456066945606695\n",
      "Epoch 79:\t train loss : 0.5582617001574971; train accuracy : 0.9931202949285913; \n",
      " validation loss : 0.6162962940132615; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.5581086167652185; train accuracy : 0.9932869667585736; \n",
      " validation loss : 0.6223972399352549; validation accuracy : 0.9288702928870293\n",
      "Epoch 81:\t train loss : 0.5607472113351575; train accuracy : 0.9905142662412094; \n",
      " validation loss : 0.6095199350831868; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5576743943955187; train accuracy : 0.9937457789894358; \n",
      " validation loss : 0.6135003882059904; validation accuracy : 0.9372384937238494\n",
      "Epoch 83:\t train loss : 0.562139602848016; train accuracy : 0.9891725270299575; \n",
      " validation loss : 0.6038879914600151; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.57395882501189; train accuracy : 0.9769717153567334; \n",
      " validation loss : 0.6423974534307872; validation accuracy : 0.9079497907949791\n",
      "Epoch 85:\t train loss : 0.567535211524206; train accuracy : 0.9836271259952291; \n",
      " validation loss : 0.6074917833394343; validation accuracy : 0.9372384937238494\n",
      "Epoch 86:\t train loss : 0.5620384575169481; train accuracy : 0.9891511509030639; \n",
      " validation loss : 0.598396084562205; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5636535465763794; train accuracy : 0.9874258806034883; \n",
      " validation loss : 0.628071534801476; validation accuracy : 0.9205020920502092\n",
      "Epoch 88:\t train loss : 0.5584734117094855; train accuracy : 0.9929093218501193; \n",
      " validation loss : 0.5840571382499953; validation accuracy : 0.9665271966527197\n",
      "Epoch 89:\t train loss : 0.5576257659984509; train accuracy : 0.9936122556460857; \n",
      " validation loss : 0.5986461365696671; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5556462451717753; train accuracy : 0.9956665324204591; \n",
      " validation loss : 0.593642349881331; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5569163055253019; train accuracy : 0.9944332228383779; \n",
      " validation loss : 0.5933998601914151; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5583134378787328; train accuracy : 0.9930059791195514; \n",
      " validation loss : 0.6041517037381829; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5568756793765905; train accuracy : 0.9944022429443291; \n",
      " validation loss : 0.6094201159913918; validation accuracy : 0.9414225941422594\n",
      "Epoch 94:\t train loss : 0.5593797550469963; train accuracy : 0.9919452275473217; \n",
      " validation loss : 0.6212490418689185; validation accuracy : 0.9288702928870293\n",
      "Epoch 95:\t train loss : 0.5659349832398943; train accuracy : 0.9852786641469686; \n",
      " validation loss : 0.6035225679766333; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5598488474727554; train accuracy : 0.991387589454444; \n",
      " validation loss : 0.6153523207237326; validation accuracy : 0.9330543933054394\n",
      "Epoch 97:\t train loss : 0.5571696707121522; train accuracy : 0.9942473434740853; \n",
      " validation loss : 0.6176020456528547; validation accuracy : 0.9330543933054394\n",
      "Epoch 98:\t train loss : 0.5582620001701963; train accuracy : 0.9931320672883298; \n",
      " validation loss : 0.6083445182400221; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5577406608548104; train accuracy : 0.9937885312432231; \n",
      " validation loss : 0.6072941479797674; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5568412052059926; train accuracy : 0.9945047863936305; \n",
      " validation loss : 0.665534664011129; validation accuracy : 0.8828451882845189\n",
      "Epoch 101:\t train loss : 0.5619620851283531; train accuracy : 0.9893215403203321; \n",
      " validation loss : 0.6229833310328725; validation accuracy : 0.9246861924686193\n",
      "Epoch 102:\t train loss : 0.5602701052344663; train accuracy : 0.9910077759534063; \n",
      " validation loss : 0.6133340176560089; validation accuracy : 0.9372384937238494\n",
      "Epoch 103:\t train loss : 0.5600678492758605; train accuracy : 0.9911103194027077; \n",
      " validation loss : 0.6471441036744883; validation accuracy : 0.899581589958159\n",
      "Epoch 104:\t train loss : 0.5597771485204736; train accuracy : 0.9915675826388674; \n",
      " validation loss : 0.6168943896839016; validation accuracy : 0.9330543933054394\n",
      "Epoch 105:\t train loss : 0.5574748340438436; train accuracy : 0.9937612689364602; \n",
      " validation loss : 0.6233640270204353; validation accuracy : 0.9288702928870293\n",
      "Epoch 106:\t train loss : 0.5585215907698445; train accuracy : 0.9927138387186716; \n",
      " validation loss : 0.6156424109057607; validation accuracy : 0.9330543933054394\n",
      "Epoch 107:\t train loss : 0.5565643451473127; train accuracy : 0.9947467393661513; \n",
      " validation loss : 0.6047018248975912; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.5594175605921211; train accuracy : 0.991840515505437; \n",
      " validation loss : 0.6162643727866001; validation accuracy : 0.9372384937238494\n",
      "Epoch 109:\t train loss : 0.5664942206517438; train accuracy : 0.9845388642770841; \n",
      " validation loss : 0.6091997393672244; validation accuracy : 0.9414225941422594\n",
      "Epoch 110:\t train loss : 0.5553153105891968; train accuracy : 0.9959977074878403; \n",
      " validation loss : 0.6091976147210443; validation accuracy : 0.9414225941422594\n",
      "Epoch 111:\t train loss : 0.5580140131330228; train accuracy : 0.9933799064407199; \n",
      " validation loss : 0.6054523803374304; validation accuracy : 0.9456066945606695\n",
      "Epoch 112:\t train loss : 0.5570727205902993; train accuracy : 0.9942024226277146; \n",
      " validation loss : 0.6317549095196432; validation accuracy : 0.9163179916317992\n",
      "Epoch 113:\t train loss : 0.5582763468548521; train accuracy : 0.9929653954583475; \n",
      " validation loss : 0.620657009747323; validation accuracy : 0.9288702928870293\n",
      "Epoch 114:\t train loss : 0.5567621191926677; train accuracy : 0.994566746181728; \n",
      " validation loss : 0.5897854500564024; validation accuracy : 0.9623430962343096\n",
      "Epoch 115:\t train loss : 0.5552610744786883; train accuracy : 0.9961526069580842; \n",
      " validation loss : 0.6063321010757905; validation accuracy : 0.9456066945606695\n",
      "Epoch 116:\t train loss : 0.556445891495182; train accuracy : 0.9949598810372069; \n",
      " validation loss : 0.6086909614150312; validation accuracy : 0.9456066945606695\n",
      "Epoch 117:\t train loss : 0.5592848255092515; train accuracy : 0.9919563803091793; \n",
      " validation loss : 0.6544684649080791; validation accuracy : 0.895397489539749\n",
      "Epoch 118:\t train loss : 0.5578229230192693; train accuracy : 0.9934824498900213; \n",
      " validation loss : 0.613546803573863; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119:\t train loss : 0.5592951512012125; train accuracy : 0.9920359986368846; \n",
      " validation loss : 0.6414322967091368; validation accuracy : 0.9121338912133892\n",
      "Epoch 120:\t train loss : 0.5639152284798169; train accuracy : 0.9872496050063508; \n",
      " validation loss : 0.6176480231921277; validation accuracy : 0.9330543933054394\n",
      "Epoch 121:\t train loss : 0.5588766777615555; train accuracy : 0.9924040397781839; \n",
      " validation loss : 0.5923801763660318; validation accuracy : 0.9581589958158996\n",
      "Epoch 122:\t train loss : 0.5564482964075748; train accuracy : 0.9948610551751913; \n",
      " validation loss : 0.6441583418172611; validation accuracy : 0.9037656903765691\n",
      "Epoch 123:\t train loss : 0.5576673108673379; train accuracy : 0.9937553827565909; \n",
      " validation loss : 0.607183447457894; validation accuracy : 0.9372384937238494\n",
      "Epoch 124:\t train loss : 0.5555861524442803; train accuracy : 0.9957712444623439; \n",
      " validation loss : 0.6052311852377479; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5632495667583547; train accuracy : 0.9880086124105456; \n",
      " validation loss : 0.593830437315691; validation accuracy : 0.9581589958158996\n",
      "Epoch 126:\t train loss : 0.558215527758154; train accuracy : 0.9931240125158772; \n",
      " validation loss : 0.593216324004303; validation accuracy : 0.9581589958158996\n",
      "Epoch 127:\t train loss : 0.5567067908199566; train accuracy : 0.9945785185414666; \n",
      " validation loss : 0.6039690512276075; validation accuracy : 0.9456066945606695\n",
      "Epoch 128:\t train loss : 0.556932763773023; train accuracy : 0.9943808668174354; \n",
      " validation loss : 0.5964149417980841; validation accuracy : 0.9539748953974896\n",
      "Epoch 129:\t train loss : 0.5552140149484727; train accuracy : 0.9961680969051085; \n",
      " validation loss : 0.6087482361984023; validation accuracy : 0.9414225941422594\n",
      "Epoch 130:\t train loss : 0.554773495462767; train accuracy : 0.996595929241922; \n",
      " validation loss : 0.614496701395939; validation accuracy : 0.9372384937238494\n",
      "Epoch 131:\t train loss : 0.5575669204849608; train accuracy : 0.9937612689364602; \n",
      " validation loss : 0.5950283958345393; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5554526362617632; train accuracy : 0.9958486941974658; \n",
      " validation loss : 0.6055677175620778; validation accuracy : 0.9456066945606695\n",
      "Epoch 133:\t train loss : 0.5574715617377213; train accuracy : 0.9938696985656309; \n",
      " validation loss : 0.6005357632675312; validation accuracy : 0.9497907949790795\n",
      "Epoch 134:\t train loss : 0.5556001179676967; train accuracy : 0.995831035657858; \n",
      " validation loss : 0.6034543950972203; validation accuracy : 0.9497907949790795\n",
      "Epoch 135:\t train loss : 0.5563800742059606; train accuracy : 0.9949192973760029; \n",
      " validation loss : 0.5960284854929159; validation accuracy : 0.9539748953974896\n",
      "Epoch 136:\t train loss : 0.5565694229675491; train accuracy : 0.9947526255460206; \n",
      " validation loss : 0.5880502334855323; validation accuracy : 0.9665271966527197\n",
      "Epoch 137:\t train loss : 0.5551133191521375; train accuracy : 0.9962765265342792; \n",
      " validation loss : 0.5934494659205831; validation accuracy : 0.9581589958158996\n",
      "Epoch 138:\t train loss : 0.554534346790465; train accuracy : 0.9968961244152544; \n",
      " validation loss : 0.5898470866675976; validation accuracy : 0.9623430962343096\n",
      "Early stopping at epoch 138\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5584734117094855; Train accuracy : 0.9929093218501193; \n",
      " Validation loss : 0.5840571382499953; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 62 ! ---\n",
      "Epoch 1:\t train loss : 0.9757272838747262; train accuracy : 0.542163326001425; \n",
      " validation loss : 0.8895848103448054; validation accuracy : 0.6317991631799164\n",
      "Epoch 2:\t train loss : 0.7742023307676641; train accuracy : 0.7751680659252146; \n",
      " validation loss : 0.7200025484727728; validation accuracy : 0.8242677824267782\n",
      "Epoch 3:\t train loss : 0.705552282529995; train accuracy : 0.8437405124074475; \n",
      " validation loss : 0.6787955311109426; validation accuracy : 0.8744769874476988\n",
      "Epoch 4:\t train loss : 0.6711345533060223; train accuracy : 0.8793017131881409; \n",
      " validation loss : 0.665983050123253; validation accuracy : 0.8828451882845189\n",
      "Epoch 5:\t train loss : 0.6559628978248265; train accuracy : 0.894667740636327; \n",
      " validation loss : 0.6507825048859076; validation accuracy : 0.9037656903765691\n",
      "Epoch 6:\t train loss : 0.6384233093356582; train accuracy : 0.9118541466588185; \n",
      " validation loss : 0.623875496656327; validation accuracy : 0.9205020920502092\n",
      "Epoch 7:\t train loss : 0.6218604036662435; train accuracy : 0.9293636729762385; \n",
      " validation loss : 0.6232535638987584; validation accuracy : 0.9288702928870293\n",
      "Epoch 8:\t train loss : 0.6147352607879103; train accuracy : 0.936458068713405; \n",
      " validation loss : 0.6423092024718798; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.6072552817545323; train accuracy : 0.9443210756219214; \n",
      " validation loss : 0.6298313921626654; validation accuracy : 0.9246861924686193\n",
      "Epoch 10:\t train loss : 0.6107555725948844; train accuracy : 0.9401660522321014; \n",
      " validation loss : 0.6001796474297595; validation accuracy : 0.9497907949790795\n",
      "Epoch 11:\t train loss : 0.5972039645080965; train accuracy : 0.9539691440255275; \n",
      " validation loss : 0.6153656010930706; validation accuracy : 0.9372384937238494\n",
      "Epoch 12:\t train loss : 0.5982385323152674; train accuracy : 0.9528774125592491; \n",
      " validation loss : 0.6081208628385447; validation accuracy : 0.9414225941422594\n",
      "Epoch 13:\t train loss : 0.5919384054615334; train accuracy : 0.9595845596208061; \n",
      " validation loss : 0.6193894295301174; validation accuracy : 0.9330543933054394\n",
      "Epoch 14:\t train loss : 0.5943029630496567; train accuracy : 0.9568583289445151; \n",
      " validation loss : 0.5987112778785889; validation accuracy : 0.9581589958158996\n",
      "Epoch 15:\t train loss : 0.5904569498476165; train accuracy : 0.9604925803153753; \n",
      " validation loss : 0.6065320065329906; validation accuracy : 0.9414225941422594\n",
      "Epoch 16:\t train loss : 0.5876838588892243; train accuracy : 0.9636333219740388; \n",
      " validation loss : 0.6195120443867209; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5837411615695705; train accuracy : 0.9675832584652561; \n",
      " validation loss : 0.6229141263326586; validation accuracy : 0.9205020920502092\n",
      "Epoch 18:\t train loss : 0.5842434873674401; train accuracy : 0.9669887542984603; \n",
      " validation loss : 0.6292399508405828; validation accuracy : 0.9246861924686193\n",
      "Epoch 19:\t train loss : 0.5778005198417009; train accuracy : 0.9736457139316583; \n",
      " validation loss : 0.5979523975422977; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5772904356768147; train accuracy : 0.9739651166393011; \n",
      " validation loss : 0.5981506711155191; validation accuracy : 0.9497907949790795\n",
      "Epoch 21:\t train loss : 0.5861199184490169; train accuracy : 0.9648238793023328; \n",
      " validation loss : 0.5966827225983132; validation accuracy : 0.9581589958158996\n",
      "Epoch 22:\t train loss : 0.5824911040668683; train accuracy : 0.9685997087889959; \n",
      " validation loss : 0.5942255074563163; validation accuracy : 0.9539748953974896\n",
      "Epoch 23:\t train loss : 0.5732525038614902; train accuracy : 0.9781997583568264; \n",
      " validation loss : 0.5918776233920131; validation accuracy : 0.9581589958158996\n",
      "Epoch 24:\t train loss : 0.5871069151649919; train accuracy : 0.9638731063539763; \n",
      " validation loss : 0.6236677816111902; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5930970779685899; train accuracy : 0.9573347997149849; \n",
      " validation loss : 0.5966920924644975; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5774849160593352; train accuracy : 0.9735100219957248; \n",
      " validation loss : 0.6146141951769671; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5725931098114911; train accuracy : 0.9789005235602094; \n",
      " validation loss : 0.6125036993288309; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5720001442818425; train accuracy : 0.9794603302456706; \n",
      " validation loss : 0.6040229550710757; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5700223770642855; train accuracy : 0.9812299017937359; \n",
      " validation loss : 0.5959375083053025; validation accuracy : 0.9581589958158996\n",
      "Epoch 30:\t train loss : 0.5726807866643123; train accuracy : 0.9784785774032653; \n",
      " validation loss : 0.6083834295022398; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:\t train loss : 0.5767217224549236; train accuracy : 0.9743582514947798; \n",
      " validation loss : 0.5951715776845922; validation accuracy : 0.9581589958158996\n",
      "Epoch 32:\t train loss : 0.5740783035678882; train accuracy : 0.9771501595464543; \n",
      " validation loss : 0.6373342631025454; validation accuracy : 0.9121338912133892\n",
      "Epoch 33:\t train loss : 0.5777851777476993; train accuracy : 0.9732739552030732; \n",
      " validation loss : 0.5909505224031188; validation accuracy : 0.9581589958158996\n",
      "Epoch 34:\t train loss : 0.5686472865722443; train accuracy : 0.9824808699154249; \n",
      " validation loss : 0.5890328077877678; validation accuracy : 0.9623430962343096\n",
      "Epoch 35:\t train loss : 0.5748994955938717; train accuracy : 0.9762848911056724; \n",
      " validation loss : 0.6049591518644375; validation accuracy : 0.9456066945606695\n",
      "Epoch 36:\t train loss : 0.5642714637581602; train accuracy : 0.9871898138108368; \n",
      " validation loss : 0.5807272324488663; validation accuracy : 0.9623430962343096\n",
      "Epoch 37:\t train loss : 0.5718396185459048; train accuracy : 0.9793305244896062; \n",
      " validation loss : 0.5925121135933046; validation accuracy : 0.9581589958158996\n",
      "Epoch 38:\t train loss : 0.5719568610618246; train accuracy : 0.9793460144366306; \n",
      " validation loss : 0.5818619704207598; validation accuracy : 0.9707112970711297\n",
      "Epoch 39:\t train loss : 0.5660583624075715; train accuracy : 0.9852631741999442; \n",
      " validation loss : 0.6056523997644161; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.5666630922270921; train accuracy : 0.9845661265838471; \n",
      " validation loss : 0.6312186386739727; validation accuracy : 0.9205020920502092\n",
      "Epoch 41:\t train loss : 0.570906351504678; train accuracy : 0.9801669816289228; \n",
      " validation loss : 0.5983940819652106; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5640781308118418; train accuracy : 0.9872768673131138; \n",
      " validation loss : 0.5899953879414974; validation accuracy : 0.9623430962343096\n",
      "Epoch 43:\t train loss : 0.5732011411087988; train accuracy : 0.9778568109297067; \n",
      " validation loss : 0.6281644769961663; validation accuracy : 0.9205020920502092\n",
      "Epoch 44:\t train loss : 0.5826268670259003; train accuracy : 0.9679763933207348; \n",
      " validation loss : 0.597869425211599; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5717090541937374; train accuracy : 0.9793364106694755; \n",
      " validation loss : 0.6080758358736135; validation accuracy : 0.9288702928870293\n",
      "Epoch 46:\t train loss : 0.5667753535050324; train accuracy : 0.9843861333994238; \n",
      " validation loss : 0.59688410795344; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5672109014693973; train accuracy : 0.9838573066080114; \n",
      " validation loss : 0.5902625755223743; validation accuracy : 0.9581589958158996\n",
      "Epoch 48:\t train loss : 0.5663330801235001; train accuracy : 0.9849725827937669; \n",
      " validation loss : 0.599383773875876; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5661799445411541; train accuracy : 0.985083181015521; \n",
      " validation loss : 0.6141908253505115; validation accuracy : 0.9372384937238494\n",
      "Epoch 50:\t train loss : 0.5657229324807483; train accuracy : 0.9854239598500573; \n",
      " validation loss : 0.5939947885703352; validation accuracy : 0.9581589958158996\n",
      "Epoch 51:\t train loss : 0.567992408782042; train accuracy : 0.983154372812045; \n",
      " validation loss : 0.6112352011751996; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5643591449186264; train accuracy : 0.9867096254530809; \n",
      " validation loss : 0.5832245285522261; validation accuracy : 0.9707112970711297\n",
      "Epoch 53:\t train loss : 0.5681565278255994; train accuracy : 0.9831041853836859; \n",
      " validation loss : 0.5824700930612061; validation accuracy : 0.9707112970711297\n",
      "Epoch 54:\t train loss : 0.6063864999572111; train accuracy : 0.9437073639208153; \n",
      " validation loss : 0.6287236620776678; validation accuracy : 0.9205020920502092\n",
      "Epoch 55:\t train loss : 0.5742034973487916; train accuracy : 0.976883112859754; \n",
      " validation loss : 0.6114957387708496; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.5667324381825495; train accuracy : 0.9845255429226432; \n",
      " validation loss : 0.601640500428311; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5667827440522033; train accuracy : 0.9845041667957496; \n",
      " validation loss : 0.593806384886902; validation accuracy : 0.9581589958158996\n",
      "Epoch 58:\t train loss : 0.5628514307690332; train accuracy : 0.9885684190960067; \n",
      " validation loss : 0.5878968890826252; validation accuracy : 0.9623430962343096\n",
      "Epoch 59:\t train loss : 0.5619335386495349; train accuracy : 0.989362123981536; \n",
      " validation loss : 0.5682378739091202; validation accuracy : 0.9832635983263598\n",
      "Epoch 60:\t train loss : 0.5613191657997777; train accuracy : 0.9901056414387063; \n",
      " validation loss : 0.6015432357755032; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5683748345575175; train accuracy : 0.9827634065491496; \n",
      " validation loss : 0.6101321297701442; validation accuracy : 0.9330543933054394\n",
      "Epoch 62:\t train loss : 0.5707095430509358; train accuracy : 0.9805424579447938; \n",
      " validation loss : 0.5976304649451604; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.567179563360519; train accuracy : 0.9841478980141888; \n",
      " validation loss : 0.5961633323641772; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5664852463280932; train accuracy : 0.9845410328696675; \n",
      " validation loss : 0.6194333438505589; validation accuracy : 0.9330543933054394\n",
      "Epoch 65:\t train loss : 0.5610036095572358; train accuracy : 0.9903652529508349; \n",
      " validation loss : 0.5849222467742765; validation accuracy : 0.9665271966527197\n",
      "Epoch 66:\t train loss : 0.5637773830359644; train accuracy : 0.9875770624864463; \n",
      " validation loss : 0.599302649805952; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5660478693719834; train accuracy : 0.9852167043588711; \n",
      " validation loss : 0.6051181270262003; validation accuracy : 0.9456066945606695\n",
      "Epoch 68:\t train loss : 0.5627136517231404; train accuracy : 0.988547042969113; \n",
      " validation loss : 0.5872992968462043; validation accuracy : 0.9665271966527197\n",
      "Epoch 69:\t train loss : 0.5652691807302364; train accuracy : 0.9858363022398463; \n",
      " validation loss : 0.5969288037589615; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5625609720217672; train accuracy : 0.9887019424393568; \n",
      " validation loss : 0.5972265837753281; validation accuracy : 0.9539748953974896\n",
      "Epoch 71:\t train loss : 0.5983756809226403; train accuracy : 0.9522887945723225; \n",
      " validation loss : 0.6110278103840123; validation accuracy : 0.9414225941422594\n",
      "Epoch 72:\t train loss : 0.5716163542323037; train accuracy : 0.9796034573561758; \n",
      " validation loss : 0.6136434346002185; validation accuracy : 0.9372384937238494\n",
      "Epoch 73:\t train loss : 0.5633299687462003; train accuracy : 0.9878441091731466; \n",
      " validation loss : 0.5921775476241391; validation accuracy : 0.9581589958158996\n",
      "Epoch 74:\t train loss : 0.568900858949172; train accuracy : 0.9822987081384181; \n",
      " validation loss : 0.5939912104544157; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.563752797812612; train accuracy : 0.9873543170482357; \n",
      " validation loss : 0.5950875390065554; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5661164859433894; train accuracy : 0.9850367111744478; \n",
      " validation loss : 0.5725321349353478; validation accuracy : 0.9790794979079498\n",
      "Epoch 77:\t train loss : 0.5618709865372051; train accuracy : 0.9895480033458286; \n",
      " validation loss : 0.5840355210104216; validation accuracy : 0.9665271966527197\n",
      "Epoch 78:\t train loss : 0.5630571278158026; train accuracy : 0.9881539081136342; \n",
      " validation loss : 0.6029180804417654; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5610006354410656; train accuracy : 0.9902664270888194; \n",
      " validation loss : 0.6024932360051883; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5602636679968738; train accuracy : 0.9909074010966883; \n",
      " validation loss : 0.5965228387761423; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.579599335188582; train accuracy : 0.9711828123547818; \n",
      " validation loss : 0.5973954754561354; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82:\t train loss : 0.5622690807911319; train accuracy : 0.9890950772948357; \n",
      " validation loss : 0.6195680468368406; validation accuracy : 0.9288702928870293\n",
      "Epoch 83:\t train loss : 0.5615178829121477; train accuracy : 0.9897338827101211; \n",
      " validation loss : 0.6041685381604427; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5604388113764873; train accuracy : 0.9908550450757458; \n",
      " validation loss : 0.5890404499805819; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.5589669815770171; train accuracy : 0.9923479661699557; \n",
      " validation loss : 0.5996757524300838; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5572761218763659; train accuracy : 0.9940924440038414; \n",
      " validation loss : 0.5725487749695295; validation accuracy : 0.9748953974895398\n",
      "Epoch 87:\t train loss : 0.5578097473545847; train accuracy : 0.9935097121967843; \n",
      " validation loss : 0.5803775783334929; validation accuracy : 0.9707112970711297\n",
      "Epoch 88:\t train loss : 0.5588060763905299; train accuracy : 0.9924910932804609; \n",
      " validation loss : 0.5915958647249325; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5732302951152419; train accuracy : 0.9778936770036246; \n",
      " validation loss : 0.6305379837443982; validation accuracy : 0.9205020920502092\n",
      "Epoch 90:\t train loss : 0.5625973359308866; train accuracy : 0.9887793921744787; \n",
      " validation loss : 0.6077973764431108; validation accuracy : 0.9414225941422594\n",
      "Epoch 91:\t train loss : 0.5634674234115237; train accuracy : 0.9877319619566901; \n",
      " validation loss : 0.583290368970286; validation accuracy : 0.9665271966527197\n",
      "Epoch 92:\t train loss : 0.5604270439342118; train accuracy : 0.9908240651816971; \n",
      " validation loss : 0.6135236750853742; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5651391964161183; train accuracy : 0.9861674773072276; \n",
      " validation loss : 0.5871461504611035; validation accuracy : 0.9623430962343096\n",
      "Epoch 94:\t train loss : 0.5603786140719892; train accuracy : 0.9908299513615664; \n",
      " validation loss : 0.5924381770313668; validation accuracy : 0.9581589958158996\n",
      "Epoch 95:\t train loss : 0.5600864552791367; train accuracy : 0.9910777905139564; \n",
      " validation loss : 0.5822238906980594; validation accuracy : 0.9707112970711297\n",
      "Epoch 96:\t train loss : 0.5572342046540886; train accuracy : 0.9940518603426376; \n",
      " validation loss : 0.5947837956416805; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5570261350685466; train accuracy : 0.9944081291241984; \n",
      " validation loss : 0.5862544395790846; validation accuracy : 0.9623430962343096\n",
      "Epoch 98:\t train loss : 0.5650916990071421; train accuracy : 0.9861210074661545; \n",
      " validation loss : 0.5781771858607794; validation accuracy : 0.9707112970711297\n",
      "Epoch 99:\t train loss : 0.5617550197315581; train accuracy : 0.9895752656525915; \n",
      " validation loss : 0.5936351709246964; validation accuracy : 0.9581589958158996\n",
      "Epoch 100:\t train loss : 0.5590715843842922; train accuracy : 0.9922122742340221; \n",
      " validation loss : 0.6172418089575856; validation accuracy : 0.9330543933054394\n",
      "Epoch 101:\t train loss : 0.5587495086985941; train accuracy : 0.9925434493014034; \n",
      " validation loss : 0.6032091332362376; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5586909934237733; train accuracy : 0.992527959354379; \n",
      " validation loss : 0.5790339669649706; validation accuracy : 0.9748953974895398\n",
      "Epoch 103:\t train loss : 0.5581136792698385; train accuracy : 0.9932308931503454; \n",
      " validation loss : 0.5849011542821204; validation accuracy : 0.9665271966527197\n",
      "Epoch 104:\t train loss : 0.5618852053228792; train accuracy : 0.9894764397905759; \n",
      " validation loss : 0.5722207550603063; validation accuracy : 0.9790794979079498\n",
      "Epoch 105:\t train loss : 0.55834454974102; train accuracy : 0.9928628520090461; \n",
      " validation loss : 0.6019674796673434; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.5617349576172108; train accuracy : 0.9895848694197465; \n",
      " validation loss : 0.5947433272349968; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5653921097857091; train accuracy : 0.9858731683137644; \n",
      " validation loss : 0.5846632250437415; validation accuracy : 0.9665271966527197\n",
      "Epoch 108:\t train loss : 0.5610196972751786; train accuracy : 0.9902664270888194; \n",
      " validation loss : 0.5916207709606581; validation accuracy : 0.9581589958158996\n",
      "Epoch 109:\t train loss : 0.5569760300831541; train accuracy : 0.9943402831562316; \n",
      " validation loss : 0.6112896385060967; validation accuracy : 0.9372384937238494\n",
      "Early stopping at epoch 109\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5619335386495349; Train accuracy : 0.989362123981536; \n",
      " Validation loss : 0.5682378739091202; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 63 ! ---\n",
      "Epoch 1:\t train loss : 0.9510276200391957; train accuracy : 0.5729953220359987; \n",
      " validation loss : 0.8718896292702908; validation accuracy : 0.6778242677824268\n",
      "Epoch 2:\t train loss : 0.7750947808539601; train accuracy : 0.7724169893738964; \n",
      " validation loss : 0.7593527048500521; validation accuracy : 0.7907949790794979\n",
      "Epoch 3:\t train loss : 0.7131020505353265; train accuracy : 0.8365078224232473; \n",
      " validation loss : 0.7316721082117036; validation accuracy : 0.8158995815899581\n",
      "Epoch 4:\t train loss : 0.6783245486630191; train accuracy : 0.871945971064779; \n",
      " validation loss : 0.7137584789894489; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.6635772322965389; train accuracy : 0.8873283558970229; \n",
      " validation loss : 0.6927307639863219; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.648100182015325; train accuracy : 0.9024629015768766; \n",
      " validation loss : 0.6994087381303636; validation accuracy : 0.8451882845188284\n",
      "Epoch 7:\t train loss : 0.6442749027094403; train accuracy : 0.906222373679482; \n",
      " validation loss : 0.6926067499463878; validation accuracy : 0.8451882845188284\n",
      "Epoch 8:\t train loss : 0.6327484472531404; train accuracy : 0.9182735524644505; \n",
      " validation loss : 0.683406802000429; validation accuracy : 0.8661087866108786\n",
      "Epoch 9:\t train loss : 0.6264049084750467; train accuracy : 0.9241597323337154; \n",
      " validation loss : 0.6618013603033537; validation accuracy : 0.891213389121339\n",
      "Epoch 10:\t train loss : 0.6263654827291099; train accuracy : 0.924186127203445; \n",
      " validation loss : 0.6745591546643511; validation accuracy : 0.8828451882845189\n",
      "Epoch 11:\t train loss : 0.614516437281596; train accuracy : 0.9363119055732829; \n",
      " validation loss : 0.64881361278926; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.5992025662375152; train accuracy : 0.9521672914278633; \n",
      " validation loss : 0.6535367415755017; validation accuracy : 0.891213389121339\n",
      "Epoch 13:\t train loss : 0.5963463601971192; train accuracy : 0.9554110102543449; \n",
      " validation loss : 0.6356750449688996; validation accuracy : 0.899581589958159\n",
      "Epoch 14:\t train loss : 0.5916088124088917; train accuracy : 0.9598110226463026; \n",
      " validation loss : 0.6308401798530942; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5881912924961391; train accuracy : 0.9630767991573469; \n",
      " validation loss : 0.630122764647861; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5871857981027884; train accuracy : 0.964430744446854; \n",
      " validation loss : 0.6145967540801842; validation accuracy : 0.9372384937238494\n",
      "Epoch 17:\t train loss : 0.5847828911699766; train accuracy : 0.966409740078689; \n",
      " validation loss : 0.6303741639338749; validation accuracy : 0.9205020920502092\n",
      "Epoch 18:\t train loss : 0.5854231611631601; train accuracy : 0.9657646147650175; \n",
      " validation loss : 0.6204135273497315; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5763646275216112; train accuracy : 0.975015830725859; \n",
      " validation loss : 0.6311251437762376; validation accuracy : 0.9163179916317992\n",
      "Epoch 20:\t train loss : 0.5775364020234199; train accuracy : 0.9739952290963165; \n",
      " validation loss : 0.6170629929271767; validation accuracy : 0.9372384937238494\n",
      "Epoch 21:\t train loss : 0.5745352811576389; train accuracy : 0.9768353418631308; \n",
      " validation loss : 0.6181787717593981; validation accuracy : 0.9288702928870293\n",
      "Epoch 22:\t train loss : 0.5786109207492387; train accuracy : 0.9726011338641222; \n",
      " validation loss : 0.6119951281270709; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:\t train loss : 0.5790785661018126; train accuracy : 0.9723742371201091; \n",
      " validation loss : 0.6335588896756158; validation accuracy : 0.9205020920502092\n",
      "Epoch 24:\t train loss : 0.5768546672542628; train accuracy : 0.9745683571362186; \n",
      " validation loss : 0.606151372551574; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5769630277888628; train accuracy : 0.9745373772421698; \n",
      " validation loss : 0.6117931357944443; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5762229705313375; train accuracy : 0.9747705938845689; \n",
      " validation loss : 0.6273700216930426; validation accuracy : 0.9205020920502092\n",
      "Epoch 27:\t train loss : 0.5822197482018779; train accuracy : 0.9689354688806964; \n",
      " validation loss : 0.622930902875423; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.5765975550828099; train accuracy : 0.9748216487499612; \n",
      " validation loss : 0.6255170352244277; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5711545281133277; train accuracy : 0.9799315963939403; \n",
      " validation loss : 0.6256823424401791; validation accuracy : 0.9205020920502092\n",
      "Epoch 30:\t train loss : 0.5745823634693223; train accuracy : 0.9766376901390997; \n",
      " validation loss : 0.6234477511176745; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5895080173296688; train accuracy : 0.9614767495895165; \n",
      " validation loss : 0.6339940264225399; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.5826213649537302; train accuracy : 0.9685017503640138; \n",
      " validation loss : 0.6247943208734963; validation accuracy : 0.9205020920502092\n",
      "Epoch 33:\t train loss : 0.5731701232734746; train accuracy : 0.9783232442145048; \n",
      " validation loss : 0.5972710715831556; validation accuracy : 0.9539748953974896\n",
      "Epoch 34:\t train loss : 0.5737865517656275; train accuracy : 0.9776663465410949; \n",
      " validation loss : 0.61367937068441; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5794255002716527; train accuracy : 0.9717400167291428; \n",
      " validation loss : 0.623734987437338; validation accuracy : 0.9246861924686193\n",
      "Epoch 36:\t train loss : 0.5730515515111831; train accuracy : 0.978191269865857; \n",
      " validation loss : 0.6278023373993172; validation accuracy : 0.9163179916317992\n",
      "Epoch 37:\t train loss : 0.5745118028613008; train accuracy : 0.9766339725518138; \n",
      " validation loss : 0.6206659570319989; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5688990883133361; train accuracy : 0.9824108553548747; \n",
      " validation loss : 0.6142294268631204; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5792583869984131; train accuracy : 0.9717336968307568; \n",
      " validation loss : 0.6070581705557521; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.570990732843561; train accuracy : 0.9801045881223086; \n",
      " validation loss : 0.6053872691990307; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5688769022601424; train accuracy : 0.9823870627962452; \n",
      " validation loss : 0.6100768031925207; validation accuracy : 0.9414225941422594\n",
      "Epoch 42:\t train loss : 0.5700066336331125; train accuracy : 0.9810431549924099; \n",
      " validation loss : 0.6035282965535654; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.5698824186749274; train accuracy : 0.9813374639858732; \n",
      " validation loss : 0.6040830833064362; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5694033230512943; train accuracy : 0.981782087425261; \n",
      " validation loss : 0.6180081804039091; validation accuracy : 0.9330543933054394\n",
      "Epoch 45:\t train loss : 0.5673759599966911; train accuracy : 0.9838815328851576; \n",
      " validation loss : 0.6215196820706759; validation accuracy : 0.9288702928870293\n",
      "Epoch 46:\t train loss : 0.5672078908581775; train accuracy : 0.9839661699556987; \n",
      " validation loss : 0.606424488923171; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5676111627081619; train accuracy : 0.9837028408562842; \n",
      " validation loss : 0.607514878931202; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5686244684449726; train accuracy : 0.9825511323151275; \n",
      " validation loss : 0.5989176885223362; validation accuracy : 0.9497907949790795\n",
      "Epoch 49:\t train loss : 0.5678686205559921; train accuracy : 0.9833419870504043; \n",
      " validation loss : 0.6038408445483003; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5711392771759107; train accuracy : 0.9800417608971778; \n",
      " validation loss : 0.6039923124127046; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5676638170963716; train accuracy : 0.983429474271198; \n",
      " validation loss : 0.6152667948317943; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.565288200969039; train accuracy : 0.9858960934353604; \n",
      " validation loss : 0.6053420641980826; validation accuracy : 0.9497907949790795\n",
      "Epoch 53:\t train loss : 0.5703052590305108; train accuracy : 0.9808171256854301; \n",
      " validation loss : 0.614612470572565; validation accuracy : 0.9372384937238494\n",
      "Epoch 54:\t train loss : 0.5666114113330991; train accuracy : 0.9845447504569534; \n",
      " validation loss : 0.6140802843669184; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.56757838990344; train accuracy : 0.9836517859908919; \n",
      " validation loss : 0.6061022586523316; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5663906143841175; train accuracy : 0.9849274141082438; \n",
      " validation loss : 0.5977333347429686; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5659912393136588; train accuracy : 0.9851287834195607; \n",
      " validation loss : 0.608036023414721; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5780767447176498; train accuracy : 0.9727878806654481; \n",
      " validation loss : 0.6215020949060558; validation accuracy : 0.9288702928870293\n",
      "Epoch 59:\t train loss : 0.5690041009392655; train accuracy : 0.9822430682487066; \n",
      " validation loss : 0.5944055327169225; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5645031564211751; train accuracy : 0.9867497753957681; \n",
      " validation loss : 0.6098271467309165; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5707310610908679; train accuracy : 0.9804181046500821; \n",
      " validation loss : 0.6325442373347726; validation accuracy : 0.9205020920502092\n",
      "Epoch 62:\t train loss : 0.5710535936602155; train accuracy : 0.9800638185817404; \n",
      " validation loss : 0.661468525588221; validation accuracy : 0.8828451882845189\n",
      "Epoch 63:\t train loss : 0.5727492320025221; train accuracy : 0.978224852071006; \n",
      " validation loss : 0.6052463226493289; validation accuracy : 0.9414225941422594\n",
      "Epoch 64:\t train loss : 0.5640037498962253; train accuracy : 0.9872336813408098; \n",
      " validation loss : 0.6158962940494326; validation accuracy : 0.9330543933054394\n",
      "Epoch 65:\t train loss : 0.5666759593763442; train accuracy : 0.9844873756931751; \n",
      " validation loss : 0.5968697259203087; validation accuracy : 0.9539748953974896\n",
      "Epoch 66:\t train loss : 0.5648072962681229; train accuracy : 0.9864454289166331; \n",
      " validation loss : 0.61328950778602; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5626638149403188; train accuracy : 0.9887069611821928; \n",
      " validation loss : 0.5954504465324763; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5652506291319328; train accuracy : 0.9859752780445491; \n",
      " validation loss : 0.5932249614673296; validation accuracy : 0.9581589958158996\n",
      "Epoch 69:\t train loss : 0.5675921105955384; train accuracy : 0.9835734688187366; \n",
      " validation loss : 0.5944552551676132; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5653376883891529; train accuracy : 0.9857429288391834; \n",
      " validation loss : 0.6025646995851786; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.566249612942222; train accuracy : 0.9851178784968555; \n",
      " validation loss : 0.5918963092805275; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5795183887953381; train accuracy : 0.9713409956937947; \n",
      " validation loss : 0.6279303503976287; validation accuracy : 0.9205020920502092\n",
      "Epoch 73:\t train loss : 0.5815832234539845; train accuracy : 0.9691531955760712; \n",
      " validation loss : 0.6139159400184464; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74:\t train loss : 0.5768498845469703; train accuracy : 0.9740944886768488; \n",
      " validation loss : 0.600173803446564; validation accuracy : 0.9497907949790795\n",
      "Epoch 75:\t train loss : 0.5655802414387351; train accuracy : 0.9856964589981102; \n",
      " validation loss : 0.6158991199045609; validation accuracy : 0.9330543933054394\n",
      "Epoch 76:\t train loss : 0.5633162179024378; train accuracy : 0.9878796740915146; \n",
      " validation loss : 0.5865465849928371; validation accuracy : 0.9623430962343096\n",
      "Epoch 77:\t train loss : 0.5628166771750279; train accuracy : 0.9884436320827783; \n",
      " validation loss : 0.6230983564623941; validation accuracy : 0.9288702928870293\n",
      "Epoch 78:\t train loss : 0.5769415605035049; train accuracy : 0.973870442083088; \n",
      " validation loss : 0.6251158406881102; validation accuracy : 0.9246861924686193\n",
      "Epoch 79:\t train loss : 0.5731407588737768; train accuracy : 0.9777446637132501; \n",
      " validation loss : 0.6154962908969819; validation accuracy : 0.9330543933054394\n",
      "Epoch 80:\t train loss : 0.5643481342196073; train accuracy : 0.986738870473063; \n",
      " validation loss : 0.594152287850709; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.5616874576074002; train accuracy : 0.9894914960190836; \n",
      " validation loss : 0.6067994311991636; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.565753972091045; train accuracy : 0.9853201152452059; \n",
      " validation loss : 0.5942458199918875; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5621069655774509; train accuracy : 0.9892600142507513; \n",
      " validation loss : 0.5993896825262399; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5605937169909959; train accuracy : 0.9907261067567149; \n",
      " validation loss : 0.6014044988651502; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5654214870335311; train accuracy : 0.9858659809783451; \n",
      " validation loss : 0.6280269753477622; validation accuracy : 0.9246861924686193\n",
      "Epoch 86:\t train loss : 0.5696061896149038; train accuracy : 0.9815087208401747; \n",
      " validation loss : 0.6168401060532674; validation accuracy : 0.9330543933054394\n",
      "Epoch 87:\t train loss : 0.5661483805661277; train accuracy : 0.9849119241612194; \n",
      " validation loss : 0.5963948285418625; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5657122855372322; train accuracy : 0.985511447070851; \n",
      " validation loss : 0.6073486458594575; validation accuracy : 0.9456066945606695\n",
      "Epoch 89:\t train loss : 0.5612203164320912; train accuracy : 0.9900491341119614; \n",
      " validation loss : 0.6301915254875168; validation accuracy : 0.9205020920502092\n",
      "Epoch 90:\t train loss : 0.562596025948755; train accuracy : 0.9887534310232658; \n",
      " validation loss : 0.6142850058106545; validation accuracy : 0.9330543933054394\n",
      "Epoch 91:\t train loss : 0.5604278073116921; train accuracy : 0.9909111186839741; \n",
      " validation loss : 0.6112234541677848; validation accuracy : 0.9372384937238494\n",
      "Epoch 92:\t train loss : 0.559715732980238; train accuracy : 0.9916345611698008; \n",
      " validation loss : 0.6029260604384168; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5642606877771015; train accuracy : 0.986904674866012; \n",
      " validation loss : 0.5945660516328427; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5678315488081102; train accuracy : 0.9832289723969144; \n",
      " validation loss : 0.6063327440993671; validation accuracy : 0.9372384937238494\n",
      "Epoch 95:\t train loss : 0.5623756261632419; train accuracy : 0.9890686824251061; \n",
      " validation loss : 0.6155006010961641; validation accuracy : 0.9330543933054394\n",
      "Epoch 96:\t train loss : 0.5600575419633412; train accuracy : 0.9913657796090337; \n",
      " validation loss : 0.6183579565799894; validation accuracy : 0.9330543933054394\n",
      "Epoch 97:\t train loss : 0.5615139749143797; train accuracy : 0.9895781158028439; \n",
      " validation loss : 0.6017776093780312; validation accuracy : 0.9497907949790795\n",
      "Epoch 98:\t train loss : 0.5642522907171228; train accuracy : 0.9869829920381672; \n",
      " validation loss : 0.5941134009469957; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5645826702582751; train accuracy : 0.9865894234641718; \n",
      " validation loss : 0.6056916046215605; validation accuracy : 0.9456066945606695\n",
      "Epoch 100:\t train loss : 0.5655697563461812; train accuracy : 0.9857383438148641; \n",
      " validation loss : 0.5967652466107194; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5623968632979766; train accuracy : 0.9887898633786673; \n",
      " validation loss : 0.6049777751328376; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5614965745262559; train accuracy : 0.9898569348492828; \n",
      " validation loss : 0.6080154830699176; validation accuracy : 0.9414225941422594\n",
      "Epoch 103:\t train loss : 0.5633112847419993; train accuracy : 0.9878951640385389; \n",
      " validation loss : 0.5973867633973435; validation accuracy : 0.9539748953974896\n",
      "Epoch 104:\t train loss : 0.5656075458362998; train accuracy : 0.9855515970135382; \n",
      " validation loss : 0.6060404426228828; validation accuracy : 0.9456066945606695\n",
      "Epoch 105:\t train loss : 0.5668897183962606; train accuracy : 0.9842923262802441; \n",
      " validation loss : 0.6092803784583443; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.5640398689216645; train accuracy : 0.9871570990427213; \n",
      " validation loss : 0.5987255986865122; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.5609756692572514; train accuracy : 0.990344310542458; \n",
      " validation loss : 0.5955794483174681; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5602338928218704; train accuracy : 0.9911133554323244; \n",
      " validation loss : 0.6044434125269635; validation accuracy : 0.9456066945606695\n",
      "Epoch 109:\t train loss : 0.5597203748293733; train accuracy : 0.9916354286068342; \n",
      " validation loss : 0.6069022798436222; validation accuracy : 0.9456066945606695\n",
      "Epoch 110:\t train loss : 0.5618685236002755; train accuracy : 0.9894349886923387; \n",
      " validation loss : 0.5858140304903584; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5681440985742725; train accuracy : 0.9832401251587719; \n",
      " validation loss : 0.5957040365359417; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5752891942922944; train accuracy : 0.9757874779268255; \n",
      " validation loss : 0.6064015414458527; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5683467062802198; train accuracy : 0.9828517612069767; \n",
      " validation loss : 0.604838083290534; validation accuracy : 0.9456066945606695\n",
      "Epoch 114:\t train loss : 0.5633265373298945; train accuracy : 0.9879060689612441; \n",
      " validation loss : 0.6175394752681431; validation accuracy : 0.9330543933054394\n",
      "Epoch 115:\t train loss : 0.5616062397456982; train accuracy : 0.9896627528733851; \n",
      " validation loss : 0.6126755514929031; validation accuracy : 0.9372384937238494\n",
      "Epoch 116:\t train loss : 0.5622717052301319; train accuracy : 0.9889401778245919; \n",
      " validation loss : 0.5967120778795371; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5588199464764231; train accuracy : 0.9926414077263855; \n",
      " validation loss : 0.6301794725888903; validation accuracy : 0.9205020920502092\n",
      "Epoch 118:\t train loss : 0.5601907263206037; train accuracy : 0.9910413581585551; \n",
      " validation loss : 0.5884279508704792; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.561369867775013; train accuracy : 0.9899461569441432; \n",
      " validation loss : 0.5835858692054163; validation accuracy : 0.9665271966527197\n",
      "Epoch 120:\t train loss : 0.5614049821733939; train accuracy : 0.9899725518138728; \n",
      " validation loss : 0.5994478779015943; validation accuracy : 0.9539748953974896\n",
      "Epoch 121:\t train loss : 0.5592904144333183; train accuracy : 0.9920938071191796; \n",
      " validation loss : 0.6309290734388083; validation accuracy : 0.9205020920502092\n",
      "Epoch 122:\t train loss : 0.5606051159112285; train accuracy : 0.9907461817280585; \n",
      " validation loss : 0.5881865047223925; validation accuracy : 0.9623430962343096\n",
      "Epoch 123:\t train loss : 0.566905856532203; train accuracy : 0.9842358189534992; \n",
      " validation loss : 0.5848817193155118; validation accuracy : 0.9665271966527197\n",
      "Epoch 124:\t train loss : 0.5621772598669134; train accuracy : 0.9890841723721305; \n",
      " validation loss : 0.5944911466475542; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125:\t train loss : 0.5591472859822045; train accuracy : 0.9922076892097029; \n",
      " validation loss : 0.6026850632922988; validation accuracy : 0.9456066945606695\n",
      "Epoch 126:\t train loss : 0.5602118707977802; train accuracy : 0.9910614331298987; \n",
      " validation loss : 0.5911582179212194; validation accuracy : 0.9581589958158996\n",
      "Epoch 127:\t train loss : 0.5574503030068803; train accuracy : 0.9939270733294092; \n",
      " validation loss : 0.588650591482496; validation accuracy : 0.9623430962343096\n",
      "Epoch 128:\t train loss : 0.5582456320794132; train accuracy : 0.9931580284395427; \n",
      " validation loss : 0.6056068683417151; validation accuracy : 0.9456066945606695\n",
      "Epoch 129:\t train loss : 0.5612119550950775; train accuracy : 0.9900390966262895; \n",
      " validation loss : 0.5966182555385057; validation accuracy : 0.9539748953974896\n",
      "Epoch 130:\t train loss : 0.5602566677243226; train accuracy : 0.9910869605625948; \n",
      " validation loss : 0.6107743044775401; validation accuracy : 0.9414225941422594\n",
      "Epoch 131:\t train loss : 0.5662469094658186; train accuracy : 0.9847871371479909; \n",
      " validation loss : 0.5910873354092386; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.5608230029847269; train accuracy : 0.9904008178692029; \n",
      " validation loss : 0.6041558192093114; validation accuracy : 0.9456066945606695\n",
      "Epoch 133:\t train loss : 0.5651417619756871; train accuracy : 0.9861832150934043; \n",
      " validation loss : 0.6494998017797622; validation accuracy : 0.895397489539749\n",
      "Epoch 134:\t train loss : 0.5725062773548175; train accuracy : 0.9786795129960656; \n",
      " validation loss : 0.6045112261232973; validation accuracy : 0.9456066945606695\n",
      "Epoch 135:\t train loss : 0.5614293465587331; train accuracy : 0.9898732922333405; \n",
      " validation loss : 0.5943799624203949; validation accuracy : 0.9539748953974896\n",
      "Epoch 136:\t train loss : 0.5582454833843364; train accuracy : 0.9931944607949441; \n",
      " validation loss : 0.6093523241605966; validation accuracy : 0.9414225941422594\n",
      "Epoch 137:\t train loss : 0.558809434903571; train accuracy : 0.9925685430155828; \n",
      " validation loss : 0.6032146609777957; validation accuracy : 0.9456066945606695\n",
      "Epoch 138:\t train loss : 0.557424079229842; train accuracy : 0.9938960934353605; \n",
      " validation loss : 0.6141428425519022; validation accuracy : 0.9372384937238494\n",
      "Epoch 139:\t train loss : 0.5587587170931497; train accuracy : 0.9925229406115431; \n",
      " validation loss : 0.6033306432689074; validation accuracy : 0.9497907949790795\n",
      "Epoch 140:\t train loss : 0.5610053499929482; train accuracy : 0.9903434431054245; \n",
      " validation loss : 0.614540797214684; validation accuracy : 0.9330543933054394\n",
      "Epoch 141:\t train loss : 0.558475304309043; train accuracy : 0.9929867715852412; \n",
      " validation loss : 0.6019156321018877; validation accuracy : 0.9497907949790795\n",
      "Epoch 142:\t train loss : 0.5580827861364532; train accuracy : 0.9932291582762787; \n",
      " validation loss : 0.5919278594855777; validation accuracy : 0.9581589958158996\n",
      "Epoch 143:\t train loss : 0.5593222859247686; train accuracy : 0.9919762074413705; \n",
      " validation loss : 0.6014253664829652; validation accuracy : 0.9497907949790795\n",
      "Epoch 144:\t train loss : 0.561336588740215; train accuracy : 0.9900227392422318; \n",
      " validation loss : 0.6249970951788809; validation accuracy : 0.9246861924686193\n",
      "Epoch 145:\t train loss : 0.5621176987361428; train accuracy : 0.9892080919483255; \n",
      " validation loss : 0.5971198929837515; validation accuracy : 0.9539748953974896\n",
      "Epoch 146:\t train loss : 0.5588654484598238; train accuracy : 0.9924873756931751; \n",
      " validation loss : 0.6027720241486011; validation accuracy : 0.9497907949790795\n",
      "Epoch 147:\t train loss : 0.5627334938949095; train accuracy : 0.9884427646457449; \n",
      " validation loss : 0.6166799342850848; validation accuracy : 0.9330543933054394\n",
      "Epoch 148:\t train loss : 0.5628563467831637; train accuracy : 0.9883498249635986; \n",
      " validation loss : 0.6020688466888612; validation accuracy : 0.9497907949790795\n",
      "Epoch 149:\t train loss : 0.5739201725629441; train accuracy : 0.9769747513863503; \n",
      " validation loss : 0.5856331142554962; validation accuracy : 0.9665271966527197\n",
      "Epoch 150:\t train loss : 0.56099371230082; train accuracy : 0.9902304284519347; \n",
      " validation loss : 0.5890278041278765; validation accuracy : 0.9623430962343096\n",
      "Epoch 151:\t train loss : 0.558964848461811; train accuracy : 0.9923734936026519; \n",
      " validation loss : 0.5994616936597132; validation accuracy : 0.9497907949790795\n",
      "Epoch 152:\t train loss : 0.5578783456570829; train accuracy : 0.9935607670621767; \n",
      " validation loss : 0.5776962312374633; validation accuracy : 0.9748953974895398\n",
      "Epoch 153:\t train loss : 0.556474606626022; train accuracy : 0.994933919885994; \n",
      " validation loss : 0.5933046269479102; validation accuracy : 0.9581589958158996\n",
      "Epoch 154:\t train loss : 0.5579260920743726; train accuracy : 0.993395830106261; \n",
      " validation loss : 0.5852517664928543; validation accuracy : 0.9665271966527197\n",
      "Epoch 155:\t train loss : 0.5589361287527315; train accuracy : 0.9922951764304966; \n",
      " validation loss : 0.5886702662802197; validation accuracy : 0.9623430962343096\n",
      "Epoch 156:\t train loss : 0.5602597971180989; train accuracy : 0.9910978654853; \n",
      " validation loss : 0.6186121934025298; validation accuracy : 0.9288702928870293\n",
      "Epoch 157:\t train loss : 0.5574052650643666; train accuracy : 0.9939680907091297; \n",
      " validation loss : 0.6045037655912027; validation accuracy : 0.9456066945606695\n",
      "Epoch 158:\t train loss : 0.5566817971228586; train accuracy : 0.9947124756033334; \n",
      " validation loss : 0.5970624495705327; validation accuracy : 0.9497907949790795\n",
      "Epoch 159:\t train loss : 0.5587576521423019; train accuracy : 0.9924300009293968; \n",
      " validation loss : 0.6057750708978861; validation accuracy : 0.9456066945606695\n",
      "Epoch 160:\t train loss : 0.5608251754537023; train accuracy : 0.990447287710276; \n",
      " validation loss : 0.6015090340802304; validation accuracy : 0.9497907949790795\n",
      "Epoch 161:\t train loss : 0.561510916030993; train accuracy : 0.989874159670374; \n",
      " validation loss : 0.5874383772472086; validation accuracy : 0.9623430962343096\n",
      "Epoch 162:\t train loss : 0.5587006737392346; train accuracy : 0.992642275163419; \n",
      " validation loss : 0.6115087417728373; validation accuracy : 0.9414225941422594\n",
      "Epoch 163:\t train loss : 0.5583520478690305; train accuracy : 0.9929930914836271; \n",
      " validation loss : 0.5971300958147413; validation accuracy : 0.9539748953974896\n",
      "Epoch 164:\t train loss : 0.5573714874868546; train accuracy : 0.9940053905015644; \n",
      " validation loss : 0.597396170617095; validation accuracy : 0.9539748953974896\n",
      "Epoch 165:\t train loss : 0.5582742974491054; train accuracy : 0.9929621115895784; \n",
      " validation loss : 0.5861771856780749; validation accuracy : 0.9665271966527197\n",
      "Epoch 166:\t train loss : 0.5569278014553204; train accuracy : 0.994428204095542; \n",
      " validation loss : 0.5970168787978448; validation accuracy : 0.9539748953974896\n",
      "Epoch 167:\t train loss : 0.556879961232869; train accuracy : 0.9944491465039189; \n",
      " validation loss : 0.5892698529637509; validation accuracy : 0.9623430962343096\n",
      "Epoch 168:\t train loss : 0.5565066239106075; train accuracy : 0.9948054152854797; \n",
      " validation loss : 0.5908919232858901; validation accuracy : 0.9581589958158996\n",
      "Epoch 169:\t train loss : 0.559665410083917; train accuracy : 0.9915989962514328; \n",
      " validation loss : 0.5826019296131224; validation accuracy : 0.9665271966527197\n",
      "Epoch 170:\t train loss : 0.5636598317570719; train accuracy : 0.9875971374577899; \n",
      " validation loss : 0.5920475241055615; validation accuracy : 0.9581589958158996\n",
      "Epoch 171:\t train loss : 0.562333961545508; train accuracy : 0.9889166331051148; \n",
      " validation loss : 0.5975242019284099; validation accuracy : 0.9539748953974896\n",
      "Epoch 172:\t train loss : 0.5575570034142939; train accuracy : 0.9938651135413117; \n",
      " validation loss : 0.5769917312724676; validation accuracy : 0.9748953974895398\n",
      "Epoch 173:\t train loss : 0.5574618274318706; train accuracy : 0.993865980978345; \n",
      " validation loss : 0.592917034899718; validation accuracy : 0.9581589958158996\n",
      "Epoch 174:\t train loss : 0.5551472341465806; train accuracy : 0.9962405278973946; \n",
      " validation loss : 0.5844960867269464; validation accuracy : 0.9665271966527197\n",
      "Epoch 175:\t train loss : 0.5553726508651402; train accuracy : 0.9959981412063571; \n",
      " validation loss : 0.5802180102164203; validation accuracy : 0.9748953974895398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176:\t train loss : 0.5586632639927719; train accuracy : 0.9926523126490907; \n",
      " validation loss : 0.6012613394777534; validation accuracy : 0.9497907949790795\n",
      "Epoch 177:\t train loss : 0.5598853553845721; train accuracy : 0.9914641717525327; \n",
      " validation loss : 0.5811697238237082; validation accuracy : 0.9665271966527197\n",
      "Epoch 178:\t train loss : 0.5567983990988173; train accuracy : 0.9944692214752625; \n",
      " validation loss : 0.6007809096435479; validation accuracy : 0.9497907949790795\n",
      "Epoch 179:\t train loss : 0.5584859921099474; train accuracy : 0.9928946993401282; \n",
      " validation loss : 0.5946170484824103; validation accuracy : 0.9539748953974896\n",
      "Epoch 180:\t train loss : 0.5559737067751551; train accuracy : 0.99536850583971; \n",
      " validation loss : 0.5807510945854426; validation accuracy : 0.9707112970711297\n",
      "Epoch 181:\t train loss : 0.5567601037689828; train accuracy : 0.9945412187490319; \n",
      " validation loss : 0.5837539941632688; validation accuracy : 0.9665271966527197\n",
      "Epoch 182:\t train loss : 0.5621365867186341; train accuracy : 0.9891707921558909; \n",
      " validation loss : 0.6016763989820583; validation accuracy : 0.9497907949790795\n",
      "Epoch 183:\t train loss : 0.5586446026639477; train accuracy : 0.9926832925431395; \n",
      " validation loss : 0.5913189483047651; validation accuracy : 0.9581589958158996\n",
      "Epoch 184:\t train loss : 0.5567962524581457; train accuracy : 0.9945265962390408; \n",
      " validation loss : 0.5936845697752414; validation accuracy : 0.9581589958158996\n",
      "Epoch 185:\t train loss : 0.5557157192344752; train accuracy : 0.9955954025837231; \n",
      " validation loss : 0.5859518352356237; validation accuracy : 0.9665271966527197\n",
      "Epoch 186:\t train loss : 0.5576946808272009; train accuracy : 0.9936017844418972; \n",
      " validation loss : 0.6025229867415157; validation accuracy : 0.9456066945606695\n",
      "Epoch 187:\t train loss : 0.5610749578117594; train accuracy : 0.9901211313857307; \n",
      " validation loss : 0.6281794354996586; validation accuracy : 0.9205020920502092\n",
      "Epoch 188:\t train loss : 0.5593941462111309; train accuracy : 0.9919343226246166; \n",
      " validation loss : 0.590056116715687; validation accuracy : 0.9623430962343096\n",
      "Epoch 189:\t train loss : 0.5562350231090779; train accuracy : 0.9951307041729918; \n",
      " validation loss : 0.6057554198331749; validation accuracy : 0.9456066945606695\n",
      "Epoch 190:\t train loss : 0.5555275064162278; train accuracy : 0.9958587316831377; \n",
      " validation loss : 0.5850949314179823; validation accuracy : 0.9665271966527197\n",
      "Epoch 191:\t train loss : 0.5575596981269626; train accuracy : 0.9938031537532142; \n",
      " validation loss : 0.5918428016538327; validation accuracy : 0.9623430962343096\n",
      "Epoch 192:\t train loss : 0.5569403622107748; train accuracy : 0.9944683540382292; \n",
      " validation loss : 0.6094489006930428; validation accuracy : 0.9414225941422594\n",
      "Epoch 193:\t train loss : 0.5576387618061325; train accuracy : 0.9936746491526999; \n",
      " validation loss : 0.6047191688839079; validation accuracy : 0.9456066945606695\n",
      "Epoch 194:\t train loss : 0.5560712641335632; train accuracy : 0.9952847362062022; \n",
      " validation loss : 0.6056003804819328; validation accuracy : 0.9456066945606695\n",
      "Epoch 195:\t train loss : 0.556707343157581; train accuracy : 0.9946860807336039; \n",
      " validation loss : 0.6109971890679814; validation accuracy : 0.9414225941422594\n",
      "Epoch 196:\t train loss : 0.5631845198776904; train accuracy : 0.9880910808885034; \n",
      " validation loss : 0.5927313242822162; validation accuracy : 0.9581589958158996\n",
      "Epoch 197:\t train loss : 0.5565578533666717; train accuracy : 0.9948263576938566; \n",
      " validation loss : 0.597476201690063; validation accuracy : 0.9539748953974896\n",
      "Epoch 198:\t train loss : 0.5560501337722158; train accuracy : 0.9953421109699805; \n",
      " validation loss : 0.5885754208348718; validation accuracy : 0.9623430962343096\n",
      "Epoch 199:\t train loss : 0.5650581791105737; train accuracy : 0.986188667554757; \n",
      " validation loss : 0.668250386458342; validation accuracy : 0.8828451882845189\n",
      "Epoch 200:\t train loss : 0.5686676760698283; train accuracy : 0.9824946249883826; \n",
      " validation loss : 0.6241743718390852; validation accuracy : 0.9288702928870293\n",
      "Epoch 201:\t train loss : 0.5600963174487977; train accuracy : 0.9911735803463552; \n",
      " validation loss : 0.6134029696244524; validation accuracy : 0.9330543933054394\n",
      "Epoch 202:\t train loss : 0.5631088242352482; train accuracy : 0.9881074382725611; \n",
      " validation loss : 0.595202790411729; validation accuracy : 0.9539748953974896\n",
      "Epoch 203:\t train loss : 0.5570859362313443; train accuracy : 0.9942523622169213; \n",
      " validation loss : 0.5868891667684818; validation accuracy : 0.9665271966527197\n",
      "Epoch 204:\t train loss : 0.5559231067980415; train accuracy : 0.9954450881377985; \n",
      " validation loss : 0.6176883653056192; validation accuracy : 0.9330543933054394\n",
      "Epoch 205:\t train loss : 0.5549680768790035; train accuracy : 0.9964100498776294; \n",
      " validation loss : 0.5987018253728642; validation accuracy : 0.9497907949790795\n",
      "Epoch 206:\t train loss : 0.5547825803169683; train accuracy : 0.9965967966789554; \n",
      " validation loss : 0.5932627251411411; validation accuracy : 0.9581589958158996\n",
      "Epoch 207:\t train loss : 0.5583809032065976; train accuracy : 0.9928482294990552; \n",
      " validation loss : 0.5966756351061655; validation accuracy : 0.9539748953974896\n",
      "Epoch 208:\t train loss : 0.555533221928924; train accuracy : 0.9957812819480157; \n",
      " validation loss : 0.5853062004653422; validation accuracy : 0.9665271966527197\n",
      "Epoch 209:\t train loss : 0.5568268415537847; train accuracy : 0.9945521236717371; \n",
      " validation loss : 0.6093079114336706; validation accuracy : 0.9414225941422594\n",
      "Epoch 210:\t train loss : 0.5584091892828008; train accuracy : 0.9928528145233744; \n",
      " validation loss : 0.6043228308593679; validation accuracy : 0.9456066945606695\n",
      "Epoch 211:\t train loss : 0.556868308414184; train accuracy : 0.9943972242014932; \n",
      " validation loss : 0.5932998130678299; validation accuracy : 0.9581589958158996\n",
      "Epoch 212:\t train loss : 0.554656361460083; train accuracy : 0.9967307537408222; \n",
      " validation loss : 0.5856600107178324; validation accuracy : 0.9665271966527197\n",
      "Epoch 213:\t train loss : 0.55417954420499; train accuracy : 0.9972063570742588; \n",
      " validation loss : 0.5810555649659267; validation accuracy : 0.9707112970711297\n",
      "Epoch 214:\t train loss : 0.5591769605270961; train accuracy : 0.9921821617770067; \n",
      " validation loss : 0.6051871422142032; validation accuracy : 0.9456066945606695\n",
      "Epoch 215:\t train loss : 0.5559456693106688; train accuracy : 0.9954614455218563; \n",
      " validation loss : 0.5915277921336541; validation accuracy : 0.9581589958158996\n",
      "Epoch 216:\t train loss : 0.5544408845493884; train accuracy : 0.9969740078688931; \n",
      " validation loss : 0.5829184305865297; validation accuracy : 0.9665271966527197\n",
      "Epoch 217:\t train loss : 0.5552285631719368; train accuracy : 0.9961430031909291; \n",
      " validation loss : 0.6061042369794952; validation accuracy : 0.9456066945606695\n",
      "Epoch 218:\t train loss : 0.5568238816180295; train accuracy : 0.9945466712103844; \n",
      " validation loss : 0.6056748334928674; validation accuracy : 0.9456066945606695\n",
      "Epoch 219:\t train loss : 0.555536160416501; train accuracy : 0.9958277517890889; \n",
      " validation loss : 0.5832064836824434; validation accuracy : 0.9665271966527197\n",
      "Epoch 220:\t train loss : 0.5555483253853782; train accuracy : 0.9959043340871774; \n",
      " validation loss : 0.6149346128079449; validation accuracy : 0.9372384937238494\n",
      "Epoch 221:\t train loss : 0.5660170589139947; train accuracy : 0.9852417980730506; \n",
      " validation loss : 0.5929808946165823; validation accuracy : 0.9581589958158996\n",
      "Epoch 222:\t train loss : 0.5565142253048447; train accuracy : 0.9948564701508721; \n",
      " validation loss : 0.6015538092022344; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 222\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5575570034142939; Train accuracy : 0.9938651135413117; \n",
      " Validation loss : 0.5769917312724676; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 64 ! ---\n",
      "Epoch 1:\t train loss : 0.9152724051276779; train accuracy : 0.6123129588896806; \n",
      " validation loss : 0.802746429967909; validation accuracy : 0.7447698744769874\n",
      "Epoch 2:\t train loss : 0.7262627584259795; train accuracy : 0.8244623439387837; \n",
      " validation loss : 0.7670475216704437; validation accuracy : 0.7782426778242678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\t train loss : 0.6793739395227969; train accuracy : 0.8707543604200874; \n",
      " validation loss : 0.7270063798013313; validation accuracy : 0.8200836820083682\n",
      "Epoch 4:\t train loss : 0.6596378689020584; train accuracy : 0.8907887481024814; \n",
      " validation loss : 0.6889874366729527; validation accuracy : 0.8577405857740585\n",
      "Epoch 5:\t train loss : 0.6447881203960838; train accuracy : 0.9054502927599988; \n",
      " validation loss : 0.6895734343926988; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6328334708336828; train accuracy : 0.9182081229282196; \n",
      " validation loss : 0.6617445249255561; validation accuracy : 0.891213389121339\n",
      "Epoch 7:\t train loss : 0.621921990876354; train accuracy : 0.9291034418662288; \n",
      " validation loss : 0.6634028679383199; validation accuracy : 0.891213389121339\n",
      "Epoch 8:\t train loss : 0.6150318204306684; train accuracy : 0.9356652932246972; \n",
      " validation loss : 0.673617586932942; validation accuracy : 0.8744769874476988\n",
      "Epoch 9:\t train loss : 0.616344956732503; train accuracy : 0.9342845193469438; \n",
      " validation loss : 0.6955895850909278; validation accuracy : 0.8577405857740585\n",
      "Epoch 10:\t train loss : 0.6218137785098585; train accuracy : 0.9285244276464575; \n",
      " validation loss : 0.6615136723023753; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.60945123887371; train accuracy : 0.9413036339415719; \n",
      " validation loss : 0.6520395019566047; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.6085024395383959; train accuracy : 0.941890702933796; \n",
      " validation loss : 0.6690322178454973; validation accuracy : 0.8786610878661087\n",
      "Epoch 13:\t train loss : 0.5946596535914128; train accuracy : 0.956243997645528; \n",
      " validation loss : 0.6626485447137981; validation accuracy : 0.8828451882845189\n",
      "Epoch 14:\t train loss : 0.5924427015200117; train accuracy : 0.9579884754794139; \n",
      " validation loss : 0.6628342573417391; validation accuracy : 0.8870292887029289\n",
      "Epoch 15:\t train loss : 0.5907724606247453; train accuracy : 0.9604417732891354; \n",
      " validation loss : 0.6588331728488929; validation accuracy : 0.891213389121339\n",
      "Epoch 16:\t train loss : 0.5947069567241599; train accuracy : 0.956445366956845; \n",
      " validation loss : 0.6808762569593173; validation accuracy : 0.8619246861924686\n",
      "Epoch 17:\t train loss : 0.5899492889102186; train accuracy : 0.9608268533721614; \n",
      " validation loss : 0.661581878402413; validation accuracy : 0.8870292887029289\n",
      "Epoch 18:\t train loss : 0.5868881637143555; train accuracy : 0.9639970259301713; \n",
      " validation loss : 0.6491918080379383; validation accuracy : 0.891213389121339\n",
      "Epoch 19:\t train loss : 0.5815173271043521; train accuracy : 0.9697320239164782; \n",
      " validation loss : 0.6355387625742903; validation accuracy : 0.9121338912133892\n",
      "Epoch 20:\t train loss : 0.5843332253437158; train accuracy : 0.9667697264475356; \n",
      " validation loss : 0.6414069733713522; validation accuracy : 0.9121338912133892\n",
      "Epoch 21:\t train loss : 0.5895104853966748; train accuracy : 0.9614972582793767; \n",
      " validation loss : 0.6763941194704255; validation accuracy : 0.8744769874476988\n",
      "Epoch 22:\t train loss : 0.5837731656884945; train accuracy : 0.9671318814089656; \n",
      " validation loss : 0.6342177089319236; validation accuracy : 0.9246861924686193\n",
      "Epoch 23:\t train loss : 0.5768876918570556; train accuracy : 0.9742513708603117; \n",
      " validation loss : 0.6278469349169097; validation accuracy : 0.9163179916317992\n",
      "Epoch 24:\t train loss : 0.5888671863888651; train accuracy : 0.9619096006691658; \n",
      " validation loss : 0.6350907577010965; validation accuracy : 0.9163179916317992\n",
      "Epoch 25:\t train loss : 0.5750313912576559; train accuracy : 0.976208990365253; \n",
      " validation loss : 0.6662016097821871; validation accuracy : 0.8828451882845189\n",
      "Epoch 26:\t train loss : 0.5831151383565754; train accuracy : 0.9677146132160228; \n",
      " validation loss : 0.6363076408885441; validation accuracy : 0.9079497907949791\n",
      "Epoch 27:\t train loss : 0.5816920852925728; train accuracy : 0.9692636079184609; \n",
      " validation loss : 0.6213870015604754; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.5735221699851218; train accuracy : 0.9775934818302922; \n",
      " validation loss : 0.6530500645846746; validation accuracy : 0.895397489539749\n",
      "Epoch 29:\t train loss : 0.5739623388715578; train accuracy : 0.9774113200532855; \n",
      " validation loss : 0.6363722264887746; validation accuracy : 0.9163179916317992\n",
      "Epoch 30:\t train loss : 0.5876144308083531; train accuracy : 0.9631311378915084; \n",
      " validation loss : 0.6763330426083761; validation accuracy : 0.8786610878661087\n",
      "Epoch 31:\t train loss : 0.574422855304782; train accuracy : 0.9767378171566653; \n",
      " validation loss : 0.6390809702669662; validation accuracy : 0.9079497907949791\n",
      "Epoch 32:\t train loss : 0.5703271272631161; train accuracy : 0.9807726385575761; \n",
      " validation loss : 0.6233231173894214; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5734770237282375; train accuracy : 0.9774946559682766; \n",
      " validation loss : 0.6726209672524214; validation accuracy : 0.8744769874476988\n",
      "Epoch 34:\t train loss : 0.569877720506856; train accuracy : 0.9812159608414139; \n",
      " validation loss : 0.6482459447740315; validation accuracy : 0.895397489539749\n",
      "Epoch 35:\t train loss : 0.5716557928367697; train accuracy : 0.9795916849964373; \n",
      " validation loss : 0.6212892051732534; validation accuracy : 0.9246861924686193\n",
      "Epoch 36:\t train loss : 0.5666720205184453; train accuracy : 0.984519037144893; \n",
      " validation loss : 0.6278517233169687; validation accuracy : 0.9246861924686193\n",
      "Epoch 37:\t train loss : 0.5738556608814168; train accuracy : 0.9772799653025187; \n",
      " validation loss : 0.6375674841972536; validation accuracy : 0.9079497907949791\n",
      "Epoch 38:\t train loss : 0.5889956419211302; train accuracy : 0.9616521577496205; \n",
      " validation loss : 0.6205023075642158; validation accuracy : 0.9246861924686193\n",
      "Epoch 39:\t train loss : 0.5727555504849507; train accuracy : 0.9782499457851854; \n",
      " validation loss : 0.6376099934990781; validation accuracy : 0.9121338912133892\n",
      "Epoch 40:\t train loss : 0.5696716297042954; train accuracy : 0.9812079060689612; \n",
      " validation loss : 0.6138246931925073; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.571196386996636; train accuracy : 0.9798646178630069; \n",
      " validation loss : 0.6038307597872392; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5681848660633627; train accuracy : 0.9831794665262245; \n",
      " validation loss : 0.6779386255853238; validation accuracy : 0.8702928870292888\n",
      "Epoch 43:\t train loss : 0.5689632292801399; train accuracy : 0.9821416400755909; \n",
      " validation loss : 0.6124559710877117; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5643225967820162; train accuracy : 0.9868431487964311; \n",
      " validation loss : 0.6328616811846921; validation accuracy : 0.9205020920502092\n",
      "Epoch 45:\t train loss : 0.5716660199491593; train accuracy : 0.9793630533783575; \n",
      " validation loss : 0.6117758088430708; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5716209344593847; train accuracy : 0.9795179528486012; \n",
      " validation loss : 0.6309795594480275; validation accuracy : 0.9205020920502092\n",
      "Epoch 47:\t train loss : 0.5666775831648261; train accuracy : 0.9844806220762725; \n",
      " validation loss : 0.6181972278058517; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5675519342076306; train accuracy : 0.9838263267139626; \n",
      " validation loss : 0.6284137985820876; validation accuracy : 0.9246861924686193\n",
      "Epoch 49:\t train loss : 0.5691024904792475; train accuracy : 0.9820604727531832; \n",
      " validation loss : 0.6214442279002239; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5824081358367378; train accuracy : 0.9685120356888379; \n",
      " validation loss : 0.6328787117649962; validation accuracy : 0.9163179916317992\n",
      "Epoch 51:\t train loss : 0.5676197393774083; train accuracy : 0.9835512252548096; \n",
      " validation loss : 0.6105791267762892; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5656951712354362; train accuracy : 0.9852882679141237; \n",
      " validation loss : 0.6272706780348772; validation accuracy : 0.9246861924686193\n",
      "Epoch 53:\t train loss : 0.5611273228362587; train accuracy : 0.9902119024752936; \n",
      " validation loss : 0.6155534205926492; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54:\t train loss : 0.5664282085972262; train accuracy : 0.9846606152606958; \n",
      " validation loss : 0.602107860828345; validation accuracy : 0.9456066945606695\n",
      "Epoch 55:\t train loss : 0.5677375656782244; train accuracy : 0.9835047554137365; \n",
      " validation loss : 0.6269440221695518; validation accuracy : 0.9163179916317992\n",
      "Epoch 56:\t train loss : 0.5786812758852535; train accuracy : 0.9723129588896806; \n",
      " validation loss : 0.6512220911794293; validation accuracy : 0.895397489539749\n",
      "Epoch 57:\t train loss : 0.5678655774809898; train accuracy : 0.9834235880913287; \n",
      " validation loss : 0.6579919626697622; validation accuracy : 0.895397489539749\n",
      "Epoch 58:\t train loss : 0.5637064188583585; train accuracy : 0.9874738994392639; \n",
      " validation loss : 0.6208995459382329; validation accuracy : 0.9330543933054394\n",
      "Epoch 59:\t train loss : 0.5630662219199937; train accuracy : 0.9882291892561728; \n",
      " validation loss : 0.6085055612084035; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5632634240227561; train accuracy : 0.9880609684314879; \n",
      " validation loss : 0.6040060181246372; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5606380270188027; train accuracy : 0.9906846556584776; \n",
      " validation loss : 0.6010355930957337; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5614972096503178; train accuracy : 0.9897589764243007; \n",
      " validation loss : 0.6231542412866669; validation accuracy : 0.9246861924686193\n",
      "Epoch 63:\t train loss : 0.5663641236168026; train accuracy : 0.9845986554725983; \n",
      " validation loss : 0.6063416748929593; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5619358327343; train accuracy : 0.989362123981536; \n",
      " validation loss : 0.6137876521444783; validation accuracy : 0.9330543933054394\n",
      "Epoch 65:\t train loss : 0.5658957812447393; train accuracy : 0.9852300257133121; \n",
      " validation loss : 0.6096072223341793; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.5622345282336569; train accuracy : 0.9890213451469996; \n",
      " validation loss : 0.6243317166961947; validation accuracy : 0.9288702928870293\n",
      "Epoch 67:\t train loss : 0.5607018697215531; train accuracy : 0.9906787694786083; \n",
      " validation loss : 0.6184037755579536; validation accuracy : 0.9330543933054394\n",
      "Epoch 68:\t train loss : 0.5609691661796783; train accuracy : 0.9904442516806593; \n",
      " validation loss : 0.6364723846994507; validation accuracy : 0.9121338912133892\n",
      "Epoch 69:\t train loss : 0.5769768929906636; train accuracy : 0.9739378543325382; \n",
      " validation loss : 0.6235716184419114; validation accuracy : 0.9288702928870293\n",
      "Epoch 70:\t train loss : 0.5640055509740487; train accuracy : 0.9872341150593265; \n",
      " validation loss : 0.5873682257786881; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.566464326806258; train accuracy : 0.9847984757892128; \n",
      " validation loss : 0.624424712482454; validation accuracy : 0.9246861924686193\n",
      "Epoch 72:\t train loss : 0.5610940751363329; train accuracy : 0.9901809225812448; \n",
      " validation loss : 0.6036826129330751; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5682749541495906; train accuracy : 0.9828098763902228; \n",
      " validation loss : 0.6100409628203983; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5623588752770773; train accuracy : 0.989036835094024; \n",
      " validation loss : 0.6135588385931361; validation accuracy : 0.9372384937238494\n",
      "Epoch 75:\t train loss : 0.5610267467183949; train accuracy : 0.9902487685492115; \n",
      " validation loss : 0.6247328484716219; validation accuracy : 0.9288702928870293\n",
      "Epoch 76:\t train loss : 0.561310791283115; train accuracy : 0.9900740419467765; \n",
      " validation loss : 0.6295330265867641; validation accuracy : 0.9246861924686193\n",
      "Epoch 77:\t train loss : 0.5622943568311368; train accuracy : 0.9889342916447226; \n",
      " validation loss : 0.6007032125580893; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5638018145627933; train accuracy : 0.9873617522228074; \n",
      " validation loss : 0.636827203985875; validation accuracy : 0.9121338912133892\n",
      "Epoch 79:\t train loss : 0.5619491352659515; train accuracy : 0.9893466340345116; \n",
      " validation loss : 0.6186289977289505; validation accuracy : 0.9330543933054394\n",
      "Epoch 80:\t train loss : 0.5595465813236442; train accuracy : 0.9919489451346076; \n",
      " validation loss : 0.6366527325330589; validation accuracy : 0.9121338912133892\n",
      "Epoch 81:\t train loss : 0.5591514904737727; train accuracy : 0.992239536540785; \n",
      " validation loss : 0.6205301308996163; validation accuracy : 0.9288702928870293\n",
      "Epoch 82:\t train loss : 0.5585829969943642; train accuracy : 0.9928414758821524; \n",
      " validation loss : 0.6144396291712769; validation accuracy : 0.9372384937238494\n",
      "Epoch 83:\t train loss : 0.558810624409636; train accuracy : 0.992440905852102; \n",
      " validation loss : 0.5943923113138165; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5592736119531371; train accuracy : 0.9921407106787695; \n",
      " validation loss : 0.5879772687076931; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.5634686646004561; train accuracy : 0.9877143034170823; \n",
      " validation loss : 0.6066279062504499; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.5595586802539072; train accuracy : 0.9917689519501843; \n",
      " validation loss : 0.6149686185786702; validation accuracy : 0.9330543933054394\n",
      "Epoch 87:\t train loss : 0.5586073653876613; train accuracy : 0.9927175563059574; \n",
      " validation loss : 0.6009821337331479; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.5572062351426202; train accuracy : 0.9942569472412405; \n",
      " validation loss : 0.5962359463913217; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5576025427948174; train accuracy : 0.9937671551163295; \n",
      " validation loss : 0.5815916735024776; validation accuracy : 0.9665271966527197\n",
      "Epoch 90:\t train loss : 0.5632175639144141; train accuracy : 0.9879039003686607; \n",
      " validation loss : 0.6243585007421678; validation accuracy : 0.9246861924686193\n",
      "Epoch 91:\t train loss : 0.5619169035195865; train accuracy : 0.9892419219926267; \n",
      " validation loss : 0.5997778150057675; validation accuracy : 0.9497907949790795\n",
      "Epoch 92:\t train loss : 0.5889796197902892; train accuracy : 0.9618578642461043; \n",
      " validation loss : 0.6222625024435665; validation accuracy : 0.9288702928870293\n",
      "Epoch 93:\t train loss : 0.5633533384262137; train accuracy : 0.9878286192261222; \n",
      " validation loss : 0.6055943477400415; validation accuracy : 0.9414225941422594\n",
      "Epoch 94:\t train loss : 0.557036535281156; train accuracy : 0.9942628334211097; \n",
      " validation loss : 0.6344489315467436; validation accuracy : 0.9163179916317992\n",
      "Epoch 95:\t train loss : 0.5636430588942597; train accuracy : 0.9875284240527897; \n",
      " validation loss : 0.607475002182509; validation accuracy : 0.9414225941422594\n",
      "Epoch 96:\t train loss : 0.5579665267088264; train accuracy : 0.9933179466526224; \n",
      " validation loss : 0.6305147625001564; validation accuracy : 0.9205020920502092\n",
      "Epoch 97:\t train loss : 0.56032300025926; train accuracy : 0.9909052325041048; \n",
      " validation loss : 0.6079813791589844; validation accuracy : 0.9456066945606695\n",
      "Epoch 98:\t train loss : 0.5588881069601521; train accuracy : 0.9924040397781839; \n",
      " validation loss : 0.6216273670430662; validation accuracy : 0.9288702928870293\n",
      "Epoch 99:\t train loss : 0.562704674195847; train accuracy : 0.9886591901855696; \n",
      " validation loss : 0.6194137605306603; validation accuracy : 0.9288702928870293\n",
      "Epoch 100:\t train loss : 0.5597679334156367; train accuracy : 0.991552092691843; \n",
      " validation loss : 0.604414990854475; validation accuracy : 0.9456066945606695\n",
      "Epoch 101:\t train loss : 0.5573291863421858; train accuracy : 0.993879302332786; \n",
      " validation loss : 0.6357213022049484; validation accuracy : 0.9163179916317992\n",
      "Epoch 102:\t train loss : 0.5608038969454818; train accuracy : 0.9903999504321696; \n",
      " validation loss : 0.6153400902118504; validation accuracy : 0.9372384937238494\n",
      "Epoch 103:\t train loss : 0.5572401189164286; train accuracy : 0.9941079339508658; \n",
      " validation loss : 0.6058734788155028; validation accuracy : 0.9456066945606695\n",
      "Epoch 104:\t train loss : 0.5623275623131339; train accuracy : 0.988885653211066; \n",
      " validation loss : 0.6145670334230336; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105:\t train loss : 0.5566150216128716; train accuracy : 0.9948049815669631; \n",
      " validation loss : 0.6048223056544588; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.5551063944202078; train accuracy : 0.9963229963753524; \n",
      " validation loss : 0.6026099392263022; validation accuracy : 0.9456066945606695\n",
      "Epoch 107:\t train loss : 0.5562569275826557; train accuracy : 0.9951008395551287; \n",
      " validation loss : 0.5917629743525094; validation accuracy : 0.9581589958158996\n",
      "Epoch 108:\t train loss : 0.5577429091953517; train accuracy : 0.993517147371356; \n",
      " validation loss : 0.6079034823950026; validation accuracy : 0.9456066945606695\n",
      "Epoch 109:\t train loss : 0.5582673878834958; train accuracy : 0.9929306979770129; \n",
      " validation loss : 0.5967795643969369; validation accuracy : 0.9539748953974896\n",
      "Epoch 110:\t train loss : 0.5580083574883379; train accuracy : 0.9933932277951609; \n",
      " validation loss : 0.6415879495325123; validation accuracy : 0.9079497907949791\n",
      "Epoch 111:\t train loss : 0.5608175619941198; train accuracy : 0.9906050373307723; \n",
      " validation loss : 0.6116758038161776; validation accuracy : 0.9372384937238494\n",
      "Epoch 112:\t train loss : 0.5609012209490631; train accuracy : 0.9903726881254066; \n",
      " validation loss : 0.6167637893982485; validation accuracy : 0.9330543933054394\n",
      "Epoch 113:\t train loss : 0.5601885739976132; train accuracy : 0.9909981721862511; \n",
      " validation loss : 0.6012844999931622; validation accuracy : 0.9497907949790795\n",
      "Epoch 114:\t train loss : 0.5600812941880151; train accuracy : 0.9911316955296012; \n",
      " validation loss : 0.5890926337871563; validation accuracy : 0.9623430962343096\n",
      "Epoch 115:\t train loss : 0.5565249377139205; train accuracy : 0.9948049815669631; \n",
      " validation loss : 0.590511354449936; validation accuracy : 0.9623430962343096\n",
      "Epoch 116:\t train loss : 0.5548702524253187; train accuracy : 0.9964255398246538; \n",
      " validation loss : 0.6293479926263723; validation accuracy : 0.9205020920502092\n",
      "Epoch 117:\t train loss : 0.5612291352086843; train accuracy : 0.9900570030050497; \n",
      " validation loss : 0.6386616309735054; validation accuracy : 0.9079497907949791\n",
      "Epoch 118:\t train loss : 0.5616620689981328; train accuracy : 0.9896136807212119; \n",
      " validation loss : 0.6029858980672802; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5602558427267199; train accuracy : 0.9909944545989653; \n",
      " validation loss : 0.5958769385307728; validation accuracy : 0.9581589958158996\n",
      "Epoch 120:\t train loss : 0.5583166735327159; train accuracy : 0.9929557916911924; \n",
      " validation loss : 0.6009925866049886; validation accuracy : 0.9497907949790795\n",
      "Epoch 121:\t train loss : 0.5681432392092892; train accuracy : 0.9829951361566344; \n",
      " validation loss : 0.6975960972505838; validation accuracy : 0.8493723849372385\n",
      "Epoch 122:\t train loss : 0.5694168084244804; train accuracy : 0.9817624461724341; \n",
      " validation loss : 0.5998283098768235; validation accuracy : 0.9497907949790795\n",
      "Epoch 123:\t train loss : 0.5567352710383482; train accuracy : 0.9945416524675486; \n",
      " validation loss : 0.6122014879587133; validation accuracy : 0.9372384937238494\n",
      "Epoch 124:\t train loss : 0.5574880570968316; train accuracy : 0.9939279407664425; \n",
      " validation loss : 0.606254700567761; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5576410185287776; train accuracy : 0.9936469531274202; \n",
      " validation loss : 0.5905651003726795; validation accuracy : 0.9623430962343096\n",
      "Epoch 126:\t train loss : 0.5557927198113887; train accuracy : 0.9955639889711577; \n",
      " validation loss : 0.6043865460836679; validation accuracy : 0.9456066945606695\n",
      "Epoch 127:\t train loss : 0.5550380146034483; train accuracy : 0.9963849561634499; \n",
      " validation loss : 0.6227862154286584; validation accuracy : 0.9246861924686193\n",
      "Epoch 128:\t train loss : 0.5558030509480436; train accuracy : 0.995505746770346; \n",
      " validation loss : 0.6092878480857095; validation accuracy : 0.9414225941422594\n",
      "Epoch 129:\t train loss : 0.5555168746734962; train accuracy : 0.9958620155519068; \n",
      " validation loss : 0.6061574916369239; validation accuracy : 0.9456066945606695\n",
      "Epoch 130:\t train loss : 0.5564585219021132; train accuracy : 0.9948396790482976; \n",
      " validation loss : 0.6356738515550298; validation accuracy : 0.9163179916317992\n",
      "Epoch 131:\t train loss : 0.5573501532328238; train accuracy : 0.9939722420149323; \n",
      " validation loss : 0.6059579700073451; validation accuracy : 0.9414225941422594\n",
      "Epoch 132:\t train loss : 0.5592320809528634; train accuracy : 0.9920728647108027; \n",
      " validation loss : 0.6143104117981611; validation accuracy : 0.9372384937238494\n",
      "Epoch 133:\t train loss : 0.5563636552435821; train accuracy : 0.994969484804362; \n",
      " validation loss : 0.6143435922120764; validation accuracy : 0.9372384937238494\n",
      "Epoch 134:\t train loss : 0.5565219131383603; train accuracy : 0.9948514514080362; \n",
      " validation loss : 0.6151959606569447; validation accuracy : 0.9330543933054394\n",
      "Epoch 135:\t train loss : 0.5630935477540765; train accuracy : 0.9880358747173085; \n",
      " validation loss : 0.6058682901735666; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.5578472719047317; train accuracy : 0.9934514699959726; \n",
      " validation loss : 0.6182337478866384; validation accuracy : 0.9330543933054394\n",
      "Epoch 137:\t train loss : 0.5554001584417593; train accuracy : 0.9960441773289135; \n",
      " validation loss : 0.6073652966359415; validation accuracy : 0.9456066945606695\n",
      "Epoch 138:\t train loss : 0.5550134092707478; train accuracy : 0.9963539762694011; \n",
      " validation loss : 0.6125680446370665; validation accuracy : 0.9372384937238494\n",
      "Epoch 139:\t train loss : 0.5543095713027861; train accuracy : 0.9970510238854983; \n",
      " validation loss : 0.6097825715159385; validation accuracy : 0.9414225941422594\n",
      "Early stopping at epoch 139\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5576025427948174; Train accuracy : 0.9937671551163295; \n",
      " Validation loss : 0.5815916735024776; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 65 ! ---\n",
      "Epoch 1:\t train loss : 0.9376050082306634; train accuracy : 0.5916131230831191; \n",
      " validation loss : 0.8168824820973257; validation accuracy : 0.7238493723849372\n",
      "Epoch 2:\t train loss : 0.740388705120049; train accuracy : 0.8104962979026612; \n",
      " validation loss : 0.6963765704515795; validation accuracy : 0.8577405857740585\n",
      "Epoch 3:\t train loss : 0.6870786260516331; train accuracy : 0.8636215496143003; \n",
      " validation loss : 0.6816358348531745; validation accuracy : 0.8661087866108786\n",
      "Epoch 4:\t train loss : 0.6629536083460386; train accuracy : 0.8876523436289848; \n",
      " validation loss : 0.6413759027633545; validation accuracy : 0.9121338912133892\n",
      "Epoch 5:\t train loss : 0.6410247959887105; train accuracy : 0.9093890764893584; \n",
      " validation loss : 0.6498734603457453; validation accuracy : 0.895397489539749\n",
      "Epoch 6:\t train loss : 0.6294648672898671; train accuracy : 0.921490442702686; \n",
      " validation loss : 0.6333010742074299; validation accuracy : 0.9163179916317992\n",
      "Epoch 7:\t train loss : 0.6151122108160995; train accuracy : 0.9359735431704823; \n",
      " validation loss : 0.6304812080083603; validation accuracy : 0.9163179916317992\n",
      "Epoch 8:\t train loss : 0.6118364221647967; train accuracy : 0.9390117413798444; \n",
      " validation loss : 0.6433304638653525; validation accuracy : 0.9037656903765691\n",
      "Epoch 9:\t train loss : 0.6032082934719857; train accuracy : 0.9479649307599368; \n",
      " validation loss : 0.6187821365026298; validation accuracy : 0.9330543933054394\n",
      "Epoch 10:\t train loss : 0.5918357419127839; train accuracy : 0.9597586666253601; \n",
      " validation loss : 0.6488501349412422; validation accuracy : 0.9079497907949791\n",
      "Epoch 11:\t train loss : 0.6033913385956234; train accuracy : 0.9478121998822764; \n",
      " validation loss : 0.6506535054908806; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.5958430920791943; train accuracy : 0.9553712940301744; \n",
      " validation loss : 0.6258360678463364; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.5888666592134659; train accuracy : 0.9624074475665293; \n",
      " validation loss : 0.6229467466665753; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5908192139891529; train accuracy : 0.9605353325691626; \n",
      " validation loss : 0.6287603419843856; validation accuracy : 0.9121338912133892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\t train loss : 0.5871153082582498; train accuracy : 0.9640087982899098; \n",
      " validation loss : 0.6157478139847345; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.6005626702945159; train accuracy : 0.9502766504538555; \n",
      " validation loss : 0.6553461395012188; validation accuracy : 0.891213389121339\n",
      "Epoch 17:\t train loss : 0.5883838228753626; train accuracy : 0.9626109854704297; \n",
      " validation loss : 0.6215601020622694; validation accuracy : 0.9246861924686193\n",
      "Epoch 18:\t train loss : 0.5817642613583638; train accuracy : 0.9696087239381641; \n",
      " validation loss : 0.6218014738815463; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.5868087442232401; train accuracy : 0.9643842746057808; \n",
      " validation loss : 0.6168273507879698; validation accuracy : 0.9372384937238494\n",
      "Epoch 20:\t train loss : 0.58316305198935; train accuracy : 0.9682957960283776; \n",
      " validation loss : 0.6345100028255874; validation accuracy : 0.9163179916317992\n",
      "Epoch 21:\t train loss : 0.5877074437284386; train accuracy : 0.963290374546919; \n",
      " validation loss : 0.6406399534628654; validation accuracy : 0.9037656903765691\n",
      "Epoch 22:\t train loss : 0.5806375450881447; train accuracy : 0.970588308187986; \n",
      " validation loss : 0.6184205566996709; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5789677529055005; train accuracy : 0.9722066978530933; \n",
      " validation loss : 0.659535208989194; validation accuracy : 0.891213389121339\n",
      "Epoch 24:\t train loss : 0.5783585911266098; train accuracy : 0.9728439542736764; \n",
      " validation loss : 0.6165909521570868; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5757310386104827; train accuracy : 0.975669010811983; \n",
      " validation loss : 0.6299855535815501; validation accuracy : 0.9246861924686193\n",
      "Epoch 26:\t train loss : 0.5828110300243969; train accuracy : 0.9681526689178723; \n",
      " validation loss : 0.6224225515017622; validation accuracy : 0.9288702928870293\n",
      "Epoch 27:\t train loss : 0.5809526819997035; train accuracy : 0.9702202670466867; \n",
      " validation loss : 0.6164579604724799; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5777714062145317; train accuracy : 0.973351404938195; \n",
      " validation loss : 0.6174611045293716; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.580835255243629; train accuracy : 0.9702261532265559; \n",
      " validation loss : 0.5975948750229131; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.577484423393545; train accuracy : 0.9734635521546516; \n",
      " validation loss : 0.6348199881863283; validation accuracy : 0.9163179916317992\n",
      "Epoch 31:\t train loss : 0.5757563274565096; train accuracy : 0.9752625546020632; \n",
      " validation loss : 0.6184256859079508; validation accuracy : 0.9288702928870293\n",
      "Epoch 32:\t train loss : 0.5705923524944322; train accuracy : 0.9804303107283373; \n",
      " validation loss : 0.58930028111495; validation accuracy : 0.9623430962343096\n",
      "Epoch 33:\t train loss : 0.5694098996444775; train accuracy : 0.9820663589330525; \n",
      " validation loss : 0.6246424213355579; validation accuracy : 0.9246861924686193\n",
      "Epoch 34:\t train loss : 0.5709681706118567; train accuracy : 0.9802038477028409; \n",
      " validation loss : 0.6197041872218574; validation accuracy : 0.9288702928870293\n",
      "Epoch 35:\t train loss : 0.5729142605540829; train accuracy : 0.9783775829486663; \n",
      " validation loss : 0.6318094651033367; validation accuracy : 0.9163179916317992\n",
      "Epoch 36:\t train loss : 0.5741349983703591; train accuracy : 0.9769178103410886; \n",
      " validation loss : 0.6035550332286258; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.56736408323045; train accuracy : 0.9837820254654729; \n",
      " validation loss : 0.5986497987161616; validation accuracy : 0.9456066945606695\n",
      "Epoch 38:\t train loss : 0.565698172691826; train accuracy : 0.985656309055423; \n",
      " validation loss : 0.5968979954077293; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5656279223356911; train accuracy : 0.9857492487375693; \n",
      " validation loss : 0.5900310524072279; validation accuracy : 0.9623430962343096\n",
      "Epoch 40:\t train loss : 0.5673909555275322; train accuracy : 0.983791629232628; \n",
      " validation loss : 0.5966616672339251; validation accuracy : 0.9539748953974896\n",
      "Epoch 41:\t train loss : 0.5724700861934134; train accuracy : 0.9786062145667462; \n",
      " validation loss : 0.6200675059490166; validation accuracy : 0.9288702928870293\n",
      "Epoch 42:\t train loss : 0.5744091637963658; train accuracy : 0.9765556553796586; \n",
      " validation loss : 0.5941384687972379; validation accuracy : 0.9623430962343096\n",
      "Epoch 43:\t train loss : 0.5668092244802174; train accuracy : 0.9846376901390997; \n",
      " validation loss : 0.6095111072973791; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5739115441699609; train accuracy : 0.9770881997583568; \n",
      " validation loss : 0.595754603093327; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5660939027736281; train accuracy : 0.985170234517798; \n",
      " validation loss : 0.6125916091038186; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5652093393271824; train accuracy : 0.9860509929056043; \n",
      " validation loss : 0.6036087304271841; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5665637781778565; train accuracy : 0.9846184826047895; \n",
      " validation loss : 0.6250699998735728; validation accuracy : 0.9246861924686193\n",
      "Epoch 48:\t train loss : 0.5699635875630579; train accuracy : 0.9811465658787447; \n",
      " validation loss : 0.6003176508988196; validation accuracy : 0.9497907949790795\n",
      "Epoch 49:\t train loss : 0.5712936134045175; train accuracy : 0.9798358065615416; \n",
      " validation loss : 0.6140851236934415; validation accuracy : 0.9372384937238494\n",
      "Epoch 50:\t train loss : 0.5678081091917605; train accuracy : 0.9833269308218966; \n",
      " validation loss : 0.5913286162121654; validation accuracy : 0.9581589958158996\n",
      "Epoch 51:\t train loss : 0.5618713420542958; train accuracy : 0.9893931038755848; \n",
      " validation loss : 0.6092184351941227; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5643269423286856; train accuracy : 0.9868955048173735; \n",
      " validation loss : 0.6017836695157075; validation accuracy : 0.9497907949790795\n",
      "Epoch 53:\t train loss : 0.5714259350548953; train accuracy : 0.9797118869853465; \n",
      " validation loss : 0.6104876851473979; validation accuracy : 0.9414225941422594\n",
      "Epoch 54:\t train loss : 0.565400998207737; train accuracy : 0.9858266984726912; \n",
      " validation loss : 0.6207508563687352; validation accuracy : 0.9205020920502092\n",
      "Epoch 55:\t train loss : 0.5624738108592587; train accuracy : 0.9888007683013724; \n",
      " validation loss : 0.5863591543246618; validation accuracy : 0.9623430962343096\n",
      "Epoch 56:\t train loss : 0.5639467125909733; train accuracy : 0.9872303974720407; \n",
      " validation loss : 0.6171331622903136; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.5653786890784491; train accuracy : 0.9858031537532141; \n",
      " validation loss : 0.6214710678229881; validation accuracy : 0.9205020920502092\n",
      "Epoch 58:\t train loss : 0.56495236959706; train accuracy : 0.986260416989374; \n",
      " validation loss : 0.6101434759051282; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5619246354777148; train accuracy : 0.9893680101614053; \n",
      " validation loss : 0.5945986741731647; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5613842483452514; train accuracy : 0.9899934942222498; \n",
      " validation loss : 0.6049195274148039; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5626553895630924; train accuracy : 0.9885684190960067; \n",
      " validation loss : 0.5908273095516764; validation accuracy : 0.9581589958158996\n",
      "Epoch 62:\t train loss : 0.5693824515814992; train accuracy : 0.9819092908702253; \n",
      " validation loss : 0.6087485488890204; validation accuracy : 0.9414225941422594\n",
      "Epoch 63:\t train loss : 0.5642263972999583; train accuracy : 0.9870504042876174; \n",
      " validation loss : 0.6080971328845952; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5642944895693643; train accuracy : 0.9870968741286905; \n",
      " validation loss : 0.5966614999589099; validation accuracy : 0.9539748953974896\n",
      "Epoch 65:\t train loss : 0.5659052875284583; train accuracy : 0.9853406239350662; \n",
      " validation loss : 0.6357137427292474; validation accuracy : 0.9163179916317992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66:\t train loss : 0.5631693615092427; train accuracy : 0.9881037206852753; \n",
      " validation loss : 0.6036333863697831; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.5694677560830851; train accuracy : 0.9816053781096069; \n",
      " validation loss : 0.6438052823664944; validation accuracy : 0.9037656903765691\n",
      "Epoch 68:\t train loss : 0.5780865120809046; train accuracy : 0.9728771027603086; \n",
      " validation loss : 0.5946942337249864; validation accuracy : 0.9581589958158996\n",
      "Epoch 69:\t train loss : 0.5659497614767274; train accuracy : 0.9853539452895071; \n",
      " validation loss : 0.5967247779816861; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5753529250403533; train accuracy : 0.9756999907060318; \n",
      " validation loss : 0.601409022942898; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5671443874350499; train accuracy : 0.9838669103751665; \n",
      " validation loss : 0.6002833328087882; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5623519777076459; train accuracy : 0.9891334923634562; \n",
      " validation loss : 0.6099508997539417; validation accuracy : 0.9372384937238494\n",
      "Epoch 73:\t train loss : 0.5594541879678773; train accuracy : 0.9918928715263794; \n",
      " validation loss : 0.5888405987339705; validation accuracy : 0.9623430962343096\n",
      "Epoch 74:\t train loss : 0.5594504194963763; train accuracy : 0.9919297376002973; \n",
      " validation loss : 0.593390754414752; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.5626554680405341; train accuracy : 0.9886591901855696; \n",
      " validation loss : 0.6206653845395982; validation accuracy : 0.9288702928870293\n",
      "Epoch 76:\t train loss : 0.5608794538813656; train accuracy : 0.9905142662412094; \n",
      " validation loss : 0.6142666120367467; validation accuracy : 0.9372384937238494\n",
      "Epoch 77:\t train loss : 0.5644018526633506; train accuracy : 0.9869088261718145; \n",
      " validation loss : 0.6069375921374222; validation accuracy : 0.9456066945606695\n",
      "Epoch 78:\t train loss : 0.5617398335603968; train accuracy : 0.9896136807212119; \n",
      " validation loss : 0.6076137787611418; validation accuracy : 0.9414225941422594\n",
      "Epoch 79:\t train loss : 0.5622036464818094; train accuracy : 0.9891201710090152; \n",
      " validation loss : 0.6134266120777894; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.5632867916670683; train accuracy : 0.9880433098918802; \n",
      " validation loss : 0.6542791114937461; validation accuracy : 0.895397489539749\n",
      "Epoch 81:\t train loss : 0.5651109412498293; train accuracy : 0.986059047678057; \n",
      " validation loss : 0.6001924673953585; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.562787648348298; train accuracy : 0.9885780228631618; \n",
      " validation loss : 0.5822013612960554; validation accuracy : 0.9707112970711297\n",
      "Epoch 83:\t train loss : 0.5649067801460627; train accuracy : 0.9863533566715201; \n",
      " validation loss : 0.5893062050558104; validation accuracy : 0.9623430962343096\n",
      "Epoch 84:\t train loss : 0.5763845828895612; train accuracy : 0.97460609064717; \n",
      " validation loss : 0.6102400684774569; validation accuracy : 0.9414225941422594\n",
      "Epoch 85:\t train loss : 0.5639847514349952; train accuracy : 0.9872149075250163; \n",
      " validation loss : 0.6158966521149861; validation accuracy : 0.9372384937238494\n",
      "Epoch 86:\t train loss : 0.5591993006342797; train accuracy : 0.9921156169645899; \n",
      " validation loss : 0.5930385967622458; validation accuracy : 0.9581589958158996\n",
      "Epoch 87:\t train loss : 0.5597075181646269; train accuracy : 0.9917069921620868; \n",
      " validation loss : 0.5842289441637791; validation accuracy : 0.9665271966527197\n",
      "Epoch 88:\t train loss : 0.5603269428758361; train accuracy : 0.9910350382601691; \n",
      " validation loss : 0.6156767113278295; validation accuracy : 0.9330543933054394\n",
      "Epoch 89:\t train loss : 0.561588938388708; train accuracy : 0.989851916106447; \n",
      " validation loss : 0.5962730390421694; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5618930237016176; train accuracy : 0.9893525202143809; \n",
      " validation loss : 0.5834024887503043; validation accuracy : 0.9665271966527197\n",
      "Epoch 91:\t train loss : 0.561753600284446; train accuracy : 0.9896062455466402; \n",
      " validation loss : 0.6074789271675233; validation accuracy : 0.9414225941422594\n",
      "Epoch 92:\t train loss : 0.560076941551086; train accuracy : 0.9913566095603953; \n",
      " validation loss : 0.6016571527484024; validation accuracy : 0.9497907949790795\n",
      "Epoch 93:\t train loss : 0.5608078913709561; train accuracy : 0.9905201524210787; \n",
      " validation loss : 0.600401712399712; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5640858537191676; train accuracy : 0.9871507791443354; \n",
      " validation loss : 0.6076802162379066; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.5678651026674062; train accuracy : 0.9832900647479785; \n",
      " validation loss : 0.6142437119128065; validation accuracy : 0.9372384937238494\n",
      "Epoch 96:\t train loss : 0.5629588702105024; train accuracy : 0.9881811704203972; \n",
      " validation loss : 0.6137310996758079; validation accuracy : 0.9372384937238494\n",
      "Epoch 97:\t train loss : 0.5596472424072458; train accuracy : 0.9917320858762663; \n",
      " validation loss : 0.6052418914898094; validation accuracy : 0.9456066945606695\n",
      "Epoch 98:\t train loss : 0.5609294952896912; train accuracy : 0.9903342730567861; \n",
      " validation loss : 0.6035438617797639; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5621408095207137; train accuracy : 0.9891762446172434; \n",
      " validation loss : 0.5956953681048877; validation accuracy : 0.9581589958158996\n",
      "Epoch 100:\t train loss : 0.5602224913563264; train accuracy : 0.9910099445459897; \n",
      " validation loss : 0.6136234434285036; validation accuracy : 0.9372384937238494\n",
      "Epoch 101:\t train loss : 0.5609959799519262; train accuracy : 0.9902819170358438; \n",
      " validation loss : 0.580769783475078; validation accuracy : 0.9707112970711297\n",
      "Epoch 102:\t train loss : 0.5594193190892023; train accuracy : 0.991840515505437; \n",
      " validation loss : 0.5985827515900787; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.5619242057578007; train accuracy : 0.9894513460763964; \n",
      " validation loss : 0.5897354781092392; validation accuracy : 0.9623430962343096\n",
      "Epoch 104:\t train loss : 0.5667638239723612; train accuracy : 0.9844171132934726; \n",
      " validation loss : 0.5991766590878427; validation accuracy : 0.9497907949790795\n",
      "Epoch 105:\t train loss : 0.5669096451762551; train accuracy : 0.9842253477493107; \n",
      " validation loss : 0.6021208739457119; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.5655930614988566; train accuracy : 0.9854121874903188; \n",
      " validation loss : 0.5862509560459795; validation accuracy : 0.9623430962343096\n",
      "Epoch 107:\t train loss : 0.5593708336920594; train accuracy : 0.9918309117382819; \n",
      " validation loss : 0.6148927573253491; validation accuracy : 0.9372384937238494\n",
      "Epoch 108:\t train loss : 0.5619758607384507; train accuracy : 0.9893893862882989; \n",
      " validation loss : 0.5879082582305132; validation accuracy : 0.9623430962343096\n",
      "Epoch 109:\t train loss : 0.5599950274525343; train accuracy : 0.9912983673595837; \n",
      " validation loss : 0.5814610882654974; validation accuracy : 0.9707112970711297\n",
      "Epoch 110:\t train loss : 0.5568635632054646; train accuracy : 0.9944951826264754; \n",
      " validation loss : 0.6058487452661367; validation accuracy : 0.9456066945606695\n",
      "Epoch 111:\t train loss : 0.5797416547659233; train accuracy : 0.9713104495182626; \n",
      " validation loss : 0.6304955119420846; validation accuracy : 0.9205020920502092\n",
      "Epoch 112:\t train loss : 0.5746082407214915; train accuracy : 0.9765113541311689; \n",
      " validation loss : 0.6080648959486293; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5597073888480899; train accuracy : 0.9915115090306391; \n",
      " validation loss : 0.5976773258787584; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5599221939541178; train accuracy : 0.9913662133275504; \n",
      " validation loss : 0.6132296522349345; validation accuracy : 0.9372384937238494\n",
      "Epoch 115:\t train loss : 0.5568972412256984; train accuracy : 0.9944391090182472; \n",
      " validation loss : 0.5851082207118552; validation accuracy : 0.9665271966527197\n",
      "Epoch 116:\t train loss : 0.5568377650477865; train accuracy : 0.9945822361287524; \n",
      " validation loss : 0.589090550735038; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117:\t train loss : 0.555593031662274; train accuracy : 0.9958332042504414; \n",
      " validation loss : 0.5930262786043541; validation accuracy : 0.9581589958158996\n",
      "Epoch 118:\t train loss : 0.5549842997622048; train accuracy : 0.9963598624492704; \n",
      " validation loss : 0.5849821872257844; validation accuracy : 0.9665271966527197\n",
      "Epoch 119:\t train loss : 0.5547238185119961; train accuracy : 0.996710245050962; \n",
      " validation loss : 0.580932880325612; validation accuracy : 0.9707112970711297\n",
      "Epoch 120:\t train loss : 0.5598910755804084; train accuracy : 0.9915115090306391; \n",
      " validation loss : 0.6100970914580162; validation accuracy : 0.9414225941422594\n",
      "Epoch 121:\t train loss : 0.5590979579498341; train accuracy : 0.9922240465937606; \n",
      " validation loss : 0.5925108282654624; validation accuracy : 0.9581589958158996\n",
      "Epoch 122:\t train loss : 0.556335076362364; train accuracy : 0.9951051767402955; \n",
      " validation loss : 0.6177423870638653; validation accuracy : 0.9330543933054394\n",
      "Epoch 123:\t train loss : 0.5552857228177228; train accuracy : 0.9960500635087828; \n",
      " validation loss : 0.6028236715711188; validation accuracy : 0.9497907949790795\n",
      "Epoch 124:\t train loss : 0.5539721309106798; train accuracy : 0.9974323863812385; \n",
      " validation loss : 0.5932889261195515; validation accuracy : 0.9581589958158996\n",
      "Epoch 125:\t train loss : 0.5568670031387806; train accuracy : 0.9945726323615973; \n",
      " validation loss : 0.60613674416246; validation accuracy : 0.9456066945606695\n",
      "Epoch 126:\t train loss : 0.5635410447975907; train accuracy : 0.987695095882772; \n",
      " validation loss : 0.5930296282188463; validation accuracy : 0.9581589958158996\n",
      "Epoch 127:\t train loss : 0.5626433133335499; train accuracy : 0.9885625329161374; \n",
      " validation loss : 0.5764910461180842; validation accuracy : 0.9748953974895398\n",
      "Epoch 128:\t train loss : 0.5598953228143402; train accuracy : 0.9914495492425416; \n",
      " validation loss : 0.5962984967464449; validation accuracy : 0.9539748953974896\n",
      "Epoch 129:\t train loss : 0.5578653474861405; train accuracy : 0.9934108863347687; \n",
      " validation loss : 0.6018830240786812; validation accuracy : 0.9497907949790795\n",
      "Epoch 130:\t train loss : 0.556891880641962; train accuracy : 0.9945261625205242; \n",
      " validation loss : 0.5901481319343068; validation accuracy : 0.9623430962343096\n",
      "Epoch 131:\t train loss : 0.5621182404398483; train accuracy : 0.989160754670219; \n",
      " validation loss : 0.61031962989088; validation accuracy : 0.9414225941422594\n",
      "Epoch 132:\t train loss : 0.5578637241474645; train accuracy : 0.9934787323027355; \n",
      " validation loss : 0.6161750065013678; validation accuracy : 0.9330543933054394\n",
      "Epoch 133:\t train loss : 0.5552947439844855; train accuracy : 0.9960810434028315; \n",
      " validation loss : 0.6056166851724333; validation accuracy : 0.9456066945606695\n",
      "Epoch 134:\t train loss : 0.5566338648125473; train accuracy : 0.9947430217788655; \n",
      " validation loss : 0.5886006276084604; validation accuracy : 0.9623430962343096\n",
      "Epoch 135:\t train loss : 0.5628160950304147; train accuracy : 0.9883205799436166; \n",
      " validation loss : 0.5858347955706823; validation accuracy : 0.9665271966527197\n",
      "Epoch 136:\t train loss : 0.556701661710496; train accuracy : 0.9946094984355154; \n",
      " validation loss : 0.5808925740066018; validation accuracy : 0.9707112970711297\n",
      "Epoch 137:\t train loss : 0.5540421469930097; train accuracy : 0.9973357291118065; \n",
      " validation loss : 0.580827227381628; validation accuracy : 0.9707112970711297\n",
      "Epoch 138:\t train loss : 0.5547506887428391; train accuracy : 0.9966365129031258; \n",
      " validation loss : 0.5946244549446205; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5592099833721141; train accuracy : 0.9922705164348338; \n",
      " validation loss : 0.5897261153462475; validation accuracy : 0.9623430962343096\n",
      "Epoch 140:\t train loss : 0.5608001037904492; train accuracy : 0.9904427026859568; \n",
      " validation loss : 0.5935453545285871; validation accuracy : 0.9581589958158996\n",
      "Epoch 141:\t train loss : 0.5556753438179306; train accuracy : 0.9956724186003284; \n",
      " validation loss : 0.5888041386586679; validation accuracy : 0.9623430962343096\n",
      "Epoch 142:\t train loss : 0.5609075091675141; train accuracy : 0.9904832863471607; \n",
      " validation loss : 0.6042905862194873; validation accuracy : 0.9456066945606695\n",
      "Epoch 143:\t train loss : 0.5571317292869694; train accuracy : 0.994191269865857; \n",
      " validation loss : 0.6016124980073693; validation accuracy : 0.9497907949790795\n",
      "Epoch 144:\t train loss : 0.5600400291198622; train accuracy : 0.9913448372006568; \n",
      " validation loss : 0.5911075833738025; validation accuracy : 0.9581589958158996\n",
      "Epoch 145:\t train loss : 0.5589848940712204; train accuracy : 0.9923634561169801; \n",
      " validation loss : 0.5918455024916186; validation accuracy : 0.9623430962343096\n",
      "Epoch 146:\t train loss : 0.556404245316047; train accuracy : 0.9949171287834195; \n",
      " validation loss : 0.6448809013830779; validation accuracy : 0.9079497907949791\n",
      "Epoch 147:\t train loss : 0.5588255788135019; train accuracy : 0.9924195297252083; \n",
      " validation loss : 0.5957584748717834; validation accuracy : 0.9539748953974896\n",
      "Epoch 148:\t train loss : 0.5576358024590689; train accuracy : 0.9937110815081013; \n",
      " validation loss : 0.5951428450208545; validation accuracy : 0.9539748953974896\n",
      "Epoch 149:\t train loss : 0.5606517206110369; train accuracy : 0.990576226029307; \n",
      " validation loss : 0.6209353901950373; validation accuracy : 0.9288702928870293\n",
      "Epoch 150:\t train loss : 0.5734396542580527; train accuracy : 0.9775993680101615; \n",
      " validation loss : 0.6069276010227013; validation accuracy : 0.9456066945606695\n",
      "Epoch 151:\t train loss : 0.5605624360586077; train accuracy : 0.9907215217323957; \n",
      " validation loss : 0.6059931846037709; validation accuracy : 0.9414225941422594\n",
      "Epoch 152:\t train loss : 0.5581351246518288; train accuracy : 0.9932463830973698; \n",
      " validation loss : 0.5855299347085954; validation accuracy : 0.9665271966527197\n",
      "Epoch 153:\t train loss : 0.5591072680172341; train accuracy : 0.9922063880541528; \n",
      " validation loss : 0.6044571471022323; validation accuracy : 0.9456066945606695\n",
      "Epoch 154:\t train loss : 0.5561002037434677; train accuracy : 0.9953471297128164; \n",
      " validation loss : 0.5970232596535826; validation accuracy : 0.9539748953974896\n",
      "Epoch 155:\t train loss : 0.5559065202468346; train accuracy : 0.9954614455218563; \n",
      " validation loss : 0.596639269569825; validation accuracy : 0.9539748953974896\n",
      "Epoch 156:\t train loss : 0.5575264056368531; train accuracy : 0.9939257721738591; \n",
      " validation loss : 0.5911317967412365; validation accuracy : 0.9581589958158996\n",
      "Epoch 157:\t train loss : 0.5569922030360717; train accuracy : 0.994355773103256; \n",
      " validation loss : 0.5891481491554975; validation accuracy : 0.9623430962343096\n",
      "Epoch 158:\t train loss : 0.558012896825829; train accuracy : 0.9932250069704761; \n",
      " validation loss : 0.5975989017982617; validation accuracy : 0.9539748953974896\n",
      "Epoch 159:\t train loss : 0.5582697762254858; train accuracy : 0.9930450137860528; \n",
      " validation loss : 0.5936691368293943; validation accuracy : 0.9581589958158996\n",
      "Epoch 160:\t train loss : 0.5621509654401243; train accuracy : 0.9891821307971127; \n",
      " validation loss : 0.5974154028505686; validation accuracy : 0.9539748953974896\n",
      "Epoch 161:\t train loss : 0.5577927538409633; train accuracy : 0.9935252021438087; \n",
      " validation loss : 0.5981185956017441; validation accuracy : 0.9539748953974896\n",
      "Epoch 162:\t train loss : 0.5561898350777804; train accuracy : 0.9951981164224418; \n",
      " validation loss : 0.5895909469576686; validation accuracy : 0.9623430962343096\n",
      "Epoch 163:\t train loss : 0.55616802974956; train accuracy : 0.9951671365283931; \n",
      " validation loss : 0.5976748457265295; validation accuracy : 0.9539748953974896\n",
      "Epoch 164:\t train loss : 0.556800488289864; train accuracy : 0.994479692679451; \n",
      " validation loss : 0.6106333203322788; validation accuracy : 0.9372384937238494\n",
      "Epoch 165:\t train loss : 0.5674406935175645; train accuracy : 0.9837643669258651; \n",
      " validation loss : 0.6036486593896635; validation accuracy : 0.9456066945606695\n",
      "Epoch 166:\t train loss : 0.5663340188391291; train accuracy : 0.9847829858421884; \n",
      " validation loss : 0.5982955532067809; validation accuracy : 0.9539748953974896\n",
      "Epoch 167:\t train loss : 0.561525823419856; train accuracy : 0.9897862387310635; \n",
      " validation loss : 0.6038965189561852; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168:\t train loss : 0.5553496700504857; train accuracy : 0.9960035936677096; \n",
      " validation loss : 0.5938540468647134; validation accuracy : 0.9581589958158996\n",
      "Epoch 169:\t train loss : 0.5555708341030924; train accuracy : 0.995817714303417; \n",
      " validation loss : 0.589205183527106; validation accuracy : 0.9623430962343096\n",
      "Epoch 170:\t train loss : 0.5558568545714427; train accuracy : 0.9955543852040026; \n",
      " validation loss : 0.5995846366827084; validation accuracy : 0.9497907949790795\n",
      "Epoch 171:\t train loss : 0.5547584264785813; train accuracy : 0.9966077016016605; \n",
      " validation loss : 0.5848494929741899; validation accuracy : 0.9665271966527197\n",
      "Epoch 172:\t train loss : 0.5536115125255003; train accuracy : 0.9977539576814647; \n",
      " validation loss : 0.5883119946691222; validation accuracy : 0.9623430962343096\n",
      "Epoch 173:\t train loss : 0.5552741390565868; train accuracy : 0.9961739830849778; \n",
      " validation loss : 0.600224879156216; validation accuracy : 0.9497907949790795\n",
      "Epoch 174:\t train loss : 0.5563624729935653; train accuracy : 0.9949812571641005; \n",
      " validation loss : 0.5974147236293271; validation accuracy : 0.9539748953974896\n",
      "Epoch 175:\t train loss : 0.5545601697730151; train accuracy : 0.9968282784472877; \n",
      " validation loss : 0.597969702011699; validation accuracy : 0.9539748953974896\n",
      "Epoch 176:\t train loss : 0.5556163591098748; train accuracy : 0.9957498683354503; \n",
      " validation loss : 0.5966259534117535; validation accuracy : 0.9539748953974896\n",
      "Epoch 177:\t train loss : 0.5599687741066105; train accuracy : 0.9912983673595837; \n",
      " validation loss : 0.6035719703162422; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 177\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5626433133335499; Train accuracy : 0.9885625329161374; \n",
      " Validation loss : 0.5764910461180842; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 66 ! ---\n",
      "Epoch 1:\t train loss : 0.9198976880411569; train accuracy : 0.6149468694817064; \n",
      " validation loss : 0.8074580514499945; validation accuracy : 0.7405857740585774\n",
      "Epoch 2:\t train loss : 0.7446644425847659; train accuracy : 0.8059930605037331; \n",
      " validation loss : 0.7483276754750298; validation accuracy : 0.7907949790794979\n",
      "Epoch 3:\t train loss : 0.7010342937186066; train accuracy : 0.8486176771275442; \n",
      " validation loss : 0.7321546554248781; validation accuracy : 0.8242677824267782\n",
      "Epoch 4:\t train loss : 0.6731470679072428; train accuracy : 0.8772489854084699; \n",
      " validation loss : 0.7167739353742271; validation accuracy : 0.8326359832635983\n",
      "Epoch 5:\t train loss : 0.6623608298108438; train accuracy : 0.8878803556491837; \n",
      " validation loss : 0.6970538034990928; validation accuracy : 0.8535564853556485\n",
      "Epoch 6:\t train loss : 0.6465921038541932; train accuracy : 0.9039595402583723; \n",
      " validation loss : 0.6796879514973211; validation accuracy : 0.8744769874476988\n",
      "Epoch 7:\t train loss : 0.6328426098076902; train accuracy : 0.9182781374887697; \n",
      " validation loss : 0.6603596614604225; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6204818048516955; train accuracy : 0.9305483441246631; \n",
      " validation loss : 0.6546850307422631; validation accuracy : 0.899581589958159\n",
      "Epoch 9:\t train loss : 0.6179724692632481; train accuracy : 0.932677902041575; \n",
      " validation loss : 0.6250798086145718; validation accuracy : 0.9330543933054394\n",
      "Epoch 10:\t train loss : 0.6029583194857796; train accuracy : 0.9485033613185043; \n",
      " validation loss : 0.6488595115596375; validation accuracy : 0.899581589958159\n",
      "Epoch 11:\t train loss : 0.6030794952553316; train accuracy : 0.9479029709718393; \n",
      " validation loss : 0.6505912823178297; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.5966888121285597; train accuracy : 0.9546314941602899; \n",
      " validation loss : 0.6469354715523061; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.5936902743559986; train accuracy : 0.9575628117351839; \n",
      " validation loss : 0.6605257896370921; validation accuracy : 0.8870292887029289\n",
      "Epoch 14:\t train loss : 0.5939937281822361; train accuracy : 0.9571873354193129; \n",
      " validation loss : 0.6324990285570737; validation accuracy : 0.9205020920502092\n",
      "Epoch 15:\t train loss : 0.5919890171487782; train accuracy : 0.9591759348183029; \n",
      " validation loss : 0.6353165920085999; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.5945582451316803; train accuracy : 0.9568134080981443; \n",
      " validation loss : 0.690937846884372; validation accuracy : 0.8619246861924686\n",
      "Epoch 17:\t train loss : 0.5856663452090777; train accuracy : 0.9657126924625917; \n",
      " validation loss : 0.6263404767166222; validation accuracy : 0.9205020920502092\n",
      "Epoch 18:\t train loss : 0.5862708216460952; train accuracy : 0.9651609405495833; \n",
      " validation loss : 0.6175170202414099; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5818258375969168; train accuracy : 0.9692171380773877; \n",
      " validation loss : 0.6375011980489269; validation accuracy : 0.9121338912133892\n",
      "Epoch 20:\t train loss : 0.5818523915545193; train accuracy : 0.9693779237275009; \n",
      " validation loss : 0.6393860572607749; validation accuracy : 0.9079497907949791\n",
      "Epoch 21:\t train loss : 0.5850394929656677; train accuracy : 0.9660379813501038; \n",
      " validation loss : 0.6504259084854207; validation accuracy : 0.891213389121339\n",
      "Epoch 22:\t train loss : 0.5799227172934633; train accuracy : 0.9712212274234022; \n",
      " validation loss : 0.6255634491532978; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.5796309955717065; train accuracy : 0.9718680876111404; \n",
      " validation loss : 0.6204560531172594; validation accuracy : 0.9288702928870293\n",
      "Epoch 24:\t train loss : 0.5762362378094246; train accuracy : 0.9749697946033025; \n",
      " validation loss : 0.6266861189226237; validation accuracy : 0.9205020920502092\n",
      "Epoch 25:\t train loss : 0.5797200147935829; train accuracy : 0.9715177050094489; \n",
      " validation loss : 0.6368286639886345; validation accuracy : 0.9037656903765691\n",
      "Epoch 26:\t train loss : 0.5820644272516641; train accuracy : 0.9688143994547539; \n",
      " validation loss : 0.634078640358684; validation accuracy : 0.9163179916317992\n",
      "Epoch 27:\t train loss : 0.5749952188766819; train accuracy : 0.9763446823011865; \n",
      " validation loss : 0.6326300604610471; validation accuracy : 0.9121338912133892\n",
      "Epoch 28:\t train loss : 0.5745287051317844; train accuracy : 0.9768927166269091; \n",
      " validation loss : 0.6101269702644697; validation accuracy : 0.9414225941422594\n",
      "Epoch 29:\t train loss : 0.572950231343997; train accuracy : 0.9784321075621921; \n",
      " validation loss : 0.6340499062117512; validation accuracy : 0.9163179916317992\n",
      "Epoch 30:\t train loss : 0.5775791062917449; train accuracy : 0.9734945320487004; \n",
      " validation loss : 0.6212942210382226; validation accuracy : 0.9205020920502092\n",
      "Epoch 31:\t train loss : 0.5848412930272133; train accuracy : 0.9661832770531925; \n",
      " validation loss : 0.6388874216397865; validation accuracy : 0.9079497907949791\n",
      "Epoch 32:\t train loss : 0.5835762897520795; train accuracy : 0.9673818891539391; \n",
      " validation loss : 0.6192856816501517; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5743421737469361; train accuracy : 0.9767784008178692; \n",
      " validation loss : 0.6297729692091157; validation accuracy : 0.9163179916317992\n",
      "Epoch 34:\t train loss : 0.5739459560683953; train accuracy : 0.9771036897053812; \n",
      " validation loss : 0.6227664050492745; validation accuracy : 0.9205020920502092\n",
      "Epoch 35:\t train loss : 0.5749035565257474; train accuracy : 0.9761758418786208; \n",
      " validation loss : 0.6424074179769454; validation accuracy : 0.9037656903765691\n",
      "Epoch 36:\t train loss : 0.5736854321146064; train accuracy : 0.9776303479042102; \n",
      " validation loss : 0.6108256199198862; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.5699956264387526; train accuracy : 0.9814157811580284; \n",
      " validation loss : 0.6349197590114638; validation accuracy : 0.9163179916317992\n",
      "Epoch 38:\t train loss : 0.5669236750541824; train accuracy : 0.9842696489978005; \n",
      " validation loss : 0.6047317028736968; validation accuracy : 0.9456066945606695\n",
      "Epoch 39:\t train loss : 0.5671908541103643; train accuracy : 0.9839598500573128; \n",
      " validation loss : 0.6007718266557175; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5723576046707765; train accuracy : 0.9788791474333158; \n",
      " validation loss : 0.5967531534630639; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41:\t train loss : 0.5679349651066786; train accuracy : 0.9831196753307103; \n",
      " validation loss : 0.6037665460391365; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5683848157715687; train accuracy : 0.9828873261253447; \n",
      " validation loss : 0.616796817522381; validation accuracy : 0.9288702928870293\n",
      "Epoch 43:\t train loss : 0.5700579931166492; train accuracy : 0.9811657734130549; \n",
      " validation loss : 0.6300803433964473; validation accuracy : 0.9163179916317992\n",
      "Epoch 44:\t train loss : 0.5723880400156756; train accuracy : 0.9786681743548437; \n",
      " validation loss : 0.63379083944902; validation accuracy : 0.9163179916317992\n",
      "Epoch 45:\t train loss : 0.5816575363687367; train accuracy : 0.9692193066699711; \n",
      " validation loss : 0.6272995804653553; validation accuracy : 0.9205020920502092\n",
      "Epoch 46:\t train loss : 0.5686841739067183; train accuracy : 0.982540661110939; \n",
      " validation loss : 0.5968801769624558; validation accuracy : 0.9581589958158996\n",
      "Epoch 47:\t train loss : 0.5638408114950729; train accuracy : 0.9875284240527897; \n",
      " validation loss : 0.604025289850634; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5654946031454188; train accuracy : 0.9856364819232318; \n",
      " validation loss : 0.6194492075845608; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5669994662209706; train accuracy : 0.9843374949657672; \n",
      " validation loss : 0.611934713629008; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5651990942957053; train accuracy : 0.9859986368846618; \n",
      " validation loss : 0.6138143001872856; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5633408161550223; train accuracy : 0.987983518696366; \n",
      " validation loss : 0.6022126280361132; validation accuracy : 0.9497907949790795\n",
      "Epoch 52:\t train loss : 0.5621721958686953; train accuracy : 0.9891452647231946; \n",
      " validation loss : 0.6115466889830136; validation accuracy : 0.9372384937238494\n",
      "Epoch 53:\t train loss : 0.5613992242504766; train accuracy : 0.9898017286780879; \n",
      " validation loss : 0.6169060457184187; validation accuracy : 0.9372384937238494\n",
      "Epoch 54:\t train loss : 0.5619554999833808; train accuracy : 0.9893562378016667; \n",
      " validation loss : 0.6464477720877045; validation accuracy : 0.899581589958159\n",
      "Epoch 55:\t train loss : 0.5724976613648629; train accuracy : 0.978421884197156; \n",
      " validation loss : 0.6460566584478967; validation accuracy : 0.9079497907949791\n",
      "Epoch 56:\t train loss : 0.5739806567228022; train accuracy : 0.976970166362031; \n",
      " validation loss : 0.6126237101011678; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.563666708561327; train accuracy : 0.9875188202856346; \n",
      " validation loss : 0.5997266481486828; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.5647488726563868; train accuracy : 0.9864809938350011; \n",
      " validation loss : 0.6041438138510894; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5621390151990387; train accuracy : 0.9891046810619908; \n",
      " validation loss : 0.5873318127615224; validation accuracy : 0.9623430962343096\n",
      "Epoch 60:\t train loss : 0.5649144839356762; train accuracy : 0.9864035440998792; \n",
      " validation loss : 0.6134374018584762; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5623698391271429; train accuracy : 0.9889225192849841; \n",
      " validation loss : 0.6247676976796861; validation accuracy : 0.9288702928870293\n",
      "Epoch 62:\t train loss : 0.5738260773625393; train accuracy : 0.9771693670807646; \n",
      " validation loss : 0.6048242735091265; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5623868905774478; train accuracy : 0.9888199758356826; \n",
      " validation loss : 0.6243079202444414; validation accuracy : 0.9288702928870293\n",
      "Epoch 64:\t train loss : 0.5663321201988029; train accuracy : 0.9850345425818644; \n",
      " validation loss : 0.6297724141032174; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.5653559387782284; train accuracy : 0.9858592273614424; \n",
      " validation loss : 0.6503416903952457; validation accuracy : 0.899581589958159\n",
      "Epoch 66:\t train loss : 0.5652459264094217; train accuracy : 0.9860627652653428; \n",
      " validation loss : 0.6014085934708181; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.56191940749417; train accuracy : 0.9894085938226092; \n",
      " validation loss : 0.6183331933632061; validation accuracy : 0.9330543933054394\n",
      "Epoch 68:\t train loss : 0.5605257264703668; train accuracy : 0.9907156355525264; \n",
      " validation loss : 0.6310043156324493; validation accuracy : 0.9205020920502092\n",
      "Epoch 69:\t train loss : 0.5598628057052204; train accuracy : 0.9914997366709006; \n",
      " validation loss : 0.6109360572376269; validation accuracy : 0.9414225941422594\n",
      "Epoch 70:\t train loss : 0.5809268605524094; train accuracy : 0.9699259580532235; \n",
      " validation loss : 0.6316230937536095; validation accuracy : 0.9205020920502092\n",
      "Epoch 71:\t train loss : 0.5692127025937744; train accuracy : 0.9819092908702253; \n",
      " validation loss : 0.6284518294375419; validation accuracy : 0.9205020920502092\n",
      "Epoch 72:\t train loss : 0.5639694688089649; train accuracy : 0.9872149075250163; \n",
      " validation loss : 0.6084764376948072; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5627376450107744; train accuracy : 0.9884984045354565; \n",
      " validation loss : 0.6117686627194333; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5649843366393872; train accuracy : 0.9863356981319124; \n",
      " validation loss : 0.6127951426539918; validation accuracy : 0.9372384937238494\n",
      "Epoch 75:\t train loss : 0.5596036394184134; train accuracy : 0.9917011059822175; \n",
      " validation loss : 0.6159361946012981; validation accuracy : 0.9330543933054394\n",
      "Epoch 76:\t train loss : 0.5603855080742257; train accuracy : 0.9909266086309985; \n",
      " validation loss : 0.596813533528221; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5602522987603141; train accuracy : 0.9911183741751604; \n",
      " validation loss : 0.6130640709731455; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5681437070527747; train accuracy : 0.9830577155426128; \n",
      " validation loss : 0.6273666753899715; validation accuracy : 0.9246861924686193\n",
      "Epoch 79:\t train loss : 0.5803435608988736; train accuracy : 0.970588308187986; \n",
      " validation loss : 0.5826126684693319; validation accuracy : 0.9707112970711297\n",
      "Epoch 80:\t train loss : 0.5643137745867185; train accuracy : 0.9869825583196505; \n",
      " validation loss : 0.5970803994916571; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5626287036881134; train accuracy : 0.9886650763654389; \n",
      " validation loss : 0.5989139931022345; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5589375507567497; train accuracy : 0.9924350196722327; \n",
      " validation loss : 0.6251957113042784; validation accuracy : 0.9246861924686193\n",
      "Epoch 83:\t train loss : 0.5598817616275523; train accuracy : 0.9914495492425416; \n",
      " validation loss : 0.6247263131332472; validation accuracy : 0.9246861924686193\n",
      "Epoch 84:\t train loss : 0.5579097507753791; train accuracy : 0.9935406920908331; \n",
      " validation loss : 0.6141242980156963; validation accuracy : 0.9372384937238494\n",
      "Epoch 85:\t train loss : 0.5587331665323053; train accuracy : 0.9925995229096316; \n",
      " validation loss : 0.616766727938406; validation accuracy : 0.9372384937238494\n",
      "Epoch 86:\t train loss : 0.5605668327082882; train accuracy : 0.9909693608847858; \n",
      " validation loss : 0.6067825988572714; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.559053363869563; train accuracy : 0.9922801202019889; \n",
      " validation loss : 0.6220848145701434; validation accuracy : 0.9288702928870293\n",
      "Epoch 88:\t train loss : 0.5711434127869042; train accuracy : 0.9799516713652839; \n",
      " validation loss : 0.602225117296637; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.5643090183719475; train accuracy : 0.9868350940239784; \n",
      " validation loss : 0.616980169511856; validation accuracy : 0.9330543933054394\n",
      "Epoch 90:\t train loss : 0.5630245728799883; train accuracy : 0.9882468477957805; \n",
      " validation loss : 0.6102339954584667; validation accuracy : 0.9414225941422594\n",
      "Epoch 91:\t train loss : 0.5670876561708174; train accuracy : 0.9841729917283683; \n",
      " validation loss : 0.6116952144157825; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:\t train loss : 0.5602974190770081; train accuracy : 0.9909767960593575; \n",
      " validation loss : 0.6009919972918971; validation accuracy : 0.9497907949790795\n",
      "Epoch 93:\t train loss : 0.5601304324503351; train accuracy : 0.9911434678893398; \n",
      " validation loss : 0.5978633654901341; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5588700041917289; train accuracy : 0.9926246166238112; \n",
      " validation loss : 0.6104610600457487; validation accuracy : 0.9372384937238494\n",
      "Epoch 95:\t train loss : 0.5588873648773726; train accuracy : 0.9924756033334365; \n",
      " validation loss : 0.6118394958678315; validation accuracy : 0.9414225941422594\n",
      "Epoch 96:\t train loss : 0.5708808628745716; train accuracy : 0.9800836457139317; \n",
      " validation loss : 0.6065249598935475; validation accuracy : 0.9414225941422594\n",
      "Epoch 97:\t train loss : 0.5617040143517453; train accuracy : 0.9895170234517798; \n",
      " validation loss : 0.6111241663386767; validation accuracy : 0.9372384937238494\n",
      "Epoch 98:\t train loss : 0.5597977363433628; train accuracy : 0.99139130704173; \n",
      " validation loss : 0.6051144502713158; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5613086335531468; train accuracy : 0.9898187676198147; \n",
      " validation loss : 0.6329707911592835; validation accuracy : 0.9205020920502092\n",
      "Epoch 100:\t train loss : 0.5591612621325345; train accuracy : 0.9922026704668669; \n",
      " validation loss : 0.6219604120829334; validation accuracy : 0.9288702928870293\n",
      "Epoch 101:\t train loss : 0.5577498472051746; train accuracy : 0.9935598996251432; \n",
      " validation loss : 0.6077721732666821; validation accuracy : 0.9414225941422594\n",
      "Epoch 102:\t train loss : 0.5587116626248856; train accuracy : 0.992615012856656; \n",
      " validation loss : 0.6066452813935125; validation accuracy : 0.9414225941422594\n",
      "Epoch 103:\t train loss : 0.5595210730401667; train accuracy : 0.9917181449239444; \n",
      " validation loss : 0.5966926536550327; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.5585924161847097; train accuracy : 0.9928222683478423; \n",
      " validation loss : 0.6044829803956883; validation accuracy : 0.9456066945606695\n",
      "Epoch 105:\t train loss : 0.5567456347171519; train accuracy : 0.9945918398959075; \n",
      " validation loss : 0.6095378008219717; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.5584599473986545; train accuracy : 0.9928842281359398; \n",
      " validation loss : 0.6040336479905397; validation accuracy : 0.9456066945606695\n",
      "Epoch 107:\t train loss : 0.5611587305336707; train accuracy : 0.9900340778834537; \n",
      " validation loss : 0.5918922112915423; validation accuracy : 0.9581589958158996\n",
      "Epoch 108:\t train loss : 0.564363427364316; train accuracy : 0.9868158864896682; \n",
      " validation loss : 0.6147623559891251; validation accuracy : 0.9414225941422594\n",
      "Epoch 109:\t train loss : 0.5662242540268569; train accuracy : 0.9850308249945785; \n",
      " validation loss : 0.5954181717691189; validation accuracy : 0.9539748953974896\n",
      "Epoch 110:\t train loss : 0.5595644179953462; train accuracy : 0.9917011059822175; \n",
      " validation loss : 0.5975610879507115; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.5590513121847506; train accuracy : 0.9922277641810465; \n",
      " validation loss : 0.5974197952649717; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5593812562902195; train accuracy : 0.9919489451346076; \n",
      " validation loss : 0.5939414427238945; validation accuracy : 0.9581589958158996\n",
      "Epoch 113:\t train loss : 0.5561547626290548; train accuracy : 0.9952269277239072; \n",
      " validation loss : 0.5927745486822454; validation accuracy : 0.9581589958158996\n",
      "Epoch 114:\t train loss : 0.5606212494805757; train accuracy : 0.9907775953406239; \n",
      " validation loss : 0.5939393356966804; validation accuracy : 0.9581589958158996\n",
      "Epoch 115:\t train loss : 0.5603089469691993; train accuracy : 0.9909362123981535; \n",
      " validation loss : 0.5970039175172116; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5584000912475334; train accuracy : 0.9929557916911924; \n",
      " validation loss : 0.5921097207123288; validation accuracy : 0.9581589958158996\n",
      "Epoch 117:\t train loss : 0.5616922497812008; train accuracy : 0.9896387744353914; \n",
      " validation loss : 0.6105776278474881; validation accuracy : 0.9414225941422594\n",
      "Epoch 118:\t train loss : 0.5603980430734141; train accuracy : 0.9909826822392267; \n",
      " validation loss : 0.5991571082614432; validation accuracy : 0.9497907949790795\n",
      "Epoch 119:\t train loss : 0.5568602939523822; train accuracy : 0.994442826605533; \n",
      " validation loss : 0.5956130878768358; validation accuracy : 0.9539748953974896\n",
      "Epoch 120:\t train loss : 0.5557901568572475; train accuracy : 0.9955949688652065; \n",
      " validation loss : 0.6056747142567928; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5551004250127941; train accuracy : 0.9962455466402305; \n",
      " validation loss : 0.6198009978687486; validation accuracy : 0.9330543933054394\n",
      "Epoch 122:\t train loss : 0.5601637272262304; train accuracy : 0.9911877691378296; \n",
      " validation loss : 0.5771725634232385; validation accuracy : 0.9707112970711297\n",
      "Epoch 123:\t train loss : 0.5613440279082897; train accuracy : 0.9897803525511942; \n",
      " validation loss : 0.5972470937749055; validation accuracy : 0.9539748953974896\n",
      "Epoch 124:\t train loss : 0.5561973123343424; train accuracy : 0.9951612503485238; \n",
      " validation loss : 0.6091213772438101; validation accuracy : 0.9414225941422594\n",
      "Epoch 125:\t train loss : 0.5562116886300811; train accuracy : 0.9952328139037765; \n",
      " validation loss : 0.601989184266399; validation accuracy : 0.9497907949790795\n",
      "Epoch 126:\t train loss : 0.5674142646213887; train accuracy : 0.9836986895504818; \n",
      " validation loss : 0.6041708474071982; validation accuracy : 0.9497907949790795\n",
      "Epoch 127:\t train loss : 0.5583841919979752; train accuracy : 0.9929152080299886; \n",
      " validation loss : 0.607224389327851; validation accuracy : 0.9456066945606695\n",
      "Epoch 128:\t train loss : 0.5584608222747175; train accuracy : 0.9929152080299886; \n",
      " validation loss : 0.5975869715038915; validation accuracy : 0.9539748953974896\n",
      "Epoch 129:\t train loss : 0.5552436171039096; train accuracy : 0.9961680969051085; \n",
      " validation loss : 0.5798745755223488; validation accuracy : 0.9707112970711297\n",
      "Epoch 130:\t train loss : 0.5550481207820115; train accuracy : 0.9962300566932061; \n",
      " validation loss : 0.5933599967373383; validation accuracy : 0.9581589958158996\n",
      "Epoch 131:\t train loss : 0.5559172964112815; train accuracy : 0.9953877133740202; \n",
      " validation loss : 0.6053847909069274; validation accuracy : 0.9456066945606695\n",
      "Epoch 132:\t train loss : 0.5575813808418301; train accuracy : 0.9937457789894358; \n",
      " validation loss : 0.5939289150644449; validation accuracy : 0.9581589958158996\n",
      "Epoch 133:\t train loss : 0.5568184850558133; train accuracy : 0.9945763499488831; \n",
      " validation loss : 0.5964420048907327; validation accuracy : 0.9539748953974896\n",
      "Epoch 134:\t train loss : 0.558928951736803; train accuracy : 0.9924077573654698; \n",
      " validation loss : 0.6142935685889758; validation accuracy : 0.9372384937238494\n",
      "Epoch 135:\t train loss : 0.5557201795257961; train accuracy : 0.9956414387062796; \n",
      " validation loss : 0.6017659558326113; validation accuracy : 0.9497907949790795\n",
      "Epoch 136:\t train loss : 0.5606046727618498; train accuracy : 0.9908026890548034; \n",
      " validation loss : 0.6143836630603277; validation accuracy : 0.9372384937238494\n",
      "Epoch 137:\t train loss : 0.557109012905919; train accuracy : 0.9943189070293379; \n",
      " validation loss : 0.5923473098420488; validation accuracy : 0.9623430962343096\n",
      "Epoch 138:\t train loss : 0.5573358750169725; train accuracy : 0.9939818457820874; \n",
      " validation loss : 0.6015585653553942; validation accuracy : 0.9497907949790795\n",
      "Epoch 139:\t train loss : 0.558506163867768; train accuracy : 0.992853248241891; \n",
      " validation loss : 0.5851199172859619; validation accuracy : 0.9665271966527197\n",
      "Epoch 140:\t train loss : 0.5595121857054406; train accuracy : 0.9918287431456985; \n",
      " validation loss : 0.5859556273049903; validation accuracy : 0.9665271966527197\n",
      "Epoch 141:\t train loss : 0.5698343559322859; train accuracy : 0.9812048080795563; \n",
      " validation loss : 0.6149180387569584; validation accuracy : 0.9372384937238494\n",
      "Epoch 142:\t train loss : 0.5599325522905176; train accuracy : 0.9912887635924285; \n",
      " validation loss : 0.5892217821053017; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143:\t train loss : 0.556113513291013; train accuracy : 0.9952792837448495; \n",
      " validation loss : 0.5861920937031917; validation accuracy : 0.9665271966527197\n",
      "Epoch 144:\t train loss : 0.5584269845232122; train accuracy : 0.9927912884537935; \n",
      " validation loss : 0.6015257056528069; validation accuracy : 0.9497907949790795\n",
      "Epoch 145:\t train loss : 0.5559259436069932; train accuracy : 0.9953935995538895; \n",
      " validation loss : 0.6062497952948785; validation accuracy : 0.9456066945606695\n",
      "Epoch 146:\t train loss : 0.5549220846249; train accuracy : 0.9964373121843924; \n",
      " validation loss : 0.6156446728184662; validation accuracy : 0.9372384937238494\n",
      "Epoch 147:\t train loss : 0.5554804823513425; train accuracy : 0.9958775054989312; \n",
      " validation loss : 0.6119660181490152; validation accuracy : 0.9372384937238494\n",
      "Epoch 148:\t train loss : 0.5560956381242006; train accuracy : 0.9952830013321354; \n",
      " validation loss : 0.6105842340706823; validation accuracy : 0.9414225941422594\n",
      "Epoch 149:\t train loss : 0.5608535738786303; train accuracy : 0.9902819170358438; \n",
      " validation loss : 0.6137204031367517; validation accuracy : 0.9372384937238494\n",
      "Epoch 150:\t train loss : 0.5569936682851082; train accuracy : 0.9943093032621828; \n",
      " validation loss : 0.5977182233458718; validation accuracy : 0.9497907949790795\n",
      "Epoch 151:\t train loss : 0.556274622248877; train accuracy : 0.9951206666873199; \n",
      " validation loss : 0.6204975479449798; validation accuracy : 0.9288702928870293\n",
      "Epoch 152:\t train loss : 0.5567185538363736; train accuracy : 0.9946655720437436; \n",
      " validation loss : 0.5975659185589867; validation accuracy : 0.9539748953974896\n",
      "Epoch 153:\t train loss : 0.5555696889729521; train accuracy : 0.995817714303417; \n",
      " validation loss : 0.5900159354278202; validation accuracy : 0.9623430962343096\n",
      "Epoch 154:\t train loss : 0.5548279053265729; train accuracy : 0.9965398556336937; \n",
      " validation loss : 0.5952178287287221; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5653482447028336; train accuracy : 0.9858864896682054; \n",
      " validation loss : 0.5971900753871617; validation accuracy : 0.9539748953974896\n",
      "Epoch 156:\t train loss : 0.5572834121981388; train accuracy : 0.9940245980358747; \n",
      " validation loss : 0.6057381462778361; validation accuracy : 0.9456066945606695\n",
      "Epoch 157:\t train loss : 0.5597978710567413; train accuracy : 0.9915558102791289; \n",
      " validation loss : 0.6373140918745948; validation accuracy : 0.9163179916317992\n",
      "Epoch 158:\t train loss : 0.5689860351790853; train accuracy : 0.9821747885622231; \n",
      " validation loss : 0.6035078474036354; validation accuracy : 0.9497907949790795\n",
      "Epoch 159:\t train loss : 0.5593426704012326; train accuracy : 0.9919858112085257; \n",
      " validation loss : 0.6073129662907577; validation accuracy : 0.9456066945606695\n",
      "Epoch 160:\t train loss : 0.558687571712912; train accuracy : 0.992738932432851; \n",
      " validation loss : 0.6054415668273173; validation accuracy : 0.9456066945606695\n",
      "Epoch 161:\t train loss : 0.5551363691430761; train accuracy : 0.996233774280492; \n",
      " validation loss : 0.602159609777221; validation accuracy : 0.9497907949790795\n",
      "Epoch 162:\t train loss : 0.5550507164820628; train accuracy : 0.9963326001425075; \n",
      " validation loss : 0.5911560027884957; validation accuracy : 0.9581589958158996\n",
      "Epoch 163:\t train loss : 0.5555376523991364; train accuracy : 0.995858297964621; \n",
      " validation loss : 0.6017320937434509; validation accuracy : 0.9497907949790795\n",
      "Epoch 164:\t train loss : 0.5557410916049309; train accuracy : 0.9956724186003284; \n",
      " validation loss : 0.602962427687743; validation accuracy : 0.9456066945606695\n",
      "Epoch 165:\t train loss : 0.5559115990248205; train accuracy : 0.9954769354688807; \n",
      " validation loss : 0.6156896289319926; validation accuracy : 0.9330543933054394\n",
      "Epoch 166:\t train loss : 0.5576651663779435; train accuracy : 0.9935871619319062; \n",
      " validation loss : 0.6048124108052491; validation accuracy : 0.9456066945606695\n",
      "Epoch 167:\t train loss : 0.5566067445030757; train accuracy : 0.9947430217788655; \n",
      " validation loss : 0.5968728776164512; validation accuracy : 0.9539748953974896\n",
      "Epoch 168:\t train loss : 0.5586139311707231; train accuracy : 0.9926924625917779; \n",
      " validation loss : 0.6023484618613401; validation accuracy : 0.9497907949790795\n",
      "Epoch 169:\t train loss : 0.5555240527298844; train accuracy : 0.9959416338796121; \n",
      " validation loss : 0.6125591406392564; validation accuracy : 0.9372384937238494\n",
      "Epoch 170:\t train loss : 0.5625035446421193; train accuracy : 0.9887793921744787; \n",
      " validation loss : 0.6053775559903631; validation accuracy : 0.9456066945606695\n",
      "Epoch 171:\t train loss : 0.5584415838204373; train accuracy : 0.9929595092784783; \n",
      " validation loss : 0.6015065325969158; validation accuracy : 0.9497907949790795\n",
      "Epoch 172:\t train loss : 0.5605348136165051; train accuracy : 0.990713466959943; \n",
      " validation loss : 0.6166602194003168; validation accuracy : 0.9330543933054394\n",
      "Early stopping at epoch 172\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5601637272262304; Train accuracy : 0.9911877691378296; \n",
      " Validation loss : 0.5771725634232385; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 67 ! ---\n",
      "Epoch 1:\t train loss : 0.9263415618347922; train accuracy : 0.6083156231605688; \n",
      " validation loss : 0.8056378561260501; validation accuracy : 0.7364016736401674\n",
      "Epoch 2:\t train loss : 0.7582579779633952; train accuracy : 0.7908727036153537; \n",
      " validation loss : 0.7042665168979424; validation accuracy : 0.8493723849372385\n",
      "Epoch 3:\t train loss : 0.7049755579759714; train accuracy : 0.8455041977756436; \n",
      " validation loss : 0.6873123055637012; validation accuracy : 0.8661087866108786\n",
      "Epoch 4:\t train loss : 0.6792835961651341; train accuracy : 0.8716843768394312; \n",
      " validation loss : 0.6664186020095143; validation accuracy : 0.8870292887029289\n",
      "Epoch 5:\t train loss : 0.6649918068691749; train accuracy : 0.886206511973729; \n",
      " validation loss : 0.6478053313259504; validation accuracy : 0.9079497907949791\n",
      "Epoch 6:\t train loss : 0.6502541372259031; train accuracy : 0.9003658725487159; \n",
      " validation loss : 0.6651300087820816; validation accuracy : 0.8786610878661087\n",
      "Epoch 7:\t train loss : 0.6424322722034134; train accuracy : 0.907907927754887; \n",
      " validation loss : 0.6698267073597435; validation accuracy : 0.8828451882845189\n",
      "Epoch 8:\t train loss : 0.6295492468561872; train accuracy : 0.921339880417609; \n",
      " validation loss : 0.6569337409307888; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6181480914769842; train accuracy : 0.933164596177081; \n",
      " validation loss : 0.64793568979919; validation accuracy : 0.9037656903765691\n",
      "Epoch 10:\t train loss : 0.6136509249359027; train accuracy : 0.9378056941045262; \n",
      " validation loss : 0.6486457721567426; validation accuracy : 0.9037656903765691\n",
      "Epoch 11:\t train loss : 0.6030867776491278; train accuracy : 0.9477849375755135; \n",
      " validation loss : 0.6436225668838895; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.6030309216566538; train accuracy : 0.9478372935964559; \n",
      " validation loss : 0.6608875341649495; validation accuracy : 0.8828451882845189\n",
      "Epoch 13:\t train loss : 0.5938263086376849; train accuracy : 0.9573444034821401; \n",
      " validation loss : 0.6461860499351987; validation accuracy : 0.9037656903765691\n",
      "Epoch 14:\t train loss : 0.5894871724712476; train accuracy : 0.9617841320982682; \n",
      " validation loss : 0.6304125979837218; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.587860642725366; train accuracy : 0.9636989993494223; \n",
      " validation loss : 0.6370401984357834; validation accuracy : 0.9121338912133892\n",
      "Epoch 16:\t train loss : 0.5834064346500488; train accuracy : 0.968073050590167; \n",
      " validation loss : 0.6175063272612569; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5853417044718535; train accuracy : 0.9663034790421017; \n",
      " validation loss : 0.6201410087436027; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.5843185769255596; train accuracy : 0.9670138480126398; \n",
      " validation loss : 0.6172692145529702; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5838060497653502; train accuracy : 0.9674342451748815; \n",
      " validation loss : 0.6212364924372094; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.576729665215978; train accuracy : 0.9746002044673007; \n",
      " validation loss : 0.6149634605457299; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:\t train loss : 0.5749289474951935; train accuracy : 0.9765091855385855; \n",
      " validation loss : 0.6172512637406686; validation accuracy : 0.9288702928870293\n",
      "Epoch 22:\t train loss : 0.5787348988047653; train accuracy : 0.9726949409833018; \n",
      " validation loss : 0.6148529531308735; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.574685231330485; train accuracy : 0.9766603674215434; \n",
      " validation loss : 0.6261476389099346; validation accuracy : 0.9205020920502092\n",
      "Epoch 24:\t train loss : 0.5719126658656615; train accuracy : 0.97966324855169; \n",
      " validation loss : 0.6497066358002423; validation accuracy : 0.895397489539749\n",
      "Epoch 25:\t train loss : 0.5777797662092659; train accuracy : 0.9733337463985873; \n",
      " validation loss : 0.6121098903516472; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5699629869724341; train accuracy : 0.9813014653489885; \n",
      " validation loss : 0.6085087949065541; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5711053210196736; train accuracy : 0.9800312896929892; \n",
      " validation loss : 0.6149455912234857; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.5676371835758404; train accuracy : 0.9835998636884662; \n",
      " validation loss : 0.6000591771808587; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5669311245549999; train accuracy : 0.9845041667957496; \n",
      " validation loss : 0.6061858810751958; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5692320121746105; train accuracy : 0.9820198890919793; \n",
      " validation loss : 0.6097724101825731; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5939421325077318; train accuracy : 0.9568465565847765; \n",
      " validation loss : 0.6259839014619819; validation accuracy : 0.9205020920502092\n",
      "Epoch 32:\t train loss : 0.5768329175162187; train accuracy : 0.9743117816537068; \n",
      " validation loss : 0.5929417381049671; validation accuracy : 0.9581589958158996\n",
      "Epoch 33:\t train loss : 0.5666657490276964; train accuracy : 0.9845078843830354; \n",
      " validation loss : 0.6204331219440563; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.5663428756789084; train accuracy : 0.9849474890795874; \n",
      " validation loss : 0.602306960531912; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.5804199927634908; train accuracy : 0.9705492735214846; \n",
      " validation loss : 0.6396780077059369; validation accuracy : 0.9037656903765691\n",
      "Epoch 36:\t train loss : 0.5693467521415992; train accuracy : 0.9819055732829394; \n",
      " validation loss : 0.5945290254601397; validation accuracy : 0.9581589958158996\n",
      "Epoch 37:\t train loss : 0.5715203751925236; train accuracy : 0.9795820812292823; \n",
      " validation loss : 0.629886231659243; validation accuracy : 0.9205020920502092\n",
      "Epoch 38:\t train loss : 0.5672514990569401; train accuracy : 0.9839502462901577; \n",
      " validation loss : 0.6154275979799729; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5632288594344853; train accuracy : 0.9881554571083367; \n",
      " validation loss : 0.6230337742320528; validation accuracy : 0.9246861924686193\n",
      "Epoch 40:\t train loss : 0.5672453047641878; train accuracy : 0.9840394683850181; \n",
      " validation loss : 0.5886196036190802; validation accuracy : 0.9623430962343096\n",
      "Epoch 41:\t train loss : 0.5653588712516119; train accuracy : 0.986072369032498; \n",
      " validation loss : 0.6212944469527971; validation accuracy : 0.9330543933054394\n",
      "Epoch 42:\t train loss : 0.5671288827689868; train accuracy : 0.9843027974844326; \n",
      " validation loss : 0.6273914455129191; validation accuracy : 0.9246861924686193\n",
      "Epoch 43:\t train loss : 0.5753602321453397; train accuracy : 0.975630905542303; \n",
      " validation loss : 0.821383817704214; validation accuracy : 0.7280334728033473\n",
      "Epoch 44:\t train loss : 0.632000988350769; train accuracy : 0.9181371789708479; \n",
      " validation loss : 0.6145610751695333; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5749601283372715; train accuracy : 0.9758895876576102; \n",
      " validation loss : 0.5978675291886292; validation accuracy : 0.9539748953974896\n",
      "Epoch 46:\t train loss : 0.5709254111503524; train accuracy : 0.9805114780507451; \n",
      " validation loss : 0.608825271430397; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.5684269494682584; train accuracy : 0.9828445738715573; \n",
      " validation loss : 0.5926013101928345; validation accuracy : 0.9581589958158996\n",
      "Epoch 48:\t train loss : 0.5688066151047922; train accuracy : 0.9824300628891849; \n",
      " validation loss : 0.6576206754943745; validation accuracy : 0.891213389121339\n",
      "Epoch 49:\t train loss : 0.5719690496236617; train accuracy : 0.9790554230304532; \n",
      " validation loss : 0.6051620798662622; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5664607466932241; train accuracy : 0.9847867034294743; \n",
      " validation loss : 0.5996086172354013; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5648090013541174; train accuracy : 0.9864537315282381; \n",
      " validation loss : 0.6319164844036319; validation accuracy : 0.9246861924686193\n",
      "Epoch 52:\t train loss : 0.5683029757600206; train accuracy : 0.9830326218284333; \n",
      " validation loss : 0.6204873915059461; validation accuracy : 0.9288702928870293\n",
      "Epoch 53:\t train loss : 0.5676407550850244; train accuracy : 0.9834235880913287; \n",
      " validation loss : 0.587546176262085; validation accuracy : 0.9665271966527197\n",
      "Epoch 54:\t train loss : 0.5657630869280726; train accuracy : 0.9855206171194895; \n",
      " validation loss : 0.6194906517718205; validation accuracy : 0.9330543933054394\n",
      "Epoch 55:\t train loss : 0.5639030953978771; train accuracy : 0.9873949007094396; \n",
      " validation loss : 0.5948075372637565; validation accuracy : 0.9539748953974896\n",
      "Epoch 56:\t train loss : 0.5630128442792351; train accuracy : 0.9883146937637474; \n",
      " validation loss : 0.6129900193823247; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.5645002308220392; train accuracy : 0.9867288329873912; \n",
      " validation loss : 0.5996931449875733; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.5646774597151062; train accuracy : 0.9866978530933425; \n",
      " validation loss : 0.6023343473658006; validation accuracy : 0.9497907949790795\n",
      "Epoch 59:\t train loss : 0.5716311771316781; train accuracy : 0.9793711081508101; \n",
      " validation loss : 0.5992100180856953; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5655113656499452; train accuracy : 0.9857161002509371; \n",
      " validation loss : 0.5976455287588318; validation accuracy : 0.9539748953974896\n",
      "Epoch 61:\t train loss : 0.588752242264964; train accuracy : 0.9621072523931968; \n",
      " validation loss : 0.6495640734691742; validation accuracy : 0.899581589958159\n",
      "Epoch 62:\t train loss : 0.6118200921651532; train accuracy : 0.9382276402614703; \n",
      " validation loss : 0.6130386535840646; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5793831425832433; train accuracy : 0.9715427987236284; \n",
      " validation loss : 0.605025525254303; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5701421637844408; train accuracy : 0.9808330493509713; \n",
      " validation loss : 0.6133073797116356; validation accuracy : 0.9372384937238494\n",
      "Epoch 65:\t train loss : 0.5660576793934573; train accuracy : 0.9852167043588711; \n",
      " validation loss : 0.5831457489715707; validation accuracy : 0.9707112970711297\n",
      "Epoch 66:\t train loss : 0.5664323374290191; train accuracy : 0.984767495895164; \n",
      " validation loss : 0.6156746455887433; validation accuracy : 0.9330543933054394\n",
      "Epoch 67:\t train loss : 0.5672871041362169; train accuracy : 0.9838845689147743; \n",
      " validation loss : 0.6026757956373242; validation accuracy : 0.9497907949790795\n",
      "Epoch 68:\t train loss : 0.5635086388780082; train accuracy : 0.9878072430992286; \n",
      " validation loss : 0.6131696676195976; validation accuracy : 0.9372384937238494\n",
      "Epoch 69:\t train loss : 0.564484688952347; train accuracy : 0.9867517581089873; \n",
      " validation loss : 0.5942139582874283; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5664959258274394; train accuracy : 0.9846029926577651; \n",
      " validation loss : 0.6144807378159961; validation accuracy : 0.9414225941422594\n",
      "Epoch 71:\t train loss : 0.5635329678109939; train accuracy : 0.9877452833111311; \n",
      " validation loss : 0.5945807262094166; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72:\t train loss : 0.5623355570228625; train accuracy : 0.988872331856625; \n",
      " validation loss : 0.5821044385483809; validation accuracy : 0.9665271966527197\n",
      "Epoch 73:\t train loss : 0.5601078632580175; train accuracy : 0.9911493540692091; \n",
      " validation loss : 0.6005526815790609; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5614208730760091; train accuracy : 0.9898887821803649; \n",
      " validation loss : 0.5840752149951614; validation accuracy : 0.9665271966527197\n",
      "Epoch 75:\t train loss : 0.5612093505095658; train accuracy : 0.9900746615446575; \n",
      " validation loss : 0.5921213445832793; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5641985535284274; train accuracy : 0.9870754980017968; \n",
      " validation loss : 0.6013133855890825; validation accuracy : 0.9497907949790795\n",
      "Epoch 77:\t train loss : 0.5645541200322213; train accuracy : 0.9866631556120078; \n",
      " validation loss : 0.5929194457691712; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5611393016367704; train accuracy : 0.9901734874066731; \n",
      " validation loss : 0.6185795863000447; validation accuracy : 0.9330543933054394\n",
      "Epoch 79:\t train loss : 0.5629904806836686; train accuracy : 0.9881693980606586; \n",
      " validation loss : 0.6006500807830225; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5627504911766499; train accuracy : 0.9885839090430311; \n",
      " validation loss : 0.5887402583138918; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5631502052406443; train accuracy : 0.9880823445583816; \n",
      " validation loss : 0.5942444896449277; validation accuracy : 0.9581589958158996\n",
      "Epoch 82:\t train loss : 0.5684761046919026; train accuracy : 0.9827132191207906; \n",
      " validation loss : 0.5959617099704577; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5647313472800396; train accuracy : 0.9864190340469036; \n",
      " validation loss : 0.601629495438481; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5620283474556491; train accuracy : 0.9891821307971127; \n",
      " validation loss : 0.5858966747150147; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5594965535105083; train accuracy : 0.9919179652405589; \n",
      " validation loss : 0.6009410850008444; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5615372531458536; train accuracy : 0.9897921249109328; \n",
      " validation loss : 0.5964885048412878; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5589529986311665; train accuracy : 0.9923052139161684; \n",
      " validation loss : 0.593778842061735; validation accuracy : 0.9581589958158996\n",
      "Epoch 88:\t train loss : 0.5670939157219744; train accuracy : 0.984130239474581; \n",
      " validation loss : 0.6312612869682379; validation accuracy : 0.9163179916317992\n",
      "Epoch 89:\t train loss : 0.5618816125578122; train accuracy : 0.989234486818055; \n",
      " validation loss : 0.5906809670622122; validation accuracy : 0.9623430962343096\n",
      "Epoch 90:\t train loss : 0.560101573002214; train accuracy : 0.9912673874655349; \n",
      " validation loss : 0.5931903562041287; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5587583697473971; train accuracy : 0.9924910932804609; \n",
      " validation loss : 0.5917912086089023; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5593310631027539; train accuracy : 0.9919607174943461; \n",
      " validation loss : 0.5936264023766797; validation accuracy : 0.9581589958158996\n",
      "Epoch 93:\t train loss : 0.5614553389457457; train accuracy : 0.9897589764243007; \n",
      " validation loss : 0.5862544059348085; validation accuracy : 0.9665271966527197\n",
      "Epoch 94:\t train loss : 0.5608598521848962; train accuracy : 0.9903593667709656; \n",
      " validation loss : 0.5907077249016963; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5635764690333348; train accuracy : 0.987809411691812; \n",
      " validation loss : 0.57895048869003; validation accuracy : 0.9665271966527197\n",
      "Epoch 96:\t train loss : 0.5586480851816484; train accuracy : 0.9927197248985409; \n",
      " validation loss : 0.5915218494157427; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5612434941842211; train accuracy : 0.9900746615446575; \n",
      " validation loss : 0.5987460307265356; validation accuracy : 0.9497907949790795\n",
      "Epoch 98:\t train loss : 0.5596113785259578; train accuracy : 0.9917748381300536; \n",
      " validation loss : 0.5857367109796263; validation accuracy : 0.9623430962343096\n",
      "Epoch 99:\t train loss : 0.5607578288022431; train accuracy : 0.9905238700083646; \n",
      " validation loss : 0.5848625355512108; validation accuracy : 0.9665271966527197\n",
      "Epoch 100:\t train loss : 0.5591619211527474; train accuracy : 0.9921252207317451; \n",
      " validation loss : 0.5945258846196311; validation accuracy : 0.9581589958158996\n",
      "Epoch 101:\t train loss : 0.5576680024444297; train accuracy : 0.9936491217200037; \n",
      " validation loss : 0.6133358549202163; validation accuracy : 0.9372384937238494\n",
      "Epoch 102:\t train loss : 0.5618316808010372; train accuracy : 0.9893776139285604; \n",
      " validation loss : 0.586398387538068; validation accuracy : 0.9665271966527197\n",
      "Epoch 103:\t train loss : 0.5568831609832353; train accuracy : 0.9944545989652716; \n",
      " validation loss : 0.5816752177549946; validation accuracy : 0.9707112970711297\n",
      "Epoch 104:\t train loss : 0.5608934963749959; train accuracy : 0.9902974069828681; \n",
      " validation loss : 0.6065442527080088; validation accuracy : 0.9456066945606695\n",
      "Epoch 105:\t train loss : 0.5598729440004901; train accuracy : 0.991400910808885; \n",
      " validation loss : 0.5903106750250381; validation accuracy : 0.9623430962343096\n",
      "Epoch 106:\t train loss : 0.5616571777077348; train accuracy : 0.9894764397905759; \n",
      " validation loss : 0.5842948877170895; validation accuracy : 0.9665271966527197\n",
      "Epoch 107:\t train loss : 0.5610222008777292; train accuracy : 0.9902044673007219; \n",
      " validation loss : 0.6061168171330279; validation accuracy : 0.9456066945606695\n",
      "Epoch 108:\t train loss : 0.5566534149113932; train accuracy : 0.9946500820967192; \n",
      " validation loss : 0.5787551980317177; validation accuracy : 0.9707112970711297\n",
      "Epoch 109:\t train loss : 0.5601806533100971; train accuracy : 0.9911552402490783; \n",
      " validation loss : 0.5815677196313269; validation accuracy : 0.9707112970711297\n",
      "Epoch 110:\t train loss : 0.5561848914761207; train accuracy : 0.9952600762105394; \n",
      " validation loss : 0.5916910849233319; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.5552500120132561; train accuracy : 0.9961526069580842; \n",
      " validation loss : 0.598720925894436; validation accuracy : 0.9497907949790795\n",
      "Epoch 112:\t train loss : 0.5672358033972388; train accuracy : 0.9839465287028718; \n",
      " validation loss : 0.5945553854316856; validation accuracy : 0.9581589958158996\n",
      "Epoch 113:\t train loss : 0.5584180872423717; train accuracy : 0.9928687381889154; \n",
      " validation loss : 0.5906072059370215; validation accuracy : 0.9581589958158996\n",
      "Epoch 114:\t train loss : 0.5580862975575389; train accuracy : 0.9933548127265405; \n",
      " validation loss : 0.5766681059104953; validation accuracy : 0.9748953974895398\n",
      "Epoch 115:\t train loss : 0.5585879271311855; train accuracy : 0.9926983487716472; \n",
      " validation loss : 0.6146293657700621; validation accuracy : 0.9330543933054394\n",
      "Epoch 116:\t train loss : 0.5582884834007718; train accuracy : 0.9931165773413054; \n",
      " validation loss : 0.6064248110998139; validation accuracy : 0.9456066945606695\n",
      "Epoch 117:\t train loss : 0.564751124594661; train accuracy : 0.9864462963536664; \n",
      " validation loss : 0.5841125047639696; validation accuracy : 0.9665271966527197\n",
      "Epoch 118:\t train loss : 0.5613988047258629; train accuracy : 0.9898850645930791; \n",
      " validation loss : 0.5931230432113714; validation accuracy : 0.9581589958158996\n",
      "Epoch 119:\t train loss : 0.5569596765226473; train accuracy : 0.9943771492301496; \n",
      " validation loss : 0.5917385983526396; validation accuracy : 0.9581589958158996\n",
      "Epoch 120:\t train loss : 0.5586668572982864; train accuracy : 0.9927352148455653; \n",
      " validation loss : 0.6044539302567087; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5563946754150467; train accuracy : 0.994969484804362; \n",
      " validation loss : 0.5977328083732868; validation accuracy : 0.9539748953974896\n",
      "Epoch 122:\t train loss : 0.5611277404164686; train accuracy : 0.9902295610149013; \n",
      " validation loss : 0.5892036756268884; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123:\t train loss : 0.5569312185696638; train accuracy : 0.9943306793890765; \n",
      " validation loss : 0.577830742966082; validation accuracy : 0.9707112970711297\n",
      "Epoch 124:\t train loss : 0.5575689019030687; train accuracy : 0.993829114904427; \n",
      " validation loss : 0.5795452802620981; validation accuracy : 0.9748953974895398\n",
      "Epoch 125:\t train loss : 0.5553799353700837; train accuracy : 0.9960655534558072; \n",
      " validation loss : 0.6101452222779459; validation accuracy : 0.9414225941422594\n",
      "Epoch 126:\t train loss : 0.5559226691031265; train accuracy : 0.9954614455218563; \n",
      " validation loss : 0.5821545389164908; validation accuracy : 0.9707112970711297\n",
      "Epoch 127:\t train loss : 0.559019892060317; train accuracy : 0.9922277641810465; \n",
      " validation loss : 0.5723667246424053; validation accuracy : 0.9790794979079498\n",
      "Epoch 128:\t train loss : 0.5579726930258543; train accuracy : 0.9933083428854673; \n",
      " validation loss : 0.5809725138853307; validation accuracy : 0.9707112970711297\n",
      "Epoch 129:\t train loss : 0.5559861231159959; train accuracy : 0.9954400693949627; \n",
      " validation loss : 0.5831057220472983; validation accuracy : 0.9665271966527197\n",
      "Epoch 130:\t train loss : 0.5569451261896059; train accuracy : 0.9944332228383779; \n",
      " validation loss : 0.58875983209523; validation accuracy : 0.9623430962343096\n",
      "Epoch 131:\t train loss : 0.5671004443266867; train accuracy : 0.9840549583320425; \n",
      " validation loss : 0.5928827487161974; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.5608164865473922; train accuracy : 0.99048917252703; \n",
      " validation loss : 0.5896887588302416; validation accuracy : 0.9623430962343096\n",
      "Epoch 133:\t train loss : 0.5560780905349421; train accuracy : 0.9952755661575637; \n",
      " validation loss : 0.5928343301747859; validation accuracy : 0.9581589958158996\n",
      "Epoch 134:\t train loss : 0.558820617254058; train accuracy : 0.9924873756931751; \n",
      " validation loss : 0.5964397275181719; validation accuracy : 0.9539748953974896\n",
      "Epoch 135:\t train loss : 0.557944146669661; train accuracy : 0.9933548127265405; \n",
      " validation loss : 0.6058881351428509; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.558178130841095; train accuracy : 0.9931999132562966; \n",
      " validation loss : 0.6072774897641927; validation accuracy : 0.9414225941422594\n",
      "Epoch 137:\t train loss : 0.5575021100236895; train accuracy : 0.9936683292543139; \n",
      " validation loss : 0.5908430859665867; validation accuracy : 0.9623430962343096\n",
      "Epoch 138:\t train loss : 0.556619689662545; train accuracy : 0.9947643979057591; \n",
      " validation loss : 0.5966501758989083; validation accuracy : 0.9497907949790795\n",
      "Epoch 139:\t train loss : 0.5566389730435116; train accuracy : 0.9947740016729143; \n",
      " validation loss : 0.5893832668502662; validation accuracy : 0.9623430962343096\n",
      "Epoch 140:\t train loss : 0.5573930154511669; train accuracy : 0.9939995043216953; \n",
      " validation loss : 0.6251937320106589; validation accuracy : 0.9246861924686193\n",
      "Epoch 141:\t train loss : 0.5602632955876006; train accuracy : 0.9910158307258589; \n",
      " validation loss : 0.6101828631154234; validation accuracy : 0.9372384937238494\n",
      "Epoch 142:\t train loss : 0.55687838614892; train accuracy : 0.9945165587533691; \n",
      " validation loss : 0.5862149284056767; validation accuracy : 0.9665271966527197\n",
      "Epoch 143:\t train loss : 0.563304345026935; train accuracy : 0.9879023513739583; \n",
      " validation loss : 0.5970716229420328; validation accuracy : 0.9539748953974896\n",
      "Epoch 144:\t train loss : 0.5623619674767487; train accuracy : 0.988872331856625; \n",
      " validation loss : 0.5849031066599931; validation accuracy : 0.9665271966527197\n",
      "Epoch 145:\t train loss : 0.5557675458196029; train accuracy : 0.9955175191300846; \n",
      " validation loss : 0.5820624445757419; validation accuracy : 0.9707112970711297\n",
      "Epoch 146:\t train loss : 0.5553083631273962; train accuracy : 0.9961430031909291; \n",
      " validation loss : 0.5930060337756681; validation accuracy : 0.9581589958158996\n",
      "Epoch 147:\t train loss : 0.5550373496892282; train accuracy : 0.9963384863223768; \n",
      " validation loss : 0.5931734062354802; validation accuracy : 0.9581589958158996\n",
      "Epoch 148:\t train loss : 0.5582651599932703; train accuracy : 0.993101087394281; \n",
      " validation loss : 0.589481350036906; validation accuracy : 0.9623430962343096\n",
      "Epoch 149:\t train loss : 0.5585853864131733; train accuracy : 0.9928126645806872; \n",
      " validation loss : 0.6016522348503832; validation accuracy : 0.9456066945606695\n",
      "Epoch 150:\t train loss : 0.5578033851666186; train accuracy : 0.9934824498900213; \n",
      " validation loss : 0.5956318565773304; validation accuracy : 0.9539748953974896\n",
      "Epoch 151:\t train loss : 0.5579155439459734; train accuracy : 0.9934942222497599; \n",
      " validation loss : 0.5993845358676418; validation accuracy : 0.9497907949790795\n",
      "Epoch 152:\t train loss : 0.5555198137389753; train accuracy : 0.9958369218377273; \n",
      " validation loss : 0.6015756405253322; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.555969960905645; train accuracy : 0.99536850583971; \n",
      " validation loss : 0.5821749864946354; validation accuracy : 0.9665271966527197\n",
      "Epoch 154:\t train loss : 0.5564305704073471; train accuracy : 0.9948728275349298; \n",
      " validation loss : 0.5696802016645598; validation accuracy : 0.9832635983263598\n",
      "Epoch 155:\t train loss : 0.5573176328298334; train accuracy : 0.9940518603426376; \n",
      " validation loss : 0.5819485850576732; validation accuracy : 0.9707112970711297\n",
      "Epoch 156:\t train loss : 0.559931273959101; train accuracy : 0.9914126831686235; \n",
      " validation loss : 0.6347546979538885; validation accuracy : 0.9121338912133892\n",
      "Epoch 157:\t train loss : 0.558468959584198; train accuracy : 0.9928938319030949; \n",
      " validation loss : 0.601520677227801; validation accuracy : 0.9497907949790795\n",
      "Epoch 158:\t train loss : 0.5582676189836429; train accuracy : 0.9930855974472568; \n",
      " validation loss : 0.6027959288934376; validation accuracy : 0.9497907949790795\n",
      "Epoch 159:\t train loss : 0.5635912121632998; train accuracy : 0.9875188202856346; \n",
      " validation loss : 0.6042158779241935; validation accuracy : 0.9456066945606695\n",
      "Epoch 160:\t train loss : 0.5576562865101965; train accuracy : 0.9936646116670281; \n",
      " validation loss : 0.5981878141862566; validation accuracy : 0.9497907949790795\n",
      "Epoch 161:\t train loss : 0.5555597842942985; train accuracy : 0.9957904519966542; \n",
      " validation loss : 0.588499380292309; validation accuracy : 0.9623430962343096\n",
      "Epoch 162:\t train loss : 0.558576646861645; train accuracy : 0.9926208990365253; \n",
      " validation loss : 0.5892066236549592; validation accuracy : 0.9623430962343096\n",
      "Epoch 163:\t train loss : 0.5578242916627446; train accuracy : 0.9936026518789306; \n",
      " validation loss : 0.5734395726276977; validation accuracy : 0.9790794979079498\n",
      "Epoch 164:\t train loss : 0.557348166863994; train accuracy : 0.994117537718021; \n",
      " validation loss : 0.597576905580917; validation accuracy : 0.9539748953974896\n",
      "Epoch 165:\t train loss : 0.5567683163941594; train accuracy : 0.9946191022026705; \n",
      " validation loss : 0.5978095773354535; validation accuracy : 0.9539748953974896\n",
      "Epoch 166:\t train loss : 0.5588703356737195; train accuracy : 0.9924718857461508; \n",
      " validation loss : 0.594089909543107; validation accuracy : 0.9581589958158996\n",
      "Epoch 167:\t train loss : 0.5586735677143579; train accuracy : 0.9927042349515165; \n",
      " validation loss : 0.6069523326375414; validation accuracy : 0.9456066945606695\n",
      "Epoch 168:\t train loss : 0.557054907581313; train accuracy : 0.9943461693361009; \n",
      " validation loss : 0.588256000385766; validation accuracy : 0.9623430962343096\n",
      "Epoch 169:\t train loss : 0.5564995812867687; train accuracy : 0.9948300752811425; \n",
      " validation loss : 0.6019992003806021; validation accuracy : 0.9497907949790795\n",
      "Epoch 170:\t train loss : 0.5556236905145543; train accuracy : 0.9957712444623439; \n",
      " validation loss : 0.5766434934728211; validation accuracy : 0.9748953974895398\n",
      "Epoch 171:\t train loss : 0.5599263593972885; train accuracy : 0.9913720995074197; \n",
      " validation loss : 0.5890714001705244; validation accuracy : 0.9623430962343096\n",
      "Epoch 172:\t train loss : 0.5579597037375801; train accuracy : 0.9933334365996468; \n",
      " validation loss : 0.5848413533719921; validation accuracy : 0.9623430962343096\n",
      "Epoch 173:\t train loss : 0.557036315256155; train accuracy : 0.9943093032621828; \n",
      " validation loss : 0.6117554287992585; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174:\t train loss : 0.5564477998428458; train accuracy : 0.9948883174819542; \n",
      " validation loss : 0.5974698347410929; validation accuracy : 0.9539748953974896\n",
      "Epoch 175:\t train loss : 0.5553171632417544; train accuracy : 0.9960500635087828; \n",
      " validation loss : 0.5817565832775179; validation accuracy : 0.9665271966527197\n",
      "Epoch 176:\t train loss : 0.5567115890376388; train accuracy : 0.9946500820967192; \n",
      " validation loss : 0.5805169467206045; validation accuracy : 0.9707112970711297\n",
      "Epoch 177:\t train loss : 0.5550460859609248; train accuracy : 0.9963384863223768; \n",
      " validation loss : 0.574742974149617; validation accuracy : 0.9790794979079498\n",
      "Epoch 178:\t train loss : 0.5547418583082209; train accuracy : 0.9967161312308311; \n",
      " validation loss : 0.5747124456826216; validation accuracy : 0.9790794979079498\n",
      "Epoch 179:\t train loss : 0.5546611493812725; train accuracy : 0.9967006412838068; \n",
      " validation loss : 0.5900979485443032; validation accuracy : 0.9623430962343096\n",
      "Epoch 180:\t train loss : 0.5569043239092594; train accuracy : 0.9944642027324266; \n",
      " validation loss : 0.5934859621509256; validation accuracy : 0.9581589958158996\n",
      "Epoch 181:\t train loss : 0.5580365070248672; train accuracy : 0.9932655906316801; \n",
      " validation loss : 0.5835426097187172; validation accuracy : 0.9665271966527197\n",
      "Epoch 182:\t train loss : 0.5561105259070129; train accuracy : 0.9951767402955481; \n",
      " validation loss : 0.5978340785503116; validation accuracy : 0.9539748953974896\n",
      "Epoch 183:\t train loss : 0.5580397610280909; train accuracy : 0.9933393227795161; \n",
      " validation loss : 0.5999200363662986; validation accuracy : 0.9497907949790795\n",
      "Epoch 184:\t train loss : 0.558777464445086; train accuracy : 0.9924814895133058; \n",
      " validation loss : 0.5998228416267172; validation accuracy : 0.9497907949790795\n",
      "Epoch 185:\t train loss : 0.5573569244217327; train accuracy : 0.9940304842157439; \n",
      " validation loss : 0.5731380216990292; validation accuracy : 0.9790794979079498\n",
      "Epoch 186:\t train loss : 0.5561626886458457; train accuracy : 0.9952290963164906; \n",
      " validation loss : 0.5684196648283146; validation accuracy : 0.9832635983263598\n",
      "Epoch 187:\t train loss : 0.5567502660574781; train accuracy : 0.9945571424145729; \n",
      " validation loss : 0.5866311229249929; validation accuracy : 0.9665271966527197\n",
      "Epoch 188:\t train loss : 0.5787350180346901; train accuracy : 0.9724316118838874; \n",
      " validation loss : 0.6116011781962342; validation accuracy : 0.9372384937238494\n",
      "Epoch 189:\t train loss : 0.564237026868288; train accuracy : 0.9868180550822516; \n",
      " validation loss : 0.573260283998749; validation accuracy : 0.9790794979079498\n",
      "Epoch 190:\t train loss : 0.5551547067042717; train accuracy : 0.9961894730320022; \n",
      " validation loss : 0.5849306565634987; validation accuracy : 0.9665271966527197\n",
      "Epoch 191:\t train loss : 0.5545810822114409; train accuracy : 0.9968090709129774; \n",
      " validation loss : 0.5809146426015004; validation accuracy : 0.9707112970711297\n",
      "Epoch 192:\t train loss : 0.5551127660713027; train accuracy : 0.9962765265342792; \n",
      " validation loss : 0.5845259561595472; validation accuracy : 0.9665271966527197\n",
      "Epoch 193:\t train loss : 0.5664175249498626; train accuracy : 0.9846782738003036; \n",
      " validation loss : 0.6126791576609214; validation accuracy : 0.9372384937238494\n",
      "Epoch 194:\t train loss : 0.5634916196642815; train accuracy : 0.9877607732581555; \n",
      " validation loss : 0.6201294665332628; validation accuracy : 0.9288702928870293\n",
      "Epoch 195:\t train loss : 0.5579877249485586; train accuracy : 0.9934322624616624; \n",
      " validation loss : 0.5934688638767818; validation accuracy : 0.9581589958158996\n",
      "Epoch 196:\t train loss : 0.5572117462674495; train accuracy : 0.9941079339508658; \n",
      " validation loss : 0.592484332032036; validation accuracy : 0.9581589958158996\n",
      "Epoch 197:\t train loss : 0.5562512582107341; train accuracy : 0.9951206666873199; \n",
      " validation loss : 0.5850001951271413; validation accuracy : 0.9665271966527197\n",
      "Epoch 198:\t train loss : 0.5595173922450253; train accuracy : 0.9918154217912575; \n",
      " validation loss : 0.5818001116432693; validation accuracy : 0.9707112970711297\n",
      "Epoch 199:\t train loss : 0.5567032556756115; train accuracy : 0.9946847795780538; \n",
      " validation loss : 0.5843231127789796; validation accuracy : 0.9665271966527197\n",
      "Epoch 200:\t train loss : 0.5558419108718022; train accuracy : 0.9954710492890114; \n",
      " validation loss : 0.587115359718312; validation accuracy : 0.9623430962343096\n",
      "Epoch 201:\t train loss : 0.559598164367114; train accuracy : 0.9917011059822175; \n",
      " validation loss : 0.5971630233166245; validation accuracy : 0.9539748953974896\n",
      "Epoch 202:\t train loss : 0.5633484739560325; train accuracy : 0.9880048948232597; \n",
      " validation loss : 0.6014498437504278; validation accuracy : 0.9497907949790795\n",
      "Epoch 203:\t train loss : 0.557187211501538; train accuracy : 0.9941698937389634; \n",
      " validation loss : 0.5860040853782065; validation accuracy : 0.9665271966527197\n",
      "Epoch 204:\t train loss : 0.5561870107506297; train accuracy : 0.9952541900306701; \n",
      " validation loss : 0.6072748168890081; validation accuracy : 0.9414225941422594\n",
      "Epoch 205:\t train loss : 0.555971017974533; train accuracy : 0.995331639765792; \n",
      " validation loss : 0.5848890390947646; validation accuracy : 0.9665271966527197\n",
      "Epoch 206:\t train loss : 0.5552462872946216; train accuracy : 0.9961894730320022; \n",
      " validation loss : 0.58893617349289; validation accuracy : 0.9623430962343096\n",
      "Epoch 207:\t train loss : 0.5567193616077765; train accuracy : 0.9946191022026705; \n",
      " validation loss : 0.5995383118388786; validation accuracy : 0.9497907949790795\n",
      "Epoch 208:\t train loss : 0.5561867294747943; train accuracy : 0.9951457604014994; \n",
      " validation loss : 0.595973136030061; validation accuracy : 0.9539748953974896\n",
      "Epoch 209:\t train loss : 0.557341777511433; train accuracy : 0.9939530344806221; \n",
      " validation loss : 0.5934057602076898; validation accuracy : 0.9581589958158996\n",
      "Epoch 210:\t train loss : 0.5638033663186451; train accuracy : 0.9875594039468385; \n",
      " validation loss : 0.5902888403236161; validation accuracy : 0.9623430962343096\n",
      "Epoch 211:\t train loss : 0.5577064273809398; train accuracy : 0.993618141825955; \n",
      " validation loss : 0.565929807949016; validation accuracy : 0.9874476987447699\n",
      "Epoch 212:\t train loss : 0.5569757398221832; train accuracy : 0.9943771492301496; \n",
      " validation loss : 0.5804767502774109; validation accuracy : 0.9707112970711297\n",
      "Epoch 213:\t train loss : 0.5551272212537601; train accuracy : 0.9962514328200998; \n",
      " validation loss : 0.593784877855824; validation accuracy : 0.9581589958158996\n",
      "Epoch 214:\t train loss : 0.5562451424098968; train accuracy : 0.9951494779887853; \n",
      " validation loss : 0.584956868860898; validation accuracy : 0.9623430962343096\n",
      "Epoch 215:\t train loss : 0.556821445361854; train accuracy : 0.9945475386474179; \n",
      " validation loss : 0.5846072541093714; validation accuracy : 0.9665271966527197\n",
      "Epoch 216:\t train loss : 0.5551023019338396; train accuracy : 0.9962669227671241; \n",
      " validation loss : 0.5886914934429057; validation accuracy : 0.9623430962343096\n",
      "Epoch 217:\t train loss : 0.5607373597283445; train accuracy : 0.9906750518913225; \n",
      " validation loss : 0.5789115874746205; validation accuracy : 0.9707112970711297\n",
      "Epoch 218:\t train loss : 0.5571950857628785; train accuracy : 0.9940924440038414; \n",
      " validation loss : 0.5928184116840335; validation accuracy : 0.9581589958158996\n",
      "Epoch 219:\t train loss : 0.5566685487067861; train accuracy : 0.9947002695250782; \n",
      " validation loss : 0.5920476021506437; validation accuracy : 0.9581589958158996\n",
      "Epoch 220:\t train loss : 0.5589393533162544; train accuracy : 0.9923634561169801; \n",
      " validation loss : 0.5859792734541857; validation accuracy : 0.9665271966527197\n",
      "Epoch 221:\t train loss : 0.5551817118589342; train accuracy : 0.9961739830849778; \n",
      " validation loss : 0.5826819620138722; validation accuracy : 0.9665271966527197\n",
      "Epoch 222:\t train loss : 0.5564869314352697; train accuracy : 0.9948979212491094; \n",
      " validation loss : 0.5875580926245692; validation accuracy : 0.9623430962343096\n",
      "Epoch 223:\t train loss : 0.5578557346661566; train accuracy : 0.9935871619319062; \n",
      " validation loss : 0.5935704318479258; validation accuracy : 0.9581589958158996\n",
      "Epoch 224:\t train loss : 0.556396446294613; train accuracy : 0.9949598810372069; \n",
      " validation loss : 0.5946180157355387; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225:\t train loss : 0.557480704997429; train accuracy : 0.9938814709253694; \n",
      " validation loss : 0.5950813074190714; validation accuracy : 0.9581589958158996\n",
      "Epoch 226:\t train loss : 0.5575940855613736; train accuracy : 0.9938446048514514; \n",
      " validation loss : 0.585696039433195; validation accuracy : 0.9665271966527197\n",
      "Epoch 227:\t train loss : 0.5565052449586202; train accuracy : 0.9948728275349298; \n",
      " validation loss : 0.5867652263534965; validation accuracy : 0.9665271966527197\n",
      "Epoch 228:\t train loss : 0.5548673512218572; train accuracy : 0.9965649493478732; \n",
      " validation loss : 0.568217837860707; validation accuracy : 0.9832635983263598\n",
      "Epoch 229:\t train loss : 0.5588488921363921; train accuracy : 0.9924718857461508; \n",
      " validation loss : 0.5918121247551904; validation accuracy : 0.9623430962343096\n",
      "Epoch 230:\t train loss : 0.5546847787535671; train accuracy : 0.9967471111248799; \n",
      " validation loss : 0.5897334170326964; validation accuracy : 0.9623430962343096\n",
      "Epoch 231:\t train loss : 0.5545195831476724; train accuracy : 0.9968961244152544; \n",
      " validation loss : 0.5838904295283119; validation accuracy : 0.9665271966527197\n",
      "Epoch 232:\t train loss : 0.5553360017351888; train accuracy : 0.9960596672759379; \n",
      " validation loss : 0.5804044033673145; validation accuracy : 0.9707112970711297\n",
      "Epoch 233:\t train loss : 0.5562208785748565; train accuracy : 0.9952232101366213; \n",
      " validation loss : 0.5930789092572112; validation accuracy : 0.9581589958158996\n",
      "Epoch 234:\t train loss : 0.5562118323086388; train accuracy : 0.9951361566343443; \n",
      " validation loss : 0.6165100006729908; validation accuracy : 0.9330543933054394\n",
      "Epoch 235:\t train loss : 0.5550419163458314; train accuracy : 0.996307506428328; \n",
      " validation loss : 0.5765694874322295; validation accuracy : 0.9748953974895398\n",
      "Epoch 236:\t train loss : 0.5562169812249752; train accuracy : 0.9951147805074506; \n",
      " validation loss : 0.5978712880807623; validation accuracy : 0.9539748953974896\n",
      "Epoch 237:\t train loss : 0.5555003313428951; train accuracy : 0.9958641841444902; \n",
      " validation loss : 0.5949640952747444; validation accuracy : 0.9539748953974896\n",
      "Epoch 238:\t train loss : 0.5581851441770621; train accuracy : 0.9931763685368196; \n",
      " validation loss : 0.6508209754731652; validation accuracy : 0.899581589958159\n",
      "Epoch 239:\t train loss : 0.564548722733457; train accuracy : 0.9866727593791629; \n",
      " validation loss : 0.5681237399505329; validation accuracy : 0.9832635983263598\n",
      "Epoch 240:\t train loss : 0.5555802714585067; train accuracy : 0.9958118281235478; \n",
      " validation loss : 0.6020540806907143; validation accuracy : 0.9497907949790795\n",
      "Epoch 241:\t train loss : 0.5569987200653453; train accuracy : 0.9944177328913535; \n",
      " validation loss : 0.5907556689353355; validation accuracy : 0.9581589958158996\n",
      "Epoch 242:\t train loss : 0.5574343741966102; train accuracy : 0.993916168406704; \n",
      " validation loss : 0.5944064571106342; validation accuracy : 0.9581589958158996\n",
      "Epoch 243:\t train loss : 0.5574565394114707; train accuracy : 0.9939434307134669; \n",
      " validation loss : 0.6014538443828098; validation accuracy : 0.9497907949790795\n",
      "Epoch 244:\t train loss : 0.5557453710884097; train accuracy : 0.9956414387062796; \n",
      " validation loss : 0.5749721560061181; validation accuracy : 0.9748953974895398\n",
      "Epoch 245:\t train loss : 0.555084960140591; train accuracy : 0.9962979026611729; \n",
      " validation loss : 0.5764477295577745; validation accuracy : 0.9748953974895398\n",
      "Epoch 246:\t train loss : 0.5557077050943114; train accuracy : 0.9956724186003284; \n",
      " validation loss : 0.572363479299014; validation accuracy : 0.9790794979079498\n",
      "Epoch 247:\t train loss : 0.555768632795948; train accuracy : 0.9956259487592553; \n",
      " validation loss : 0.6016296642202618; validation accuracy : 0.9497907949790795\n",
      "Epoch 248:\t train loss : 0.5597751260204552; train accuracy : 0.991588958765761; \n",
      " validation loss : 0.6007191408332103; validation accuracy : 0.9497907949790795\n",
      "Epoch 249:\t train loss : 0.557861535131998; train accuracy : 0.993554013445274; \n",
      " validation loss : 0.5825782100958817; validation accuracy : 0.9665271966527197\n",
      "Epoch 250:\t train loss : 0.5600799932640622; train accuracy : 0.9912054276774374; \n",
      " validation loss : 0.6141022796570555; validation accuracy : 0.9372384937238494\n",
      "Epoch 251:\t train loss : 0.5579904466642455; train accuracy : 0.9934883360698906; \n",
      " validation loss : 0.5837714635059029; validation accuracy : 0.9665271966527197\n",
      "Epoch 252:\t train loss : 0.5700930441739899; train accuracy : 0.98111186839741; \n",
      " validation loss : 0.6028019219032034; validation accuracy : 0.9497907949790795\n",
      "Epoch 253:\t train loss : 0.5620502948482358; train accuracy : 0.989311936553177; \n",
      " validation loss : 0.5989748808886353; validation accuracy : 0.9539748953974896\n",
      "Epoch 254:\t train loss : 0.5569445298706853; train accuracy : 0.9944177328913535; \n",
      " validation loss : 0.5914760345559887; validation accuracy : 0.9623430962343096\n",
      "Epoch 255:\t train loss : 0.5579193317529703; train accuracy : 0.9935252021438087; \n",
      " validation loss : 0.5841181261929049; validation accuracy : 0.9623430962343096\n",
      "Epoch 256:\t train loss : 0.5592300499575124; train accuracy : 0.9921038446048515; \n",
      " validation loss : 0.5890936619157197; validation accuracy : 0.9623430962343096\n",
      "Epoch 257:\t train loss : 0.557486627543242; train accuracy : 0.9938040211902475; \n",
      " validation loss : 0.584922072085966; validation accuracy : 0.9665271966527197\n",
      "Epoch 258:\t train loss : 0.554771505067302; train accuracy : 0.9966231915486848; \n",
      " validation loss : 0.5849159038412378; validation accuracy : 0.9665271966527197\n",
      "Epoch 259:\t train loss : 0.5557559162833766; train accuracy : 0.995693794727222; \n",
      " validation loss : 0.5931150695766906; validation accuracy : 0.9581589958158996\n",
      "Epoch 260:\t train loss : 0.5562378921703417; train accuracy : 0.9951516465813687; \n",
      " validation loss : 0.587873070391665; validation accuracy : 0.9623430962343096\n",
      "Epoch 261:\t train loss : 0.5659024846174072; train accuracy : 0.98539390935283; \n",
      " validation loss : 0.6849769410452757; validation accuracy : 0.8661087866108786\n",
      "Early stopping at epoch 261\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5577064273809398; Train accuracy : 0.993618141825955; \n",
      " Validation loss : 0.565929807949016; Validation accuracy : 0.9874476987447699\n",
      "--- Let's train model 68 ! ---\n",
      "Epoch 1:\t train loss : 0.9313746399510594; train accuracy : 0.5962093001641935; \n",
      " validation loss : 0.8066976104857572; validation accuracy : 0.7364016736401674\n",
      "Epoch 2:\t train loss : 0.7548294475178271; train accuracy : 0.793966355835063; \n",
      " validation loss : 0.7527286107592137; validation accuracy : 0.7907949790794979\n",
      "Epoch 3:\t train loss : 0.6948885729363637; train accuracy : 0.8553706744322934; \n",
      " validation loss : 0.6941689728736467; validation accuracy : 0.8535564853556485\n",
      "Epoch 4:\t train loss : 0.6645253177073113; train accuracy : 0.8865990272313269; \n",
      " validation loss : 0.6642971329207634; validation accuracy : 0.8828451882845189\n",
      "Epoch 5:\t train loss : 0.644834650877913; train accuracy : 0.9059208773505995; \n",
      " validation loss : 0.6340273365138365; validation accuracy : 0.9205020920502092\n",
      "Epoch 6:\t train loss : 0.627658477143865; train accuracy : 0.9235970754980017; \n",
      " validation loss : 0.6531408433129628; validation accuracy : 0.9037656903765691\n",
      "Epoch 7:\t train loss : 0.6129454132461969; train accuracy : 0.9381229282195855; \n",
      " validation loss : 0.6212872866760664; validation accuracy : 0.9205020920502092\n",
      "Epoch 8:\t train loss : 0.6044171987605026; train accuracy : 0.946719848818117; \n",
      " validation loss : 0.637780996925826; validation accuracy : 0.9163179916317992\n",
      "Epoch 9:\t train loss : 0.6045857187926418; train accuracy : 0.9463016202484588; \n",
      " validation loss : 0.6165881276330418; validation accuracy : 0.9330543933054394\n",
      "Epoch 10:\t train loss : 0.5953280846529743; train accuracy : 0.9562845813067319; \n",
      " validation loss : 0.6289244240876398; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.5979754682216628; train accuracy : 0.9528458130673193; \n",
      " validation loss : 0.6168793034410603; validation accuracy : 0.9288702928870293\n",
      "Epoch 12:\t train loss : 0.5977184851093998; train accuracy : 0.9534697481334614; \n",
      " validation loss : 0.6077486298677298; validation accuracy : 0.9414225941422594\n",
      "Epoch 13:\t train loss : 0.5870689806519737; train accuracy : 0.9639889711577186; \n",
      " validation loss : 0.6538880668439689; validation accuracy : 0.891213389121339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\t train loss : 0.5904759019200535; train accuracy : 0.9608466805043526; \n",
      " validation loss : 0.6446357150881856; validation accuracy : 0.9079497907949791\n",
      "Epoch 15:\t train loss : 0.5988957919526218; train accuracy : 0.9516915022150624; \n",
      " validation loss : 0.6337483998652497; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5947574840382166; train accuracy : 0.9561259642492023; \n",
      " validation loss : 0.6266044808481785; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.5895308695311458; train accuracy : 0.9617547011989219; \n",
      " validation loss : 0.6275314786423439; validation accuracy : 0.9246861924686193\n",
      "Epoch 18:\t train loss : 0.596318166608249; train accuracy : 0.9544316738436754; \n",
      " validation loss : 0.6322540822890056; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.5941663927472857; train accuracy : 0.956834784225038; \n",
      " validation loss : 0.6242591136849482; validation accuracy : 0.9205020920502092\n",
      "Epoch 20:\t train loss : 0.5873849836340397; train accuracy : 0.9637529043650671; \n",
      " validation loss : 0.6290407234320995; validation accuracy : 0.9205020920502092\n",
      "Epoch 21:\t train loss : 0.586406492148645; train accuracy : 0.964618172805849; \n",
      " validation loss : 0.6201621917159447; validation accuracy : 0.9288702928870293\n",
      "Epoch 22:\t train loss : 0.5795988617292729; train accuracy : 0.9716180798661669; \n",
      " validation loss : 0.6021444167634709; validation accuracy : 0.9497907949790795\n",
      "Epoch 23:\t train loss : 0.5807911158009516; train accuracy : 0.9703324142631432; \n",
      " validation loss : 0.6161961071079242; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5877302762753235; train accuracy : 0.9633929179962204; \n",
      " validation loss : 0.6041369841696655; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5862814591952649; train accuracy : 0.964769354688807; \n",
      " validation loss : 0.596302820506806; validation accuracy : 0.9497907949790795\n",
      "Epoch 26:\t train loss : 0.5857971131485081; train accuracy : 0.9653350475541373; \n",
      " validation loss : 0.6063615436270275; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5803313464053248; train accuracy : 0.9708863347687351; \n",
      " validation loss : 0.6087423833055277; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.57599407207602; train accuracy : 0.9750974317667833; \n",
      " validation loss : 0.5969258098297955; validation accuracy : 0.9539748953974896\n",
      "Epoch 29:\t train loss : 0.5807401899293444; train accuracy : 0.9703922054586573; \n",
      " validation loss : 0.6030167109334692; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5811363310850606; train accuracy : 0.970189287152638; \n",
      " validation loss : 0.6197919235323542; validation accuracy : 0.9288702928870293\n",
      "Epoch 31:\t train loss : 0.5774415080020752; train accuracy : 0.9736317729793365; \n",
      " validation loss : 0.6043034579493485; validation accuracy : 0.9456066945606695\n",
      "Epoch 32:\t train loss : 0.5881284746680029; train accuracy : 0.9628197899563183; \n",
      " validation loss : 0.6086722768591541; validation accuracy : 0.9414225941422594\n",
      "Epoch 33:\t train loss : 0.5765502636716325; train accuracy : 0.9746327333560519; \n",
      " validation loss : 0.6142751795972788; validation accuracy : 0.9330543933054394\n",
      "Epoch 34:\t train loss : 0.5793228098791433; train accuracy : 0.9716970785959912; \n",
      " validation loss : 0.6216912379657021; validation accuracy : 0.9246861924686193\n",
      "Epoch 35:\t train loss : 0.5758682969619677; train accuracy : 0.9754462653737724; \n",
      " validation loss : 0.5979961373367839; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5765730823879276; train accuracy : 0.9746407881285046; \n",
      " validation loss : 0.6170922075466532; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5815228129374833; train accuracy : 0.9696722327209641; \n",
      " validation loss : 0.6232023840416747; validation accuracy : 0.9246861924686193\n",
      "Epoch 38:\t train loss : 0.5782472712502511; train accuracy : 0.9731980544626537; \n",
      " validation loss : 0.6111983523187005; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5753859469973073; train accuracy : 0.9759611512128629; \n",
      " validation loss : 0.6172134262161745; validation accuracy : 0.9330543933054394\n",
      "Epoch 40:\t train loss : 0.572980120450116; train accuracy : 0.9780405217014158; \n",
      " validation loss : 0.6116421426936127; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5751429208446902; train accuracy : 0.9759825273397565; \n",
      " validation loss : 0.5996080405453453; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5737667446515005; train accuracy : 0.9774519037144893; \n",
      " validation loss : 0.6061230464548922; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5724512551457237; train accuracy : 0.9785250472443384; \n",
      " validation loss : 0.6155084068540564; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5712936720521822; train accuracy : 0.9797118869853465; \n",
      " validation loss : 0.5978226832598965; validation accuracy : 0.9581589958158996\n",
      "Epoch 45:\t train loss : 0.5734028151841798; train accuracy : 0.9775058087301342; \n",
      " validation loss : 0.6091152971493626; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5712618628812258; train accuracy : 0.9798646178630069; \n",
      " validation loss : 0.6056013821502972; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5706206665058302; train accuracy : 0.9807224511292172; \n",
      " validation loss : 0.610521138201216; validation accuracy : 0.9372384937238494\n",
      "Epoch 48:\t train loss : 0.5728118066508944; train accuracy : 0.9785405371913628; \n",
      " validation loss : 0.603220338610225; validation accuracy : 0.9456066945606695\n",
      "Epoch 49:\t train loss : 0.5733762916728511; train accuracy : 0.9777424951206667; \n",
      " validation loss : 0.6030831187388226; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5699500339282777; train accuracy : 0.9811657734130549; \n",
      " validation loss : 0.6265212246894962; validation accuracy : 0.9246861924686193\n",
      "Epoch 51:\t train loss : 0.5754783630748197; train accuracy : 0.9756070510238855; \n",
      " validation loss : 0.6067111424703704; validation accuracy : 0.9456066945606695\n",
      "Epoch 52:\t train loss : 0.5763675626395065; train accuracy : 0.9743886117909477; \n",
      " validation loss : 0.6612913684907956; validation accuracy : 0.8870292887029289\n",
      "Epoch 53:\t train loss : 0.5911351504874733; train accuracy : 0.9593714179497506; \n",
      " validation loss : 0.6172666303458194; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5700447418295316; train accuracy : 0.9812549955079154; \n",
      " validation loss : 0.6091032311377823; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5688983478345007; train accuracy : 0.982463211375817; \n",
      " validation loss : 0.6230868195708785; validation accuracy : 0.9330543933054394\n",
      "Epoch 56:\t train loss : 0.5720883902082753; train accuracy : 0.9788754298460299; \n",
      " validation loss : 0.6030323823439955; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.565491690269303; train accuracy : 0.9858459060070015; \n",
      " validation loss : 0.602060225725629; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5650611995431715; train accuracy : 0.9861866848415378; \n",
      " validation loss : 0.5903736277019169; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5658626039180829; train accuracy : 0.9854623749186778; \n",
      " validation loss : 0.5919234272917157; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5678646852536481; train accuracy : 0.9835592800272623; \n",
      " validation loss : 0.6074169664971887; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5640370573548931; train accuracy : 0.9873174509743177; \n",
      " validation loss : 0.6257410147326983; validation accuracy : 0.9246861924686193\n",
      "Epoch 62:\t train loss : 0.5702178787790377; train accuracy : 0.9807689209702903; \n",
      " validation loss : 0.6149044052826158; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5658982245709089; train accuracy : 0.98538120759627; \n",
      " validation loss : 0.6173363493687681; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.5674523646573943; train accuracy : 0.9837488769788407; \n",
      " validation loss : 0.5896391956948503; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:\t train loss : 0.5667645171987823; train accuracy : 0.9843957371665789; \n",
      " validation loss : 0.6009740898316686; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5638762820329358; train accuracy : 0.9872474364137674; \n",
      " validation loss : 0.6182066883495498; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5725105564918237; train accuracy : 0.9786275906936398; \n",
      " validation loss : 0.6036763526407167; validation accuracy : 0.9497907949790795\n",
      "Epoch 68:\t train loss : 0.5777830327857514; train accuracy : 0.9731729607484743; \n",
      " validation loss : 0.5998940587263881; validation accuracy : 0.9539748953974896\n",
      "Epoch 69:\t train loss : 0.5640432185466099; train accuracy : 0.9872105703398495; \n",
      " validation loss : 0.6037867719915796; validation accuracy : 0.9456066945606695\n",
      "Epoch 70:\t train loss : 0.5651108965596823; train accuracy : 0.9862058923758481; \n",
      " validation loss : 0.5886340091259847; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5778082165483276; train accuracy : 0.9732098268223922; \n",
      " validation loss : 0.6304513614446491; validation accuracy : 0.9205020920502092\n",
      "Epoch 72:\t train loss : 0.5680956361431845; train accuracy : 0.983104185383686; \n",
      " validation loss : 0.6191789331907023; validation accuracy : 0.9330543933054394\n",
      "Epoch 73:\t train loss : 0.5684475337221341; train accuracy : 0.9827959354379008; \n",
      " validation loss : 0.6274745874636538; validation accuracy : 0.9246861924686193\n",
      "Epoch 74:\t train loss : 0.5690650230350214; train accuracy : 0.9822714458316553; \n",
      " validation loss : 0.5945073622042697; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.5653420479370435; train accuracy : 0.9858517921868707; \n",
      " validation loss : 0.5927447443418791; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5656335316410889; train accuracy : 0.985582576907587; \n",
      " validation loss : 0.5930144402754286; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5658367152401851; train accuracy : 0.9854100188977354; \n",
      " validation loss : 0.5977978918014057; validation accuracy : 0.9539748953974896\n",
      "Epoch 78:\t train loss : 0.568303351954375; train accuracy : 0.9828349701044022; \n",
      " validation loss : 0.6082558829361469; validation accuracy : 0.9414225941422594\n",
      "Epoch 79:\t train loss : 0.5655180765171729; train accuracy : 0.9858149261129527; \n",
      " validation loss : 0.5963636949562673; validation accuracy : 0.9539748953974896\n",
      "Epoch 80:\t train loss : 0.5625413721542747; train accuracy : 0.9887831097617646; \n",
      " validation loss : 0.6122205737349895; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.5625982137750004; train accuracy : 0.9886901700796183; \n",
      " validation loss : 0.5935116296549252; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5622082546460085; train accuracy : 0.9890774187552278; \n",
      " validation loss : 0.5987925706678923; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5606818912570543; train accuracy : 0.9907717091607546; \n",
      " validation loss : 0.6062380107428859; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.564481760232743; train accuracy : 0.9868003965426438; \n",
      " validation loss : 0.6367334366457014; validation accuracy : 0.9163179916317992\n",
      "Epoch 85:\t train loss : 0.564622628594634; train accuracy : 0.9865739335171474; \n",
      " validation loss : 0.6008818143491845; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5652494114399346; train accuracy : 0.9859019796152297; \n",
      " validation loss : 0.6144656656307943; validation accuracy : 0.9372384937238494\n",
      "Epoch 87:\t train loss : 0.5681285854372169; train accuracy : 0.982953003500728; \n",
      " validation loss : 0.5984784880777058; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5646080383872972; train accuracy : 0.9866241209455063; \n",
      " validation loss : 0.5819441251832989; validation accuracy : 0.9707112970711297\n",
      "Epoch 89:\t train loss : 0.5675732261952354; train accuracy : 0.9836227888100623; \n",
      " validation loss : 0.6025593121068753; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5628543109334566; train accuracy : 0.988386257319; \n",
      " validation loss : 0.5983299123382922; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5644900947920262; train accuracy : 0.9866609870194244; \n",
      " validation loss : 0.5894200486331316; validation accuracy : 0.9623430962343096\n",
      "Epoch 92:\t train loss : 0.5618520577393121; train accuracy : 0.9894395737166579; \n",
      " validation loss : 0.5955569352089473; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5613268994853395; train accuracy : 0.9900281917035844; \n",
      " validation loss : 0.5927827894124135; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5619823011488919; train accuracy : 0.9892434709873292; \n",
      " validation loss : 0.6257086018038098; validation accuracy : 0.9205020920502092\n",
      "Epoch 95:\t train loss : 0.567863330421655; train accuracy : 0.9834604541652467; \n",
      " validation loss : 0.5995464358408803; validation accuracy : 0.9456066945606695\n",
      "Epoch 96:\t train loss : 0.5634722363936367; train accuracy : 0.9878286192261222; \n",
      " validation loss : 0.6063509186071332; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.5613536039083604; train accuracy : 0.9899544595557483; \n",
      " validation loss : 0.5899887559430735; validation accuracy : 0.9623430962343096\n",
      "Epoch 98:\t train loss : 0.5615992216779072; train accuracy : 0.9897552588370148; \n",
      " validation loss : 0.5993282043813122; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5610025362705516; train accuracy : 0.9902022987081384; \n",
      " validation loss : 0.6092461556526111; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5629440423964389; train accuracy : 0.9882527339756498; \n",
      " validation loss : 0.5983522329108211; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.5603735521767726; train accuracy : 0.9910077759534063; \n",
      " validation loss : 0.5932742420139557; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.5657945179039199; train accuracy : 0.9855494284209548; \n",
      " validation loss : 0.6044034007828999; validation accuracy : 0.9456066945606695\n",
      "Epoch 103:\t train loss : 0.5595359216434164; train accuracy : 0.9918928715263794; \n",
      " validation loss : 0.5811492148654431; validation accuracy : 0.9707112970711297\n",
      "Epoch 104:\t train loss : 0.5586290430471031; train accuracy : 0.9927138387186716; \n",
      " validation loss : 0.5830162221163887; validation accuracy : 0.9665271966527197\n",
      "Epoch 105:\t train loss : 0.5591868950686336; train accuracy : 0.9921908981071285; \n",
      " validation loss : 0.6111358813694446; validation accuracy : 0.9372384937238494\n",
      "Epoch 106:\t train loss : 0.5676341700132251; train accuracy : 0.9835196257628799; \n",
      " validation loss : 0.6061751645883515; validation accuracy : 0.9456066945606695\n",
      "Epoch 107:\t train loss : 0.5685478745583931; train accuracy : 0.9828504600514266; \n",
      " validation loss : 0.5844041648425851; validation accuracy : 0.9665271966527197\n",
      "Epoch 108:\t train loss : 0.561417727945305; train accuracy : 0.9898887821803649; \n",
      " validation loss : 0.590346820751968; validation accuracy : 0.9623430962343096\n",
      "Epoch 109:\t train loss : 0.594435110558171; train accuracy : 0.9563391059202577; \n",
      " validation loss : 0.6089366610515629; validation accuracy : 0.9414225941422594\n",
      "Epoch 110:\t train loss : 0.571960425840921; train accuracy : 0.9792354162148765; \n",
      " validation loss : 0.601595764381772; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.567558221667752; train accuracy : 0.9837643669258651; \n",
      " validation loss : 0.6065047844164261; validation accuracy : 0.9414225941422594\n",
      "Epoch 112:\t train loss : 0.5653712475769662; train accuracy : 0.9859329595092785; \n",
      " validation loss : 0.6005404605863024; validation accuracy : 0.9497907949790795\n",
      "Epoch 113:\t train loss : 0.5617396797736601; train accuracy : 0.9895383995786734; \n",
      " validation loss : 0.5971369736877972; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5593192452997259; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.5965227505497993; validation accuracy : 0.9539748953974896\n",
      "Epoch 115:\t train loss : 0.560550724302252; train accuracy : 0.9907930852876483; \n",
      " validation loss : 0.6163681026951652; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116:\t train loss : 0.559477525408125; train accuracy : 0.991850119272592; \n",
      " validation loss : 0.6064371506967613; validation accuracy : 0.9456066945606695\n",
      "Epoch 117:\t train loss : 0.55932912867749; train accuracy : 0.9919858112085257; \n",
      " validation loss : 0.6126917494718398; validation accuracy : 0.9372384937238494\n",
      "Epoch 118:\t train loss : 0.5584798452973555; train accuracy : 0.9928628520090461; \n",
      " validation loss : 0.5934716092416422; validation accuracy : 0.9581589958158996\n",
      "Epoch 119:\t train loss : 0.5603651192432103; train accuracy : 0.9908956287369497; \n",
      " validation loss : 0.5937226782824064; validation accuracy : 0.9581589958158996\n",
      "Epoch 120:\t train loss : 0.5597908000887598; train accuracy : 0.9915093404380557; \n",
      " validation loss : 0.602612949753217; validation accuracy : 0.9497907949790795\n",
      "Epoch 121:\t train loss : 0.563884548571276; train accuracy : 0.9875129341057653; \n",
      " validation loss : 0.5931179644323605; validation accuracy : 0.9581589958158996\n",
      "Epoch 122:\t train loss : 0.5614675085907064; train accuracy : 0.9897434864772763; \n",
      " validation loss : 0.5948601844724456; validation accuracy : 0.9581589958158996\n",
      "Epoch 123:\t train loss : 0.56521402082975; train accuracy : 0.9860878589795223; \n",
      " validation loss : 0.625468264836653; validation accuracy : 0.9246861924686193\n",
      "Epoch 124:\t train loss : 0.5615075900211672; train accuracy : 0.989874841228043; \n",
      " validation loss : 0.5915522226818173; validation accuracy : 0.9581589958158996\n",
      "Epoch 125:\t train loss : 0.5598178780668074; train accuracy : 0.9915830725858917; \n",
      " validation loss : 0.5956401470331293; validation accuracy : 0.9581589958158996\n",
      "Epoch 126:\t train loss : 0.5628415028384427; train accuracy : 0.9884460485145141; \n",
      " validation loss : 0.617439183432464; validation accuracy : 0.9330543933054394\n",
      "Epoch 127:\t train loss : 0.5626902248732737; train accuracy : 0.9886127203444964; \n",
      " validation loss : 0.5807228043167207; validation accuracy : 0.9707112970711297\n",
      "Epoch 128:\t train loss : 0.5590788622977101; train accuracy : 0.9922683478422504; \n",
      " validation loss : 0.6166883765223244; validation accuracy : 0.9330543933054394\n",
      "Epoch 129:\t train loss : 0.562446895324148; train accuracy : 0.9888178072430992; \n",
      " validation loss : 0.6021529467959619; validation accuracy : 0.9456066945606695\n",
      "Epoch 130:\t train loss : 0.5674359982763006; train accuracy : 0.9836500511168251; \n",
      " validation loss : 0.6249157359128134; validation accuracy : 0.9246861924686193\n",
      "Epoch 131:\t train loss : 0.562321245265668; train accuracy : 0.9890966262895381; \n",
      " validation loss : 0.6033156929361944; validation accuracy : 0.9497907949790795\n",
      "Epoch 132:\t train loss : 0.5599043707313897; train accuracy : 0.9913817032745748; \n",
      " validation loss : 0.5975345491585915; validation accuracy : 0.9539748953974896\n",
      "Epoch 133:\t train loss : 0.5597020978291032; train accuracy : 0.9915366027448186; \n",
      " validation loss : 0.5927455381752034; validation accuracy : 0.9581589958158996\n",
      "Epoch 134:\t train loss : 0.5618477098179089; train accuracy : 0.9893466340345116; \n",
      " validation loss : 0.6118590475320976; validation accuracy : 0.9372384937238494\n",
      "Epoch 135:\t train loss : 0.5709171348279077; train accuracy : 0.9800504972272995; \n",
      " validation loss : 0.6234718057254982; validation accuracy : 0.9246861924686193\n",
      "Epoch 136:\t train loss : 0.568059954632432; train accuracy : 0.9831757489389387; \n",
      " validation loss : 0.5892475617598527; validation accuracy : 0.9623430962343096\n",
      "Epoch 137:\t train loss : 0.5617200442365095; train accuracy : 0.9895015335047554; \n",
      " validation loss : 0.5863395153794863; validation accuracy : 0.9665271966527197\n",
      "Epoch 138:\t train loss : 0.5631685114642622; train accuracy : 0.9879931224635212; \n",
      " validation loss : 0.5949959177277679; validation accuracy : 0.9539748953974896\n",
      "Epoch 139:\t train loss : 0.5611086563797502; train accuracy : 0.9901425075126243; \n",
      " validation loss : 0.6119693905457276; validation accuracy : 0.9414225941422594\n",
      "Epoch 140:\t train loss : 0.5691520722705582; train accuracy : 0.9821069425942563; \n",
      " validation loss : 0.5973879406662327; validation accuracy : 0.9539748953974896\n",
      "Epoch 141:\t train loss : 0.5658829463488662; train accuracy : 0.985344341522352; \n",
      " validation loss : 0.601168382600551; validation accuracy : 0.9497907949790795\n",
      "Epoch 142:\t train loss : 0.5600833570527062; train accuracy : 0.9912422937513554; \n",
      " validation loss : 0.60152291355559; validation accuracy : 0.9497907949790795\n",
      "Epoch 143:\t train loss : 0.5581617322346737; train accuracy : 0.9931977446637132; \n",
      " validation loss : 0.5924934741568507; validation accuracy : 0.9581589958158996\n",
      "Epoch 144:\t train loss : 0.5587623871251879; train accuracy : 0.9925626568357137; \n",
      " validation loss : 0.5980028273177553; validation accuracy : 0.9539748953974896\n",
      "Epoch 145:\t train loss : 0.559554825823864; train accuracy : 0.9917748381300536; \n",
      " validation loss : 0.60421887573523; validation accuracy : 0.9456066945606695\n",
      "Epoch 146:\t train loss : 0.5579198520017377; train accuracy : 0.9934824498900213; \n",
      " validation loss : 0.5971566649699587; validation accuracy : 0.9539748953974896\n",
      "Epoch 147:\t train loss : 0.5582934662633472; train accuracy : 0.9930701075002324; \n",
      " validation loss : 0.6113134950702288; validation accuracy : 0.9372384937238494\n",
      "Epoch 148:\t train loss : 0.5603964830860428; train accuracy : 0.9908919111496639; \n",
      " validation loss : 0.6065444769434007; validation accuracy : 0.9456066945606695\n",
      "Epoch 149:\t train loss : 0.5612358810266491; train accuracy : 0.990039964063323; \n",
      " validation loss : 0.6103627828307703; validation accuracy : 0.9414225941422594\n",
      "Epoch 150:\t train loss : 0.567638374196239; train accuracy : 0.9835283001332136; \n",
      " validation loss : 0.5934134754377012; validation accuracy : 0.9581589958158996\n",
      "Epoch 151:\t train loss : 0.5615456259359962; train accuracy : 0.9898887821803649; \n",
      " validation loss : 0.5932829428654547; validation accuracy : 0.9581589958158996\n",
      "Epoch 152:\t train loss : 0.5598077215859065; train accuracy : 0.9915366027448186; \n",
      " validation loss : 0.5974962667567405; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.5647646125211735; train accuracy : 0.9864382415812137; \n",
      " validation loss : 0.5975193028498184; validation accuracy : 0.9539748953974896\n",
      "Epoch 154:\t train loss : 0.5603174470061293; train accuracy : 0.9909634747049165; \n",
      " validation loss : 0.5919864174957937; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5595067922818149; train accuracy : 0.991927569007714; \n",
      " validation loss : 0.6017024170064261; validation accuracy : 0.9497907949790795\n",
      "Epoch 156:\t train loss : 0.559159346806869; train accuracy : 0.9921775767526875; \n",
      " validation loss : 0.5934826205924871; validation accuracy : 0.9581589958158996\n",
      "Epoch 157:\t train loss : 0.5572177715114878; train accuracy : 0.9940924440038414; \n",
      " validation loss : 0.6191796526473585; validation accuracy : 0.9330543933054394\n",
      "Epoch 158:\t train loss : 0.5577450630184737; train accuracy : 0.9937361752222807; \n",
      " validation loss : 0.6076703465250776; validation accuracy : 0.9414225941422594\n",
      "Epoch 159:\t train loss : 0.5615083715430386; train accuracy : 0.9897066204033582; \n",
      " validation loss : 0.591203544061054; validation accuracy : 0.9623430962343096\n",
      "Epoch 160:\t train loss : 0.5585846119063956; train accuracy : 0.9927699123268998; \n",
      " validation loss : 0.6009942489306705; validation accuracy : 0.9497907949790795\n",
      "Epoch 161:\t train loss : 0.5564870584338697; train accuracy : 0.9948263576938566; \n",
      " validation loss : 0.6000550716149192; validation accuracy : 0.9497907949790795\n",
      "Epoch 162:\t train loss : 0.5572952013288025; train accuracy : 0.9940769540568171; \n",
      " validation loss : 0.5810258918224889; validation accuracy : 0.9707112970711297\n",
      "Epoch 163:\t train loss : 0.5570858589232016; train accuracy : 0.9941698937389634; \n",
      " validation loss : 0.5977214639891366; validation accuracy : 0.9539748953974896\n",
      "Epoch 164:\t train loss : 0.5575780086466053; train accuracy : 0.9936683292543139; \n",
      " validation loss : 0.5963801967310557; validation accuracy : 0.9539748953974896\n",
      "Epoch 165:\t train loss : 0.5569969783319758; train accuracy : 0.994268719600979; \n",
      " validation loss : 0.5895020813856912; validation accuracy : 0.9623430962343096\n",
      "Epoch 166:\t train loss : 0.5574035157083244; train accuracy : 0.9938542086186065; \n",
      " validation loss : 0.5919854716947865; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167:\t train loss : 0.5606701965570635; train accuracy : 0.9905607360822826; \n",
      " validation loss : 0.5977860252216256; validation accuracy : 0.9539748953974896\n",
      "Epoch 168:\t train loss : 0.5611313144661059; train accuracy : 0.9901948635335667; \n",
      " validation loss : 0.6015251955313955; validation accuracy : 0.9497907949790795\n",
      "Epoch 169:\t train loss : 0.562225830555915; train accuracy : 0.989046438861179; \n",
      " validation loss : 0.587408395333719; validation accuracy : 0.9665271966527197\n",
      "Epoch 170:\t train loss : 0.5571135164838078; train accuracy : 0.9942569472412405; \n",
      " validation loss : 0.5968993870414578; validation accuracy : 0.9539748953974896\n",
      "Epoch 171:\t train loss : 0.5559422767109272; train accuracy : 0.9954629945165587; \n",
      " validation loss : 0.5970688408221864; validation accuracy : 0.9539748953974896\n",
      "Epoch 172:\t train loss : 0.5597235019675919; train accuracy : 0.9916081663000712; \n",
      " validation loss : 0.593417808673668; validation accuracy : 0.9581589958158996\n",
      "Epoch 173:\t train loss : 0.5581348923850117; train accuracy : 0.9933083428854673; \n",
      " validation loss : 0.5969903834571646; validation accuracy : 0.9539748953974896\n",
      "Epoch 174:\t train loss : 0.5622738033228831; train accuracy : 0.9888472381424456; \n",
      " validation loss : 0.6168805315420801; validation accuracy : 0.9330543933054394\n",
      "Epoch 175:\t train loss : 0.5596043939436856; train accuracy : 0.9916701260881687; \n",
      " validation loss : 0.6048654064973396; validation accuracy : 0.9456066945606695\n",
      "Epoch 176:\t train loss : 0.5565884168032292; train accuracy : 0.9947526255460206; \n",
      " validation loss : 0.5804176343420862; validation accuracy : 0.9707112970711297\n",
      "Epoch 177:\t train loss : 0.5570217042095965; train accuracy : 0.9943771492301496; \n",
      " validation loss : 0.5854647010621038; validation accuracy : 0.9665271966527197\n",
      "Epoch 178:\t train loss : 0.5553229244976025; train accuracy : 0.9960965333498559; \n",
      " validation loss : 0.5877883164255987; validation accuracy : 0.9623430962343096\n",
      "Epoch 179:\t train loss : 0.554996491138819; train accuracy : 0.9964506335388332; \n",
      " validation loss : 0.5889006434691563; validation accuracy : 0.9623430962343096\n",
      "Epoch 180:\t train loss : 0.5532039954438722; train accuracy : 0.9982496359862449; \n",
      " validation loss : 0.592746984992474; validation accuracy : 0.9581589958158996\n",
      "Epoch 181:\t train loss : 0.5559002467326654; train accuracy : 0.9953994857337588; \n",
      " validation loss : 0.5734902860152954; validation accuracy : 0.9790794979079498\n",
      "Epoch 182:\t train loss : 0.5575523991331258; train accuracy : 0.9938210601319744; \n",
      " validation loss : 0.5940028124082972; validation accuracy : 0.9581589958158996\n",
      "Epoch 183:\t train loss : 0.5663081339249204; train accuracy : 0.9848855292914899; \n",
      " validation loss : 0.6022888347498265; validation accuracy : 0.9497907949790795\n",
      "Epoch 184:\t train loss : 0.5559981407128104; train accuracy : 0.9953412435329471; \n",
      " validation loss : 0.5964322982696735; validation accuracy : 0.9539748953974896\n",
      "Epoch 185:\t train loss : 0.5582066415469937; train accuracy : 0.993091483627126; \n",
      " validation loss : 0.6058103770981021; validation accuracy : 0.9456066945606695\n",
      "Epoch 186:\t train loss : 0.5571274358675238; train accuracy : 0.9942938133151584; \n",
      " validation loss : 0.6010276915297784; validation accuracy : 0.9497907949790795\n",
      "Epoch 187:\t train loss : 0.5562505663778271; train accuracy : 0.9950587068992224; \n",
      " validation loss : 0.585799791118702; validation accuracy : 0.9665271966527197\n",
      "Epoch 188:\t train loss : 0.5685609297883296; train accuracy : 0.9826549769199789; \n",
      " validation loss : 0.6128064920054538; validation accuracy : 0.9372384937238494\n",
      "Epoch 189:\t train loss : 0.5597742946912668; train accuracy : 0.9915056228507698; \n",
      " validation loss : 0.6045413869703609; validation accuracy : 0.9456066945606695\n",
      "Epoch 190:\t train loss : 0.5566833163831415; train accuracy : 0.9946404783295641; \n",
      " validation loss : 0.5974913659337542; validation accuracy : 0.9539748953974896\n",
      "Epoch 191:\t train loss : 0.5593854499193746; train accuracy : 0.9918677778121999; \n",
      " validation loss : 0.5792534496171673; validation accuracy : 0.9707112970711297\n",
      "Epoch 192:\t train loss : 0.5556712503335185; train accuracy : 0.995693794727222; \n",
      " validation loss : 0.5817604957583278; validation accuracy : 0.9707112970711297\n",
      "Epoch 193:\t train loss : 0.554798958333054; train accuracy : 0.9965553455807181; \n",
      " validation loss : 0.6018404196721777; validation accuracy : 0.9497907949790795\n",
      "Epoch 194:\t train loss : 0.5551965374923228; train accuracy : 0.9961275132439047; \n",
      " validation loss : 0.6109420820133916; validation accuracy : 0.9372384937238494\n",
      "Epoch 195:\t train loss : 0.5544728354844413; train accuracy : 0.996921218129434; \n",
      " validation loss : 0.5850164013507487; validation accuracy : 0.9665271966527197\n",
      "Epoch 196:\t train loss : 0.557042734701504; train accuracy : 0.994392639177174; \n",
      " validation loss : 0.5899153564262288; validation accuracy : 0.9623430962343096\n",
      "Epoch 197:\t train loss : 0.5563235386679685; train accuracy : 0.9949967471111248; \n",
      " validation loss : 0.6058857992346023; validation accuracy : 0.9456066945606695\n",
      "Epoch 198:\t train loss : 0.55505528913189; train accuracy : 0.9964004461104743; \n",
      " validation loss : 0.610034342279236; validation accuracy : 0.9414225941422594\n",
      "Epoch 199:\t train loss : 0.5606566672257194; train accuracy : 0.9906573933517148; \n",
      " validation loss : 0.5866367142908051; validation accuracy : 0.9623430962343096\n",
      "Epoch 200:\t train loss : 0.5594663665339333; train accuracy : 0.9918213079711268; \n",
      " validation loss : 0.5943129031271316; validation accuracy : 0.9581589958158996\n",
      "Epoch 201:\t train loss : 0.5638115652169096; train accuracy : 0.9872709811332445; \n",
      " validation loss : 0.6347905659215602; validation accuracy : 0.9163179916317992\n",
      "Epoch 202:\t train loss : 0.5605536999622991; train accuracy : 0.9907060317853713; \n",
      " validation loss : 0.608466745936401; validation accuracy : 0.9414225941422594\n",
      "Epoch 203:\t train loss : 0.5558683432899546; train accuracy : 0.9954496731621177; \n",
      " validation loss : 0.622962395656022; validation accuracy : 0.9246861924686193\n",
      "Epoch 204:\t train loss : 0.5567769567219352; train accuracy : 0.994594008488491; \n",
      " validation loss : 0.5932108346983801; validation accuracy : 0.9581589958158996\n",
      "Epoch 205:\t train loss : 0.5559207460939498; train accuracy : 0.995445955574832; \n",
      " validation loss : 0.605296090722984; validation accuracy : 0.9456066945606695\n",
      "Epoch 206:\t train loss : 0.5557111701474671; train accuracy : 0.9956628148331732; \n",
      " validation loss : 0.602016781634685; validation accuracy : 0.9497907949790795\n",
      "Epoch 207:\t train loss : 0.5555571868825212; train accuracy : 0.9958332042504414; \n",
      " validation loss : 0.5720433452758045; validation accuracy : 0.9790794979079498\n",
      "Epoch 208:\t train loss : 0.556478818159298; train accuracy : 0.994841847640881; \n",
      " validation loss : 0.5891255801443845; validation accuracy : 0.9623430962343096\n",
      "Epoch 209:\t train loss : 0.5552881049289858; train accuracy : 0.9960500635087828; \n",
      " validation loss : 0.6024949130778502; validation accuracy : 0.9456066945606695\n",
      "Epoch 210:\t train loss : 0.5557461615409263; train accuracy : 0.9956473248861488; \n",
      " validation loss : 0.6093618484369768; validation accuracy : 0.9414225941422594\n",
      "Epoch 211:\t train loss : 0.5545571114799964; train accuracy : 0.9969020105951237; \n",
      " validation loss : 0.5912969949640706; validation accuracy : 0.9581589958158996\n",
      "Epoch 212:\t train loss : 0.5545459614622803; train accuracy : 0.996871030701075; \n",
      " validation loss : 0.598325269333115; validation accuracy : 0.9539748953974896\n",
      "Epoch 213:\t train loss : 0.5560661328087828; train accuracy : 0.9953043774590291; \n",
      " validation loss : 0.6020198506402067; validation accuracy : 0.9456066945606695\n",
      "Epoch 214:\t train loss : 0.5566388114132037; train accuracy : 0.9946655720437436; \n",
      " validation loss : 0.5894180493771874; validation accuracy : 0.9623430962343096\n",
      "Epoch 215:\t train loss : 0.5581898957070288; train accuracy : 0.9930797112673875; \n",
      " validation loss : 0.5970164080732313; validation accuracy : 0.9539748953974896\n",
      "Epoch 216:\t train loss : 0.5548662222519628; train accuracy : 0.9964624058985718; \n",
      " validation loss : 0.5932839828048991; validation accuracy : 0.9539748953974896\n",
      "Epoch 217:\t train loss : 0.5557750447785011; train accuracy : 0.9955949688652065; \n",
      " validation loss : 0.5930201875309347; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218:\t train loss : 0.5548905641991944; train accuracy : 0.9964682920784411; \n",
      " validation loss : 0.5892630283716962; validation accuracy : 0.9623430962343096\n",
      "Epoch 219:\t train loss : 0.5569628311518773; train accuracy : 0.9944545989652716; \n",
      " validation loss : 0.58439737409348; validation accuracy : 0.9665271966527197\n",
      "Epoch 220:\t train loss : 0.5557286877229544; train accuracy : 0.9956783047801976; \n",
      " validation loss : 0.5975833991132429; validation accuracy : 0.9497907949790795\n",
      "Epoch 221:\t train loss : 0.554575899385084; train accuracy : 0.9968031847331082; \n",
      " validation loss : 0.6139806064774149; validation accuracy : 0.9372384937238494\n",
      "Epoch 222:\t train loss : 0.5543498474703451; train accuracy : 0.9970104402242944; \n",
      " validation loss : 0.5862468401075579; validation accuracy : 0.9623430962343096\n",
      "Epoch 223:\t train loss : 0.5825611606306417; train accuracy : 0.9681542179125747; \n",
      " validation loss : 0.6074414530525375; validation accuracy : 0.9414225941422594\n",
      "Epoch 224:\t train loss : 0.5637821429693592; train accuracy : 0.9874317667833576; \n",
      " validation loss : 0.5972561874680623; validation accuracy : 0.9539748953974896\n",
      "Epoch 225:\t train loss : 0.5582741187525969; train accuracy : 0.9931475572353542; \n",
      " validation loss : 0.6113757258973317; validation accuracy : 0.9414225941422594\n",
      "Epoch 226:\t train loss : 0.5579152243436698; train accuracy : 0.9934477524086868; \n",
      " validation loss : 0.592047902224236; validation accuracy : 0.9581589958158996\n",
      "Epoch 227:\t train loss : 0.5569241983536163; train accuracy : 0.9943012484897301; \n",
      " validation loss : 0.6123533163254197; validation accuracy : 0.9372384937238494\n",
      "Epoch 228:\t train loss : 0.5622161972926688; train accuracy : 0.989036835094024; \n",
      " validation loss : 0.6006632421426439; validation accuracy : 0.9456066945606695\n",
      "Epoch 229:\t train loss : 0.5603102257381414; train accuracy : 0.9910173797205614; \n",
      " validation loss : 0.5970629605776042; validation accuracy : 0.9539748953974896\n",
      "Epoch 230:\t train loss : 0.5557904078773226; train accuracy : 0.9955543852040026; \n",
      " validation loss : 0.5831520249447285; validation accuracy : 0.9665271966527197\n",
      "Epoch 231:\t train loss : 0.5577057568996334; train accuracy : 0.9935657858050125; \n",
      " validation loss : 0.5944567458673355; validation accuracy : 0.9581589958158996\n",
      "Epoch 232:\t train loss : 0.5560486850563375; train accuracy : 0.9953161498187676; \n",
      " validation loss : 0.5795922232455688; validation accuracy : 0.9707112970711297\n",
      "Epoch 233:\t train loss : 0.5591914309349095; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.5940698634719758; validation accuracy : 0.9581589958158996\n",
      "Epoch 234:\t train loss : 0.5548970105787903; train accuracy : 0.9964992719724899; \n",
      " validation loss : 0.5850137696643689; validation accuracy : 0.9623430962343096\n",
      "Epoch 235:\t train loss : 0.5548846649697889; train accuracy : 0.996508875739645; \n",
      " validation loss : 0.5781652525433933; validation accuracy : 0.9748953974895398\n",
      "Epoch 236:\t train loss : 0.5550714252529544; train accuracy : 0.9963753523962948; \n",
      " validation loss : 0.6027154406148217; validation accuracy : 0.9456066945606695\n",
      "Epoch 237:\t train loss : 0.555898536397712; train accuracy : 0.9954924254159051; \n",
      " validation loss : 0.5841301794319318; validation accuracy : 0.9665271966527197\n",
      "Epoch 238:\t train loss : 0.5604952289786927; train accuracy : 0.9906669971188699; \n",
      " validation loss : 0.6038985113298777; validation accuracy : 0.9456066945606695\n",
      "Epoch 239:\t train loss : 0.5605334315204867; train accuracy : 0.9908705350227702; \n",
      " validation loss : 0.5883100816744904; validation accuracy : 0.9581589958158996\n",
      "Epoch 240:\t train loss : 0.5562104618476851; train accuracy : 0.9950063508782799; \n",
      " validation loss : 0.6010228024242993; validation accuracy : 0.9497907949790795\n",
      "Epoch 241:\t train loss : 0.5592264072806084; train accuracy : 0.9921407106787695; \n",
      " validation loss : 0.6010789136486182; validation accuracy : 0.9497907949790795\n",
      "Epoch 242:\t train loss : 0.5560282066317459; train accuracy : 0.9953530158926857; \n",
      " validation loss : 0.5872986521708801; validation accuracy : 0.9623430962343096\n",
      "Epoch 243:\t train loss : 0.5562520685608424; train accuracy : 0.9950587068992224; \n",
      " validation loss : 0.5849660850308169; validation accuracy : 0.9665271966527197\n",
      "Epoch 244:\t train loss : 0.5562454162375995; train accuracy : 0.9951516465813687; \n",
      " validation loss : 0.6015352725720511; validation accuracy : 0.9497907949790795\n",
      "Epoch 245:\t train loss : 0.5575340446939878; train accuracy : 0.9938018525976641; \n",
      " validation loss : 0.5991033007397781; validation accuracy : 0.9497907949790795\n",
      "Epoch 246:\t train loss : 0.5546262981326526; train accuracy : 0.9967722048390595; \n",
      " validation loss : 0.5959559842430739; validation accuracy : 0.9539748953974896\n",
      "Epoch 247:\t train loss : 0.5556389474783455; train accuracy : 0.9957712444623439; \n",
      " validation loss : 0.5755129254137213; validation accuracy : 0.9748953974895398\n",
      "Epoch 248:\t train loss : 0.5593012216154893; train accuracy : 0.9919607174943461; \n",
      " validation loss : 0.5934088720511483; validation accuracy : 0.9581589958158996\n",
      "Epoch 249:\t train loss : 0.5561335169082925; train accuracy : 0.9952387000836457; \n",
      " validation loss : 0.5855746314600732; validation accuracy : 0.9665271966527197\n",
      "Epoch 250:\t train loss : 0.5549821521700821; train accuracy : 0.9963908423433192; \n",
      " validation loss : 0.5807202146296698; validation accuracy : 0.9707112970711297\n",
      "Epoch 251:\t train loss : 0.5551382675729108; train accuracy : 0.9963443725022461; \n",
      " validation loss : 0.6019927281429625; validation accuracy : 0.9456066945606695\n",
      "Epoch 252:\t train loss : 0.5549953131198083; train accuracy : 0.9963288825552217; \n",
      " validation loss : 0.5895751477088143; validation accuracy : 0.9623430962343096\n",
      "Epoch 253:\t train loss : 0.5605555951321888; train accuracy : 0.9907215217323957; \n",
      " validation loss : 0.5962630589976661; validation accuracy : 0.9539748953974896\n",
      "Epoch 254:\t train loss : 0.5559533190097806; train accuracy : 0.995445955574832; \n",
      " validation loss : 0.5892370360690116; validation accuracy : 0.9623430962343096\n",
      "Epoch 255:\t train loss : 0.5606780807606446; train accuracy : 0.9905821122091762; \n",
      " validation loss : 0.5930451232458853; validation accuracy : 0.9581589958158996\n",
      "Epoch 256:\t train loss : 0.5557434076353919; train accuracy : 0.9957247746212707; \n",
      " validation loss : 0.5893371840459988; validation accuracy : 0.9623430962343096\n",
      "Epoch 257:\t train loss : 0.5564414091781253; train accuracy : 0.9948514514080362; \n",
      " validation loss : 0.5931425539859979; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 257\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5555571868825212; Train accuracy : 0.9958332042504414; \n",
      " Validation loss : 0.5720433452758045; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 69 ! ---\n",
      "Epoch 1:\t train loss : 0.9599519993245436; train accuracy : 0.5754047523157471; \n",
      " validation loss : 0.8503601567190437; validation accuracy : 0.6778242677824268\n",
      "Epoch 2:\t train loss : 0.7860873337811014; train accuracy : 0.760725549118622; \n",
      " validation loss : 0.7798738920246087; validation accuracy : 0.7531380753138075\n",
      "Epoch 3:\t train loss : 0.7133193092923763; train accuracy : 0.8369190495368506; \n",
      " validation loss : 0.7214746586520346; validation accuracy : 0.8158995815899581\n",
      "Epoch 4:\t train loss : 0.6818538485958742; train accuracy : 0.8683813005359522; \n",
      " validation loss : 0.6889359125886445; validation accuracy : 0.8661087866108786\n",
      "Epoch 5:\t train loss : 0.6618066020527383; train accuracy : 0.8887815607670622; \n",
      " validation loss : 0.6804421107336185; validation accuracy : 0.8702928870292888\n",
      "Epoch 6:\t train loss : 0.6431435682213618; train accuracy : 0.9076114501688404; \n",
      " validation loss : 0.6687696334950772; validation accuracy : 0.8828451882845189\n",
      "Epoch 7:\t train loss : 0.6321564634206439; train accuracy : 0.9186749899315344; \n",
      " validation loss : 0.6770136873974713; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6240408348999779; train accuracy : 0.9262111589578363; \n",
      " validation loss : 0.6651528226915295; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6152746818553677; train accuracy : 0.9357588525047245; \n",
      " validation loss : 0.6687519924933698; validation accuracy : 0.8870292887029289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\t train loss : 0.6088540191676737; train accuracy : 0.94236345611698; \n",
      " validation loss : 0.6385177087632408; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.6043343600032896; train accuracy : 0.9469020105951238; \n",
      " validation loss : 0.6606274388618152; validation accuracy : 0.8870292887029289\n",
      "Epoch 12:\t train loss : 0.5959140463638765; train accuracy : 0.9558146163140122; \n",
      " validation loss : 0.6571053105823578; validation accuracy : 0.8870292887029289\n",
      "Epoch 13:\t train loss : 0.6038135618138456; train accuracy : 0.9470996623191549; \n",
      " validation loss : 0.6380856661473862; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.595255309653044; train accuracy : 0.9557253942191518; \n",
      " validation loss : 0.638375009120193; validation accuracy : 0.9121338912133892\n",
      "Epoch 15:\t train loss : 0.5926339668111449; train accuracy : 0.9585327922178506; \n",
      " validation loss : 0.6505858154482638; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.6017259010303432; train accuracy : 0.949111186839741; \n",
      " validation loss : 0.6406716183444717; validation accuracy : 0.9037656903765691\n",
      "Epoch 17:\t train loss : 0.5859653476122142; train accuracy : 0.9652229003376809; \n",
      " validation loss : 0.6276831030091302; validation accuracy : 0.9163179916317992\n",
      "Epoch 18:\t train loss : 0.5846254530623476; train accuracy : 0.9664871898138109; \n",
      " validation loss : 0.6220548606458538; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.587799152002399; train accuracy : 0.9631937172774869; \n",
      " validation loss : 0.6565928582207818; validation accuracy : 0.8870292887029289\n",
      "Epoch 20:\t train loss : 0.5974150019308802; train accuracy : 0.9533281700176586; \n",
      " validation loss : 0.652316566022805; validation accuracy : 0.899581589958159\n",
      "Epoch 21:\t train loss : 0.5859485525305305; train accuracy : 0.9652036928033706; \n",
      " validation loss : 0.6396689755327775; validation accuracy : 0.9037656903765691\n",
      "Epoch 22:\t train loss : 0.584038946673761; train accuracy : 0.9670389417268193; \n",
      " validation loss : 0.6326258002189741; validation accuracy : 0.9163179916317992\n",
      "Epoch 23:\t train loss : 0.5783487498343894; train accuracy : 0.9728247467393661; \n",
      " validation loss : 0.605760535395961; validation accuracy : 0.9456066945606695\n",
      "Epoch 24:\t train loss : 0.5853110558240082; train accuracy : 0.9656972025155673; \n",
      " validation loss : 0.6248345822029431; validation accuracy : 0.9246861924686193\n",
      "Epoch 25:\t train loss : 0.5851659570478914; train accuracy : 0.9660150562285077; \n",
      " validation loss : 0.6352865551678618; validation accuracy : 0.9163179916317992\n",
      "Epoch 26:\t train loss : 0.5824891955313081; train accuracy : 0.9686344062703306; \n",
      " validation loss : 0.6522036755210998; validation accuracy : 0.895397489539749\n",
      "Epoch 27:\t train loss : 0.5869919831279798; train accuracy : 0.9639276309675021; \n",
      " validation loss : 0.6064772821244039; validation accuracy : 0.9456066945606695\n",
      "Epoch 28:\t train loss : 0.574612341179037; train accuracy : 0.9763660584280802; \n",
      " validation loss : 0.6303933144882208; validation accuracy : 0.9246861924686193\n",
      "Epoch 29:\t train loss : 0.572459924084544; train accuracy : 0.9789742557080455; \n",
      " validation loss : 0.6136248851224635; validation accuracy : 0.9330543933054394\n",
      "Epoch 30:\t train loss : 0.5783147094021697; train accuracy : 0.972892592707333; \n",
      " validation loss : 0.6088048766485556; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5714100151358359; train accuracy : 0.980176585396078; \n",
      " validation loss : 0.6443260451119474; validation accuracy : 0.899581589958159\n",
      "Epoch 32:\t train loss : 0.5728645394116824; train accuracy : 0.9780293689395583; \n",
      " validation loss : 0.6088519843722078; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.5661293077008218; train accuracy : 0.9853170792155891; \n",
      " validation loss : 0.6189409751406265; validation accuracy : 0.9330543933054394\n",
      "Epoch 34:\t train loss : 0.5703171527707905; train accuracy : 0.9808581430651507; \n",
      " validation loss : 0.6116954661029551; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.5753485497652819; train accuracy : 0.9758394002292512; \n",
      " validation loss : 0.6038527134100993; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.5693414569894188; train accuracy : 0.9818708758016048; \n",
      " validation loss : 0.6280908638695163; validation accuracy : 0.9246861924686193\n",
      "Epoch 37:\t train loss : 0.5689526029607515; train accuracy : 0.9822057684562718; \n",
      " validation loss : 0.6248330994388909; validation accuracy : 0.9246861924686193\n",
      "Epoch 38:\t train loss : 0.5798266241563605; train accuracy : 0.9713473155921807; \n",
      " validation loss : 0.6228451029926838; validation accuracy : 0.9246861924686193\n",
      "Epoch 39:\t train loss : 0.5707818328681817; train accuracy : 0.9805018742835899; \n",
      " validation loss : 0.6121915303525688; validation accuracy : 0.9330543933054394\n",
      "Epoch 40:\t train loss : 0.5751917987549826; train accuracy : 0.9760156758263887; \n",
      " validation loss : 0.6043913868767856; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5841768861647948; train accuracy : 0.9666132779825893; \n",
      " validation loss : 0.6392887265393984; validation accuracy : 0.9205020920502092\n",
      "Epoch 42:\t train loss : 0.5700212192841582; train accuracy : 0.9813383314229065; \n",
      " validation loss : 0.6144483751369848; validation accuracy : 0.9372384937238494\n",
      "Epoch 43:\t train loss : 0.5695856070397652; train accuracy : 0.9816385265962391; \n",
      " validation loss : 0.6287870329510727; validation accuracy : 0.9205020920502092\n",
      "Epoch 44:\t train loss : 0.5742367057601822; train accuracy : 0.9766544812416742; \n",
      " validation loss : 0.6204811021638886; validation accuracy : 0.9246861924686193\n",
      "Epoch 45:\t train loss : 0.5721059419079161; train accuracy : 0.9788946373803402; \n",
      " validation loss : 0.6463058088871311; validation accuracy : 0.895397489539749\n",
      "Epoch 46:\t train loss : 0.5719937315782868; train accuracy : 0.9788909197930543; \n",
      " validation loss : 0.6318620472162303; validation accuracy : 0.9163179916317992\n",
      "Epoch 47:\t train loss : 0.5638263129693352; train accuracy : 0.9874627466774064; \n",
      " validation loss : 0.6164248106218908; validation accuracy : 0.9330543933054394\n",
      "Epoch 48:\t train loss : 0.5640710753223744; train accuracy : 0.9872613773660894; \n",
      " validation loss : 0.6230031144351026; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5648811081086003; train accuracy : 0.986347470491651; \n",
      " validation loss : 0.6270274599318238; validation accuracy : 0.9205020920502092\n",
      "Epoch 50:\t train loss : 0.5659461013386882; train accuracy : 0.9852167043588711; \n",
      " validation loss : 0.6351637929986788; validation accuracy : 0.9121338912133892\n",
      "Epoch 51:\t train loss : 0.5674753817721718; train accuracy : 0.983717897084792; \n",
      " validation loss : 0.6069659458098217; validation accuracy : 0.9456066945606695\n",
      "Epoch 52:\t train loss : 0.563874609304299; train accuracy : 0.9874531429102512; \n",
      " validation loss : 0.6009619371653251; validation accuracy : 0.9539748953974896\n",
      "Epoch 53:\t train loss : 0.5671026929283167; train accuracy : 0.984043185972304; \n",
      " validation loss : 0.6355783464901352; validation accuracy : 0.9163179916317992\n",
      "Epoch 54:\t train loss : 0.5708849813964186; train accuracy : 0.9801728678087921; \n",
      " validation loss : 0.6276049707542729; validation accuracy : 0.9246861924686193\n",
      "Epoch 55:\t train loss : 0.5624879961475298; train accuracy : 0.9887948821215031; \n",
      " validation loss : 0.6259773928257057; validation accuracy : 0.9246861924686193\n",
      "Epoch 56:\t train loss : 0.5649116010856353; train accuracy : 0.986270020756529; \n",
      " validation loss : 0.6169267300363115; validation accuracy : 0.9330543933054394\n",
      "Epoch 57:\t train loss : 0.5689940926062962; train accuracy : 0.9823392917996221; \n",
      " validation loss : 0.639022548891932; validation accuracy : 0.9121338912133892\n",
      "Epoch 58:\t train loss : 0.5750114452126178; train accuracy : 0.9759692059853156; \n",
      " validation loss : 0.6123834686060343; validation accuracy : 0.9372384937238494\n",
      "Epoch 59:\t train loss : 0.5674824106535657; train accuracy : 0.9838130053595217; \n",
      " validation loss : 0.6396204952915077; validation accuracy : 0.9121338912133892\n",
      "Epoch 60:\t train loss : 0.5635819945640014; train accuracy : 0.9876176461476501; \n",
      " validation loss : 0.5974043522671535; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61:\t train loss : 0.5693016019388841; train accuracy : 0.9818708758016048; \n",
      " validation loss : 0.6080433203675887; validation accuracy : 0.9372384937238494\n",
      "Epoch 62:\t train loss : 0.5640613083649104; train accuracy : 0.9871529477369188; \n",
      " validation loss : 0.5940480693687932; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.5646280863661856; train accuracy : 0.9864964837820255; \n",
      " validation loss : 0.6244168056141507; validation accuracy : 0.9288702928870293\n",
      "Epoch 64:\t train loss : 0.5631383306279295; train accuracy : 0.9881752842405279; \n",
      " validation loss : 0.5934742157690721; validation accuracy : 0.9497907949790795\n",
      "Epoch 65:\t train loss : 0.5628183688340651; train accuracy : 0.9883980296787385; \n",
      " validation loss : 0.5987691303600361; validation accuracy : 0.9539748953974896\n",
      "Epoch 66:\t train loss : 0.5626750997761159; train accuracy : 0.9884850831810155; \n",
      " validation loss : 0.6173871350565223; validation accuracy : 0.9288702928870293\n",
      "Epoch 67:\t train loss : 0.571927102112835; train accuracy : 0.9791350413581585; \n",
      " validation loss : 0.6068843678081113; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5775318713427116; train accuracy : 0.973428854673317; \n",
      " validation loss : 0.6310161636681392; validation accuracy : 0.9205020920502092\n",
      "Epoch 69:\t train loss : 0.5689356488661504; train accuracy : 0.9821710709749373; \n",
      " validation loss : 0.6273006148097179; validation accuracy : 0.9246861924686193\n",
      "Epoch 70:\t train loss : 0.5620738477000742; train accuracy : 0.9891046810619908; \n",
      " validation loss : 0.5991187001832928; validation accuracy : 0.9539748953974896\n",
      "Epoch 71:\t train loss : 0.5630860880249366; train accuracy : 0.9881752842405279; \n",
      " validation loss : 0.613252681232835; validation accuracy : 0.9330543933054394\n",
      "Epoch 72:\t train loss : 0.561842337060376; train accuracy : 0.9894513460763964; \n",
      " validation loss : 0.6086407051321722; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5571632292107153; train accuracy : 0.9942996994950277; \n",
      " validation loss : 0.6123337095149205; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5586105242938897; train accuracy : 0.9927042349515165; \n",
      " validation loss : 0.5996252085901752; validation accuracy : 0.9497907949790795\n",
      "Epoch 75:\t train loss : 0.5601753971308036; train accuracy : 0.9911397503020539; \n",
      " validation loss : 0.6031078339732836; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.55859477718431; train accuracy : 0.9927816846866384; \n",
      " validation loss : 0.6019568180965033; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5622505127287869; train accuracy : 0.9889807614857957; \n",
      " validation loss : 0.6382796299456778; validation accuracy : 0.9079497907949791\n",
      "Epoch 78:\t train loss : 0.571491114250835; train accuracy : 0.9795783636419964; \n",
      " validation loss : 0.6190548182055274; validation accuracy : 0.9330543933054394\n",
      "Epoch 79:\t train loss : 0.5683902391793665; train accuracy : 0.9827132191207906; \n",
      " validation loss : 0.6315089254268801; validation accuracy : 0.9163179916317992\n",
      "Epoch 80:\t train loss : 0.5754162246420336; train accuracy : 0.9755141113417393; \n",
      " validation loss : 0.6165378823282259; validation accuracy : 0.9330543933054394\n",
      "Epoch 81:\t train loss : 0.5724234794972312; train accuracy : 0.9785464233712321; \n",
      " validation loss : 0.61033533898019; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.561070148540227; train accuracy : 0.9900805477245268; \n",
      " validation loss : 0.6119082636725354; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5578289586531471; train accuracy : 0.993503826016915; \n",
      " validation loss : 0.6219764047166569; validation accuracy : 0.9288702928870293\n",
      "Epoch 84:\t train loss : 0.5598417695280534; train accuracy : 0.9913817032745748; \n",
      " validation loss : 0.6103923473965435; validation accuracy : 0.9414225941422594\n",
      "Epoch 85:\t train loss : 0.5586919646388157; train accuracy : 0.992564825428297; \n",
      " validation loss : 0.6116238245964781; validation accuracy : 0.9372384937238494\n",
      "Epoch 86:\t train loss : 0.5563674300494661; train accuracy : 0.9949849747513864; \n",
      " validation loss : 0.5974848637255498; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5619058126718258; train accuracy : 0.9894203661823476; \n",
      " validation loss : 0.6262601165786642; validation accuracy : 0.9205020920502092\n",
      "Epoch 88:\t train loss : 0.5661339185461624; train accuracy : 0.9849843551535054; \n",
      " validation loss : 0.6184520595439291; validation accuracy : 0.9288702928870293\n",
      "Epoch 89:\t train loss : 0.5611713859543404; train accuracy : 0.9901019238514204; \n",
      " validation loss : 0.6065274617581492; validation accuracy : 0.9414225941422594\n",
      "Epoch 90:\t train loss : 0.556236775534586; train accuracy : 0.9950314445924595; \n",
      " validation loss : 0.5944417976711548; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5558457634938675; train accuracy : 0.995569875151027; \n",
      " validation loss : 0.5975424359684116; validation accuracy : 0.9539748953974896\n",
      "Epoch 92:\t train loss : 0.5555199437928483; train accuracy : 0.995817714303417; \n",
      " validation loss : 0.6017664167216327; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5645420530412069; train accuracy : 0.9866727593791629; \n",
      " validation loss : 0.6362290965514246; validation accuracy : 0.9163179916317992\n",
      "Epoch 94:\t train loss : 0.5609493438941423; train accuracy : 0.9902413333746398; \n",
      " validation loss : 0.5940368879180736; validation accuracy : 0.9539748953974896\n",
      "Epoch 95:\t train loss : 0.5578780296392817; train accuracy : 0.9934632423557112; \n",
      " validation loss : 0.597136015102914; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5565059165858239; train accuracy : 0.9948883174819542; \n",
      " validation loss : 0.6101419417675823; validation accuracy : 0.9414225941422594\n",
      "Epoch 97:\t train loss : 0.5674885548067966; train accuracy : 0.9836581058892778; \n",
      " validation loss : 0.5809056766203742; validation accuracy : 0.9707112970711297\n",
      "Epoch 98:\t train loss : 0.5562905460126425; train accuracy : 0.9951398742216302; \n",
      " validation loss : 0.6110542063184962; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5618238273194046; train accuracy : 0.989435856129372; \n",
      " validation loss : 0.6052972378050081; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5560166368698144; train accuracy : 0.9953220359986369; \n",
      " validation loss : 0.6181959619160514; validation accuracy : 0.9330543933054394\n",
      "Epoch 101:\t train loss : 0.5739642282012397; train accuracy : 0.9770284085628427; \n",
      " validation loss : 0.6123561279423262; validation accuracy : 0.9330543933054394\n",
      "Epoch 102:\t train loss : 0.5634975996757032; train accuracy : 0.9877143034170823; \n",
      " validation loss : 0.6250459278682414; validation accuracy : 0.9246861924686193\n",
      "Epoch 103:\t train loss : 0.5606552625128898; train accuracy : 0.9906072059233557; \n",
      " validation loss : 0.5997083052601683; validation accuracy : 0.9539748953974896\n",
      "Epoch 104:\t train loss : 0.5816033047522186; train accuracy : 0.9692053657176493; \n",
      " validation loss : 0.6297249672101947; validation accuracy : 0.9246861924686193\n",
      "Epoch 105:\t train loss : 0.5678718738292209; train accuracy : 0.9832126150128566; \n",
      " validation loss : 0.5978141912554557; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5634582664225736; train accuracy : 0.9877511694910003; \n",
      " validation loss : 0.5867283392601174; validation accuracy : 0.9665271966527197\n",
      "Epoch 107:\t train loss : 0.5595800408499291; train accuracy : 0.9918464016853062; \n",
      " validation loss : 0.5987248025208277; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5613353448074575; train accuracy : 0.9900164193438459; \n",
      " validation loss : 0.6093954351748758; validation accuracy : 0.9414225941422594\n",
      "Epoch 109:\t train loss : 0.5633861395083047; train accuracy : 0.9879894048762353; \n",
      " validation loss : 0.609758443631563; validation accuracy : 0.9372384937238494\n",
      "Epoch 110:\t train loss : 0.5622692371438315; train accuracy : 0.9888819356237801; \n",
      " validation loss : 0.5970238111086482; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.5630114561368226; train accuracy : 0.9881576257009201; \n",
      " validation loss : 0.5870821981403973; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112:\t train loss : 0.5592633651318991; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.5980697971602199; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.56100468663021; train accuracy : 0.9902915208029989; \n",
      " validation loss : 0.5985094485040834; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5674631257956727; train accuracy : 0.9837237832646613; \n",
      " validation loss : 0.6116010566395936; validation accuracy : 0.9414225941422594\n",
      "Epoch 115:\t train loss : 0.5647118714122538; train accuracy : 0.9865274636760742; \n",
      " validation loss : 0.5893445641473497; validation accuracy : 0.9665271966527197\n",
      "Epoch 116:\t train loss : 0.5566395379464844; train accuracy : 0.9947643979057591; \n",
      " validation loss : 0.57721965343368; validation accuracy : 0.9748953974895398\n",
      "Epoch 117:\t train loss : 0.5585992865669053; train accuracy : 0.9927971746336628; \n",
      " validation loss : 0.6159565449831886; validation accuracy : 0.9330543933054394\n",
      "Epoch 118:\t train loss : 0.5585746740698413; train accuracy : 0.992729328665696; \n",
      " validation loss : 0.6084121543890193; validation accuracy : 0.9414225941422594\n",
      "Epoch 119:\t train loss : 0.5656674657837651; train accuracy : 0.9856305957433625; \n",
      " validation loss : 0.5965867904966683; validation accuracy : 0.9497907949790795\n",
      "Epoch 120:\t train loss : 0.5659242868991112; train accuracy : 0.9854372812044982; \n",
      " validation loss : 0.6150462603962122; validation accuracy : 0.9372384937238494\n",
      "Epoch 121:\t train loss : 0.5587860893763211; train accuracy : 0.9925434493014034; \n",
      " validation loss : 0.5871841817487897; validation accuracy : 0.9665271966527197\n",
      "Epoch 122:\t train loss : 0.55974880182203; train accuracy : 0.99139130704173; \n",
      " validation loss : 0.5897146227267381; validation accuracy : 0.9623430962343096\n",
      "Epoch 123:\t train loss : 0.5577589163639332; train accuracy : 0.9936277455931101; \n",
      " validation loss : 0.6140562233748939; validation accuracy : 0.9372384937238494\n",
      "Epoch 124:\t train loss : 0.5571088550441466; train accuracy : 0.9942451748815019; \n",
      " validation loss : 0.6060922489461937; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5558971529105337; train accuracy : 0.9955020291830602; \n",
      " validation loss : 0.5847991634094073; validation accuracy : 0.9665271966527197\n",
      "Epoch 126:\t train loss : 0.5649444976332807; train accuracy : 0.9862390408624803; \n",
      " validation loss : 0.6212779094559164; validation accuracy : 0.9330543933054394\n",
      "Epoch 127:\t train loss : 0.5613944519528073; train accuracy : 0.9900532854177638; \n",
      " validation loss : 0.5875530688446287; validation accuracy : 0.9623430962343096\n",
      "Epoch 128:\t train loss : 0.558880900614695; train accuracy : 0.9923730598841352; \n",
      " validation loss : 0.6112031630415279; validation accuracy : 0.9372384937238494\n",
      "Epoch 129:\t train loss : 0.557783810432451; train accuracy : 0.9935598996251432; \n",
      " validation loss : 0.5939433936842031; validation accuracy : 0.9539748953974896\n",
      "Epoch 130:\t train loss : 0.5571166584762717; train accuracy : 0.9942842095480033; \n",
      " validation loss : 0.5956988462812741; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5566045410966366; train accuracy : 0.9947894916199387; \n",
      " validation loss : 0.6024319887981148; validation accuracy : 0.9497907949790795\n",
      "Epoch 132:\t train loss : 0.555585117098611; train accuracy : 0.9958022243563927; \n",
      " validation loss : 0.6011139634598469; validation accuracy : 0.9497907949790795\n",
      "Epoch 133:\t train loss : 0.5589149066256155; train accuracy : 0.9923575699371108; \n",
      " validation loss : 0.5872039609259337; validation accuracy : 0.9623430962343096\n",
      "Epoch 134:\t train loss : 0.5640855379822629; train accuracy : 0.9871507791443354; \n",
      " validation loss : 0.5999845508017029; validation accuracy : 0.9497907949790795\n",
      "Epoch 135:\t train loss : 0.5596107218197339; train accuracy : 0.9917785557173394; \n",
      " validation loss : 0.606819077702858; validation accuracy : 0.9414225941422594\n",
      "Epoch 136:\t train loss : 0.5575586193759678; train accuracy : 0.9938504910313206; \n",
      " validation loss : 0.5724801848212272; validation accuracy : 0.9790794979079498\n",
      "Epoch 137:\t train loss : 0.5564201494650438; train accuracy : 0.9949849747513864; \n",
      " validation loss : 0.5857899801144335; validation accuracy : 0.9665271966527197\n",
      "Epoch 138:\t train loss : 0.5682440499182496; train accuracy : 0.9830171318814089; \n",
      " validation loss : 0.5870730981957428; validation accuracy : 0.9665271966527197\n",
      "Epoch 139:\t train loss : 0.563979074228918; train accuracy : 0.9870578394621891; \n",
      " validation loss : 0.6201469861884538; validation accuracy : 0.9330543933054394\n",
      "Epoch 140:\t train loss : 0.5604065536718377; train accuracy : 0.9906477895845596; \n",
      " validation loss : 0.5937702759502647; validation accuracy : 0.9581589958158996\n",
      "Epoch 141:\t train loss : 0.5556077758952388; train accuracy : 0.9957557545153195; \n",
      " validation loss : 0.5789826895096344; validation accuracy : 0.9707112970711297\n",
      "Epoch 142:\t train loss : 0.5560381385759449; train accuracy : 0.9953626196598407; \n",
      " validation loss : 0.5860792056948844; validation accuracy : 0.9665271966527197\n",
      "Epoch 143:\t train loss : 0.5575915507440234; train accuracy : 0.9937206852752564; \n",
      " validation loss : 0.5801986109277482; validation accuracy : 0.9707112970711297\n",
      "Epoch 144:\t train loss : 0.5581463335288037; train accuracy : 0.9931999132562966; \n",
      " validation loss : 0.5890635133911586; validation accuracy : 0.9623430962343096\n",
      "Epoch 145:\t train loss : 0.5565549941509221; train accuracy : 0.9946751758108987; \n",
      " validation loss : 0.587094666176686; validation accuracy : 0.9623430962343096\n",
      "Epoch 146:\t train loss : 0.5678786752672039; train accuracy : 0.9832686886210849; \n",
      " validation loss : 0.616423951964763; validation accuracy : 0.9330543933054394\n",
      "Epoch 147:\t train loss : 0.574482690155487; train accuracy : 0.9765438830199201; \n",
      " validation loss : 0.5956031726241622; validation accuracy : 0.9581589958158996\n",
      "Epoch 148:\t train loss : 0.5705822637374095; train accuracy : 0.980675981288144; \n",
      " validation loss : 0.5795187928324517; validation accuracy : 0.9707112970711297\n",
      "Epoch 149:\t train loss : 0.5593093945906965; train accuracy : 0.9920846370705412; \n",
      " validation loss : 0.6030146444842516; validation accuracy : 0.9456066945606695\n",
      "Epoch 150:\t train loss : 0.5601648405647851; train accuracy : 0.9911124879952911; \n",
      " validation loss : 0.5886643065816586; validation accuracy : 0.9623430962343096\n",
      "Epoch 151:\t train loss : 0.5582852782155496; train accuracy : 0.992940301744168; \n",
      " validation loss : 0.597000246271689; validation accuracy : 0.9539748953974896\n",
      "Epoch 152:\t train loss : 0.5614275108108957; train accuracy : 0.989861519873602; \n",
      " validation loss : 0.6272152556945954; validation accuracy : 0.9205020920502092\n",
      "Epoch 153:\t train loss : 0.5643611708867188; train accuracy : 0.9869088261718145; \n",
      " validation loss : 0.6122986509150354; validation accuracy : 0.9414225941422594\n",
      "Epoch 154:\t train loss : 0.5615538819099584; train accuracy : 0.9897611450168841; \n",
      " validation loss : 0.5910921458350237; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5587509266681254; train accuracy : 0.992527959354379; \n",
      " validation loss : 0.5873642229852005; validation accuracy : 0.9665271966527197\n",
      "Epoch 156:\t train loss : 0.5596775223518357; train accuracy : 0.9915771864060224; \n",
      " validation loss : 0.6247581213606994; validation accuracy : 0.9288702928870293\n",
      "Epoch 157:\t train loss : 0.5587328814149761; train accuracy : 0.9925124694073546; \n",
      " validation loss : 0.5964640590645067; validation accuracy : 0.9539748953974896\n",
      "Epoch 158:\t train loss : 0.5603760313458879; train accuracy : 0.9908491588958765; \n",
      " validation loss : 0.6089268733456115; validation accuracy : 0.9456066945606695\n",
      "Epoch 159:\t train loss : 0.5601108966228381; train accuracy : 0.9911493540692091; \n",
      " validation loss : 0.5875852669185014; validation accuracy : 0.9623430962343096\n",
      "Epoch 160:\t train loss : 0.556451169079077; train accuracy : 0.9949443910901825; \n",
      " validation loss : 0.5966774865228709; validation accuracy : 0.9539748953974896\n",
      "Epoch 161:\t train loss : 0.5561532487203263; train accuracy : 0.9952910561045881; \n",
      " validation loss : 0.5884731540672286; validation accuracy : 0.9623430962343096\n",
      "Epoch 162:\t train loss : 0.5593300889563151; train accuracy : 0.9919703212615013; \n",
      " validation loss : 0.6132900476303219; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163:\t train loss : 0.5614416503929085; train accuracy : 0.9897530902444314; \n",
      " validation loss : 0.6081706222596271; validation accuracy : 0.9414225941422594\n",
      "Epoch 164:\t train loss : 0.5577818681835759; train accuracy : 0.9937361752222807; \n",
      " validation loss : 0.6210211435522137; validation accuracy : 0.9288702928870293\n",
      "Epoch 165:\t train loss : 0.5639959387726853; train accuracy : 0.9871278540227393; \n",
      " validation loss : 0.6054174503139844; validation accuracy : 0.9456066945606695\n",
      "Epoch 166:\t train loss : 0.5613826276721607; train accuracy : 0.9898946683602342; \n",
      " validation loss : 0.601400561129052; validation accuracy : 0.9497907949790795\n",
      "Epoch 167:\t train loss : 0.5567161383423538; train accuracy : 0.9945977260757768; \n",
      " validation loss : 0.6011173700554593; validation accuracy : 0.9497907949790795\n",
      "Epoch 168:\t train loss : 0.5668363862538689; train accuracy : 0.9844629635366647; \n",
      " validation loss : 0.6313164164815503; validation accuracy : 0.9205020920502092\n",
      "Epoch 169:\t train loss : 0.5682419810714573; train accuracy : 0.9829145884321075; \n",
      " validation loss : 0.6081453997752088; validation accuracy : 0.9414225941422594\n",
      "Epoch 170:\t train loss : 0.5607378633313809; train accuracy : 0.9905201524210787; \n",
      " validation loss : 0.5952027904462049; validation accuracy : 0.9539748953974896\n",
      "Epoch 171:\t train loss : 0.5577396643387628; train accuracy : 0.9937885312432232; \n",
      " validation loss : 0.589772664079006; validation accuracy : 0.9581589958158996\n",
      "Epoch 172:\t train loss : 0.562495756464073; train accuracy : 0.9889246878775675; \n",
      " validation loss : 0.5887426031972351; validation accuracy : 0.9581589958158996\n",
      "Epoch 173:\t train loss : 0.557203022818536; train accuracy : 0.9941389138449146; \n",
      " validation loss : 0.5918203496745051; validation accuracy : 0.9581589958158996\n",
      "Epoch 174:\t train loss : 0.5561257167529796; train accuracy : 0.9951826264754174; \n",
      " validation loss : 0.5994270429792641; validation accuracy : 0.9497907949790795\n",
      "Epoch 175:\t train loss : 0.5560103156044329; train accuracy : 0.9953375259456613; \n",
      " validation loss : 0.5806912664598659; validation accuracy : 0.9707112970711297\n",
      "Epoch 176:\t train loss : 0.5563125703645811; train accuracy : 0.9950528207193531; \n",
      " validation loss : 0.6009730780308498; validation accuracy : 0.9497907949790795\n",
      "Epoch 177:\t train loss : 0.5565625158528174; train accuracy : 0.9947953777998079; \n",
      " validation loss : 0.5939244987916956; validation accuracy : 0.9539748953974896\n",
      "Epoch 178:\t train loss : 0.5557316652785296; train accuracy : 0.9957188884414016; \n",
      " validation loss : 0.5963728783459067; validation accuracy : 0.9539748953974896\n",
      "Epoch 179:\t train loss : 0.5581433985597483; train accuracy : 0.9932132346107376; \n",
      " validation loss : 0.5936121845391402; validation accuracy : 0.9539748953974896\n",
      "Epoch 180:\t train loss : 0.5592523781996264; train accuracy : 0.9919858112085257; \n",
      " validation loss : 0.6057140157106393; validation accuracy : 0.9456066945606695\n",
      "Epoch 181:\t train loss : 0.5587428806866138; train accuracy : 0.9926267852163946; \n",
      " validation loss : 0.5895024197787871; validation accuracy : 0.9623430962343096\n",
      "Epoch 182:\t train loss : 0.5544214755889718; train accuracy : 0.9969425942563276; \n",
      " validation loss : 0.6009306651024915; validation accuracy : 0.9497907949790795\n",
      "Epoch 183:\t train loss : 0.5564638994161137; train accuracy : 0.9948979212491094; \n",
      " validation loss : 0.6010758394415242; validation accuracy : 0.9497907949790795\n",
      "Epoch 184:\t train loss : 0.5566631698759441; train accuracy : 0.9947489079587347; \n",
      " validation loss : 0.603202990969324; validation accuracy : 0.9456066945606695\n",
      "Epoch 185:\t train loss : 0.5574347369549586; train accuracy : 0.9940149942687196; \n",
      " validation loss : 0.6266259692568407; validation accuracy : 0.9163179916317992\n",
      "Epoch 186:\t train loss : 0.5639136634006486; train accuracy : 0.9873388271012113; \n",
      " validation loss : 0.5798339698577207; validation accuracy : 0.9748953974895398\n",
      "Early stopping at epoch 186\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5575586193759678; Train accuracy : 0.9938504910313206; \n",
      " Validation loss : 0.5724801848212272; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 70 ! ---\n",
      "Epoch 1:\t train loss : 0.9386452084216211; train accuracy : 0.5844979708169398; \n",
      " validation loss : 0.8197609905211773; validation accuracy : 0.7322175732217573\n",
      "Epoch 2:\t train loss : 0.7543295393985829; train accuracy : 0.7945636481923232; \n",
      " validation loss : 0.7128118517855904; validation accuracy : 0.8326359832635983\n",
      "Epoch 3:\t train loss : 0.7054537249955342; train accuracy : 0.8449450106880635; \n",
      " validation loss : 0.7237324381169703; validation accuracy : 0.8158995815899581\n",
      "Epoch 4:\t train loss : 0.6781110984514427; train accuracy : 0.8721939960965334; \n",
      " validation loss : 0.6949482358261544; validation accuracy : 0.8451882845188284\n",
      "Epoch 5:\t train loss : 0.6580157698978298; train accuracy : 0.8926038600947985; \n",
      " validation loss : 0.6945992811485848; validation accuracy : 0.8493723849372385\n",
      "Epoch 6:\t train loss : 0.6537251478074164; train accuracy : 0.8969255553146008; \n",
      " validation loss : 0.6915612006130837; validation accuracy : 0.8577405857740585\n",
      "Epoch 7:\t train loss : 0.6490371340394119; train accuracy : 0.9009219616468912; \n",
      " validation loss : 0.699454123411228; validation accuracy : 0.8451882845188284\n",
      "Epoch 8:\t train loss : 0.6373031595939362; train accuracy : 0.9134068589485423; \n",
      " validation loss : 0.6826603853857136; validation accuracy : 0.8702928870292888\n",
      "Epoch 9:\t train loss : 0.6198432791182894; train accuracy : 0.9312822578146782; \n",
      " validation loss : 0.6577669767706591; validation accuracy : 0.8870292887029289\n",
      "Epoch 10:\t train loss : 0.6073644475722992; train accuracy : 0.9440016729142786; \n",
      " validation loss : 0.6088957883169464; validation accuracy : 0.9456066945606695\n",
      "Epoch 11:\t train loss : 0.5999877704095363; train accuracy : 0.9518064376219834; \n",
      " validation loss : 0.6406511109073386; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.5975789199456781; train accuracy : 0.95372935964559; \n",
      " validation loss : 0.6399506026892386; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.5947165167296706; train accuracy : 0.9566238111465659; \n",
      " validation loss : 0.6307465181528304; validation accuracy : 0.9163179916317992\n",
      "Epoch 14:\t train loss : 0.5905726982880739; train accuracy : 0.9606261036587255; \n",
      " validation loss : 0.6742706121500404; validation accuracy : 0.8870292887029289\n",
      "Epoch 15:\t train loss : 0.5847861121949781; train accuracy : 0.9667350289662009; \n",
      " validation loss : 0.6401749680916843; validation accuracy : 0.9121338912133892\n",
      "Epoch 16:\t train loss : 0.588852597257601; train accuracy : 0.9623668639053254; \n",
      " validation loss : 0.6199231999176918; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5876533195306429; train accuracy : 0.963693113169553; \n",
      " validation loss : 0.6099390455901226; validation accuracy : 0.9414225941422594\n",
      "Epoch 18:\t train loss : 0.583291821816663; train accuracy : 0.967862077511695; \n",
      " validation loss : 0.606656537574869; validation accuracy : 0.9456066945606695\n",
      "Epoch 19:\t train loss : 0.5864521888400112; train accuracy : 0.964944081291242; \n",
      " validation loss : 0.649158713179415; validation accuracy : 0.899581589958159\n",
      "Epoch 20:\t train loss : 0.5877950660015653; train accuracy : 0.9634843086836643; \n",
      " validation loss : 0.6282678503391955; validation accuracy : 0.9205020920502092\n",
      "Epoch 21:\t train loss : 0.5865085956296726; train accuracy : 0.9646903559589827; \n",
      " validation loss : 0.6328765908393632; validation accuracy : 0.9205020920502092\n",
      "Epoch 22:\t train loss : 0.5836367876631451; train accuracy : 0.9675832584652561; \n",
      " validation loss : 0.6285778701968056; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.5758751163070783; train accuracy : 0.9756129372037547; \n",
      " validation loss : 0.6218171679947636; validation accuracy : 0.9246861924686193\n",
      "Epoch 24:\t train loss : 0.57308251867202; train accuracy : 0.9785811208525667; \n",
      " validation loss : 0.6206568506323157; validation accuracy : 0.9288702928870293\n",
      "Epoch 25:\t train loss : 0.5772525491191522; train accuracy : 0.9741200161095449; \n",
      " validation loss : 0.6219082679058346; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5806929549988281; train accuracy : 0.9704179187707178; \n",
      " validation loss : 0.6069953357944363; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:\t train loss : 0.5798220609125428; train accuracy : 0.9713473155921807; \n",
      " validation loss : 0.6307458986199057; validation accuracy : 0.9163179916317992\n",
      "Epoch 28:\t train loss : 0.5760169120071428; train accuracy : 0.975517828929025; \n",
      " validation loss : 0.620418112109515; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5775658710623995; train accuracy : 0.9738353108832368; \n",
      " validation loss : 0.6184552994012432; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.5831372625616378; train accuracy : 0.9679122649400539; \n",
      " validation loss : 0.6478007059941606; validation accuracy : 0.9037656903765691\n",
      "Epoch 31:\t train loss : 0.5847128802171093; train accuracy : 0.9661891632330617; \n",
      " validation loss : 0.6310174268682534; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.5840900988883462; train accuracy : 0.9668707209021346; \n",
      " validation loss : 0.5989834003814228; validation accuracy : 0.9581589958158996\n",
      "Epoch 33:\t train loss : 0.5727849876377955; train accuracy : 0.9784321075621921; \n",
      " validation loss : 0.596405131310273; validation accuracy : 0.9497907949790795\n",
      "Epoch 34:\t train loss : 0.5719065839333431; train accuracy : 0.9794950277270051; \n",
      " validation loss : 0.6183687872157229; validation accuracy : 0.9288702928870293\n",
      "Epoch 35:\t train loss : 0.5730305449433355; train accuracy : 0.9784321075621921; \n",
      " validation loss : 0.6005567440498095; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5719251080563027; train accuracy : 0.9791970011462561; \n",
      " validation loss : 0.619440751081417; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5707165622572344; train accuracy : 0.9805483441246631; \n",
      " validation loss : 0.6059058408727187; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5826063181576607; train accuracy : 0.968146782738003; \n",
      " validation loss : 0.6331507048559546; validation accuracy : 0.9163179916317992\n",
      "Epoch 39:\t train loss : 0.5752393542695293; train accuracy : 0.9758527215836922; \n",
      " validation loss : 0.6167778586437864; validation accuracy : 0.9372384937238494\n",
      "Epoch 40:\t train loss : 0.5730267712711417; train accuracy : 0.9780758387806314; \n",
      " validation loss : 0.6240428340367132; validation accuracy : 0.9288702928870293\n",
      "Epoch 41:\t train loss : 0.5694206361667681; train accuracy : 0.981926949409833; \n",
      " validation loss : 0.6148817260543665; validation accuracy : 0.9288702928870293\n",
      "Epoch 42:\t train loss : 0.5700311169351684; train accuracy : 0.9810557947891818; \n",
      " validation loss : 0.6300977950436556; validation accuracy : 0.9205020920502092\n",
      "Epoch 43:\t train loss : 0.5691932602488787; train accuracy : 0.981876761981474; \n",
      " validation loss : 0.6194182159270455; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5655656781044992; train accuracy : 0.9857337587905449; \n",
      " validation loss : 0.6152062688943377; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5694637333212472; train accuracy : 0.9817720499395892; \n",
      " validation loss : 0.6159228520994878; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5671329370350622; train accuracy : 0.9841228043000093; \n",
      " validation loss : 0.6135209760299224; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.5658348138750797; train accuracy : 0.9854239598500573; \n",
      " validation loss : 0.6094851516192146; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.5711292327824949; train accuracy : 0.9799965922116547; \n",
      " validation loss : 0.6047066785494681; validation accuracy : 0.9456066945606695\n",
      "Epoch 49:\t train loss : 0.5673403197856947; train accuracy : 0.9839775085969206; \n",
      " validation loss : 0.6652536467815123; validation accuracy : 0.8828451882845189\n",
      "Epoch 50:\t train loss : 0.6021643054407603; train accuracy : 0.9480600390346665; \n",
      " validation loss : 0.6176988169980223; validation accuracy : 0.9330543933054394\n",
      "Epoch 51:\t train loss : 0.5724853669107917; train accuracy : 0.9787183617832027; \n",
      " validation loss : 0.6058011244376377; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5711690212956899; train accuracy : 0.979888162582484; \n",
      " validation loss : 0.6059333569134624; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.5654857422364508; train accuracy : 0.9859137519749682; \n",
      " validation loss : 0.6269231886144251; validation accuracy : 0.9205020920502092\n",
      "Epoch 54:\t train loss : 0.5672113866735945; train accuracy : 0.9840453545648874; \n",
      " validation loss : 0.615401762443599; validation accuracy : 0.9330543933054394\n",
      "Epoch 55:\t train loss : 0.5643314409000029; train accuracy : 0.9869980482666749; \n",
      " validation loss : 0.6124056475393048; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.5679139322752208; train accuracy : 0.9832708572136684; \n",
      " validation loss : 0.6143447972391637; validation accuracy : 0.9330543933054394\n",
      "Epoch 57:\t train loss : 0.5647103282259748; train accuracy : 0.9866882493261873; \n",
      " validation loss : 0.615618731148199; validation accuracy : 0.9330543933054394\n",
      "Epoch 58:\t train loss : 0.5710565838789465; train accuracy : 0.9801109080206946; \n",
      " validation loss : 0.6202414203218215; validation accuracy : 0.9330543933054394\n",
      "Epoch 59:\t train loss : 0.5653440653568816; train accuracy : 0.9859602218160414; \n",
      " validation loss : 0.596875491949528; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5632184193164513; train accuracy : 0.9881347005793241; \n",
      " validation loss : 0.619536542171137; validation accuracy : 0.9288702928870293\n",
      "Epoch 61:\t train loss : 0.5641688434940284; train accuracy : 0.9871470615570495; \n",
      " validation loss : 0.6269490051035406; validation accuracy : 0.9246861924686193\n",
      "Epoch 62:\t train loss : 0.5649361194283911; train accuracy : 0.9863106044177329; \n",
      " validation loss : 0.607465135689996; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5626260610267116; train accuracy : 0.9886495864184145; \n",
      " validation loss : 0.6042922198715367; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5776072103403884; train accuracy : 0.9733764986523746; \n",
      " validation loss : 0.6306441128598396; validation accuracy : 0.9163179916317992\n",
      "Epoch 65:\t train loss : 0.5668820864989786; train accuracy : 0.9842157439821556; \n",
      " validation loss : 0.6091254056262927; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5602627162684258; train accuracy : 0.9911183741751604; \n",
      " validation loss : 0.5849540115728505; validation accuracy : 0.9665271966527197\n",
      "Epoch 67:\t train loss : 0.5653568879565973; train accuracy : 0.9860066916571145; \n",
      " validation loss : 0.6032507003600545; validation accuracy : 0.9497907949790795\n",
      "Epoch 68:\t train loss : 0.5690214356837975; train accuracy : 0.9819985129650857; \n",
      " validation loss : 0.6302851450614498; validation accuracy : 0.9205020920502092\n",
      "Epoch 69:\t train loss : 0.5621319776018755; train accuracy : 0.9893370302673565; \n",
      " validation loss : 0.5977553052741457; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5647053452355909; train accuracy : 0.9865702159298615; \n",
      " validation loss : 0.5935219789582686; validation accuracy : 0.9581589958158996\n",
      "Epoch 71:\t train loss : 0.5625943117669969; train accuracy : 0.9886960562594876; \n",
      " validation loss : 0.6076510555674919; validation accuracy : 0.9414225941422594\n",
      "Epoch 72:\t train loss : 0.5631389444430986; train accuracy : 0.9881966603674215; \n",
      " validation loss : 0.6074246913903408; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5765748278908706; train accuracy : 0.9744645125313671; \n",
      " validation loss : 0.82047129689183; validation accuracy : 0.7280334728033473\n",
      "Epoch 74:\t train loss : 0.5844063447112655; train accuracy : 0.9665919018556957; \n",
      " validation loss : 0.616470837219615; validation accuracy : 0.9330543933054394\n",
      "Epoch 75:\t train loss : 0.5663397984459315; train accuracy : 0.9849239443601103; \n",
      " validation loss : 0.5952823283750353; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5702627156840415; train accuracy : 0.9808987267263546; \n",
      " validation loss : 0.607042346468354; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5635246677245008; train accuracy : 0.9878013569193593; \n",
      " validation loss : 0.6209309663185837; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78:\t train loss : 0.5609345699119379; train accuracy : 0.9904058366120387; \n",
      " validation loss : 0.6058464147028403; validation accuracy : 0.9456066945606695\n",
      "Epoch 79:\t train loss : 0.5614237114797132; train accuracy : 0.9899101583072586; \n",
      " validation loss : 0.6132614773229874; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.560975212991412; train accuracy : 0.9903497630038105; \n",
      " validation loss : 0.6093006313081156; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.564540008645427; train accuracy : 0.9865702159298615; \n",
      " validation loss : 0.6079464072269759; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5612547508017159; train accuracy : 0.9900185879364293; \n",
      " validation loss : 0.6270204250095048; validation accuracy : 0.9205020920502092\n",
      "Epoch 83:\t train loss : 0.5623751661388924; train accuracy : 0.9889188016976982; \n",
      " validation loss : 0.6241922029527376; validation accuracy : 0.9288702928870293\n",
      "Epoch 84:\t train loss : 0.560614824738058; train accuracy : 0.9907658229808854; \n",
      " validation loss : 0.593125291880463; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5612725677134837; train accuracy : 0.9899721180953561; \n",
      " validation loss : 0.6227304443239152; validation accuracy : 0.9246861924686193\n",
      "Epoch 86:\t train loss : 0.562380051289824; train accuracy : 0.9888044858886582; \n",
      " validation loss : 0.6016522053765125; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5874636520694623; train accuracy : 0.9632497908857152; \n",
      " validation loss : 0.629068539331112; validation accuracy : 0.9205020920502092\n",
      "Epoch 88:\t train loss : 0.5651725297832595; train accuracy : 0.9860066916571145; \n",
      " validation loss : 0.6013574947272609; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.567958206891098; train accuracy : 0.983228104959881; \n",
      " validation loss : 0.6070975033023456; validation accuracy : 0.9456066945606695\n",
      "Epoch 90:\t train loss : 0.566666753488903; train accuracy : 0.9845292605099291; \n",
      " validation loss : 0.5928650463836762; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5631186692951936; train accuracy : 0.9881597942935035; \n",
      " validation loss : 0.6123301900796551; validation accuracy : 0.9372384937238494\n",
      "Epoch 92:\t train loss : 0.5626679281540165; train accuracy : 0.9885374392019579; \n",
      " validation loss : 0.6071825619684962; validation accuracy : 0.9414225941422594\n",
      "Epoch 93:\t train loss : 0.5598947452802383; train accuracy : 0.9914591530096967; \n",
      " validation loss : 0.6004540896068769; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5640643470448125; train accuracy : 0.9871160816630007; \n",
      " validation loss : 0.6139452277233786; validation accuracy : 0.9372384937238494\n",
      "Epoch 95:\t train loss : 0.5599481216986594; train accuracy : 0.9915424889246879; \n",
      " validation loss : 0.6063254808859248; validation accuracy : 0.9456066945606695\n",
      "Epoch 96:\t train loss : 0.5603886917766758; train accuracy : 0.9909634747049165; \n",
      " validation loss : 0.6135419344626413; validation accuracy : 0.9372384937238494\n",
      "Epoch 97:\t train loss : 0.5601102605923436; train accuracy : 0.9911471854766256; \n",
      " validation loss : 0.5889756437175938; validation accuracy : 0.9623430962343096\n",
      "Epoch 98:\t train loss : 0.56309408283441; train accuracy : 0.9882431302084946; \n",
      " validation loss : 0.6051850169908316; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5614526339501844; train accuracy : 0.989962514328201; \n",
      " validation loss : 0.6198248819876947; validation accuracy : 0.9288702928870293\n",
      "Epoch 100:\t train loss : 0.5684515827882015; train accuracy : 0.98285262864401; \n",
      " validation loss : 0.5950211972498118; validation accuracy : 0.9581589958158996\n",
      "Epoch 101:\t train loss : 0.5605139768759786; train accuracy : 0.9907658229808854; \n",
      " validation loss : 0.6196595265684316; validation accuracy : 0.9330543933054394\n",
      "Epoch 102:\t train loss : 0.562102284245905; train accuracy : 0.9891821307971127; \n",
      " validation loss : 0.6077627707751115; validation accuracy : 0.9414225941422594\n",
      "Epoch 103:\t train loss : 0.5590644840258221; train accuracy : 0.9923361938102172; \n",
      " validation loss : 0.6098863675209099; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.563546029830636; train accuracy : 0.9877319619566901; \n",
      " validation loss : 0.5935467565365489; validation accuracy : 0.9581589958158996\n",
      "Epoch 105:\t train loss : 0.5630810259190003; train accuracy : 0.9882217540816011; \n",
      " validation loss : 0.6172789578280331; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.5637326599904892; train accuracy : 0.9873794107624152; \n",
      " validation loss : 0.6191389655280497; validation accuracy : 0.9288702928870293\n",
      "Epoch 107:\t train loss : 0.5652734868449404; train accuracy : 0.9859506180488863; \n",
      " validation loss : 0.6152933407503552; validation accuracy : 0.9330543933054394\n",
      "Epoch 108:\t train loss : 0.5608368775581609; train accuracy : 0.9903962328448837; \n",
      " validation loss : 0.6114181646629441; validation accuracy : 0.9372384937238494\n",
      "Epoch 109:\t train loss : 0.5585240633228765; train accuracy : 0.9929093218501193; \n",
      " validation loss : 0.618876997417614; validation accuracy : 0.9330543933054394\n",
      "Epoch 110:\t train loss : 0.5573478742428706; train accuracy : 0.9939685244276465; \n",
      " validation loss : 0.5953072477204725; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.558269253472593; train accuracy : 0.9931224635211747; \n",
      " validation loss : 0.5997033446609866; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5655665702139102; train accuracy : 0.9855729731404319; \n",
      " validation loss : 0.6056473953509058; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5647842050977199; train accuracy : 0.9864249202267729; \n",
      " validation loss : 0.6039022586151077; validation accuracy : 0.9456066945606695\n",
      "Epoch 114:\t train loss : 0.5661329574504058; train accuracy : 0.9850463149416029; \n",
      " validation loss : 0.6137640242378568; validation accuracy : 0.9330543933054394\n",
      "Epoch 115:\t train loss : 0.5739475181170618; train accuracy : 0.9770262399702593; \n",
      " validation loss : 0.6178570819169257; validation accuracy : 0.9330543933054394\n",
      "Epoch 116:\t train loss : 0.5652907328361286; train accuracy : 0.985870999721181; \n",
      " validation loss : 0.5924269987908516; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 116\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5602627162684258; Train accuracy : 0.9911183741751604; \n",
      " Validation loss : 0.5849540115728505; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 71 ! ---\n",
      "Epoch 1:\t train loss : 0.9675790320895453; train accuracy : 0.5543752904365067; \n",
      " validation loss : 0.8470361003852073; validation accuracy : 0.6903765690376569\n",
      "Epoch 2:\t train loss : 0.7770206018390944; train accuracy : 0.7705365717649245; \n",
      " validation loss : 0.7277933477714357; validation accuracy : 0.8158995815899581\n",
      "Epoch 3:\t train loss : 0.7103985856366586; train accuracy : 0.8390256823321665; \n",
      " validation loss : 0.6916030156571779; validation accuracy : 0.8535564853556485\n",
      "Epoch 4:\t train loss : 0.6794974404798552; train accuracy : 0.8701177235973853; \n",
      " validation loss : 0.6979783352732492; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.6620008863575201; train accuracy : 0.8885956814027696; \n",
      " validation loss : 0.6549891009085461; validation accuracy : 0.899581589958159\n",
      "Epoch 6:\t train loss : 0.6494532402390817; train accuracy : 0.900637256420583; \n",
      " validation loss : 0.6395640065563958; validation accuracy : 0.9121338912133892\n",
      "Epoch 7:\t train loss : 0.6318987835223318; train accuracy : 0.91865949998451; \n",
      " validation loss : 0.6408982006691317; validation accuracy : 0.9121338912133892\n",
      "Epoch 8:\t train loss : 0.6243379261452165; train accuracy : 0.9260547104928901; \n",
      " validation loss : 0.6248022229116563; validation accuracy : 0.9288702928870293\n",
      "Epoch 9:\t train loss : 0.6147053665489844; train accuracy : 0.9365333498559435; \n",
      " validation loss : 0.6229263124668936; validation accuracy : 0.9288702928870293\n",
      "Epoch 10:\t train loss : 0.6197216805164805; train accuracy : 0.9312187490318783; \n",
      " validation loss : 0.6321925973670924; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.6066354120819506; train accuracy : 0.9440983301837108; \n",
      " validation loss : 0.6280415408633783; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\t train loss : 0.6070159980307205; train accuracy : 0.9438659809783451; \n",
      " validation loss : 0.6239146437621259; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.5950114294504949; train accuracy : 0.9564769664487748; \n",
      " validation loss : 0.6237888498845886; validation accuracy : 0.9205020920502092\n",
      "Epoch 14:\t train loss : 0.5952698762693373; train accuracy : 0.9560683416462715; \n",
      " validation loss : 0.608335800141305; validation accuracy : 0.9414225941422594\n",
      "Epoch 15:\t train loss : 0.592768682979364; train accuracy : 0.9585371294030174; \n",
      " validation loss : 0.6223464253645103; validation accuracy : 0.9246861924686193\n",
      "Epoch 16:\t train loss : 0.5872416739173523; train accuracy : 0.9643864431983643; \n",
      " validation loss : 0.6388670402933018; validation accuracy : 0.9079497907949791\n",
      "Epoch 17:\t train loss : 0.5903333792978953; train accuracy : 0.961013352334335; \n",
      " validation loss : 0.6450884184408237; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.5886324487034853; train accuracy : 0.9625682332166424; \n",
      " validation loss : 0.6180424066065269; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5902410010975374; train accuracy : 0.9607927754887078; \n",
      " validation loss : 0.6265974767110807; validation accuracy : 0.9246861924686193\n",
      "Epoch 20:\t train loss : 0.5877388580444561; train accuracy : 0.9634378388425912; \n",
      " validation loss : 0.599486467134468; validation accuracy : 0.9539748953974896\n",
      "Epoch 21:\t train loss : 0.5859849228483257; train accuracy : 0.9650717184547228; \n",
      " validation loss : 0.6129937589541229; validation accuracy : 0.9414225941422594\n",
      "Epoch 22:\t train loss : 0.5885308013575158; train accuracy : 0.9627098113324453; \n",
      " validation loss : 0.6341846984146764; validation accuracy : 0.9163179916317992\n",
      "Epoch 23:\t train loss : 0.5837262222415938; train accuracy : 0.9676356144861984; \n",
      " validation loss : 0.6135692326488303; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5786965417581951; train accuracy : 0.9724316118838874; \n",
      " validation loss : 0.6231669101225638; validation accuracy : 0.9246861924686193\n",
      "Epoch 25:\t train loss : 0.5816805582407221; train accuracy : 0.969287152637938; \n",
      " validation loss : 0.6183842925030174; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.576716693631741; train accuracy : 0.9745441308590724; \n",
      " validation loss : 0.5942950827223118; validation accuracy : 0.9581589958158996\n",
      "Epoch 27:\t train loss : 0.5772702117440486; train accuracy : 0.9738972706713342; \n",
      " validation loss : 0.589923627358193; validation accuracy : 0.9623430962343096\n",
      "Epoch 28:\t train loss : 0.574212544812187; train accuracy : 0.9771154620651198; \n",
      " validation loss : 0.6040091167591235; validation accuracy : 0.9456066945606695\n",
      "Epoch 29:\t train loss : 0.5725756140691055; train accuracy : 0.9788289600049568; \n",
      " validation loss : 0.6078227856544641; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5743502048695622; train accuracy : 0.9769760525419003; \n",
      " validation loss : 0.5877883825272947; validation accuracy : 0.9665271966527197\n",
      "Epoch 31:\t train loss : 0.573275307502303; train accuracy : 0.9778877908237554; \n",
      " validation loss : 0.6336116446275221; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.5826388687260418; train accuracy : 0.9684293193717277; \n",
      " validation loss : 0.6143245896512078; validation accuracy : 0.9330543933054394\n",
      "Epoch 33:\t train loss : 0.5749503579232123; train accuracy : 0.9761780104712042; \n",
      " validation loss : 0.6403472938040282; validation accuracy : 0.9079497907949791\n",
      "Epoch 34:\t train loss : 0.5911463931266807; train accuracy : 0.9595845596208061; \n",
      " validation loss : 0.6113057980870928; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5747438486966816; train accuracy : 0.9764184144490226; \n",
      " validation loss : 0.6015640502558869; validation accuracy : 0.9456066945606695\n",
      "Epoch 36:\t train loss : 0.5694733235616913; train accuracy : 0.9817624461724341; \n",
      " validation loss : 0.6224153149024392; validation accuracy : 0.9246861924686193\n",
      "Epoch 37:\t train loss : 0.5683889935157417; train accuracy : 0.9829706620403358; \n",
      " validation loss : 0.5991200003890828; validation accuracy : 0.9456066945606695\n",
      "Epoch 38:\t train loss : 0.5709452234192002; train accuracy : 0.9801669816289228; \n",
      " validation loss : 0.5769295503099008; validation accuracy : 0.9748953974895398\n",
      "Epoch 39:\t train loss : 0.584840055269223; train accuracy : 0.9658809132872765; \n",
      " validation loss : 0.6723374507095246; validation accuracy : 0.8828451882845189\n",
      "Epoch 40:\t train loss : 0.5822328738943412; train accuracy : 0.9687044208308807; \n",
      " validation loss : 0.597996728900572; validation accuracy : 0.9497907949790795\n",
      "Epoch 41:\t train loss : 0.5663889570558525; train accuracy : 0.9850153350475541; \n",
      " validation loss : 0.5972361099123997; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5670106190583799; train accuracy : 0.9844267170606277; \n",
      " validation loss : 0.5980587501191632; validation accuracy : 0.9539748953974896\n",
      "Epoch 43:\t train loss : 0.5655878588209695; train accuracy : 0.9856076706217665; \n",
      " validation loss : 0.5991730468153917; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.5633797899112016; train accuracy : 0.9878478267604325; \n",
      " validation loss : 0.60421375075665; validation accuracy : 0.9414225941422594\n",
      "Epoch 45:\t train loss : 0.5654069641793793; train accuracy : 0.9857064964837821; \n",
      " validation loss : 0.5997523720580802; validation accuracy : 0.9497907949790795\n",
      "Epoch 46:\t train loss : 0.5652308746219407; train accuracy : 0.9859484494563029; \n",
      " validation loss : 0.6270212368327286; validation accuracy : 0.9205020920502092\n",
      "Epoch 47:\t train loss : 0.5676066994052057; train accuracy : 0.9835261315406302; \n",
      " validation loss : 0.6123691144831761; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.571384175419173; train accuracy : 0.9798726726354596; \n",
      " validation loss : 0.6130339593171871; validation accuracy : 0.9372384937238494\n",
      "Epoch 49:\t train loss : 0.5611256259104777; train accuracy : 0.990250937141795; \n",
      " validation loss : 0.583549245098824; validation accuracy : 0.9707112970711297\n",
      "Epoch 50:\t train loss : 0.5614978053666837; train accuracy : 0.9897279965302519; \n",
      " validation loss : 0.5806478834108297; validation accuracy : 0.9707112970711297\n",
      "Epoch 51:\t train loss : 0.5729817782623369; train accuracy : 0.9779519192044364; \n",
      " validation loss : 0.6008178932809052; validation accuracy : 0.9497907949790795\n",
      "Epoch 52:\t train loss : 0.565690945578553; train accuracy : 0.9857588525047244; \n",
      " validation loss : 0.5999636971090431; validation accuracy : 0.9539748953974896\n",
      "Epoch 53:\t train loss : 0.5663026659084667; train accuracy : 0.9849939589206604; \n",
      " validation loss : 0.6140921363499695; validation accuracy : 0.9330543933054394\n",
      "Epoch 54:\t train loss : 0.5664808134793107; train accuracy : 0.9845661265838471; \n",
      " validation loss : 0.6106172323865323; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.5608972617974616; train accuracy : 0.9903187831097617; \n",
      " validation loss : 0.5865739344203148; validation accuracy : 0.9665271966527197\n",
      "Epoch 56:\t train loss : 0.5602900776443891; train accuracy : 0.9910719043340872; \n",
      " validation loss : 0.5914633867485392; validation accuracy : 0.9623430962343096\n",
      "Epoch 57:\t train loss : 0.5633425345810619; train accuracy : 0.9880144985904148; \n",
      " validation loss : 0.5952727013980273; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.560541168053988; train accuracy : 0.990700145605502; \n",
      " validation loss : 0.599720330932737; validation accuracy : 0.9497907949790795\n",
      "Epoch 59:\t train loss : 0.5595189114612948; train accuracy : 0.9918656092196164; \n",
      " validation loss : 0.5873659473847961; validation accuracy : 0.9623430962343096\n",
      "Epoch 60:\t train loss : 0.5645505764811725; train accuracy : 0.9865333498559435; \n",
      " validation loss : 0.6147812934033057; validation accuracy : 0.9330543933054394\n",
      "Epoch 61:\t train loss : 0.5701641781290644; train accuracy : 0.9808020694569225; \n",
      " validation loss : 0.6192295221787933; validation accuracy : 0.9288702928870293\n",
      "Epoch 62:\t train loss : 0.571272498460281; train accuracy : 0.9799191424765328; \n",
      " validation loss : 0.6243398296404183; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63:\t train loss : 0.5644258679999111; train accuracy : 0.9867133430403668; \n",
      " validation loss : 0.6135937624264496; validation accuracy : 0.9372384937238494\n",
      "Epoch 64:\t train loss : 0.5650550123960438; train accuracy : 0.986233154682611; \n",
      " validation loss : 0.5962729005101478; validation accuracy : 0.9539748953974896\n",
      "Epoch 65:\t train loss : 0.5632650984984926; train accuracy : 0.9879525388023173; \n",
      " validation loss : 0.5773477976312006; validation accuracy : 0.9748953974895398\n",
      "Epoch 66:\t train loss : 0.5614565629905603; train accuracy : 0.9898268223922674; \n",
      " validation loss : 0.6014901040892754; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.5593561315268001; train accuracy : 0.9919489451346076; \n",
      " validation loss : 0.5909794027468539; validation accuracy : 0.9623430962343096\n",
      "Epoch 68:\t train loss : 0.5617781739667131; train accuracy : 0.9893680101614052; \n",
      " validation loss : 0.6071547244017351; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.561213508447361; train accuracy : 0.9900591715976331; \n",
      " validation loss : 0.6058523925527772; validation accuracy : 0.9456066945606695\n",
      "Epoch 70:\t train loss : 0.5608974582873998; train accuracy : 0.9901985811208526; \n",
      " validation loss : 0.6005343135537897; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5637328195704953; train accuracy : 0.9874782366244308; \n",
      " validation loss : 0.5871640290717123; validation accuracy : 0.9623430962343096\n",
      "Epoch 72:\t train loss : 0.5631455818309861; train accuracy : 0.9880048948232597; \n",
      " validation loss : 0.6004829065510615; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5596990558793158; train accuracy : 0.9914473806499582; \n",
      " validation loss : 0.6126387169877803; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5614697494808599; train accuracy : 0.9897338827101211; \n",
      " validation loss : 0.6222266313612115; validation accuracy : 0.9288702928870293\n",
      "Epoch 75:\t train loss : 0.5584982264947639; train accuracy : 0.9927773475014715; \n",
      " validation loss : 0.5913190912955408; validation accuracy : 0.9623430962343096\n",
      "Epoch 76:\t train loss : 0.5606059620260166; train accuracy : 0.9908240651816971; \n",
      " validation loss : 0.6066192014688464; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5690747600504824; train accuracy : 0.9820353790390037; \n",
      " validation loss : 0.5848600546647287; validation accuracy : 0.9623430962343096\n",
      "Epoch 78:\t train loss : 0.5599007925915737; train accuracy : 0.991350723380526; \n",
      " validation loss : 0.6083218261120384; validation accuracy : 0.9414225941422594\n",
      "Epoch 79:\t train loss : 0.5561913525460813; train accuracy : 0.9950992905604262; \n",
      " validation loss : 0.5833462083343968; validation accuracy : 0.9665271966527197\n",
      "Epoch 80:\t train loss : 0.5583691525088026; train accuracy : 0.9931165773413054; \n",
      " validation loss : 0.5852659817204917; validation accuracy : 0.9665271966527197\n",
      "Epoch 81:\t train loss : 0.5671001266183607; train accuracy : 0.9840394683850181; \n",
      " validation loss : 0.5924450126954954; validation accuracy : 0.9581589958158996\n",
      "Epoch 82:\t train loss : 0.5609863400979215; train accuracy : 0.9903283868769168; \n",
      " validation loss : 0.5874746705132138; validation accuracy : 0.9623430962343096\n",
      "Epoch 83:\t train loss : 0.5570946333932214; train accuracy : 0.9943285107964931; \n",
      " validation loss : 0.6135557085962698; validation accuracy : 0.9372384937238494\n",
      "Epoch 84:\t train loss : 0.5742732573675722; train accuracy : 0.9767746832305834; \n",
      " validation loss : 0.6187523770887771; validation accuracy : 0.9288702928870293\n",
      "Epoch 85:\t train loss : 0.5679391346646036; train accuracy : 0.9831986740605347; \n",
      " validation loss : 0.6099277496730332; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.5620562223690799; train accuracy : 0.9891452647231946; \n",
      " validation loss : 0.5974935030007491; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5652592356665328; train accuracy : 0.9857411939651166; \n",
      " validation loss : 0.6205209757131233; validation accuracy : 0.9288702928870293\n",
      "Epoch 88:\t train loss : 0.5634154045118495; train accuracy : 0.9879488212150315; \n",
      " validation loss : 0.5937753659676288; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 88\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5709452234192002; Train accuracy : 0.9801669816289228; \n",
      " Validation loss : 0.5769295503099008; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 72 ! ---\n",
      "Epoch 1:\t train loss : 0.9689119435146702; train accuracy : 0.5579144335326374; \n",
      " validation loss : 0.8901770848136088; validation accuracy : 0.6276150627615062\n",
      "Epoch 2:\t train loss : 0.7981074358663782; train accuracy : 0.7486625979739149; \n",
      " validation loss : 0.7508136270165942; validation accuracy : 0.8117154811715481\n",
      "Epoch 3:\t train loss : 0.72403682173861; train accuracy : 0.8252758759565042; \n",
      " validation loss : 0.699034335312916; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.6886381208601534; train accuracy : 0.8608835465782707; \n",
      " validation loss : 0.697330787875478; validation accuracy : 0.8535564853556485\n",
      "Epoch 5:\t train loss : 0.6697972429007008; train accuracy : 0.8803816722946808; \n",
      " validation loss : 0.6857347343095488; validation accuracy : 0.8577405857740585\n",
      "Epoch 6:\t train loss : 0.6578029496555902; train accuracy : 0.8926924625917779; \n",
      " validation loss : 0.7139606381615794; validation accuracy : 0.8326359832635983\n",
      "Epoch 7:\t train loss : 0.6516818305214642; train accuracy : 0.8980519842622138; \n",
      " validation loss : 0.6596262898193871; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6333582677363477; train accuracy : 0.9177189504011897; \n",
      " validation loss : 0.6390672843619659; validation accuracy : 0.9163179916317992\n",
      "Epoch 9:\t train loss : 0.6265842870773172; train accuracy : 0.9239496266922768; \n",
      " validation loss : 0.6601908651303516; validation accuracy : 0.8870292887029289\n",
      "Epoch 10:\t train loss : 0.6225547623226346; train accuracy : 0.9278685832894451; \n",
      " validation loss : 0.6331141599933744; validation accuracy : 0.9205020920502092\n",
      "Epoch 11:\t train loss : 0.6116409325702736; train accuracy : 0.9395133058644939; \n",
      " validation loss : 0.6296753181171765; validation accuracy : 0.9205020920502092\n",
      "Epoch 12:\t train loss : 0.608361901284148; train accuracy : 0.9426732550574677; \n",
      " validation loss : 0.6330086203071785; validation accuracy : 0.9163179916317992\n",
      "Epoch 13:\t train loss : 0.6007891049054994; train accuracy : 0.9506601815421791; \n",
      " validation loss : 0.6357742100452719; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5963788707437633; train accuracy : 0.954718547662567; \n",
      " validation loss : 0.6423665661932254; validation accuracy : 0.899581589958159\n",
      "Epoch 15:\t train loss : 0.602934621353089; train accuracy : 0.9479670993525202; \n",
      " validation loss : 0.6355054651205372; validation accuracy : 0.9121338912133892\n",
      "Epoch 16:\t train loss : 0.595252183904377; train accuracy : 0.9558418786207751; \n",
      " validation loss : 0.6111204305443911; validation accuracy : 0.9372384937238494\n",
      "Epoch 17:\t train loss : 0.5883486441761425; train accuracy : 0.9626243068248707; \n",
      " validation loss : 0.6363054300221744; validation accuracy : 0.9079497907949791\n",
      "Epoch 18:\t train loss : 0.5935021430431892; train accuracy : 0.9574469469314415; \n",
      " validation loss : 0.6396884471987409; validation accuracy : 0.9121338912133892\n",
      "Epoch 19:\t train loss : 0.5906885268404307; train accuracy : 0.96010161405248; \n",
      " validation loss : 0.6188811798214447; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5872188321414374; train accuracy : 0.9637395830106261; \n",
      " validation loss : 0.6099826444908657; validation accuracy : 0.9414225941422594\n",
      "Epoch 21:\t train loss : 0.5881233843365998; train accuracy : 0.9627482264010657; \n",
      " validation loss : 0.618152845293997; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5850481655289645; train accuracy : 0.9659081755940394; \n",
      " validation loss : 0.6298990969266941; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.5927153330649115; train accuracy : 0.9580606586325475; \n",
      " validation loss : 0.657253600365186; validation accuracy : 0.891213389121339\n",
      "Epoch 24:\t train loss : 0.5917541305402994; train accuracy : 0.9588837944174231; \n",
      " validation loss : 0.6246264243209947; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:\t train loss : 0.5798879563348041; train accuracy : 0.9712735834443447; \n",
      " validation loss : 0.6174737800702853; validation accuracy : 0.9288702928870293\n",
      "Epoch 26:\t train loss : 0.5800109068813208; train accuracy : 0.9711614362278881; \n",
      " validation loss : 0.6141118890583644; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5834960289286987; train accuracy : 0.9676569906130921; \n",
      " validation loss : 0.6283778336214461; validation accuracy : 0.9205020920502092\n",
      "Epoch 28:\t train loss : 0.5880185747486835; train accuracy : 0.9630137240930636; \n",
      " validation loss : 0.6319924520258926; validation accuracy : 0.9246861924686193\n",
      "Epoch 29:\t train loss : 0.5802935759123581; train accuracy : 0.9708671272344248; \n",
      " validation loss : 0.6227693850055948; validation accuracy : 0.9330543933054394\n",
      "Epoch 30:\t train loss : 0.5831111575740434; train accuracy : 0.9677691378295487; \n",
      " validation loss : 0.607298022485896; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5791839703710813; train accuracy : 0.9715545710833668; \n",
      " validation loss : 0.6247793200534235; validation accuracy : 0.9205020920502092\n",
      "Epoch 32:\t train loss : 0.5780923995298903; train accuracy : 0.9729619876700022; \n",
      " validation loss : 0.5986302261412842; validation accuracy : 0.9539748953974896\n",
      "Epoch 33:\t train loss : 0.5770430259854954; train accuracy : 0.9739378543325382; \n",
      " validation loss : 0.6130020495836197; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5734800185536273; train accuracy : 0.9779652405588772; \n",
      " validation loss : 0.6034470541117352; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.5740408582375703; train accuracy : 0.976759193283559; \n",
      " validation loss : 0.5960962466375965; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5707086608325691; train accuracy : 0.9804207069611822; \n",
      " validation loss : 0.5749417767862911; validation accuracy : 0.9748953974895398\n",
      "Epoch 37:\t train loss : 0.5701141035499102; train accuracy : 0.9811310759317203; \n",
      " validation loss : 0.6106363581713179; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5700315089016892; train accuracy : 0.981038136249574; \n",
      " validation loss : 0.5981294484735084; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5809288319722212; train accuracy : 0.9700771399361814; \n",
      " validation loss : 0.6183567532392461; validation accuracy : 0.9288702928870293\n",
      "Epoch 40:\t train loss : 0.5765301863075041; train accuracy : 0.9748074599584869; \n",
      " validation loss : 0.5910616176612643; validation accuracy : 0.9581589958158996\n",
      "Epoch 41:\t train loss : 0.5706610554447731; train accuracy : 0.9804030484215744; \n",
      " validation loss : 0.5946784667307601; validation accuracy : 0.9539748953974896\n",
      "Epoch 42:\t train loss : 0.5670942113782911; train accuracy : 0.9841073143529849; \n",
      " validation loss : 0.5920269356000879; validation accuracy : 0.9623430962343096\n",
      "Epoch 43:\t train loss : 0.569459413729307; train accuracy : 0.981715976331361; \n",
      " validation loss : 0.5923519811655142; validation accuracy : 0.9581589958158996\n",
      "Epoch 44:\t train loss : 0.5751446809750937; train accuracy : 0.9757037082933177; \n",
      " validation loss : 0.6041435666827198; validation accuracy : 0.9497907949790795\n",
      "Epoch 45:\t train loss : 0.5701678338378618; train accuracy : 0.9811214721645652; \n",
      " validation loss : 0.59229643992338; validation accuracy : 0.9581589958158996\n",
      "Epoch 46:\t train loss : 0.5703387576497055; train accuracy : 0.9807902970971839; \n",
      " validation loss : 0.617168222300649; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.5845770762279253; train accuracy : 0.9666634654109483; \n",
      " validation loss : 0.6273660799633254; validation accuracy : 0.9246861924686193\n",
      "Epoch 48:\t train loss : 0.5718730639435375; train accuracy : 0.979274450881378; \n",
      " validation loss : 0.6282275215806272; validation accuracy : 0.9246861924686193\n",
      "Epoch 49:\t train loss : 0.5703279418772798; train accuracy : 0.9808891229591995; \n",
      " validation loss : 0.6004218159022134; validation accuracy : 0.9539748953974896\n",
      "Epoch 50:\t train loss : 0.5690174443097693; train accuracy : 0.9822116546361411; \n",
      " validation loss : 0.5880184430112355; validation accuracy : 0.9665271966527197\n",
      "Epoch 51:\t train loss : 0.5703108252083036; train accuracy : 0.9807459958486942; \n",
      " validation loss : 0.5977194508137204; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5674174228352998; train accuracy : 0.9838380990737011; \n",
      " validation loss : 0.6103326504470327; validation accuracy : 0.9372384937238494\n",
      "Epoch 53:\t train loss : 0.5678378552588433; train accuracy : 0.9835032064190341; \n",
      " validation loss : 0.6057291188978009; validation accuracy : 0.9414225941422594\n",
      "Epoch 54:\t train loss : 0.5686328080551839; train accuracy : 0.9823916478205644; \n",
      " validation loss : 0.615565549383417; validation accuracy : 0.9330543933054394\n",
      "Epoch 55:\t train loss : 0.5664999562356134; train accuracy : 0.9847210260540908; \n",
      " validation loss : 0.6063949662747008; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5699778190728437; train accuracy : 0.9811679420056384; \n",
      " validation loss : 0.6047830577021656; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5724052145616331; train accuracy : 0.9786585705876886; \n",
      " validation loss : 0.6021281995754528; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5674078244925802; train accuracy : 0.9838845689147743; \n",
      " validation loss : 0.586867675838006; validation accuracy : 0.9623430962343096\n",
      "Epoch 59:\t train loss : 0.5699909540432172; train accuracy : 0.9811716595929242; \n",
      " validation loss : 0.6229618022391709; validation accuracy : 0.9288702928870293\n",
      "Epoch 60:\t train loss : 0.5768785633494797; train accuracy : 0.9738625731899997; \n",
      " validation loss : 0.616170707797766; validation accuracy : 0.9330543933054394\n",
      "Epoch 61:\t train loss : 0.5680203250530144; train accuracy : 0.9830849778493758; \n",
      " validation loss : 0.5912237126153811; validation accuracy : 0.9581589958158996\n",
      "Epoch 62:\t train loss : 0.5654537940485007; train accuracy : 0.985656309055423; \n",
      " validation loss : 0.5987866842506733; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.5736361988065598; train accuracy : 0.9775550667616717; \n",
      " validation loss : 0.6009959819317439; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5703772210526077; train accuracy : 0.9807902970971839; \n",
      " validation loss : 0.6221863464056011; validation accuracy : 0.9288702928870293\n",
      "Epoch 65:\t train loss : 0.5678823665990549; train accuracy : 0.9832590848539298; \n",
      " validation loss : 0.6269726753671675; validation accuracy : 0.9246861924686193\n",
      "Epoch 66:\t train loss : 0.5705480605410451; train accuracy : 0.9806685461135723; \n",
      " validation loss : 0.597291036895933; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5640385587968306; train accuracy : 0.9873174509743177; \n",
      " validation loss : 0.5912314336624671; validation accuracy : 0.9581589958158996\n",
      "Epoch 68:\t train loss : 0.5670375038481221; train accuracy : 0.9840645620991977; \n",
      " validation loss : 0.6088308952020927; validation accuracy : 0.9414225941422594\n",
      "Epoch 69:\t train loss : 0.5644897591817665; train accuracy : 0.9867715852411785; \n",
      " validation loss : 0.5979720082563318; validation accuracy : 0.9581589958158996\n",
      "Epoch 70:\t train loss : 0.5646580614628308; train accuracy : 0.9865547259828371; \n",
      " validation loss : 0.5908317465819968; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5660175126660804; train accuracy : 0.9851916106446916; \n",
      " validation loss : 0.5892514205742543; validation accuracy : 0.9623430962343096\n",
      "Epoch 72:\t train loss : 0.5636008307221613; train accuracy : 0.9877629418507389; \n",
      " validation loss : 0.6119195899903784; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5653125788213939; train accuracy : 0.9859912017100901; \n",
      " validation loss : 0.5979192555385504; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5683363652474357; train accuracy : 0.9827596889618637; \n",
      " validation loss : 0.6399026118046193; validation accuracy : 0.9121338912133892\n",
      "Epoch 75:\t train loss : 0.5646297311072516; train accuracy : 0.9866011958239103; \n",
      " validation loss : 0.6016797201462913; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76:\t train loss : 0.5662082046391811; train accuracy : 0.985005731280399; \n",
      " validation loss : 0.6063249842023362; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5609949641080287; train accuracy : 0.9902664270888194; \n",
      " validation loss : 0.6017992624176423; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5682639886905267; train accuracy : 0.9828600638185817; \n",
      " validation loss : 0.6113533909570569; validation accuracy : 0.9330543933054394\n",
      "Epoch 79:\t train loss : 0.5649372890559897; train accuracy : 0.9863047182378636; \n",
      " validation loss : 0.6159610043166933; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.5756521487526249; train accuracy : 0.9755045075745841; \n",
      " validation loss : 0.5937294052022147; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5833809459293021; train accuracy : 0.9676046345921497; \n",
      " validation loss : 0.621674854602479; validation accuracy : 0.9246861924686193\n",
      "Epoch 82:\t train loss : 0.5674293291568716; train accuracy : 0.983704575730351; \n",
      " validation loss : 0.5875099408088885; validation accuracy : 0.9665271966527197\n",
      "Epoch 83:\t train loss : 0.5648794670396287; train accuracy : 0.9863068868304471; \n",
      " validation loss : 0.609820759917399; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5641626725547946; train accuracy : 0.9871839276309675; \n",
      " validation loss : 0.6165128650052779; validation accuracy : 0.9330543933054394\n",
      "Epoch 85:\t train loss : 0.5644254027626922; train accuracy : 0.9868025651352272; \n",
      " validation loss : 0.6273842422854751; validation accuracy : 0.9246861924686193\n",
      "Epoch 86:\t train loss : 0.5632015989735446; train accuracy : 0.9880513646643329; \n",
      " validation loss : 0.6047573530954707; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 86\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5707086608325691; Train accuracy : 0.9804207069611822; \n",
      " Validation loss : 0.5749417767862911; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 73 ! ---\n",
      "Epoch 1:\t train loss : 0.9788625756189174; train accuracy : 0.54384367545463; \n",
      " validation loss : 0.898234720917506; validation accuracy : 0.6359832635983264\n",
      "Epoch 2:\t train loss : 0.8032068082792159; train accuracy : 0.7433436599646829; \n",
      " validation loss : 0.7689243844394693; validation accuracy : 0.7824267782426778\n",
      "Epoch 3:\t train loss : 0.7111048947907065; train accuracy : 0.8388974255708046; \n",
      " validation loss : 0.6988902423026672; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.6815247825733614; train accuracy : 0.8685805012546857; \n",
      " validation loss : 0.6756153074928555; validation accuracy : 0.8786610878661087\n",
      "Epoch 5:\t train loss : 0.65884791363893; train accuracy : 0.8919489451346077; \n",
      " validation loss : 0.6947117867618358; validation accuracy : 0.8451882845188284\n",
      "Epoch 6:\t train loss : 0.6467096890412598; train accuracy : 0.9035899501223705; \n",
      " validation loss : 0.657391353111698; validation accuracy : 0.9037656903765691\n",
      "Epoch 7:\t train loss : 0.6297054283913723; train accuracy : 0.920826543573221; \n",
      " validation loss : 0.677154261798751; validation accuracy : 0.8702928870292888\n",
      "Epoch 8:\t train loss : 0.6274463769687397; train accuracy : 0.9231831841135103; \n",
      " validation loss : 0.6417637123501595; validation accuracy : 0.899581589958159\n",
      "Epoch 9:\t train loss : 0.6122272417475257; train accuracy : 0.9387388085132748; \n",
      " validation loss : 0.6496906441167756; validation accuracy : 0.891213389121339\n",
      "Epoch 10:\t train loss : 0.606748446803166; train accuracy : 0.9440630131044951; \n",
      " validation loss : 0.6426981353561421; validation accuracy : 0.899581589958159\n",
      "Epoch 11:\t train loss : 0.6056285271695; train accuracy : 0.9448845998946683; \n",
      " validation loss : 0.6514964401207668; validation accuracy : 0.895397489539749\n",
      "Epoch 12:\t train loss : 0.6048985756366153; train accuracy : 0.9468031847331082; \n",
      " validation loss : 0.6447437602002797; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.5931009746227174; train accuracy : 0.9578283094271818; \n",
      " validation loss : 0.6448245910551433; validation accuracy : 0.9037656903765691\n",
      "Epoch 14:\t train loss : 0.5889061850146914; train accuracy : 0.962502555841259; \n",
      " validation loss : 0.6296818300285987; validation accuracy : 0.9205020920502092\n",
      "Epoch 15:\t train loss : 0.5873053459509608; train accuracy : 0.9638384088726416; \n",
      " validation loss : 0.6417445985300175; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.5867004927495837; train accuracy : 0.9645531150283466; \n",
      " validation loss : 0.6052507648027579; validation accuracy : 0.9456066945606695\n",
      "Epoch 17:\t train loss : 0.5931110720096257; train accuracy : 0.9575030205396697; \n",
      " validation loss : 0.6191409807086432; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.5846820572531425; train accuracy : 0.9665513181944918; \n",
      " validation loss : 0.6119814249325126; validation accuracy : 0.9414225941422594\n",
      "Epoch 19:\t train loss : 0.581090775846065; train accuracy : 0.9700402738622634; \n",
      " validation loss : 0.6119262207645528; validation accuracy : 0.9414225941422594\n",
      "Epoch 20:\t train loss : 0.580614340144652; train accuracy : 0.970551442114068; \n",
      " validation loss : 0.6110209907273779; validation accuracy : 0.9372384937238494\n",
      "Epoch 21:\t train loss : 0.5799222809868623; train accuracy : 0.9712794696242139; \n",
      " validation loss : 0.6232659363403055; validation accuracy : 0.9246861924686193\n",
      "Epoch 22:\t train loss : 0.5776323085574573; train accuracy : 0.9734170823135785; \n",
      " validation loss : 0.6178686939783922; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5772405598523633; train accuracy : 0.9737113913070418; \n",
      " validation loss : 0.604177279021255; validation accuracy : 0.9497907949790795\n",
      "Epoch 24:\t train loss : 0.5752050664085885; train accuracy : 0.9761005607360823; \n",
      " validation loss : 0.6095722382279233; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.5785019055487954; train accuracy : 0.9723910282226835; \n",
      " validation loss : 0.6243324358818843; validation accuracy : 0.9246861924686193\n",
      "Epoch 26:\t train loss : 0.5737195796262937; train accuracy : 0.9775646705288268; \n",
      " validation loss : 0.6094753414313251; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5717977854004058; train accuracy : 0.9796654171442734; \n",
      " validation loss : 0.6087332840550801; validation accuracy : 0.9456066945606695\n",
      "Epoch 28:\t train loss : 0.5756179509446384; train accuracy : 0.9756380309179342; \n",
      " validation loss : 0.6119332366543149; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.5773563051966156; train accuracy : 0.9737733510951393; \n",
      " validation loss : 0.6194664818606708; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.582208860976202; train accuracy : 0.968897735369745; \n",
      " validation loss : 0.6255593667815387; validation accuracy : 0.9288702928870293\n",
      "Epoch 31:\t train loss : 0.5798054913486492; train accuracy : 0.9711208525666842; \n",
      " validation loss : 0.6040286589109466; validation accuracy : 0.9456066945606695\n",
      "Epoch 32:\t train loss : 0.576162931523743; train accuracy : 0.9750803928250565; \n",
      " validation loss : 0.6393455279673766; validation accuracy : 0.9079497907949791\n",
      "Epoch 33:\t train loss : 0.5729377674512969; train accuracy : 0.9782093621239816; \n",
      " validation loss : 0.5972849769256857; validation accuracy : 0.9497907949790795\n",
      "Epoch 34:\t train loss : 0.5691939890358965; train accuracy : 0.9821091111868397; \n",
      " validation loss : 0.6052583660204951; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.5773394946135822; train accuracy : 0.9734908144614145; \n",
      " validation loss : 0.6363303810693044; validation accuracy : 0.9079497907949791\n",
      "Epoch 36:\t train loss : 0.578297653001566; train accuracy : 0.9728402366863905; \n",
      " validation loss : 0.6166816052782162; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5729262758583613; train accuracy : 0.9779770129186158; \n",
      " validation loss : 0.6193227800044839; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5725627786338039; train accuracy : 0.9788754298460299; \n",
      " validation loss : 0.6257652612071123; validation accuracy : 0.9205020920502092\n",
      "Epoch 39:\t train loss : 0.5745578729001511; train accuracy : 0.9764280182161778; \n",
      " validation loss : 0.6117682988719284; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40:\t train loss : 0.568422755514279; train accuracy : 0.9828002726230677; \n",
      " validation loss : 0.6418207830012246; validation accuracy : 0.9037656903765691\n",
      "Epoch 41:\t train loss : 0.5711788858085431; train accuracy : 0.9799014839369249; \n",
      " validation loss : 0.6326596800898371; validation accuracy : 0.9121338912133892\n",
      "Epoch 42:\t train loss : 0.569672398025053; train accuracy : 0.9816444127761083; \n",
      " validation loss : 0.6155888575756547; validation accuracy : 0.9288702928870293\n",
      "Epoch 43:\t train loss : 0.564130157600106; train accuracy : 0.9871374577898944; \n",
      " validation loss : 0.6153673812010108; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5647705870094621; train accuracy : 0.9867347191672604; \n",
      " validation loss : 0.6154392764107954; validation accuracy : 0.9330543933054394\n",
      "Epoch 45:\t train loss : 0.573776660229672; train accuracy : 0.9775027107407293; \n",
      " validation loss : 0.6162295385106963; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5704317911444408; train accuracy : 0.980662659933703; \n",
      " validation loss : 0.624514831100164; validation accuracy : 0.9246861924686193\n",
      "Epoch 47:\t train loss : 0.5665396143287165; train accuracy : 0.9847269122339601; \n",
      " validation loss : 0.6052761184713387; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5652120340109441; train accuracy : 0.9860435577310326; \n",
      " validation loss : 0.6074878343148842; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.5631382749024515; train accuracy : 0.988258620155519; \n",
      " validation loss : 0.6077456521033876; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5648729404536652; train accuracy : 0.9865237460887883; \n",
      " validation loss : 0.6050653331730955; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5638521439406252; train accuracy : 0.9874007868893089; \n",
      " validation loss : 0.6029902324615094; validation accuracy : 0.9456066945606695\n",
      "Epoch 52:\t train loss : 0.566783018899467; train accuracy : 0.9843861333994238; \n",
      " validation loss : 0.6027314529106427; validation accuracy : 0.9497907949790795\n",
      "Epoch 53:\t train loss : 0.5716674316827202; train accuracy : 0.9795687598748413; \n",
      " validation loss : 0.6298221070352232; validation accuracy : 0.9205020920502092\n",
      "Epoch 54:\t train loss : 0.563909812408475; train accuracy : 0.9873911831221537; \n",
      " validation loss : 0.6036120731497753; validation accuracy : 0.9456066945606695\n",
      "Epoch 55:\t train loss : 0.5665807356672568; train accuracy : 0.9845661265838471; \n",
      " validation loss : 0.6109591858976433; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.5662469907177917; train accuracy : 0.9849127915982527; \n",
      " validation loss : 0.6362742787782513; validation accuracy : 0.9121338912133892\n",
      "Epoch 57:\t train loss : 0.5774823974853063; train accuracy : 0.9733978747792682; \n",
      " validation loss : 0.6052777859618371; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5665288950250538; train accuracy : 0.9846029926577651; \n",
      " validation loss : 0.5938832308571411; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5634892997954596; train accuracy : 0.987822733046253; \n",
      " validation loss : 0.6117556029661643; validation accuracy : 0.9372384937238494\n",
      "Epoch 60:\t train loss : 0.563842719326646; train accuracy : 0.9874221630162024; \n",
      " validation loss : 0.6006225844805066; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5646335923249691; train accuracy : 0.9868062827225131; \n",
      " validation loss : 0.6098646549732126; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5637190562477433; train accuracy : 0.9874045044765947; \n",
      " validation loss : 0.620688483335186; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5633494432033102; train accuracy : 0.9878558815328852; \n",
      " validation loss : 0.6054429805075485; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5605276004084059; train accuracy : 0.9907968028749342; \n",
      " validation loss : 0.618575063933186; validation accuracy : 0.9246861924686193\n",
      "Epoch 65:\t train loss : 0.5728943941030086; train accuracy : 0.9781570061030391; \n",
      " validation loss : 0.6072915495093596; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5708904798825953; train accuracy : 0.9801146256079805; \n",
      " validation loss : 0.5996818538874277; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5680106516583614; train accuracy : 0.983228104959881; \n",
      " validation loss : 0.6096487430920714; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5674070734743811; train accuracy : 0.9835592800272623; \n",
      " validation loss : 0.58891824572597; validation accuracy : 0.9623430962343096\n",
      "Epoch 69:\t train loss : 0.5628404427910912; train accuracy : 0.9885625329161374; \n",
      " validation loss : 0.5934866047019216; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5646273323893616; train accuracy : 0.9865739335171474; \n",
      " validation loss : 0.6214519043322979; validation accuracy : 0.9246861924686193\n",
      "Epoch 71:\t train loss : 0.5692068067607651; train accuracy : 0.9818457820874252; \n",
      " validation loss : 0.6071142993600636; validation accuracy : 0.9456066945606695\n",
      "Epoch 72:\t train loss : 0.5590990947821647; train accuracy : 0.9921311069116143; \n",
      " validation loss : 0.5894112553572388; validation accuracy : 0.9623430962343096\n",
      "Epoch 73:\t train loss : 0.5587282363626901; train accuracy : 0.9924969794603302; \n",
      " validation loss : 0.6039509052006353; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.5679961589323302; train accuracy : 0.9831137891508411; \n",
      " validation loss : 0.605782155341356; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5605801346352319; train accuracy : 0.9907717091607546; \n",
      " validation loss : 0.6047964792158764; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5587742223263972; train accuracy : 0.9925744291954521; \n",
      " validation loss : 0.6210856863679095; validation accuracy : 0.9288702928870293\n",
      "Epoch 77:\t train loss : 0.5598475845598939; train accuracy : 0.9914960190836147; \n",
      " validation loss : 0.6007119420629522; validation accuracy : 0.9456066945606695\n",
      "Epoch 78:\t train loss : 0.5581329307737413; train accuracy : 0.993215403203321; \n",
      " validation loss : 0.5971138367587459; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.560083114504388; train accuracy : 0.9911744477833886; \n",
      " validation loss : 0.6100414028217799; validation accuracy : 0.9414225941422594\n",
      "Epoch 80:\t train loss : 0.5571034786920557; train accuracy : 0.994355773103256; \n",
      " validation loss : 0.6082259137724437; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.5599420515640544; train accuracy : 0.9913256296663465; \n",
      " validation loss : 0.6032184183039466; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5609808301884723; train accuracy : 0.9902723132686886; \n",
      " validation loss : 0.6020712146624111; validation accuracy : 0.9497907949790795\n",
      "Epoch 83:\t train loss : 0.5602852105672915; train accuracy : 0.9908764212026395; \n",
      " validation loss : 0.6041505299289711; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5616560721559399; train accuracy : 0.9894919297376003; \n",
      " validation loss : 0.6228625653098014; validation accuracy : 0.9246861924686193\n",
      "Epoch 85:\t train loss : 0.5629074867937446; train accuracy : 0.9882623377428049; \n",
      " validation loss : 0.5926200753787926; validation accuracy : 0.9623430962343096\n",
      "Epoch 86:\t train loss : 0.5691786004609584; train accuracy : 0.9819387217695715; \n",
      " validation loss : 0.5992515997095742; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5620802479896922; train accuracy : 0.9892072245112922; \n",
      " validation loss : 0.5867119869444345; validation accuracy : 0.9665271966527197\n",
      "Epoch 88:\t train loss : 0.5645267411727211; train accuracy : 0.9864868800148704; \n",
      " validation loss : 0.5897366545302892; validation accuracy : 0.9623430962343096\n",
      "Epoch 89:\t train loss : 0.5640630210454712; train accuracy : 0.9871721552712289; \n",
      " validation loss : 0.5988083466749864; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5596274993255426; train accuracy : 0.9917283682889805; \n",
      " validation loss : 0.5912765417248248; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91:\t train loss : 0.5715804927567902; train accuracy : 0.9795511013352334; \n",
      " validation loss : 0.5967185029504511; validation accuracy : 0.9539748953974896\n",
      "Epoch 92:\t train loss : 0.5596819243837713; train accuracy : 0.9916236562470956; \n",
      " validation loss : 0.5882603378600892; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5591183503835295; train accuracy : 0.9922085566467362; \n",
      " validation loss : 0.5923843131658291; validation accuracy : 0.9581589958158996\n",
      "Epoch 94:\t train loss : 0.5565835023474534; train accuracy : 0.9947798878527835; \n",
      " validation loss : 0.5890376907595539; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5575603147214441; train accuracy : 0.9938077387775334; \n",
      " validation loss : 0.605519660837724; validation accuracy : 0.9456066945606695\n",
      "Epoch 96:\t train loss : 0.5588782431421073; train accuracy : 0.9923730598841352; \n",
      " validation loss : 0.5988244863336635; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5569618779496255; train accuracy : 0.9943867529973047; \n",
      " validation loss : 0.5933064318976206; validation accuracy : 0.9581589958158996\n",
      "Epoch 98:\t train loss : 0.5572449310701877; train accuracy : 0.9941234238978902; \n",
      " validation loss : 0.60404698845315; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5587993602198362; train accuracy : 0.992564825428297; \n",
      " validation loss : 0.5772732937544613; validation accuracy : 0.9748953974895398\n",
      "Epoch 100:\t train loss : 0.5566122453009236; train accuracy : 0.9947953777998079; \n",
      " validation loss : 0.592845245871463; validation accuracy : 0.9581589958158996\n",
      "Epoch 101:\t train loss : 0.584142073873733; train accuracy : 0.9666789553579727; \n",
      " validation loss : 0.6104458754447275; validation accuracy : 0.9372384937238494\n",
      "Epoch 102:\t train loss : 0.5665533416549703; train accuracy : 0.9845388642770841; \n",
      " validation loss : 0.5981284336663919; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5569024444357487; train accuracy : 0.9945202763406549; \n",
      " validation loss : 0.5923294171252605; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.5577006917402879; train accuracy : 0.9937206852752564; \n",
      " validation loss : 0.5956819041298563; validation accuracy : 0.9539748953974896\n",
      "Epoch 105:\t train loss : 0.5575614813214064; train accuracy : 0.9936646116670281; \n",
      " validation loss : 0.6168419269130471; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.5563871793150632; train accuracy : 0.9948610551751913; \n",
      " validation loss : 0.6003455736176686; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5584455212359977; train accuracy : 0.9928687381889154; \n",
      " validation loss : 0.5974448431949341; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5563042512584094; train accuracy : 0.9950277270051736; \n",
      " validation loss : 0.5932657275352134; validation accuracy : 0.9581589958158996\n",
      "Epoch 109:\t train loss : 0.555197140415016; train accuracy : 0.9961835868521329; \n",
      " validation loss : 0.6002582573346011; validation accuracy : 0.9497907949790795\n",
      "Epoch 110:\t train loss : 0.5584516311030778; train accuracy : 0.9928281545277116; \n",
      " validation loss : 0.5982777258941201; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.5567552090961594; train accuracy : 0.9945571424145729; \n",
      " validation loss : 0.5979442244220351; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5573895389632951; train accuracy : 0.9938969608723938; \n",
      " validation loss : 0.6078739071498985; validation accuracy : 0.9414225941422594\n",
      "Epoch 113:\t train loss : 0.5605318229624564; train accuracy : 0.9907968028749342; \n",
      " validation loss : 0.6179082754833067; validation accuracy : 0.9372384937238494\n",
      "Epoch 114:\t train loss : 0.5700385174236237; train accuracy : 0.981038136249574; \n",
      " validation loss : 0.6089694930025203; validation accuracy : 0.9414225941422594\n",
      "Epoch 115:\t train loss : 0.5605297769678527; train accuracy : 0.9909479847578921; \n",
      " validation loss : 0.6018533172190634; validation accuracy : 0.9497907949790795\n",
      "Epoch 116:\t train loss : 0.5561899208438373; train accuracy : 0.9952232101366213; \n",
      " validation loss : 0.5921509435217623; validation accuracy : 0.9581589958158996\n",
      "Epoch 117:\t train loss : 0.5643603149927219; train accuracy : 0.9867347191672604; \n",
      " validation loss : 0.6061897556158973; validation accuracy : 0.9456066945606695\n",
      "Epoch 118:\t train loss : 0.5596580866247647; train accuracy : 0.991676012268038; \n",
      " validation loss : 0.6099792323192156; validation accuracy : 0.9414225941422594\n",
      "Epoch 119:\t train loss : 0.5581853865964432; train accuracy : 0.9931069735741503; \n",
      " validation loss : 0.6001854054887258; validation accuracy : 0.9497907949790795\n",
      "Epoch 120:\t train loss : 0.5609231258048696; train accuracy : 0.9903807428978593; \n",
      " validation loss : 0.5966606818517494; validation accuracy : 0.9539748953974896\n",
      "Epoch 121:\t train loss : 0.5619759860223863; train accuracy : 0.9892809566591282; \n",
      " validation loss : 0.6137894676894944; validation accuracy : 0.9372384937238494\n",
      "Epoch 122:\t train loss : 0.5570522587415849; train accuracy : 0.9942842095480033; \n",
      " validation loss : 0.6007089248909151; validation accuracy : 0.9497907949790795\n",
      "Epoch 123:\t train loss : 0.5580893850614461; train accuracy : 0.9931844233092723; \n",
      " validation loss : 0.6038608233449353; validation accuracy : 0.9456066945606695\n",
      "Epoch 124:\t train loss : 0.556727097395684; train accuracy : 0.9945320487003935; \n",
      " validation loss : 0.5864873706405268; validation accuracy : 0.9665271966527197\n",
      "Epoch 125:\t train loss : 0.5553990350434939; train accuracy : 0.9959881037206852; \n",
      " validation loss : 0.5991032483078382; validation accuracy : 0.9539748953974896\n",
      "Epoch 126:\t train loss : 0.5585748885256918; train accuracy : 0.9927352148455653; \n",
      " validation loss : 0.604697558859801; validation accuracy : 0.9456066945606695\n",
      "Epoch 127:\t train loss : 0.5569554659442236; train accuracy : 0.9943771492301496; \n",
      " validation loss : 0.5927118381839147; validation accuracy : 0.9581589958158996\n",
      "Epoch 128:\t train loss : 0.5561293052260647; train accuracy : 0.9952637937978251; \n",
      " validation loss : 0.6087289868053983; validation accuracy : 0.9414225941422594\n",
      "Epoch 129:\t train loss : 0.557199038365915; train accuracy : 0.9940518603426376; \n",
      " validation loss : 0.617421344351751; validation accuracy : 0.9330543933054394\n",
      "Epoch 130:\t train loss : 0.5551125513606169; train accuracy : 0.9962824127141485; \n",
      " validation loss : 0.5955873926226639; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5587324596806917; train accuracy : 0.9927116701260882; \n",
      " validation loss : 0.624273844412606; validation accuracy : 0.9288702928870293\n",
      "Epoch 132:\t train loss : 0.5625803808614684; train accuracy : 0.9886282102915208; \n",
      " validation loss : 0.6019177147179103; validation accuracy : 0.9497907949790795\n",
      "Epoch 133:\t train loss : 0.5610439706439022; train accuracy : 0.9902391647820564; \n",
      " validation loss : 0.6115894474750506; validation accuracy : 0.9414225941422594\n",
      "Epoch 134:\t train loss : 0.557050660602505; train accuracy : 0.994154403791939; \n",
      " validation loss : 0.5783731434745432; validation accuracy : 0.9748953974895398\n",
      "Epoch 135:\t train loss : 0.5624813717962401; train accuracy : 0.9886709625453081; \n",
      " validation loss : 0.5815443701792898; validation accuracy : 0.9707112970711297\n",
      "Epoch 136:\t train loss : 0.5569550168414287; train accuracy : 0.9942879271352891; \n",
      " validation loss : 0.6050485042061755; validation accuracy : 0.9456066945606695\n",
      "Epoch 137:\t train loss : 0.5560245454976798; train accuracy : 0.9953994857337588; \n",
      " validation loss : 0.5921183718491821; validation accuracy : 0.9581589958158996\n",
      "Epoch 138:\t train loss : 0.557870235219357; train accuracy : 0.9934883360698906; \n",
      " validation loss : 0.5962967115949777; validation accuracy : 0.9497907949790795\n",
      "Epoch 139:\t train loss : 0.555708889783916; train accuracy : 0.9956879085473528; \n",
      " validation loss : 0.6067908142349686; validation accuracy : 0.9414225941422594\n",
      "Epoch 140:\t train loss : 0.556290395468811; train accuracy : 0.9950587068992224; \n",
      " validation loss : 0.6030670848560508; validation accuracy : 0.9497907949790795\n",
      "Epoch 141:\t train loss : 0.5583281145318715; train accuracy : 0.99301775147929; \n",
      " validation loss : 0.594362617519454; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142:\t train loss : 0.5627389493512744; train accuracy : 0.9884754794138604; \n",
      " validation loss : 0.6080844087804224; validation accuracy : 0.9414225941422594\n",
      "Epoch 143:\t train loss : 0.5672856520637416; train accuracy : 0.9840859382260913; \n",
      " validation loss : 0.6056313187121551; validation accuracy : 0.9456066945606695\n",
      "Epoch 144:\t train loss : 0.5594520599469394; train accuracy : 0.9917844418972087; \n",
      " validation loss : 0.5970284758994264; validation accuracy : 0.9539748953974896\n",
      "Epoch 145:\t train loss : 0.5558004469305063; train accuracy : 0.9956104588122309; \n",
      " validation loss : 0.58518240067936; validation accuracy : 0.9665271966527197\n",
      "Epoch 146:\t train loss : 0.5570803472371392; train accuracy : 0.9943034170823135; \n",
      " validation loss : 0.5796611529343433; validation accuracy : 0.9707112970711297\n",
      "Epoch 147:\t train loss : 0.560342155688934; train accuracy : 0.9909693608847857; \n",
      " validation loss : 0.5796335109941493; validation accuracy : 0.9707112970711297\n",
      "Epoch 148:\t train loss : 0.5576740837273397; train accuracy : 0.99374206140215; \n",
      " validation loss : 0.5999501662833056; validation accuracy : 0.9497907949790795\n",
      "Epoch 149:\t train loss : 0.5553640426039254; train accuracy : 0.9960035936677096; \n",
      " validation loss : 0.6212704970904359; validation accuracy : 0.9288702928870293\n",
      "Early stopping at epoch 149\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5587993602198362; Train accuracy : 0.992564825428297; \n",
      " Validation loss : 0.5772732937544613; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 74 ! ---\n",
      "Epoch 1:\t train loss : 0.9384939329259674; train accuracy : 0.5844728771027603; \n",
      " validation loss : 0.8181337148672696; validation accuracy : 0.7154811715481172\n",
      "Epoch 2:\t train loss : 0.7575288301163572; train accuracy : 0.7906812478701323; \n",
      " validation loss : 0.7386398444820681; validation accuracy : 0.8117154811715481\n",
      "Epoch 3:\t train loss : 0.7010489476280288; train accuracy : 0.8484897301651229; \n",
      " validation loss : 0.7024075233825307; validation accuracy : 0.8451882845188284\n",
      "Epoch 4:\t train loss : 0.6769050713060855; train accuracy : 0.873967595030825; \n",
      " validation loss : 0.7077635626798447; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.6655086144062388; train accuracy : 0.8843644474735897; \n",
      " validation loss : 0.6646682985727984; validation accuracy : 0.8870292887029289\n",
      "Epoch 6:\t train loss : 0.6568665956456656; train accuracy : 0.8928343505065213; \n",
      " validation loss : 0.6911738175334912; validation accuracy : 0.8451882845188284\n",
      "Epoch 7:\t train loss : 0.6439771221045546; train accuracy : 0.9063694662164256; \n",
      " validation loss : 0.6648103621435868; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6277299211792006; train accuracy : 0.9236872269896838; \n",
      " validation loss : 0.6736485927811201; validation accuracy : 0.8744769874476988\n",
      "Epoch 9:\t train loss : 0.6252562530854389; train accuracy : 0.9253880231729608; \n",
      " validation loss : 0.6558882138980636; validation accuracy : 0.891213389121339\n",
      "Epoch 10:\t train loss : 0.6123090979751706; train accuracy : 0.9385420861860653; \n",
      " validation loss : 0.6619327792789604; validation accuracy : 0.895397489539749\n",
      "Epoch 11:\t train loss : 0.6040834754291061; train accuracy : 0.9475014715449673; \n",
      " validation loss : 0.6559842751495053; validation accuracy : 0.895397489539749\n",
      "Epoch 12:\t train loss : 0.5992225730416134; train accuracy : 0.9520617119489452; \n",
      " validation loss : 0.6306696428852879; validation accuracy : 0.9121338912133892\n",
      "Epoch 13:\t train loss : 0.6028457826264544; train accuracy : 0.9478949161993866; \n",
      " validation loss : 0.6478127694498161; validation accuracy : 0.899581589958159\n",
      "Epoch 14:\t train loss : 0.591969762832068; train accuracy : 0.9594999845100529; \n",
      " validation loss : 0.6156545114203795; validation accuracy : 0.9372384937238494\n",
      "Epoch 15:\t train loss : 0.5864122178336222; train accuracy : 0.9650732674494253; \n",
      " validation loss : 0.6350744860897304; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.5878299762477371; train accuracy : 0.9635025868211531; \n",
      " validation loss : 0.6527294299922024; validation accuracy : 0.891213389121339\n",
      "Epoch 17:\t train loss : 0.5830221087143141; train accuracy : 0.9682239226741844; \n",
      " validation loss : 0.614940070678983; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.5800161106463116; train accuracy : 0.9713683819201339; \n",
      " validation loss : 0.6080345295719684; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5790927038970267; train accuracy : 0.9724805601164844; \n",
      " validation loss : 0.6138866381678453; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.5800024017011985; train accuracy : 0.9715108894327581; \n",
      " validation loss : 0.65702550532701; validation accuracy : 0.8828451882845189\n",
      "Epoch 21:\t train loss : 0.591680643608288; train accuracy : 0.9592676353046873; \n",
      " validation loss : 0.6244943915386625; validation accuracy : 0.9246861924686193\n",
      "Epoch 22:\t train loss : 0.5882057745762799; train accuracy : 0.9625886799467146; \n",
      " validation loss : 0.6363039337551235; validation accuracy : 0.9079497907949791\n",
      "Epoch 23:\t train loss : 0.5798901352615832; train accuracy : 0.9713497939837046; \n",
      " validation loss : 0.5934664881833739; validation accuracy : 0.9581589958158996\n",
      "Epoch 24:\t train loss : 0.5770892351180036; train accuracy : 0.9740574367235664; \n",
      " validation loss : 0.6219969149076755; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5713855823898709; train accuracy : 0.9799219306669971; \n",
      " validation loss : 0.5919514720807002; validation accuracy : 0.9623430962343096\n",
      "Epoch 26:\t train loss : 0.5708217421805019; train accuracy : 0.9805167446327333; \n",
      " validation loss : 0.5975317890696433; validation accuracy : 0.9539748953974896\n",
      "Epoch 27:\t train loss : 0.5720865839153215; train accuracy : 0.9790544936336317; \n",
      " validation loss : 0.6152256356554779; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5771928316316377; train accuracy : 0.9739211251897518; \n",
      " validation loss : 0.6083033247367841; validation accuracy : 0.9456066945606695\n",
      "Epoch 29:\t train loss : 0.5753692831677257; train accuracy : 0.9759007404194677; \n",
      " validation loss : 0.6197257987239577; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.5715544260960355; train accuracy : 0.9797205613556802; \n",
      " validation loss : 0.5975891408249729; validation accuracy : 0.9497907949790795\n",
      "Epoch 31:\t train loss : 0.5797689870253675; train accuracy : 0.9713745778989435; \n",
      " validation loss : 0.6495657756833231; validation accuracy : 0.899581589958159\n",
      "Epoch 32:\t train loss : 0.5796253850014714; train accuracy : 0.9713466959942997; \n",
      " validation loss : 0.6508438468909267; validation accuracy : 0.895397489539749\n",
      "Epoch 33:\t train loss : 0.5703631895295482; train accuracy : 0.9808451315096502; \n",
      " validation loss : 0.5962602670553101; validation accuracy : 0.9539748953974896\n",
      "Epoch 34:\t train loss : 0.5704564676881083; train accuracy : 0.9807986616685771; \n",
      " validation loss : 0.6215938588542769; validation accuracy : 0.9288702928870293\n",
      "Epoch 35:\t train loss : 0.5673578506490135; train accuracy : 0.9840329626072679; \n",
      " validation loss : 0.6196269000259974; validation accuracy : 0.9330543933054394\n",
      "Epoch 36:\t train loss : 0.5677901085199277; train accuracy : 0.9832212893831903; \n",
      " validation loss : 0.588944843404055; validation accuracy : 0.9623430962343096\n",
      "Epoch 37:\t train loss : 0.5726050562900357; train accuracy : 0.9784410917314663; \n",
      " validation loss : 0.5931984740892313; validation accuracy : 0.9581589958158996\n",
      "Epoch 38:\t train loss : 0.5666798606962296; train accuracy : 0.9844883670497847; \n",
      " validation loss : 0.6085887314218659; validation accuracy : 0.9414225941422594\n",
      "Epoch 39:\t train loss : 0.5654009860271354; train accuracy : 0.985783326621023; \n",
      " validation loss : 0.5965737728543652; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.5666988471976131; train accuracy : 0.9846184826047895; \n",
      " validation loss : 0.6137941013368012; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5722797190958622; train accuracy : 0.9787075188202856; \n",
      " validation loss : 0.6030630231534478; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.565320962431891; train accuracy : 0.9860900275721057; \n",
      " validation loss : 0.6165841835341473; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43:\t train loss : 0.5676020794123435; train accuracy : 0.9840515505436972; \n",
      " validation loss : 0.5986901803146455; validation accuracy : 0.9539748953974896\n",
      "Epoch 44:\t train loss : 0.5626110910222264; train accuracy : 0.9888131602589919; \n",
      " validation loss : 0.5851640326937473; validation accuracy : 0.9665271966527197\n",
      "Epoch 45:\t train loss : 0.5760911682652945; train accuracy : 0.9749155797887171; \n",
      " validation loss : 0.6319562918136091; validation accuracy : 0.9163179916317992\n",
      "Epoch 46:\t train loss : 0.580794240815637; train accuracy : 0.9701353821369931; \n",
      " validation loss : 0.6080974034181374; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5724886723286614; train accuracy : 0.9787942625236221; \n",
      " validation loss : 0.6448449149328994; validation accuracy : 0.9037656903765691\n",
      "Epoch 48:\t train loss : 0.5728648778968526; train accuracy : 0.9782335264413395; \n",
      " validation loss : 0.5953260513865561; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5728329544928897; train accuracy : 0.9783791319433688; \n",
      " validation loss : 0.6233752075716401; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5716094229939535; train accuracy : 0.9795563679172217; \n",
      " validation loss : 0.5959736478964777; validation accuracy : 0.9581589958158996\n",
      "Epoch 51:\t train loss : 0.5663912247382942; train accuracy : 0.9847145202763407; \n",
      " validation loss : 0.5888066970762124; validation accuracy : 0.9581589958158996\n",
      "Epoch 52:\t train loss : 0.5657633066335794; train accuracy : 0.9854766256699402; \n",
      " validation loss : 0.5950483190764846; validation accuracy : 0.9539748953974896\n",
      "Epoch 53:\t train loss : 0.5661150118566561; train accuracy : 0.9851265528671892; \n",
      " validation loss : 0.6051302047352355; validation accuracy : 0.9456066945606695\n",
      "Epoch 54:\t train loss : 0.5634102761605806; train accuracy : 0.9879116453421729; \n",
      " validation loss : 0.5926435343568844; validation accuracy : 0.9581589958158996\n",
      "Epoch 55:\t train loss : 0.563098036743175; train accuracy : 0.988085132748846; \n",
      " validation loss : 0.6053588192585085; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.5616649428319761; train accuracy : 0.9897270671334304; \n",
      " validation loss : 0.599692208483042; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5638476858346995; train accuracy : 0.9875089067195391; \n",
      " validation loss : 0.6031030502406282; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.578682444423395; train accuracy : 0.9721986430806406; \n",
      " validation loss : 0.5923486498773088; validation accuracy : 0.9581589958158996\n",
      "Epoch 59:\t train loss : 0.5789265927343645; train accuracy : 0.9720871154620652; \n",
      " validation loss : 0.6107714466245125; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5705541086351491; train accuracy : 0.9806096843148796; \n",
      " validation loss : 0.5945229896316016; validation accuracy : 0.9539748953974896\n",
      "Epoch 61:\t train loss : 0.572060328106584; train accuracy : 0.9789863378667245; \n",
      " validation loss : 0.5974895492586059; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5694679087067346; train accuracy : 0.9816599027231326; \n",
      " validation loss : 0.604714888050528; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5696708260362684; train accuracy : 0.9815390811363425; \n",
      " validation loss : 0.5979871529516575; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5637168074305392; train accuracy : 0.9875894544440658; \n",
      " validation loss : 0.5868144334886204; validation accuracy : 0.9623430962343096\n",
      "Epoch 65:\t train loss : 0.5649400579328848; train accuracy : 0.9863006908516373; \n",
      " validation loss : 0.6022728561144415; validation accuracy : 0.9456066945606695\n",
      "Epoch 66:\t train loss : 0.5652566291201757; train accuracy : 0.9859227361442424; \n",
      " validation loss : 0.58887842751471; validation accuracy : 0.9623430962343096\n",
      "Epoch 67:\t train loss : 0.5631076279113899; train accuracy : 0.9881192106322997; \n",
      " validation loss : 0.6073483443681869; validation accuracy : 0.9372384937238494\n",
      "Epoch 68:\t train loss : 0.5640202566701736; train accuracy : 0.9872951454506026; \n",
      " validation loss : 0.5862125798187013; validation accuracy : 0.9665271966527197\n",
      "Epoch 69:\t train loss : 0.5647401757687248; train accuracy : 0.9866197837603395; \n",
      " validation loss : 0.6167472844972621; validation accuracy : 0.9330543933054394\n",
      "Epoch 70:\t train loss : 0.5656608447433381; train accuracy : 0.9855447814368475; \n",
      " validation loss : 0.5835407457938748; validation accuracy : 0.9665271966527197\n",
      "Epoch 71:\t train loss : 0.5650231114108243; train accuracy : 0.986282102915208; \n",
      " validation loss : 0.6265740190155739; validation accuracy : 0.9246861924686193\n",
      "Epoch 72:\t train loss : 0.564138559565726; train accuracy : 0.9871960097896465; \n",
      " validation loss : 0.5885756491107695; validation accuracy : 0.9623430962343096\n",
      "Epoch 73:\t train loss : 0.56399581793141; train accuracy : 0.9871929118002416; \n",
      " validation loss : 0.5828224276514403; validation accuracy : 0.9707112970711297\n",
      "Epoch 74:\t train loss : 0.5651698452238471; train accuracy : 0.9860528516992472; \n",
      " validation loss : 0.5957854489253528; validation accuracy : 0.9539748953974896\n",
      "Epoch 75:\t train loss : 0.569162050034091; train accuracy : 0.9820905232504105; \n",
      " validation loss : 0.6262290847517504; validation accuracy : 0.9246861924686193\n",
      "Epoch 76:\t train loss : 0.570363428203255; train accuracy : 0.9809287772235818; \n",
      " validation loss : 0.5929576907329573; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5658072908605016; train accuracy : 0.9854022739242232; \n",
      " validation loss : 0.6077141890075467; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5687706836334662; train accuracy : 0.9824746739366151; \n",
      " validation loss : 0.5890330113910519; validation accuracy : 0.9665271966527197\n",
      "Epoch 79:\t train loss : 0.5726927099671176; train accuracy : 0.9784441897208711; \n",
      " validation loss : 0.6121300908018623; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.5672355992579909; train accuracy : 0.9840856284271507; \n",
      " validation loss : 0.6068680855264569; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.5657396016911385; train accuracy : 0.9855540754050621; \n",
      " validation loss : 0.5985468390861962; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5644434122955079; train accuracy : 0.9868211530716565; \n",
      " validation loss : 0.5937090505443363; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5630177182831677; train accuracy : 0.9882090523250411; \n",
      " validation loss : 0.601713176344584; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5637563296008163; train accuracy : 0.9877443539143096; \n",
      " validation loss : 0.5811129232063293; validation accuracy : 0.9707112970711297\n",
      "Epoch 85:\t train loss : 0.5620935828289004; train accuracy : 0.9891477431147185; \n",
      " validation loss : 0.5923521471500217; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5645098503312148; train accuracy : 0.9866042938133152; \n",
      " validation loss : 0.6026225520927041; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.5618266636262679; train accuracy : 0.9894017782459184; \n",
      " validation loss : 0.5932520818608863; validation accuracy : 0.9581589958158996\n",
      "Epoch 88:\t train loss : 0.5602715640456455; train accuracy : 0.9910994764397906; \n",
      " validation loss : 0.5958955001108951; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5908901690464397; train accuracy : 0.9597230397472041; \n",
      " validation loss : 0.6021553990166543; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5796612126592978; train accuracy : 0.9713250100684656; \n",
      " validation loss : 0.6000279216789861; validation accuracy : 0.9497907949790795\n",
      "Epoch 91:\t train loss : 0.5718105993776058; train accuracy : 0.9793395086588804; \n",
      " validation loss : 0.6090133944413525; validation accuracy : 0.9414225941422594\n",
      "Epoch 92:\t train loss : 0.5637566920749107; train accuracy : 0.9874407509526317; \n",
      " validation loss : 0.608140126346419; validation accuracy : 0.9414225941422594\n",
      "Epoch 93:\t train loss : 0.5658833683748639; train accuracy : 0.9853496081043402; \n",
      " validation loss : 0.5873957261253714; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94:\t train loss : 0.5617869343860072; train accuracy : 0.9895195018433037; \n",
      " validation loss : 0.5981748317611265; validation accuracy : 0.9539748953974896\n",
      "Epoch 95:\t train loss : 0.5628726145790022; train accuracy : 0.9883639517952849; \n",
      " validation loss : 0.5976175489007556; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5637793155003287; train accuracy : 0.9875212986771585; \n",
      " validation loss : 0.5939728708071267; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5606590174697504; train accuracy : 0.9908516372874004; \n",
      " validation loss : 0.5829974328308611; validation accuracy : 0.9665271966527197\n",
      "Epoch 98:\t train loss : 0.5630664058583493; train accuracy : 0.9882276402614703; \n",
      " validation loss : 0.6127922268638085; validation accuracy : 0.9372384937238494\n",
      "Epoch 99:\t train loss : 0.5652116378278724; train accuracy : 0.9860466557204375; \n",
      " validation loss : 0.6096022417167728; validation accuracy : 0.9372384937238494\n",
      "Epoch 100:\t train loss : 0.5652430278452312; train accuracy : 0.9860249697946033; \n",
      " validation loss : 0.5943302661248875; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5621018195720164; train accuracy : 0.9891446451253136; \n",
      " validation loss : 0.5725842824935508; validation accuracy : 0.9790794979079498\n",
      "Epoch 102:\t train loss : 0.5628419642557394; train accuracy : 0.9883174819542118; \n",
      " validation loss : 0.5824148081712326; validation accuracy : 0.9707112970711297\n",
      "Epoch 103:\t train loss : 0.561439151928607; train accuracy : 0.9898138108367669; \n",
      " validation loss : 0.5960578022111845; validation accuracy : 0.9539748953974896\n",
      "Epoch 104:\t train loss : 0.5632188637984594; train accuracy : 0.9880293689395582; \n",
      " validation loss : 0.6204457919131905; validation accuracy : 0.9288702928870293\n",
      "Epoch 105:\t train loss : 0.5623484071839068; train accuracy : 0.9890486074537626; \n",
      " validation loss : 0.6008515161824478; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.5611770333386241; train accuracy : 0.9901390997242789; \n",
      " validation loss : 0.5928718892337733; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5668451175365954; train accuracy : 0.9842219399609653; \n",
      " validation loss : 0.6061370662398359; validation accuracy : 0.9456066945606695\n",
      "Epoch 108:\t train loss : 0.56057065606675; train accuracy : 0.9907494036370396; \n",
      " validation loss : 0.5873372158731001; validation accuracy : 0.9623430962343096\n",
      "Epoch 109:\t train loss : 0.5663698189158483; train accuracy : 0.9848756157253942; \n",
      " validation loss : 0.605618612090094; validation accuracy : 0.9456066945606695\n",
      "Epoch 110:\t train loss : 0.5602857195563957; train accuracy : 0.9909755568635955; \n",
      " validation loss : 0.5861873539600642; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5585414032892688; train accuracy : 0.9929148982310481; \n",
      " validation loss : 0.5834166841369667; validation accuracy : 0.9665271966527197\n",
      "Epoch 112:\t train loss : 0.5605554794866433; train accuracy : 0.9907865795098981; \n",
      " validation loss : 0.6029169809665043; validation accuracy : 0.9497907949790795\n",
      "Epoch 113:\t train loss : 0.5605367791021744; train accuracy : 0.9907710895628737; \n",
      " validation loss : 0.5971034643845136; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5616651934185622; train accuracy : 0.9896651073453329; \n",
      " validation loss : 0.6042667654610699; validation accuracy : 0.9456066945606695\n",
      "Epoch 115:\t train loss : 0.5636365026313924; train accuracy : 0.9876359242851389; \n",
      " validation loss : 0.5823802522945356; validation accuracy : 0.9707112970711297\n",
      "Epoch 116:\t train loss : 0.5627116521820112; train accuracy : 0.9885126552867189; \n",
      " validation loss : 0.5961112256351602; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.559728836195388; train accuracy : 0.9915208029988537; \n",
      " validation loss : 0.604752429870782; validation accuracy : 0.9456066945606695\n",
      "Epoch 118:\t train loss : 0.5577706261858087; train accuracy : 0.993543790080238; \n",
      " validation loss : 0.6066772395236041; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5607241280108854; train accuracy : 0.9904922705164348; \n",
      " validation loss : 0.6017285763139529; validation accuracy : 0.9497907949790795\n",
      "Epoch 120:\t train loss : 0.5591495253441848; train accuracy : 0.992189968710307; \n",
      " validation loss : 0.60550044224124; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5573380604955042; train accuracy : 0.9939310387558474; \n",
      " validation loss : 0.6081116858863046; validation accuracy : 0.9414225941422594\n",
      "Epoch 122:\t train loss : 0.557697556718169; train accuracy : 0.9936057498683354; \n",
      " validation loss : 0.5917086455212196; validation accuracy : 0.9581589958158996\n",
      "Epoch 123:\t train loss : 0.563521190223473; train accuracy : 0.987759843861334; \n",
      " validation loss : 0.6023824131316439; validation accuracy : 0.9456066945606695\n",
      "Epoch 124:\t train loss : 0.5592550604840084; train accuracy : 0.9920567551658973; \n",
      " validation loss : 0.591911656136811; validation accuracy : 0.9581589958158996\n",
      "Epoch 125:\t train loss : 0.5579863208545712; train accuracy : 0.9934632423557112; \n",
      " validation loss : 0.5977644422581617; validation accuracy : 0.9539748953974896\n",
      "Epoch 126:\t train loss : 0.558202536189973; train accuracy : 0.9931131695529601; \n",
      " validation loss : 0.5900860895033482; validation accuracy : 0.9623430962343096\n",
      "Epoch 127:\t train loss : 0.5569534196718166; train accuracy : 0.9943988351559837; \n",
      " validation loss : 0.5954519256808609; validation accuracy : 0.9539748953974896\n",
      "Epoch 128:\t train loss : 0.5569891825313084; train accuracy : 0.994392639177174; \n",
      " validation loss : 0.5936572650088873; validation accuracy : 0.9581589958158996\n",
      "Epoch 129:\t train loss : 0.5574009920383198; train accuracy : 0.993915548808823; \n",
      " validation loss : 0.5933465607740045; validation accuracy : 0.9581589958158996\n",
      "Epoch 130:\t train loss : 0.5596717481331159; train accuracy : 0.9915331949564733; \n",
      " validation loss : 0.6045220873741664; validation accuracy : 0.9456066945606695\n",
      "Epoch 131:\t train loss : 0.5576980331249572; train accuracy : 0.9936491217200037; \n",
      " validation loss : 0.5957465751992717; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5579552137007573; train accuracy : 0.9933826946311843; \n",
      " validation loss : 0.5944832234984094; validation accuracy : 0.9581589958158996\n",
      "Epoch 133:\t train loss : 0.558472987896277; train accuracy : 0.9927259208773506; \n",
      " validation loss : 0.5933363457838502; validation accuracy : 0.9581589958158996\n",
      "Epoch 134:\t train loss : 0.560189913124048; train accuracy : 0.9910870844821711; \n",
      " validation loss : 0.5925099099548721; validation accuracy : 0.9581589958158996\n",
      "Epoch 135:\t train loss : 0.5627291312075248; train accuracy : 0.988459989466836; \n",
      " validation loss : 0.6137644356675265; validation accuracy : 0.9372384937238494\n",
      "Epoch 136:\t train loss : 0.5608551184263383; train accuracy : 0.9904179187707178; \n",
      " validation loss : 0.586084701636209; validation accuracy : 0.9665271966527197\n",
      "Epoch 137:\t train loss : 0.5608529617061214; train accuracy : 0.9904241147495275; \n",
      " validation loss : 0.5933230268760347; validation accuracy : 0.9581589958158996\n",
      "Epoch 138:\t train loss : 0.5581920656434965; train accuracy : 0.9931317574893894; \n",
      " validation loss : 0.5936901947398595; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5566754205678327; train accuracy : 0.9946621642553982; \n",
      " validation loss : 0.5933159984990852; validation accuracy : 0.9581589958158996\n",
      "Epoch 140:\t train loss : 0.5569222806736186; train accuracy : 0.9943740512407447; \n",
      " validation loss : 0.5890338881229621; validation accuracy : 0.9623430962343096\n",
      "Epoch 141:\t train loss : 0.5632200662214087; train accuracy : 0.9879643111620559; \n",
      " validation loss : 0.6059055596945028; validation accuracy : 0.9456066945606695\n",
      "Epoch 142:\t train loss : 0.5580394077498755; train accuracy : 0.9933548127265405; \n",
      " validation loss : 0.5714683039145924; validation accuracy : 0.9790794979079498\n",
      "Epoch 143:\t train loss : 0.5562392411137261; train accuracy : 0.995191920443632; \n",
      " validation loss : 0.5870087474423328; validation accuracy : 0.9623430962343096\n",
      "Epoch 144:\t train loss : 0.5561742418378826; train accuracy : 0.9951795284860125; \n",
      " validation loss : 0.5848752098224361; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145:\t train loss : 0.5560050607244251; train accuracy : 0.9954149756807832; \n",
      " validation loss : 0.6057027585668802; validation accuracy : 0.9456066945606695\n",
      "Epoch 146:\t train loss : 0.5600855625027374; train accuracy : 0.9912233960159856; \n",
      " validation loss : 0.586716664697859; validation accuracy : 0.9665271966527197\n",
      "Epoch 147:\t train loss : 0.5574656367556038; train accuracy : 0.9939093528300134; \n",
      " validation loss : 0.5763987977086643; validation accuracy : 0.9748953974895398\n",
      "Epoch 148:\t train loss : 0.5555683286509252; train accuracy : 0.9959075559961584; \n",
      " validation loss : 0.5823854977154406; validation accuracy : 0.9665271966527197\n",
      "Epoch 149:\t train loss : 0.5547538848879255; train accuracy : 0.9966541714427336; \n",
      " validation loss : 0.6039181230575409; validation accuracy : 0.9456066945606695\n",
      "Epoch 150:\t train loss : 0.5589136542990513; train accuracy : 0.9924006319898386; \n",
      " validation loss : 0.5847534778328558; validation accuracy : 0.9665271966527197\n",
      "Epoch 151:\t train loss : 0.5571964358308688; train accuracy : 0.994191269865857; \n",
      " validation loss : 0.6026064871805887; validation accuracy : 0.9456066945606695\n",
      "Epoch 152:\t train loss : 0.5615977119998634; train accuracy : 0.9896434214194988; \n",
      " validation loss : 0.5986736411200827; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.5637515348690029; train accuracy : 0.9876204343381145; \n",
      " validation loss : 0.5974033505074708; validation accuracy : 0.9539748953974896\n",
      "Epoch 154:\t train loss : 0.5569946973906907; train accuracy : 0.9942563276433595; \n",
      " validation loss : 0.6122438886862174; validation accuracy : 0.9372384937238494\n",
      "Epoch 155:\t train loss : 0.5587249247622804; train accuracy : 0.9926174912481799; \n",
      " validation loss : 0.5883078221383357; validation accuracy : 0.9623430962343096\n",
      "Epoch 156:\t train loss : 0.5572684458401141; train accuracy : 0.9940363703956132; \n",
      " validation loss : 0.6019561764634486; validation accuracy : 0.9497907949790795\n",
      "Epoch 157:\t train loss : 0.5571443909351795; train accuracy : 0.9942346417175253; \n",
      " validation loss : 0.6013656886215493; validation accuracy : 0.9456066945606695\n",
      "Epoch 158:\t train loss : 0.5557880663232868; train accuracy : 0.9955079153629295; \n",
      " validation loss : 0.5980260866304352; validation accuracy : 0.9539748953974896\n",
      "Epoch 159:\t train loss : 0.5549737101698549; train accuracy : 0.9964744880572508; \n",
      " validation loss : 0.6011719842439519; validation accuracy : 0.9497907949790795\n",
      "Epoch 160:\t train loss : 0.5544434321438567; train accuracy : 0.9969144025527432; \n",
      " validation loss : 0.5848822096627818; validation accuracy : 0.9665271966527197\n",
      "Epoch 161:\t train loss : 0.5610400716894789; train accuracy : 0.990213451469996; \n",
      " validation loss : 0.616778252860965; validation accuracy : 0.9330543933054394\n",
      "Epoch 162:\t train loss : 0.5595755288607361; train accuracy : 0.9916818984479073; \n",
      " validation loss : 0.6092298765329937; validation accuracy : 0.9414225941422594\n",
      "Epoch 163:\t train loss : 0.5563790858929669; train accuracy : 0.9949812571641005; \n",
      " validation loss : 0.5958210790773628; validation accuracy : 0.9581589958158996\n",
      "Epoch 164:\t train loss : 0.5581744177001265; train accuracy : 0.9931596393940333; \n",
      " validation loss : 0.6117087008569682; validation accuracy : 0.9372384937238494\n",
      "Epoch 165:\t train loss : 0.5554024812938874; train accuracy : 0.9959168499643731; \n",
      " validation loss : 0.5965944015812983; validation accuracy : 0.9539748953974896\n",
      "Epoch 166:\t train loss : 0.5546847486366158; train accuracy : 0.9966541714427336; \n",
      " validation loss : 0.6100868880980811; validation accuracy : 0.9414225941422594\n",
      "Epoch 167:\t train loss : 0.5579168746598004; train accuracy : 0.9934384584404721; \n",
      " validation loss : 0.6072155869472436; validation accuracy : 0.9456066945606695\n",
      "Epoch 168:\t train loss : 0.5561888005568106; train accuracy : 0.9952972520833978; \n",
      " validation loss : 0.617378357621826; validation accuracy : 0.9330543933054394\n",
      "Epoch 169:\t train loss : 0.556215309347966; train accuracy : 0.995219802348276; \n",
      " validation loss : 0.5948732749123903; validation accuracy : 0.9539748953974896\n",
      "Epoch 170:\t train loss : 0.553775389281669; train accuracy : 0.9977074878403915; \n",
      " validation loss : 0.6074570997026456; validation accuracy : 0.9456066945606695\n",
      "Epoch 171:\t train loss : 0.5571083511750927; train accuracy : 0.9942284457387156; \n",
      " validation loss : 0.5954011932495338; validation accuracy : 0.9539748953974896\n",
      "Epoch 172:\t train loss : 0.5622448095958037; train accuracy : 0.9890486074537626; \n",
      " validation loss : 0.5936888847637585; validation accuracy : 0.9581589958158996\n",
      "Epoch 173:\t train loss : 0.5568445463841747; train accuracy : 0.9946002044673007; \n",
      " validation loss : 0.5824771872463176; validation accuracy : 0.9707112970711297\n",
      "Epoch 174:\t train loss : 0.5561052342592155; train accuracy : 0.9953220359986369; \n",
      " validation loss : 0.6027473633900782; validation accuracy : 0.9497907949790795\n",
      "Epoch 175:\t train loss : 0.5570873048734503; train accuracy : 0.99424393568574; \n",
      " validation loss : 0.5950933323661944; validation accuracy : 0.9497907949790795\n",
      "Epoch 176:\t train loss : 0.5556020801273168; train accuracy : 0.995644226896744; \n",
      " validation loss : 0.5837683618174712; validation accuracy : 0.9665271966527197\n",
      "Epoch 177:\t train loss : 0.5621492220576418; train accuracy : 0.9892499767650794; \n",
      " validation loss : 0.6049241632111132; validation accuracy : 0.9456066945606695\n",
      "Epoch 178:\t train loss : 0.5567557091054224; train accuracy : 0.9945382446792032; \n",
      " validation loss : 0.6043827792628214; validation accuracy : 0.9456066945606695\n",
      "Epoch 179:\t train loss : 0.5572609757708035; train accuracy : 0.9940518603426376; \n",
      " validation loss : 0.5843369400149963; validation accuracy : 0.9665271966527197\n",
      "Epoch 180:\t train loss : 0.5554975838417466; train accuracy : 0.995895164038539; \n",
      " validation loss : 0.5820308356661463; validation accuracy : 0.9707112970711297\n",
      "Epoch 181:\t train loss : 0.5591337126691086; train accuracy : 0.9922736144242387; \n",
      " validation loss : 0.6264614821788955; validation accuracy : 0.9246861924686193\n",
      "Epoch 182:\t train loss : 0.5585302821354197; train accuracy : 0.9929118002416432; \n",
      " validation loss : 0.6007127702246574; validation accuracy : 0.9497907949790795\n",
      "Epoch 183:\t train loss : 0.5578863616460557; train accuracy : 0.9933981845782087; \n",
      " validation loss : 0.5977904775504469; validation accuracy : 0.9539748953974896\n",
      "Epoch 184:\t train loss : 0.5573925053479853; train accuracy : 0.9940208804485888; \n",
      " validation loss : 0.5861737457444771; validation accuracy : 0.9665271966527197\n",
      "Epoch 185:\t train loss : 0.5557079097720713; train accuracy : 0.9957402645682951; \n",
      " validation loss : 0.5765493739211063; validation accuracy : 0.9748953974895398\n",
      "Epoch 186:\t train loss : 0.5540043477266303; train accuracy : 0.9973791009634747; \n",
      " validation loss : 0.6001402373740936; validation accuracy : 0.9497907949790795\n",
      "Epoch 187:\t train loss : 0.5563014572933019; train accuracy : 0.9950803928250566; \n",
      " validation loss : 0.5874372249994549; validation accuracy : 0.9623430962343096\n",
      "Epoch 188:\t train loss : 0.5580697285700419; train accuracy : 0.9932092072245112; \n",
      " validation loss : 0.5875241903681301; validation accuracy : 0.9623430962343096\n",
      "Epoch 189:\t train loss : 0.5570979645872577; train accuracy : 0.9942129557916912; \n",
      " validation loss : 0.6015815802137296; validation accuracy : 0.9497907949790795\n",
      "Epoch 190:\t train loss : 0.5538180471113693; train accuracy : 0.997620744137055; \n",
      " validation loss : 0.5765549908629034; validation accuracy : 0.9748953974895398\n",
      "Epoch 191:\t train loss : 0.554322947645864; train accuracy : 0.9970569100653676; \n",
      " validation loss : 0.5876672796799366; validation accuracy : 0.9623430962343096\n",
      "Epoch 192:\t train loss : 0.5538223664979972; train accuracy : 0.9976300381052696; \n",
      " validation loss : 0.5723667004636827; validation accuracy : 0.9790794979079498\n",
      "Early stopping at epoch 192\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5580394077498755; Train accuracy : 0.9933548127265405; \n",
      " Validation loss : 0.5714683039145924; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 75 ! ---\n",
      "Epoch 1:\t train loss : 0.9860176897480321; train accuracy : 0.5396418724247963; \n",
      " validation loss : 0.8866990347433991; validation accuracy : 0.6485355648535565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\t train loss : 0.7978187873737321; train accuracy : 0.7495678304780198; \n",
      " validation loss : 0.7012459225162564; validation accuracy : 0.8535564853556485\n",
      "Epoch 3:\t train loss : 0.7224153844980815; train accuracy : 0.8273924223179157; \n",
      " validation loss : 0.6896579900603166; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.7011290411692543; train accuracy : 0.8485981597942935; \n",
      " validation loss : 0.6578346490248668; validation accuracy : 0.891213389121339\n",
      "Epoch 5:\t train loss : 0.6818666290362251; train accuracy : 0.8675764428885653; \n",
      " validation loss : 0.669907173532823; validation accuracy : 0.8828451882845189\n",
      "Epoch 6:\t train loss : 0.6731851682391281; train accuracy : 0.8762384212645993; \n",
      " validation loss : 0.6684607051132596; validation accuracy : 0.891213389121339\n",
      "Epoch 7:\t train loss : 0.6637838568701656; train accuracy : 0.886433904396047; \n",
      " validation loss : 0.6259639916181405; validation accuracy : 0.9163179916317992\n",
      "Epoch 8:\t train loss : 0.6508146631560192; train accuracy : 0.8991325629666347; \n",
      " validation loss : 0.6323901356608902; validation accuracy : 0.9246861924686193\n",
      "Epoch 9:\t train loss : 0.6455019498464593; train accuracy : 0.9050714086557824; \n",
      " validation loss : 0.6308797841971685; validation accuracy : 0.9205020920502092\n",
      "Epoch 10:\t train loss : 0.6364118977059126; train accuracy : 0.9138820905232504; \n",
      " validation loss : 0.6191126556232762; validation accuracy : 0.9372384937238494\n",
      "Epoch 11:\t train loss : 0.6226094692712595; train accuracy : 0.9282908392453297; \n",
      " validation loss : 0.6151156656094164; validation accuracy : 0.9372384937238494\n",
      "Epoch 12:\t train loss : 0.617246934273966; train accuracy : 0.933616283032312; \n",
      " validation loss : 0.6255804021344412; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.6099041698233129; train accuracy : 0.9411041234238979; \n",
      " validation loss : 0.6042450237644885; validation accuracy : 0.9414225941422594\n",
      "Epoch 14:\t train loss : 0.6077137172321955; train accuracy : 0.94330369590136; \n",
      " validation loss : 0.6295090677791624; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5991166454066852; train accuracy : 0.9521453576628768; \n",
      " validation loss : 0.6159345592892722; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5984656864658972; train accuracy : 0.9526689178723009; \n",
      " validation loss : 0.5879015531811821; validation accuracy : 0.9665271966527197\n",
      "Epoch 17:\t train loss : 0.5936492757706457; train accuracy : 0.9573251959478298; \n",
      " validation loss : 0.6203441658297478; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.6000652087466904; train accuracy : 0.9507016946002045; \n",
      " validation loss : 0.5996597126711124; validation accuracy : 0.9497907949790795\n",
      "Epoch 19:\t train loss : 0.5905855177398044; train accuracy : 0.9604696551937792; \n",
      " validation loss : 0.6079374024408701; validation accuracy : 0.9372384937238494\n",
      "Epoch 20:\t train loss : 0.5896791850689231; train accuracy : 0.9614950896867933; \n",
      " validation loss : 0.6033823920391863; validation accuracy : 0.9414225941422594\n",
      "Epoch 21:\t train loss : 0.5927351182009521; train accuracy : 0.958248396790483; \n",
      " validation loss : 0.5812502335280834; validation accuracy : 0.9707112970711297\n",
      "Epoch 22:\t train loss : 0.5944891609321513; train accuracy : 0.9565785805012547; \n",
      " validation loss : 0.6035088924140808; validation accuracy : 0.9456066945606695\n",
      "Epoch 23:\t train loss : 0.5839318800452985; train accuracy : 0.9673193097679605; \n",
      " validation loss : 0.6077756475687361; validation accuracy : 0.9414225941422594\n",
      "Epoch 24:\t train loss : 0.5851152265219639; train accuracy : 0.9656711794045665; \n",
      " validation loss : 0.5972691805136002; validation accuracy : 0.9539748953974896\n",
      "Epoch 25:\t train loss : 0.5869608938921139; train accuracy : 0.964103596765699; \n",
      " validation loss : 0.5866049624513145; validation accuracy : 0.9665271966527197\n",
      "Epoch 26:\t train loss : 0.5873788436529828; train accuracy : 0.9637690139099724; \n",
      " validation loss : 0.617049733426307; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5808571658805064; train accuracy : 0.9706558443570122; \n",
      " validation loss : 0.6148223568578385; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5862124058536238; train accuracy : 0.964655038879767; \n",
      " validation loss : 0.6187243079640806; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5894309792946031; train accuracy : 0.9613216022801202; \n",
      " validation loss : 0.5928543901566695; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.5800817885407117; train accuracy : 0.9709191734564268; \n",
      " validation loss : 0.6031879504582195; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5746214144028647; train accuracy : 0.9764893584063943; \n",
      " validation loss : 0.6079764772375869; validation accuracy : 0.9414225941422594\n",
      "Epoch 32:\t train loss : 0.577850824848735; train accuracy : 0.9733944669909229; \n",
      " validation loss : 0.6206698595860877; validation accuracy : 0.9246861924686193\n",
      "Epoch 33:\t train loss : 0.575299810812568; train accuracy : 0.975869760525419; \n",
      " validation loss : 0.5890245256050984; validation accuracy : 0.9581589958158996\n",
      "Epoch 34:\t train loss : 0.5745977599254283; train accuracy : 0.9766597478236625; \n",
      " validation loss : 0.6270997391080017; validation accuracy : 0.9205020920502092\n",
      "Epoch 35:\t train loss : 0.5767107811156392; train accuracy : 0.9743207658229809; \n",
      " validation loss : 0.5984923662054654; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5821086512464491; train accuracy : 0.9688466185445646; \n",
      " validation loss : 0.6044324756953608; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.5764185853462952; train accuracy : 0.9745871929118003; \n",
      " validation loss : 0.5887697034156035; validation accuracy : 0.9623430962343096\n",
      "Epoch 38:\t train loss : 0.5724253985712437; train accuracy : 0.9788593203011245; \n",
      " validation loss : 0.5985832741505056; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5717961058259684; train accuracy : 0.9794169583940023; \n",
      " validation loss : 0.5762142132567803; validation accuracy : 0.9790794979079498\n",
      "Epoch 40:\t train loss : 0.5723074267173542; train accuracy : 0.9788221444282661; \n",
      " validation loss : 0.5974265162773514; validation accuracy : 0.9539748953974896\n",
      "Epoch 41:\t train loss : 0.5769264350796796; train accuracy : 0.9740977105858298; \n",
      " validation loss : 0.5876569757888864; validation accuracy : 0.9623430962343096\n",
      "Epoch 42:\t train loss : 0.5705049753198373; train accuracy : 0.980526038600948; \n",
      " validation loss : 0.5975072224987408; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.5710526433854816; train accuracy : 0.9801852597664116; \n",
      " validation loss : 0.6121002810489479; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5731407078073141; train accuracy : 0.9779423154372812; \n",
      " validation loss : 0.6230724791646989; validation accuracy : 0.9246861924686193\n",
      "Epoch 45:\t train loss : 0.5789066758897781; train accuracy : 0.9719322159918213; \n",
      " validation loss : 0.5916240037103209; validation accuracy : 0.9581589958158996\n",
      "Epoch 46:\t train loss : 0.5765731904845471; train accuracy : 0.9744911552402491; \n",
      " validation loss : 0.5665753512659781; validation accuracy : 0.9832635983263598\n",
      "Epoch 47:\t train loss : 0.5701983496730719; train accuracy : 0.9812168902382354; \n",
      " validation loss : 0.5743458574363577; validation accuracy : 0.9790794979079498\n",
      "Epoch 48:\t train loss : 0.5704889951198555; train accuracy : 0.9804795687598749; \n",
      " validation loss : 0.6027837023542935; validation accuracy : 0.9456066945606695\n",
      "Epoch 49:\t train loss : 0.5692371049725165; train accuracy : 0.9820905232504105; \n",
      " validation loss : 0.594058384074689; validation accuracy : 0.9581589958158996\n",
      "Epoch 50:\t train loss : 0.5787605166659001; train accuracy : 0.9721521732395675; \n",
      " validation loss : 0.5839555112567566; validation accuracy : 0.9665271966527197\n",
      "Epoch 51:\t train loss : 0.5822066807309313; train accuracy : 0.9685244276464574; \n",
      " validation loss : 0.6086719860824207; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5720681990710078; train accuracy : 0.9789398680256514; \n",
      " validation loss : 0.5979441299199953; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53:\t train loss : 0.5743876895209231; train accuracy : 0.9764986523746089; \n",
      " validation loss : 0.591790787423134; validation accuracy : 0.9623430962343096\n",
      "Epoch 54:\t train loss : 0.565430554530757; train accuracy : 0.985783326621023; \n",
      " validation loss : 0.6072624019587233; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.568352882277464; train accuracy : 0.9825645156293565; \n",
      " validation loss : 0.6002039607432573; validation accuracy : 0.9497907949790795\n",
      "Epoch 56:\t train loss : 0.5654077262667246; train accuracy : 0.9857926205892376; \n",
      " validation loss : 0.6076304417671687; validation accuracy : 0.9372384937238494\n",
      "Epoch 57:\t train loss : 0.5635201541210183; train accuracy : 0.987759843861334; \n",
      " validation loss : 0.5976846118148288; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.5675034050015421; train accuracy : 0.9836395179528487; \n",
      " validation loss : 0.5839858987432401; validation accuracy : 0.9707112970711297\n",
      "Epoch 59:\t train loss : 0.5654567538460797; train accuracy : 0.9857802286316181; \n",
      " validation loss : 0.5973698154579251; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5688249040582956; train accuracy : 0.9822671086464885; \n",
      " validation loss : 0.571122487895298; validation accuracy : 0.9832635983263598\n",
      "Epoch 61:\t train loss : 0.5659147062079599; train accuracy : 0.9854921156169646; \n",
      " validation loss : 0.5757202545686279; validation accuracy : 0.9748953974895398\n",
      "Epoch 62:\t train loss : 0.5633832631286521; train accuracy : 0.9878992533845534; \n",
      " validation loss : 0.6014089000631501; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5707465874951839; train accuracy : 0.9805012546857089; \n",
      " validation loss : 0.582931341458253; validation accuracy : 0.9665271966527197\n",
      "Epoch 64:\t train loss : 0.5695431113302807; train accuracy : 0.9816630007125375; \n",
      " validation loss : 0.6111442444023741; validation accuracy : 0.9372384937238494\n",
      "Epoch 65:\t train loss : 0.5662171636284626; train accuracy : 0.9850181232380185; \n",
      " validation loss : 0.5816127336186953; validation accuracy : 0.9707112970711297\n",
      "Epoch 66:\t train loss : 0.5677127461373377; train accuracy : 0.983655007899873; \n",
      " validation loss : 0.6037945974628036; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.5720807282362983; train accuracy : 0.979125747389944; \n",
      " validation loss : 0.5882364332100617; validation accuracy : 0.9623430962343096\n",
      "Epoch 68:\t train loss : 0.5693208243622594; train accuracy : 0.9817311564794449; \n",
      " validation loss : 0.5767075940060203; validation accuracy : 0.9748953974895398\n",
      "Epoch 69:\t train loss : 0.568088498449575; train accuracy : 0.9832522692772391; \n",
      " validation loss : 0.5814013014700329; validation accuracy : 0.9665271966527197\n",
      "Epoch 70:\t train loss : 0.5724591856512597; train accuracy : 0.9786083831593296; \n",
      " validation loss : 0.5761238511009287; validation accuracy : 0.9748953974895398\n",
      "Epoch 71:\t train loss : 0.5709853657149706; train accuracy : 0.9801480838935531; \n",
      " validation loss : 0.6021676080324927; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5646214478167954; train accuracy : 0.9866569596331981; \n",
      " validation loss : 0.6036202598915312; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5615712409080194; train accuracy : 0.9899532203599863; \n",
      " validation loss : 0.5791220281578793; validation accuracy : 0.9665271966527197\n",
      "Epoch 74:\t train loss : 0.5611361599714658; train accuracy : 0.990213451469996; \n",
      " validation loss : 0.5786729914703085; validation accuracy : 0.9748953974895398\n",
      "Epoch 75:\t train loss : 0.5696052740073839; train accuracy : 0.9815638650515816; \n",
      " validation loss : 0.5814863475668144; validation accuracy : 0.9707112970711297\n",
      "Epoch 76:\t train loss : 0.5658257759339016; train accuracy : 0.9852659623904086; \n",
      " validation loss : 0.5773117373036377; validation accuracy : 0.9748953974895398\n",
      "Epoch 77:\t train loss : 0.5647426604699116; train accuracy : 0.9865671179404566; \n",
      " validation loss : 0.590352760122349; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5654103753390368; train accuracy : 0.9857244648223303; \n",
      " validation loss : 0.5831043800890201; validation accuracy : 0.9665271966527197\n",
      "Epoch 79:\t train loss : 0.567397960731993; train accuracy : 0.983778927476068; \n",
      " validation loss : 0.5867682265768731; validation accuracy : 0.9623430962343096\n",
      "Epoch 80:\t train loss : 0.5668103034924888; train accuracy : 0.984404721335853; \n",
      " validation loss : 0.6061550487386924; validation accuracy : 0.9456066945606695\n",
      "Epoch 81:\t train loss : 0.5685911736126253; train accuracy : 0.9825923975340004; \n",
      " validation loss : 0.5886928197313429; validation accuracy : 0.9623430962343096\n",
      "Epoch 82:\t train loss : 0.5633175542714743; train accuracy : 0.9879550171938412; \n",
      " validation loss : 0.5854863403395751; validation accuracy : 0.9623430962343096\n",
      "Epoch 83:\t train loss : 0.5626763625178028; train accuracy : 0.9886055949688652; \n",
      " validation loss : 0.5802702961700645; validation accuracy : 0.9707112970711297\n",
      "Epoch 84:\t train loss : 0.5620942851208963; train accuracy : 0.9892778586697234; \n",
      " validation loss : 0.5900356657331757; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.5661744381685161; train accuracy : 0.9850336131850429; \n",
      " validation loss : 0.5933296452068475; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5632310225802297; train accuracy : 0.9880324669289631; \n",
      " validation loss : 0.6018252781690241; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5627641873315014; train accuracy : 0.9885219492549335; \n",
      " validation loss : 0.6079827846385787; validation accuracy : 0.9414225941422594\n",
      "Epoch 88:\t train loss : 0.5705813743080806; train accuracy : 0.9805074506645187; \n",
      " validation loss : 0.5930161508142346; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5629113846159877; train accuracy : 0.9884414015304067; \n",
      " validation loss : 0.5806640818872886; validation accuracy : 0.9707112970711297\n",
      "Epoch 90:\t train loss : 0.5644227586245322; train accuracy : 0.9868397410080858; \n",
      " validation loss : 0.5894956485994753; validation accuracy : 0.9623430962343096\n",
      "Epoch 91:\t train loss : 0.5674317200160012; train accuracy : 0.9837324576349948; \n",
      " validation loss : 0.5896110126463872; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5625236662321438; train accuracy : 0.9887140245980359; \n",
      " validation loss : 0.6079004532536052; validation accuracy : 0.9414225941422594\n",
      "Epoch 93:\t train loss : 0.5632916281078149; train accuracy : 0.9879983890455094; \n",
      " validation loss : 0.6044584740685404; validation accuracy : 0.9456066945606695\n",
      "Epoch 94:\t train loss : 0.5648942731942822; train accuracy : 0.986282102915208; \n",
      " validation loss : 0.5907722104189678; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5621379657754157; train accuracy : 0.9891632330617429; \n",
      " validation loss : 0.6325083954984859; validation accuracy : 0.9121338912133892\n",
      "Epoch 96:\t train loss : 0.564128614305636; train accuracy : 0.9873044394188172; \n",
      " validation loss : 0.5808272752105063; validation accuracy : 0.9707112970711297\n",
      "Early stopping at epoch 96\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5765731904845471; Train accuracy : 0.9744911552402491; \n",
      " Validation loss : 0.5665753512659781; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 76 ! ---\n",
      "Epoch 1:\t train loss : 0.9583505350196385; train accuracy : 0.5715434183215093; \n",
      " validation loss : 0.813495223542057; validation accuracy : 0.7447698744769874\n",
      "Epoch 2:\t train loss : 0.7454735325054304; train accuracy : 0.8034815204931999; \n",
      " validation loss : 0.7591107949760364; validation accuracy : 0.799163179916318\n",
      "Epoch 3:\t train loss : 0.6822724861573948; train accuracy : 0.867546392391338; \n",
      " validation loss : 0.6921606381352086; validation accuracy : 0.8493723849372385\n",
      "Epoch 4:\t train loss : 0.6554601353426254; train accuracy : 0.8953065460516125; \n",
      " validation loss : 0.6723859915902938; validation accuracy : 0.8702928870292888\n",
      "Epoch 5:\t train loss : 0.6385371134829114; train accuracy : 0.9123396015985625; \n",
      " validation loss : 0.6584060667322688; validation accuracy : 0.8828451882845189\n",
      "Epoch 6:\t train loss : 0.6317066279326686; train accuracy : 0.9191802720034697; \n",
      " validation loss : 0.695576497735169; validation accuracy : 0.8493723849372385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\t train loss : 0.6236976813071673; train accuracy : 0.9269642801821618; \n",
      " validation loss : 0.655083354460355; validation accuracy : 0.895397489539749\n",
      "Epoch 8:\t train loss : 0.6124023819281034; train accuracy : 0.9388915393909353; \n",
      " validation loss : 0.636079699431237; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.598986728191762; train accuracy : 0.9527476068031847; \n",
      " validation loss : 0.6340244112868619; validation accuracy : 0.9163179916317992\n",
      "Epoch 10:\t train loss : 0.6019048723865555; train accuracy : 0.9490278509247498; \n",
      " validation loss : 0.6276753135114262; validation accuracy : 0.9288702928870293\n",
      "Epoch 11:\t train loss : 0.598153884664474; train accuracy : 0.9528597540196413; \n",
      " validation loss : 0.6354438982295392; validation accuracy : 0.9163179916317992\n",
      "Epoch 12:\t train loss : 0.5936410791101531; train accuracy : 0.9577988785278354; \n",
      " validation loss : 0.7124593032392186; validation accuracy : 0.8284518828451883\n",
      "Epoch 13:\t train loss : 0.5925345036954934; train accuracy : 0.9586086929582701; \n",
      " validation loss : 0.6065931145898878; validation accuracy : 0.9456066945606695\n",
      "Epoch 14:\t train loss : 0.5872651865391136; train accuracy : 0.9639158586077635; \n",
      " validation loss : 0.617970266303094; validation accuracy : 0.9288702928870293\n",
      "Epoch 15:\t train loss : 0.5907510549355036; train accuracy : 0.9604888627280894; \n",
      " validation loss : 0.6188222487763755; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.582793476332016; train accuracy : 0.9684410917314663; \n",
      " validation loss : 0.6181434971409332; validation accuracy : 0.9330543933054394\n",
      "Epoch 17:\t train loss : 0.5806590371680485; train accuracy : 0.9707100591715976; \n",
      " validation loss : 0.614575186493827; validation accuracy : 0.9372384937238494\n",
      "Epoch 18:\t train loss : 0.5827924773661427; train accuracy : 0.9684138294247033; \n",
      " validation loss : 0.6084372971154741; validation accuracy : 0.9414225941422594\n",
      "Epoch 19:\t train loss : 0.5812333152789514; train accuracy : 0.9698175284240528; \n",
      " validation loss : 0.6160449912854233; validation accuracy : 0.9330543933054394\n",
      "Epoch 20:\t train loss : 0.5812229526613932; train accuracy : 0.970024783915239; \n",
      " validation loss : 0.6189896315199414; validation accuracy : 0.9246861924686193\n",
      "Epoch 21:\t train loss : 0.5821934699514009; train accuracy : 0.9689057901421977; \n",
      " validation loss : 0.6213177267132008; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5796684250153076; train accuracy : 0.97135320177205; \n",
      " validation loss : 0.6256314734746843; validation accuracy : 0.9246861924686193\n",
      "Epoch 23:\t train loss : 0.5799811052667667; train accuracy : 0.9711865299420676; \n",
      " validation loss : 0.6243855717543116; validation accuracy : 0.9246861924686193\n",
      "Epoch 24:\t train loss : 0.5805423975797469; train accuracy : 0.9704953685058397; \n",
      " validation loss : 0.6135584928455132; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5726805319905138; train accuracy : 0.9786526844078193; \n",
      " validation loss : 0.6023208276359125; validation accuracy : 0.9497907949790795\n",
      "Epoch 26:\t train loss : 0.5704297295357987; train accuracy : 0.9807748071501595; \n",
      " validation loss : 0.5943613219925714; validation accuracy : 0.9581589958158996\n",
      "Epoch 27:\t train loss : 0.5729190631451716; train accuracy : 0.9781548375104557; \n",
      " validation loss : 0.6184537684165521; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.5865636347305434; train accuracy : 0.9640301744168035; \n",
      " validation loss : 0.6129230079510272; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5756399415445571; train accuracy : 0.9754986213947148; \n",
      " validation loss : 0.6034087033515404; validation accuracy : 0.9497907949790795\n",
      "Epoch 30:\t train loss : 0.5719061687867868; train accuracy : 0.9791830601939341; \n",
      " validation loss : 0.6366578764476488; validation accuracy : 0.9121338912133892\n",
      "Epoch 31:\t train loss : 0.5827880116608948; train accuracy : 0.9679977694476285; \n",
      " validation loss : 0.5945077354727782; validation accuracy : 0.9581589958158996\n",
      "Epoch 32:\t train loss : 0.5702823458737254; train accuracy : 0.9807785247374454; \n",
      " validation loss : 0.6241793795200599; validation accuracy : 0.9246861924686193\n",
      "Epoch 33:\t train loss : 0.5707807416972995; train accuracy : 0.9805638340716875; \n",
      " validation loss : 0.5913708335095997; validation accuracy : 0.9623430962343096\n",
      "Epoch 34:\t train loss : 0.5744594462341636; train accuracy : 0.9765792000991357; \n",
      " validation loss : 0.5957407531604381; validation accuracy : 0.9581589958158996\n",
      "Epoch 35:\t train loss : 0.573448624890263; train accuracy : 0.9776495554385204; \n",
      " validation loss : 0.6279368098861944; validation accuracy : 0.9246861924686193\n",
      "Epoch 36:\t train loss : 0.5726394797892054; train accuracy : 0.9788134700579324; \n",
      " validation loss : 0.6096449927741442; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.5735670180484247; train accuracy : 0.9775897642430063; \n",
      " validation loss : 0.5946185435310074; validation accuracy : 0.9581589958158996\n",
      "Epoch 38:\t train loss : 0.5662558034085922; train accuracy : 0.9850522011214722; \n",
      " validation loss : 0.6002604656704623; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5700840774619572; train accuracy : 0.9811214721645652; \n",
      " validation loss : 0.6096517453609965; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5674944888028421; train accuracy : 0.9838535890207255; \n",
      " validation loss : 0.5944400033169547; validation accuracy : 0.9581589958158996\n",
      "Epoch 41:\t train loss : 0.5665064911536192; train accuracy : 0.984767495895164; \n",
      " validation loss : 0.6017662291295289; validation accuracy : 0.9414225941422594\n",
      "Epoch 42:\t train loss : 0.5711417482584901; train accuracy : 0.9801514916818984; \n",
      " validation loss : 0.6224540704812498; validation accuracy : 0.9288702928870293\n",
      "Epoch 43:\t train loss : 0.5670925184938725; train accuracy : 0.9840918244059605; \n",
      " validation loss : 0.59136056926918; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5658378536680415; train accuracy : 0.9852882679141237; \n",
      " validation loss : 0.606832920724481; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.5674326067374792; train accuracy : 0.9838226091266767; \n",
      " validation loss : 0.6049663898584949; validation accuracy : 0.9456066945606695\n",
      "Epoch 46:\t train loss : 0.5698769605762615; train accuracy : 0.9813073515288577; \n",
      " validation loss : 0.6022060033275195; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5711822764089018; train accuracy : 0.9799346324235572; \n",
      " validation loss : 0.608986314032493; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.5653287752814875; train accuracy : 0.985944731869017; \n",
      " validation loss : 0.5946147400491516; validation accuracy : 0.9581589958158996\n",
      "Epoch 49:\t train loss : 0.5660323859233967; train accuracy : 0.9852764955543852; \n",
      " validation loss : 0.613360893285577; validation accuracy : 0.9372384937238494\n",
      "Epoch 50:\t train loss : 0.590908318220202; train accuracy : 0.9600470894389541; \n",
      " validation loss : 0.6071171616376142; validation accuracy : 0.9372384937238494\n",
      "Epoch 51:\t train loss : 0.569640042386542; train accuracy : 0.9815530220886645; \n",
      " validation loss : 0.598704900233618; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5639323603477777; train accuracy : 0.9874066730691781; \n",
      " validation loss : 0.5999732250918659; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5630559352955948; train accuracy : 0.9882003779547074; \n",
      " validation loss : 0.5921171703382355; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.5609043291144201; train accuracy : 0.9903497630038105; \n",
      " validation loss : 0.6187646712622672; validation accuracy : 0.9288702928870293\n",
      "Epoch 55:\t train loss : 0.565090989026917; train accuracy : 0.9861092351064159; \n",
      " validation loss : 0.6017738352211945; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.562609400413119; train accuracy : 0.988547042969113; \n",
      " validation loss : 0.6228573403479878; validation accuracy : 0.9246861924686193\n",
      "Epoch 57:\t train loss : 0.5617667402934343; train accuracy : 0.9894144800024783; \n",
      " validation loss : 0.6166920188599071; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58:\t train loss : 0.5695058111179825; train accuracy : 0.9814681371789709; \n",
      " validation loss : 0.5961661902597146; validation accuracy : 0.9539748953974896\n",
      "Epoch 59:\t train loss : 0.5626783386663569; train accuracy : 0.9885315530220886; \n",
      " validation loss : 0.6069685186015323; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5636232104569134; train accuracy : 0.9876641159887233; \n",
      " validation loss : 0.5851453275404935; validation accuracy : 0.9665271966527197\n",
      "Epoch 61:\t train loss : 0.5614598498177108; train accuracy : 0.9898231048049816; \n",
      " validation loss : 0.5874747177246125; validation accuracy : 0.9623430962343096\n",
      "Epoch 62:\t train loss : 0.5613124133562731; train accuracy : 0.9898946683602342; \n",
      " validation loss : 0.5976805387694736; validation accuracy : 0.9539748953974896\n",
      "Epoch 63:\t train loss : 0.5651268095960587; train accuracy : 0.9860996313392608; \n",
      " validation loss : 0.6018970655909193; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5627201333934047; train accuracy : 0.9885780228631618; \n",
      " validation loss : 0.59275771901406; validation accuracy : 0.9539748953974896\n",
      "Epoch 65:\t train loss : 0.5690624675405038; train accuracy : 0.9819985129650857; \n",
      " validation loss : 0.6382293336615422; validation accuracy : 0.9121338912133892\n",
      "Epoch 66:\t train loss : 0.5743341784647007; train accuracy : 0.9766913473155922; \n",
      " validation loss : 0.6049008910928809; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5661648705137249; train accuracy : 0.9852049319991326; \n",
      " validation loss : 0.6072274494469027; validation accuracy : 0.9456066945606695\n",
      "Epoch 68:\t train loss : 0.5615742639045527; train accuracy : 0.9897766349639084; \n",
      " validation loss : 0.6015361520102032; validation accuracy : 0.9497907949790795\n",
      "Epoch 69:\t train loss : 0.559544078209976; train accuracy : 0.9918036494315189; \n",
      " validation loss : 0.58610736658696; validation accuracy : 0.9665271966527197\n",
      "Epoch 70:\t train loss : 0.5663248842627543; train accuracy : 0.985005731280399; \n",
      " validation loss : 0.6006389730032724; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5685536137175441; train accuracy : 0.9825834133647263; \n",
      " validation loss : 0.5990576317487644; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5616512806458954; train accuracy : 0.9895907555996158; \n",
      " validation loss : 0.6182394272891694; validation accuracy : 0.9330543933054394\n",
      "Epoch 73:\t train loss : 0.5708718288095617; train accuracy : 0.9800910808885034; \n",
      " validation loss : 0.6098529285924312; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5678394467688789; train accuracy : 0.9834198705040429; \n",
      " validation loss : 0.5885758277639607; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.5750782870302278; train accuracy : 0.9759227361442424; \n",
      " validation loss : 0.5889145850422842; validation accuracy : 0.9623430962343096\n",
      "Epoch 76:\t train loss : 0.562276723381389; train accuracy : 0.9889401778245919; \n",
      " validation loss : 0.5869832290755977; validation accuracy : 0.9623430962343096\n",
      "Epoch 77:\t train loss : 0.5594363532830091; train accuracy : 0.9919762074413705; \n",
      " validation loss : 0.6009263127057445; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5738527892189147; train accuracy : 0.9773360389107469; \n",
      " validation loss : 0.5955352422430319; validation accuracy : 0.9581589958158996\n",
      "Epoch 79:\t train loss : 0.5657381973063071; train accuracy : 0.9853096440410174; \n",
      " validation loss : 0.5988375766221807; validation accuracy : 0.9539748953974896\n",
      "Epoch 80:\t train loss : 0.5631865606991602; train accuracy : 0.9880572508442022; \n",
      " validation loss : 0.5963166863921452; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5606605481248562; train accuracy : 0.9906013197434864; \n",
      " validation loss : 0.5878661362723374; validation accuracy : 0.9623430962343096\n",
      "Epoch 82:\t train loss : 0.5627899417412267; train accuracy : 0.9883611636048205; \n",
      " validation loss : 0.5892223058618851; validation accuracy : 0.9665271966527197\n",
      "Epoch 83:\t train loss : 0.5608341945593447; train accuracy : 0.9904619102202671; \n",
      " validation loss : 0.6060804089444433; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5704001311323147; train accuracy : 0.9807181139440503; \n",
      " validation loss : 0.659760166179484; validation accuracy : 0.891213389121339\n",
      "Epoch 85:\t train loss : 0.5647262845210499; train accuracy : 0.9865023699618948; \n",
      " validation loss : 0.6073645461389645; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.5620361998766843; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.592387683305508; validation accuracy : 0.9581589958158996\n",
      "Epoch 87:\t train loss : 0.5618067356384048; train accuracy : 0.9894978159174695; \n",
      " validation loss : 0.619644450207923; validation accuracy : 0.9330543933054394\n",
      "Epoch 88:\t train loss : 0.5619980604137911; train accuracy : 0.9893680101614053; \n",
      " validation loss : 0.5927179465528998; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5614344085866303; train accuracy : 0.9897434864772763; \n",
      " validation loss : 0.6018262487279002; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5619679914374871; train accuracy : 0.989234486818055; \n",
      " validation loss : 0.5860841932365268; validation accuracy : 0.9623430962343096\n",
      "Epoch 91:\t train loss : 0.560389978904608; train accuracy : 0.9908491588958765; \n",
      " validation loss : 0.5901494835535452; validation accuracy : 0.9623430962343096\n",
      "Epoch 92:\t train loss : 0.5672967974591582; train accuracy : 0.9838594752005948; \n",
      " validation loss : 0.5867067258825521; validation accuracy : 0.9665271966527197\n",
      "Epoch 93:\t train loss : 0.5593442183777652; train accuracy : 0.9920691471235168; \n",
      " validation loss : 0.581572570549761; validation accuracy : 0.9707112970711297\n",
      "Epoch 94:\t train loss : 0.5627769433423169; train accuracy : 0.9882682239226742; \n",
      " validation loss : 0.6183061654691169; validation accuracy : 0.9330543933054394\n",
      "Epoch 95:\t train loss : 0.5587320527539847; train accuracy : 0.9926732550574677; \n",
      " validation loss : 0.6178593035264758; validation accuracy : 0.9288702928870293\n",
      "Epoch 96:\t train loss : 0.566184328822175; train accuracy : 0.9850986709625453; \n",
      " validation loss : 0.578637091176293; validation accuracy : 0.9707112970711297\n",
      "Epoch 97:\t train loss : 0.5588209131098253; train accuracy : 0.9925434493014034; \n",
      " validation loss : 0.5951158233037634; validation accuracy : 0.9539748953974896\n",
      "Epoch 98:\t train loss : 0.5597180143638468; train accuracy : 0.9915734688187366; \n",
      " validation loss : 0.5950416358209693; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5612001629267085; train accuracy : 0.9901483936924935; \n",
      " validation loss : 0.5971189069840576; validation accuracy : 0.9539748953974896\n",
      "Epoch 100:\t train loss : 0.5669164522233804; train accuracy : 0.9841847640881068; \n",
      " validation loss : 0.5997999542393355; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.55920598174542; train accuracy : 0.9920632609436476; \n",
      " validation loss : 0.5850864356728553; validation accuracy : 0.9665271966527197\n",
      "Epoch 102:\t train loss : 0.5599472043513068; train accuracy : 0.9913971932215991; \n",
      " validation loss : 0.5859405444618119; validation accuracy : 0.9623430962343096\n",
      "Epoch 103:\t train loss : 0.5612015511443676; train accuracy : 0.9900281917035844; \n",
      " validation loss : 0.6103769751900755; validation accuracy : 0.9372384937238494\n",
      "Epoch 104:\t train loss : 0.5614940223238425; train accuracy : 0.9897921249109328; \n",
      " validation loss : 0.5911481720339312; validation accuracy : 0.9581589958158996\n",
      "Epoch 105:\t train loss : 0.559332494145226; train accuracy : 0.9919489451346076; \n",
      " validation loss : 0.604790685360883; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.5696378102006249; train accuracy : 0.9815455869140928; \n",
      " validation loss : 0.5853739812922727; validation accuracy : 0.9665271966527197\n",
      "Epoch 107:\t train loss : 0.5614023478167861; train accuracy : 0.9898327085721367; \n",
      " validation loss : 0.5861064956818802; validation accuracy : 0.9665271966527197\n",
      "Epoch 108:\t train loss : 0.569043414796827; train accuracy : 0.9822559558846309; \n",
      " validation loss : 0.6154369595995988; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109:\t train loss : 0.5606760234628965; train accuracy : 0.9905821122091762; \n",
      " validation loss : 0.5992217962378841; validation accuracy : 0.9539748953974896\n",
      "Epoch 110:\t train loss : 0.5574624955034366; train accuracy : 0.9939279407664425; \n",
      " validation loss : 0.620208909987728; validation accuracy : 0.9246861924686193\n",
      "Epoch 111:\t train loss : 0.5572014337339356; train accuracy : 0.994191269865857; \n",
      " validation loss : 0.5919710239400884; validation accuracy : 0.9581589958158996\n",
      "Epoch 112:\t train loss : 0.5608386824800358; train accuracy : 0.9904368165060875; \n",
      " validation loss : 0.619343529760258; validation accuracy : 0.9288702928870293\n",
      "Epoch 113:\t train loss : 0.5654038390046754; train accuracy : 0.9857219864308064; \n",
      " validation loss : 0.6330591050908472; validation accuracy : 0.9163179916317992\n",
      "Epoch 114:\t train loss : 0.5665186747961792; train accuracy : 0.9846761052077202; \n",
      " validation loss : 0.6133632955233626; validation accuracy : 0.9330543933054394\n",
      "Epoch 115:\t train loss : 0.5689999813438097; train accuracy : 0.9822271445831655; \n",
      " validation loss : 0.6008860254061288; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5623549856040474; train accuracy : 0.9888103720685275; \n",
      " validation loss : 0.5809444287312775; validation accuracy : 0.9707112970711297\n",
      "Epoch 117:\t train loss : 0.557441701491403; train accuracy : 0.9939124508194181; \n",
      " validation loss : 0.5850005486425521; validation accuracy : 0.9665271966527197\n",
      "Epoch 118:\t train loss : 0.5584700626962487; train accuracy : 0.9927816846866384; \n",
      " validation loss : 0.588191660566736; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.5564080877077383; train accuracy : 0.9949598810372068; \n",
      " validation loss : 0.591516122579316; validation accuracy : 0.9581589958158996\n",
      "Epoch 120:\t train loss : 0.5558055172781906; train accuracy : 0.9955949688652065; \n",
      " validation loss : 0.5967135573039937; validation accuracy : 0.9539748953974896\n",
      "Epoch 121:\t train loss : 0.5575673424608251; train accuracy : 0.9937206852752564; \n",
      " validation loss : 0.5755012019181928; validation accuracy : 0.9748953974895398\n",
      "Epoch 122:\t train loss : 0.5660437250772112; train accuracy : 0.9852204219461569; \n",
      " validation loss : 0.6655454908646814; validation accuracy : 0.8828451882845189\n",
      "Epoch 123:\t train loss : 0.5680156152398991; train accuracy : 0.9830326218284333; \n",
      " validation loss : 0.5923825729185676; validation accuracy : 0.9581589958158996\n",
      "Epoch 124:\t train loss : 0.5615470900820076; train accuracy : 0.9897921249109328; \n",
      " validation loss : 0.5934350781831996; validation accuracy : 0.9581589958158996\n",
      "Epoch 125:\t train loss : 0.5575094573408612; train accuracy : 0.9938446048514514; \n",
      " validation loss : 0.6191840413977979; validation accuracy : 0.9330543933054394\n",
      "Epoch 126:\t train loss : 0.5568393421912476; train accuracy : 0.9944855788593203; \n",
      " validation loss : 0.6014372047673701; validation accuracy : 0.9497907949790795\n",
      "Epoch 127:\t train loss : 0.5559825541305767; train accuracy : 0.9953220359986369; \n",
      " validation loss : 0.5920564774046538; validation accuracy : 0.9581589958158996\n",
      "Epoch 128:\t train loss : 0.5563409768277606; train accuracy : 0.9950528207193531; \n",
      " validation loss : 0.5755152867101015; validation accuracy : 0.9748953974895398\n",
      "Epoch 129:\t train loss : 0.55822708680099; train accuracy : 0.9929461879240373; \n",
      " validation loss : 0.6184167044640518; validation accuracy : 0.9330543933054394\n",
      "Epoch 130:\t train loss : 0.5627948380441153; train accuracy : 0.9883921434988693; \n",
      " validation loss : 0.6017270714016884; validation accuracy : 0.9497907949790795\n",
      "Epoch 131:\t train loss : 0.5600693025618542; train accuracy : 0.9912481799312246; \n",
      " validation loss : 0.5920707549292256; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.557578179637493; train accuracy : 0.99374206140215; \n",
      " validation loss : 0.5776225093023435; validation accuracy : 0.9748953974895398\n",
      "Epoch 133:\t train loss : 0.5630299327644858; train accuracy : 0.9882409616159112; \n",
      " validation loss : 0.6051861217993093; validation accuracy : 0.9414225941422594\n",
      "Epoch 134:\t train loss : 0.5593559003162555; train accuracy : 0.9919607174943461; \n",
      " validation loss : 0.5917702716219093; validation accuracy : 0.9581589958158996\n",
      "Epoch 135:\t train loss : 0.558754946529105; train accuracy : 0.9925103008147712; \n",
      " validation loss : 0.6006388149735765; validation accuracy : 0.9497907949790795\n",
      "Epoch 136:\t train loss : 0.5672023772898829; train accuracy : 0.9840453545648874; \n",
      " validation loss : 0.5769860177903577; validation accuracy : 0.9748953974895398\n",
      "Epoch 137:\t train loss : 0.5559794087400317; train accuracy : 0.9953839957867344; \n",
      " validation loss : 0.5886746634849517; validation accuracy : 0.9623430962343096\n",
      "Epoch 138:\t train loss : 0.5724273330335901; train accuracy : 0.9787920939310387; \n",
      " validation loss : 0.5921361017469923; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5726135178106514; train accuracy : 0.9785405371913628; \n",
      " validation loss : 0.6036114552205749; validation accuracy : 0.9414225941422594\n",
      "Epoch 140:\t train loss : 0.5674868696775509; train accuracy : 0.983717897084792; \n",
      " validation loss : 0.5912957118559917; validation accuracy : 0.9581589958158996\n",
      "Epoch 141:\t train loss : 0.5632477616107509; train accuracy : 0.9880668546113572; \n",
      " validation loss : 0.5974646256886751; validation accuracy : 0.9539748953974896\n",
      "Epoch 142:\t train loss : 0.5603856454795328; train accuracy : 0.9908550450757458; \n",
      " validation loss : 0.5997507916848784; validation accuracy : 0.9497907949790795\n",
      "Epoch 143:\t train loss : 0.5617545033119482; train accuracy : 0.989522909631649; \n",
      " validation loss : 0.5933847458813752; validation accuracy : 0.9539748953974896\n",
      "Epoch 144:\t train loss : 0.5618866686204698; train accuracy : 0.9893311440874872; \n",
      " validation loss : 0.6011540518184075; validation accuracy : 0.9497907949790795\n",
      "Epoch 145:\t train loss : 0.5583225108178326; train accuracy : 0.9929365841568821; \n",
      " validation loss : 0.6000341716751159; validation accuracy : 0.9497907949790795\n",
      "Epoch 146:\t train loss : 0.5589034785368882; train accuracy : 0.9924814895133058; \n",
      " validation loss : 0.5986331174751441; validation accuracy : 0.9456066945606695\n",
      "Epoch 147:\t train loss : 0.5583807530048436; train accuracy : 0.9929830539979553; \n",
      " validation loss : 0.5923608560183213; validation accuracy : 0.9623430962343096\n",
      "Epoch 148:\t train loss : 0.5594730162055166; train accuracy : 0.9918250255584126; \n",
      " validation loss : 0.6012973111817035; validation accuracy : 0.9539748953974896\n",
      "Epoch 149:\t train loss : 0.5593548165190385; train accuracy : 0.9919179652405589; \n",
      " validation loss : 0.6087002349438414; validation accuracy : 0.9414225941422594\n",
      "Epoch 150:\t train loss : 0.5586141377150098; train accuracy : 0.9926983487716472; \n",
      " validation loss : 0.5988625395519497; validation accuracy : 0.9497907949790795\n",
      "Epoch 151:\t train loss : 0.5592779294876487; train accuracy : 0.9920632609436476; \n",
      " validation loss : 0.5974215699991873; validation accuracy : 0.9539748953974896\n",
      "Epoch 152:\t train loss : 0.5645642371086258; train accuracy : 0.9866241209455063; \n",
      " validation loss : 0.611054345387037; validation accuracy : 0.9372384937238494\n",
      "Epoch 153:\t train loss : 0.5617220275723643; train accuracy : 0.9895287958115183; \n",
      " validation loss : 0.5725530526824179; validation accuracy : 0.9790794979079498\n",
      "Epoch 154:\t train loss : 0.5584619823180588; train accuracy : 0.992853248241891; \n",
      " validation loss : 0.6015975229814388; validation accuracy : 0.9497907949790795\n",
      "Epoch 155:\t train loss : 0.5611114079354181; train accuracy : 0.9903571981783822; \n",
      " validation loss : 0.6263458260685932; validation accuracy : 0.9246861924686193\n",
      "Epoch 156:\t train loss : 0.5621428289598499; train accuracy : 0.9891415471359087; \n",
      " validation loss : 0.5826394224994548; validation accuracy : 0.9665271966527197\n",
      "Epoch 157:\t train loss : 0.5624282256035287; train accuracy : 0.9888509557297314; \n",
      " validation loss : 0.5908258357203637; validation accuracy : 0.9623430962343096\n",
      "Epoch 158:\t train loss : 0.5595142118418788; train accuracy : 0.9917379720561356; \n",
      " validation loss : 0.58338638374359; validation accuracy : 0.9665271966527197\n",
      "Epoch 159:\t train loss : 0.55619529843471; train accuracy : 0.9952910561045881; \n",
      " validation loss : 0.5738134145484821; validation accuracy : 0.9790794979079498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160:\t train loss : 0.5572912394675984; train accuracy : 0.9940245980358747; \n",
      " validation loss : 0.6034355824786084; validation accuracy : 0.9456066945606695\n",
      "Epoch 161:\t train loss : 0.5599098950820339; train accuracy : 0.9914185693484928; \n",
      " validation loss : 0.5736668408032384; validation accuracy : 0.9790794979079498\n",
      "Epoch 162:\t train loss : 0.5711792084192904; train accuracy : 0.9799324638309737; \n",
      " validation loss : 0.6064114172588606; validation accuracy : 0.9456066945606695\n",
      "Epoch 163:\t train loss : 0.5705239392850976; train accuracy : 0.9805793240187118; \n",
      " validation loss : 0.585475205611234; validation accuracy : 0.9665271966527197\n",
      "Epoch 164:\t train loss : 0.5644215323155454; train accuracy : 0.9867096254530809; \n",
      " validation loss : 0.5898571170484678; validation accuracy : 0.9623430962343096\n",
      "Epoch 165:\t train loss : 0.5624777216699067; train accuracy : 0.9888568419096007; \n",
      " validation loss : 0.5914091617479946; validation accuracy : 0.9581589958158996\n",
      "Epoch 166:\t train loss : 0.563605458721704; train accuracy : 0.987571176306577; \n",
      " validation loss : 0.6014053073544802; validation accuracy : 0.9497907949790795\n",
      "Epoch 167:\t train loss : 0.5614594756155145; train accuracy : 0.9897611450168841; \n",
      " validation loss : 0.5976142612899543; validation accuracy : 0.9539748953974896\n",
      "Epoch 168:\t train loss : 0.5695306298238924; train accuracy : 0.9815551906812479; \n",
      " validation loss : 0.5939849716979723; validation accuracy : 0.9581589958158996\n",
      "Epoch 169:\t train loss : 0.5641015314943975; train accuracy : 0.9871256854301558; \n",
      " validation loss : 0.5813557113393075; validation accuracy : 0.9707112970711297\n",
      "Epoch 170:\t train loss : 0.5593553028646263; train accuracy : 0.9918522878651755; \n",
      " validation loss : 0.5803578521678632; validation accuracy : 0.9707112970711297\n",
      "Epoch 171:\t train loss : 0.5614391873073422; train accuracy : 0.9897301651228353; \n",
      " validation loss : 0.5823245121357562; validation accuracy : 0.9707112970711297\n",
      "Epoch 172:\t train loss : 0.5602223091069828; train accuracy : 0.9909848508318101; \n",
      " validation loss : 0.6041806825821842; validation accuracy : 0.9456066945606695\n",
      "Epoch 173:\t train loss : 0.5583310530689329; train accuracy : 0.9928746243687846; \n",
      " validation loss : 0.583897903667942; validation accuracy : 0.9665271966527197\n",
      "Epoch 174:\t train loss : 0.5572601990301193; train accuracy : 0.9941640075590942; \n",
      " validation loss : 0.5809195081613315; validation accuracy : 0.9707112970711297\n",
      "Epoch 175:\t train loss : 0.5564950362641141; train accuracy : 0.9949443910901825; \n",
      " validation loss : 0.5888784773064509; validation accuracy : 0.9623430962343096\n",
      "Epoch 176:\t train loss : 0.5553411965771241; train accuracy : 0.9960441773289135; \n",
      " validation loss : 0.5970878256810438; validation accuracy : 0.9539748953974896\n",
      "Epoch 177:\t train loss : 0.5577660333174598; train accuracy : 0.9936432355401345; \n",
      " validation loss : 0.5755678121947249; validation accuracy : 0.9748953974895398\n",
      "Epoch 178:\t train loss : 0.5614183013320487; train accuracy : 0.9898172186251123; \n",
      " validation loss : 0.5864656098005503; validation accuracy : 0.9623430962343096\n",
      "Epoch 179:\t train loss : 0.5602476120392836; train accuracy : 0.9910409244400384; \n",
      " validation loss : 0.5827240362839503; validation accuracy : 0.9665271966527197\n",
      "Epoch 180:\t train loss : 0.5699856150151191; train accuracy : 0.9811059822175409; \n",
      " validation loss : 0.6045998763540467; validation accuracy : 0.9456066945606695\n",
      "Epoch 181:\t train loss : 0.5644034281256646; train accuracy : 0.9869360884785774; \n",
      " validation loss : 0.5949793005603011; validation accuracy : 0.9581589958158996\n",
      "Epoch 182:\t train loss : 0.5627161472913974; train accuracy : 0.9883980296787385; \n",
      " validation loss : 0.5942070751975026; validation accuracy : 0.9539748953974896\n",
      "Epoch 183:\t train loss : 0.5560003730868459; train accuracy : 0.9953935995538895; \n",
      " validation loss : 0.5921125890671717; validation accuracy : 0.9623430962343096\n",
      "Epoch 184:\t train loss : 0.5583340195159691; train accuracy : 0.9929189256172744; \n",
      " validation loss : 0.567198258128526; validation accuracy : 0.9832635983263598\n",
      "Epoch 185:\t train loss : 0.557577588881115; train accuracy : 0.99374206140215; \n",
      " validation loss : 0.5828662487467341; validation accuracy : 0.9665271966527197\n",
      "Epoch 186:\t train loss : 0.5568374510924574; train accuracy : 0.9944951826264754; \n",
      " validation loss : 0.5779958666865005; validation accuracy : 0.9748953974895398\n",
      "Epoch 187:\t train loss : 0.5584678013943571; train accuracy : 0.9928436444747359; \n",
      " validation loss : 0.5978913484229519; validation accuracy : 0.9497907949790795\n",
      "Epoch 188:\t train loss : 0.5576166123701667; train accuracy : 0.9937575513491744; \n",
      " validation loss : 0.5780970086323236; validation accuracy : 0.9748953974895398\n",
      "Epoch 189:\t train loss : 0.560535451705736; train accuracy : 0.9907060317853713; \n",
      " validation loss : 0.6004736705477562; validation accuracy : 0.9497907949790795\n",
      "Epoch 190:\t train loss : 0.5563673389318985; train accuracy : 0.9949657672170761; \n",
      " validation loss : 0.5803694988041427; validation accuracy : 0.9707112970711297\n",
      "Epoch 191:\t train loss : 0.5611481547838525; train accuracy : 0.9900473992378946; \n",
      " validation loss : 0.6010598226115799; validation accuracy : 0.9497907949790795\n",
      "Epoch 192:\t train loss : 0.5614844184299566; train accuracy : 0.9897397688899904; \n",
      " validation loss : 0.5836307653995177; validation accuracy : 0.9707112970711297\n",
      "Epoch 193:\t train loss : 0.5570824239020994; train accuracy : 0.9941389138449146; \n",
      " validation loss : 0.5951460272958861; validation accuracy : 0.9581589958158996\n",
      "Epoch 194:\t train loss : 0.5570458517283043; train accuracy : 0.9942842095480033; \n",
      " validation loss : 0.5870141961088721; validation accuracy : 0.9665271966527197\n",
      "Epoch 195:\t train loss : 0.5625531742954667; train accuracy : 0.9886303788841042; \n",
      " validation loss : 0.5856610043464099; validation accuracy : 0.9623430962343096\n",
      "Epoch 196:\t train loss : 0.5590237958810539; train accuracy : 0.9922801202019889; \n",
      " validation loss : 0.5871661598077956; validation accuracy : 0.9623430962343096\n",
      "Epoch 197:\t train loss : 0.5576494101431295; train accuracy : 0.9937516651693051; \n",
      " validation loss : 0.6004095215337334; validation accuracy : 0.9497907949790795\n",
      "Epoch 198:\t train loss : 0.5561948768548411; train accuracy : 0.9952387000836457; \n",
      " validation loss : 0.5929995876124879; validation accuracy : 0.9581589958158996\n",
      "Epoch 199:\t train loss : 0.5551129245204358; train accuracy : 0.9962610365872548; \n",
      " validation loss : 0.5775938963530565; validation accuracy : 0.9748953974895398\n",
      "Epoch 200:\t train loss : 0.5577462775091302; train accuracy : 0.9935967656990613; \n",
      " validation loss : 0.6036563782997277; validation accuracy : 0.9456066945606695\n",
      "Epoch 201:\t train loss : 0.5576654635649092; train accuracy : 0.9936063694662164; \n",
      " validation loss : 0.5824205923677125; validation accuracy : 0.9707112970711297\n",
      "Epoch 202:\t train loss : 0.5582970951469851; train accuracy : 0.9929926577651105; \n",
      " validation loss : 0.6037846771580382; validation accuracy : 0.9456066945606695\n",
      "Epoch 203:\t train loss : 0.5561836934402646; train accuracy : 0.9951051767402955; \n",
      " validation loss : 0.5866584161602749; validation accuracy : 0.9665271966527197\n",
      "Epoch 204:\t train loss : 0.5559852293108718; train accuracy : 0.9954090895009139; \n",
      " validation loss : 0.5930256278246078; validation accuracy : 0.9581589958158996\n",
      "Epoch 205:\t train loss : 0.5566248040412693; train accuracy : 0.9947740016729143; \n",
      " validation loss : 0.5962598981684853; validation accuracy : 0.9539748953974896\n",
      "Epoch 206:\t train loss : 0.5595493359038459; train accuracy : 0.9916915022150624; \n",
      " validation loss : 0.5916440084081304; validation accuracy : 0.9581589958158996\n",
      "Epoch 207:\t train loss : 0.5573147798747923; train accuracy : 0.9940053905015644; \n",
      " validation loss : 0.5980651354085467; validation accuracy : 0.9539748953974896\n",
      "Epoch 208:\t train loss : 0.5579467248407938; train accuracy : 0.9934108863347687; \n",
      " validation loss : 0.5939342788421912; validation accuracy : 0.9581589958158996\n",
      "Epoch 209:\t train loss : 0.5557936169918272; train accuracy : 0.9956259487592553; \n",
      " validation loss : 0.580898917871711; validation accuracy : 0.9707112970711297\n",
      "Epoch 210:\t train loss : 0.555834932491434; train accuracy : 0.9955175191300846; \n",
      " validation loss : 0.574113314776679; validation accuracy : 0.9748953974895398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211:\t train loss : 0.5598160683361064; train accuracy : 0.9915424889246879; \n",
      " validation loss : 0.5983080941765279; validation accuracy : 0.9497907949790795\n",
      "Epoch 212:\t train loss : 0.5614464278232475; train accuracy : 0.9897958424982186; \n",
      " validation loss : 0.6056349773159917; validation accuracy : 0.9456066945606695\n",
      "Epoch 213:\t train loss : 0.5569235946241352; train accuracy : 0.9944273366585086; \n",
      " validation loss : 0.579204533137036; validation accuracy : 0.9707112970711297\n",
      "Epoch 214:\t train loss : 0.5565432685306767; train accuracy : 0.9948573375879054; \n",
      " validation loss : 0.584950334844749; validation accuracy : 0.9665271966527197\n",
      "Epoch 215:\t train loss : 0.560448139854313; train accuracy : 0.9909111186839741; \n",
      " validation loss : 0.6023339326271732; validation accuracy : 0.9497907949790795\n",
      "Epoch 216:\t train loss : 0.561438716267194; train accuracy : 0.9898481985191611; \n",
      " validation loss : 0.5932902921329224; validation accuracy : 0.9581589958158996\n",
      "Epoch 217:\t train loss : 0.5568705983880003; train accuracy : 0.9945261625205242; \n",
      " validation loss : 0.5804307130477853; validation accuracy : 0.9707112970711297\n",
      "Epoch 218:\t train loss : 0.5576713629269738; train accuracy : 0.993705195328232; \n",
      " validation loss : 0.5877623858003133; validation accuracy : 0.9623430962343096\n",
      "Epoch 219:\t train loss : 0.5565727034196081; train accuracy : 0.9948514514080362; \n",
      " validation loss : 0.589394710440693; validation accuracy : 0.9623430962343096\n",
      "Epoch 220:\t train loss : 0.5604321629925297; train accuracy : 0.9908705350227702; \n",
      " validation loss : 0.5808160984814006; validation accuracy : 0.9707112970711297\n",
      "Epoch 221:\t train loss : 0.5580129174465147; train accuracy : 0.993416772514638; \n",
      " validation loss : 0.5812656455373596; validation accuracy : 0.9665271966527197\n",
      "Epoch 222:\t train loss : 0.5562728671916871; train accuracy : 0.995170854115679; \n",
      " validation loss : 0.600756940944752; validation accuracy : 0.9497907949790795\n",
      "Epoch 223:\t train loss : 0.5569960833684311; train accuracy : 0.9943867529973047; \n",
      " validation loss : 0.600924203292117; validation accuracy : 0.9497907949790795\n",
      "Epoch 224:\t train loss : 0.5604664417687806; train accuracy : 0.9908491588958765; \n",
      " validation loss : 0.5939634971588258; validation accuracy : 0.9581589958158996\n",
      "Epoch 225:\t train loss : 0.5559009395550549; train accuracy : 0.9954614455218563; \n",
      " validation loss : 0.5783121846789218; validation accuracy : 0.9707112970711297\n",
      "Epoch 226:\t train loss : 0.5565142591971451; train accuracy : 0.9949289011431581; \n",
      " validation loss : 0.6048634066275818; validation accuracy : 0.9456066945606695\n",
      "Epoch 227:\t train loss : 0.5594471353312159; train accuracy : 0.9918346293255677; \n",
      " validation loss : 0.5851732913969104; validation accuracy : 0.9665271966527197\n",
      "Epoch 228:\t train loss : 0.5595622177130697; train accuracy : 0.9917165959292419; \n",
      " validation loss : 0.5833658900993309; validation accuracy : 0.9707112970711297\n",
      "Epoch 229:\t train loss : 0.5585583890938015; train accuracy : 0.9927912884537935; \n",
      " validation loss : 0.5885114631425733; validation accuracy : 0.9623430962343096\n",
      "Epoch 230:\t train loss : 0.5591529251853398; train accuracy : 0.9922240465937606; \n",
      " validation loss : 0.5999135946278974; validation accuracy : 0.9497907949790795\n",
      "Epoch 231:\t train loss : 0.5592217391853922; train accuracy : 0.992038167229468; \n",
      " validation loss : 0.5757155192683331; validation accuracy : 0.9748953974895398\n",
      "Epoch 232:\t train loss : 0.5577003820955402; train accuracy : 0.9936491217200037; \n",
      " validation loss : 0.5845919160818983; validation accuracy : 0.9665271966527197\n",
      "Epoch 233:\t train loss : 0.5569253065544408; train accuracy : 0.9944545989652716; \n",
      " validation loss : 0.5823560708084323; validation accuracy : 0.9665271966527197\n",
      "Epoch 234:\t train loss : 0.5557078799914364; train accuracy : 0.9956473248861488; \n",
      " validation loss : 0.5915777466807525; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 234\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5583340195159691; Train accuracy : 0.9929189256172744; \n",
      " Validation loss : 0.567198258128526; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 77 ! ---\n",
      "Epoch 1:\t train loss : 0.932119328517644; train accuracy : 0.5920756529012671; \n",
      " validation loss : 0.793011727777804; validation accuracy : 0.7531380753138075\n",
      "Epoch 2:\t train loss : 0.7460022192568273; train accuracy : 0.804232473124942; \n",
      " validation loss : 0.7443790352432934; validation accuracy : 0.8075313807531381\n",
      "Epoch 3:\t train loss : 0.7046226760662505; train accuracy : 0.8455308404845255; \n",
      " validation loss : 0.7131222201073042; validation accuracy : 0.8326359832635983\n",
      "Epoch 4:\t train loss : 0.6697701884693115; train accuracy : 0.881487344713281; \n",
      " validation loss : 0.6966682613962178; validation accuracy : 0.8451882845188284\n",
      "Epoch 5:\t train loss : 0.6554709339311473; train accuracy : 0.8953604510672574; \n",
      " validation loss : 0.6824443717112401; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6404943924843779; train accuracy : 0.9100470894389541; \n",
      " validation loss : 0.6604791772013646; validation accuracy : 0.891213389121339\n",
      "Epoch 7:\t train loss : 0.6228567004029568; train accuracy : 0.9285383685987794; \n",
      " validation loss : 0.6636449968728302; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6197924933723452; train accuracy : 0.9311738281855076; \n",
      " validation loss : 0.6794942651469906; validation accuracy : 0.8661087866108786\n",
      "Epoch 9:\t train loss : 0.6110826096070189; train accuracy : 0.9403321044642027; \n",
      " validation loss : 0.6679321051967058; validation accuracy : 0.8744769874476988\n",
      "Epoch 10:\t train loss : 0.6095319827135111; train accuracy : 0.9416856160351932; \n",
      " validation loss : 0.6710238619015689; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.6071928837338477; train accuracy : 0.9438306638991295; \n",
      " validation loss : 0.6490610225905973; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.6106724777076622; train accuracy : 0.9402797484432603; \n",
      " validation loss : 0.6451965970778956; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.5992591962400042; train accuracy : 0.9518625112302116; \n",
      " validation loss : 0.625519125845741; validation accuracy : 0.9288702928870293\n",
      "Epoch 14:\t train loss : 0.5932245005090239; train accuracy : 0.9580024164317358; \n",
      " validation loss : 0.6410389151724156; validation accuracy : 0.9121338912133892\n",
      "Epoch 15:\t train loss : 0.5898153659700982; train accuracy : 0.9616462715697512; \n",
      " validation loss : 0.6220013754207632; validation accuracy : 0.9246861924686193\n",
      "Epoch 16:\t train loss : 0.5856080945196118; train accuracy : 0.9657164100498776; \n",
      " validation loss : 0.6240223631686435; validation accuracy : 0.9163179916317992\n",
      "Epoch 17:\t train loss : 0.5862842565478881; train accuracy : 0.9650017038941727; \n",
      " validation loss : 0.640387525178721; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.586047587865445; train accuracy : 0.9651491681898448; \n",
      " validation loss : 0.6625650704289988; validation accuracy : 0.8786610878661087\n",
      "Epoch 19:\t train loss : 0.5945402553138011; train accuracy : 0.9565367576442888; \n",
      " validation loss : 0.6298847698719899; validation accuracy : 0.9205020920502092\n",
      "Epoch 20:\t train loss : 0.5811436616200417; train accuracy : 0.9701657424331609; \n",
      " validation loss : 0.6292387655098749; validation accuracy : 0.9246861924686193\n",
      "Epoch 21:\t train loss : 0.5795039204543938; train accuracy : 0.9718275039499364; \n",
      " validation loss : 0.6581365481716157; validation accuracy : 0.891213389121339\n",
      "Epoch 22:\t train loss : 0.5766947894405536; train accuracy : 0.9747551039375445; \n",
      " validation loss : 0.6109692744671515; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5789930245674704; train accuracy : 0.9724427646457449; \n",
      " validation loss : 0.6343802214250192; validation accuracy : 0.9121338912133892\n",
      "Epoch 24:\t train loss : 0.5803434367612419; train accuracy : 0.970651816970786; \n",
      " validation loss : 0.6143478373754545; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5748311597250261; train accuracy : 0.9762517426190402; \n",
      " validation loss : 0.6452714765517156; validation accuracy : 0.9037656903765691\n",
      "Epoch 26:\t train loss : 0.5694474635056934; train accuracy : 0.9822271445831655; \n",
      " validation loss : 0.5950638115750544; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:\t train loss : 0.5724371777221227; train accuracy : 0.9789411072214133; \n",
      " validation loss : 0.6274309745968647; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.5712514324136252; train accuracy : 0.9800681557669073; \n",
      " validation loss : 0.611740101472597; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5663718298461513; train accuracy : 0.9850906161900926; \n",
      " validation loss : 0.6174881569959875; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.5752303701190492; train accuracy : 0.9755392050559187; \n",
      " validation loss : 0.6145597827753522; validation accuracy : 0.9372384937238494\n",
      "Epoch 31:\t train loss : 0.5673065529004473; train accuracy : 0.9839908299513616; \n",
      " validation loss : 0.6173027724954049; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5683370167281916; train accuracy : 0.9829588896805973; \n",
      " validation loss : 0.6023328220355576; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.5648935296807494; train accuracy : 0.9864286378140587; \n",
      " validation loss : 0.6265370483162964; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.5674538217870176; train accuracy : 0.9838845689147743; \n",
      " validation loss : 0.6817484160648174; validation accuracy : 0.8661087866108786\n",
      "Epoch 35:\t train loss : 0.5709049557025979; train accuracy : 0.9802887326125345; \n",
      " validation loss : 0.6046810910167169; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5752502388404207; train accuracy : 0.9757368567799498; \n",
      " validation loss : 0.6207457587538643; validation accuracy : 0.9288702928870293\n",
      "Epoch 37:\t train loss : 0.5738413698248659; train accuracy : 0.9774289785928932; \n",
      " validation loss : 0.6100457449571228; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5791877482842448; train accuracy : 0.9714653489885064; \n",
      " validation loss : 0.618561149442191; validation accuracy : 0.9288702928870293\n",
      "Epoch 39:\t train loss : 0.5717836952878756; train accuracy : 0.9794581616530872; \n",
      " validation loss : 0.6073847237437783; validation accuracy : 0.9372384937238494\n",
      "Epoch 40:\t train loss : 0.5684008790334797; train accuracy : 0.9825620372378326; \n",
      " validation loss : 0.6112358958376992; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5630789273331543; train accuracy : 0.98827194150996; \n",
      " validation loss : 0.6637262850414422; validation accuracy : 0.891213389121339\n",
      "Epoch 42:\t train loss : 0.575369814669619; train accuracy : 0.9758740977105859; \n",
      " validation loss : 0.6105582216611194; validation accuracy : 0.9372384937238494\n",
      "Epoch 43:\t train loss : 0.563920737417094; train accuracy : 0.9872768673131138; \n",
      " validation loss : 0.6182121396769878; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.561210553796519; train accuracy : 0.9901115276185756; \n",
      " validation loss : 0.6124469385644762; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5656090493154127; train accuracy : 0.9856343133306484; \n",
      " validation loss : 0.6108195789188322; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5695689162867793; train accuracy : 0.9814430434647914; \n",
      " validation loss : 0.6045636150009249; validation accuracy : 0.9497907949790795\n",
      "Epoch 47:\t train loss : 0.5635111329199577; train accuracy : 0.987809411691812; \n",
      " validation loss : 0.596145968082749; validation accuracy : 0.9539748953974896\n",
      "Epoch 48:\t train loss : 0.5669259820111574; train accuracy : 0.9844245484680443; \n",
      " validation loss : 0.6052568299898355; validation accuracy : 0.9456066945606695\n",
      "Epoch 49:\t train loss : 0.5631735226233129; train accuracy : 0.987983518696366; \n",
      " validation loss : 0.6011611589136213; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5668584784376173; train accuracy : 0.9843861333994238; \n",
      " validation loss : 0.612727232526955; validation accuracy : 0.9372384937238494\n",
      "Epoch 51:\t train loss : 0.5624070614947368; train accuracy : 0.9889438954118777; \n",
      " validation loss : 0.6051783549420071; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5642976665156263; train accuracy : 0.9870770469964992; \n",
      " validation loss : 0.6236676609480737; validation accuracy : 0.9288702928870293\n",
      "Epoch 53:\t train loss : 0.5627640667594906; train accuracy : 0.9886068341646271; \n",
      " validation loss : 0.6178604411600508; validation accuracy : 0.9288702928870293\n",
      "Epoch 54:\t train loss : 0.564658007310644; train accuracy : 0.9866300071253756; \n",
      " validation loss : 0.6179700864321898; validation accuracy : 0.9330543933054394\n",
      "Epoch 55:\t train loss : 0.561445964226894; train accuracy : 0.9898364261594226; \n",
      " validation loss : 0.6357384169559391; validation accuracy : 0.9121338912133892\n",
      "Epoch 56:\t train loss : 0.564174631391458; train accuracy : 0.9871566653242045; \n",
      " validation loss : 0.6172562823730191; validation accuracy : 0.9330543933054394\n",
      "Epoch 57:\t train loss : 0.5648792807216887; train accuracy : 0.9862855107035534; \n",
      " validation loss : 0.6233662329912024; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.5625885615043466; train accuracy : 0.9885854580377335; \n",
      " validation loss : 0.6196020578899931; validation accuracy : 0.9330543933054394\n",
      "Epoch 59:\t train loss : 0.5700622199505726; train accuracy : 0.9810653985563369; \n",
      " validation loss : 0.6096460530045108; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5619664865815464; train accuracy : 0.9892286006381859; \n",
      " validation loss : 0.6010073343032272; validation accuracy : 0.9497907949790795\n",
      "Epoch 61:\t train loss : 0.5598745439828926; train accuracy : 0.9914340592955172; \n",
      " validation loss : 0.6212649758634444; validation accuracy : 0.9330543933054394\n",
      "Epoch 62:\t train loss : 0.559774383008086; train accuracy : 0.9915211127977942; \n",
      " validation loss : 0.605651794321013; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5637733715594782; train accuracy : 0.9874007868893089; \n",
      " validation loss : 0.6087179949864969; validation accuracy : 0.9414225941422594\n",
      "Epoch 64:\t train loss : 0.5678614362976379; train accuracy : 0.983268688621085; \n",
      " validation loss : 0.6308482118329494; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.5652057495939805; train accuracy : 0.9860008054772452; \n",
      " validation loss : 0.6192049074520748; validation accuracy : 0.9288702928870293\n",
      "Epoch 66:\t train loss : 0.5613902325462387; train accuracy : 0.9898578022863161; \n",
      " validation loss : 0.619691797069312; validation accuracy : 0.9330543933054394\n",
      "Epoch 67:\t train loss : 0.56461869445818; train accuracy : 0.9866049134111962; \n",
      " validation loss : 0.5964368255237468; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5615332606065062; train accuracy : 0.9898268223922674; \n",
      " validation loss : 0.6057377892532463; validation accuracy : 0.9414225941422594\n",
      "Epoch 69:\t train loss : 0.5652286418560452; train accuracy : 0.9860782552123671; \n",
      " validation loss : 0.5993222422043047; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5611002825406098; train accuracy : 0.9901403389200409; \n",
      " validation loss : 0.5953950536696846; validation accuracy : 0.9539748953974896\n",
      "Epoch 71:\t train loss : 0.5837928890099556; train accuracy : 0.9669422844573872; \n",
      " validation loss : 0.6217382598458487; validation accuracy : 0.9246861924686193\n",
      "Epoch 72:\t train loss : 0.5646115235711565; train accuracy : 0.9865023699618948; \n",
      " validation loss : 0.6016352952695526; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5629448010985927; train accuracy : 0.9883456736577961; \n",
      " validation loss : 0.6154081486195748; validation accuracy : 0.9330543933054394\n",
      "Epoch 74:\t train loss : 0.5587783413806363; train accuracy : 0.9925995229096316; \n",
      " validation loss : 0.627041083010542; validation accuracy : 0.9205020920502092\n",
      "Epoch 75:\t train loss : 0.5582276730701476; train accuracy : 0.9931475572353542; \n",
      " validation loss : 0.6013083060791908; validation accuracy : 0.9497907949790795\n",
      "Epoch 76:\t train loss : 0.5634592989242143; train accuracy : 0.9879680287493416; \n",
      " validation loss : 0.6109517600202548; validation accuracy : 0.9372384937238494\n",
      "Early stopping at epoch 76\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5694474635056934; Train accuracy : 0.9822271445831655; \n",
      " Validation loss : 0.5950638115750544; Validation accuracy : 0.9581589958158996\n",
      "--- Let's train model 78 ! ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t train loss : 0.9610569460496301; train accuracy : 0.5692530747544844; \n",
      " validation loss : 0.8615033477446857; validation accuracy : 0.6820083682008368\n",
      "Epoch 2:\t train loss : 0.7779163740902393; train accuracy : 0.7693726571455126; \n",
      " validation loss : 0.7627926028174761; validation accuracy : 0.7866108786610879\n",
      "Epoch 3:\t train loss : 0.7143894992239056; train accuracy : 0.8355515970135382; \n",
      " validation loss : 0.7373445376401495; validation accuracy : 0.8200836820083682\n",
      "Epoch 4:\t train loss : 0.6887874736690862; train accuracy : 0.8603804330989188; \n",
      " validation loss : 0.6951314418437061; validation accuracy : 0.8451882845188284\n",
      "Epoch 5:\t train loss : 0.6647400833163016; train accuracy : 0.885642987700982; \n",
      " validation loss : 0.7028322002767258; validation accuracy : 0.8451882845188284\n",
      "Epoch 6:\t train loss : 0.6459122606141918; train accuracy : 0.9048269772917377; \n",
      " validation loss : 0.7002521468730155; validation accuracy : 0.8493723849372385\n",
      "Epoch 7:\t train loss : 0.6347239532681817; train accuracy : 0.9153756312153413; \n",
      " validation loss : 0.6813931214019662; validation accuracy : 0.8619246861924686\n",
      "Epoch 8:\t train loss : 0.6239129763586917; train accuracy : 0.9268499643731218; \n",
      " validation loss : 0.6789813889064359; validation accuracy : 0.8619246861924686\n",
      "Epoch 9:\t train loss : 0.6262876389497216; train accuracy : 0.9249564732488614; \n",
      " validation loss : 0.6842168278978998; validation accuracy : 0.8619246861924686\n",
      "Epoch 10:\t train loss : 0.6099695400362983; train accuracy : 0.9414089655813377; \n",
      " validation loss : 0.6610685877278155; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.6125453062949964; train accuracy : 0.9383515598376654; \n",
      " validation loss : 0.6562043492802305; validation accuracy : 0.891213389121339\n",
      "Epoch 12:\t train loss : 0.6039059413898875; train accuracy : 0.9475120047089439; \n",
      " validation loss : 0.6411230414699687; validation accuracy : 0.9121338912133892\n",
      "Epoch 13:\t train loss : 0.5947396481668358; train accuracy : 0.9567653892623688; \n",
      " validation loss : 0.6364866604322265; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5944414538655554; train accuracy : 0.9566820533473775; \n",
      " validation loss : 0.6309970312068357; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5902307097245503; train accuracy : 0.9612943399733573; \n",
      " validation loss : 0.6398420891810553; validation accuracy : 0.9121338912133892\n",
      "Epoch 16:\t train loss : 0.5951167114945752; train accuracy : 0.9561981474023359; \n",
      " validation loss : 0.6552591623226401; validation accuracy : 0.895397489539749\n",
      "Epoch 17:\t train loss : 0.5877697740899148; train accuracy : 0.9637240930636017; \n",
      " validation loss : 0.6405547844963506; validation accuracy : 0.9079497907949791\n",
      "Epoch 18:\t train loss : 0.582813313922779; train accuracy : 0.968609312556151; \n",
      " validation loss : 0.6605900446743; validation accuracy : 0.891213389121339\n",
      "Epoch 19:\t train loss : 0.587122521383899; train accuracy : 0.9640670404907216; \n",
      " validation loss : 0.6177620627464118; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5823449549628947; train accuracy : 0.9688859630100065; \n",
      " validation loss : 0.6409510363132972; validation accuracy : 0.9079497907949791\n",
      "Epoch 21:\t train loss : 0.5837141425865467; train accuracy : 0.9673760029740698; \n",
      " validation loss : 0.6390135131990593; validation accuracy : 0.9163179916317992\n",
      "Epoch 22:\t train loss : 0.5860853178452328; train accuracy : 0.9649964373121844; \n",
      " validation loss : 0.6250475374654839; validation accuracy : 0.9246861924686193\n",
      "Epoch 23:\t train loss : 0.579367330583439; train accuracy : 0.972177886551628; \n",
      " validation loss : 0.6306611867401243; validation accuracy : 0.9205020920502092\n",
      "Epoch 24:\t train loss : 0.5755085654116486; train accuracy : 0.9757213668329254; \n",
      " validation loss : 0.6220485678265283; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5885732276767418; train accuracy : 0.9624192199262679; \n",
      " validation loss : 0.6449125501186634; validation accuracy : 0.9037656903765691\n",
      "Epoch 26:\t train loss : 0.5795692395147575; train accuracy : 0.9719455373462623; \n",
      " validation loss : 0.6186910244987852; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5817498654408823; train accuracy : 0.9694265621611574; \n",
      " validation loss : 0.6135867012728815; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5811286288130139; train accuracy : 0.9700926298832058; \n",
      " validation loss : 0.627644756062561; validation accuracy : 0.9205020920502092\n",
      "Epoch 29:\t train loss : 0.5766855375085116; train accuracy : 0.9746039220545866; \n",
      " validation loss : 0.62029259245734; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.5749829724123091; train accuracy : 0.9760135072338053; \n",
      " validation loss : 0.6137735262880589; validation accuracy : 0.9372384937238494\n",
      "Epoch 31:\t train loss : 0.5733625487984023; train accuracy : 0.9779401468446978; \n",
      " validation loss : 0.617054726104638; validation accuracy : 0.9288702928870293\n",
      "Epoch 32:\t train loss : 0.5778904961410285; train accuracy : 0.9731072833730908; \n",
      " validation loss : 0.6162504411084679; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5746317947287453; train accuracy : 0.9765423340252176; \n",
      " validation loss : 0.6463913125893039; validation accuracy : 0.9037656903765691\n",
      "Epoch 34:\t train loss : 0.5746229564831398; train accuracy : 0.9765268440781932; \n",
      " validation loss : 0.6368276085998074; validation accuracy : 0.9163179916317992\n",
      "Epoch 35:\t train loss : 0.5771129904316178; train accuracy : 0.9736900151801481; \n",
      " validation loss : 0.6507382939194222; validation accuracy : 0.895397489539749\n",
      "Epoch 36:\t train loss : 0.5697563468494026; train accuracy : 0.9814755723535425; \n",
      " validation loss : 0.6233945613299986; validation accuracy : 0.9246861924686193\n",
      "Epoch 37:\t train loss : 0.5786796467869667; train accuracy : 0.9723910282226835; \n",
      " validation loss : 0.6147940270702984; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5869457401682903; train accuracy : 0.963606059667276; \n",
      " validation loss : 0.6038074706738585; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.580093018984929; train accuracy : 0.9705765358282474; \n",
      " validation loss : 0.6226737986871165; validation accuracy : 0.9288702928870293\n",
      "Epoch 40:\t train loss : 0.5814975284646507; train accuracy : 0.9693955822671086; \n",
      " validation loss : 0.6358141990079087; validation accuracy : 0.9121338912133892\n",
      "Epoch 41:\t train loss : 0.5724803031223676; train accuracy : 0.9790399330834288; \n",
      " validation loss : 0.6090312446408811; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.5709800981035705; train accuracy : 0.9801242293751355; \n",
      " validation loss : 0.6230045880990825; validation accuracy : 0.9288702928870293\n",
      "Epoch 43:\t train loss : 0.5682207825574538; train accuracy : 0.9830886954366616; \n",
      " validation loss : 0.6258728857140682; validation accuracy : 0.9205020920502092\n",
      "Epoch 44:\t train loss : 0.5704200598463982; train accuracy : 0.9807769757427429; \n",
      " validation loss : 0.6070279476487837; validation accuracy : 0.9414225941422594\n",
      "Epoch 45:\t train loss : 0.5668533523903285; train accuracy : 0.9842873075374082; \n",
      " validation loss : 0.5968727390102018; validation accuracy : 0.9497907949790795\n",
      "Epoch 46:\t train loss : 0.5702508547767939; train accuracy : 0.9808116732240776; \n",
      " validation loss : 0.6151352014163751; validation accuracy : 0.9414225941422594\n",
      "Epoch 47:\t train loss : 0.5686357708715776; train accuracy : 0.9825892995445956; \n",
      " validation loss : 0.6170688846190521; validation accuracy : 0.9372384937238494\n",
      "Epoch 48:\t train loss : 0.564053730904761; train accuracy : 0.9871315716100251; \n",
      " validation loss : 0.6110031424464042; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.571571352152319; train accuracy : 0.9795687598748413; \n",
      " validation loss : 0.6145667542831709; validation accuracy : 0.9330543933054394\n",
      "Epoch 50:\t train loss : 0.5668480339301275; train accuracy : 0.9842873075374082; \n",
      " validation loss : 0.5937258074038693; validation accuracy : 0.9539748953974896\n",
      "Epoch 51:\t train loss : 0.5966924235840748; train accuracy : 0.9539734812106943; \n",
      " validation loss : 0.589452133880324; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:\t train loss : 0.5810558408098481; train accuracy : 0.96961244152545; \n",
      " validation loss : 0.6066910478183551; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.569598741548464; train accuracy : 0.9815610768611172; \n",
      " validation loss : 0.5808637978798843; validation accuracy : 0.9665271966527197\n",
      "Epoch 54:\t train loss : 0.5651953042154015; train accuracy : 0.9861055175191301; \n",
      " validation loss : 0.5978892351159005; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.5729888313777652; train accuracy : 0.9780036556274978; \n",
      " validation loss : 0.6103491578530639; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.579925979516967; train accuracy : 0.9710530065987174; \n",
      " validation loss : 0.5970972649368941; validation accuracy : 0.9539748953974896\n",
      "Epoch 57:\t train loss : 0.5672255856390591; train accuracy : 0.9838882865020602; \n",
      " validation loss : 0.610465217252873; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5651498228719606; train accuracy : 0.9860878589795223; \n",
      " validation loss : 0.6117837442599869; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.562692826538041; train accuracy : 0.9885315530220886; \n",
      " validation loss : 0.5968158017443428; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5649967717197735; train accuracy : 0.9863223767774715; \n",
      " validation loss : 0.6043923549863566; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5676054420632457; train accuracy : 0.9836581058892778; \n",
      " validation loss : 0.602764682630067; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5741032435094275; train accuracy : 0.9768034945320487; \n",
      " validation loss : 0.6130307786975372; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5796454557878676; train accuracy : 0.9713377118250256; \n",
      " validation loss : 0.5882597663395726; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.5647080224556983; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.5793272465420991; validation accuracy : 0.9707112970711297\n",
      "Epoch 65:\t train loss : 0.5635139172127273; train accuracy : 0.9876796059357477; \n",
      " validation loss : 0.5859093386302693; validation accuracy : 0.9665271966527197\n",
      "Epoch 66:\t train loss : 0.5614525482412507; train accuracy : 0.9897766349639084; \n",
      " validation loss : 0.5920806011463076; validation accuracy : 0.9581589958158996\n",
      "Epoch 67:\t train loss : 0.5613115562570514; train accuracy : 0.9899566281483317; \n",
      " validation loss : 0.5957259817843602; validation accuracy : 0.9581589958158996\n",
      "Epoch 68:\t train loss : 0.5659022096506957; train accuracy : 0.9853406239350662; \n",
      " validation loss : 0.6032893527763369; validation accuracy : 0.9497907949790795\n",
      "Epoch 69:\t train loss : 0.5619101393980388; train accuracy : 0.9893525202143809; \n",
      " validation loss : 0.6104526526535663; validation accuracy : 0.9372384937238494\n",
      "Epoch 70:\t train loss : 0.5627520684169256; train accuracy : 0.9885374392019579; \n",
      " validation loss : 0.5908838668796202; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5622263125026846; train accuracy : 0.9890833049350971; \n",
      " validation loss : 0.6036408768380868; validation accuracy : 0.9456066945606695\n",
      "Epoch 72:\t train loss : 0.5652879749024758; train accuracy : 0.9859661079959107; \n",
      " validation loss : 0.5947528492589792; validation accuracy : 0.9581589958158996\n",
      "Epoch 73:\t train loss : 0.5616874352387403; train accuracy : 0.9897493726571455; \n",
      " validation loss : 0.6114560495834996; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.566134750980914; train accuracy : 0.9850463149416029; \n",
      " validation loss : 0.5909948439533801; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.5620416101206933; train accuracy : 0.989247808172496; \n",
      " validation loss : 0.6106478673000025; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5671265265403469; train accuracy : 0.9842002540351312; \n",
      " validation loss : 0.6088438122002315; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5617361913864884; train accuracy : 0.9896527153877134; \n",
      " validation loss : 0.5812987198717638; validation accuracy : 0.9707112970711297\n",
      "Epoch 78:\t train loss : 0.5611056491629256; train accuracy : 0.9901483936924935; \n",
      " validation loss : 0.5860729197802425; validation accuracy : 0.9665271966527197\n",
      "Epoch 79:\t train loss : 0.5705525589426564; train accuracy : 0.9804767805694105; \n",
      " validation loss : 0.5912371340646554; validation accuracy : 0.9623430962343096\n",
      "Epoch 80:\t train loss : 0.5658826194752186; train accuracy : 0.9851178784968555; \n",
      " validation loss : 0.5982927072168468; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5632449355377249; train accuracy : 0.9879488212150315; \n",
      " validation loss : 0.6045572783790158; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5616277574510693; train accuracy : 0.9894823259704452; \n",
      " validation loss : 0.5846993657744458; validation accuracy : 0.9665271966527197\n",
      "Epoch 83:\t train loss : 0.5612031175418538; train accuracy : 0.9901211313857307; \n",
      " validation loss : 0.6136675832221237; validation accuracy : 0.9372384937238494\n",
      "Epoch 84:\t train loss : 0.5686198343301251; train accuracy : 0.9823975340004337; \n",
      " validation loss : 0.6073683162359675; validation accuracy : 0.9414225941422594\n",
      "Epoch 105:\t train loss : 0.5570043593292529; train accuracy : 0.9942510610613712; \n",
      " validation loss : 0.5898628926914588; validation accuracy : 0.9623430962343096\n",
      "Epoch 106:\t train loss : 0.561169439557666; train accuracy : 0.9900340778834537; \n",
      " validation loss : 0.6016144238538496; validation accuracy : 0.9456066945606695\n",
      "Epoch 107:\t train loss : 0.5672580781218637; train accuracy : 0.9838786827349051; \n",
      " validation loss : 0.6004974621173969; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.5636755432402303; train accuracy : 0.9875748938938629; \n",
      " validation loss : 0.5839708364791575; validation accuracy : 0.9665271966527197\n",
      "Epoch 109:\t train loss : 0.5581829464687119; train accuracy : 0.9932714768115493; \n",
      " validation loss : 0.5842659187022928; validation accuracy : 0.9665271966527197\n",
      "Epoch 110:\t train loss : 0.5629279957065031; train accuracy : 0.9883146937637474; \n",
      " validation loss : 0.5911790453645318; validation accuracy : 0.9539748953974896\n",
      "Epoch 111:\t train loss : 0.5583133192366592; train accuracy : 0.9929926577651105; \n",
      " validation loss : 0.6001858059293645; validation accuracy : 0.9497907949790795\n",
      "Epoch 112:\t train loss : 0.5568825139246464; train accuracy : 0.9945202763406549; \n",
      " validation loss : 0.5905468129778392; validation accuracy : 0.9623430962343096\n",
      "Epoch 113:\t train loss : 0.5577911084986296; train accuracy : 0.9936026518789306; \n",
      " validation loss : 0.5965469204538608; validation accuracy : 0.9497907949790795\n",
      "Epoch 114:\t train loss : 0.5584647821285491; train accuracy : 0.9927757985067691; \n",
      " validation loss : 0.5845789382354214; validation accuracy : 0.9665271966527197\n",
      "Epoch 115:\t train loss : 0.5601615981711201; train accuracy : 0.991189937730413; \n",
      " validation loss : 0.5908392937573083; validation accuracy : 0.9581589958158996\n",
      "Epoch 116:\t train loss : 0.5646698420896018; train accuracy : 0.986471390067846; \n",
      " validation loss : 0.5923620417207376; validation accuracy : 0.9581589958158996\n",
      "Epoch 117:\t train loss : 0.5672821843506964; train accuracy : 0.983905945041668; \n",
      " validation loss : 0.5988297661881432; validation accuracy : 0.9539748953974896\n",
      "Epoch 118:\t train loss : 0.5583368106649573; train accuracy : 0.9930081477121349; \n",
      " validation loss : 0.5932608800850073; validation accuracy : 0.9581589958158996\n",
      "Epoch 119:\t train loss : 0.5580638447254941; train accuracy : 0.9932714768115493; \n",
      " validation loss : 0.5852572254106042; validation accuracy : 0.9665271966527197\n",
      "Epoch 120:\t train loss : 0.557131831939054; train accuracy : 0.9942222497599058; \n",
      " validation loss : 0.5914007933951885; validation accuracy : 0.9581589958158996\n",
      "Epoch 121:\t train loss : 0.5573524745123779; train accuracy : 0.9939279407664425; \n",
      " validation loss : 0.5832828715724834; validation accuracy : 0.9665271966527197\n",
      "Epoch 122:\t train loss : 0.555458488683851; train accuracy : 0.9959298615198736; \n",
      " validation loss : 0.5893963686260564; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123:\t train loss : 0.5577915003121965; train accuracy : 0.9934108863347687; \n",
      " validation loss : 0.6018265978707104; validation accuracy : 0.9497907949790795\n",
      "Epoch 124:\t train loss : 0.5611856181328441; train accuracy : 0.9901462250999101; \n",
      " validation loss : 0.6053632919016405; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5616173608004661; train accuracy : 0.9895538895256978; \n",
      " validation loss : 0.5842369772697773; validation accuracy : 0.9665271966527197\n",
      "Epoch 126:\t train loss : 0.5582077530064092; train accuracy : 0.9931357848756157; \n",
      " validation loss : 0.6007067461927745; validation accuracy : 0.9456066945606695\n",
      "Epoch 127:\t train loss : 0.5572033348744693; train accuracy : 0.994154403791939; \n",
      " validation loss : 0.5955892189110705; validation accuracy : 0.9539748953974896\n",
      "Epoch 128:\t train loss : 0.5561465212872374; train accuracy : 0.9952077201895969; \n",
      " validation loss : 0.5960467687569547; validation accuracy : 0.9581589958158996\n",
      "Epoch 129:\t train loss : 0.5595490879716216; train accuracy : 0.9918367979181512; \n",
      " validation loss : 0.5967286314833955; validation accuracy : 0.9539748953974896\n",
      "Epoch 130:\t train loss : 0.5598999249032649; train accuracy : 0.9914030794014684; \n",
      " validation loss : 0.5929477780912199; validation accuracy : 0.9581589958158996\n",
      "Epoch 131:\t train loss : 0.5570674172136403; train accuracy : 0.9942842095480033; \n",
      " validation loss : 0.5984279789124601; validation accuracy : 0.9497907949790795\n",
      "Epoch 132:\t train loss : 0.5618643813835118; train accuracy : 0.9893835001084297; \n",
      " validation loss : 0.5899858884815095; validation accuracy : 0.9623430962343096\n",
      "Epoch 133:\t train loss : 0.5592785288189717; train accuracy : 0.9919179652405589; \n",
      " validation loss : 0.6141293371336846; validation accuracy : 0.9330543933054394\n",
      "Epoch 134:\t train loss : 0.5603492473560813; train accuracy : 0.9909944545989653; \n",
      " validation loss : 0.5983120360951637; validation accuracy : 0.9497907949790795\n",
      "Epoch 135:\t train loss : 0.5629167660844767; train accuracy : 0.9883301837107717; \n",
      " validation loss : 0.5953232802995966; validation accuracy : 0.9539748953974896\n",
      "Epoch 136:\t train loss : 0.5587343815076128; train accuracy : 0.9926267852163946; \n",
      " validation loss : 0.5891265878037956; validation accuracy : 0.9623430962343096\n",
      "Epoch 137:\t train loss : 0.5580507280182587; train accuracy : 0.9932869667585736; \n",
      " validation loss : 0.5944673906630003; validation accuracy : 0.9539748953974896\n",
      "Epoch 138:\t train loss : 0.5705614028008988; train accuracy : 0.9808020694569225; \n",
      " validation loss : 0.5933188747286375; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5646597613629308; train accuracy : 0.9865392360358127; \n",
      " validation loss : 0.6074822983035287; validation accuracy : 0.9414225941422594\n",
      "Epoch 140:\t train loss : 0.5646968989446055; train accuracy : 0.9865488398029679; \n",
      " validation loss : 0.5850404893616967; validation accuracy : 0.9665271966527197\n",
      "Epoch 141:\t train loss : 0.560724629353956; train accuracy : 0.9905142662412094; \n",
      " validation loss : 0.585165510648616; validation accuracy : 0.9665271966527197\n",
      "Epoch 142:\t train loss : 0.5562629477226962; train accuracy : 0.9951243842746058; \n",
      " validation loss : 0.5938493896122191; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 142\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5589829511003973; Train accuracy : 0.9924099259580532; \n",
      " Validation loss : 0.572150938405079; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 79 ! ---\n",
      "Epoch 1:\t train loss : 0.9052516283759517; train accuracy : 0.6220022305523715; \n",
      " validation loss : 0.7835926520121076; validation accuracy : 0.7615062761506276\n",
      "Epoch 2:\t train loss : 0.7330010748933857; train accuracy : 0.8169673781715666; \n",
      " validation loss : 0.7189780935628302; validation accuracy : 0.8284518828451883\n",
      "Epoch 3:\t train loss : 0.692024651252917; train accuracy : 0.85824653799684; \n",
      " validation loss : 0.7296835703054244; validation accuracy : 0.8242677824267782\n",
      "Epoch 4:\t train loss : 0.6734291129518646; train accuracy : 0.877208401747266; \n",
      " validation loss : 0.7047528630303057; validation accuracy : 0.8451882845188284\n",
      "Epoch 5:\t train loss : 0.654326605463917; train accuracy : 0.8961179094767496; \n",
      " validation loss : 0.6628568511199949; validation accuracy : 0.8828451882845189\n",
      "Epoch 6:\t train loss : 0.6348035361699924; train accuracy : 0.9153911211623657; \n",
      " validation loss : 0.654989046905023; validation accuracy : 0.895397489539749\n",
      "Epoch 7:\t train loss : 0.623038269418744; train accuracy : 0.9279925028656402; \n",
      " validation loss : 0.6455215190868745; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6109539885026296; train accuracy : 0.9400281917035844; \n",
      " validation loss : 0.6369447777156068; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.6043463503029325; train accuracy : 0.9468053533256916; \n",
      " validation loss : 0.6077543212959317; validation accuracy : 0.9497907949790795\n",
      "Epoch 10:\t train loss : 0.5974118125778739; train accuracy : 0.9540118962793147; \n",
      " validation loss : 0.6275176057317214; validation accuracy : 0.9205020920502092\n",
      "Epoch 11:\t train loss : 0.597333897712709; train accuracy : 0.9540450447659469; \n",
      " validation loss : 0.6228858063890078; validation accuracy : 0.9330543933054394\n",
      "Epoch 12:\t train loss : 0.5908263691183357; train accuracy : 0.9605390501564485; \n",
      " validation loss : 0.6228055215198214; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.5870611875129206; train accuracy : 0.9645162489544286; \n",
      " validation loss : 0.6113114290444849; validation accuracy : 0.9414225941422594\n",
      "Epoch 14:\t train loss : 0.5864527799428014; train accuracy : 0.9650887573964497; \n",
      " validation loss : 0.62379270446947; validation accuracy : 0.9288702928870293\n",
      "Epoch 15:\t train loss : 0.5992899761208956; train accuracy : 0.9514250751262431; \n",
      " validation loss : 0.6183383214813346; validation accuracy : 0.9372384937238494\n",
      "Epoch 16:\t train loss : 0.5874037940805824; train accuracy : 0.9638074289785928; \n",
      " validation loss : 0.6037839038021694; validation accuracy : 0.9497907949790795\n",
      "Epoch 17:\t train loss : 0.583006241063823; train accuracy : 0.9681077480715016; \n",
      " validation loss : 0.615948836650945; validation accuracy : 0.9372384937238494\n",
      "Epoch 18:\t train loss : 0.5811598924606969; train accuracy : 0.9703308652684408; \n",
      " validation loss : 0.6238997892478192; validation accuracy : 0.9246861924686193\n",
      "Epoch 19:\t train loss : 0.5826295838044201; train accuracy : 0.9686269710957588; \n",
      " validation loss : 0.6017407298521347; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5793099180079689; train accuracy : 0.9718990675051892; \n",
      " validation loss : 0.5997530558444056; validation accuracy : 0.9539748953974896\n",
      "Epoch 21:\t train loss : 0.58040270988029; train accuracy : 0.9708612410545556; \n",
      " validation loss : 0.6004971398242251; validation accuracy : 0.9456066945606695\n",
      "Epoch 22:\t train loss : 0.5816904907560245; train accuracy : 0.9696936088478577; \n",
      " validation loss : 0.6083547465119125; validation accuracy : 0.9456066945606695\n",
      "Epoch 23:\t train loss : 0.5838732099047117; train accuracy : 0.9671259952290963; \n",
      " validation loss : 0.611934732108969; validation accuracy : 0.9414225941422594\n",
      "Epoch 24:\t train loss : 0.5859819464168117; train accuracy : 0.9651197372904985; \n",
      " validation loss : 0.6276649283472326; validation accuracy : 0.9205020920502092\n",
      "Epoch 25:\t train loss : 0.5850403947046174; train accuracy : 0.9660748474240218; \n",
      " validation loss : 0.6341275861484573; validation accuracy : 0.9121338912133892\n",
      "Epoch 26:\t train loss : 0.5773662760374069; train accuracy : 0.9738080485764739; \n",
      " validation loss : 0.6117027919671421; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5753205112439174; train accuracy : 0.9759109637845038; \n",
      " validation loss : 0.6169715901486453; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5818823584250371; train accuracy : 0.969223024257257; \n",
      " validation loss : 0.6256995643950769; validation accuracy : 0.9246861924686193\n",
      "Epoch 29:\t train loss : 0.5812981421907283; train accuracy : 0.9699687103070107; \n",
      " validation loss : 0.6000836529555311; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.5771548723343047; train accuracy : 0.9740072492952074; \n",
      " validation loss : 0.628750911644751; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:\t train loss : 0.581098429813016; train accuracy : 0.9700071253756312; \n",
      " validation loss : 0.6305871068891757; validation accuracy : 0.9246861924686193\n",
      "Epoch 32:\t train loss : 0.57929922143152; train accuracy : 0.9715427987236284; \n",
      " validation loss : 0.6050299442460134; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.571463351743568; train accuracy : 0.9797775643607299; \n",
      " validation loss : 0.6048533730507257; validation accuracy : 0.9456066945606695\n",
      "Epoch 34:\t train loss : 0.5684515430113513; train accuracy : 0.9828814399454754; \n",
      " validation loss : 0.6094444304091441; validation accuracy : 0.9414225941422594\n",
      "Epoch 35:\t train loss : 0.56582582257684; train accuracy : 0.9855943492673255; \n",
      " validation loss : 0.5930498363318221; validation accuracy : 0.9581589958158996\n",
      "Epoch 36:\t train loss : 0.5649042371922564; train accuracy : 0.9863880541528548; \n",
      " validation loss : 0.5979795940653273; validation accuracy : 0.9497907949790795\n",
      "Epoch 37:\t train loss : 0.5641651571975033; train accuracy : 0.9872186251123021; \n",
      " validation loss : 0.6104715672047636; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5705622343355445; train accuracy : 0.9806273428544875; \n",
      " validation loss : 0.7147879145631122; validation accuracy : 0.8410041841004184\n",
      "Epoch 39:\t train loss : 0.5802841285303008; train accuracy : 0.9706406642089284; \n",
      " validation loss : 0.610164731028279; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.5749037850261531; train accuracy : 0.9759419436785526; \n",
      " validation loss : 0.6377927624059226; validation accuracy : 0.9121338912133892\n",
      "Epoch 41:\t train loss : 0.5705922090801804; train accuracy : 0.9805852101985811; \n",
      " validation loss : 0.635250585216048; validation accuracy : 0.9205020920502092\n",
      "Epoch 42:\t train loss : 0.5681347151885622; train accuracy : 0.9830326218284333; \n",
      " validation loss : 0.609091542905483; validation accuracy : 0.9330543933054394\n",
      "Epoch 43:\t train loss : 0.5685580957751784; train accuracy : 0.9826181108460609; \n",
      " validation loss : 0.6101840570910756; validation accuracy : 0.9372384937238494\n",
      "Epoch 44:\t train loss : 0.5664444640845616; train accuracy : 0.9849069054183834; \n",
      " validation loss : 0.6118246525337689; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5646266132588214; train accuracy : 0.9866107995910655; \n",
      " validation loss : 0.6035940439582362; validation accuracy : 0.9497907949790795\n",
      "Epoch 46:\t train loss : 0.5629216193156846; train accuracy : 0.9883921434988693; \n",
      " validation loss : 0.6105794370617322; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.5649708222485784; train accuracy : 0.9861402150004647; \n",
      " validation loss : 0.610298550842008; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.5632513033046572; train accuracy : 0.9880668546113572; \n",
      " validation loss : 0.6050749664198996; validation accuracy : 0.9456066945606695\n",
      "Epoch 49:\t train loss : 0.5683647253210166; train accuracy : 0.9827575203692803; \n",
      " validation loss : 0.6101286226004312; validation accuracy : 0.9414225941422594\n",
      "Epoch 50:\t train loss : 0.5660012983631763; train accuracy : 0.9851916106446916; \n",
      " validation loss : 0.5983169401817455; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.56671289493064; train accuracy : 0.9844267170606277; \n",
      " validation loss : 0.5929148738899741; validation accuracy : 0.9581589958158996\n",
      "Epoch 52:\t train loss : 0.5801683290046075; train accuracy : 0.9703987112364075; \n",
      " validation loss : 0.6109365059696794; validation accuracy : 0.9414225941422594\n",
      "Epoch 53:\t train loss : 0.5667870063900109; train accuracy : 0.9845137705629047; \n",
      " validation loss : 0.6065268929907655; validation accuracy : 0.9456066945606695\n",
      "Epoch 54:\t train loss : 0.5673765222461952; train accuracy : 0.9839443601102884; \n",
      " validation loss : 0.6134080225539515; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.5630554019928529; train accuracy : 0.98827194150996; \n",
      " validation loss : 0.5853441166947103; validation accuracy : 0.9665271966527197\n",
      "Epoch 56:\t train loss : 0.5610474776034264; train accuracy : 0.9901889773536975; \n",
      " validation loss : 0.5914998736767026; validation accuracy : 0.9581589958158996\n",
      "Epoch 57:\t train loss : 0.5608591924278618; train accuracy : 0.9904966077016016; \n",
      " validation loss : 0.6052047229552142; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5637911760746038; train accuracy : 0.9874066730691781; \n",
      " validation loss : 0.6069226860924146; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5603423183467351; train accuracy : 0.9910291520802998; \n",
      " validation loss : 0.6210725343875787; validation accuracy : 0.9288702928870293\n",
      "Epoch 60:\t train loss : 0.5822109974562535; train accuracy : 0.9687332321323461; \n",
      " validation loss : 0.6184756325384625; validation accuracy : 0.9330543933054394\n",
      "Epoch 61:\t train loss : 0.5806247342024385; train accuracy : 0.9701332135444096; \n",
      " validation loss : 0.6074238333018026; validation accuracy : 0.9456066945606695\n",
      "Epoch 62:\t train loss : 0.5909556383975693; train accuracy : 0.9594665262244803; \n",
      " validation loss : 0.6199106420797135; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5677781857661132; train accuracy : 0.9835806561541559; \n",
      " validation loss : 0.5894986152438653; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.5726763544709624; train accuracy : 0.978184268409802; \n",
      " validation loss : 0.5846971158237223; validation accuracy : 0.9665271966527197\n",
      "Epoch 65:\t train loss : 0.5617220547734451; train accuracy : 0.9895848694197465; \n",
      " validation loss : 0.6004377796492895; validation accuracy : 0.9456066945606695\n",
      "Epoch 66:\t train loss : 0.5629138692148736; train accuracy : 0.988459989466836; \n",
      " validation loss : 0.5811671533558449; validation accuracy : 0.9707112970711297\n",
      "Epoch 67:\t train loss : 0.5607223101105777; train accuracy : 0.9907679915734688; \n",
      " validation loss : 0.6032420258656186; validation accuracy : 0.9456066945606695\n",
      "Epoch 68:\t train loss : 0.5611755239562538; train accuracy : 0.9901889773536975; \n",
      " validation loss : 0.6155794344144203; validation accuracy : 0.9372384937238494\n",
      "Epoch 69:\t train loss : 0.5625431800983645; train accuracy : 0.9888162582483968; \n",
      " validation loss : 0.5961312316941965; validation accuracy : 0.9581589958158996\n",
      "Epoch 70:\t train loss : 0.5615341912388904; train accuracy : 0.9896991852287865; \n",
      " validation loss : 0.5855103393813428; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.562281320070569; train accuracy : 0.9890582112209176; \n",
      " validation loss : 0.609161902498896; validation accuracy : 0.9414225941422594\n",
      "Epoch 72:\t train loss : 0.5638230145482312; train accuracy : 0.9874841228043; \n",
      " validation loss : 0.5960563745012327; validation accuracy : 0.9539748953974896\n",
      "Epoch 73:\t train loss : 0.5665719460104072; train accuracy : 0.9845816165308715; \n",
      " validation loss : 0.598217080841247; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5651970617075185; train accuracy : 0.9861519873602033; \n",
      " validation loss : 0.6002404110386712; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5610712670842575; train accuracy : 0.9903166145171783; \n",
      " validation loss : 0.5940479064440868; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5597633638648826; train accuracy : 0.9915056228507698; \n",
      " validation loss : 0.5849716533574445; validation accuracy : 0.9665271966527197\n",
      "Epoch 77:\t train loss : 0.5658237213468712; train accuracy : 0.9853406239350662; \n",
      " validation loss : 0.5933957375710539; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5692821718377138; train accuracy : 0.9818281235478175; \n",
      " validation loss : 0.6188710718595799; validation accuracy : 0.9330543933054394\n",
      "Epoch 79:\t train loss : 0.5651439765664715; train accuracy : 0.9861210074661545; \n",
      " validation loss : 0.589899999458536; validation accuracy : 0.9623430962343096\n",
      "Epoch 80:\t train loss : 0.5633136281633272; train accuracy : 0.9879525388023173; \n",
      " validation loss : 0.5933513544488033; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.561302958792058; train accuracy : 0.9900650577775024; \n",
      " validation loss : 0.5995013032534123; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82:\t train loss : 0.5597764566182338; train accuracy : 0.99163914619412; \n",
      " validation loss : 0.6103195028609505; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5613866982371035; train accuracy : 0.9898327085721367; \n",
      " validation loss : 0.6015481903510371; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5664178904606689; train accuracy : 0.9848235695033923; \n",
      " validation loss : 0.596914131606357; validation accuracy : 0.9539748953974896\n",
      "Epoch 85:\t train loss : 0.5626268941701872; train accuracy : 0.9887366399206915; \n",
      " validation loss : 0.5922374225911674; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5603868717232854; train accuracy : 0.9908860249697946; \n",
      " validation loss : 0.60007309892573; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5590536936461272; train accuracy : 0.9923169862759069; \n",
      " validation loss : 0.6263201990033247; validation accuracy : 0.9246861924686193\n",
      "Epoch 88:\t train loss : 0.5617202231294163; train accuracy : 0.9895266272189349; \n",
      " validation loss : 0.5826204681531779; validation accuracy : 0.9707112970711297\n",
      "Epoch 89:\t train loss : 0.5612921074501303; train accuracy : 0.9900554540103473; \n",
      " validation loss : 0.5867088302852245; validation accuracy : 0.9665271966527197\n",
      "Epoch 90:\t train loss : 0.5650970045025526; train accuracy : 0.986146101180334; \n",
      " validation loss : 0.6095462964835614; validation accuracy : 0.9414225941422594\n",
      "Epoch 91:\t train loss : 0.5647930651723164; train accuracy : 0.986357074258806; \n",
      " validation loss : 0.5847781636144993; validation accuracy : 0.9665271966527197\n",
      "Epoch 92:\t train loss : 0.5710517650884874; train accuracy : 0.9802385451841754; \n",
      " validation loss : 0.5868595780238948; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.565404866620114; train accuracy : 0.985682951764305; \n",
      " validation loss : 0.5910213126035345; validation accuracy : 0.9623430962343096\n",
      "Epoch 94:\t train loss : 0.5638243140168925; train accuracy : 0.9872923572601382; \n",
      " validation loss : 0.5891593902347124; validation accuracy : 0.9623430962343096\n",
      "Epoch 95:\t train loss : 0.5590898977616264; train accuracy : 0.9924040397781839; \n",
      " validation loss : 0.577049643052442; validation accuracy : 0.9748953974895398\n",
      "Epoch 96:\t train loss : 0.5600044213645521; train accuracy : 0.9913101397193221; \n",
      " validation loss : 0.5815122664925694; validation accuracy : 0.9707112970711297\n",
      "Epoch 97:\t train loss : 0.5583975246965601; train accuracy : 0.9929520741039065; \n",
      " validation loss : 0.5812400252950466; validation accuracy : 0.9707112970711297\n",
      "Epoch 98:\t train loss : 0.5579648271462738; train accuracy : 0.9933703026735649; \n",
      " validation loss : 0.5974423118855442; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5682564822562964; train accuracy : 0.9829839833947768; \n",
      " validation loss : 0.6420223524522536; validation accuracy : 0.9079497907949791\n",
      "Epoch 100:\t train loss : 0.5656408425008804; train accuracy : 0.9855574831934075; \n",
      " validation loss : 0.5965006488202551; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5631993885113761; train accuracy : 0.988070572198643; \n",
      " validation loss : 0.5898012334041361; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.5699121080091322; train accuracy : 0.9813501037826451; \n",
      " validation loss : 0.6050742249673887; validation accuracy : 0.9456066945606695\n",
      "Epoch 103:\t train loss : 0.5607766940579354; train accuracy : 0.9905356423681031; \n",
      " validation loss : 0.5951357802373508; validation accuracy : 0.9539748953974896\n",
      "Epoch 104:\t train loss : 0.5600116104877293; train accuracy : 0.9913448372006568; \n",
      " validation loss : 0.5898042852295765; validation accuracy : 0.9623430962343096\n",
      "Epoch 105:\t train loss : 0.5625152715860253; train accuracy : 0.9887270361535363; \n",
      " validation loss : 0.6016564223588754; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.5597098659548017; train accuracy : 0.991676012268038; \n",
      " validation loss : 0.5926303624700977; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5675678738705524; train accuracy : 0.9836426159422534; \n",
      " validation loss : 0.5952611118504084; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5602900144109959; train accuracy : 0.9909789646519409; \n",
      " validation loss : 0.5885850168717454; validation accuracy : 0.9623430962343096\n",
      "Epoch 109:\t train loss : 0.5628886768587096; train accuracy : 0.9885219492549335; \n",
      " validation loss : 0.6062482096127477; validation accuracy : 0.9456066945606695\n",
      "Epoch 110:\t train loss : 0.5603660134508868; train accuracy : 0.9909170048638434; \n",
      " validation loss : 0.5933049775488347; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.5592191738581179; train accuracy : 0.9921620868056631; \n",
      " validation loss : 0.5764842716510827; validation accuracy : 0.9748953974895398\n",
      "Epoch 112:\t train loss : 0.5586542499802387; train accuracy : 0.9926887450044921; \n",
      " validation loss : 0.5893664142129005; validation accuracy : 0.9623430962343096\n",
      "Epoch 113:\t train loss : 0.5631098536196548; train accuracy : 0.9882062641345767; \n",
      " validation loss : 0.6001952561074769; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5641499424009796; train accuracy : 0.9871256854301558; \n",
      " validation loss : 0.6128607901093711; validation accuracy : 0.9372384937238494\n",
      "Epoch 115:\t train loss : 0.5632079636946242; train accuracy : 0.9880048948232597; \n",
      " validation loss : 0.6039244079953846; validation accuracy : 0.9456066945606695\n",
      "Epoch 116:\t train loss : 0.5591017671085388; train accuracy : 0.9923361938102172; \n",
      " validation loss : 0.5875369459029962; validation accuracy : 0.9623430962343096\n",
      "Epoch 117:\t train loss : 0.5678134270090144; train accuracy : 0.9834641717525326; \n",
      " validation loss : 0.5982772426579208; validation accuracy : 0.9539748953974896\n",
      "Epoch 118:\t train loss : 0.5626501356070256; train accuracy : 0.9887211499736671; \n",
      " validation loss : 0.5864864658713815; validation accuracy : 0.9665271966527197\n",
      "Epoch 119:\t train loss : 0.5623857402499812; train accuracy : 0.9888140896558134; \n",
      " validation loss : 0.5933472431695158; validation accuracy : 0.9581589958158996\n",
      "Epoch 120:\t train loss : 0.5594923119577988; train accuracy : 0.9917977632516497; \n",
      " validation loss : 0.5949399097890361; validation accuracy : 0.9539748953974896\n",
      "Epoch 121:\t train loss : 0.559650556996617; train accuracy : 0.9918095356113882; \n",
      " validation loss : 0.6109997792727775; validation accuracy : 0.9372384937238494\n",
      "Epoch 122:\t train loss : 0.5653368230520434; train accuracy : 0.98585767836674; \n",
      " validation loss : 0.601536924356792; validation accuracy : 0.9497907949790795\n",
      "Epoch 123:\t train loss : 0.5742390161279172; train accuracy : 0.9769760525419003; \n",
      " validation loss : 0.5891357179799014; validation accuracy : 0.9623430962343096\n",
      "Epoch 124:\t train loss : 0.5641164938285711; train accuracy : 0.9871278540227393; \n",
      " validation loss : 0.5883330765069503; validation accuracy : 0.9623430962343096\n",
      "Epoch 125:\t train loss : 0.5594135946455986; train accuracy : 0.9918987577062487; \n",
      " validation loss : 0.5915186270262873; validation accuracy : 0.9581589958158996\n",
      "Epoch 126:\t train loss : 0.5609273943520514; train accuracy : 0.99037485671799; \n",
      " validation loss : 0.5874776525136222; validation accuracy : 0.9623430962343096\n",
      "Epoch 127:\t train loss : 0.560088367066611; train accuracy : 0.9911862201431271; \n",
      " validation loss : 0.5932736909283819; validation accuracy : 0.9581589958158996\n",
      "Epoch 128:\t train loss : 0.561096146795467; train accuracy : 0.9902413333746398; \n",
      " validation loss : 0.5941835472343691; validation accuracy : 0.9539748953974896\n",
      "Epoch 129:\t train loss : 0.566531596132253; train accuracy : 0.9847749310697358; \n",
      " validation loss : 0.6153234219780035; validation accuracy : 0.9372384937238494\n",
      "Epoch 130:\t train loss : 0.560632151469852; train accuracy : 0.9907989714675176; \n",
      " validation loss : 0.5890889012517521; validation accuracy : 0.9623430962343096\n",
      "Epoch 131:\t train loss : 0.5583292839620916; train accuracy : 0.9929830539979553; \n",
      " validation loss : 0.5932689991002043; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.5578396360819161; train accuracy : 0.9936159732333716; \n",
      " validation loss : 0.6027172410114983; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133:\t train loss : 0.5608086658083544; train accuracy : 0.99048917252703; \n",
      " validation loss : 0.5974734872869335; validation accuracy : 0.9539748953974896\n",
      "Epoch 134:\t train loss : 0.5611513636526638; train accuracy : 0.9900030979894049; \n",
      " validation loss : 0.5898956069837896; validation accuracy : 0.9623430962343096\n",
      "Epoch 135:\t train loss : 0.5583424848519699; train accuracy : 0.9929306979770129; \n",
      " validation loss : 0.605746658362815; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.5602138237364618; train accuracy : 0.9910350382601691; \n",
      " validation loss : 0.5987548795617126; validation accuracy : 0.9539748953974896\n",
      "Epoch 137:\t train loss : 0.5574394626853593; train accuracy : 0.9940053905015644; \n",
      " validation loss : 0.5953482148364377; validation accuracy : 0.9581589958158996\n",
      "Epoch 138:\t train loss : 0.55786570720679; train accuracy : 0.9934787323027355; \n",
      " validation loss : 0.5964277124356168; validation accuracy : 0.9539748953974896\n",
      "Epoch 139:\t train loss : 0.5580081476003906; train accuracy : 0.9932869667585736; \n",
      " validation loss : 0.5943158454341594; validation accuracy : 0.9539748953974896\n",
      "Epoch 140:\t train loss : 0.5600440395221831; train accuracy : 0.9912732736454041; \n",
      " validation loss : 0.6060402581163475; validation accuracy : 0.9456066945606695\n",
      "Epoch 141:\t train loss : 0.5779610394740714; train accuracy : 0.9730725858917563; \n",
      " validation loss : 0.5926651068804406; validation accuracy : 0.9581589958158996\n",
      "Epoch 142:\t train loss : 0.5624020276148693; train accuracy : 0.9889652715387713; \n",
      " validation loss : 0.5919239920791014; validation accuracy : 0.9581589958158996\n",
      "Epoch 143:\t train loss : 0.5571327169159954; train accuracy : 0.9941757799188327; \n",
      " validation loss : 0.5954621563682351; validation accuracy : 0.9581589958158996\n",
      "Epoch 144:\t train loss : 0.5591955657271219; train accuracy : 0.9922063880541528; \n",
      " validation loss : 0.5967180636487313; validation accuracy : 0.9539748953974896\n",
      "Epoch 145:\t train loss : 0.563295523314436; train accuracy : 0.9878382229932774; \n",
      " validation loss : 0.5852698238010984; validation accuracy : 0.9665271966527197\n",
      "Epoch 146:\t train loss : 0.5594283039750427; train accuracy : 0.9919179652405589; \n",
      " validation loss : 0.5848978000119066; validation accuracy : 0.9665271966527197\n",
      "Epoch 147:\t train loss : 0.5578849431429542; train accuracy : 0.9935097121967843; \n",
      " validation loss : 0.5849638760184247; validation accuracy : 0.9665271966527197\n",
      "Epoch 148:\t train loss : 0.5586114120860419; train accuracy : 0.9927757985067691; \n",
      " validation loss : 0.6025790649629191; validation accuracy : 0.9456066945606695\n",
      "Epoch 149:\t train loss : 0.5578723835042706; train accuracy : 0.9934477524086868; \n",
      " validation loss : 0.5922112515155846; validation accuracy : 0.9581589958158996\n",
      "Epoch 150:\t train loss : 0.5609398039203194; train accuracy : 0.9903454258186437; \n",
      " validation loss : 0.6510103702221919; validation accuracy : 0.899581589958159\n",
      "Epoch 151:\t train loss : 0.5651557158497149; train accuracy : 0.9859912017100901; \n",
      " validation loss : 0.6019761824676558; validation accuracy : 0.9497907949790795\n",
      "Epoch 152:\t train loss : 0.5588698064749739; train accuracy : 0.9924718857461508; \n",
      " validation loss : 0.5923199023690651; validation accuracy : 0.9581589958158996\n",
      "Epoch 153:\t train loss : 0.5580002374106474; train accuracy : 0.9933489265466712; \n",
      " validation loss : 0.60141755733948; validation accuracy : 0.9497907949790795\n",
      "Epoch 154:\t train loss : 0.5644624513463975; train accuracy : 0.9867966789553579; \n",
      " validation loss : 0.5951349733150679; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5594287823773728; train accuracy : 0.9918618916323306; \n",
      " validation loss : 0.59530805555471; validation accuracy : 0.9581589958158996\n",
      "Epoch 156:\t train loss : 0.5624087386258348; train accuracy : 0.9887793921744787; \n",
      " validation loss : 0.5993543816244115; validation accuracy : 0.9497907949790795\n",
      "Epoch 157:\t train loss : 0.5583617857240828; train accuracy : 0.9929306979770129; \n",
      " validation loss : 0.6097848250107055; validation accuracy : 0.9414225941422594\n",
      "Epoch 158:\t train loss : 0.5564114283590643; train accuracy : 0.9950122370581492; \n",
      " validation loss : 0.5909009296700355; validation accuracy : 0.9623430962343096\n",
      "Epoch 159:\t train loss : 0.5563748067604365; train accuracy : 0.9949289011431581; \n",
      " validation loss : 0.6000109730207018; validation accuracy : 0.9497907949790795\n",
      "Epoch 160:\t train loss : 0.5578214896606215; train accuracy : 0.9935502958579882; \n",
      " validation loss : 0.5848290471665327; validation accuracy : 0.9665271966527197\n",
      "Epoch 161:\t train loss : 0.5625337489644586; train accuracy : 0.9887248675609529; \n",
      " validation loss : 0.6063520926596053; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 161\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5592191738581179; Train accuracy : 0.9921620868056631; \n",
      " Validation loss : 0.5764842716510827; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 80 ! ---\n",
      "Epoch 1:\t train loss : 0.9321065327575966; train accuracy : 0.5985953716038291; \n",
      " validation loss : 0.8010434206512738; validation accuracy : 0.7447698744769874\n",
      "Epoch 2:\t train loss : 0.7465819502339343; train accuracy : 0.8032609436475727; \n",
      " validation loss : 0.7445016229976961; validation accuracy : 0.803347280334728\n",
      "Epoch 3:\t train loss : 0.700263449726537; train accuracy : 0.8494947179280646; \n",
      " validation loss : 0.696345614435935; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.6790711668000868; train accuracy : 0.8722110350382601; \n",
      " validation loss : 0.69273206578368; validation accuracy : 0.8493723849372385\n",
      "Epoch 5:\t train loss : 0.6644031872844084; train accuracy : 0.8865296322686577; \n",
      " validation loss : 0.6782090173929701; validation accuracy : 0.8661087866108786\n",
      "Epoch 6:\t train loss : 0.6499549559681626; train accuracy : 0.900536261965984; \n",
      " validation loss : 0.6914490212643297; validation accuracy : 0.8493723849372385\n",
      "Epoch 7:\t train loss : 0.6343472471156383; train accuracy : 0.9165513181944918; \n",
      " validation loss : 0.6497314370590993; validation accuracy : 0.895397489539749\n",
      "Epoch 8:\t train loss : 0.6262934820014884; train accuracy : 0.9245943182874314; \n",
      " validation loss : 0.647806916635806; validation accuracy : 0.9037656903765691\n",
      "Epoch 9:\t train loss : 0.6196469387246907; train accuracy : 0.9310269834877165; \n",
      " validation loss : 0.6289842982212036; validation accuracy : 0.9246861924686193\n",
      "Epoch 10:\t train loss : 0.6072886466496474; train accuracy : 0.9437110815081012; \n",
      " validation loss : 0.630106439501981; validation accuracy : 0.9205020920502092\n",
      "Epoch 11:\t train loss : 0.6004206823331893; train accuracy : 0.9507552898169088; \n",
      " validation loss : 0.6116086986642053; validation accuracy : 0.9414225941422594\n",
      "Epoch 12:\t train loss : 0.5959764746252959; train accuracy : 0.9555475696273119; \n",
      " validation loss : 0.6136619568915026; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.5975542072884115; train accuracy : 0.953605440069395; \n",
      " validation loss : 0.6336630459915604; validation accuracy : 0.9079497907949791\n",
      "Epoch 14:\t train loss : 0.5916512413753459; train accuracy : 0.9597239691440255; \n",
      " validation loss : 0.6067600400601387; validation accuracy : 0.9456066945606695\n",
      "Epoch 15:\t train loss : 0.5888515132830934; train accuracy : 0.9626611728987887; \n",
      " validation loss : 0.6329317792135103; validation accuracy : 0.9163179916317992\n",
      "Epoch 16:\t train loss : 0.5896304682416735; train accuracy : 0.9615149168189845; \n",
      " validation loss : 0.6248950422577272; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5881858715503137; train accuracy : 0.9634356702500078; \n",
      " validation loss : 0.611296889398848; validation accuracy : 0.9372384937238494\n",
      "Epoch 18:\t train loss : 0.5850412626182444; train accuracy : 0.9661619009262988; \n",
      " validation loss : 0.6166761280971572; validation accuracy : 0.9205020920502092\n",
      "Epoch 19:\t train loss : 0.5907673101703959; train accuracy : 0.9602388549831159; \n",
      " validation loss : 0.6085499119442321; validation accuracy : 0.9456066945606695\n",
      "Epoch 20:\t train loss : 0.5836726720513252; train accuracy : 0.9675309024443136; \n",
      " validation loss : 0.6194190109187829; validation accuracy : 0.9246861924686193\n",
      "Epoch 21:\t train loss : 0.5793973467883354; train accuracy : 0.9719204436320827; \n",
      " validation loss : 0.6153216101269838; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:\t train loss : 0.5789991400468486; train accuracy : 0.9722243563927011; \n",
      " validation loss : 0.5958855939983253; validation accuracy : 0.9623430962343096\n",
      "Epoch 23:\t train loss : 0.5825723821703471; train accuracy : 0.968760494439109; \n",
      " validation loss : 0.6149514068459816; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5942469640867596; train accuracy : 0.9567381269556058; \n",
      " validation loss : 0.6224191945751464; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5783513289916488; train accuracy : 0.9727141485176121; \n",
      " validation loss : 0.6100801078633248; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5829945690313669; train accuracy : 0.9681254066111094; \n",
      " validation loss : 0.6070129719120622; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5754115730952741; train accuracy : 0.9758084203352024; \n",
      " validation loss : 0.6183807584611465; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5757054734720071; train accuracy : 0.9754676415006661; \n",
      " validation loss : 0.6116179166175063; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5728208028464143; train accuracy : 0.9786062145667462; \n",
      " validation loss : 0.6152977879208769; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5778257745498471; train accuracy : 0.973391988599399; \n",
      " validation loss : 0.597618922787724; validation accuracy : 0.9539748953974896\n",
      "Epoch 31:\t train loss : 0.5749892091482097; train accuracy : 0.9760348833606989; \n",
      " validation loss : 0.6134588559920796; validation accuracy : 0.9330543933054394\n",
      "Epoch 32:\t train loss : 0.6127353218495342; train accuracy : 0.9378060039034667; \n",
      " validation loss : 0.8381076609511703; validation accuracy : 0.702928870292887\n",
      "Epoch 33:\t train loss : 0.6074750276571372; train accuracy : 0.9429210942098578; \n",
      " validation loss : 0.610579221405248; validation accuracy : 0.9330543933054394\n",
      "Epoch 34:\t train loss : 0.579325811821763; train accuracy : 0.9717906378760185; \n",
      " validation loss : 0.625807623244421; validation accuracy : 0.9205020920502092\n",
      "Epoch 35:\t train loss : 0.5711190579325219; train accuracy : 0.9802171690572818; \n",
      " validation loss : 0.5872088303657298; validation accuracy : 0.9665271966527197\n",
      "Epoch 36:\t train loss : 0.5698166807736437; train accuracy : 0.9812955791691192; \n",
      " validation loss : 0.6238066162132193; validation accuracy : 0.9288702928870293\n",
      "Epoch 37:\t train loss : 0.5697248719607494; train accuracy : 0.9816481303633942; \n",
      " validation loss : 0.6191801673540231; validation accuracy : 0.9372384937238494\n",
      "Epoch 38:\t train loss : 0.573675927834269; train accuracy : 0.9774540723070727; \n",
      " validation loss : 0.6024294225075921; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5704445379399868; train accuracy : 0.9809238204405341; \n",
      " validation loss : 0.6098936895151202; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5680854148939153; train accuracy : 0.9831853527060938; \n",
      " validation loss : 0.6052319595002557; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5677404564302149; train accuracy : 0.9832665200285015; \n",
      " validation loss : 0.6121105141651791; validation accuracy : 0.9372384937238494\n",
      "Epoch 42:\t train loss : 0.5672873023269461; train accuracy : 0.983727500851947; \n",
      " validation loss : 0.6126532023097474; validation accuracy : 0.9414225941422594\n",
      "Epoch 43:\t train loss : 0.5718979227626627; train accuracy : 0.9792103225006971; \n",
      " validation loss : 0.6007864125873728; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5790662599032892; train accuracy : 0.9720229870813841; \n",
      " validation loss : 0.6123629061964481; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.569585268678496; train accuracy : 0.981688714024598; \n",
      " validation loss : 0.5929012549404304; validation accuracy : 0.9581589958158996\n",
      "Epoch 46:\t train loss : 0.562093391601945; train accuracy : 0.9893215403203321; \n",
      " validation loss : 0.5951665569814811; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.564270071898948; train accuracy : 0.9871043093032622; \n",
      " validation loss : 0.6145031583867632; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5662982316117066; train accuracy : 0.9849725827937669; \n",
      " validation loss : 0.6373641451175143; validation accuracy : 0.9121338912133892\n",
      "Epoch 49:\t train loss : 0.5653254503291889; train accuracy : 0.9858555097741566; \n",
      " validation loss : 0.5890755117904023; validation accuracy : 0.9623430962343096\n",
      "Epoch 50:\t train loss : 0.5672046799866772; train accuracy : 0.9838145543542242; \n",
      " validation loss : 0.6155170509803651; validation accuracy : 0.9372384937238494\n",
      "Epoch 51:\t train loss : 0.5682165699136872; train accuracy : 0.9831020167911025; \n",
      " validation loss : 0.6051379422027815; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5816336834099323; train accuracy : 0.9691536292945878; \n",
      " validation loss : 0.6139009164278978; validation accuracy : 0.9330543933054394\n",
      "Epoch 53:\t train loss : 0.5624925005983011; train accuracy : 0.9888103720685275; \n",
      " validation loss : 0.5935954105862992; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5623722007994637; train accuracy : 0.9888952569782211; \n",
      " validation loss : 0.5951177379974479; validation accuracy : 0.9581589958158996\n",
      "Epoch 55:\t train loss : 0.5660124978738985; train accuracy : 0.985055918708758; \n",
      " validation loss : 0.634394262689917; validation accuracy : 0.9205020920502092\n",
      "Epoch 56:\t train loss : 0.5688526142415882; train accuracy : 0.9823392917996221; \n",
      " validation loss : 0.5772661251319807; validation accuracy : 0.9748953974895398\n",
      "Epoch 57:\t train loss : 0.5629959282554984; train accuracy : 0.9883744849592614; \n",
      " validation loss : 0.6191157173610153; validation accuracy : 0.9330543933054394\n",
      "Epoch 58:\t train loss : 0.562326513733634; train accuracy : 0.9890582112209176; \n",
      " validation loss : 0.5944160569987136; validation accuracy : 0.9539748953974896\n",
      "Epoch 59:\t train loss : 0.5614405362477264; train accuracy : 0.9898268223922674; \n",
      " validation loss : 0.6101775843760936; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5617791315860242; train accuracy : 0.9896254530809505; \n",
      " validation loss : 0.6054778664348396; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5613925494014689; train accuracy : 0.9899876080423805; \n",
      " validation loss : 0.5845166986650758; validation accuracy : 0.9665271966527197\n",
      "Epoch 62:\t train loss : 0.5626917481109993; train accuracy : 0.9884076334458937; \n",
      " validation loss : 0.6116207625135316; validation accuracy : 0.9414225941422594\n",
      "Epoch 63:\t train loss : 0.5640459118669123; train accuracy : 0.9871315716100251; \n",
      " validation loss : 0.5921872214499635; validation accuracy : 0.9581589958158996\n",
      "Epoch 64:\t train loss : 0.563545822835089; train accuracy : 0.9877415657238452; \n",
      " validation loss : 0.6082122205880525; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.5697297224386645; train accuracy : 0.9811620558257691; \n",
      " validation loss : 0.6089198995486733; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.567035726843973; train accuracy : 0.9841478980141888; \n",
      " validation loss : 0.5879258818757617; validation accuracy : 0.9623430962343096\n",
      "Epoch 67:\t train loss : 0.5659709079123263; train accuracy : 0.9851237646767248; \n",
      " validation loss : 0.5969742181698092; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5635355014847042; train accuracy : 0.9876641159887233; \n",
      " validation loss : 0.5932939520542394; validation accuracy : 0.9581589958158996\n",
      "Epoch 69:\t train loss : 0.5623180822475611; train accuracy : 0.9890582112209176; \n",
      " validation loss : 0.5960059975150558; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5749808671029505; train accuracy : 0.9759537160382912; \n",
      " validation loss : 0.5797210022276695; validation accuracy : 0.9707112970711297\n",
      "Epoch 71:\t train loss : 0.5639872319676169; train accuracy : 0.9872303974720407; \n",
      " validation loss : 0.5741441683755859; validation accuracy : 0.9748953974895398\n",
      "Epoch 72:\t train loss : 0.5625809420888357; train accuracy : 0.9886650763654389; \n",
      " validation loss : 0.6002313129248229; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73:\t train loss : 0.5590767613190507; train accuracy : 0.9924040397781839; \n",
      " validation loss : 0.6049003769385892; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.5595095782930944; train accuracy : 0.9917726695374701; \n",
      " validation loss : 0.5738357959583883; validation accuracy : 0.9790794979079498\n",
      "Epoch 75:\t train loss : 0.5597426585170472; train accuracy : 0.9915675826388674; \n",
      " validation loss : 0.5806796283105485; validation accuracy : 0.9707112970711297\n",
      "Epoch 76:\t train loss : 0.5626649143463588; train accuracy : 0.9885529291489823; \n",
      " validation loss : 0.6034616412225264; validation accuracy : 0.9456066945606695\n",
      "Epoch 77:\t train loss : 0.5618910027343228; train accuracy : 0.9893503516217974; \n",
      " validation loss : 0.5978369153599354; validation accuracy : 0.9539748953974896\n",
      "Epoch 78:\t train loss : 0.5635580136741536; train accuracy : 0.9877976393320734; \n",
      " validation loss : 0.5984091783537199; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5582272072295947; train accuracy : 0.993101087394281; \n",
      " validation loss : 0.5990055858150543; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5608716579459195; train accuracy : 0.9903283868769168; \n",
      " validation loss : 0.5949459374471778; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5626326416488446; train accuracy : 0.9885662505034233; \n",
      " validation loss : 0.6015476714556166; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.562928652799683; train accuracy : 0.9882254716688869; \n",
      " validation loss : 0.5993301962387482; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5600554516957981; train accuracy : 0.9912887635924285; \n",
      " validation loss : 0.6114119757379118; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5588446572233612; train accuracy : 0.9924659995662815; \n",
      " validation loss : 0.600247895266534; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5582917376485261; train accuracy : 0.9929712816382168; \n",
      " validation loss : 0.5812724372774731; validation accuracy : 0.9707112970711297\n",
      "Epoch 86:\t train loss : 0.5602176262502963; train accuracy : 0.9910969980482667; \n",
      " validation loss : 0.594344436531762; validation accuracy : 0.9581589958158996\n",
      "Epoch 87:\t train loss : 0.558020392146163; train accuracy : 0.9933703026735649; \n",
      " validation loss : 0.6006009363570606; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.5631165390962345; train accuracy : 0.9880764583785123; \n",
      " validation loss : 0.5974956773120152; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.564038561052251; train accuracy : 0.9871374577898944; \n",
      " validation loss : 0.5923107401655825; validation accuracy : 0.9581589958158996\n",
      "Epoch 90:\t train loss : 0.5592883714378264; train accuracy : 0.9919489451346076; \n",
      " validation loss : 0.614233597727338; validation accuracy : 0.9372384937238494\n",
      "Epoch 91:\t train loss : 0.5564633728788198; train accuracy : 0.9949134111961337; \n",
      " validation loss : 0.5750357358741659; validation accuracy : 0.9748953974895398\n",
      "Epoch 92:\t train loss : 0.5560257629448919; train accuracy : 0.9953877133740202; \n",
      " validation loss : 0.5882314707082417; validation accuracy : 0.9581589958158996\n",
      "Epoch 93:\t train loss : 0.5571407338486515; train accuracy : 0.9942318535270609; \n",
      " validation loss : 0.5974256076858225; validation accuracy : 0.9539748953974896\n",
      "Epoch 94:\t train loss : 0.5580686486630569; train accuracy : 0.9932597044518108; \n",
      " validation loss : 0.6079739539654602; validation accuracy : 0.9414225941422594\n",
      "Epoch 95:\t train loss : 0.5666645146522887; train accuracy : 0.9844112271136033; \n",
      " validation loss : 0.5914481443284029; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.560634469656144; train accuracy : 0.9907097493726571; \n",
      " validation loss : 0.6320525309115863; validation accuracy : 0.9205020920502092\n",
      "Epoch 97:\t train loss : 0.5816992062158691; train accuracy : 0.969213420490102; \n",
      " validation loss : 0.6170606319735608; validation accuracy : 0.9330543933054394\n",
      "Epoch 98:\t train loss : 0.5621943547422574; train accuracy : 0.9890582112209176; \n",
      " validation loss : 0.6068567696396787; validation accuracy : 0.9456066945606695\n",
      "Epoch 99:\t train loss : 0.5603406506036953; train accuracy : 0.990988568419096; \n",
      " validation loss : 0.5889357223330829; validation accuracy : 0.9623430962343096\n",
      "Epoch 100:\t train loss : 0.55889260997752; train accuracy : 0.9923981535983147; \n",
      " validation loss : 0.6084846109172304; validation accuracy : 0.9414225941422594\n",
      "Epoch 101:\t train loss : 0.5710073873041465; train accuracy : 0.9799405186034263; \n",
      " validation loss : 0.5931511684357846; validation accuracy : 0.9539748953974896\n",
      "Epoch 102:\t train loss : 0.5614956410699339; train accuracy : 0.9896991852287865; \n",
      " validation loss : 0.5903216170333634; validation accuracy : 0.9623430962343096\n",
      "Epoch 103:\t train loss : 0.5583238665075508; train accuracy : 0.9930214690665757; \n",
      " validation loss : 0.5781289554762462; validation accuracy : 0.9707112970711297\n",
      "Epoch 104:\t train loss : 0.556960156173763; train accuracy : 0.9943247932092072; \n",
      " validation loss : 0.5852884441529539; validation accuracy : 0.9665271966527197\n",
      "Epoch 105:\t train loss : 0.5564590236769857; train accuracy : 0.9949075250162644; \n",
      " validation loss : 0.5935432422678849; validation accuracy : 0.9581589958158996\n",
      "Epoch 106:\t train loss : 0.5565664462330405; train accuracy : 0.9946383097369806; \n",
      " validation loss : 0.6002398418525031; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5577812020117683; train accuracy : 0.9934263762817931; \n",
      " validation loss : 0.5804236707647344; validation accuracy : 0.9707112970711297\n",
      "Epoch 108:\t train loss : 0.5557241603945444; train accuracy : 0.9956879085473528; \n",
      " validation loss : 0.595001226524594; validation accuracy : 0.9539748953974896\n",
      "Epoch 109:\t train loss : 0.5560431065835129; train accuracy : 0.9953065460516125; \n",
      " validation loss : 0.591112680378925; validation accuracy : 0.9623430962343096\n",
      "Epoch 110:\t train loss : 0.5569222586666026; train accuracy : 0.9943616592831253; \n",
      " validation loss : 0.5962756732867375; validation accuracy : 0.9539748953974896\n",
      "Epoch 111:\t train loss : 0.558091562191265; train accuracy : 0.9931881408965582; \n",
      " validation loss : 0.6031934530906211; validation accuracy : 0.9456066945606695\n",
      "Epoch 112:\t train loss : 0.5586758063805046; train accuracy : 0.9926983487716472; \n",
      " validation loss : 0.5811695526862085; validation accuracy : 0.9707112970711297\n",
      "Epoch 113:\t train loss : 0.5562373585490988; train accuracy : 0.9950838006134018; \n",
      " validation loss : 0.6042492501596464; validation accuracy : 0.9456066945606695\n",
      "Epoch 114:\t train loss : 0.556504597827593; train accuracy : 0.9948337928684283; \n",
      " validation loss : 0.5967285857999681; validation accuracy : 0.9539748953974896\n",
      "Epoch 115:\t train loss : 0.5621274371761933; train accuracy : 0.9890058551999752; \n",
      " validation loss : 0.5882325794472738; validation accuracy : 0.9623430962343096\n",
      "Epoch 116:\t train loss : 0.5628943941407447; train accuracy : 0.9884113510331795; \n",
      " validation loss : 0.6096082125549156; validation accuracy : 0.9414225941422594\n",
      "Epoch 117:\t train loss : 0.5633851479120121; train accuracy : 0.9878131292790978; \n",
      " validation loss : 0.5900108782710287; validation accuracy : 0.9581589958158996\n",
      "Epoch 118:\t train loss : 0.5695893237423837; train accuracy : 0.9815087208401747; \n",
      " validation loss : 0.597588685608754; validation accuracy : 0.9539748953974896\n",
      "Epoch 119:\t train loss : 0.559024386531051; train accuracy : 0.9922801202019889; \n",
      " validation loss : 0.6053210604957192; validation accuracy : 0.9456066945606695\n",
      "Epoch 120:\t train loss : 0.5584030334846432; train accuracy : 0.9929573406858948; \n",
      " validation loss : 0.6173062889034665; validation accuracy : 0.9330543933054394\n",
      "Epoch 121:\t train loss : 0.5587015625428782; train accuracy : 0.9926208990365253; \n",
      " validation loss : 0.5891345273025694; validation accuracy : 0.9623430962343096\n",
      "Epoch 122:\t train loss : 0.5569781778137138; train accuracy : 0.9943093032621828; \n",
      " validation loss : 0.5889382669135049; validation accuracy : 0.9623430962343096\n",
      "Epoch 123:\t train loss : 0.5571430672317002; train accuracy : 0.9942724371882647; \n",
      " validation loss : 0.5885865597958247; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124:\t train loss : 0.5572307795898014; train accuracy : 0.9941448000247839; \n",
      " validation loss : 0.598989387687821; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 124\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5595095782930944; Train accuracy : 0.9917726695374701; \n",
      " Validation loss : 0.5738357959583883; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 81 ! ---\n",
      "Epoch 1:\t train loss : 0.9682743750701237; train accuracy : 0.5540766442578766; \n",
      " validation loss : 0.8501548411345359; validation accuracy : 0.694560669456067\n",
      "Epoch 2:\t train loss : 0.7699915913260152; train accuracy : 0.7780042752253787; \n",
      " validation loss : 0.7670386680599479; validation accuracy : 0.7949790794979079\n",
      "Epoch 3:\t train loss : 0.7039048120187084; train accuracy : 0.8464410297716782; \n",
      " validation loss : 0.7180538203270487; validation accuracy : 0.8284518828451883\n",
      "Epoch 4:\t train loss : 0.6805479363137286; train accuracy : 0.8695173332507203; \n",
      " validation loss : 0.699027009077487; validation accuracy : 0.8493723849372385\n",
      "Epoch 5:\t train loss : 0.6594732100644122; train accuracy : 0.8903438768239412; \n",
      " validation loss : 0.6914715336519917; validation accuracy : 0.8535564853556485\n",
      "Epoch 6:\t train loss : 0.6456188416392925; train accuracy : 0.9045230645311193; \n",
      " validation loss : 0.670162094298346; validation accuracy : 0.8744769874476988\n",
      "Epoch 7:\t train loss : 0.6295321779805335; train accuracy : 0.9212057374763778; \n",
      " validation loss : 0.6654795421847853; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6220179173642103; train accuracy : 0.9285309334242077; \n",
      " validation loss : 0.6460274371394044; validation accuracy : 0.9037656903765691\n",
      "Epoch 9:\t train loss : 0.6175781200340583; train accuracy : 0.9333947767898634; \n",
      " validation loss : 0.6221111382331603; validation accuracy : 0.9205020920502092\n",
      "Epoch 10:\t train loss : 0.6115781602649963; train accuracy : 0.9389593853589021; \n",
      " validation loss : 0.6305770007261742; validation accuracy : 0.9246861924686193\n",
      "Epoch 11:\t train loss : 0.6055965112590856; train accuracy : 0.9453530158926856; \n",
      " validation loss : 0.640012598031307; validation accuracy : 0.9037656903765691\n",
      "Epoch 12:\t train loss : 0.6018774229402747; train accuracy : 0.9488670652746367; \n",
      " validation loss : 0.6163771735424662; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.5988501754215357; train accuracy : 0.9523736794820161; \n",
      " validation loss : 0.6188018674859732; validation accuracy : 0.9330543933054394\n",
      "Epoch 14:\t train loss : 0.5963478372375026; train accuracy : 0.9546218903931348; \n",
      " validation loss : 0.6408024388140996; validation accuracy : 0.9079497907949791\n",
      "Epoch 15:\t train loss : 0.5916187953235353; train accuracy : 0.9595145450602559; \n",
      " validation loss : 0.6304284286706299; validation accuracy : 0.9163179916317992\n",
      "Epoch 16:\t train loss : 0.5925520564814818; train accuracy : 0.9583490814461415; \n",
      " validation loss : 0.6149309649298023; validation accuracy : 0.9372384937238494\n",
      "Epoch 17:\t train loss : 0.5888552860671326; train accuracy : 0.9623241116515382; \n",
      " validation loss : 0.6187085979996254; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.5975584424444986; train accuracy : 0.953454258186437; \n",
      " validation loss : 0.62095323323887; validation accuracy : 0.9330543933054394\n",
      "Epoch 19:\t train loss : 0.5828594495163666; train accuracy : 0.9682936274357942; \n",
      " validation loss : 0.6006004668810578; validation accuracy : 0.9539748953974896\n",
      "Epoch 20:\t train loss : 0.5854534201911701; train accuracy : 0.9657960283775829; \n",
      " validation loss : 0.6211199773220093; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5853284114941729; train accuracy : 0.9657260138170327; \n",
      " validation loss : 0.6204157807642603; validation accuracy : 0.9288702928870293\n",
      "Epoch 22:\t train loss : 0.5858223867029215; train accuracy : 0.9652052417980731; \n",
      " validation loss : 0.6172361383277412; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5811293934436664; train accuracy : 0.9700034077883454; \n",
      " validation loss : 0.6292505041693375; validation accuracy : 0.9163179916317992\n",
      "Epoch 24:\t train loss : 0.5817607784237614; train accuracy : 0.9691551782892902; \n",
      " validation loss : 0.6185340318152479; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5829769234307067; train accuracy : 0.9681542179125747; \n",
      " validation loss : 0.6048978203793792; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5784331107762644; train accuracy : 0.9728380680938071; \n",
      " validation loss : 0.6102801146323852; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5787520981675803; train accuracy : 0.9723733696830756; \n",
      " validation loss : 0.6464476397757092; validation accuracy : 0.9079497907949791\n",
      "Epoch 28:\t train loss : 0.5779253927441104; train accuracy : 0.9731302084946869; \n",
      " validation loss : 0.6070154381368266; validation accuracy : 0.9414225941422594\n",
      "Epoch 29:\t train loss : 0.5796894464602967; train accuracy : 0.9712212274234022; \n",
      " validation loss : 0.6219694056021486; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.5792530574301858; train accuracy : 0.9717574893893863; \n",
      " validation loss : 0.6106582723193182; validation accuracy : 0.9414225941422594\n",
      "Epoch 31:\t train loss : 0.5725492141750742; train accuracy : 0.9785191610644691; \n",
      " validation loss : 0.638706925349198; validation accuracy : 0.9121338912133892\n",
      "Epoch 32:\t train loss : 0.5745925037924603; train accuracy : 0.9765497691997893; \n",
      " validation loss : 0.62950637627459; validation accuracy : 0.9205020920502092\n",
      "Epoch 33:\t train loss : 0.5793765224432711; train accuracy : 0.9714845565228167; \n",
      " validation loss : 0.6245162959579279; validation accuracy : 0.9246861924686193\n",
      "Epoch 34:\t train loss : 0.575042366827015; train accuracy : 0.9760599770748783; \n",
      " validation loss : 0.5951056629352989; validation accuracy : 0.9581589958158996\n",
      "Epoch 35:\t train loss : 0.5699776533322289; train accuracy : 0.9813169552960129; \n",
      " validation loss : 0.605908783613381; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.5754827467203567; train accuracy : 0.9755642987700982; \n",
      " validation loss : 0.6100874543012552; validation accuracy : 0.9414225941422594\n",
      "Epoch 37:\t train loss : 0.5781157254105453; train accuracy : 0.9729272901886675; \n",
      " validation loss : 0.6241128893487426; validation accuracy : 0.9246861924686193\n",
      "Epoch 38:\t train loss : 0.5721517830109589; train accuracy : 0.9789838594752006; \n",
      " validation loss : 0.5869575644323924; validation accuracy : 0.9665271966527197\n",
      "Epoch 39:\t train loss : 0.5712138992527052; train accuracy : 0.9798667864555903; \n",
      " validation loss : 0.6045032425337119; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5697779463909441; train accuracy : 0.9814098949781592; \n",
      " validation loss : 0.6114494490678887; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5735069868963629; train accuracy : 0.9776495554385204; \n",
      " validation loss : 0.6168965650114739; validation accuracy : 0.9288702928870293\n",
      "Epoch 42:\t train loss : 0.5682218459514182; train accuracy : 0.9828408562842715; \n",
      " validation loss : 0.6142864229433707; validation accuracy : 0.9372384937238494\n",
      "Epoch 43:\t train loss : 0.5708289300251064; train accuracy : 0.980350692400632; \n",
      " validation loss : 0.5897908825456624; validation accuracy : 0.9581589958158996\n",
      "Epoch 44:\t train loss : 0.5684120126346822; train accuracy : 0.9827265404752316; \n",
      " validation loss : 0.6101441303990218; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5662485884371103; train accuracy : 0.9850094488676848; \n",
      " validation loss : 0.6320458878322661; validation accuracy : 0.9121338912133892\n",
      "Epoch 46:\t train loss : 0.5715699542639958; train accuracy : 0.979287772235819; \n",
      " validation loss : 0.5997745999396845; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5673178303181057; train accuracy : 0.9840026023111001; \n",
      " validation loss : 0.5984005744950377; validation accuracy : 0.9539748953974896\n",
      "Epoch 48:\t train loss : 0.564922425540842; train accuracy : 0.9862892282908392; \n",
      " validation loss : 0.678585806559711; validation accuracy : 0.8744769874476988\n",
      "Epoch 49:\t train loss : 0.565410064359629; train accuracy : 0.9858768859010503; \n",
      " validation loss : 0.6166361034358236; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50:\t train loss : 0.5667671988808534; train accuracy : 0.9844982806158803; \n",
      " validation loss : 0.6017804265127911; validation accuracy : 0.9497907949790795\n",
      "Epoch 51:\t train loss : 0.5645186404962915; train accuracy : 0.9869147123516837; \n",
      " validation loss : 0.5906844206606101; validation accuracy : 0.9623430962343096\n",
      "Epoch 52:\t train loss : 0.5744183411720858; train accuracy : 0.9766795749558537; \n",
      " validation loss : 0.6150667506977963; validation accuracy : 0.9372384937238494\n",
      "Epoch 53:\t train loss : 0.5740959724085088; train accuracy : 0.9768632857275628; \n",
      " validation loss : 0.6047614734082971; validation accuracy : 0.9456066945606695\n",
      "Epoch 54:\t train loss : 0.5684670122024287; train accuracy : 0.9828312525171164; \n",
      " validation loss : 0.6027481540321555; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.5660411091928209; train accuracy : 0.98538120759627; \n",
      " validation loss : 0.5965924119416159; validation accuracy : 0.9539748953974896\n",
      "Epoch 56:\t train loss : 0.5801960991917073; train accuracy : 0.97087673100158; \n",
      " validation loss : 0.6034826893408679; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5714639931453854; train accuracy : 0.9796787384987143; \n",
      " validation loss : 0.627618068382326; validation accuracy : 0.9246861924686193\n",
      "Epoch 58:\t train loss : 0.5681786617683255; train accuracy : 0.9829337959664178; \n",
      " validation loss : 0.6009008060691805; validation accuracy : 0.9497907949790795\n",
      "Epoch 59:\t train loss : 0.5802579705275701; train accuracy : 0.9708008302611605; \n",
      " validation loss : 0.6222467315331393; validation accuracy : 0.9205020920502092\n",
      "Epoch 60:\t train loss : 0.5868870553948974; train accuracy : 0.9638848787137148; \n",
      " validation loss : 0.6138516627437495; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5695833405580407; train accuracy : 0.9814467610520772; \n",
      " validation loss : 0.6021686461211283; validation accuracy : 0.9456066945606695\n",
      "Epoch 62:\t train loss : 0.5694641465160264; train accuracy : 0.9818340097276868; \n",
      " validation loss : 0.6047253955422279; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5739186941399365; train accuracy : 0.9771966293875275; \n",
      " validation loss : 0.6128696630082832; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.574211521403132; train accuracy : 0.9768344744260975; \n",
      " validation loss : 0.6275654945986163; validation accuracy : 0.9205020920502092\n",
      "Epoch 65:\t train loss : 0.572620244962612; train accuracy : 0.978596610799591; \n",
      " validation loss : 0.6236882372884646; validation accuracy : 0.9288702928870293\n",
      "Epoch 66:\t train loss : 0.5711915439740212; train accuracy : 0.9797620744137056; \n",
      " validation loss : 0.640820084343605; validation accuracy : 0.9079497907949791\n",
      "Epoch 67:\t train loss : 0.580795076576507; train accuracy : 0.9702143808668174; \n",
      " validation loss : 0.6113265340554229; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5660461916446768; train accuracy : 0.9852417980730506; \n",
      " validation loss : 0.5866864744982511; validation accuracy : 0.9665271966527197\n",
      "Epoch 69:\t train loss : 0.5634479688570497; train accuracy : 0.9877415657238452; \n",
      " validation loss : 0.599364536158154; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5655897371366764; train accuracy : 0.9856755165897333; \n",
      " validation loss : 0.5979862654824323; validation accuracy : 0.9539748953974896\n",
      "Epoch 71:\t train loss : 0.5671646630929049; train accuracy : 0.98411691812014; \n",
      " validation loss : 0.5849297750010999; validation accuracy : 0.9665271966527197\n",
      "Epoch 72:\t train loss : 0.562756805288489; train accuracy : 0.9883840887264166; \n",
      " validation loss : 0.5928575678674762; validation accuracy : 0.9623430962343096\n",
      "Epoch 73:\t train loss : 0.5629118975063748; train accuracy : 0.9883029214040088; \n",
      " validation loss : 0.6032797396621129; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5622228515325269; train accuracy : 0.9889284054648533; \n",
      " validation loss : 0.6085264107180209; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.568735880431367; train accuracy : 0.9823510641593606; \n",
      " validation loss : 0.6086760145762223; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5646568227530044; train accuracy : 0.9865813686917191; \n",
      " validation loss : 0.5994275767222023; validation accuracy : 0.9497907949790795\n",
      "Epoch 77:\t train loss : 0.5640536132070468; train accuracy : 0.98712196784287; \n",
      " validation loss : 0.6251977510707349; validation accuracy : 0.9246861924686193\n",
      "Epoch 78:\t train loss : 0.5693272809706496; train accuracy : 0.9817720499395892; \n",
      " validation loss : 0.6188475646305673; validation accuracy : 0.9288702928870293\n",
      "Epoch 79:\t train loss : 0.5638471693788898; train accuracy : 0.9872768673131138; \n",
      " validation loss : 0.583954817157704; validation accuracy : 0.9665271966527197\n",
      "Epoch 80:\t train loss : 0.5611693777204644; train accuracy : 0.9901115276185756; \n",
      " validation loss : 0.5882214764770379; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5631053380278784; train accuracy : 0.9881693980606586; \n",
      " validation loss : 0.5947695643870806; validation accuracy : 0.9581589958158996\n",
      "Epoch 82:\t train loss : 0.5625511665085919; train accuracy : 0.988661358778153; \n",
      " validation loss : 0.5907110544651204; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.560261426728568; train accuracy : 0.9911279779423154; \n",
      " validation loss : 0.591337471847294; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5611721273087106; train accuracy : 0.9901152452058614; \n",
      " validation loss : 0.5935087292954185; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5590339242929294; train accuracy : 0.9922993277362991; \n",
      " validation loss : 0.6110105200341232; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.5619057625225009; train accuracy : 0.9892595805322346; \n",
      " validation loss : 0.5900385967967797; validation accuracy : 0.9623430962343096\n",
      "Epoch 87:\t train loss : 0.5589016230983683; train accuracy : 0.9924814895133058; \n",
      " validation loss : 0.5786114111979377; validation accuracy : 0.9748953974895398\n",
      "Epoch 88:\t train loss : 0.5593092622025124; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.5889608031751633; validation accuracy : 0.9623430962343096\n",
      "Epoch 89:\t train loss : 0.5624941741982433; train accuracy : 0.9886923386722017; \n",
      " validation loss : 0.629987160400077; validation accuracy : 0.9163179916317992\n",
      "Epoch 90:\t train loss : 0.5609106375249366; train accuracy : 0.9902450509619257; \n",
      " validation loss : 0.6027944102486267; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5571281515510087; train accuracy : 0.9942163635800365; \n",
      " validation loss : 0.58525294449035; validation accuracy : 0.9665271966527197\n",
      "Epoch 92:\t train loss : 0.5577946681231819; train accuracy : 0.9935561820378574; \n",
      " validation loss : 0.6079140293486905; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5615673843122213; train accuracy : 0.9896158493137953; \n",
      " validation loss : 0.6017219736610226; validation accuracy : 0.9456066945606695\n",
      "Epoch 94:\t train loss : 0.5576089521800401; train accuracy : 0.9936646116670281; \n",
      " validation loss : 0.6202949830988014; validation accuracy : 0.9288702928870293\n",
      "Epoch 95:\t train loss : 0.5607937052779433; train accuracy : 0.99048917252703; \n",
      " validation loss : 0.5814218998873754; validation accuracy : 0.9707112970711297\n",
      "Epoch 96:\t train loss : 0.5646010252945094; train accuracy : 0.9863821679729855; \n",
      " validation loss : 0.6006230813237479; validation accuracy : 0.9497907949790795\n",
      "Epoch 97:\t train loss : 0.5605964311971363; train accuracy : 0.9906226958703801; \n",
      " validation loss : 0.6071869170336078; validation accuracy : 0.9414225941422594\n",
      "Epoch 98:\t train loss : 0.5672121780416537; train accuracy : 0.983841816660987; \n",
      " validation loss : 0.5985270347842117; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5608775732683199; train accuracy : 0.9901329037454691; \n",
      " validation loss : 0.6051782359407639; validation accuracy : 0.9456066945606695\n",
      "Epoch 100:\t train loss : 0.564111380678804; train accuracy : 0.9870290281607237; \n",
      " validation loss : 0.6309452394003732; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101:\t train loss : 0.5630820037074048; train accuracy : 0.9880919483255367; \n",
      " validation loss : 0.6150580367954179; validation accuracy : 0.9372384937238494\n",
      "Epoch 102:\t train loss : 0.5616517883502161; train accuracy : 0.9898481985191611; \n",
      " validation loss : 0.5916593862866549; validation accuracy : 0.9581589958158996\n",
      "Epoch 103:\t train loss : 0.5609556491267783; train accuracy : 0.9902664270888194; \n",
      " validation loss : 0.6015569776909673; validation accuracy : 0.9497907949790795\n",
      "Epoch 104:\t train loss : 0.5642737111390594; train accuracy : 0.9867715852411785; \n",
      " validation loss : 0.6261924369140487; validation accuracy : 0.9246861924686193\n",
      "Epoch 105:\t train loss : 0.5607567476313529; train accuracy : 0.9904832863471607; \n",
      " validation loss : 0.6035919431541842; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.5624647231111506; train accuracy : 0.9887580160475851; \n",
      " validation loss : 0.6001212866968795; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.5616553123163087; train accuracy : 0.9896217354936646; \n",
      " validation loss : 0.6058426505712652; validation accuracy : 0.9456066945606695\n",
      "Epoch 108:\t train loss : 0.5630120770009956; train accuracy : 0.9881693980606586; \n",
      " validation loss : 0.6141239697499793; validation accuracy : 0.9330543933054394\n",
      "Epoch 109:\t train loss : 0.556707576889291; train accuracy : 0.9946094984355154; \n",
      " validation loss : 0.6007022718603842; validation accuracy : 0.9497907949790795\n",
      "Epoch 110:\t train loss : 0.5576897224387042; train accuracy : 0.9936993091483627; \n",
      " validation loss : 0.6323788546895092; validation accuracy : 0.9163179916317992\n",
      "Epoch 111:\t train loss : 0.558150024943822; train accuracy : 0.9932655906316801; \n",
      " validation loss : 0.6052862479593502; validation accuracy : 0.9456066945606695\n",
      "Epoch 112:\t train loss : 0.5573501412445261; train accuracy : 0.9939434307134669; \n",
      " validation loss : 0.5872717555742484; validation accuracy : 0.9665271966527197\n",
      "Epoch 113:\t train loss : 0.5589352707039701; train accuracy : 0.9922159918213079; \n",
      " validation loss : 0.6184306956846991; validation accuracy : 0.9288702928870293\n",
      "Epoch 114:\t train loss : 0.55760806680298; train accuracy : 0.9938195111372718; \n",
      " validation loss : 0.6031804648681655; validation accuracy : 0.9456066945606695\n",
      "Epoch 115:\t train loss : 0.5564938179791317; train accuracy : 0.9950218408253043; \n",
      " validation loss : 0.6050216298986154; validation accuracy : 0.9456066945606695\n",
      "Epoch 116:\t train loss : 0.557835751479062; train accuracy : 0.9934514699959726; \n",
      " validation loss : 0.6220491439111459; validation accuracy : 0.9288702928870293\n",
      "Epoch 117:\t train loss : 0.5639705746443947; train accuracy : 0.9872613773660894; \n",
      " validation loss : 0.6099235476194491; validation accuracy : 0.9414225941422594\n",
      "Epoch 118:\t train loss : 0.5608806963654882; train accuracy : 0.9902723132686886; \n",
      " validation loss : 0.601348229255356; validation accuracy : 0.9497907949790795\n",
      "Epoch 119:\t train loss : 0.5565360797560335; train accuracy : 0.9948108677468323; \n",
      " validation loss : 0.6305595523073254; validation accuracy : 0.9205020920502092\n",
      "Epoch 120:\t train loss : 0.555998455714717; train accuracy : 0.9953530158926857; \n",
      " validation loss : 0.6159800379606547; validation accuracy : 0.9330543933054394\n",
      "Epoch 121:\t train loss : 0.5595435086059178; train accuracy : 0.9917475758232907; \n",
      " validation loss : 0.6201600287770865; validation accuracy : 0.9288702928870293\n",
      "Epoch 122:\t train loss : 0.5633265894205796; train accuracy : 0.9879060689612441; \n",
      " validation loss : 0.616628404213731; validation accuracy : 0.9330543933054394\n",
      "Epoch 123:\t train loss : 0.558681808332601; train accuracy : 0.99265559651786; \n",
      " validation loss : 0.6212909473621476; validation accuracy : 0.9288702928870293\n",
      "Epoch 124:\t train loss : 0.5638849206874554; train accuracy : 0.9873911831221537; \n",
      " validation loss : 0.6002069507069203; validation accuracy : 0.9497907949790795\n",
      "Epoch 125:\t train loss : 0.5596572867077753; train accuracy : 0.99175346200316; \n",
      " validation loss : 0.603775179211625; validation accuracy : 0.9497907949790795\n",
      "Epoch 126:\t train loss : 0.5642749697565534; train accuracy : 0.9868778462777658; \n",
      " validation loss : 0.5983895560192346; validation accuracy : 0.9497907949790795\n",
      "Epoch 127:\t train loss : 0.5608746670667443; train accuracy : 0.9903999504321696; \n",
      " validation loss : 0.6012133164742584; validation accuracy : 0.9497907949790795\n",
      "Epoch 128:\t train loss : 0.5598164835139982; train accuracy : 0.9916140524799405; \n",
      " validation loss : 0.6011680145441347; validation accuracy : 0.9497907949790795\n",
      "Epoch 129:\t train loss : 0.5577474645041407; train accuracy : 0.9936646116670281; \n",
      " validation loss : 0.5878106874619781; validation accuracy : 0.9623430962343096\n",
      "Epoch 130:\t train loss : 0.561557653915903; train accuracy : 0.9896970166362031; \n",
      " validation loss : 0.6429370749724455; validation accuracy : 0.9079497907949791\n",
      "Epoch 131:\t train loss : 0.570649482175406; train accuracy : 0.9804303107283373; \n",
      " validation loss : 0.6098952395215227; validation accuracy : 0.9414225941422594\n",
      "Epoch 132:\t train loss : 0.5579448567982345; train accuracy : 0.9933703026735649; \n",
      " validation loss : 0.6190590145070353; validation accuracy : 0.9288702928870293\n",
      "Epoch 133:\t train loss : 0.5579975852596378; train accuracy : 0.9932714768115493; \n",
      " validation loss : 0.5877718149703379; validation accuracy : 0.9665271966527197\n",
      "Epoch 134:\t train loss : 0.5564048794863264; train accuracy : 0.9949289011431581; \n",
      " validation loss : 0.5982201003554866; validation accuracy : 0.9539748953974896\n",
      "Epoch 135:\t train loss : 0.55527938014024; train accuracy : 0.9960382911490443; \n",
      " validation loss : 0.6060102779233313; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.5598363908323624; train accuracy : 0.9913411196133709; \n",
      " validation loss : 0.6161359443770738; validation accuracy : 0.9330543933054394\n",
      "Epoch 137:\t train loss : 0.5580214643910886; train accuracy : 0.9932618730443942; \n",
      " validation loss : 0.6096485337004438; validation accuracy : 0.9414225941422594\n",
      "Early stopping at epoch 137\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5589016230983683; Train accuracy : 0.9924814895133058; \n",
      " Validation loss : 0.5786114111979377; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 82 ! ---\n",
      "Epoch 1:\t train loss : 0.9084123175138847; train accuracy : 0.6322689674401314; \n",
      " validation loss : 0.8105454636241634; validation accuracy : 0.7405857740585774\n",
      "Epoch 2:\t train loss : 0.740472934799368; train accuracy : 0.8104851451408036; \n",
      " validation loss : 0.7126155116239469; validation accuracy : 0.8326359832635983\n",
      "Epoch 3:\t train loss : 0.7016100040516127; train accuracy : 0.8486796369156417; \n",
      " validation loss : 0.6888352144144874; validation accuracy : 0.8619246861924686\n",
      "Epoch 4:\t train loss : 0.6831539466868354; train accuracy : 0.8669695467641501; \n",
      " validation loss : 0.6761491671653912; validation accuracy : 0.8744769874476988\n",
      "Epoch 5:\t train loss : 0.6650040061395107; train accuracy : 0.884566126583847; \n",
      " validation loss : 0.6611495845380371; validation accuracy : 0.895397489539749\n",
      "Epoch 6:\t train loss : 0.6454812715854965; train accuracy : 0.904980327767279; \n",
      " validation loss : 0.6669108535300015; validation accuracy : 0.8744769874476988\n",
      "Epoch 7:\t train loss : 0.6310354743235321; train accuracy : 0.9199030329316273; \n",
      " validation loss : 0.6351515253760982; validation accuracy : 0.9121338912133892\n",
      "Epoch 8:\t train loss : 0.6185502572942488; train accuracy : 0.9320102853248242; \n",
      " validation loss : 0.6443416713615009; validation accuracy : 0.9121338912133892\n",
      "Epoch 9:\t train loss : 0.6118303035427005; train accuracy : 0.939073701167942; \n",
      " validation loss : 0.6462724639541139; validation accuracy : 0.9037656903765691\n",
      "Epoch 10:\t train loss : 0.6051287088562504; train accuracy : 0.9454512221568202; \n",
      " validation loss : 0.6469362077296597; validation accuracy : 0.9079497907949791\n",
      "Epoch 11:\t train loss : 0.6024499520507026; train accuracy : 0.9483580656154156; \n",
      " validation loss : 0.623215490754849; validation accuracy : 0.9246861924686193\n",
      "Epoch 12:\t train loss : 0.5985806719249899; train accuracy : 0.9528132841785681; \n",
      " validation loss : 0.6692066438885662; validation accuracy : 0.8744769874476988\n",
      "Epoch 13:\t train loss : 0.5940603541388949; train accuracy : 0.9569704761609715; \n",
      " validation loss : 0.6321488648226646; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\t train loss : 0.6000863036436387; train accuracy : 0.9507531212243254; \n",
      " validation loss : 0.6552120354084706; validation accuracy : 0.895397489539749\n",
      "Epoch 15:\t train loss : 0.5992884040646731; train accuracy : 0.9519672232720964; \n",
      " validation loss : 0.630058954224013; validation accuracy : 0.9246861924686193\n",
      "Epoch 16:\t train loss : 0.5933946809500495; train accuracy : 0.9572877102760309; \n",
      " validation loss : 0.6226452105699355; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5904628466452103; train accuracy : 0.9606474797856192; \n",
      " validation loss : 0.6125053993285917; validation accuracy : 0.9372384937238494\n",
      "Epoch 18:\t train loss : 0.582619352473519; train accuracy : 0.9688630378884104; \n",
      " validation loss : 0.6295890634895842; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.585285015268159; train accuracy : 0.9654028935221042; \n",
      " validation loss : 0.6039729320413955; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5786591002551772; train accuracy : 0.9725747389943926; \n",
      " validation loss : 0.6155503342616775; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5746205159215808; train accuracy : 0.9765150717184548; \n",
      " validation loss : 0.6195817925827667; validation accuracy : 0.9288702928870293\n",
      "Epoch 22:\t train loss : 0.58100384551666; train accuracy : 0.9701716286130302; \n",
      " validation loss : 0.6368226717576552; validation accuracy : 0.9079497907949791\n",
      "Epoch 23:\t train loss : 0.5861705500415672; train accuracy : 0.964742711979925; \n",
      " validation loss : 0.6870951659789281; validation accuracy : 0.8577405857740585\n",
      "Epoch 24:\t train loss : 0.5892144459541756; train accuracy : 0.9615458967130333; \n",
      " validation loss : 0.6106414697031317; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.5754072719467331; train accuracy : 0.9755680163573841; \n",
      " validation loss : 0.6530294301101905; validation accuracy : 0.9037656903765691\n",
      "Epoch 26:\t train loss : 0.5774125101214118; train accuracy : 0.9737327674339353; \n",
      " validation loss : 0.6089405333611477; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5728548184661127; train accuracy : 0.9784277703770253; \n",
      " validation loss : 0.6134775887572848; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5715771663477615; train accuracy : 0.9796071749434617; \n",
      " validation loss : 0.5976442632177421; validation accuracy : 0.9539748953974896\n",
      "Epoch 29:\t train loss : 0.5776041194689135; train accuracy : 0.9735410018897735; \n",
      " validation loss : 0.6133050501443638; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.5741268141717822; train accuracy : 0.9769989776634964; \n",
      " validation loss : 0.6408769001739709; validation accuracy : 0.9079497907949791\n",
      "Epoch 31:\t train loss : 0.5729847345259516; train accuracy : 0.9783524892344868; \n",
      " validation loss : 0.6141099734575637; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5751077064877842; train accuracy : 0.9761145016884042; \n",
      " validation loss : 0.6101172911891769; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5751061749288032; train accuracy : 0.9760407695405682; \n",
      " validation loss : 0.6126523483668674; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.570501175557261; train accuracy : 0.9808249945785186; \n",
      " validation loss : 0.624534319789144; validation accuracy : 0.9246861924686193\n",
      "Epoch 35:\t train loss : 0.5759543718397268; train accuracy : 0.9750611852907463; \n",
      " validation loss : 0.6090486152020478; validation accuracy : 0.9414225941422594\n",
      "Epoch 36:\t train loss : 0.5708237049755862; train accuracy : 0.9803432572260603; \n",
      " validation loss : 0.6101612715494834; validation accuracy : 0.9372384937238494\n",
      "Epoch 37:\t train loss : 0.5695324691003387; train accuracy : 0.981688714024598; \n",
      " validation loss : 0.6161921708878758; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5709052521674679; train accuracy : 0.9801920753431024; \n",
      " validation loss : 0.6378063359271047; validation accuracy : 0.9121338912133892\n",
      "Epoch 39:\t train loss : 0.5812150705011206; train accuracy : 0.9699414480002478; \n",
      " validation loss : 0.6096600517277188; validation accuracy : 0.9372384937238494\n",
      "Epoch 40:\t train loss : 0.5678979173879884; train accuracy : 0.9833173270547415; \n",
      " validation loss : 0.6082869165347694; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5696291575594813; train accuracy : 0.9815455869140928; \n",
      " validation loss : 0.6015273192338562; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.5681588381285474; train accuracy : 0.9830304532358499; \n",
      " validation loss : 0.6104719385666029; validation accuracy : 0.9372384937238494\n",
      "Epoch 43:\t train loss : 0.5652836831317145; train accuracy : 0.9860745376250813; \n",
      " validation loss : 0.6106800965913055; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5690100211404351; train accuracy : 0.9823355742123362; \n",
      " validation loss : 0.6268530342488536; validation accuracy : 0.9246861924686193\n",
      "Epoch 45:\t train loss : 0.5703952848338515; train accuracy : 0.9807961832770532; \n",
      " validation loss : 0.6097788951160339; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5663700409656344; train accuracy : 0.9849069054183834; \n",
      " validation loss : 0.5911539305895118; validation accuracy : 0.9581589958158996\n",
      "Epoch 47:\t train loss : 0.5624107391665277; train accuracy : 0.9891489823104805; \n",
      " validation loss : 0.6187882888261151; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.571859664674631; train accuracy : 0.9793128659499984; \n",
      " validation loss : 0.6138715096104133; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.5728127068443318; train accuracy : 0.9783562068217727; \n",
      " validation loss : 0.615932572595086; validation accuracy : 0.9330543933054394\n",
      "Epoch 50:\t train loss : 0.5754596164085996; train accuracy : 0.9754905666222622; \n",
      " validation loss : 0.6842131833306454; validation accuracy : 0.8619246861924686\n",
      "Epoch 51:\t train loss : 0.5845620874085311; train accuracy : 0.966195049412931; \n",
      " validation loss : 0.5982271071148836; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5703245205461489; train accuracy : 0.9807710895628737; \n",
      " validation loss : 0.5833278634655876; validation accuracy : 0.9665271966527197\n",
      "Epoch 53:\t train loss : 0.5660700356336253; train accuracy : 0.9852012144118467; \n",
      " validation loss : 0.608572806264926; validation accuracy : 0.9414225941422594\n",
      "Epoch 54:\t train loss : 0.5649800735899233; train accuracy : 0.9862641345766597; \n",
      " validation loss : 0.6167156720234849; validation accuracy : 0.9330543933054394\n",
      "Epoch 55:\t train loss : 0.5696920404458389; train accuracy : 0.9814563648192324; \n",
      " validation loss : 0.6043803327959869; validation accuracy : 0.9456066945606695\n",
      "Epoch 56:\t train loss : 0.5682650308365719; train accuracy : 0.9829145884321075; \n",
      " validation loss : 0.6044380168609095; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5656338985138494; train accuracy : 0.9854704296911304; \n",
      " validation loss : 0.5955359201989675; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.5677822272256512; train accuracy : 0.9832531986740606; \n",
      " validation loss : 0.5949730244115994; validation accuracy : 0.9539748953974896\n",
      "Epoch 59:\t train loss : 0.5645496866172656; train accuracy : 0.9866476656649834; \n",
      " validation loss : 0.6105504094836812; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5644202016778221; train accuracy : 0.9868586387434555; \n",
      " validation loss : 0.6060464577159915; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5619847623374921; train accuracy : 0.9894048762353232; \n",
      " validation loss : 0.5977937422934436; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5615537963660084; train accuracy : 0.9898850645930791; \n",
      " validation loss : 0.6192593654217055; validation accuracy : 0.9330543933054394\n",
      "Epoch 63:\t train loss : 0.5638730540204041; train accuracy : 0.9873890145295703; \n",
      " validation loss : 0.6109793852080206; validation accuracy : 0.9414225941422594\n",
      "Epoch 64:\t train loss : 0.5709280113332084; train accuracy : 0.9801338331422906; \n",
      " validation loss : 0.6529286275542441; validation accuracy : 0.9037656903765691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:\t train loss : 0.6045017110016999; train accuracy : 0.945881842684098; \n",
      " validation loss : 0.6038641405237021; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5721448951029798; train accuracy : 0.9789218996871031; \n",
      " validation loss : 0.603883318055647; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5714580773333041; train accuracy : 0.9796809070912977; \n",
      " validation loss : 0.606732524836487; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5658352577758796; train accuracy : 0.9857064964837821; \n",
      " validation loss : 0.6044552803574547; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5672606774780793; train accuracy : 0.9842098578022863; \n",
      " validation loss : 0.6000794228929965; validation accuracy : 0.9456066945606695\n",
      "Epoch 70:\t train loss : 0.5646262742370832; train accuracy : 0.9866182347656371; \n",
      " validation loss : 0.6298114178821399; validation accuracy : 0.9205020920502092\n",
      "Epoch 71:\t train loss : 0.5656628043288512; train accuracy : 0.9855323894792279; \n",
      " validation loss : 0.5948933643198254; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5624262414525018; train accuracy : 0.9888140896558134; \n",
      " validation loss : 0.5990994304961444; validation accuracy : 0.9539748953974896\n",
      "Epoch 73:\t train loss : 0.5617027536199558; train accuracy : 0.9895538895256978; \n",
      " validation loss : 0.58781194412025; validation accuracy : 0.9623430962343096\n",
      "Epoch 74:\t train loss : 0.56231597597222; train accuracy : 0.9890117413798445; \n",
      " validation loss : 0.611322365549263; validation accuracy : 0.9372384937238494\n",
      "Epoch 75:\t train loss : 0.5629841566584717; train accuracy : 0.9882778276898293; \n",
      " validation loss : 0.6206236520246464; validation accuracy : 0.9288702928870293\n",
      "Epoch 76:\t train loss : 0.5659521909666927; train accuracy : 0.9853192478081725; \n",
      " validation loss : 0.607457836433888; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5678564903638577; train accuracy : 0.9832377087270362; \n",
      " validation loss : 0.6037544788917344; validation accuracy : 0.9456066945606695\n",
      "Epoch 78:\t train loss : 0.5633122417388927; train accuracy : 0.987896465194089; \n",
      " validation loss : 0.6057804507294529; validation accuracy : 0.9372384937238494\n",
      "Epoch 79:\t train loss : 0.5612696430206329; train accuracy : 0.990039964063323; \n",
      " validation loss : 0.605436241810855; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5605946376347702; train accuracy : 0.9907775953406239; \n",
      " validation loss : 0.6048496576256626; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.6111528333611456; train accuracy : 0.9393893862882989; \n",
      " validation loss : 0.6028759403115806; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5683900898106745; train accuracy : 0.9828312525171163; \n",
      " validation loss : 0.6224709369798115; validation accuracy : 0.9288702928870293\n",
      "Epoch 83:\t train loss : 0.5634560925292619; train accuracy : 0.9878072430992286; \n",
      " validation loss : 0.6013799959049481; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.5644025768157583; train accuracy : 0.9868896186375042; \n",
      " validation loss : 0.594353787983507; validation accuracy : 0.9581589958158996\n",
      "Epoch 85:\t train loss : 0.5620819966488529; train accuracy : 0.9892072245112922; \n",
      " validation loss : 0.6211450877744861; validation accuracy : 0.9288702928870293\n",
      "Epoch 86:\t train loss : 0.5648337186969787; train accuracy : 0.9863821679729855; \n",
      " validation loss : 0.6140121014893526; validation accuracy : 0.9414225941422594\n",
      "Epoch 87:\t train loss : 0.5643442830634143; train accuracy : 0.9869243161188389; \n",
      " validation loss : 0.5956838918612082; validation accuracy : 0.9539748953974896\n",
      "Epoch 88:\t train loss : 0.5625710017253542; train accuracy : 0.9887735059946094; \n",
      " validation loss : 0.6109520205110447; validation accuracy : 0.9414225941422594\n",
      "Epoch 89:\t train loss : 0.5619520157530306; train accuracy : 0.9893429164472257; \n",
      " validation loss : 0.6016362846848669; validation accuracy : 0.9497907949790795\n",
      "Epoch 90:\t train loss : 0.5603862899118697; train accuracy : 0.9908956287369497; \n",
      " validation loss : 0.5985427777620942; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5619337267531386; train accuracy : 0.9894299699495027; \n",
      " validation loss : 0.6043559382012801; validation accuracy : 0.9456066945606695\n",
      "Epoch 92:\t train loss : 0.5630427089182224; train accuracy : 0.9882313578487562; \n",
      " validation loss : 0.6129073694702403; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5692981370872108; train accuracy : 0.9816599027231326; \n",
      " validation loss : 0.6018901907851875; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5623126119303911; train accuracy : 0.9889380092320085; \n",
      " validation loss : 0.5910582245197669; validation accuracy : 0.9581589958158996\n",
      "Epoch 95:\t train loss : 0.5656224384873154; train accuracy : 0.9855788593203011; \n",
      " validation loss : 0.5926008361495143; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.5609227326963167; train accuracy : 0.9904272127389324; \n",
      " validation loss : 0.6138031668441716; validation accuracy : 0.9372384937238494\n",
      "Epoch 97:\t train loss : 0.5605030255311201; train accuracy : 0.9907775953406239; \n",
      " validation loss : 0.5935059676253224; validation accuracy : 0.9581589958158996\n",
      "Epoch 98:\t train loss : 0.5630114984606409; train accuracy : 0.9882276402614703; \n",
      " validation loss : 0.5841913215019022; validation accuracy : 0.9665271966527197\n",
      "Epoch 99:\t train loss : 0.5626861481016453; train accuracy : 0.9887425261005607; \n",
      " validation loss : 0.6091702282885886; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5643548958514379; train accuracy : 0.9869264847114223; \n",
      " validation loss : 0.6149136891745525; validation accuracy : 0.9372384937238494\n",
      "Epoch 101:\t train loss : 0.5639984521209083; train accuracy : 0.9870909879488212; \n",
      " validation loss : 0.5848224317495483; validation accuracy : 0.9665271966527197\n",
      "Epoch 102:\t train loss : 0.5592892282586543; train accuracy : 0.9921311069116143; \n",
      " validation loss : 0.5916019844445316; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 102\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5703245205461489; Train accuracy : 0.9807710895628737; \n",
      " Validation loss : 0.5833278634655876; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 83 ! ---\n",
      "Epoch 1:\t train loss : 0.9521828831873704; train accuracy : 0.5786591901855695; \n",
      " validation loss : 0.9265323286829739; validation accuracy : 0.5899581589958159\n",
      "Epoch 2:\t train loss : 0.7628027134778821; train accuracy : 0.7853700548344125; \n",
      " validation loss : 0.7507169095910913; validation accuracy : 0.7907949790794979\n",
      "Epoch 3:\t train loss : 0.7055307597359791; train accuracy : 0.8447755506676167; \n",
      " validation loss : 0.7374299082248117; validation accuracy : 0.803347280334728\n",
      "Epoch 4:\t train loss : 0.6846352154548696; train accuracy : 0.8650097586666253; \n",
      " validation loss : 0.748175530141733; validation accuracy : 0.7866108786610879\n",
      "Epoch 5:\t train loss : 0.6708827168046112; train accuracy : 0.8793497320239165; \n",
      " validation loss : 0.749135206673967; validation accuracy : 0.7949790794979079\n",
      "Epoch 6:\t train loss : 0.658855928409831; train accuracy : 0.8913352334335016; \n",
      " validation loss : 0.7549020082035084; validation accuracy : 0.803347280334728\n",
      "Epoch 7:\t train loss : 0.650621871293025; train accuracy : 0.8998878527835434; \n",
      " validation loss : 0.7401949599745259; validation accuracy : 0.8075313807531381\n",
      "Epoch 8:\t train loss : 0.6381332920827821; train accuracy : 0.9122060782552124; \n",
      " validation loss : 0.7292037815927683; validation accuracy : 0.8158995815899581\n",
      "Epoch 9:\t train loss : 0.6282919405840249; train accuracy : 0.9225282691533195; \n",
      " validation loss : 0.7133015282099849; validation accuracy : 0.8368200836820083\n",
      "Epoch 10:\t train loss : 0.6210258563745481; train accuracy : 0.9297112673874656; \n",
      " validation loss : 0.6907782955040629; validation accuracy : 0.8535564853556485\n",
      "Epoch 11:\t train loss : 0.6156983162544045; train accuracy : 0.9349047368258001; \n",
      " validation loss : 0.6958550716109293; validation accuracy : 0.8577405857740585\n",
      "Epoch 12:\t train loss : 0.6111290852816397; train accuracy : 0.9403070107500232; \n",
      " validation loss : 0.6861590098977736; validation accuracy : 0.8577405857740585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\t train loss : 0.6079847344311528; train accuracy : 0.9423944360110288; \n",
      " validation loss : 0.66621518566514; validation accuracy : 0.8828451882845189\n",
      "Epoch 14:\t train loss : 0.6046046940980343; train accuracy : 0.9468378822144429; \n",
      " validation loss : 0.6780554883983244; validation accuracy : 0.8702928870292888\n",
      "Epoch 15:\t train loss : 0.6034724351255164; train accuracy : 0.9477982589299545; \n",
      " validation loss : 0.6688379838372591; validation accuracy : 0.8870292887029289\n",
      "Epoch 16:\t train loss : 0.5977688306937; train accuracy : 0.9535391430961306; \n",
      " validation loss : 0.6719152557197374; validation accuracy : 0.8744769874476988\n",
      "Epoch 17:\t train loss : 0.5990994224038292; train accuracy : 0.95198859939899; \n",
      " validation loss : 0.6553095227063158; validation accuracy : 0.891213389121339\n",
      "Epoch 18:\t train loss : 0.6034411131673844; train accuracy : 0.9475488707828619; \n",
      " validation loss : 0.6876790438936456; validation accuracy : 0.8577405857740585\n",
      "Epoch 19:\t train loss : 0.5888870857472065; train accuracy : 0.9624619721800551; \n",
      " validation loss : 0.6377918639698571; validation accuracy : 0.9079497907949791\n",
      "Epoch 20:\t train loss : 0.5830949452035311; train accuracy : 0.9680244121565105; \n",
      " validation loss : 0.6284301001331337; validation accuracy : 0.9205020920502092\n",
      "Epoch 21:\t train loss : 0.5829991430073266; train accuracy : 0.9682685337216147; \n",
      " validation loss : 0.6379465455039263; validation accuracy : 0.9163179916317992\n",
      "Epoch 22:\t train loss : 0.5812780340166893; train accuracy : 0.9699296756405092; \n",
      " validation loss : 0.6472717092773549; validation accuracy : 0.899581589958159\n",
      "Epoch 23:\t train loss : 0.5833033818425207; train accuracy : 0.9680981443043465; \n",
      " validation loss : 0.6294665462713492; validation accuracy : 0.9163179916317992\n",
      "Epoch 24:\t train loss : 0.5797838091893459; train accuracy : 0.9715177050094489; \n",
      " validation loss : 0.648585809382221; validation accuracy : 0.899581589958159\n",
      "Epoch 25:\t train loss : 0.5783860405319866; train accuracy : 0.9728904241147496; \n",
      " validation loss : 0.6331161993988186; validation accuracy : 0.9205020920502092\n",
      "Epoch 26:\t train loss : 0.5914940846755311; train accuracy : 0.9591855385854581; \n",
      " validation loss : 0.6217036658507218; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5783300959800527; train accuracy : 0.9730298336379689; \n",
      " validation loss : 0.6422436010941706; validation accuracy : 0.9079497907949791\n",
      "Epoch 28:\t train loss : 0.5776645026994476; train accuracy : 0.9734672697419375; \n",
      " validation loss : 0.6220877646871716; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5767284422879821; train accuracy : 0.9745360760866197; \n",
      " validation loss : 0.6405883516790368; validation accuracy : 0.9163179916317992\n",
      "Epoch 30:\t train loss : 0.5755475146873941; train accuracy : 0.9757309706000805; \n",
      " validation loss : 0.6436757413413595; validation accuracy : 0.9037656903765691\n",
      "Epoch 31:\t train loss : 0.5767084010741488; train accuracy : 0.9744335326373184; \n",
      " validation loss : 0.6323652018748193; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.575954876505205; train accuracy : 0.9751305802534155; \n",
      " validation loss : 0.623830367176033; validation accuracy : 0.9163179916317992\n",
      "Epoch 33:\t train loss : 0.5779485877363902; train accuracy : 0.9729619876700022; \n",
      " validation loss : 0.6390564455020001; validation accuracy : 0.9121338912133892\n",
      "Epoch 34:\t train loss : 0.5710216845680575; train accuracy : 0.9803912760618358; \n",
      " validation loss : 0.6142739494905441; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5732798403132774; train accuracy : 0.977959354379008; \n",
      " validation loss : 0.6471354239983204; validation accuracy : 0.895397489539749\n",
      "Epoch 36:\t train loss : 0.5753800568063249; train accuracy : 0.9757480095418074; \n",
      " validation loss : 0.6305316736243608; validation accuracy : 0.9246861924686193\n",
      "Epoch 37:\t train loss : 0.5709971220781462; train accuracy : 0.9800910808885034; \n",
      " validation loss : 0.6544366976891058; validation accuracy : 0.895397489539749\n",
      "Epoch 38:\t train loss : 0.577988186754317; train accuracy : 0.9731051147805074; \n",
      " validation loss : 0.6182654056488903; validation accuracy : 0.9330543933054394\n",
      "Epoch 39:\t train loss : 0.5733582029556382; train accuracy : 0.977848756157254; \n",
      " validation loss : 0.6413374811457462; validation accuracy : 0.9079497907949791\n",
      "Epoch 40:\t train loss : 0.571793459440912; train accuracy : 0.9794832553672667; \n",
      " validation loss : 0.6245369612433456; validation accuracy : 0.9288702928870293\n",
      "Epoch 41:\t train loss : 0.5866372071100022; train accuracy : 0.9641172279190805; \n",
      " validation loss : 0.6344881901578434; validation accuracy : 0.9163179916317992\n",
      "Epoch 42:\t train loss : 0.5811128365317205; train accuracy : 0.9700402738622634; \n",
      " validation loss : 0.6447559470190269; validation accuracy : 0.9079497907949791\n",
      "Epoch 43:\t train loss : 0.5723779163724756; train accuracy : 0.978885033613185; \n",
      " validation loss : 0.6448202370143488; validation accuracy : 0.899581589958159\n",
      "Epoch 44:\t train loss : 0.5740862510538783; train accuracy : 0.9770881997583568; \n",
      " validation loss : 0.6386826280299137; validation accuracy : 0.9079497907949791\n",
      "Epoch 45:\t train loss : 0.5745906133497881; train accuracy : 0.9765113541311689; \n",
      " validation loss : 0.6198075694087822; validation accuracy : 0.9330543933054394\n",
      "Epoch 46:\t train loss : 0.5705863592064915; train accuracy : 0.9803352024536076; \n",
      " validation loss : 0.6116702629575829; validation accuracy : 0.9414225941422594\n",
      "Epoch 47:\t train loss : 0.5687408791127553; train accuracy : 0.9824594937885313; \n",
      " validation loss : 0.622829366445815; validation accuracy : 0.9246861924686193\n",
      "Epoch 48:\t train loss : 0.5723711260205867; train accuracy : 0.9787803215713002; \n",
      " validation loss : 0.6354931176032563; validation accuracy : 0.9163179916317992\n",
      "Epoch 49:\t train loss : 0.5687273272919271; train accuracy : 0.9825155673967595; \n",
      " validation loss : 0.6426403199557847; validation accuracy : 0.9079497907949791\n",
      "Epoch 50:\t train loss : 0.5774782204506018; train accuracy : 0.9735313981226185; \n",
      " validation loss : 0.6220874400502532; validation accuracy : 0.9288702928870293\n",
      "Epoch 51:\t train loss : 0.5723825453698332; train accuracy : 0.9788385637721119; \n",
      " validation loss : 0.6267928302748276; validation accuracy : 0.9246861924686193\n",
      "Epoch 52:\t train loss : 0.5691908195321759; train accuracy : 0.9819675330710369; \n",
      " validation loss : 0.6183122307937132; validation accuracy : 0.9372384937238494\n",
      "Epoch 53:\t train loss : 0.5745863272526135; train accuracy : 0.9764317358034635; \n",
      " validation loss : 0.6301160213684689; validation accuracy : 0.9121338912133892\n",
      "Epoch 54:\t train loss : 0.5677171834652286; train accuracy : 0.9834449642182224; \n",
      " validation loss : 0.6344179118386252; validation accuracy : 0.9205020920502092\n",
      "Epoch 55:\t train loss : 0.5706772561921307; train accuracy : 0.9804767805694105; \n",
      " validation loss : 0.6147561682728508; validation accuracy : 0.9330543933054394\n",
      "Epoch 56:\t train loss : 0.5665216407784137; train accuracy : 0.9845388642770841; \n",
      " validation loss : 0.6323650098729219; validation accuracy : 0.9205020920502092\n",
      "Epoch 57:\t train loss : 0.5660646255264646; train accuracy : 0.9851643483379287; \n",
      " validation loss : 0.617833067458725; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.569939554829691; train accuracy : 0.9811679420056384; \n",
      " validation loss : 0.6263943176134618; validation accuracy : 0.9205020920502092\n",
      "Epoch 59:\t train loss : 0.5655154363531228; train accuracy : 0.9857994361659284; \n",
      " validation loss : 0.6229578003341593; validation accuracy : 0.9330543933054394\n",
      "Epoch 60:\t train loss : 0.5670527213459347; train accuracy : 0.9841825954955234; \n",
      " validation loss : 0.6256155945487649; validation accuracy : 0.9246861924686193\n",
      "Epoch 61:\t train loss : 0.5672287243047661; train accuracy : 0.9841051457604015; \n",
      " validation loss : 0.6128473103456263; validation accuracy : 0.9372384937238494\n",
      "Epoch 62:\t train loss : 0.5679888774949408; train accuracy : 0.9829551720933114; \n",
      " validation loss : 0.6106286949304266; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5632754025704106; train accuracy : 0.9880203847702841; \n",
      " validation loss : 0.6166017087100002; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:\t train loss : 0.5666996040666779; train accuracy : 0.9844518107748071; \n",
      " validation loss : 0.6248609168197966; validation accuracy : 0.9246861924686193\n",
      "Epoch 65:\t train loss : 0.5714693696747167; train accuracy : 0.9797332631122402; \n",
      " validation loss : 0.6390777153136589; validation accuracy : 0.9121338912133892\n",
      "Epoch 66:\t train loss : 0.5681681206859188; train accuracy : 0.9829861519873602; \n",
      " validation loss : 0.6236776202887268; validation accuracy : 0.9288702928870293\n",
      "Epoch 67:\t train loss : 0.5647994473976312; train accuracy : 0.9864964837820255; \n",
      " validation loss : 0.6142267227850735; validation accuracy : 0.9372384937238494\n",
      "Epoch 68:\t train loss : 0.5602318321176284; train accuracy : 0.9911493540692091; \n",
      " validation loss : 0.6230352759125815; validation accuracy : 0.9288702928870293\n",
      "Epoch 69:\t train loss : 0.561825978416624; train accuracy : 0.9896040769540568; \n",
      " validation loss : 0.6364072238974108; validation accuracy : 0.9121338912133892\n",
      "Epoch 70:\t train loss : 0.574958671512248; train accuracy : 0.9760289971808297; \n",
      " validation loss : 0.6294513030696598; validation accuracy : 0.9205020920502092\n",
      "Epoch 71:\t train loss : 0.5682209215086428; train accuracy : 0.9828312525171164; \n",
      " validation loss : 0.6271523597754298; validation accuracy : 0.9163179916317992\n",
      "Epoch 72:\t train loss : 0.5664717072853502; train accuracy : 0.9849570928467425; \n",
      " validation loss : 0.6573591529348909; validation accuracy : 0.891213389121339\n",
      "Epoch 73:\t train loss : 0.5847621859439496; train accuracy : 0.9662142569472413; \n",
      " validation loss : 0.6293151513603435; validation accuracy : 0.9205020920502092\n",
      "Epoch 74:\t train loss : 0.5655938878708071; train accuracy : 0.9856578580501255; \n",
      " validation loss : 0.6256149801001901; validation accuracy : 0.9288702928870293\n",
      "Epoch 75:\t train loss : 0.5615761958927225; train accuracy : 0.9897862387310635; \n",
      " validation loss : 0.6228517213426603; validation accuracy : 0.9288702928870293\n",
      "Epoch 76:\t train loss : 0.5629332194345853; train accuracy : 0.9881693980606586; \n",
      " validation loss : 0.6161482990508282; validation accuracy : 0.9372384937238494\n",
      "Epoch 77:\t train loss : 0.5616461819526085; train accuracy : 0.9897279965302519; \n",
      " validation loss : 0.6170676598640963; validation accuracy : 0.9288702928870293\n",
      "Epoch 78:\t train loss : 0.5633427329112055; train accuracy : 0.9878382229932774; \n",
      " validation loss : 0.5982296466811331; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5610863832508305; train accuracy : 0.9902701446761052; \n",
      " validation loss : 0.6135269686707896; validation accuracy : 0.9414225941422594\n",
      "Epoch 80:\t train loss : 0.5730404994779708; train accuracy : 0.9780832739552031; \n",
      " validation loss : 0.6234120964334862; validation accuracy : 0.9288702928870293\n",
      "Epoch 81:\t train loss : 0.5711110177166971; train accuracy : 0.9799907060317854; \n",
      " validation loss : 0.6121955223614939; validation accuracy : 0.9372384937238494\n",
      "Epoch 82:\t train loss : 0.5619912582214136; train accuracy : 0.9893097679605936; \n",
      " validation loss : 0.6177729004799908; validation accuracy : 0.9330543933054394\n",
      "Epoch 83:\t train loss : 0.5601907680652372; train accuracy : 0.9911434678893398; \n",
      " validation loss : 0.6396796816042155; validation accuracy : 0.9079497907949791\n",
      "Epoch 84:\t train loss : 0.5597836289230524; train accuracy : 0.9916701260881687; \n",
      " validation loss : 0.6208288994122189; validation accuracy : 0.9288702928870293\n",
      "Epoch 85:\t train loss : 0.5610424235110671; train accuracy : 0.9902605409089501; \n",
      " validation loss : 0.5998340411898497; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5673759541849557; train accuracy : 0.9837525945661266; \n",
      " validation loss : 0.6276308542834551; validation accuracy : 0.9205020920502092\n",
      "Epoch 87:\t train loss : 0.563105596153658; train accuracy : 0.9882468477957805; \n",
      " validation loss : 0.6211361307080487; validation accuracy : 0.9288702928870293\n",
      "Epoch 88:\t train loss : 0.5593681535768686; train accuracy : 0.9919526627218935; \n",
      " validation loss : 0.6350025584280332; validation accuracy : 0.9163179916317992\n",
      "Epoch 89:\t train loss : 0.5623490870114465; train accuracy : 0.9890154589671303; \n",
      " validation loss : 0.6425718326547422; validation accuracy : 0.9079497907949791\n",
      "Epoch 90:\t train loss : 0.5608203361973059; train accuracy : 0.9905607360822826; \n",
      " validation loss : 0.6101308635437395; validation accuracy : 0.9414225941422594\n",
      "Epoch 91:\t train loss : 0.5660401941115816; train accuracy : 0.9853288515753276; \n",
      " validation loss : 0.6365605818258306; validation accuracy : 0.9121338912133892\n",
      "Epoch 92:\t train loss : 0.5681941983361791; train accuracy : 0.9828312525171163; \n",
      " validation loss : 0.6321976726180643; validation accuracy : 0.9163179916317992\n",
      "Epoch 93:\t train loss : 0.5593667210642758; train accuracy : 0.9919334551875832; \n",
      " validation loss : 0.613628124084807; validation accuracy : 0.9414225941422594\n",
      "Epoch 94:\t train loss : 0.5820908069169508; train accuracy : 0.9688571517085411; \n",
      " validation loss : 0.6418197633075269; validation accuracy : 0.9079497907949791\n",
      "Epoch 95:\t train loss : 0.5704375762705642; train accuracy : 0.9807342234889557; \n",
      " validation loss : 0.6275043144724546; validation accuracy : 0.9246861924686193\n",
      "Epoch 96:\t train loss : 0.5629179266839843; train accuracy : 0.988299203816723; \n",
      " validation loss : 0.621151171936295; validation accuracy : 0.9330543933054394\n",
      "Epoch 97:\t train loss : 0.5614036322527289; train accuracy : 0.9899662319154868; \n",
      " validation loss : 0.6200136906518371; validation accuracy : 0.9330543933054394\n",
      "Epoch 98:\t train loss : 0.5681487031806465; train accuracy : 0.9830112457015397; \n",
      " validation loss : 0.6065890619487188; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5667482284988532; train accuracy : 0.9843898509867096; \n",
      " validation loss : 0.6032660357000851; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5637601860629752; train accuracy : 0.9875321416400756; \n",
      " validation loss : 0.6297453333934618; validation accuracy : 0.9205020920502092\n",
      "Epoch 101:\t train loss : 0.5620830116866373; train accuracy : 0.9892013383314229; \n",
      " validation loss : 0.6220864063292547; validation accuracy : 0.9288702928870293\n",
      "Epoch 102:\t train loss : 0.5601729676706432; train accuracy : 0.9910660181542179; \n",
      " validation loss : 0.6070066760414683; validation accuracy : 0.9372384937238494\n",
      "Epoch 103:\t train loss : 0.562199699492043; train accuracy : 0.9890272313268689; \n",
      " validation loss : 0.6179572252582093; validation accuracy : 0.9288702928870293\n",
      "Epoch 104:\t train loss : 0.5631938645540392; train accuracy : 0.9881325319867406; \n",
      " validation loss : 0.6220116259281631; validation accuracy : 0.9330543933054394\n",
      "Epoch 105:\t train loss : 0.575971140280487; train accuracy : 0.9750199820316614; \n",
      " validation loss : 0.6618974507125217; validation accuracy : 0.895397489539749\n",
      "Epoch 106:\t train loss : 0.574512244092019; train accuracy : 0.976484091824406; \n",
      " validation loss : 0.6364323567615469; validation accuracy : 0.9163179916317992\n",
      "Epoch 107:\t train loss : 0.5630669690557999; train accuracy : 0.9882682239226742; \n",
      " validation loss : 0.6227148947502193; validation accuracy : 0.9288702928870293\n",
      "Epoch 108:\t train loss : 0.5631753437527213; train accuracy : 0.9881384181666099; \n",
      " validation loss : 0.6077053551826124; validation accuracy : 0.9456066945606695\n",
      "Epoch 109:\t train loss : 0.5611469934014561; train accuracy : 0.9903128969298925; \n",
      " validation loss : 0.6100349774226281; validation accuracy : 0.9414225941422594\n",
      "Epoch 110:\t train loss : 0.5616466841576105; train accuracy : 0.9895848694197465; \n",
      " validation loss : 0.6291641265742877; validation accuracy : 0.9246861924686193\n",
      "Epoch 111:\t train loss : 0.5751793218316001; train accuracy : 0.9759419436785526; \n",
      " validation loss : 0.6451450312914636; validation accuracy : 0.9037656903765691\n",
      "Epoch 112:\t train loss : 0.5676287331312847; train accuracy : 0.9835283001332136; \n",
      " validation loss : 0.6042592525152732; validation accuracy : 0.9497907949790795\n",
      "Epoch 113:\t train loss : 0.5621824508675864; train accuracy : 0.9891142848291459; \n",
      " validation loss : 0.6176105290529321; validation accuracy : 0.9330543933054394\n",
      "Epoch 114:\t train loss : 0.5602307779621833; train accuracy : 0.9911567892437808; \n",
      " validation loss : 0.6530123693239654; validation accuracy : 0.895397489539749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115:\t train loss : 0.567203252872784; train accuracy : 0.9838573066080114; \n",
      " validation loss : 0.6289229885431447; validation accuracy : 0.9205020920502092\n",
      "Epoch 116:\t train loss : 0.5620774768651308; train accuracy : 0.9891917345642678; \n",
      " validation loss : 0.6362731564682838; validation accuracy : 0.9163179916317992\n",
      "Epoch 117:\t train loss : 0.564763102749723; train accuracy : 0.9865990272313269; \n",
      " validation loss : 0.6343958766487626; validation accuracy : 0.9121338912133892\n",
      "Epoch 118:\t train loss : 0.558365299561118; train accuracy : 0.9930081477121349; \n",
      " validation loss : 0.6285027231934603; validation accuracy : 0.9205020920502092\n",
      "Epoch 119:\t train loss : 0.5681411637623112; train accuracy : 0.9831292790978655; \n",
      " validation loss : 0.6440355776641495; validation accuracy : 0.895397489539749\n",
      "Epoch 120:\t train loss : 0.5694723841393526; train accuracy : 0.9817469562254098; \n",
      " validation loss : 0.6316188082763715; validation accuracy : 0.9205020920502092\n",
      "Epoch 121:\t train loss : 0.5638070821784424; train accuracy : 0.9875284240527897; \n",
      " validation loss : 0.6139814148469193; validation accuracy : 0.9372384937238494\n",
      "Epoch 122:\t train loss : 0.5639120753122441; train accuracy : 0.9872400012391958; \n",
      " validation loss : 0.6456917234100239; validation accuracy : 0.9037656903765691\n",
      "Epoch 123:\t train loss : 0.5596401049789655; train accuracy : 0.9918442330927228; \n",
      " validation loss : 0.6193088896022124; validation accuracy : 0.9330543933054394\n",
      "Epoch 124:\t train loss : 0.5594475776660701; train accuracy : 0.9919393413674525; \n",
      " validation loss : 0.6089319789599191; validation accuracy : 0.9414225941422594\n",
      "Epoch 125:\t train loss : 0.5630216150246947; train accuracy : 0.9882217540816011; \n",
      " validation loss : 0.6136242562984832; validation accuracy : 0.9372384937238494\n",
      "Epoch 126:\t train loss : 0.5603706330604727; train accuracy : 0.9909671922922023; \n",
      " validation loss : 0.6137428700225254; validation accuracy : 0.9372384937238494\n",
      "Epoch 127:\t train loss : 0.5601769170098831; train accuracy : 0.9911840515505437; \n",
      " validation loss : 0.6155615471640845; validation accuracy : 0.9330543933054394\n",
      "Epoch 128:\t train loss : 0.5622067846296978; train accuracy : 0.9891201710090152; \n",
      " validation loss : 0.6218159818998565; validation accuracy : 0.9288702928870293\n",
      "Early stopping at epoch 128\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5633427329112055; Train accuracy : 0.9878382229932774; \n",
      " Validation loss : 0.5982296466811331; Validation accuracy : 0.9497907949790795\n",
      "--- Let's train model 84 ! ---\n",
      "Epoch 1:\t train loss : 0.9489258140997966; train accuracy : 0.577708417237213; \n",
      " validation loss : 0.8701950124385995; validation accuracy : 0.6652719665271967\n",
      "Epoch 2:\t train loss : 0.7652430130336495; train accuracy : 0.7824093063601723; \n",
      " validation loss : 0.7534154579150124; validation accuracy : 0.8117154811715481\n",
      "Epoch 3:\t train loss : 0.7162447616874311; train accuracy : 0.8333845534248273; \n",
      " validation loss : 0.7254048799686341; validation accuracy : 0.8284518828451883\n",
      "Epoch 4:\t train loss : 0.6875657508741685; train accuracy : 0.8625372533225937; \n",
      " validation loss : 0.7122762052416776; validation accuracy : 0.8326359832635983\n",
      "Epoch 5:\t train loss : 0.6680923115150117; train accuracy : 0.8821747885622231; \n",
      " validation loss : 0.6816218764525548; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6579329220615903; train accuracy : 0.8920226772824437; \n",
      " validation loss : 0.7001765848993954; validation accuracy : 0.8451882845188284\n",
      "Epoch 7:\t train loss : 0.6399412626412077; train accuracy : 0.9102735524644505; \n",
      " validation loss : 0.6511898363945289; validation accuracy : 0.899581589958159\n",
      "Epoch 8:\t train loss : 0.6215358298605098; train accuracy : 0.9289293348616747; \n",
      " validation loss : 0.6785386036143967; validation accuracy : 0.8744769874476988\n",
      "Epoch 9:\t train loss : 0.6195171848040893; train accuracy : 0.931125189751851; \n",
      " validation loss : 0.6598450128244289; validation accuracy : 0.891213389121339\n",
      "Epoch 10:\t train loss : 0.6130570568474202; train accuracy : 0.9374199944236191; \n",
      " validation loss : 0.6711812447028732; validation accuracy : 0.8744769874476988\n",
      "Epoch 11:\t train loss : 0.602467798441999; train accuracy : 0.9485166826729453; \n",
      " validation loss : 0.6591320423156448; validation accuracy : 0.8786610878661087\n",
      "Epoch 12:\t train loss : 0.5945620134494055; train accuracy : 0.9567285231884507; \n",
      " validation loss : 0.6531066240184866; validation accuracy : 0.895397489539749\n",
      "Epoch 13:\t train loss : 0.5939588767103167; train accuracy : 0.9572861612813284; \n",
      " validation loss : 0.6574316178657639; validation accuracy : 0.891213389121339\n",
      "Epoch 14:\t train loss : 0.5888619529676705; train accuracy : 0.9625954955234053; \n",
      " validation loss : 0.6372280182012476; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5902469778585431; train accuracy : 0.9608429629170668; \n",
      " validation loss : 0.6541852080450716; validation accuracy : 0.895397489539749\n",
      "Epoch 16:\t train loss : 0.5866519147984666; train accuracy : 0.9646033024567056; \n",
      " validation loss : 0.6412219519866118; validation accuracy : 0.9121338912133892\n",
      "Epoch 17:\t train loss : 0.5878232646229756; train accuracy : 0.9632631122401561; \n",
      " validation loss : 0.6341293888013981; validation accuracy : 0.9246861924686193\n",
      "Epoch 18:\t train loss : 0.5841522191532471; train accuracy : 0.9671879550171938; \n",
      " validation loss : 0.6529258336843473; validation accuracy : 0.895397489539749\n",
      "Epoch 19:\t train loss : 0.583346935762794; train accuracy : 0.9677279345704638; \n",
      " validation loss : 0.6326478833292278; validation accuracy : 0.9121338912133892\n",
      "Epoch 20:\t train loss : 0.583987696333032; train accuracy : 0.9669438334520896; \n",
      " validation loss : 0.6390398091449554; validation accuracy : 0.899581589958159\n",
      "Epoch 21:\t train loss : 0.5798576435332642; train accuracy : 0.9714012206078255; \n",
      " validation loss : 0.6139728753643048; validation accuracy : 0.9372384937238494\n",
      "Epoch 22:\t train loss : 0.5830244155733599; train accuracy : 0.9681312927909786; \n",
      " validation loss : 0.6212153105416308; validation accuracy : 0.9288702928870293\n",
      "Epoch 23:\t train loss : 0.5810923369833064; train accuracy : 0.9701657424331609; \n",
      " validation loss : 0.6359864527833788; validation accuracy : 0.9121338912133892\n",
      "Epoch 24:\t train loss : 0.5779286392333814; train accuracy : 0.9731862821029152; \n",
      " validation loss : 0.6451958876714222; validation accuracy : 0.9037656903765691\n",
      "Epoch 25:\t train loss : 0.5792859392226865; train accuracy : 0.9715427987236284; \n",
      " validation loss : 0.6491298412429373; validation accuracy : 0.899581589958159\n",
      "Epoch 26:\t train loss : 0.5885506789768614; train accuracy : 0.9621249109328046; \n",
      " validation loss : 0.6444282302506276; validation accuracy : 0.9079497907949791\n",
      "Epoch 27:\t train loss : 0.58231004795461; train accuracy : 0.9688261718144924; \n",
      " validation loss : 0.6083031973808393; validation accuracy : 0.9456066945606695\n",
      "Epoch 28:\t train loss : 0.5708539058241004; train accuracy : 0.9802555841259023; \n",
      " validation loss : 0.6134533500008553; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5708271547157062; train accuracy : 0.9806103039127606; \n",
      " validation loss : 0.6267470304810633; validation accuracy : 0.9205020920502092\n",
      "Epoch 30:\t train loss : 0.5675468482181663; train accuracy : 0.983915548808823; \n",
      " validation loss : 0.6184543910066709; validation accuracy : 0.9288702928870293\n",
      "Epoch 31:\t train loss : 0.5714747528214741; train accuracy : 0.97954893274265; \n",
      " validation loss : 0.6299399450954362; validation accuracy : 0.9246861924686193\n",
      "Epoch 32:\t train loss : 0.5802391699563426; train accuracy : 0.9708243749806376; \n",
      " validation loss : 0.6342119089725381; validation accuracy : 0.9163179916317992\n",
      "Epoch 33:\t train loss : 0.5705600545958077; train accuracy : 0.9806818674680132; \n",
      " validation loss : 0.6271855871089473; validation accuracy : 0.9288702928870293\n",
      "Epoch 34:\t train loss : 0.5736345536405565; train accuracy : 0.9776709315654141; \n",
      " validation loss : 0.6463276336758049; validation accuracy : 0.899581589958159\n",
      "Epoch 35:\t train loss : 0.570768257057255; train accuracy : 0.9804628396170885; \n",
      " validation loss : 0.6318801064849541; validation accuracy : 0.9163179916317992\n",
      "Epoch 36:\t train loss : 0.5761084075944576; train accuracy : 0.9749756807831718; \n",
      " validation loss : 0.6539075274689264; validation accuracy : 0.895397489539749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:\t train loss : 0.574315001831878; train accuracy : 0.9766544812416742; \n",
      " validation loss : 0.6394434353119108; validation accuracy : 0.9121338912133892\n",
      "Epoch 38:\t train loss : 0.5689851271346741; train accuracy : 0.9821416400755909; \n",
      " validation loss : 0.6356936298141779; validation accuracy : 0.9163179916317992\n",
      "Epoch 39:\t train loss : 0.5687645979320571; train accuracy : 0.9823238018525977; \n",
      " validation loss : 0.6095469526793473; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5660840401387347; train accuracy : 0.9851274822640107; \n",
      " validation loss : 0.6337945014205544; validation accuracy : 0.9205020920502092\n",
      "Epoch 41:\t train loss : 0.5756611313309512; train accuracy : 0.9751962576287989; \n",
      " validation loss : 0.6116038034344354; validation accuracy : 0.9372384937238494\n",
      "Epoch 42:\t train loss : 0.5774619756011199; train accuracy : 0.9735270609374516; \n",
      " validation loss : 0.6369456379058446; validation accuracy : 0.9121338912133892\n",
      "Epoch 43:\t train loss : 0.5740623577045287; train accuracy : 0.9769621115895784; \n",
      " validation loss : 0.6350048850057137; validation accuracy : 0.9121338912133892\n",
      "Epoch 44:\t train loss : 0.5701640574896863; train accuracy : 0.9809606865144521; \n",
      " validation loss : 0.6152380094238444; validation accuracy : 0.9330543933054394\n",
      "Epoch 45:\t train loss : 0.5627103447937418; train accuracy : 0.988711546206512; \n",
      " validation loss : 0.6192207822847002; validation accuracy : 0.9330543933054394\n",
      "Epoch 46:\t train loss : 0.5688028075447258; train accuracy : 0.9822832181913937; \n",
      " validation loss : 0.6112659923362569; validation accuracy : 0.9372384937238494\n",
      "Epoch 47:\t train loss : 0.5675409425273937; train accuracy : 0.9837024071377676; \n",
      " validation loss : 0.6196502674385509; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5679348238694807; train accuracy : 0.9831271105052821; \n",
      " validation loss : 0.6212802683694264; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5667009845742975; train accuracy : 0.9843529849127916; \n",
      " validation loss : 0.5975264264667811; validation accuracy : 0.9539748953974896\n",
      "Epoch 50:\t train loss : 0.5756688906916407; train accuracy : 0.9749388147092537; \n",
      " validation loss : 0.6463975614729223; validation accuracy : 0.9079497907949791\n",
      "Epoch 51:\t train loss : 0.5682139259742287; train accuracy : 0.9827885002633291; \n",
      " validation loss : 0.635599995075509; validation accuracy : 0.9163179916317992\n",
      "Epoch 52:\t train loss : 0.5689250695928264; train accuracy : 0.9821496948480436; \n",
      " validation loss : 0.6033844748462946; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5644564774052994; train accuracy : 0.9869494098330184; \n",
      " validation loss : 0.5983579360851907; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.56289937306731; train accuracy : 0.9885197806623501; \n",
      " validation loss : 0.6228148644081201; validation accuracy : 0.9288702928870293\n",
      "Epoch 55:\t train loss : 0.5757767156926852; train accuracy : 0.9751674463273335; \n",
      " validation loss : 0.6430564718247155; validation accuracy : 0.9037656903765691\n",
      "Epoch 56:\t train loss : 0.570668425226447; train accuracy : 0.9805424579447938; \n",
      " validation loss : 0.6262592743728289; validation accuracy : 0.9246861924686193\n",
      "Epoch 57:\t train loss : 0.5676487245277498; train accuracy : 0.9833926081972799; \n",
      " validation loss : 0.6086142492003096; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.567900911781181; train accuracy : 0.9833210446420273; \n",
      " validation loss : 0.6296220054741596; validation accuracy : 0.9205020920502092\n",
      "Epoch 59:\t train loss : 0.5614501327799845; train accuracy : 0.9899079897146752; \n",
      " validation loss : 0.6159948028569788; validation accuracy : 0.9330543933054394\n",
      "Epoch 60:\t train loss : 0.5623026553335688; train accuracy : 0.9889342916447226; \n",
      " validation loss : 0.6074315384867556; validation accuracy : 0.9414225941422594\n",
      "Epoch 61:\t train loss : 0.5627022548635666; train accuracy : 0.9886244927042349; \n",
      " validation loss : 0.6291747939043564; validation accuracy : 0.9205020920502092\n",
      "Epoch 62:\t train loss : 0.5617083914506923; train accuracy : 0.989563493292853; \n",
      " validation loss : 0.6113865858861209; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.564284964290151; train accuracy : 0.9868623563307414; \n",
      " validation loss : 0.6172886573479968; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.5650374415879379; train accuracy : 0.9860937451593915; \n",
      " validation loss : 0.6126037811039454; validation accuracy : 0.9372384937238494\n",
      "Epoch 65:\t train loss : 0.5700759087315659; train accuracy : 0.9809783450540599; \n",
      " validation loss : 0.59864777001315; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.5670958255605959; train accuracy : 0.9838920040893461; \n",
      " validation loss : 0.6004153905888012; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.567836226644501; train accuracy : 0.9831875212986771; \n",
      " validation loss : 0.6257092217086339; validation accuracy : 0.9246861924686193\n",
      "Epoch 68:\t train loss : 0.5657814314813236; train accuracy : 0.9852978716812788; \n",
      " validation loss : 0.6055011801135513; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.5612569299774148; train accuracy : 0.9899042721273893; \n",
      " validation loss : 0.6131423526393182; validation accuracy : 0.9372384937238494\n",
      "Epoch 70:\t train loss : 0.5596815072169137; train accuracy : 0.9916642399082995; \n",
      " validation loss : 0.626937786458633; validation accuracy : 0.9246861924686193\n",
      "Epoch 71:\t train loss : 0.563222402920852; train accuracy : 0.9880395923045944; \n",
      " validation loss : 0.6448965270976749; validation accuracy : 0.9037656903765691\n",
      "Epoch 72:\t train loss : 0.5702049849068684; train accuracy : 0.981088323677933; \n",
      " validation loss : 0.6855135981887961; validation accuracy : 0.8661087866108786\n",
      "Epoch 73:\t train loss : 0.5701182049570143; train accuracy : 0.9813169552960129; \n",
      " validation loss : 0.6315913314442012; validation accuracy : 0.9205020920502092\n",
      "Epoch 74:\t train loss : 0.5674070857222911; train accuracy : 0.9837798568728895; \n",
      " validation loss : 0.6117069993655742; validation accuracy : 0.9372384937238494\n",
      "Epoch 75:\t train loss : 0.5599226008651088; train accuracy : 0.9914340592955172; \n",
      " validation loss : 0.5925932771363559; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5674051485803294; train accuracy : 0.9837798568728895; \n",
      " validation loss : 0.6244306923761757; validation accuracy : 0.9288702928870293\n",
      "Epoch 77:\t train loss : 0.5653952613227563; train accuracy : 0.9857470801449859; \n",
      " validation loss : 0.6110687202813465; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5612540777161683; train accuracy : 0.989938969608724; \n",
      " validation loss : 0.6362481833822303; validation accuracy : 0.9121338912133892\n",
      "Epoch 79:\t train loss : 0.5590248804651687; train accuracy : 0.9923361938102172; \n",
      " validation loss : 0.6367385356577452; validation accuracy : 0.9121338912133892\n",
      "Epoch 80:\t train loss : 0.5660454721367064; train accuracy : 0.9851039375445336; \n",
      " validation loss : 0.6309086368515764; validation accuracy : 0.9205020920502092\n",
      "Epoch 81:\t train loss : 0.5621506278726129; train accuracy : 0.9891356609560396; \n",
      " validation loss : 0.6076000966905338; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5663909200282435; train accuracy : 0.9848892468787757; \n",
      " validation loss : 0.6228902314449313; validation accuracy : 0.9288702928870293\n",
      "Epoch 83:\t train loss : 0.5679464794082384; train accuracy : 0.9828681185910344; \n",
      " validation loss : 0.608395672945775; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5601376987984297; train accuracy : 0.9910719043340872; \n",
      " validation loss : 0.6043814051528915; validation accuracy : 0.9414225941422594\n",
      "Epoch 85:\t train loss : 0.5628569801999; train accuracy : 0.9883803711391307; \n",
      " validation loss : 0.6294760922883971; validation accuracy : 0.9205020920502092\n",
      "Epoch 86:\t train loss : 0.5632704275554696; train accuracy : 0.9879776325164968; \n",
      " validation loss : 0.6078591023465804; validation accuracy : 0.9414225941422594\n",
      "Epoch 87:\t train loss : 0.5589747516148643; train accuracy : 0.9924254159050776; \n",
      " validation loss : 0.6019383386903716; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88:\t train loss : 0.5603837160485777; train accuracy : 0.9909730784720716; \n",
      " validation loss : 0.6134516669449643; validation accuracy : 0.9372384937238494\n",
      "Epoch 89:\t train loss : 0.5604343100245621; train accuracy : 0.9909324948108678; \n",
      " validation loss : 0.6141847235470875; validation accuracy : 0.9372384937238494\n",
      "Epoch 90:\t train loss : 0.5600933394222223; train accuracy : 0.9911589578363642; \n",
      " validation loss : 0.6119121764189023; validation accuracy : 0.9414225941422594\n",
      "Epoch 91:\t train loss : 0.560524388456493; train accuracy : 0.9908218965891137; \n",
      " validation loss : 0.6100879130411683; validation accuracy : 0.9372384937238494\n",
      "Epoch 92:\t train loss : 0.5599054755171231; train accuracy : 0.9914452120573748; \n",
      " validation loss : 0.614762101779652; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5604254919481522; train accuracy : 0.9908587626630316; \n",
      " validation loss : 0.6167658381558022; validation accuracy : 0.9330543933054394\n",
      "Epoch 94:\t train loss : 0.5651448851670271; train accuracy : 0.9861866848415378; \n",
      " validation loss : 0.616996949216428; validation accuracy : 0.9330543933054394\n",
      "Epoch 95:\t train loss : 0.5634241621782079; train accuracy : 0.9877976393320734; \n",
      " validation loss : 0.6467833944971525; validation accuracy : 0.9079497907949791\n",
      "Epoch 96:\t train loss : 0.5638538393079928; train accuracy : 0.9873543170482357; \n",
      " validation loss : 0.6116554128607442; validation accuracy : 0.9372384937238494\n",
      "Epoch 97:\t train loss : 0.5588340182161122; train accuracy : 0.9924601133864122; \n",
      " validation loss : 0.6276937427730496; validation accuracy : 0.9246861924686193\n",
      "Epoch 98:\t train loss : 0.5764321207476825; train accuracy : 0.9744357012299018; \n",
      " validation loss : 0.6122063406875006; validation accuracy : 0.9372384937238494\n",
      "Epoch 99:\t train loss : 0.559122420898312; train accuracy : 0.9922742340221197; \n",
      " validation loss : 0.6164541639620827; validation accuracy : 0.9330543933054394\n",
      "Epoch 100:\t train loss : 0.5604340979747974; train accuracy : 0.990901514916819; \n",
      " validation loss : 0.6214287089786049; validation accuracy : 0.9288702928870293\n",
      "Epoch 101:\t train loss : 0.5598415516126979; train accuracy : 0.9914997366709005; \n",
      " validation loss : 0.5995056834730369; validation accuracy : 0.9539748953974896\n",
      "Epoch 102:\t train loss : 0.5642959642025805; train accuracy : 0.9868933362247901; \n",
      " validation loss : 0.6104723273971921; validation accuracy : 0.9414225941422594\n",
      "Epoch 103:\t train loss : 0.5585560360695011; train accuracy : 0.9927485362000061; \n",
      " validation loss : 0.6084478049601181; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.5581376616075172; train accuracy : 0.9931940270764273; \n",
      " validation loss : 0.5975258670284948; validation accuracy : 0.9539748953974896\n",
      "Epoch 105:\t train loss : 0.5567253772183955; train accuracy : 0.9947061557049475; \n",
      " validation loss : 0.623653223896551; validation accuracy : 0.9288702928870293\n",
      "Epoch 106:\t train loss : 0.5577992144875332; train accuracy : 0.9935289197310945; \n",
      " validation loss : 0.6184100662681158; validation accuracy : 0.9330543933054394\n",
      "Epoch 107:\t train loss : 0.5617676463490583; train accuracy : 0.9894646674308374; \n",
      " validation loss : 0.6489901201213852; validation accuracy : 0.9037656903765691\n",
      "Epoch 108:\t train loss : 0.5697871006782632; train accuracy : 0.9813169552960129; \n",
      " validation loss : 0.6133758550820009; validation accuracy : 0.9372384937238494\n",
      "Epoch 109:\t train loss : 0.5623622649563772; train accuracy : 0.9889903652529508; \n",
      " validation loss : 0.5945337736941059; validation accuracy : 0.9581589958158996\n",
      "Epoch 110:\t train loss : 0.5627000637083344; train accuracy : 0.9885839090430311; \n",
      " validation loss : 0.6049224379183441; validation accuracy : 0.9456066945606695\n",
      "Epoch 111:\t train loss : 0.5586716991469627; train accuracy : 0.9925744291954521; \n",
      " validation loss : 0.6117953857140415; validation accuracy : 0.9372384937238494\n",
      "Epoch 112:\t train loss : 0.5681440872296482; train accuracy : 0.9829300783791319; \n",
      " validation loss : 0.605968175598131; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5607000771293731; train accuracy : 0.9905201524210787; \n",
      " validation loss : 0.5932860467155613; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5599000044852724; train accuracy : 0.9914436630626723; \n",
      " validation loss : 0.5874395322421067; validation accuracy : 0.9665271966527197\n",
      "Epoch 115:\t train loss : 0.5616508363567899; train accuracy : 0.9895170234517798; \n",
      " validation loss : 0.5960690976230475; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.557828902485523; train accuracy : 0.9934728461228662; \n",
      " validation loss : 0.6286248575870228; validation accuracy : 0.9246861924686193\n",
      "Epoch 117:\t train loss : 0.6006521383465772; train accuracy : 0.9496053161498188; \n",
      " validation loss : 0.5968211753420609; validation accuracy : 0.9539748953974896\n",
      "Epoch 118:\t train loss : 0.561728294471125; train accuracy : 0.9893931038755848; \n",
      " validation loss : 0.5978481416549636; validation accuracy : 0.9497907949790795\n",
      "Epoch 119:\t train loss : 0.558894148537596; train accuracy : 0.9924659995662815; \n",
      " validation loss : 0.6046983430966995; validation accuracy : 0.9456066945606695\n",
      "Epoch 120:\t train loss : 0.5581283994175433; train accuracy : 0.9931940270764273; \n",
      " validation loss : 0.6040521991060723; validation accuracy : 0.9497907949790795\n",
      "Epoch 121:\t train loss : 0.5575385046043969; train accuracy : 0.9937767588834846; \n",
      " validation loss : 0.6078571894244658; validation accuracy : 0.9414225941422594\n",
      "Epoch 122:\t train loss : 0.5584700440942552; train accuracy : 0.9928783419560705; \n",
      " validation loss : 0.5989638747283537; validation accuracy : 0.9539748953974896\n",
      "Epoch 123:\t train loss : 0.5602277319286995; train accuracy : 0.9910932804609808; \n",
      " validation loss : 0.5954996508685176; validation accuracy : 0.9581589958158996\n",
      "Epoch 124:\t train loss : 0.557447018743211; train accuracy : 0.9939685244276465; \n",
      " validation loss : 0.5979261381664522; validation accuracy : 0.9539748953974896\n",
      "Epoch 125:\t train loss : 0.555506893294784; train accuracy : 0.9958892778586698; \n",
      " validation loss : 0.6103019431579532; validation accuracy : 0.9414225941422594\n",
      "Epoch 126:\t train loss : 0.5566339288885044; train accuracy : 0.9947024381176616; \n",
      " validation loss : 0.6098869186794328; validation accuracy : 0.9414225941422594\n",
      "Epoch 127:\t train loss : 0.5573258737883846; train accuracy : 0.993879302332786; \n",
      " validation loss : 0.5944012777677632; validation accuracy : 0.9581589958158996\n",
      "Epoch 128:\t train loss : 0.5587122299110365; train accuracy : 0.9926828588246228; \n",
      " validation loss : 0.5931124240188546; validation accuracy : 0.9581589958158996\n",
      "Epoch 129:\t train loss : 0.556285076630418; train accuracy : 0.995170854115679; \n",
      " validation loss : 0.5962083331226843; validation accuracy : 0.9539748953974896\n",
      "Epoch 130:\t train loss : 0.5618048714307071; train accuracy : 0.9893466340345116; \n",
      " validation loss : 0.6003046657952326; validation accuracy : 0.9497907949790795\n",
      "Epoch 131:\t train loss : 0.5588403733736288; train accuracy : 0.9925161869946405; \n",
      " validation loss : 0.5918536433790915; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.5587358899612233; train accuracy : 0.9925493354812727; \n",
      " validation loss : 0.5980108159647631; validation accuracy : 0.9539748953974896\n",
      "Epoch 133:\t train loss : 0.5586231594080405; train accuracy : 0.9926983487716472; \n",
      " validation loss : 0.6004258054939434; validation accuracy : 0.9497907949790795\n",
      "Epoch 134:\t train loss : 0.5582580653811041; train accuracy : 0.9931630471823786; \n",
      " validation loss : 0.5977311274216072; validation accuracy : 0.9497907949790795\n",
      "Epoch 135:\t train loss : 0.5583279727646865; train accuracy : 0.9930605037330772; \n",
      " validation loss : 0.6017959607490265; validation accuracy : 0.9497907949790795\n",
      "Epoch 136:\t train loss : 0.5611751577590366; train accuracy : 0.9901521112797794; \n",
      " validation loss : 0.6168435667106961; validation accuracy : 0.9330543933054394\n",
      "Epoch 137:\t train loss : 0.5583925026608456; train accuracy : 0.9929226432045603; \n",
      " validation loss : 0.6008479872854571; validation accuracy : 0.9497907949790795\n",
      "Epoch 138:\t train loss : 0.558931923127204; train accuracy : 0.9923457975773723; \n",
      " validation loss : 0.59727134883383; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139:\t train loss : 0.5564115927863429; train accuracy : 0.9950004646984107; \n",
      " validation loss : 0.602663197844233; validation accuracy : 0.9456066945606695\n",
      "Epoch 140:\t train loss : 0.5591478745576612; train accuracy : 0.9921754081601041; \n",
      " validation loss : 0.6062063483639571; validation accuracy : 0.9414225941422594\n",
      "Epoch 141:\t train loss : 0.5602933762477189; train accuracy : 0.9910254344930141; \n",
      " validation loss : 0.6059106576940797; validation accuracy : 0.9456066945606695\n",
      "Epoch 142:\t train loss : 0.5573137018064598; train accuracy : 0.9940924440038414; \n",
      " validation loss : 0.6038514306217101; validation accuracy : 0.9497907949790795\n",
      "Epoch 143:\t train loss : 0.5576529369061817; train accuracy : 0.9936934229684934; \n",
      " validation loss : 0.5908424125483968; validation accuracy : 0.9623430962343096\n",
      "Epoch 144:\t train loss : 0.5603534834605433; train accuracy : 0.9908860249697946; \n",
      " validation loss : 0.6130534430868279; validation accuracy : 0.9372384937238494\n",
      "Epoch 145:\t train loss : 0.5564876307903939; train accuracy : 0.9948359614610118; \n",
      " validation loss : 0.6010258568289797; validation accuracy : 0.9497907949790795\n",
      "Epoch 146:\t train loss : 0.5555818081232942; train accuracy : 0.9958775054989312; \n",
      " validation loss : 0.5993767958528401; validation accuracy : 0.9497907949790795\n",
      "Epoch 147:\t train loss : 0.5571433855925844; train accuracy : 0.9941581213792249; \n",
      " validation loss : 0.6063711985254026; validation accuracy : 0.9456066945606695\n",
      "Epoch 148:\t train loss : 0.5577093326103704; train accuracy : 0.9936432355401345; \n",
      " validation loss : 0.6068084116154142; validation accuracy : 0.9456066945606695\n",
      "Epoch 149:\t train loss : 0.560943335126174; train accuracy : 0.9904774001672915; \n",
      " validation loss : 0.6022583909796229; validation accuracy : 0.9497907949790795\n",
      "Epoch 150:\t train loss : 0.5576023163505048; train accuracy : 0.9938077387775334; \n",
      " validation loss : 0.6036492088113213; validation accuracy : 0.9456066945606695\n",
      "Epoch 151:\t train loss : 0.5579401829865767; train accuracy : 0.993315778060039; \n",
      " validation loss : 0.6114799105652167; validation accuracy : 0.9414225941422594\n",
      "Epoch 152:\t train loss : 0.5556419776334409; train accuracy : 0.9956259487592553; \n",
      " validation loss : 0.5902919143542051; validation accuracy : 0.9623430962343096\n",
      "Epoch 153:\t train loss : 0.565136060903301; train accuracy : 0.9860531614981877; \n",
      " validation loss : 0.5926261378030858; validation accuracy : 0.9581589958158996\n",
      "Epoch 154:\t train loss : 0.5560540349732901; train accuracy : 0.9953994857337588; \n",
      " validation loss : 0.5944836171839962; validation accuracy : 0.9581589958158996\n",
      "Epoch 155:\t train loss : 0.5568189082712778; train accuracy : 0.9945165587533691; \n",
      " validation loss : 0.614086519260888; validation accuracy : 0.9372384937238494\n",
      "Epoch 156:\t train loss : 0.5578744149461644; train accuracy : 0.9934824498900213; \n",
      " validation loss : 0.5982879389881376; validation accuracy : 0.9497907949790795\n",
      "Epoch 157:\t train loss : 0.5595100437718411; train accuracy : 0.9917438582360049; \n",
      " validation loss : 0.6042869066804674; validation accuracy : 0.9456066945606695\n",
      "Epoch 158:\t train loss : 0.5568042471531536; train accuracy : 0.9945320487003935; \n",
      " validation loss : 0.6175210188407525; validation accuracy : 0.9330543933054394\n",
      "Epoch 159:\t train loss : 0.5558397204227009; train accuracy : 0.9955949688652065; \n",
      " validation loss : 0.5974702587722329; validation accuracy : 0.9539748953974896\n",
      "Epoch 160:\t train loss : 0.5603055732725635; train accuracy : 0.9911087704080052; \n",
      " validation loss : 0.59393425600127; validation accuracy : 0.9539748953974896\n",
      "Epoch 161:\t train loss : 0.5572056574265505; train accuracy : 0.9942104774001673; \n",
      " validation loss : 0.5927488858120996; validation accuracy : 0.9581589958158996\n",
      "Epoch 162:\t train loss : 0.5588898829272877; train accuracy : 0.9924099259580532; \n",
      " validation loss : 0.613698657432713; validation accuracy : 0.9330543933054394\n",
      "Epoch 163:\t train loss : 0.5581295629539418; train accuracy : 0.9931689333622479; \n",
      " validation loss : 0.6222201663280402; validation accuracy : 0.9288702928870293\n",
      "Epoch 164:\t train loss : 0.5573245802737447; train accuracy : 0.9940459741627683; \n",
      " validation loss : 0.5920820445382687; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 164\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5599000044852724; Train accuracy : 0.9914436630626723; \n",
      " Validation loss : 0.5874395322421067; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 85 ! ---\n",
      "Epoch 1:\t train loss : 0.9240943501783925; train accuracy : 0.601050838006134; \n",
      " validation loss : 0.8294262888451298; validation accuracy : 0.7364016736401674\n",
      "Epoch 2:\t train loss : 0.7375669275944567; train accuracy : 0.8127178661048979; \n",
      " validation loss : 0.7266160525545758; validation accuracy : 0.8075313807531381\n",
      "Epoch 3:\t train loss : 0.6909265721894728; train accuracy : 0.8597165339694538; \n",
      " validation loss : 0.716608512845538; validation accuracy : 0.8326359832635983\n",
      "Epoch 4:\t train loss : 0.6732021252725069; train accuracy : 0.8780411412992968; \n",
      " validation loss : 0.7431841084640632; validation accuracy : 0.799163179916318\n",
      "Epoch 5:\t train loss : 0.6591549309425192; train accuracy : 0.8913528919731094; \n",
      " validation loss : 0.6956766153479867; validation accuracy : 0.8493723849372385\n",
      "Epoch 6:\t train loss : 0.6488572909319859; train accuracy : 0.901589578363642; \n",
      " validation loss : 0.6977675593882937; validation accuracy : 0.8451882845188284\n",
      "Epoch 7:\t train loss : 0.6294868125154709; train accuracy : 0.9211282877412559; \n",
      " validation loss : 0.7022761804473486; validation accuracy : 0.8326359832635983\n",
      "Epoch 8:\t train loss : 0.6299328972603336; train accuracy : 0.9208612410545556; \n",
      " validation loss : 0.7131471634104183; validation accuracy : 0.8368200836820083\n",
      "Epoch 9:\t train loss : 0.622153786309321; train accuracy : 0.9287920939310388; \n",
      " validation loss : 0.6556278326176872; validation accuracy : 0.895397489539749\n",
      "Epoch 10:\t train loss : 0.6081791025661731; train accuracy : 0.9427971746336627; \n",
      " validation loss : 0.6776825860021232; validation accuracy : 0.8619246861924686\n",
      "Epoch 11:\t train loss : 0.6001851641107565; train accuracy : 0.9513535115709905; \n",
      " validation loss : 0.682852881603902; validation accuracy : 0.8619246861924686\n",
      "Epoch 12:\t train loss : 0.5984417337341225; train accuracy : 0.9532181913937854; \n",
      " validation loss : 0.6637570168897595; validation accuracy : 0.8870292887029289\n",
      "Epoch 13:\t train loss : 0.5947788429005497; train accuracy : 0.9565153815173952; \n",
      " validation loss : 0.6444593335579097; validation accuracy : 0.9079497907949791\n",
      "Epoch 14:\t train loss : 0.5937099653888256; train accuracy : 0.9576247715232814; \n",
      " validation loss : 0.6443959741562375; validation accuracy : 0.9037656903765691\n",
      "Epoch 15:\t train loss : 0.5938019621525439; train accuracy : 0.9576445986554726; \n",
      " validation loss : 0.659648464718335; validation accuracy : 0.8828451882845189\n",
      "Epoch 16:\t train loss : 0.5849201417868473; train accuracy : 0.9663403451160197; \n",
      " validation loss : 0.6549623177322377; validation accuracy : 0.891213389121339\n",
      "Epoch 17:\t train loss : 0.5850754554163525; train accuracy : 0.9662334644815515; \n",
      " validation loss : 0.6212419676720331; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.5852890361200692; train accuracy : 0.9660240403977818; \n",
      " validation loss : 0.7001104948707212; validation accuracy : 0.8493723849372385\n",
      "Epoch 19:\t train loss : 0.6243869929458473; train accuracy : 0.926044487127854; \n",
      " validation loss : 0.6650099495467573; validation accuracy : 0.8744769874476988\n",
      "Epoch 20:\t train loss : 0.598695231305832; train accuracy : 0.9523293782335265; \n",
      " validation loss : 0.6797461927539681; validation accuracy : 0.8702928870292888\n",
      "Epoch 21:\t train loss : 0.588278071124499; train accuracy : 0.9632129248117971; \n",
      " validation loss : 0.6340560351944019; validation accuracy : 0.9163179916317992\n",
      "Epoch 22:\t train loss : 0.5815032668658114; train accuracy : 0.9697090987948821; \n",
      " validation loss : 0.6605454538722396; validation accuracy : 0.891213389121339\n",
      "Epoch 23:\t train loss : 0.5923827887841764; train accuracy : 0.958658880386629; \n",
      " validation loss : 0.6297717605211838; validation accuracy : 0.9205020920502092\n",
      "Epoch 24:\t train loss : 0.5834437343390052; train accuracy : 0.9675773722853868; \n",
      " validation loss : 0.6524156916468105; validation accuracy : 0.8828451882845189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:\t train loss : 0.5826782352387216; train accuracy : 0.9682161777006723; \n",
      " validation loss : 0.626833355738482; validation accuracy : 0.9246861924686193\n",
      "Epoch 26:\t train loss : 0.575131298332899; train accuracy : 0.9761182192756901; \n",
      " validation loss : 0.6111517591270461; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.575803464327043; train accuracy : 0.9755856748969919; \n",
      " validation loss : 0.6383827872310808; validation accuracy : 0.9121338912133892\n",
      "Epoch 28:\t train loss : 0.5804521658856993; train accuracy : 0.9706326094364757; \n",
      " validation loss : 0.6678693892484542; validation accuracy : 0.8786610878661087\n",
      "Epoch 29:\t train loss : 0.5785555464610059; train accuracy : 0.972828464326652; \n",
      " validation loss : 0.6367909075980671; validation accuracy : 0.9121338912133892\n",
      "Epoch 30:\t train loss : 0.575408496167737; train accuracy : 0.9757870442083088; \n",
      " validation loss : 0.6261901509412446; validation accuracy : 0.9205020920502092\n",
      "Epoch 31:\t train loss : 0.57254612191104; train accuracy : 0.9788909197930543; \n",
      " validation loss : 0.6182633454468822; validation accuracy : 0.9288702928870293\n",
      "Epoch 32:\t train loss : 0.5742591911851141; train accuracy : 0.9768307568388116; \n",
      " validation loss : 0.6231072108738627; validation accuracy : 0.9246861924686193\n",
      "Epoch 33:\t train loss : 0.5720681188112816; train accuracy : 0.9788946373803402; \n",
      " validation loss : 0.6282019974689996; validation accuracy : 0.9121338912133892\n",
      "Epoch 34:\t train loss : 0.5716734577232229; train accuracy : 0.97948542395985; \n",
      " validation loss : 0.5917213263025379; validation accuracy : 0.9623430962343096\n",
      "Epoch 35:\t train loss : 0.5699592408194216; train accuracy : 0.9813597075498002; \n",
      " validation loss : 0.5994361653579076; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5766964085796181; train accuracy : 0.9743870627962452; \n",
      " validation loss : 0.62328232745729; validation accuracy : 0.9246861924686193\n",
      "Epoch 37:\t train loss : 0.5765706958454464; train accuracy : 0.9745205861395954; \n",
      " validation loss : 0.6326255513399891; validation accuracy : 0.9163179916317992\n",
      "Epoch 38:\t train loss : 0.5701047368082531; train accuracy : 0.981024814895133; \n",
      " validation loss : 0.6151838759546023; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5859783353979694; train accuracy : 0.9647036773134235; \n",
      " validation loss : 0.6274265312026099; validation accuracy : 0.9205020920502092\n",
      "Epoch 40:\t train loss : 0.5822868512402349; train accuracy : 0.9684042256575482; \n",
      " validation loss : 0.6310381517811182; validation accuracy : 0.9205020920502092\n",
      "Epoch 41:\t train loss : 0.5721605001141155; train accuracy : 0.9791911149663868; \n",
      " validation loss : 0.6208062802218102; validation accuracy : 0.9330543933054394\n",
      "Epoch 42:\t train loss : 0.5682411800981105; train accuracy : 0.9830090771089562; \n",
      " validation loss : 0.5818463791745265; validation accuracy : 0.9707112970711297\n",
      "Epoch 43:\t train loss : 0.5671073151730237; train accuracy : 0.9843802472195545; \n",
      " validation loss : 0.6279487855472711; validation accuracy : 0.9163179916317992\n",
      "Epoch 44:\t train loss : 0.5700275396944806; train accuracy : 0.9808987267263546; \n",
      " validation loss : 0.6336212462802492; validation accuracy : 0.9163179916317992\n",
      "Epoch 45:\t train loss : 0.5662259224518721; train accuracy : 0.9850094488676848; \n",
      " validation loss : 0.6226201869235775; validation accuracy : 0.9246861924686193\n",
      "Epoch 46:\t train loss : 0.5664844229414117; train accuracy : 0.984767495895164; \n",
      " validation loss : 0.6298536211312589; validation accuracy : 0.9205020920502092\n",
      "Epoch 47:\t train loss : 0.566442619791702; train accuracy : 0.984968865206481; \n",
      " validation loss : 0.6213025830692339; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5656230996397419; train accuracy : 0.9856253291613742; \n",
      " validation loss : 0.6130982011688021; validation accuracy : 0.9372384937238494\n",
      "Epoch 49:\t train loss : 0.5650374293296087; train accuracy : 0.9861807986616686; \n",
      " validation loss : 0.6264894038198723; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5761758009928408; train accuracy : 0.9745574522135134; \n",
      " validation loss : 0.6420709195247564; validation accuracy : 0.9079497907949791\n",
      "Epoch 51:\t train loss : 0.6024711332380237; train accuracy : 0.947796709935252; \n",
      " validation loss : 0.6309831418532738; validation accuracy : 0.9246861924686193\n",
      "Epoch 52:\t train loss : 0.5805236390973023; train accuracy : 0.9703286966758574; \n",
      " validation loss : 0.648911148217692; validation accuracy : 0.899581589958159\n",
      "Epoch 53:\t train loss : 0.574030689929874; train accuracy : 0.976960562594876; \n",
      " validation loss : 0.6484241588011529; validation accuracy : 0.9037656903765691\n",
      "Epoch 54:\t train loss : 0.5718695184353372; train accuracy : 0.979086402924502; \n",
      " validation loss : 0.6497150817128711; validation accuracy : 0.899581589958159\n",
      "Epoch 55:\t train loss : 0.5665320297342596; train accuracy : 0.984767495895164; \n",
      " validation loss : 0.6281904463202835; validation accuracy : 0.9246861924686193\n",
      "Epoch 56:\t train loss : 0.5630416770909304; train accuracy : 0.9880919483255367; \n",
      " validation loss : 0.6340680931899103; validation accuracy : 0.9163179916317992\n",
      "Epoch 57:\t train loss : 0.5640167268966693; train accuracy : 0.9871898138108368; \n",
      " validation loss : 0.6071917192571652; validation accuracy : 0.9456066945606695\n",
      "Epoch 58:\t train loss : 0.5609039865321224; train accuracy : 0.9904427026859568; \n",
      " validation loss : 0.6116566142435436; validation accuracy : 0.9372384937238494\n",
      "Epoch 59:\t train loss : 0.5637238552986285; train accuracy : 0.9874841228043; \n",
      " validation loss : 0.6022186771905887; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5604408539012347; train accuracy : 0.9908609312556151; \n",
      " validation loss : 0.6082374279794374; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5616165312364324; train accuracy : 0.9895944731869017; \n",
      " validation loss : 0.6087616533425413; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5732690507462738; train accuracy : 0.9777660398401438; \n",
      " validation loss : 0.612777599297224; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5657837395318662; train accuracy : 0.9853753214164007; \n",
      " validation loss : 0.6334086315108144; validation accuracy : 0.9163179916317992\n",
      "Epoch 64:\t train loss : 0.5788735829794804; train accuracy : 0.971916106446916; \n",
      " validation loss : 0.7728388539263614; validation accuracy : 0.7740585774058577\n",
      "Epoch 65:\t train loss : 0.590424229866283; train accuracy : 0.9602100436816506; \n",
      " validation loss : 0.6404652615945173; validation accuracy : 0.9163179916317992\n",
      "Epoch 66:\t train loss : 0.5674136234879906; train accuracy : 0.9837798568728895; \n",
      " validation loss : 0.6212242643648226; validation accuracy : 0.9246861924686193\n",
      "Epoch 67:\t train loss : 0.5715216924395977; train accuracy : 0.9794036370395613; \n",
      " validation loss : 0.63483890250723; validation accuracy : 0.9121338912133892\n",
      "Epoch 68:\t train loss : 0.5631786304910692; train accuracy : 0.9880513646643329; \n",
      " validation loss : 0.613766784821618; validation accuracy : 0.9372384937238494\n",
      "Epoch 69:\t train loss : 0.5654807219395258; train accuracy : 0.985719817838223; \n",
      " validation loss : 0.6225912436437652; validation accuracy : 0.9288702928870293\n",
      "Epoch 70:\t train loss : 0.5662271855944756; train accuracy : 0.9850618048886273; \n",
      " validation loss : 0.6165681041051674; validation accuracy : 0.9330543933054394\n",
      "Epoch 71:\t train loss : 0.5604935302590219; train accuracy : 0.990901514916819; \n",
      " validation loss : 0.6093326889105016; validation accuracy : 0.9414225941422594\n",
      "Epoch 72:\t train loss : 0.5603265922015944; train accuracy : 0.9909789646519409; \n",
      " validation loss : 0.6116135984411736; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5610168552156772; train accuracy : 0.9902664270888194; \n",
      " validation loss : 0.6116942277825161; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5646058974987922; train accuracy : 0.9866049134111962; \n",
      " validation loss : 0.6214854522172822; validation accuracy : 0.9330543933054394\n",
      "Epoch 75:\t train loss : 0.5698385832954423; train accuracy : 0.9812336193810217; \n",
      " validation loss : 0.612982797298874; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76:\t train loss : 0.5656596385657781; train accuracy : 0.9855243347067753; \n",
      " validation loss : 0.6167210263007771; validation accuracy : 0.9288702928870293\n",
      "Epoch 77:\t train loss : 0.5614755628705576; train accuracy : 0.9897707487840391; \n",
      " validation loss : 0.6194088371309023; validation accuracy : 0.9330543933054394\n",
      "Epoch 78:\t train loss : 0.5579897734973995; train accuracy : 0.9933393227795161; \n",
      " validation loss : 0.6048488139835863; validation accuracy : 0.9414225941422594\n",
      "Epoch 79:\t train loss : 0.5657771022945579; train accuracy : 0.9854063013104495; \n",
      " validation loss : 0.6055092123824689; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5604446782141854; train accuracy : 0.9908550450757458; \n",
      " validation loss : 0.6106315379482131; validation accuracy : 0.9414225941422594\n",
      "Epoch 81:\t train loss : 0.5610582844588378; train accuracy : 0.9902760308559745; \n",
      " validation loss : 0.6093367033179551; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5616573762481053; train accuracy : 0.9896468292078441; \n",
      " validation loss : 0.6141545017308903; validation accuracy : 0.9330543933054394\n",
      "Epoch 83:\t train loss : 0.5575911200498239; train accuracy : 0.9938600947984758; \n",
      " validation loss : 0.6015255952190683; validation accuracy : 0.9497907949790795\n",
      "Epoch 84:\t train loss : 0.5603439598642439; train accuracy : 0.9909111186839741; \n",
      " validation loss : 0.5850812792809664; validation accuracy : 0.9665271966527197\n",
      "Epoch 85:\t train loss : 0.562345559479485; train accuracy : 0.9889342916447226; \n",
      " validation loss : 0.6018586649176706; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5644717609876571; train accuracy : 0.9867133430403668; \n",
      " validation loss : 0.6092005466203197; validation accuracy : 0.9414225941422594\n",
      "Epoch 87:\t train loss : 0.5610960650294736; train accuracy : 0.9901948635335667; \n",
      " validation loss : 0.613585904222211; validation accuracy : 0.9372384937238494\n",
      "Epoch 88:\t train loss : 0.5605849327533452; train accuracy : 0.9907621053935995; \n",
      " validation loss : 0.6100824090107064; validation accuracy : 0.9414225941422594\n",
      "Epoch 89:\t train loss : 0.559711511011227; train accuracy : 0.9916044487127854; \n",
      " validation loss : 0.6116593640405318; validation accuracy : 0.9372384937238494\n",
      "Epoch 90:\t train loss : 0.5664696822724086; train accuracy : 0.9846355215465163; \n",
      " validation loss : 0.6406426237789637; validation accuracy : 0.9121338912133892\n",
      "Epoch 91:\t train loss : 0.5640860048940788; train accuracy : 0.9871278540227393; \n",
      " validation loss : 0.6090421170293466; validation accuracy : 0.9414225941422594\n",
      "Epoch 92:\t train loss : 0.5618139507753201; train accuracy : 0.9895068000867437; \n",
      " validation loss : 0.6637864509667636; validation accuracy : 0.8870292887029289\n",
      "Early stopping at epoch 92\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5682411800981105; Train accuracy : 0.9830090771089562; \n",
      " Validation loss : 0.5818463791745265; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 86 ! ---\n",
      "Epoch 1:\t train loss : 0.958682790357236; train accuracy : 0.5643176678335761; \n",
      " validation loss : 0.8633089576479568; validation accuracy : 0.6652719665271967\n",
      "Epoch 2:\t train loss : 0.7710668980916866; train accuracy : 0.7777372285386784; \n",
      " validation loss : 0.7555283401912027; validation accuracy : 0.7949790794979079\n",
      "Epoch 3:\t train loss : 0.7158571768307187; train accuracy : 0.8336890857833266; \n",
      " validation loss : 0.7230232076858425; validation accuracy : 0.8326359832635983\n",
      "Epoch 4:\t train loss : 0.6857475178350928; train accuracy : 0.8649034976300382; \n",
      " validation loss : 0.7690348738653859; validation accuracy : 0.7782426778242678\n",
      "Epoch 5:\t train loss : 0.6818103861440533; train accuracy : 0.8678540227392423; \n",
      " validation loss : 0.7088063760768668; validation accuracy : 0.8451882845188284\n",
      "Epoch 6:\t train loss : 0.6658931505654813; train accuracy : 0.8841361256544502; \n",
      " validation loss : 0.6678700598192803; validation accuracy : 0.8870292887029289\n",
      "Epoch 7:\t train loss : 0.6622471178949826; train accuracy : 0.8877201895969515; \n",
      " validation loss : 0.7035600403247934; validation accuracy : 0.8368200836820083\n",
      "Epoch 8:\t train loss : 0.665153378157592; train accuracy : 0.8844229994733418; \n",
      " validation loss : 0.6789832484074677; validation accuracy : 0.8661087866108786\n",
      "Epoch 9:\t train loss : 0.6527908141112518; train accuracy : 0.8972155271228972; \n",
      " validation loss : 0.6728923873579183; validation accuracy : 0.8786610878661087\n",
      "Epoch 10:\t train loss : 0.6377934241563418; train accuracy : 0.9126611728987887; \n",
      " validation loss : 0.6568957573681315; validation accuracy : 0.899581589958159\n",
      "Epoch 11:\t train loss : 0.628341311890415; train accuracy : 0.9224043495771245; \n",
      " validation loss : 0.6676567538858625; validation accuracy : 0.8870292887029289\n",
      "Epoch 12:\t train loss : 0.6136584973378804; train accuracy : 0.937745283311131; \n",
      " validation loss : 0.6464837752138459; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.6127288340667824; train accuracy : 0.9380454784844636; \n",
      " validation loss : 0.6369514443956109; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.6007959500399656; train accuracy : 0.9505362619659841; \n",
      " validation loss : 0.6245893512739427; validation accuracy : 0.9288702928870293\n",
      "Epoch 15:\t train loss : 0.6013509832485285; train accuracy : 0.9499070603178537; \n",
      " validation loss : 0.6297158744129406; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5943619501406453; train accuracy : 0.9569896836952818; \n",
      " validation loss : 0.6232335807721754; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.603140653662346; train accuracy : 0.9477598438613339; \n",
      " validation loss : 0.6493213111784839; validation accuracy : 0.899581589958159\n",
      "Epoch 18:\t train loss : 0.5957698206016483; train accuracy : 0.9555144211406796; \n",
      " validation loss : 0.6534200605776541; validation accuracy : 0.895397489539749\n",
      "Epoch 19:\t train loss : 0.5908971175595444; train accuracy : 0.9603878682734905; \n",
      " validation loss : 0.6352360268036465; validation accuracy : 0.9121338912133892\n",
      "Epoch 20:\t train loss : 0.5884296997248607; train accuracy : 0.9630447039871124; \n",
      " validation loss : 0.6101891588938412; validation accuracy : 0.9497907949790795\n",
      "Epoch 21:\t train loss : 0.5885851356147668; train accuracy : 0.9623882400322191; \n",
      " validation loss : 0.6233782980102832; validation accuracy : 0.9246861924686193\n",
      "Epoch 22:\t train loss : 0.5911009427465932; train accuracy : 0.959913566095604; \n",
      " validation loss : 0.6062600611408278; validation accuracy : 0.9497907949790795\n",
      "Epoch 23:\t train loss : 0.5833919609292272; train accuracy : 0.9680420706961183; \n",
      " validation loss : 0.6222566771003655; validation accuracy : 0.9288702928870293\n",
      "Epoch 24:\t train loss : 0.5902075584083519; train accuracy : 0.9606629697326435; \n",
      " validation loss : 0.614151790452773; validation accuracy : 0.9372384937238494\n",
      "Epoch 25:\t train loss : 0.5848985906443359; train accuracy : 0.9664871898138109; \n",
      " validation loss : 0.6153230711360065; validation accuracy : 0.9330543933054394\n",
      "Epoch 26:\t train loss : 0.5801778455815843; train accuracy : 0.970936522197094; \n",
      " validation loss : 0.6201522590587876; validation accuracy : 0.9288702928870293\n",
      "Epoch 27:\t train loss : 0.5786891841877408; train accuracy : 0.9725806251742619; \n",
      " validation loss : 0.6090731900289249; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.5812233469376981; train accuracy : 0.9700520462220019; \n",
      " validation loss : 0.5985548709773747; validation accuracy : 0.9539748953974896\n",
      "Epoch 29:\t train loss : 0.5757680254135734; train accuracy : 0.9754558691409275; \n",
      " validation loss : 0.6127106251961637; validation accuracy : 0.9330543933054394\n",
      "Epoch 30:\t train loss : 0.5859348978711569; train accuracy : 0.9651123021159268; \n",
      " validation loss : 0.6016144048399343; validation accuracy : 0.9497907949790795\n",
      "Epoch 31:\t train loss : 0.5786738023660623; train accuracy : 0.9723386722017411; \n",
      " validation loss : 0.6092658078517071; validation accuracy : 0.9414225941422594\n",
      "Epoch 32:\t train loss : 0.5728464705854809; train accuracy : 0.9786158183339013; \n",
      " validation loss : 0.6172261275878506; validation accuracy : 0.9330543933054394\n",
      "Epoch 33:\t train loss : 0.5717401837350337; train accuracy : 0.9795820812292821; \n",
      " validation loss : 0.627009619460431; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:\t train loss : 0.5839093968208899; train accuracy : 0.9671259952290964; \n",
      " validation loss : 0.6245771020600014; validation accuracy : 0.9246861924686193\n",
      "Epoch 35:\t train loss : 0.5866677924884149; train accuracy : 0.9641246630936522; \n",
      " validation loss : 0.6297509527405043; validation accuracy : 0.9205020920502092\n",
      "Epoch 36:\t train loss : 0.5739886897591353; train accuracy : 0.9768248706589423; \n",
      " validation loss : 0.6056772026446698; validation accuracy : 0.9456066945606695\n",
      "Epoch 37:\t train loss : 0.573131727575977; train accuracy : 0.9782189658911367; \n",
      " validation loss : 0.6052144062539422; validation accuracy : 0.9497907949790795\n",
      "Epoch 38:\t train loss : 0.5777670527267136; train accuracy : 0.9731456984417113; \n",
      " validation loss : 0.6085321113843712; validation accuracy : 0.9372384937238494\n",
      "Epoch 39:\t train loss : 0.5775907670749013; train accuracy : 0.9735970754980018; \n",
      " validation loss : 0.5882047278823228; validation accuracy : 0.9581589958158996\n",
      "Epoch 40:\t train loss : 0.5726807269138909; train accuracy : 0.9786489668205335; \n",
      " validation loss : 0.6298905395856496; validation accuracy : 0.9246861924686193\n",
      "Epoch 41:\t train loss : 0.5795558935060194; train accuracy : 0.9712735834443447; \n",
      " validation loss : 0.6232372046877619; validation accuracy : 0.9288702928870293\n",
      "Epoch 42:\t train loss : 0.569946896612703; train accuracy : 0.9813810836766939; \n",
      " validation loss : 0.61515707311695; validation accuracy : 0.9330543933054394\n",
      "Epoch 43:\t train loss : 0.5706474459861377; train accuracy : 0.9805365717649246; \n",
      " validation loss : 0.6169158754766848; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5721977738999667; train accuracy : 0.9790671953901917; \n",
      " validation loss : 0.6031163076848275; validation accuracy : 0.9497907949790795\n",
      "Epoch 45:\t train loss : 0.5751187924897279; train accuracy : 0.976081353201772; \n",
      " validation loss : 0.6131384206656603; validation accuracy : 0.9330543933054394\n",
      "Epoch 46:\t train loss : 0.568170008441755; train accuracy : 0.983067319309768; \n",
      " validation loss : 0.6081191795809933; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5654269084734258; train accuracy : 0.9858886582607888; \n",
      " validation loss : 0.6009234248470554; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5822035071916303; train accuracy : 0.9685975401964125; \n",
      " validation loss : 0.6578489375870546; validation accuracy : 0.8870292887029289\n",
      "Epoch 49:\t train loss : 0.5870379894837229; train accuracy : 0.9636584156882183; \n",
      " validation loss : 0.5999076120524566; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5669894116991142; train accuracy : 0.9841943678552619; \n",
      " validation loss : 0.6079801282293228; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5655848237130463; train accuracy : 0.9858864896682054; \n",
      " validation loss : 0.6094435836398087; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5673196416319461; train accuracy : 0.9838167229468076; \n",
      " validation loss : 0.6064623721635074; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5620646260454352; train accuracy : 0.9892013383314229; \n",
      " validation loss : 0.600605767951427; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.5659768117154897; train accuracy : 0.9852588370147775; \n",
      " validation loss : 0.6150521865611417; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.5729384825018278; train accuracy : 0.9781009324948109; \n",
      " validation loss : 0.5993888422681932; validation accuracy : 0.9497907949790795\n",
      "Epoch 56:\t train loss : 0.5647596200525222; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.6099248300807963; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.567282222347947; train accuracy : 0.9838108367669383; \n",
      " validation loss : 0.6114515369511095; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5655919819100429; train accuracy : 0.9856792341770191; \n",
      " validation loss : 0.6347136103336228; validation accuracy : 0.9121338912133892\n",
      "Epoch 59:\t train loss : 0.5657794372798447; train accuracy : 0.9854859196381548; \n",
      " validation loss : 0.5983323195475102; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.5642937821726677; train accuracy : 0.9869515784256018; \n",
      " validation loss : 0.5949251407965308; validation accuracy : 0.9581589958158996\n",
      "Epoch 61:\t train loss : 0.5667825260859798; train accuracy : 0.9842947427119799; \n",
      " validation loss : 0.6440980528231797; validation accuracy : 0.9079497907949791\n",
      "Epoch 62:\t train loss : 0.5694766525507318; train accuracy : 0.9817528424052789; \n",
      " validation loss : 0.6128304240436042; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5668780573834469; train accuracy : 0.9841671055484991; \n",
      " validation loss : 0.6161409308579864; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.5802732625368742; train accuracy : 0.9704157501781344; \n",
      " validation loss : 0.6252317511301719; validation accuracy : 0.9246861924686193\n",
      "Epoch 65:\t train loss : 0.5667131086129681; train accuracy : 0.9845661265838471; \n",
      " validation loss : 0.6065065955491385; validation accuracy : 0.9456066945606695\n",
      "Epoch 66:\t train loss : 0.5641130404356637; train accuracy : 0.9871529477369188; \n",
      " validation loss : 0.6225010094546943; validation accuracy : 0.9288702928870293\n",
      "Epoch 67:\t train loss : 0.5615791502277239; train accuracy : 0.9897766349639084; \n",
      " validation loss : 0.6219936911532045; validation accuracy : 0.9288702928870293\n",
      "Epoch 68:\t train loss : 0.5642644824929833; train accuracy : 0.987034914340593; \n",
      " validation loss : 0.6273175318158494; validation accuracy : 0.9205020920502092\n",
      "Epoch 69:\t train loss : 0.5632888606916135; train accuracy : 0.9880823445583816; \n",
      " validation loss : 0.6184036872341682; validation accuracy : 0.9330543933054394\n",
      "Epoch 70:\t train loss : 0.5634896174875788; train accuracy : 0.9878345054059915; \n",
      " validation loss : 0.6092886365344271; validation accuracy : 0.9372384937238494\n",
      "Epoch 71:\t train loss : 0.5661456553764276; train accuracy : 0.9851606307506429; \n",
      " validation loss : 0.6164644563580236; validation accuracy : 0.9330543933054394\n",
      "Epoch 72:\t train loss : 0.5666086487530478; train accuracy : 0.9845757303510022; \n",
      " validation loss : 0.6466222117209862; validation accuracy : 0.9037656903765691\n",
      "Epoch 73:\t train loss : 0.5832731864189972; train accuracy : 0.9677071780414511; \n",
      " validation loss : 0.6047194438366807; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.5706110506761738; train accuracy : 0.9803875584745501; \n",
      " validation loss : 0.6203153216129673; validation accuracy : 0.9372384937238494\n",
      "Epoch 75:\t train loss : 0.5760164323339163; train accuracy : 0.9748009541807368; \n",
      " validation loss : 0.6667518118097961; validation accuracy : 0.8828451882845189\n",
      "Epoch 76:\t train loss : 0.5800193166552947; train accuracy : 0.97087673100158; \n",
      " validation loss : 0.6248241087062646; validation accuracy : 0.9205020920502092\n",
      "Epoch 77:\t train loss : 0.5681646083221701; train accuracy : 0.9831196753307103; \n",
      " validation loss : 0.6114766214512058; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5698987872340898; train accuracy : 0.9810595123764677; \n",
      " validation loss : 0.6212955746961204; validation accuracy : 0.9246861924686193\n",
      "Epoch 79:\t train loss : 0.5675251867604286; train accuracy : 0.9835416214876546; \n",
      " validation loss : 0.6000571891803427; validation accuracy : 0.9539748953974896\n",
      "Epoch 80:\t train loss : 0.5636178876026309; train accuracy : 0.9876656649834258; \n",
      " validation loss : 0.6124454240366844; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.561564886608502; train accuracy : 0.9897862387310635; \n",
      " validation loss : 0.5947841438641754; validation accuracy : 0.9581589958158996\n",
      "Epoch 82:\t train loss : 0.5651573675642116; train accuracy : 0.9860162954242696; \n",
      " validation loss : 0.6055124838448344; validation accuracy : 0.9456066945606695\n",
      "Epoch 83:\t train loss : 0.5667859711337477; train accuracy : 0.9845041667957496; \n",
      " validation loss : 0.6061787199951011; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.563517622927516; train accuracy : 0.9878654853000403; \n",
      " validation loss : 0.6194586296693672; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85:\t train loss : 0.5622352350817293; train accuracy : 0.9889246878775675; \n",
      " validation loss : 0.6032401836225557; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5636447927557457; train accuracy : 0.9876641159887233; \n",
      " validation loss : 0.6029587565366923; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.5608392474022036; train accuracy : 0.9904619102202671; \n",
      " validation loss : 0.6030876999324448; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.5629520228500395; train accuracy : 0.9883456736577961; \n",
      " validation loss : 0.6126995166522596; validation accuracy : 0.9372384937238494\n",
      "Epoch 89:\t train loss : 0.5672513202594496; train accuracy : 0.9837702531057344; \n",
      " validation loss : 0.6036268875308028; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 89\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5775907670749013; Train accuracy : 0.9735970754980018; \n",
      " Validation loss : 0.5882047278823228; Validation accuracy : 0.9581589958158996\n",
      "--- Let's train model 87 ! ---\n",
      "Epoch 1:\t train loss : 0.9536257592259045; train accuracy : 0.56881192106323; \n",
      " validation loss : 0.8197421918517751; validation accuracy : 0.7322175732217573\n",
      "Epoch 2:\t train loss : 0.7564549026996789; train accuracy : 0.7925013166454971; \n",
      " validation loss : 0.7503998695235479; validation accuracy : 0.799163179916318\n",
      "Epoch 3:\t train loss : 0.6959989745463812; train accuracy : 0.8549109328046098; \n",
      " validation loss : 0.6997095798575659; validation accuracy : 0.8493723849372385\n",
      "Epoch 4:\t train loss : 0.664328692691797; train accuracy : 0.8863865051581523; \n",
      " validation loss : 0.6716941136758605; validation accuracy : 0.8786610878661087\n",
      "Epoch 5:\t train loss : 0.6498093765640092; train accuracy : 0.9003798135010378; \n",
      " validation loss : 0.6736572033380287; validation accuracy : 0.8744769874476988\n",
      "Epoch 6:\t train loss : 0.6339323115892886; train accuracy : 0.917070541218749; \n",
      " validation loss : 0.6577128633276514; validation accuracy : 0.8870292887029289\n",
      "Epoch 7:\t train loss : 0.6149307813837586; train accuracy : 0.9366284581306732; \n",
      " validation loss : 0.6444113226966821; validation accuracy : 0.9121338912133892\n",
      "Epoch 8:\t train loss : 0.6043403217094787; train accuracy : 0.9474094612596425; \n",
      " validation loss : 0.6415833493929733; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.594658675060084; train accuracy : 0.95709656432975; \n",
      " validation loss : 0.6410004432021612; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.5938681788665746; train accuracy : 0.9578651755010997; \n",
      " validation loss : 0.6566425926491768; validation accuracy : 0.895397489539749\n",
      "Epoch 11:\t train loss : 0.5927021431701405; train accuracy : 0.9587075188202856; \n",
      " validation loss : 0.6434084260612586; validation accuracy : 0.9079497907949791\n",
      "Epoch 12:\t train loss : 0.5854677980225249; train accuracy : 0.9664466061526069; \n",
      " validation loss : 0.6140555177006284; validation accuracy : 0.9372384937238494\n",
      "Epoch 13:\t train loss : 0.5815601677577373; train accuracy : 0.9699377304129619; \n",
      " validation loss : 0.6191942984069363; validation accuracy : 0.9330543933054394\n",
      "Epoch 14:\t train loss : 0.5815333643849643; train accuracy : 0.9701914557452214; \n",
      " validation loss : 0.6194621494164549; validation accuracy : 0.9372384937238494\n",
      "Epoch 15:\t train loss : 0.5833235618728382; train accuracy : 0.9680383531088324; \n",
      " validation loss : 0.6483239763522286; validation accuracy : 0.9037656903765691\n",
      "Epoch 16:\t train loss : 0.579470920737957; train accuracy : 0.9719455373462623; \n",
      " validation loss : 0.6242298778156256; validation accuracy : 0.9205020920502092\n",
      "Epoch 17:\t train loss : 0.5804888275788949; train accuracy : 0.9711363425137086; \n",
      " validation loss : 0.629021381889832; validation accuracy : 0.9205020920502092\n",
      "Epoch 18:\t train loss : 0.5783505633924405; train accuracy : 0.9729641562625856; \n",
      " validation loss : 0.6192501868578648; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5723880561205499; train accuracy : 0.9791970011462561; \n",
      " validation loss : 0.6233298963523297; validation accuracy : 0.9246861924686193\n",
      "Epoch 20:\t train loss : 0.5713096324072383; train accuracy : 0.980250317543914; \n",
      " validation loss : 0.6132756331539956; validation accuracy : 0.9372384937238494\n",
      "Epoch 21:\t train loss : 0.5942104247784948; train accuracy : 0.9566436382787571; \n",
      " validation loss : 0.6089824359482087; validation accuracy : 0.9414225941422594\n",
      "Epoch 22:\t train loss : 0.5783922300925636; train accuracy : 0.9730416059977075; \n",
      " validation loss : 0.6154600487979957; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5770066532389488; train accuracy : 0.9742188419715605; \n",
      " validation loss : 0.6183024434490955; validation accuracy : 0.9330543933054394\n",
      "Epoch 24:\t train loss : 0.5705489939792757; train accuracy : 0.9806685461135723; \n",
      " validation loss : 0.6030893804626628; validation accuracy : 0.9497907949790795\n",
      "Epoch 25:\t train loss : 0.5658934743471333; train accuracy : 0.9856253291613742; \n",
      " validation loss : 0.6159860147958365; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5756510414384592; train accuracy : 0.9757501781343908; \n",
      " validation loss : 0.6473784693912638; validation accuracy : 0.9037656903765691\n",
      "Epoch 27:\t train loss : 0.5692784942348045; train accuracy : 0.9819424393568574; \n",
      " validation loss : 0.5920663971344682; validation accuracy : 0.9539748953974896\n",
      "Epoch 28:\t train loss : 0.5704104270702361; train accuracy : 0.9807710895628737; \n",
      " validation loss : 0.6057515138983813; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5676613834539344; train accuracy : 0.9837820254654729; \n",
      " validation loss : 0.6013043485379059; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5640511874039357; train accuracy : 0.9873292233340561; \n",
      " validation loss : 0.6259680724035915; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5660584410344051; train accuracy : 0.9853251339880418; \n",
      " validation loss : 0.6155937886814224; validation accuracy : 0.9288702928870293\n",
      "Epoch 32:\t train loss : 0.567865676780858; train accuracy : 0.983543790080238; \n",
      " validation loss : 0.6213797926194629; validation accuracy : 0.9246861924686193\n",
      "Epoch 33:\t train loss : 0.5697568005887689; train accuracy : 0.9814777409461259; \n",
      " validation loss : 0.6345442962365537; validation accuracy : 0.9163179916317992\n",
      "Epoch 34:\t train loss : 0.573711574233968; train accuracy : 0.9774621270795254; \n",
      " validation loss : 0.6065256033386971; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.5819034271604903; train accuracy : 0.968837944174231; \n",
      " validation loss : 0.6003601166137644; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.5726241107446906; train accuracy : 0.9783760339539639; \n",
      " validation loss : 0.601819121138213; validation accuracy : 0.9497907949790795\n",
      "Epoch 37:\t train loss : 0.5669889860881798; train accuracy : 0.9843551535053751; \n",
      " validation loss : 0.6060062149955433; validation accuracy : 0.9456066945606695\n",
      "Epoch 38:\t train loss : 0.5621234933778939; train accuracy : 0.9892809566591282; \n",
      " validation loss : 0.6211970066774231; validation accuracy : 0.9288702928870293\n",
      "Epoch 39:\t train loss : 0.5619625766098472; train accuracy : 0.9894048762353232; \n",
      " validation loss : 0.5821715468591969; validation accuracy : 0.9707112970711297\n",
      "Epoch 40:\t train loss : 0.5628861682573317; train accuracy : 0.9884290095727872; \n",
      " validation loss : 0.605847967736611; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5761037847638779; train accuracy : 0.9749409833018371; \n",
      " validation loss : 0.6342861623794777; validation accuracy : 0.9163179916317992\n",
      "Epoch 42:\t train loss : 0.5720300608536479; train accuracy : 0.9791136652312649; \n",
      " validation loss : 0.6294698609268938; validation accuracy : 0.9205020920502092\n",
      "Epoch 43:\t train loss : 0.5694600981154962; train accuracy : 0.9817683323523033; \n",
      " validation loss : 0.6179015250503946; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.56115953688771; train accuracy : 0.9902413333746398; \n",
      " validation loss : 0.6175016673225683; validation accuracy : 0.9330543933054394\n",
      "Epoch 45:\t train loss : 0.57877337895144; train accuracy : 0.9720325908485393; \n",
      " validation loss : 0.655116577151293; validation accuracy : 0.895397489539749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:\t train loss : 0.5857207084612744; train accuracy : 0.9654729080826544; \n",
      " validation loss : 0.6051418887555197; validation accuracy : 0.9456066945606695\n",
      "Epoch 47:\t train loss : 0.5667246668992302; train accuracy : 0.9845661265838471; \n",
      " validation loss : 0.6034501083448135; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.5663312871866324; train accuracy : 0.9850153350475541; \n",
      " validation loss : 0.5781284200930265; validation accuracy : 0.9748953974895398\n",
      "Epoch 49:\t train loss : 0.5759905649172716; train accuracy : 0.9752272375228477; \n",
      " validation loss : 0.648327802844974; validation accuracy : 0.8870292887029289\n",
      "Epoch 50:\t train loss : 0.5914971340436954; train accuracy : 0.9588624182905294; \n",
      " validation loss : 0.6092156859137571; validation accuracy : 0.9414225941422594\n",
      "Epoch 51:\t train loss : 0.5704779144934508; train accuracy : 0.980653056166548; \n",
      " validation loss : 0.6096466315219857; validation accuracy : 0.9414225941422594\n",
      "Epoch 52:\t train loss : 0.5629673408695534; train accuracy : 0.9885064593079091; \n",
      " validation loss : 0.5841374028226434; validation accuracy : 0.9665271966527197\n",
      "Epoch 53:\t train loss : 0.5693950616076023; train accuracy : 0.9815979429350352; \n",
      " validation loss : 0.5939882358512464; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.564743250374514; train accuracy : 0.9864190340469036; \n",
      " validation loss : 0.5904559904762576; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5612566901545846; train accuracy : 0.9900244741162986; \n",
      " validation loss : 0.5868707316779875; validation accuracy : 0.9581589958158996\n",
      "Epoch 56:\t train loss : 0.5597509991652365; train accuracy : 0.9916295424269649; \n",
      " validation loss : 0.6002219069100484; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5596614484200954; train accuracy : 0.9915926763530468; \n",
      " validation loss : 0.6000511321446568; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.5636308304023249; train accuracy : 0.9874878403915859; \n",
      " validation loss : 0.5884065195270363; validation accuracy : 0.9623430962343096\n",
      "Epoch 59:\t train loss : 0.5616312714638437; train accuracy : 0.9896062455466402; \n",
      " validation loss : 0.6053088823814214; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5615082000907909; train accuracy : 0.989724278942966; \n",
      " validation loss : 0.5930126260006863; validation accuracy : 0.9539748953974896\n",
      "Epoch 61:\t train loss : 0.5612956688221447; train accuracy : 0.9899315344341523; \n",
      " validation loss : 0.6065233456844966; validation accuracy : 0.9497907949790795\n",
      "Epoch 62:\t train loss : 0.5597729736303116; train accuracy : 0.9915830725858917; \n",
      " validation loss : 0.5879276237064028; validation accuracy : 0.9623430962343096\n",
      "Epoch 63:\t train loss : 0.5575090409796253; train accuracy : 0.993906564639549; \n",
      " validation loss : 0.6018292643931422; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5642798873228133; train accuracy : 0.9869435236531491; \n",
      " validation loss : 0.617529883065887; validation accuracy : 0.9330543933054394\n",
      "Epoch 65:\t train loss : 0.5868133965737509; train accuracy : 0.9638560674122495; \n",
      " validation loss : 0.6184793059292256; validation accuracy : 0.9330543933054394\n",
      "Epoch 66:\t train loss : 0.5702266437667565; train accuracy : 0.9811679420056384; \n",
      " validation loss : 0.5980115075375806; validation accuracy : 0.9539748953974896\n",
      "Epoch 67:\t train loss : 0.5665941382538374; train accuracy : 0.984519656742774; \n",
      " validation loss : 0.5828991422741858; validation accuracy : 0.9665271966527197\n",
      "Epoch 68:\t train loss : 0.5625131987960517; train accuracy : 0.9888664456767557; \n",
      " validation loss : 0.5940168425026022; validation accuracy : 0.9539748953974896\n",
      "Epoch 69:\t train loss : 0.5611365010450838; train accuracy : 0.9901793735865423; \n",
      " validation loss : 0.5859369372647343; validation accuracy : 0.9665271966527197\n",
      "Epoch 70:\t train loss : 0.5629454774786256; train accuracy : 0.9884946869481707; \n",
      " validation loss : 0.5911053658413852; validation accuracy : 0.9581589958158996\n",
      "Epoch 71:\t train loss : 0.5681906755954992; train accuracy : 0.9830886954366617; \n",
      " validation loss : 0.5884149483562862; validation accuracy : 0.9665271966527197\n",
      "Epoch 72:\t train loss : 0.562859866263489; train accuracy : 0.9883146937637474; \n",
      " validation loss : 0.5837982777309639; validation accuracy : 0.9707112970711297\n",
      "Epoch 73:\t train loss : 0.55860327394699; train accuracy : 0.9926577651104433; \n",
      " validation loss : 0.5671957464398019; validation accuracy : 0.9874476987447699\n",
      "Epoch 74:\t train loss : 0.558815716724264; train accuracy : 0.9924718857461508; \n",
      " validation loss : 0.5717962489766193; validation accuracy : 0.9790794979079498\n",
      "Epoch 75:\t train loss : 0.5588550103029668; train accuracy : 0.9925493354812727; \n",
      " validation loss : 0.5852282629247898; validation accuracy : 0.9665271966527197\n",
      "Epoch 76:\t train loss : 0.5629689943163808; train accuracy : 0.9883146937637474; \n",
      " validation loss : 0.5800313150990856; validation accuracy : 0.9707112970711297\n",
      "Epoch 77:\t train loss : 0.5677377910802311; train accuracy : 0.983456736577961; \n",
      " validation loss : 0.5813886767890221; validation accuracy : 0.9748953974895398\n",
      "Epoch 78:\t train loss : 0.5648704475470799; train accuracy : 0.9862139471483008; \n",
      " validation loss : 0.5897365111980415; validation accuracy : 0.9623430962343096\n",
      "Epoch 79:\t train loss : 0.5602426590575399; train accuracy : 0.9911862201431271; \n",
      " validation loss : 0.5692795312987742; validation accuracy : 0.9790794979079498\n",
      "Epoch 80:\t train loss : 0.5622384183941406; train accuracy : 0.9889711577186406; \n",
      " validation loss : 0.5863256207338691; validation accuracy : 0.9665271966527197\n",
      "Epoch 81:\t train loss : 0.5615614695280176; train accuracy : 0.9896682053347378; \n",
      " validation loss : 0.5792600521550992; validation accuracy : 0.9748953974895398\n",
      "Epoch 82:\t train loss : 0.5745870148938997; train accuracy : 0.9765017503640138; \n",
      " validation loss : 0.5971844501630843; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.562611362743199; train accuracy : 0.9887388085132749; \n",
      " validation loss : 0.6038600467719331; validation accuracy : 0.9456066945606695\n",
      "Epoch 84:\t train loss : 0.5583088626924223; train accuracy : 0.9930391276061836; \n",
      " validation loss : 0.5734388817795133; validation accuracy : 0.9790794979079498\n",
      "Epoch 85:\t train loss : 0.5626429295814058; train accuracy : 0.9884850831810155; \n",
      " validation loss : 0.584509344645884; validation accuracy : 0.9665271966527197\n",
      "Epoch 86:\t train loss : 0.5628214309768512; train accuracy : 0.9883825397317141; \n",
      " validation loss : 0.581855014909694; validation accuracy : 0.9665271966527197\n",
      "Epoch 87:\t train loss : 0.5620231426995009; train accuracy : 0.9893060503733078; \n",
      " validation loss : 0.5890663284257713; validation accuracy : 0.9623430962343096\n",
      "Epoch 88:\t train loss : 0.5621883061166353; train accuracy : 0.9890891911149664; \n",
      " validation loss : 0.5776967421821702; validation accuracy : 0.9748953974895398\n",
      "Epoch 89:\t train loss : 0.561773642639264; train accuracy : 0.9894764397905759; \n",
      " validation loss : 0.5781817540282767; validation accuracy : 0.9748953974895398\n",
      "Epoch 90:\t train loss : 0.5590471643419758; train accuracy : 0.9921871805198426; \n",
      " validation loss : 0.580440534561956; validation accuracy : 0.9707112970711297\n",
      "Epoch 91:\t train loss : 0.5578877876480834; train accuracy : 0.9933548127265405; \n",
      " validation loss : 0.598145109412576; validation accuracy : 0.9539748953974896\n",
      "Epoch 92:\t train loss : 0.5594036649049687; train accuracy : 0.9918869853465101; \n",
      " validation loss : 0.6013975244588606; validation accuracy : 0.9497907949790795\n",
      "Epoch 93:\t train loss : 0.562137676228633; train accuracy : 0.9890272313268689; \n",
      " validation loss : 0.5821973467210587; validation accuracy : 0.9665271966527197\n",
      "Epoch 94:\t train loss : 0.5642412992421381; train accuracy : 0.9869825583196505; \n",
      " validation loss : 0.5914027331357637; validation accuracy : 0.9581589958158996\n",
      "Epoch 95:\t train loss : 0.5617263527723774; train accuracy : 0.9894978159174695; \n",
      " validation loss : 0.5937795304887188; validation accuracy : 0.9581589958158996\n",
      "Epoch 96:\t train loss : 0.5607063298699853; train accuracy : 0.9904581926329812; \n",
      " validation loss : 0.5972860635704517; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97:\t train loss : 0.5575247673579624; train accuracy : 0.9938350010842962; \n",
      " validation loss : 0.584747635136465; validation accuracy : 0.9665271966527197\n",
      "Epoch 98:\t train loss : 0.5701375279228168; train accuracy : 0.9809355928002726; \n",
      " validation loss : 0.6111046054642731; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5661319915534081; train accuracy : 0.9851916106446916; \n",
      " validation loss : 0.5898780718613817; validation accuracy : 0.9623430962343096\n",
      "Epoch 100:\t train loss : 0.5613281730153289; train accuracy : 0.9900089841692742; \n",
      " validation loss : 0.5690482309462073; validation accuracy : 0.9832635983263598\n",
      "Epoch 101:\t train loss : 0.5554156577843683; train accuracy : 0.9959416338796121; \n",
      " validation loss : 0.5937805565808078; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.5574006298646689; train accuracy : 0.993865980978345; \n",
      " validation loss : 0.5753473444244742; validation accuracy : 0.9748953974895398\n",
      "Epoch 103:\t train loss : 0.5603416421727085; train accuracy : 0.9909538709377614; \n",
      " validation loss : 0.592608342552583; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.557812399741247; train accuracy : 0.9934942222497599; \n",
      " validation loss : 0.5869784219487525; validation accuracy : 0.9665271966527197\n",
      "Epoch 105:\t train loss : 0.5619105247993273; train accuracy : 0.9892964466061526; \n",
      " validation loss : 0.5763405942578597; validation accuracy : 0.9748953974895398\n",
      "Epoch 106:\t train loss : 0.5566104231707635; train accuracy : 0.9947489079587347; \n",
      " validation loss : 0.5927342335409533; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5568128754238797; train accuracy : 0.9944855788593203; \n",
      " validation loss : 0.577733039357465; validation accuracy : 0.9748953974895398\n",
      "Epoch 108:\t train loss : 0.5589761722295209; train accuracy : 0.9923324762229313; \n",
      " validation loss : 0.5874764130939925; validation accuracy : 0.9623430962343096\n",
      "Epoch 109:\t train loss : 0.5592597548643489; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.5724490370557829; validation accuracy : 0.9790794979079498\n",
      "Epoch 110:\t train loss : 0.560070488615233; train accuracy : 0.9911958239102823; \n",
      " validation loss : 0.5944885100560843; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.56146202987703; train accuracy : 0.9899005545401035; \n",
      " validation loss : 0.5766837206289155; validation accuracy : 0.9748953974895398\n",
      "Epoch 112:\t train loss : 0.5564809883945565; train accuracy : 0.9948263576938566; \n",
      " validation loss : 0.5783228248074179; validation accuracy : 0.9748953974895398\n",
      "Epoch 113:\t train loss : 0.5575078707282047; train accuracy : 0.9938969608723938; \n",
      " validation loss : 0.5724668302369341; validation accuracy : 0.9790794979079498\n",
      "Epoch 114:\t train loss : 0.5579189740961158; train accuracy : 0.9934477524086868; \n",
      " validation loss : 0.5935820204317609; validation accuracy : 0.9581589958158996\n",
      "Epoch 115:\t train loss : 0.5610335897077817; train accuracy : 0.9902354471947706; \n",
      " validation loss : 0.576276321794143; validation accuracy : 0.9707112970711297\n",
      "Epoch 116:\t train loss : 0.5581715200534495; train accuracy : 0.9931844233092723; \n",
      " validation loss : 0.6010599702770819; validation accuracy : 0.9497907949790795\n",
      "Epoch 117:\t train loss : 0.5563884751720335; train accuracy : 0.9950277270051736; \n",
      " validation loss : 0.5857570151561556; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5580788797240104; train accuracy : 0.9932618730443942; \n",
      " validation loss : 0.6115455790459408; validation accuracy : 0.9372384937238494\n",
      "Epoch 119:\t train loss : 0.5582788043487271; train accuracy : 0.9929830539979553; \n",
      " validation loss : 0.5977688411120976; validation accuracy : 0.9539748953974896\n",
      "Epoch 120:\t train loss : 0.5576962433952606; train accuracy : 0.9936646116670281; \n",
      " validation loss : 0.5844041292996041; validation accuracy : 0.9623430962343096\n",
      "Epoch 121:\t train loss : 0.5578852858379528; train accuracy : 0.9934263762817931; \n",
      " validation loss : 0.564218482076455; validation accuracy : 0.9832635983263598\n",
      "Epoch 122:\t train loss : 0.5558366925157358; train accuracy : 0.9955388952569783; \n",
      " validation loss : 0.5862069694139903; validation accuracy : 0.9665271966527197\n",
      "Epoch 123:\t train loss : 0.5650758458317974; train accuracy : 0.9861925710214071; \n",
      " validation loss : 0.6062389882990056; validation accuracy : 0.9456066945606695\n",
      "Epoch 124:\t train loss : 0.5604008302706772; train accuracy : 0.9908454413085908; \n",
      " validation loss : 0.6052545383186784; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5574058128567047; train accuracy : 0.9939434307134669; \n",
      " validation loss : 0.5683754278282626; validation accuracy : 0.9832635983263598\n",
      "Epoch 126:\t train loss : 0.5624109246197988; train accuracy : 0.9889476129991636; \n",
      " validation loss : 0.5968787808403007; validation accuracy : 0.9539748953974896\n",
      "Epoch 127:\t train loss : 0.5629191288774954; train accuracy : 0.9883360698906409; \n",
      " validation loss : 0.5813772162012396; validation accuracy : 0.9707112970711297\n",
      "Epoch 128:\t train loss : 0.5595396628147206; train accuracy : 0.9917069921620868; \n",
      " validation loss : 0.5731153288514254; validation accuracy : 0.9790794979079498\n",
      "Epoch 129:\t train loss : 0.5644051679448627; train accuracy : 0.9867966789553579; \n",
      " validation loss : 0.5887223744141662; validation accuracy : 0.9623430962343096\n",
      "Epoch 130:\t train loss : 0.558378747617595; train accuracy : 0.992890114315809; \n",
      " validation loss : 0.606474115660185; validation accuracy : 0.9456066945606695\n",
      "Epoch 131:\t train loss : 0.5578753415059636; train accuracy : 0.9934787323027355; \n",
      " validation loss : 0.5762410302989085; validation accuracy : 0.9707112970711297\n",
      "Epoch 132:\t train loss : 0.5561612472357208; train accuracy : 0.9952136063694662; \n",
      " validation loss : 0.588243024263823; validation accuracy : 0.9623430962343096\n",
      "Epoch 133:\t train loss : 0.558091101593459; train accuracy : 0.9932463830973698; \n",
      " validation loss : 0.5914985642546269; validation accuracy : 0.9623430962343096\n",
      "Epoch 134:\t train loss : 0.5562649996302252; train accuracy : 0.9951516465813687; \n",
      " validation loss : 0.5777333414909152; validation accuracy : 0.9748953974895398\n",
      "Epoch 135:\t train loss : 0.5553398820757001; train accuracy : 0.9960500635087828; \n",
      " validation loss : 0.584741676177752; validation accuracy : 0.9665271966527197\n",
      "Epoch 136:\t train loss : 0.558119048373597; train accuracy : 0.9932618730443942; \n",
      " validation loss : 0.5817105926599025; validation accuracy : 0.9707112970711297\n",
      "Epoch 137:\t train loss : 0.5579982606875936; train accuracy : 0.9933857926205892; \n",
      " validation loss : 0.5855152117404477; validation accuracy : 0.9665271966527197\n",
      "Epoch 138:\t train loss : 0.555251609740797; train accuracy : 0.9962049629790266; \n",
      " validation loss : 0.5960483333971719; validation accuracy : 0.9539748953974896\n",
      "Epoch 139:\t train loss : 0.5582816825607586; train accuracy : 0.9930642213203631; \n",
      " validation loss : 0.5908127580739758; validation accuracy : 0.9623430962343096\n",
      "Epoch 140:\t train loss : 0.5607048099996105; train accuracy : 0.9905356423681031; \n",
      " validation loss : 0.5866902745265834; validation accuracy : 0.9623430962343096\n",
      "Epoch 141:\t train loss : 0.5591472130557432; train accuracy : 0.9921775767526875; \n",
      " validation loss : 0.5790345993505286; validation accuracy : 0.9707112970711297\n",
      "Epoch 142:\t train loss : 0.5553954689901566; train accuracy : 0.9959881037206852; \n",
      " validation loss : 0.5765042834185522; validation accuracy : 0.9748953974895398\n",
      "Epoch 143:\t train loss : 0.5665138553600234; train accuracy : 0.9847829858421884; \n",
      " validation loss : 0.5912176430555993; validation accuracy : 0.9623430962343096\n",
      "Epoch 144:\t train loss : 0.5639957413872456; train accuracy : 0.9872982434400074; \n",
      " validation loss : 0.6011604733104828; validation accuracy : 0.9497907949790795\n",
      "Epoch 145:\t train loss : 0.5579751822073825; train accuracy : 0.9933489265466712; \n",
      " validation loss : 0.5989384935634048; validation accuracy : 0.9539748953974896\n",
      "Epoch 146:\t train loss : 0.5576176020252066; train accuracy : 0.9937361752222807; \n",
      " validation loss : 0.5704810724670719; validation accuracy : 0.9832635983263598\n",
      "Epoch 147:\t train loss : 0.5569953700220769; train accuracy : 0.994392639177174; \n",
      " validation loss : 0.594263387384263; validation accuracy : 0.9581589958158996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148:\t train loss : 0.5589119244522675; train accuracy : 0.9923014963288825; \n",
      " validation loss : 0.5911150400290239; validation accuracy : 0.9581589958158996\n",
      "Epoch 149:\t train loss : 0.5594930929017398; train accuracy : 0.991877381579355; \n",
      " validation loss : 0.5905393966968409; validation accuracy : 0.9581589958158996\n",
      "Epoch 150:\t train loss : 0.5583364504250843; train accuracy : 0.9930391276061836; \n",
      " validation loss : 0.5910859587496128; validation accuracy : 0.9623430962343096\n",
      "Epoch 151:\t train loss : 0.5778978049781177; train accuracy : 0.9731478670342948; \n",
      " validation loss : 0.5792684221625936; validation accuracy : 0.9748953974895398\n",
      "Epoch 152:\t train loss : 0.5703952834720043; train accuracy : 0.9806412838068094; \n",
      " validation loss : 0.5875248389687527; validation accuracy : 0.9623430962343096\n",
      "Epoch 153:\t train loss : 0.5616640800894727; train accuracy : 0.989563493292853; \n",
      " validation loss : 0.6083567077172661; validation accuracy : 0.9414225941422594\n",
      "Epoch 154:\t train loss : 0.5586251978750613; train accuracy : 0.9925744291954521; \n",
      " validation loss : 0.5808016696617075; validation accuracy : 0.9707112970711297\n",
      "Epoch 155:\t train loss : 0.5551452346428332; train accuracy : 0.9962300566932061; \n",
      " validation loss : 0.5773356259296895; validation accuracy : 0.9748953974895398\n",
      "Epoch 156:\t train loss : 0.5560050624914062; train accuracy : 0.9953065460516125; \n",
      " validation loss : 0.5923812481861019; validation accuracy : 0.9581589958158996\n",
      "Epoch 157:\t train loss : 0.5558356987232095; train accuracy : 0.9955388952569783; \n",
      " validation loss : 0.5838360008503778; validation accuracy : 0.9665271966527197\n",
      "Epoch 158:\t train loss : 0.5644378021955392; train accuracy : 0.9867560952941541; \n",
      " validation loss : 0.5985710605078419; validation accuracy : 0.9497907949790795\n",
      "Epoch 159:\t train loss : 0.5578418023414218; train accuracy : 0.9935097121967843; \n",
      " validation loss : 0.5864167110216524; validation accuracy : 0.9665271966527197\n",
      "Epoch 160:\t train loss : 0.55906708554166; train accuracy : 0.9922705164348338; \n",
      " validation loss : 0.5776179152607765; validation accuracy : 0.9748953974895398\n",
      "Epoch 161:\t train loss : 0.556483151176926; train accuracy : 0.9948883174819542; \n",
      " validation loss : 0.5851894248664868; validation accuracy : 0.9665271966527197\n",
      "Epoch 162:\t train loss : 0.5573322720836861; train accuracy : 0.9939840143746709; \n",
      " validation loss : 0.5802925321956798; validation accuracy : 0.9707112970711297\n",
      "Epoch 163:\t train loss : 0.5638215919314196; train accuracy : 0.9874531429102512; \n",
      " validation loss : 0.5701267771173546; validation accuracy : 0.9790794979079498\n",
      "Epoch 164:\t train loss : 0.5589060697578265; train accuracy : 0.9923981535983147; \n",
      " validation loss : 0.5822000511362807; validation accuracy : 0.9707112970711297\n",
      "Epoch 165:\t train loss : 0.5577139097340988; train accuracy : 0.9935967656990613; \n",
      " validation loss : 0.5955211004312995; validation accuracy : 0.9539748953974896\n",
      "Epoch 166:\t train loss : 0.5553035217264398; train accuracy : 0.9960655534558072; \n",
      " validation loss : 0.5801306301812444; validation accuracy : 0.9665271966527197\n",
      "Epoch 167:\t train loss : 0.5571198920647316; train accuracy : 0.9942532296539546; \n",
      " validation loss : 0.5874563507325669; validation accuracy : 0.9623430962343096\n",
      "Epoch 168:\t train loss : 0.5570444730424784; train accuracy : 0.9943034170823135; \n",
      " validation loss : 0.5798973495135843; validation accuracy : 0.9707112970711297\n",
      "Epoch 169:\t train loss : 0.5581420932512315; train accuracy : 0.9931320672883298; \n",
      " validation loss : 0.5816193609125818; validation accuracy : 0.9707112970711297\n",
      "Epoch 170:\t train loss : 0.5594469842777604; train accuracy : 0.9919895287958115; \n",
      " validation loss : 0.5994830372120872; validation accuracy : 0.9539748953974896\n",
      "Epoch 171:\t train loss : 0.5572030215928658; train accuracy : 0.994268719600979; \n",
      " validation loss : 0.5825621532076032; validation accuracy : 0.9707112970711297\n",
      "Early stopping at epoch 171\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5578852858379528; Train accuracy : 0.9934263762817931; \n",
      " Validation loss : 0.564218482076455; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 88 ! ---\n",
      "Epoch 1:\t train loss : 0.9771234210979549; train accuracy : 0.5525896093435361; \n",
      " validation loss : 0.8679135773239414; validation accuracy : 0.6778242677824268\n",
      "Epoch 2:\t train loss : 0.7751031932911576; train accuracy : 0.7731618079866167; \n",
      " validation loss : 0.7216189052822942; validation accuracy : 0.8326359832635983\n",
      "Epoch 3:\t train loss : 0.7065558166464047; train accuracy : 0.8428746243687847; \n",
      " validation loss : 0.6890771000315477; validation accuracy : 0.8577405857740585\n",
      "Epoch 4:\t train loss : 0.6835111819761408; train accuracy : 0.8667040490721521; \n",
      " validation loss : 0.7011951468273863; validation accuracy : 0.8451882845188284\n",
      "Epoch 5:\t train loss : 0.6676918753336235; train accuracy : 0.8823761578735401; \n",
      " validation loss : 0.6672973888152504; validation accuracy : 0.8870292887029289\n",
      "Epoch 6:\t train loss : 0.6527440462827186; train accuracy : 0.8979221785061495; \n",
      " validation loss : 0.6381035805890378; validation accuracy : 0.9121338912133892\n",
      "Epoch 7:\t train loss : 0.648218323057027; train accuracy : 0.9023411505932649; \n",
      " validation loss : 0.6709546706526527; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6273957115599528; train accuracy : 0.9232755041977756; \n",
      " validation loss : 0.6271110843389265; validation accuracy : 0.9246861924686193\n",
      "Epoch 9:\t train loss : 0.630354715844288; train accuracy : 0.9205455559341987; \n",
      " validation loss : 0.6510506339068299; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.6208414527151908; train accuracy : 0.9300216859258341; \n",
      " validation loss : 0.630745531359456; validation accuracy : 0.9205020920502092\n",
      "Epoch 11:\t train loss : 0.6058458055198811; train accuracy : 0.945496143003191; \n",
      " validation loss : 0.6196973276798557; validation accuracy : 0.9246861924686193\n",
      "Epoch 12:\t train loss : 0.5999014611485046; train accuracy : 0.9515313361628304; \n",
      " validation loss : 0.6255793458001321; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.5960473972769116; train accuracy : 0.9550822516186994; \n",
      " validation loss : 0.6271059241053645; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5952080227930666; train accuracy : 0.9560255893924843; \n",
      " validation loss : 0.6198936151755455; validation accuracy : 0.9288702928870293\n",
      "Epoch 15:\t train loss : 0.5926034749251324; train accuracy : 0.9584575110753121; \n",
      " validation loss : 0.6041917502171014; validation accuracy : 0.9456066945606695\n",
      "Epoch 16:\t train loss : 0.5869511884243577; train accuracy : 0.9646225099910158; \n",
      " validation loss : 0.5978605625246463; validation accuracy : 0.9539748953974896\n",
      "Epoch 17:\t train loss : 0.5855084284874325; train accuracy : 0.9657628798909508; \n",
      " validation loss : 0.6060389126667249; validation accuracy : 0.9414225941422594\n",
      "Epoch 18:\t train loss : 0.587946232366052; train accuracy : 0.9631199851296508; \n",
      " validation loss : 0.6067059483895451; validation accuracy : 0.9372384937238494\n",
      "Epoch 19:\t train loss : 0.5926470471573194; train accuracy : 0.9584147588215248; \n",
      " validation loss : 0.6021708774567612; validation accuracy : 0.9497907949790795\n",
      "Epoch 20:\t train loss : 0.5896675260814226; train accuracy : 0.9614470708510177; \n",
      " validation loss : 0.6203985797483743; validation accuracy : 0.9288702928870293\n",
      "Epoch 21:\t train loss : 0.5826192619204071; train accuracy : 0.968485392979956; \n",
      " validation loss : 0.6120800268644039; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.579162456011572; train accuracy : 0.9720539669754329; \n",
      " validation loss : 0.605185042187674; validation accuracy : 0.9456066945606695\n",
      "Epoch 23:\t train loss : 0.5812472843087986; train accuracy : 0.9699200718733542; \n",
      " validation loss : 0.615304721274629; validation accuracy : 0.9330543933054394\n",
      "Epoch 24:\t train loss : 0.57745018175663; train accuracy : 0.9738604045974163; \n",
      " validation loss : 0.597487215896775; validation accuracy : 0.9456066945606695\n",
      "Epoch 25:\t train loss : 0.5801094660275453; train accuracy : 0.9709092598903312; \n",
      " validation loss : 0.5814126890173928; validation accuracy : 0.9707112970711297\n",
      "Epoch 26:\t train loss : 0.5849469614590185; train accuracy : 0.9661132624926423; \n",
      " validation loss : 0.640302043752885; validation accuracy : 0.9121338912133892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:\t train loss : 0.5878325854239327; train accuracy : 0.9629245019982031; \n",
      " validation loss : 0.6122840690322225; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.576022666637947; train accuracy : 0.9751615601474642; \n",
      " validation loss : 0.6227755317865354; validation accuracy : 0.9205020920502092\n",
      "Epoch 29:\t train loss : 0.5745569582828197; train accuracy : 0.9766352737073639; \n",
      " validation loss : 0.6046368255460017; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5752355701964819; train accuracy : 0.9761182192756901; \n",
      " validation loss : 0.5976161488659854; validation accuracy : 0.9497907949790795\n",
      "Epoch 31:\t train loss : 0.5660502283584669; train accuracy : 0.9854276774373432; \n",
      " validation loss : 0.5962450551591467; validation accuracy : 0.9497907949790795\n",
      "Epoch 32:\t train loss : 0.5761129991763749; train accuracy : 0.9750841104123424; \n",
      " validation loss : 0.6210896668633863; validation accuracy : 0.9288702928870293\n",
      "Epoch 33:\t train loss : 0.5936355660976059; train accuracy : 0.9568561603519316; \n",
      " validation loss : 0.6306924287282482; validation accuracy : 0.9205020920502092\n",
      "Epoch 34:\t train loss : 0.5763146430080222; train accuracy : 0.9746850893769943; \n",
      " validation loss : 0.6073063466945696; validation accuracy : 0.9456066945606695\n",
      "Epoch 35:\t train loss : 0.5747053508614747; train accuracy : 0.9764376219833328; \n",
      " validation loss : 0.5998889766415655; validation accuracy : 0.9497907949790795\n",
      "Epoch 36:\t train loss : 0.571114306909223; train accuracy : 0.9801205117878496; \n",
      " validation loss : 0.598283868467046; validation accuracy : 0.9539748953974896\n",
      "Epoch 37:\t train loss : 0.568693226158512; train accuracy : 0.9824071377675888; \n",
      " validation loss : 0.5880695267405666; validation accuracy : 0.9623430962343096\n",
      "Epoch 38:\t train loss : 0.5679903659901101; train accuracy : 0.983104185383686; \n",
      " validation loss : 0.5988905449180483; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5640638669517755; train accuracy : 0.9874413705505127; \n",
      " validation loss : 0.5978100882997714; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5755335570377274; train accuracy : 0.9754617553207968; \n",
      " validation loss : 0.5877488345441495; validation accuracy : 0.9665271966527197\n",
      "Epoch 41:\t train loss : 0.568168990532549; train accuracy : 0.9831624275844977; \n",
      " validation loss : 0.5926761318442605; validation accuracy : 0.9581589958158996\n",
      "Epoch 42:\t train loss : 0.5696757365977034; train accuracy : 0.9815994919297376; \n",
      " validation loss : 0.6075489324746239; validation accuracy : 0.9456066945606695\n",
      "Epoch 43:\t train loss : 0.5797969464544225; train accuracy : 0.9711902475293535; \n",
      " validation loss : 0.6010183720208501; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5703235433212828; train accuracy : 0.98086402924502; \n",
      " validation loss : 0.6096971261373877; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5648163010007353; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.6187839865888642; validation accuracy : 0.9246861924686193\n",
      "Epoch 46:\t train loss : 0.5665710441152336; train accuracy : 0.984643576318969; \n",
      " validation loss : 0.5855099856840806; validation accuracy : 0.9665271966527197\n",
      "Epoch 47:\t train loss : 0.5639665730402266; train accuracy : 0.9873890145295703; \n",
      " validation loss : 0.5884980686109871; validation accuracy : 0.9623430962343096\n",
      "Epoch 48:\t train loss : 0.5667526717892536; train accuracy : 0.9845041667957496; \n",
      " validation loss : 0.6001175712157527; validation accuracy : 0.9497907949790795\n",
      "Epoch 49:\t train loss : 0.5731645636185106; train accuracy : 0.97756033334366; \n",
      " validation loss : 0.5975964108366947; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5799622733514929; train accuracy : 0.9712079060689612; \n",
      " validation loss : 0.6018538617210415; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5673203178865599; train accuracy : 0.9840004337185166; \n",
      " validation loss : 0.6166451670685582; validation accuracy : 0.9330543933054394\n",
      "Epoch 52:\t train loss : 0.572109902692195; train accuracy : 0.9788230738250875; \n",
      " validation loss : 0.5917570593726469; validation accuracy : 0.9581589958158996\n",
      "Epoch 53:\t train loss : 0.5761007634346713; train accuracy : 0.975018433036959; \n",
      " validation loss : 0.597246104070475; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.5723852281539521; train accuracy : 0.9786409120480808; \n",
      " validation loss : 0.6066728719715533; validation accuracy : 0.9456066945606695\n",
      "Epoch 55:\t train loss : 0.5736292098904041; train accuracy : 0.9771966293875275; \n",
      " validation loss : 0.6096863198072865; validation accuracy : 0.9414225941422594\n",
      "Epoch 56:\t train loss : 0.5717198985825959; train accuracy : 0.9794367855261935; \n",
      " validation loss : 0.6223959235981753; validation accuracy : 0.9288702928870293\n",
      "Epoch 57:\t train loss : 0.56651922247036; train accuracy : 0.9846376901390997; \n",
      " validation loss : 0.5877693793984986; validation accuracy : 0.9665271966527197\n",
      "Epoch 58:\t train loss : 0.5653905482570178; train accuracy : 0.9857684562718796; \n",
      " validation loss : 0.5974024008412377; validation accuracy : 0.9539748953974896\n",
      "Epoch 59:\t train loss : 0.5671689736800244; train accuracy : 0.9840180922581245; \n",
      " validation loss : 0.6218241543427274; validation accuracy : 0.9288702928870293\n",
      "Epoch 60:\t train loss : 0.5709318206173459; train accuracy : 0.9803875584745501; \n",
      " validation loss : 0.6032493665857501; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.564486176473571; train accuracy : 0.9866823631463181; \n",
      " validation loss : 0.5997415325244982; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.56316897141247; train accuracy : 0.9881015520926918; \n",
      " validation loss : 0.6000695449764255; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5707578476421217; train accuracy : 0.9806103039127606; \n",
      " validation loss : 0.6148211333392098; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.5659080819601918; train accuracy : 0.9852417980730506; \n",
      " validation loss : 0.6476316876680507; validation accuracy : 0.895397489539749\n",
      "Epoch 65:\t train loss : 0.570414524616226; train accuracy : 0.9808677468323058; \n",
      " validation loss : 0.6129427227093716; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.5692910142765997; train accuracy : 0.9818436134948418; \n",
      " validation loss : 0.610180277668193; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5643923981309062; train accuracy : 0.9868121689023823; \n",
      " validation loss : 0.6149207422343267; validation accuracy : 0.9330543933054394\n",
      "Epoch 68:\t train loss : 0.5655178138498134; train accuracy : 0.9857433625577; \n",
      " validation loss : 0.5986699800356411; validation accuracy : 0.9539748953974896\n",
      "Epoch 69:\t train loss : 0.5685493834256594; train accuracy : 0.9828135939775086; \n",
      " validation loss : 0.615433468533235; validation accuracy : 0.9372384937238494\n",
      "Epoch 70:\t train loss : 0.566807746226142; train accuracy : 0.9844245484680443; \n",
      " validation loss : 0.5925589778587296; validation accuracy : 0.9581589958158996\n",
      "Epoch 71:\t train loss : 0.5663832462326598; train accuracy : 0.9847247436413767; \n",
      " validation loss : 0.5857312150217788; validation accuracy : 0.9665271966527197\n",
      "Epoch 72:\t train loss : 0.5654772235799529; train accuracy : 0.9858149261129527; \n",
      " validation loss : 0.6093046510993728; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5732524785151694; train accuracy : 0.9777505498931194; \n",
      " validation loss : 0.6337088870685508; validation accuracy : 0.9163179916317992\n",
      "Epoch 74:\t train loss : 0.5662952090354192; train accuracy : 0.9849939589206606; \n",
      " validation loss : 0.5933365886239546; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.5673142217966823; train accuracy : 0.9840026023111001; \n",
      " validation loss : 0.6070611126981663; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 75\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5801094660275453; Train accuracy : 0.9709092598903312; \n",
      " Validation loss : 0.5814126890173928; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 89 ! ---\n",
      "Epoch 1:\t train loss : 0.954929705167133; train accuracy : 0.5743359459710647; \n",
      " validation loss : 0.8277850690601113; validation accuracy : 0.7112970711297071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\t train loss : 0.7651401656564502; train accuracy : 0.7832361597323337; \n",
      " validation loss : 0.7128678427834935; validation accuracy : 0.8284518828451883\n",
      "Epoch 3:\t train loss : 0.710858990959683; train accuracy : 0.8387564670528826; \n",
      " validation loss : 0.701093870057472; validation accuracy : 0.8451882845188284\n",
      "Epoch 4:\t train loss : 0.6883354515465316; train accuracy : 0.8619721800551442; \n",
      " validation loss : 0.6698355463641826; validation accuracy : 0.8870292887029289\n",
      "Epoch 5:\t train loss : 0.6705114948280371; train accuracy : 0.8787226989683695; \n",
      " validation loss : 0.6618523305660358; validation accuracy : 0.8870292887029289\n",
      "Epoch 6:\t train loss : 0.663724937554972; train accuracy : 0.8864676724805601; \n",
      " validation loss : 0.6725501712992533; validation accuracy : 0.8744769874476988\n",
      "Epoch 7:\t train loss : 0.6574102627275797; train accuracy : 0.8923228724557762; \n",
      " validation loss : 0.6428391390667431; validation accuracy : 0.9079497907949791\n",
      "Epoch 8:\t train loss : 0.6478639466161922; train accuracy : 0.9021670435887109; \n",
      " validation loss : 0.6394205019323319; validation accuracy : 0.9037656903765691\n",
      "Epoch 9:\t train loss : 0.6331611091398215; train accuracy : 0.9175346200315995; \n",
      " validation loss : 0.654937937372477; validation accuracy : 0.895397489539749\n",
      "Epoch 10:\t train loss : 0.6174522568059251; train accuracy : 0.9336522197094086; \n",
      " validation loss : 0.6259064605771935; validation accuracy : 0.9246861924686193\n",
      "Epoch 11:\t train loss : 0.6058187310498486; train accuracy : 0.9457461507481645; \n",
      " validation loss : 0.6494362467484374; validation accuracy : 0.899581589958159\n",
      "Epoch 12:\t train loss : 0.601263933150129; train accuracy : 0.9498141206357075; \n",
      " validation loss : 0.6320519096480526; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.5999094298301515; train accuracy : 0.9512487995291056; \n",
      " validation loss : 0.6715655811102017; validation accuracy : 0.8744769874476988\n",
      "Epoch 14:\t train loss : 0.5942342439287153; train accuracy : 0.9570420397162241; \n",
      " validation loss : 0.6307200448717278; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5921302080455553; train accuracy : 0.9592437807862697; \n",
      " validation loss : 0.6289572421190359; validation accuracy : 0.9163179916317992\n",
      "Epoch 16:\t train loss : 0.5912726401871937; train accuracy : 0.9596539545834754; \n",
      " validation loss : 0.691740865266641; validation accuracy : 0.8577405857740585\n",
      "Epoch 17:\t train loss : 0.5962178594637698; train accuracy : 0.9552857895225998; \n",
      " validation loss : 0.6475919641070225; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.595893072591829; train accuracy : 0.9551079649307599; \n",
      " validation loss : 0.6375459021360049; validation accuracy : 0.9079497907949791\n",
      "Epoch 19:\t train loss : 0.591028535298777; train accuracy : 0.9604461104743022; \n",
      " validation loss : 0.6093555624248617; validation accuracy : 0.9414225941422594\n",
      "Epoch 20:\t train loss : 0.5894022336171058; train accuracy : 0.9616100250937142; \n",
      " validation loss : 0.6309679072873824; validation accuracy : 0.9163179916317992\n",
      "Epoch 21:\t train loss : 0.5868901588684625; train accuracy : 0.9642005638340717; \n",
      " validation loss : 0.6320656500749545; validation accuracy : 0.9163179916317992\n",
      "Epoch 22:\t train loss : 0.5787399793989697; train accuracy : 0.9727200346974814; \n",
      " validation loss : 0.6279977119495208; validation accuracy : 0.9205020920502092\n",
      "Epoch 23:\t train loss : 0.5793519812633309; train accuracy : 0.971902785092475; \n",
      " validation loss : 0.6196298240311331; validation accuracy : 0.9288702928870293\n",
      "Epoch 24:\t train loss : 0.5783258863509179; train accuracy : 0.9730239474580997; \n",
      " validation loss : 0.6066893938580545; validation accuracy : 0.9497907949790795\n",
      "Epoch 25:\t train loss : 0.5855638960508347; train accuracy : 0.9657628798909508; \n",
      " validation loss : 0.6341249898865303; validation accuracy : 0.9163179916317992\n",
      "Epoch 26:\t train loss : 0.5818339310071459; train accuracy : 0.9693992998543944; \n",
      " validation loss : 0.6217533786194227; validation accuracy : 0.9246861924686193\n",
      "Epoch 27:\t train loss : 0.5826365844569538; train accuracy : 0.9684661854456458; \n",
      " validation loss : 0.6201876733802981; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.578975115590676; train accuracy : 0.9721837727314973; \n",
      " validation loss : 0.6117114256697715; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.5795360785888932; train accuracy : 0.9714225967347192; \n",
      " validation loss : 0.6295827483508954; validation accuracy : 0.9205020920502092\n",
      "Epoch 30:\t train loss : 0.5847555555426394; train accuracy : 0.9660977725456179; \n",
      " validation loss : 0.6284681135651886; validation accuracy : 0.9205020920502092\n",
      "Epoch 31:\t train loss : 0.5784135487263358; train accuracy : 0.9725245515660337; \n",
      " validation loss : 0.6139972697490849; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5750751820567201; train accuracy : 0.976369776015366; \n",
      " validation loss : 0.6117647658956062; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5768482308879969; train accuracy : 0.974092753802782; \n",
      " validation loss : 0.6185641937792885; validation accuracy : 0.9330543933054394\n",
      "Epoch 34:\t train loss : 0.5727912088610899; train accuracy : 0.9783524892344868; \n",
      " validation loss : 0.5963909477155952; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.570691225040896; train accuracy : 0.9803197125065832; \n",
      " validation loss : 0.5904977269669669; validation accuracy : 0.9581589958158996\n",
      "Epoch 36:\t train loss : 0.5697223509842795; train accuracy : 0.9815706806282722; \n",
      " validation loss : 0.6169025345154875; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.574225881243265; train accuracy : 0.977070541218749; \n",
      " validation loss : 0.6217100064824805; validation accuracy : 0.9246861924686193\n",
      "Epoch 38:\t train loss : 0.5717936807700432; train accuracy : 0.9795260076210539; \n",
      " validation loss : 0.5967737958805754; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.576348829628165; train accuracy : 0.9744703987112364; \n",
      " validation loss : 0.6135043858955486; validation accuracy : 0.9414225941422594\n",
      "Epoch 40:\t train loss : 0.5697712044655325; train accuracy : 0.9813944050311348; \n",
      " validation loss : 0.6080500324199911; validation accuracy : 0.9414225941422594\n",
      "Epoch 41:\t train loss : 0.5704896342038562; train accuracy : 0.9804067660088602; \n",
      " validation loss : 0.6285769482657724; validation accuracy : 0.9205020920502092\n",
      "Epoch 42:\t train loss : 0.5843250631826847; train accuracy : 0.9663750425973543; \n",
      " validation loss : 0.605328007963303; validation accuracy : 0.9414225941422594\n",
      "Epoch 43:\t train loss : 0.5750543681316352; train accuracy : 0.9760060720592335; \n",
      " validation loss : 0.6102961323544046; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5835813298267509; train accuracy : 0.9672152173239568; \n",
      " validation loss : 0.6288902323297587; validation accuracy : 0.9205020920502092\n",
      "Epoch 45:\t train loss : 0.5714106923669862; train accuracy : 0.9797679605935747; \n",
      " validation loss : 0.6110068305106109; validation accuracy : 0.9414225941422594\n",
      "Epoch 46:\t train loss : 0.5657589453506308; train accuracy : 0.9857219864308064; \n",
      " validation loss : 0.6089266482379606; validation accuracy : 0.9414225941422594\n",
      "Epoch 47:\t train loss : 0.5664358370845846; train accuracy : 0.9847712134824499; \n",
      " validation loss : 0.6084017167064775; validation accuracy : 0.9414225941422594\n",
      "Epoch 48:\t train loss : 0.5667639610052118; train accuracy : 0.9843470987329224; \n",
      " validation loss : 0.6240653949687905; validation accuracy : 0.9288702928870293\n",
      "Epoch 49:\t train loss : 0.5678180769866329; train accuracy : 0.9832745748009541; \n",
      " validation loss : 0.621308287935996; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.5665836182183754; train accuracy : 0.9846841599801729; \n",
      " validation loss : 0.6117791240212497; validation accuracy : 0.9372384937238494\n",
      "Epoch 51:\t train loss : 0.5650701591685103; train accuracy : 0.9862080609684315; \n",
      " validation loss : 0.5982207007097562; validation accuracy : 0.9539748953974896\n",
      "Epoch 52:\t train loss : 0.5666515615355654; train accuracy : 0.9845757303510022; \n",
      " validation loss : 0.6289968042116432; validation accuracy : 0.9205020920502092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53:\t train loss : 0.5704878134190818; train accuracy : 0.9804303107283373; \n",
      " validation loss : 0.5944589045929981; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.5679860098438945; train accuracy : 0.9833461383562069; \n",
      " validation loss : 0.597786907951212; validation accuracy : 0.9539748953974896\n",
      "Epoch 55:\t train loss : 0.5866797937785742; train accuracy : 0.964068589485424; \n",
      " validation loss : 0.6553024058018269; validation accuracy : 0.895397489539749\n",
      "Epoch 56:\t train loss : 0.6184208972822429; train accuracy : 0.9316908826171815; \n",
      " validation loss : 0.6295790529072453; validation accuracy : 0.9205020920502092\n",
      "Epoch 57:\t train loss : 0.577077013403547; train accuracy : 0.9737268812540661; \n",
      " validation loss : 0.6219918064599503; validation accuracy : 0.9246861924686193\n",
      "Epoch 58:\t train loss : 0.5679525095675163; train accuracy : 0.9831100715635552; \n",
      " validation loss : 0.6170801366794327; validation accuracy : 0.9330543933054394\n",
      "Epoch 59:\t train loss : 0.5659462764643698; train accuracy : 0.9851916106446916; \n",
      " validation loss : 0.6003292603297853; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5622398482400891; train accuracy : 0.9892227144583166; \n",
      " validation loss : 0.6035606414048442; validation accuracy : 0.9456066945606695\n",
      "Epoch 61:\t train loss : 0.5652633886992673; train accuracy : 0.986031785371294; \n",
      " validation loss : 0.6267347822550237; validation accuracy : 0.9205020920502092\n",
      "Epoch 62:\t train loss : 0.5792310257688762; train accuracy : 0.9718680876111404; \n",
      " validation loss : 0.624329282575396; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5721484750765685; train accuracy : 0.9789373896341275; \n",
      " validation loss : 0.6181762820957548; validation accuracy : 0.9330543933054394\n",
      "Epoch 64:\t train loss : 0.5686760790201607; train accuracy : 0.9824108553548747; \n",
      " validation loss : 0.6066904852593347; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.5679138168773189; train accuracy : 0.9830849778493758; \n",
      " validation loss : 0.6121226624377795; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.5682667097150973; train accuracy : 0.9829337959664178; \n",
      " validation loss : 0.605613424561067; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5636623399453122; train accuracy : 0.9876641159887233; \n",
      " validation loss : 0.6143442511459466; validation accuracy : 0.9372384937238494\n",
      "Epoch 68:\t train loss : 0.5613474776930766; train accuracy : 0.9899330834288547; \n",
      " validation loss : 0.6469670877847197; validation accuracy : 0.899581589958159\n",
      "Epoch 69:\t train loss : 0.5771991132680818; train accuracy : 0.9733758790544936; \n",
      " validation loss : 0.6068718658023784; validation accuracy : 0.9414225941422594\n",
      "Epoch 70:\t train loss : 0.5739039216023165; train accuracy : 0.977446637132501; \n",
      " validation loss : 0.6159330180105199; validation accuracy : 0.9330543933054394\n",
      "Epoch 71:\t train loss : 0.5699742640380466; train accuracy : 0.9811694910003408; \n",
      " validation loss : 0.6049283660480056; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5660232365063357; train accuracy : 0.9851835558722389; \n",
      " validation loss : 0.6353759293710788; validation accuracy : 0.9163179916317992\n",
      "Epoch 73:\t train loss : 0.566206174572254; train accuracy : 0.9849202267728244; \n",
      " validation loss : 0.5959140781824621; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5684839237349211; train accuracy : 0.9825716410049877; \n",
      " validation loss : 0.6149155497381803; validation accuracy : 0.9330543933054394\n",
      "Epoch 75:\t train loss : 0.5710385647582166; train accuracy : 0.9800910808885034; \n",
      " validation loss : 0.6364769115189794; validation accuracy : 0.9163179916317992\n",
      "Epoch 76:\t train loss : 0.5664015921246588; train accuracy : 0.9847343474085318; \n",
      " validation loss : 0.6163764124191712; validation accuracy : 0.9330543933054394\n",
      "Epoch 77:\t train loss : 0.5701434968683123; train accuracy : 0.9810750023234921; \n",
      " validation loss : 0.6165683165053548; validation accuracy : 0.9372384937238494\n",
      "Epoch 78:\t train loss : 0.5638437634907106; train accuracy : 0.9874996127513244; \n",
      " validation loss : 0.6006643284906211; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5625172622011713; train accuracy : 0.988798599708789; \n",
      " validation loss : 0.6070107551575633; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.5606322376248091; train accuracy : 0.9906168096905108; \n",
      " validation loss : 0.595366468088529; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.5638354124669775; train accuracy : 0.9871972489854085; \n",
      " validation loss : 0.6109266938615574; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5640754649972497; train accuracy : 0.9870578394621891; \n",
      " validation loss : 0.6136365723074549; validation accuracy : 0.9372384937238494\n",
      "Epoch 83:\t train loss : 0.5609958751743727; train accuracy : 0.9901985811208526; \n",
      " validation loss : 0.6101106956007144; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5629635288427403; train accuracy : 0.9882542829703522; \n",
      " validation loss : 0.6059901144670237; validation accuracy : 0.9456066945606695\n",
      "Epoch 85:\t train loss : 0.5725097731198728; train accuracy : 0.9783813005359522; \n",
      " validation loss : 0.6054140995583248; validation accuracy : 0.9456066945606695\n",
      "Early stopping at epoch 85\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.570691225040896; Train accuracy : 0.9803197125065832; \n",
      " Validation loss : 0.5904977269669669; Validation accuracy : 0.9581589958158996\n",
      "--- Let's train model 90 ! ---\n",
      "Epoch 1:\t train loss : 0.9457611793026838; train accuracy : 0.5802162396604603; \n",
      " validation loss : 0.8416847187168806; validation accuracy : 0.702928870292887\n",
      "Epoch 2:\t train loss : 0.7574325800525659; train accuracy : 0.790388797670312; \n",
      " validation loss : 0.7550309322667581; validation accuracy : 0.799163179916318\n",
      "Epoch 3:\t train loss : 0.694987822692941; train accuracy : 0.8556538306638991; \n",
      " validation loss : 0.7338390233479769; validation accuracy : 0.8075313807531381\n",
      "Epoch 4:\t train loss : 0.668664269145507; train accuracy : 0.8819381021716906; \n",
      " validation loss : 0.705262344874664; validation accuracy : 0.8493723849372385\n",
      "Epoch 5:\t train loss : 0.6551984792293635; train accuracy : 0.895244586263515; \n",
      " validation loss : 0.6854883366144038; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6418122385432937; train accuracy : 0.9082598593512811; \n",
      " validation loss : 0.6765658066508159; validation accuracy : 0.8702928870292888\n",
      "Epoch 7:\t train loss : 0.6241421772144321; train accuracy : 0.9269487902351374; \n",
      " validation loss : 0.6769255987755683; validation accuracy : 0.8661087866108786\n",
      "Epoch 8:\t train loss : 0.6260109679810905; train accuracy : 0.924954304656278; \n",
      " validation loss : 0.716017525991361; validation accuracy : 0.8284518828451883\n",
      "Epoch 9:\t train loss : 0.6192519963863626; train accuracy : 0.9314888937079835; \n",
      " validation loss : 0.7135294923888064; validation accuracy : 0.8284518828451883\n",
      "Epoch 10:\t train loss : 0.6093820653163963; train accuracy : 0.941515226617925; \n",
      " validation loss : 0.6619248302526665; validation accuracy : 0.8870292887029289\n",
      "Epoch 11:\t train loss : 0.5951821725490423; train accuracy : 0.956019703212615; \n",
      " validation loss : 0.6470896423573326; validation accuracy : 0.9037656903765691\n",
      "Epoch 12:\t train loss : 0.598465360479309; train accuracy : 0.9526583847083243; \n",
      " validation loss : 0.6801453936332665; validation accuracy : 0.8661087866108786\n",
      "Epoch 13:\t train loss : 0.5913388288108037; train accuracy : 0.9599931844233093; \n",
      " validation loss : 0.6498298045695184; validation accuracy : 0.899581589958159\n",
      "Epoch 14:\t train loss : 0.5814414350100819; train accuracy : 0.9704953685058397; \n",
      " validation loss : 0.6537066689538158; validation accuracy : 0.891213389121339\n",
      "Epoch 15:\t train loss : 0.5840967223615094; train accuracy : 0.9673177607732582; \n",
      " validation loss : 0.6406842686778331; validation accuracy : 0.9037656903765691\n",
      "Epoch 16:\t train loss : 0.582009062496686; train accuracy : 0.9692481179714365; \n",
      " validation loss : 0.6737935816649883; validation accuracy : 0.8786610878661087\n",
      "Epoch 17:\t train loss : 0.5885343121027976; train accuracy : 0.9621809845410328; \n",
      " validation loss : 0.6514201304502936; validation accuracy : 0.895397489539749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:\t train loss : 0.5824928396849817; train accuracy : 0.9685547879426252; \n",
      " validation loss : 0.668399576486269; validation accuracy : 0.8702928870292888\n",
      "Epoch 19:\t train loss : 0.5792370269986578; train accuracy : 0.9719920071873354; \n",
      " validation loss : 0.6576438858622171; validation accuracy : 0.891213389121339\n",
      "Epoch 20:\t train loss : 0.5841415190518268; train accuracy : 0.9668840422565754; \n",
      " validation loss : 0.6423824695041486; validation accuracy : 0.9037656903765691\n",
      "Epoch 21:\t train loss : 0.5810416802322946; train accuracy : 0.9701583072585892; \n",
      " validation loss : 0.639388974901368; validation accuracy : 0.9037656903765691\n",
      "Epoch 22:\t train loss : 0.5812965341471032; train accuracy : 0.969987917841321; \n",
      " validation loss : 0.6624213453553214; validation accuracy : 0.8870292887029289\n",
      "Epoch 23:\t train loss : 0.5789080075945211; train accuracy : 0.9723076923076923; \n",
      " validation loss : 0.6752568772933979; validation accuracy : 0.8744769874476988\n",
      "Epoch 24:\t train loss : 0.5815644055025324; train accuracy : 0.9694959571238266; \n",
      " validation loss : 0.6341502848084135; validation accuracy : 0.9163179916317992\n",
      "Epoch 25:\t train loss : 0.5710605483022394; train accuracy : 0.9803218810991666; \n",
      " validation loss : 0.6467380667129722; validation accuracy : 0.895397489539749\n",
      "Epoch 26:\t train loss : 0.5739226318132226; train accuracy : 0.9771966293875275; \n",
      " validation loss : 0.628604310261904; validation accuracy : 0.9246861924686193\n",
      "Epoch 27:\t train loss : 0.5742970782555517; train accuracy : 0.9766331051147805; \n",
      " validation loss : 0.6214069417051622; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.5717948930020226; train accuracy : 0.9793246383097369; \n",
      " validation loss : 0.6331106079173366; validation accuracy : 0.9163179916317992\n",
      "Epoch 29:\t train loss : 0.5709010812515886; train accuracy : 0.9805638340716875; \n",
      " validation loss : 0.6394315414698744; validation accuracy : 0.9121338912133892\n",
      "Epoch 30:\t train loss : 0.5831018223373245; train accuracy : 0.9675538275659097; \n",
      " validation loss : 0.6538506999576271; validation accuracy : 0.899581589958159\n",
      "Epoch 31:\t train loss : 0.603067723067613; train accuracy : 0.9472914278633167; \n",
      " validation loss : 0.6483823524971649; validation accuracy : 0.899581589958159\n",
      "Epoch 32:\t train loss : 0.5724312826701782; train accuracy : 0.9788289600049568; \n",
      " validation loss : 0.6644027825725303; validation accuracy : 0.8828451882845189\n",
      "Epoch 33:\t train loss : 0.5698846824973341; train accuracy : 0.9813538213699309; \n",
      " validation loss : 0.6491941494377088; validation accuracy : 0.899581589958159\n",
      "Epoch 34:\t train loss : 0.5686325309887008; train accuracy : 0.9826859568140277; \n",
      " validation loss : 0.6369939383783368; validation accuracy : 0.9121338912133892\n",
      "Epoch 35:\t train loss : 0.5697910906228763; train accuracy : 0.9815397007342235; \n",
      " validation loss : 0.6330755214274167; validation accuracy : 0.9121338912133892\n",
      "Epoch 36:\t train loss : 0.5679091805429867; train accuracy : 0.9834914340592955; \n",
      " validation loss : 0.6164375184709671; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5643668490893652; train accuracy : 0.9869921620868056; \n",
      " validation loss : 0.6259780376915214; validation accuracy : 0.9288702928870293\n",
      "Epoch 38:\t train loss : 0.5673426208505182; train accuracy : 0.9839502462901577; \n",
      " validation loss : 0.7027740507379027; validation accuracy : 0.8451882845188284\n",
      "Epoch 39:\t train loss : 0.600986696236238; train accuracy : 0.9495315840019827; \n",
      " validation loss : 0.6369789537337122; validation accuracy : 0.9163179916317992\n",
      "Epoch 40:\t train loss : 0.5761057099509246; train accuracy : 0.974894513460764; \n",
      " validation loss : 0.6408584848360268; validation accuracy : 0.9079497907949791\n",
      "Epoch 41:\t train loss : 0.5698416535593829; train accuracy : 0.9812181294339973; \n",
      " validation loss : 0.6462604023929376; validation accuracy : 0.9037656903765691\n",
      "Epoch 42:\t train loss : 0.5668370624972267; train accuracy : 0.9843529849127916; \n",
      " validation loss : 0.6263495907093559; validation accuracy : 0.9246861924686193\n",
      "Epoch 43:\t train loss : 0.5678764966896851; train accuracy : 0.9832900647479785; \n",
      " validation loss : 0.6387695619919446; validation accuracy : 0.9079497907949791\n",
      "Epoch 44:\t train loss : 0.5651668652119123; train accuracy : 0.9859794293503517; \n",
      " validation loss : 0.6448024465981493; validation accuracy : 0.9037656903765691\n",
      "Epoch 45:\t train loss : 0.5678863465040647; train accuracy : 0.9832900647479785; \n",
      " validation loss : 0.6193247940262653; validation accuracy : 0.9288702928870293\n",
      "Epoch 46:\t train loss : 0.5621173666504555; train accuracy : 0.9891511509030639; \n",
      " validation loss : 0.6393957874628362; validation accuracy : 0.9121338912133892\n",
      "Epoch 47:\t train loss : 0.5624026030670987; train accuracy : 0.9889652715387713; \n",
      " validation loss : 0.6319557619677978; validation accuracy : 0.9205020920502092\n",
      "Epoch 48:\t train loss : 0.5624358272216599; train accuracy : 0.9886864524923324; \n",
      " validation loss : 0.6373236389451301; validation accuracy : 0.9163179916317992\n",
      "Epoch 49:\t train loss : 0.5630389312980479; train accuracy : 0.9882136993091484; \n",
      " validation loss : 0.6608245132901794; validation accuracy : 0.8870292887029289\n",
      "Epoch 50:\t train loss : 0.5656070015321787; train accuracy : 0.9855361070665138; \n",
      " validation loss : 0.6063916795164491; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5631507027928361; train accuracy : 0.9882837138696986; \n",
      " validation loss : 0.6198836889300807; validation accuracy : 0.9330543933054394\n",
      "Epoch 52:\t train loss : 0.5683853805233349; train accuracy : 0.9828814399454754; \n",
      " validation loss : 0.6380806731405579; validation accuracy : 0.9121338912133892\n",
      "Epoch 53:\t train loss : 0.572206819089327; train accuracy : 0.9789683695281762; \n",
      " validation loss : 0.6400977260996822; validation accuracy : 0.9037656903765691\n",
      "Epoch 54:\t train loss : 0.5638845695619255; train accuracy : 0.987332940921342; \n",
      " validation loss : 0.6576924624813572; validation accuracy : 0.891213389121339\n",
      "Epoch 55:\t train loss : 0.5623377122905179; train accuracy : 0.9889438954118777; \n",
      " validation loss : 0.637775098603226; validation accuracy : 0.9121338912133892\n",
      "Epoch 56:\t train loss : 0.5630472048952233; train accuracy : 0.9882970352241396; \n",
      " validation loss : 0.647120034070285; validation accuracy : 0.899581589958159\n",
      "Epoch 57:\t train loss : 0.5666541139615665; train accuracy : 0.9846472939062548; \n",
      " validation loss : 0.6340344553290687; validation accuracy : 0.9121338912133892\n",
      "Epoch 58:\t train loss : 0.564115498742956; train accuracy : 0.9870386319278788; \n",
      " validation loss : 0.6386352989730439; validation accuracy : 0.9121338912133892\n",
      "Epoch 59:\t train loss : 0.5674238122664854; train accuracy : 0.9836206202174789; \n",
      " validation loss : 0.6697728803119587; validation accuracy : 0.8786610878661087\n",
      "Epoch 60:\t train loss : 0.5641064143390947; train accuracy : 0.9871529477369188; \n",
      " validation loss : 0.6410594924193234; validation accuracy : 0.9121338912133892\n",
      "Epoch 61:\t train loss : 0.5654611557110734; train accuracy : 0.9856600266427089; \n",
      " validation loss : 0.6266562768187953; validation accuracy : 0.9205020920502092\n",
      "Epoch 62:\t train loss : 0.5649352047551327; train accuracy : 0.9863378667244957; \n",
      " validation loss : 0.6207642118809168; validation accuracy : 0.9288702928870293\n",
      "Epoch 63:\t train loss : 0.5619431012020106; train accuracy : 0.9893872176957155; \n",
      " validation loss : 0.6381097286481093; validation accuracy : 0.9079497907949791\n",
      "Epoch 64:\t train loss : 0.5622950233643758; train accuracy : 0.9889652715387713; \n",
      " validation loss : 0.6340475545172171; validation accuracy : 0.9163179916317992\n",
      "Epoch 65:\t train loss : 0.5664128692493752; train accuracy : 0.9848641531645962; \n",
      " validation loss : 0.623368891018742; validation accuracy : 0.9288702928870293\n",
      "Epoch 66:\t train loss : 0.5636990280308101; train accuracy : 0.987584497661018; \n",
      " validation loss : 0.6343237093190994; validation accuracy : 0.9163179916317992\n",
      "Epoch 67:\t train loss : 0.563994530856912; train accuracy : 0.9873617522228074; \n",
      " validation loss : 0.6232790976928062; validation accuracy : 0.9288702928870293\n",
      "Epoch 68:\t train loss : 0.5650012211376622; train accuracy : 0.9862951144707085; \n",
      " validation loss : 0.6146495229928577; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:\t train loss : 0.5609725406223738; train accuracy : 0.9903128969298925; \n",
      " validation loss : 0.6097601767863525; validation accuracy : 0.9372384937238494\n",
      "Epoch 70:\t train loss : 0.5627584726170907; train accuracy : 0.9885138944824808; \n",
      " validation loss : 0.6436095338245629; validation accuracy : 0.9079497907949791\n",
      "Epoch 71:\t train loss : 0.5698144293851974; train accuracy : 0.9813538213699309; \n",
      " validation loss : 0.644225034600787; validation accuracy : 0.9079497907949791\n",
      "Epoch 72:\t train loss : 0.5709148623325487; train accuracy : 0.9800836457139317; \n",
      " validation loss : 0.6131666036189287; validation accuracy : 0.9372384937238494\n",
      "Epoch 73:\t train loss : 0.5658091110756776; train accuracy : 0.985582576907587; \n",
      " validation loss : 0.6247312959039864; validation accuracy : 0.9288702928870293\n",
      "Epoch 74:\t train loss : 0.5636754160445846; train accuracy : 0.9876390222745438; \n",
      " validation loss : 0.623441408461313; validation accuracy : 0.9246861924686193\n",
      "Epoch 75:\t train loss : 0.5622951972824264; train accuracy : 0.9889246878775675; \n",
      " validation loss : 0.6047640073624675; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5632264294269624; train accuracy : 0.9879525388023173; \n",
      " validation loss : 0.6207961053404658; validation accuracy : 0.9288702928870293\n",
      "Epoch 77:\t train loss : 0.562582189081699; train accuracy : 0.9886591901855696; \n",
      " validation loss : 0.6363138579666; validation accuracy : 0.9079497907949791\n",
      "Epoch 78:\t train loss : 0.5626445947203798; train accuracy : 0.9886452492332476; \n",
      " validation loss : 0.6235330892191383; validation accuracy : 0.9288702928870293\n",
      "Epoch 79:\t train loss : 0.5681260742747972; train accuracy : 0.9829588896805973; \n",
      " validation loss : 0.6276638975991846; validation accuracy : 0.9246861924686193\n",
      "Epoch 80:\t train loss : 0.5587737605083357; train accuracy : 0.9926305028036804; \n",
      " validation loss : 0.6291953239833956; validation accuracy : 0.9205020920502092\n",
      "Epoch 81:\t train loss : 0.5606237193657937; train accuracy : 0.9906883732457635; \n",
      " validation loss : 0.6277723686051748; validation accuracy : 0.9205020920502092\n",
      "Epoch 82:\t train loss : 0.5669668193329706; train accuracy : 0.9842482728709068; \n",
      " validation loss : 0.6908473250864035; validation accuracy : 0.8619246861924686\n",
      "Epoch 83:\t train loss : 0.5757079243557667; train accuracy : 0.9752817621363735; \n",
      " validation loss : 0.6470508254394839; validation accuracy : 0.9037656903765691\n",
      "Epoch 84:\t train loss : 0.5619360364381155; train accuracy : 0.9892942780135692; \n",
      " validation loss : 0.6162991267797087; validation accuracy : 0.9330543933054394\n",
      "Epoch 85:\t train loss : 0.5621956150487005; train accuracy : 0.9891025124694074; \n",
      " validation loss : 0.6483112535600513; validation accuracy : 0.9037656903765691\n",
      "Epoch 86:\t train loss : 0.5708654804144745; train accuracy : 0.9801301155550048; \n",
      " validation loss : 0.6445788201360252; validation accuracy : 0.9037656903765691\n",
      "Epoch 87:\t train loss : 0.5651088703808728; train accuracy : 0.9860937451593915; \n",
      " validation loss : 0.6452182735170598; validation accuracy : 0.9079497907949791\n",
      "Epoch 88:\t train loss : 0.5632745421110872; train accuracy : 0.9879680287493416; \n",
      " validation loss : 0.6159088414680887; validation accuracy : 0.9372384937238494\n",
      "Epoch 89:\t train loss : 0.5601393426352188; train accuracy : 0.9910873942811116; \n",
      " validation loss : 0.6179002323406703; validation accuracy : 0.9330543933054394\n",
      "Epoch 90:\t train loss : 0.5609247076214242; train accuracy : 0.9904736825800056; \n",
      " validation loss : 0.6366195889109927; validation accuracy : 0.9121338912133892\n",
      "Epoch 91:\t train loss : 0.5588792940493369; train accuracy : 0.9925183555872239; \n",
      " validation loss : 0.6300158087398094; validation accuracy : 0.9246861924686193\n",
      "Epoch 92:\t train loss : 0.5581737893776035; train accuracy : 0.9931881408965582; \n",
      " validation loss : 0.614976438751701; validation accuracy : 0.9372384937238494\n",
      "Epoch 93:\t train loss : 0.5606433750047026; train accuracy : 0.9908432727160074; \n",
      " validation loss : 0.6269537885413391; validation accuracy : 0.9246861924686193\n",
      "Epoch 94:\t train loss : 0.5636439740070622; train accuracy : 0.9876582298088541; \n",
      " validation loss : 0.6444126833834048; validation accuracy : 0.9037656903765691\n",
      "Epoch 95:\t train loss : 0.5641150002693704; train accuracy : 0.9870754980017968; \n",
      " validation loss : 0.6322853404704052; validation accuracy : 0.9205020920502092\n",
      "Epoch 96:\t train loss : 0.5592806432914169; train accuracy : 0.9920691471235168; \n",
      " validation loss : 0.6201419720522866; validation accuracy : 0.9288702928870293\n",
      "Epoch 97:\t train loss : 0.5624609058792758; train accuracy : 0.9888878218036494; \n",
      " validation loss : 0.6213287316620201; validation accuracy : 0.9288702928870293\n",
      "Epoch 98:\t train loss : 0.5774055529780894; train accuracy : 0.9735676445986555; \n",
      " validation loss : 0.6573921426987995; validation accuracy : 0.895397489539749\n",
      "Epoch 99:\t train loss : 0.5682370349628323; train accuracy : 0.9828622324111651; \n",
      " validation loss : 0.6417686602589436; validation accuracy : 0.9037656903765691\n",
      "Epoch 100:\t train loss : 0.5604053945284063; train accuracy : 0.9908181790018278; \n",
      " validation loss : 0.6368135482758425; validation accuracy : 0.9121338912133892\n",
      "Epoch 101:\t train loss : 0.5594114804469872; train accuracy : 0.9919430589547383; \n",
      " validation loss : 0.6223851610400958; validation accuracy : 0.9330543933054394\n",
      "Epoch 102:\t train loss : 0.561529722197461; train accuracy : 0.9897707487840391; \n",
      " validation loss : 0.6181962735731308; validation accuracy : 0.9330543933054394\n",
      "Epoch 103:\t train loss : 0.5600497242767893; train accuracy : 0.9913042535394528; \n",
      " validation loss : 0.6271684270859951; validation accuracy : 0.9246861924686193\n",
      "Epoch 104:\t train loss : 0.559690667477459; train accuracy : 0.9915307165649493; \n",
      " validation loss : 0.636013026983765; validation accuracy : 0.9121338912133892\n",
      "Epoch 105:\t train loss : 0.5577480650043259; train accuracy : 0.9936587254871588; \n",
      " validation loss : 0.634263126890834; validation accuracy : 0.9163179916317992\n",
      "Epoch 106:\t train loss : 0.5570543608963506; train accuracy : 0.9944081291241984; \n",
      " validation loss : 0.6136109092408225; validation accuracy : 0.9372384937238494\n",
      "Epoch 107:\t train loss : 0.5587728597976432; train accuracy : 0.9925626568357137; \n",
      " validation loss : 0.6222482234408537; validation accuracy : 0.9288702928870293\n",
      "Epoch 108:\t train loss : 0.5597598376351948; train accuracy : 0.991565414046284; \n",
      " validation loss : 0.6333309599012124; validation accuracy : 0.9163179916317992\n",
      "Epoch 109:\t train loss : 0.559743846369729; train accuracy : 0.9915734688187366; \n",
      " validation loss : 0.6221679814280677; validation accuracy : 0.9288702928870293\n",
      "Epoch 110:\t train loss : 0.5624014037169763; train accuracy : 0.988835465782707; \n",
      " validation loss : 0.6402357689068517; validation accuracy : 0.9079497907949791\n",
      "Epoch 111:\t train loss : 0.5633194324931619; train accuracy : 0.9879178413209827; \n",
      " validation loss : 0.6253939775889509; validation accuracy : 0.9246861924686193\n",
      "Epoch 112:\t train loss : 0.5633184730195473; train accuracy : 0.9879215589082685; \n",
      " validation loss : 0.6323906415471547; validation accuracy : 0.9205020920502092\n",
      "Epoch 113:\t train loss : 0.5615155648539402; train accuracy : 0.9898305399795533; \n",
      " validation loss : 0.6052223946288495; validation accuracy : 0.9456066945606695\n",
      "Epoch 114:\t train loss : 0.5662931195950313; train accuracy : 0.984895133058645; \n",
      " validation loss : 0.6237725672282035; validation accuracy : 0.9246861924686193\n",
      "Epoch 115:\t train loss : 0.5603279486672768; train accuracy : 0.9911338641221847; \n",
      " validation loss : 0.6205327494592539; validation accuracy : 0.9288702928870293\n",
      "Epoch 116:\t train loss : 0.5587532414356915; train accuracy : 0.9926401065708356; \n",
      " validation loss : 0.6294767182872912; validation accuracy : 0.9246861924686193\n",
      "Epoch 117:\t train loss : 0.560148300698826; train accuracy : 0.9912268038043309; \n",
      " validation loss : 0.6016840614200235; validation accuracy : 0.9497907949790795\n",
      "Epoch 118:\t train loss : 0.5583060071464129; train accuracy : 0.9930428451934694; \n",
      " validation loss : 0.6039474723958275; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5599608353911625; train accuracy : 0.9914281731156479; \n",
      " validation loss : 0.6280296679186231; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120:\t train loss : 0.5622037469763805; train accuracy : 0.9891415471359087; \n",
      " validation loss : 0.6255897849330263; validation accuracy : 0.9246861924686193\n",
      "Epoch 121:\t train loss : 0.5657295054662497; train accuracy : 0.9854084699030329; \n",
      " validation loss : 0.6229871396338332; validation accuracy : 0.9246861924686193\n",
      "Epoch 122:\t train loss : 0.5626603956836873; train accuracy : 0.9887639022274544; \n",
      " validation loss : 0.597023057176571; validation accuracy : 0.9539748953974896\n",
      "Epoch 123:\t train loss : 0.5615141443332254; train accuracy : 0.989851916106447; \n",
      " validation loss : 0.619887067847819; validation accuracy : 0.9330543933054394\n",
      "Epoch 124:\t train loss : 0.559603221455883; train accuracy : 0.9916273738343815; \n",
      " validation loss : 0.6170200260971678; validation accuracy : 0.9330543933054394\n",
      "Epoch 125:\t train loss : 0.5579981388774599; train accuracy : 0.9933857926205892; \n",
      " validation loss : 0.6234172994550754; validation accuracy : 0.9288702928870293\n",
      "Epoch 126:\t train loss : 0.5571094972362444; train accuracy : 0.9942628334211097; \n",
      " validation loss : 0.6264520117889539; validation accuracy : 0.9246861924686193\n",
      "Epoch 127:\t train loss : 0.5581119227428295; train accuracy : 0.9932655906316801; \n",
      " validation loss : 0.623125674880456; validation accuracy : 0.9246861924686193\n",
      "Epoch 128:\t train loss : 0.5615056298382173; train accuracy : 0.9897397688899904; \n",
      " validation loss : 0.648214051883537; validation accuracy : 0.9037656903765691\n",
      "Epoch 129:\t train loss : 0.5614249501995081; train accuracy : 0.989811332445243; \n",
      " validation loss : 0.6601591777425708; validation accuracy : 0.891213389121339\n",
      "Epoch 130:\t train loss : 0.5585097076215557; train accuracy : 0.9928008922209486; \n",
      " validation loss : 0.6200268020862221; validation accuracy : 0.9330543933054394\n",
      "Epoch 131:\t train loss : 0.5576131672003831; train accuracy : 0.9937265714551257; \n",
      " validation loss : 0.6121550071695703; validation accuracy : 0.9372384937238494\n",
      "Epoch 132:\t train loss : 0.5616522528754894; train accuracy : 0.9894646674308374; \n",
      " validation loss : 0.618811140220468; validation accuracy : 0.9330543933054394\n",
      "Epoch 133:\t train loss : 0.5594124508865915; train accuracy : 0.9920013011555501; \n",
      " validation loss : 0.6076960327645112; validation accuracy : 0.9414225941422594\n",
      "Epoch 134:\t train loss : 0.5596983918644266; train accuracy : 0.9916701260881687; \n",
      " validation loss : 0.6152466973041004; validation accuracy : 0.9372384937238494\n",
      "Epoch 135:\t train loss : 0.5621619933489606; train accuracy : 0.9891548684903497; \n",
      " validation loss : 0.6176510365131954; validation accuracy : 0.9330543933054394\n",
      "Epoch 136:\t train loss : 0.5601174934929095; train accuracy : 0.9911338641221847; \n",
      " validation loss : 0.6182769131539798; validation accuracy : 0.9288702928870293\n",
      "Epoch 137:\t train loss : 0.5580879405483744; train accuracy : 0.993302456705598; \n",
      " validation loss : 0.6211756587323706; validation accuracy : 0.9288702928870293\n",
      "Epoch 138:\t train loss : 0.5613488593201176; train accuracy : 0.9899042721273893; \n",
      " validation loss : 0.6231740947517262; validation accuracy : 0.9246861924686193\n",
      "Epoch 139:\t train loss : 0.5635132947876543; train accuracy : 0.9876833235230336; \n",
      " validation loss : 0.6194987530360481; validation accuracy : 0.9330543933054394\n",
      "Epoch 140:\t train loss : 0.5823354690321312; train accuracy : 0.9685259766411599; \n",
      " validation loss : 0.6456918259679061; validation accuracy : 0.9037656903765691\n",
      "Epoch 141:\t train loss : 0.5665070872141162; train accuracy : 0.9847365160011152; \n",
      " validation loss : 0.6121432468596656; validation accuracy : 0.9330543933054394\n",
      "Epoch 142:\t train loss : 0.5619678507746309; train accuracy : 0.9893097679605936; \n",
      " validation loss : 0.6336634660917053; validation accuracy : 0.9163179916317992\n",
      "Epoch 143:\t train loss : 0.5610383477293505; train accuracy : 0.9901056414387063; \n",
      " validation loss : 0.6309527351740425; validation accuracy : 0.9205020920502092\n",
      "Epoch 144:\t train loss : 0.5585430819397316; train accuracy : 0.9927699123268998; \n",
      " validation loss : 0.6355404876240598; validation accuracy : 0.9121338912133892\n",
      "Epoch 145:\t train loss : 0.5562752796371467; train accuracy : 0.9950624244865083; \n",
      " validation loss : 0.6234907950153641; validation accuracy : 0.9288702928870293\n",
      "Epoch 146:\t train loss : 0.5615622283527151; train accuracy : 0.9897803525511942; \n",
      " validation loss : 0.6287497488641006; validation accuracy : 0.9205020920502092\n",
      "Epoch 147:\t train loss : 0.5618308507880228; train accuracy : 0.98953623098609; \n",
      " validation loss : 0.6415481450402984; validation accuracy : 0.9079497907949791\n",
      "Epoch 148:\t train loss : 0.5584754502886442; train accuracy : 0.99290343567025; \n",
      " validation loss : 0.6269540030492882; validation accuracy : 0.9246861924686193\n",
      "Epoch 149:\t train loss : 0.5588380545166388; train accuracy : 0.9924873756931751; \n",
      " validation loss : 0.6292064609746418; validation accuracy : 0.9205020920502092\n",
      "Epoch 150:\t train loss : 0.5555790026016675; train accuracy : 0.9958892778586697; \n",
      " validation loss : 0.6074419146642919; validation accuracy : 0.9414225941422594\n",
      "Epoch 151:\t train loss : 0.555275285601593; train accuracy : 0.9960965333498559; \n",
      " validation loss : 0.6147351581282061; validation accuracy : 0.9330543933054394\n",
      "Epoch 152:\t train loss : 0.5546516218043466; train accuracy : 0.9967412249450107; \n",
      " validation loss : 0.6248918032912278; validation accuracy : 0.9246861924686193\n",
      "Epoch 153:\t train loss : 0.5592928676499213; train accuracy : 0.9919216828278448; \n",
      " validation loss : 0.6410175827582105; validation accuracy : 0.9079497907949791\n",
      "Epoch 154:\t train loss : 0.5583635135622149; train accuracy : 0.9930081477121349; \n",
      " validation loss : 0.6208269802396346; validation accuracy : 0.9288702928870293\n",
      "Epoch 155:\t train loss : 0.5581514516970133; train accuracy : 0.9931357848756157; \n",
      " validation loss : 0.6116945333736892; validation accuracy : 0.9372384937238494\n",
      "Epoch 156:\t train loss : 0.561425564187878; train accuracy : 0.9898268223922674; \n",
      " validation loss : 0.6643990843779152; validation accuracy : 0.8870292887029289\n",
      "Epoch 157:\t train loss : 0.5609748354833992; train accuracy : 0.9904368165060875; \n",
      " validation loss : 0.5939709461415745; validation accuracy : 0.9581589958158996\n",
      "Epoch 158:\t train loss : 0.5594002568171726; train accuracy : 0.9919157966479755; \n",
      " validation loss : 0.6134267850537379; validation accuracy : 0.9372384937238494\n",
      "Epoch 159:\t train loss : 0.5565379847822584; train accuracy : 0.9948455652281669; \n",
      " validation loss : 0.6100101749618954; validation accuracy : 0.9414225941422594\n",
      "Epoch 160:\t train loss : 0.5576328351817901; train accuracy : 0.9936838192013383; \n",
      " validation loss : 0.6011706915949004; validation accuracy : 0.9497907949790795\n",
      "Epoch 161:\t train loss : 0.5639581806275483; train accuracy : 0.9871994175779919; \n",
      " validation loss : 0.6384885601432153; validation accuracy : 0.9121338912133892\n",
      "Epoch 162:\t train loss : 0.5559390084343203; train accuracy : 0.995331639765792; \n",
      " validation loss : 0.5947261684651253; validation accuracy : 0.9539748953974896\n",
      "Epoch 163:\t train loss : 0.554762987733233; train accuracy : 0.9966888689240683; \n",
      " validation loss : 0.6198560596311501; validation accuracy : 0.9330543933054394\n",
      "Epoch 164:\t train loss : 0.5572690420036261; train accuracy : 0.9940614641097927; \n",
      " validation loss : 0.6339883669241625; validation accuracy : 0.9163179916317992\n",
      "Epoch 165:\t train loss : 0.5565188811634063; train accuracy : 0.9948145853341182; \n",
      " validation loss : 0.6065831949307081; validation accuracy : 0.9456066945606695\n",
      "Epoch 166:\t train loss : 0.5548891873347586; train accuracy : 0.9964159360574987; \n",
      " validation loss : 0.596507765960369; validation accuracy : 0.9539748953974896\n",
      "Epoch 167:\t train loss : 0.5560747935300339; train accuracy : 0.9953257535859227; \n",
      " validation loss : 0.602268586740757; validation accuracy : 0.9497907949790795\n",
      "Epoch 168:\t train loss : 0.5703925759755497; train accuracy : 0.980836766938257; \n",
      " validation loss : 0.6157941971398067; validation accuracy : 0.9330543933054394\n",
      "Epoch 169:\t train loss : 0.5644677616194569; train accuracy : 0.9867811890083336; \n",
      " validation loss : 0.614179225278081; validation accuracy : 0.9372384937238494\n",
      "Epoch 170:\t train loss : 0.5599454865764034; train accuracy : 0.9914260045230645; \n",
      " validation loss : 0.6291784827569487; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171:\t train loss : 0.5639581260000915; train accuracy : 0.9872400012391958; \n",
      " validation loss : 0.6446734882298314; validation accuracy : 0.9079497907949791\n",
      "Epoch 172:\t train loss : 0.5602304893049416; train accuracy : 0.9911589578363642; \n",
      " validation loss : 0.6203423017487284; validation accuracy : 0.9288702928870293\n",
      "Epoch 173:\t train loss : 0.5570105142152195; train accuracy : 0.9943151894420521; \n",
      " validation loss : 0.6142927362302812; validation accuracy : 0.9372384937238494\n",
      "Epoch 174:\t train loss : 0.5554221051131791; train accuracy : 0.9960131974348647; \n",
      " validation loss : 0.6055794405064543; validation accuracy : 0.9456066945606695\n",
      "Epoch 175:\t train loss : 0.5568011367374578; train accuracy : 0.9945785185414666; \n",
      " validation loss : 0.6265464608855652; validation accuracy : 0.9205020920502092\n",
      "Epoch 176:\t train loss : 0.5578508950782907; train accuracy : 0.9935230335512253; \n",
      " validation loss : 0.6178785809292751; validation accuracy : 0.9330543933054394\n",
      "Epoch 177:\t train loss : 0.558170538028964; train accuracy : 0.9931106911614362; \n",
      " validation loss : 0.6144449568184478; validation accuracy : 0.9372384937238494\n",
      "Epoch 178:\t train loss : 0.5574663345317639; train accuracy : 0.9938851885126553; \n",
      " validation loss : 0.6095432106010767; validation accuracy : 0.9414225941422594\n",
      "Epoch 179:\t train loss : 0.5574897740108832; train accuracy : 0.9938077387775334; \n",
      " validation loss : 0.6052869134649881; validation accuracy : 0.9456066945606695\n",
      "Epoch 180:\t train loss : 0.5562765392447078; train accuracy : 0.9950838006134018; \n",
      " validation loss : 0.616707779886047; validation accuracy : 0.9330543933054394\n",
      "Epoch 181:\t train loss : 0.55638176720197; train accuracy : 0.9950218408253043; \n",
      " validation loss : 0.6101781373958554; validation accuracy : 0.9414225941422594\n",
      "Epoch 182:\t train loss : 0.5622540093887347; train accuracy : 0.9889785928932123; \n",
      " validation loss : 0.6145635897026962; validation accuracy : 0.9372384937238494\n",
      "Epoch 183:\t train loss : 0.558015118649326; train accuracy : 0.9933371541869327; \n",
      " validation loss : 0.6077475181177607; validation accuracy : 0.9414225941422594\n",
      "Epoch 184:\t train loss : 0.5548672410271938; train accuracy : 0.9965612317605874; \n",
      " validation loss : 0.6253553859570069; validation accuracy : 0.9246861924686193\n",
      "Epoch 185:\t train loss : 0.5569757915297672; train accuracy : 0.9943867529973047; \n",
      " validation loss : 0.6085031362119903; validation accuracy : 0.9414225941422594\n",
      "Epoch 186:\t train loss : 0.5547038918849851; train accuracy : 0.9966482852628644; \n",
      " validation loss : 0.6166498258651988; validation accuracy : 0.9330543933054394\n",
      "Epoch 187:\t train loss : 0.5548950018877543; train accuracy : 0.996508875739645; \n",
      " validation loss : 0.6212738019390405; validation accuracy : 0.9288702928870293\n",
      "Epoch 188:\t train loss : 0.5582095161744967; train accuracy : 0.993054617553208; \n",
      " validation loss : 0.6097774831580972; validation accuracy : 0.9414225941422594\n",
      "Epoch 189:\t train loss : 0.5548891214986019; train accuracy : 0.9965553455807181; \n",
      " validation loss : 0.591924537587064; validation accuracy : 0.9581589958158996\n",
      "Epoch 190:\t train loss : 0.5581508580190594; train accuracy : 0.9931475572353542; \n",
      " validation loss : 0.6141810188324678; validation accuracy : 0.9372384937238494\n",
      "Epoch 191:\t train loss : 0.5559347570840844; train accuracy : 0.995418693268069; \n",
      " validation loss : 0.6135747407921461; validation accuracy : 0.9372384937238494\n",
      "Epoch 192:\t train loss : 0.5586493050677144; train accuracy : 0.9927138387186716; \n",
      " validation loss : 0.6149116195327767; validation accuracy : 0.9330543933054394\n",
      "Epoch 193:\t train loss : 0.5558990591607931; train accuracy : 0.9954710492890114; \n",
      " validation loss : 0.6058068312709877; validation accuracy : 0.9456066945606695\n",
      "Epoch 194:\t train loss : 0.5556631255983147; train accuracy : 0.995693794727222; \n",
      " validation loss : 0.6161683786595867; validation accuracy : 0.9330543933054394\n",
      "Epoch 195:\t train loss : 0.5576365968127922; train accuracy : 0.9936993091483627; \n",
      " validation loss : 0.6160896086614465; validation accuracy : 0.9330543933054394\n",
      "Epoch 196:\t train loss : 0.5562393869717461; train accuracy : 0.995093404380557; \n",
      " validation loss : 0.6062663281877778; validation accuracy : 0.9456066945606695\n",
      "Epoch 197:\t train loss : 0.6461990039195733; train accuracy : 0.9036113262492642; \n",
      " validation loss : 0.6649198499033842; validation accuracy : 0.8870292887029289\n",
      "Epoch 198:\t train loss : 0.5819334410378714; train accuracy : 0.9689810712847362; \n",
      " validation loss : 0.6118235103858125; validation accuracy : 0.9414225941422594\n",
      "Epoch 199:\t train loss : 0.5725723463398843; train accuracy : 0.9784609188636575; \n",
      " validation loss : 0.6300859353065194; validation accuracy : 0.9205020920502092\n",
      "Epoch 200:\t train loss : 0.5717565393223036; train accuracy : 0.9792722822887946; \n",
      " validation loss : 0.6336749643663047; validation accuracy : 0.9163179916317992\n",
      "Epoch 201:\t train loss : 0.5615573357283732; train accuracy : 0.9895848694197465; \n",
      " validation loss : 0.6271423821124963; validation accuracy : 0.9246861924686193\n",
      "Epoch 202:\t train loss : 0.5585069564308454; train accuracy : 0.9926865764119087; \n",
      " validation loss : 0.5976194648178504; validation accuracy : 0.9539748953974896\n",
      "Epoch 203:\t train loss : 0.5592100788463258; train accuracy : 0.9921252207317451; \n",
      " validation loss : 0.6078426638380307; validation accuracy : 0.9456066945606695\n",
      "Epoch 204:\t train loss : 0.5576627252437222; train accuracy : 0.9937767588834846; \n",
      " validation loss : 0.6366598342316948; validation accuracy : 0.9163179916317992\n",
      "Epoch 205:\t train loss : 0.557507915244927; train accuracy : 0.9939257721738591; \n",
      " validation loss : 0.5980984721108846; validation accuracy : 0.9539748953974896\n",
      "Epoch 206:\t train loss : 0.5581338425191015; train accuracy : 0.9932714768115493; \n",
      " validation loss : 0.603162424076393; validation accuracy : 0.9497907949790795\n",
      "Epoch 207:\t train loss : 0.5593607543555472; train accuracy : 0.9920477709966232; \n",
      " validation loss : 0.6176815184970993; validation accuracy : 0.9372384937238494\n",
      "Epoch 208:\t train loss : 0.5578425443445734; train accuracy : 0.9934610737631278; \n",
      " validation loss : 0.6192314409751213; validation accuracy : 0.9330543933054394\n",
      "Epoch 209:\t train loss : 0.556698724060527; train accuracy : 0.9946132160228012; \n",
      " validation loss : 0.6016865298156169; validation accuracy : 0.9497907949790795\n",
      "Epoch 210:\t train loss : 0.5578536274973961; train accuracy : 0.9934979398370457; \n",
      " validation loss : 0.6264589871982019; validation accuracy : 0.9246861924686193\n",
      "Epoch 211:\t train loss : 0.5574085919973677; train accuracy : 0.9938851885126553; \n",
      " validation loss : 0.6126302692229053; validation accuracy : 0.9372384937238494\n",
      "Epoch 212:\t train loss : 0.5567490280446492; train accuracy : 0.994566746181728; \n",
      " validation loss : 0.6018839027704117; validation accuracy : 0.9456066945606695\n",
      "Epoch 213:\t train loss : 0.5562404029180209; train accuracy : 0.9951457604014994; \n",
      " validation loss : 0.6419163152892831; validation accuracy : 0.9079497907949791\n",
      "Epoch 214:\t train loss : 0.5597585372424454; train accuracy : 0.9914997366709006; \n",
      " validation loss : 0.6240789606589269; validation accuracy : 0.9288702928870293\n",
      "Epoch 215:\t train loss : 0.5559503145190942; train accuracy : 0.9954128070881998; \n",
      " validation loss : 0.6072333119008636; validation accuracy : 0.9456066945606695\n",
      "Epoch 216:\t train loss : 0.5571636102985215; train accuracy : 0.9942377397069302; \n",
      " validation loss : 0.6182635544646211; validation accuracy : 0.9330543933054394\n",
      "Epoch 217:\t train loss : 0.5553352654879795; train accuracy : 0.9960110288422813; \n",
      " validation loss : 0.6163868019791202; validation accuracy : 0.9330543933054394\n",
      "Epoch 218:\t train loss : 0.5555535278232631; train accuracy : 0.9958332042504414; \n",
      " validation loss : 0.6087734967355255; validation accuracy : 0.9456066945606695\n",
      "Epoch 219:\t train loss : 0.5574742822415374; train accuracy : 0.9938814709253694; \n",
      " validation loss : 0.6185875088048564; validation accuracy : 0.9330543933054394\n",
      "Epoch 220:\t train loss : 0.5551233400991749; train accuracy : 0.9962086805663124; \n",
      " validation loss : 0.6029025533561969; validation accuracy : 0.9456066945606695\n",
      "Epoch 221:\t train loss : 0.5573592725914981; train accuracy : 0.9939626382477772; \n",
      " validation loss : 0.6161174050308466; validation accuracy : 0.9330543933054394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222:\t train loss : 0.5559695315271215; train accuracy : 0.9953257535859227; \n",
      " validation loss : 0.6033119118687749; validation accuracy : 0.9456066945606695\n",
      "Epoch 223:\t train loss : 0.5554663649964765; train accuracy : 0.9958737879116454; \n",
      " validation loss : 0.6069253110271836; validation accuracy : 0.9414225941422594\n",
      "Epoch 224:\t train loss : 0.5559445965659122; train accuracy : 0.9954400693949627; \n",
      " validation loss : 0.5953660431040495; validation accuracy : 0.9581589958158996\n",
      "Epoch 225:\t train loss : 0.5554728279344265; train accuracy : 0.9959704451810775; \n",
      " validation loss : 0.6059882041555542; validation accuracy : 0.9456066945606695\n",
      "Epoch 226:\t train loss : 0.5552002002538218; train accuracy : 0.9962086805663124; \n",
      " validation loss : 0.5912796441417915; validation accuracy : 0.9623430962343096\n",
      "Epoch 227:\t train loss : 0.5560360685862071; train accuracy : 0.9953567334799714; \n",
      " validation loss : 0.5972187781343806; validation accuracy : 0.9539748953974896\n",
      "Epoch 228:\t train loss : 0.5562587398785837; train accuracy : 0.9951516465813687; \n",
      " validation loss : 0.6395873244342158; validation accuracy : 0.9121338912133892\n",
      "Epoch 229:\t train loss : 0.5583777224747017; train accuracy : 0.9929056042628334; \n",
      " validation loss : 0.6134060087519482; validation accuracy : 0.9372384937238494\n",
      "Epoch 230:\t train loss : 0.5622142176865007; train accuracy : 0.9889962514328201; \n",
      " validation loss : 0.6229799731709067; validation accuracy : 0.9288702928870293\n",
      "Epoch 231:\t train loss : 0.555383967504776; train accuracy : 0.9960131974348647; \n",
      " validation loss : 0.6302656957663235; validation accuracy : 0.9205020920502092\n",
      "Epoch 232:\t train loss : 0.5570416588783115; train accuracy : 0.9943867529973047; \n",
      " validation loss : 0.6095148080390582; validation accuracy : 0.9414225941422594\n",
      "Epoch 233:\t train loss : 0.5562621363465614; train accuracy : 0.9950683106663775; \n",
      " validation loss : 0.6165970510725761; validation accuracy : 0.9330543933054394\n",
      "Epoch 234:\t train loss : 0.5568812109659862; train accuracy : 0.9945512562347036; \n",
      " validation loss : 0.5971637361744423; validation accuracy : 0.9497907949790795\n",
      "Epoch 235:\t train loss : 0.5567253752558976; train accuracy : 0.9946500820967192; \n",
      " validation loss : 0.624158210409962; validation accuracy : 0.9246861924686193\n",
      "Epoch 236:\t train loss : 0.5571287914546158; train accuracy : 0.9942067598128814; \n",
      " validation loss : 0.614955856643566; validation accuracy : 0.9372384937238494\n",
      "Epoch 237:\t train loss : 0.5564839162572817; train accuracy : 0.9949385049103132; \n",
      " validation loss : 0.61098197821176; validation accuracy : 0.9414225941422594\n",
      "Epoch 238:\t train loss : 0.5551412033301201; train accuracy : 0.9962359428730754; \n",
      " validation loss : 0.6372884175173876; validation accuracy : 0.9121338912133892\n",
      "Epoch 239:\t train loss : 0.557653619729009; train accuracy : 0.9936742154341832; \n",
      " validation loss : 0.6140359595423285; validation accuracy : 0.9372384937238494\n",
      "Epoch 240:\t train loss : 0.5549314249263715; train accuracy : 0.9964314260045231; \n",
      " validation loss : 0.6093781193595357; validation accuracy : 0.9414225941422594\n",
      "Epoch 241:\t train loss : 0.5556075373475229; train accuracy : 0.9958022243563927; \n",
      " validation loss : 0.6132466704895833; validation accuracy : 0.9372384937238494\n",
      "Epoch 242:\t train loss : 0.5564478571523352; train accuracy : 0.9949075250162644; \n",
      " validation loss : 0.6136808830418363; validation accuracy : 0.9372384937238494\n",
      "Epoch 243:\t train loss : 0.5559389648094508; train accuracy : 0.9954769354688807; \n",
      " validation loss : 0.6244223604477219; validation accuracy : 0.9246861924686193\n",
      "Epoch 244:\t train loss : 0.5556504402524753; train accuracy : 0.9957498683354503; \n",
      " validation loss : 0.6247849308092679; validation accuracy : 0.9246861924686193\n",
      "Epoch 245:\t train loss : 0.5545416532645429; train accuracy : 0.9967722048390595; \n",
      " validation loss : 0.5991433408396114; validation accuracy : 0.9539748953974896\n",
      "Epoch 246:\t train loss : 0.5555483121835894; train accuracy : 0.9957963381765235; \n",
      " validation loss : 0.6172641763583686; validation accuracy : 0.9330543933054394\n",
      "Epoch 247:\t train loss : 0.5597297721942828; train accuracy : 0.9916140524799405; \n",
      " validation loss : 0.6087929022450991; validation accuracy : 0.9414225941422594\n",
      "Epoch 248:\t train loss : 0.5556068408635662; train accuracy : 0.9957033984943772; \n",
      " validation loss : 0.6281229988188147; validation accuracy : 0.9246861924686193\n",
      "Epoch 249:\t train loss : 0.5571860901379789; train accuracy : 0.9941698937389634; \n",
      " validation loss : 0.6104762173110522; validation accuracy : 0.9414225941422594\n",
      "Epoch 250:\t train loss : 0.5570075411934242; train accuracy : 0.9942724371882649; \n",
      " validation loss : 0.6066648433015004; validation accuracy : 0.9456066945606695\n",
      "Epoch 251:\t train loss : 0.5581993644737108; train accuracy : 0.993141671055485; \n",
      " validation loss : 0.6309994040830034; validation accuracy : 0.9205020920502092\n",
      "Epoch 252:\t train loss : 0.5557717869698967; train accuracy : 0.9956318349391245; \n",
      " validation loss : 0.6115007985013392; validation accuracy : 0.9372384937238494\n",
      "Epoch 253:\t train loss : 0.5549741276453862; train accuracy : 0.9963480900895318; \n",
      " validation loss : 0.6180814480716562; validation accuracy : 0.9330543933054394\n",
      "Epoch 254:\t train loss : 0.5542813045917407; train accuracy : 0.9971808296415626; \n",
      " validation loss : 0.602209362275766; validation accuracy : 0.9497907949790795\n",
      "Epoch 255:\t train loss : 0.5541297367641393; train accuracy : 0.9972678831438396; \n",
      " validation loss : 0.5970918335167358; validation accuracy : 0.9539748953974896\n",
      "Epoch 256:\t train loss : 0.5541797717650543; train accuracy : 0.9972272994826358; \n",
      " validation loss : 0.5973428768836617; validation accuracy : 0.9539748953974896\n",
      "Epoch 257:\t train loss : 0.5587926639589461; train accuracy : 0.9925065832274853; \n",
      " validation loss : 0.6273741086191668; validation accuracy : 0.9205020920502092\n",
      "Epoch 258:\t train loss : 0.5565111434042155; train accuracy : 0.9947953777998079; \n",
      " validation loss : 0.6102263681875404; validation accuracy : 0.9414225941422594\n",
      "Epoch 259:\t train loss : 0.5577450971104451; train accuracy : 0.9935016574243316; \n",
      " validation loss : 0.6254211527586844; validation accuracy : 0.9246861924686193\n",
      "Epoch 260:\t train loss : 0.5558333006854068; train accuracy : 0.9955543852040026; \n",
      " validation loss : 0.6226519684135502; validation accuracy : 0.9288702928870293\n",
      "Epoch 261:\t train loss : 0.5549870444925248; train accuracy : 0.9964388611790947; \n",
      " validation loss : 0.6281269250733534; validation accuracy : 0.9205020920502092\n",
      "Epoch 262:\t train loss : 0.555455183247485; train accuracy : 0.9959608414139224; \n",
      " validation loss : 0.6181459247387715; validation accuracy : 0.9330543933054394\n",
      "Epoch 263:\t train loss : 0.5531129846159175; train accuracy : 0.9983115957743425; \n",
      " validation loss : 0.605793992779098; validation accuracy : 0.9456066945606695\n",
      "Epoch 264:\t train loss : 0.5545129218012741; train accuracy : 0.9968496545741814; \n",
      " validation loss : 0.6058682060981232; validation accuracy : 0.9456066945606695\n",
      "Epoch 265:\t train loss : 0.554206916584262; train accuracy : 0.9972155271228972; \n",
      " validation loss : 0.6053295246275966; validation accuracy : 0.9414225941422594\n",
      "Epoch 266:\t train loss : 0.5559363276977178; train accuracy : 0.9953065460516125; \n",
      " validation loss : 0.6036732727474959; validation accuracy : 0.9456066945606695\n",
      "Epoch 267:\t train loss : 0.553882598326014; train accuracy : 0.9975370984231234; \n",
      " validation loss : 0.6190471235742521; validation accuracy : 0.9288702928870293\n",
      "Epoch 268:\t train loss : 0.5588264566924531; train accuracy : 0.992454227206543; \n",
      " validation loss : 0.6409355659762317; validation accuracy : 0.9079497907949791\n",
      "Epoch 269:\t train loss : 0.5564532726372571; train accuracy : 0.9948883174819542; \n",
      " validation loss : 0.6107546673716776; validation accuracy : 0.9414225941422594\n",
      "Epoch 270:\t train loss : 0.5560497245849926; train accuracy : 0.9953353573530779; \n",
      " validation loss : 0.6016539657114036; validation accuracy : 0.9497907949790795\n",
      "Epoch 271:\t train loss : 0.5542575888565553; train accuracy : 0.9971439635676446; \n",
      " validation loss : 0.6180870667800837; validation accuracy : 0.9330543933054394\n",
      "Epoch 272:\t train loss : 0.5563359235225798; train accuracy : 0.9950159546454351; \n",
      " validation loss : 0.6227137246132602; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273:\t train loss : 0.5546348943510512; train accuracy : 0.9967818086062146; \n",
      " validation loss : 0.6225076257770331; validation accuracy : 0.9288702928870293\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5552002002538218; Train accuracy : 0.9962086805663124; \n",
      " Validation loss : 0.5912796441417915; Validation accuracy : 0.9623430962343096\n",
      "--- Let's train model 91 ! ---\n",
      "Epoch 1:\t train loss : 0.9463918527624192; train accuracy : 0.583292233340562; \n",
      " validation loss : 0.810057766523312; validation accuracy : 0.7322175732217573\n",
      "Epoch 2:\t train loss : 0.7725911512384621; train accuracy : 0.7760001858793643; \n",
      " validation loss : 0.7459184122151247; validation accuracy : 0.8075313807531381\n",
      "Epoch 3:\t train loss : 0.7126130601779527; train accuracy : 0.8371101954831315; \n",
      " validation loss : 0.7156026498897244; validation accuracy : 0.8326359832635983\n",
      "Epoch 4:\t train loss : 0.6927568513466345; train accuracy : 0.8571173208587627; \n",
      " validation loss : 0.6827978595091704; validation accuracy : 0.8577405857740585\n",
      "Epoch 5:\t train loss : 0.6727152019639737; train accuracy : 0.8775432944019331; \n",
      " validation loss : 0.6926536973575184; validation accuracy : 0.8451882845188284\n",
      "Epoch 6:\t train loss : 0.6589114607048117; train accuracy : 0.8909922860063818; \n",
      " validation loss : 0.6855958665462145; validation accuracy : 0.8577405857740585\n",
      "Epoch 7:\t train loss : 0.6476252824185196; train accuracy : 0.9026407261687165; \n",
      " validation loss : 0.6541040811037021; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.6261074800006868; train accuracy : 0.924981566963041; \n",
      " validation loss : 0.6467893404666443; validation accuracy : 0.9037656903765691\n",
      "Epoch 9:\t train loss : 0.6190585413954879; train accuracy : 0.9321689023823538; \n",
      " validation loss : 0.6308709369381269; validation accuracy : 0.9246861924686193\n",
      "Epoch 10:\t train loss : 0.6082828955192238; train accuracy : 0.9428761733634871; \n",
      " validation loss : 0.6650620602707089; validation accuracy : 0.8702928870292888\n",
      "Epoch 11:\t train loss : 0.605966312697089; train accuracy : 0.9451553641686545; \n",
      " validation loss : 0.6185989335549128; validation accuracy : 0.9330543933054394\n",
      "Epoch 12:\t train loss : 0.6021305551071945; train accuracy : 0.9490706031785371; \n",
      " validation loss : 0.629212823035123; validation accuracy : 0.9163179916317992\n",
      "Epoch 13:\t train loss : 0.5991059519805485; train accuracy : 0.9515874097710586; \n",
      " validation loss : 0.6227506193850166; validation accuracy : 0.9163179916317992\n",
      "Epoch 14:\t train loss : 0.5886287614567982; train accuracy : 0.9629960655534558; \n",
      " validation loss : 0.6165326558178983; validation accuracy : 0.9330543933054394\n",
      "Epoch 15:\t train loss : 0.5860451319945976; train accuracy : 0.9656101490132903; \n",
      " validation loss : 0.6144749615680805; validation accuracy : 0.9330543933054394\n",
      "Epoch 16:\t train loss : 0.587109734417907; train accuracy : 0.9642485826698473; \n",
      " validation loss : 0.6381876877360422; validation accuracy : 0.9079497907949791\n",
      "Epoch 17:\t train loss : 0.5898728805161769; train accuracy : 0.9611992316986275; \n",
      " validation loss : 0.6078713758634642; validation accuracy : 0.9456066945606695\n",
      "Epoch 18:\t train loss : 0.5883634330335238; train accuracy : 0.962790978654853; \n",
      " validation loss : 0.6149471802545811; validation accuracy : 0.9414225941422594\n",
      "Epoch 19:\t train loss : 0.5834286864777101; train accuracy : 0.9678156076706218; \n",
      " validation loss : 0.6214424609727076; validation accuracy : 0.9205020920502092\n",
      "Epoch 20:\t train loss : 0.5813812910783306; train accuracy : 0.9697304749217758; \n",
      " validation loss : 0.6155154863459595; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5814000681315948; train accuracy : 0.9698581120852566; \n",
      " validation loss : 0.6132922659778177; validation accuracy : 0.9414225941422594\n",
      "Epoch 22:\t train loss : 0.5812893181912568; train accuracy : 0.969786548530004; \n",
      " validation loss : 0.594321958500393; validation accuracy : 0.9623430962343096\n",
      "Epoch 23:\t train loss : 0.5753864228180834; train accuracy : 0.9760931255615106; \n",
      " validation loss : 0.6141513553319436; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5850529097279435; train accuracy : 0.9659568140276961; \n",
      " validation loss : 0.6275862185367651; validation accuracy : 0.9246861924686193\n",
      "Epoch 25:\t train loss : 0.5812094152137021; train accuracy : 0.9697688899903962; \n",
      " validation loss : 0.6318729968790151; validation accuracy : 0.9205020920502092\n",
      "Epoch 26:\t train loss : 0.5850998807267296; train accuracy : 0.9656987515102698; \n",
      " validation loss : 0.6530141462311462; validation accuracy : 0.891213389121339\n",
      "Epoch 27:\t train loss : 0.5801110806852632; train accuracy : 0.970913597075498; \n",
      " validation loss : 0.6140969007398269; validation accuracy : 0.9372384937238494\n",
      "Epoch 28:\t train loss : 0.5725077903175966; train accuracy : 0.9786217045137706; \n",
      " validation loss : 0.6179129171380017; validation accuracy : 0.9288702928870293\n",
      "Epoch 29:\t train loss : 0.5778492165076784; train accuracy : 0.9732312029492859; \n",
      " validation loss : 0.6095559427589224; validation accuracy : 0.9372384937238494\n",
      "Epoch 30:\t train loss : 0.5762474074198989; train accuracy : 0.9751423526131541; \n",
      " validation loss : 0.6111613672099618; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5775911832133902; train accuracy : 0.9734111961337092; \n",
      " validation loss : 0.6379376277652856; validation accuracy : 0.9163179916317992\n",
      "Epoch 32:\t train loss : 0.5836405100048002; train accuracy : 0.9672926670590787; \n",
      " validation loss : 0.6021460027731065; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.5686583438033088; train accuracy : 0.9828253663372472; \n",
      " validation loss : 0.6003033930135023; validation accuracy : 0.9539748953974896\n",
      "Epoch 34:\t train loss : 0.5692448319752114; train accuracy : 0.982178506149509; \n",
      " validation loss : 0.5860888327805317; validation accuracy : 0.9665271966527197\n",
      "Epoch 35:\t train loss : 0.5740924394693216; train accuracy : 0.9767784008178693; \n",
      " validation loss : 0.6119396648117601; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.5703693619522568; train accuracy : 0.981115585984696; \n",
      " validation loss : 0.6148537008464061; validation accuracy : 0.9330543933054394\n",
      "Epoch 37:\t train loss : 0.5699821667007041; train accuracy : 0.9810632299637535; \n",
      " validation loss : 0.6218399305213198; validation accuracy : 0.9246861924686193\n",
      "Epoch 38:\t train loss : 0.618160792767156; train accuracy : 0.9321032250069705; \n",
      " validation loss : 0.6237591236118522; validation accuracy : 0.9205020920502092\n",
      "Epoch 39:\t train loss : 0.5763320617138701; train accuracy : 0.9744254778648657; \n",
      " validation loss : 0.5941758930815922; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.5692496191331067; train accuracy : 0.9820353790390037; \n",
      " validation loss : 0.601800340470397; validation accuracy : 0.9497907949790795\n",
      "Epoch 41:\t train loss : 0.5801233853919464; train accuracy : 0.9707992812664581; \n",
      " validation loss : 0.5987574684696992; validation accuracy : 0.9497907949790795\n",
      "Epoch 42:\t train loss : 0.5729235129440461; train accuracy : 0.9780758387806314; \n",
      " validation loss : 0.6111321557257264; validation accuracy : 0.9414225941422594\n",
      "Epoch 43:\t train loss : 0.5700583874944182; train accuracy : 0.9809916664085009; \n",
      " validation loss : 0.6280020411330406; validation accuracy : 0.9205020920502092\n",
      "Epoch 44:\t train loss : 0.5670596841045497; train accuracy : 0.9841014281731156; \n",
      " validation loss : 0.5939266959042219; validation accuracy : 0.9581589958158996\n",
      "Epoch 45:\t train loss : 0.5665402541872931; train accuracy : 0.984891415471359; \n",
      " validation loss : 0.5970744724033947; validation accuracy : 0.9539748953974896\n",
      "Epoch 46:\t train loss : 0.5680960944773163; train accuracy : 0.9829647758604666; \n",
      " validation loss : 0.593131357308947; validation accuracy : 0.9623430962343096\n",
      "Epoch 47:\t train loss : 0.5688953341195169; train accuracy : 0.9821496948480436; \n",
      " validation loss : 0.6001288763326893; validation accuracy : 0.9539748953974896\n",
      "Epoch 48:\t train loss : 0.5662438065462517; train accuracy : 0.9850655224759132; \n",
      " validation loss : 0.5816723577904396; validation accuracy : 0.9665271966527197\n",
      "Epoch 49:\t train loss : 0.5696165497876383; train accuracy : 0.9814098949781592; \n",
      " validation loss : 0.6151740141968217; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50:\t train loss : 0.5670709633266984; train accuracy : 0.9841633879612132; \n",
      " validation loss : 0.6107912801804751; validation accuracy : 0.9330543933054394\n",
      "Epoch 51:\t train loss : 0.5664499244051383; train accuracy : 0.9848390594504167; \n",
      " validation loss : 0.6220455457594968; validation accuracy : 0.9288702928870293\n",
      "Epoch 52:\t train loss : 0.5809947767085573; train accuracy : 0.9698949781591747; \n",
      " validation loss : 0.6418221574000869; validation accuracy : 0.9037656903765691\n",
      "Epoch 53:\t train loss : 0.5743096036776263; train accuracy : 0.9767687970507141; \n",
      " validation loss : 0.5936596757845249; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5672266922907536; train accuracy : 0.983992998543945; \n",
      " validation loss : 0.6024689796608499; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.5666601038709381; train accuracy : 0.9847461197682704; \n",
      " validation loss : 0.5971060492377506; validation accuracy : 0.9539748953974896\n",
      "Epoch 56:\t train loss : 0.5636723454639396; train accuracy : 0.9876272499148053; \n",
      " validation loss : 0.6074352705023587; validation accuracy : 0.9456066945606695\n",
      "Epoch 57:\t train loss : 0.5695662285976293; train accuracy : 0.9816636203104185; \n",
      " validation loss : 0.5843574098099792; validation accuracy : 0.9623430962343096\n",
      "Epoch 58:\t train loss : 0.5779481044546678; train accuracy : 0.9730357198178382; \n",
      " validation loss : 0.627023314540121; validation accuracy : 0.9205020920502092\n",
      "Epoch 59:\t train loss : 0.5724998592899343; train accuracy : 0.9785169924718857; \n",
      " validation loss : 0.592695929390894; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5676950466952211; train accuracy : 0.9834604541652467; \n",
      " validation loss : 0.577733574323398; validation accuracy : 0.9748953974895398\n",
      "Epoch 61:\t train loss : 0.567002268477619; train accuracy : 0.9842504414634902; \n",
      " validation loss : 0.6320103933527232; validation accuracy : 0.9163179916317992\n",
      "Epoch 62:\t train loss : 0.5684583097622893; train accuracy : 0.9827324266551009; \n",
      " validation loss : 0.5897728121227273; validation accuracy : 0.9623430962343096\n",
      "Epoch 63:\t train loss : 0.565139421933102; train accuracy : 0.9861925710214071; \n",
      " validation loss : 0.5976245732240965; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5712490646261253; train accuracy : 0.9797193221599182; \n",
      " validation loss : 0.5963476968719664; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.5718636625701269; train accuracy : 0.9792258124477214; \n",
      " validation loss : 0.6001732345959013; validation accuracy : 0.9539748953974896\n",
      "Epoch 66:\t train loss : 0.5779560359262503; train accuracy : 0.9729347253632392; \n",
      " validation loss : 0.6393869020333177; validation accuracy : 0.9121338912133892\n",
      "Epoch 67:\t train loss : 0.5703772111602866; train accuracy : 0.980763034790421; \n",
      " validation loss : 0.6046017899162714; validation accuracy : 0.9497907949790795\n",
      "Epoch 68:\t train loss : 0.5713861204865133; train accuracy : 0.9795975711763065; \n",
      " validation loss : 0.6118645220058877; validation accuracy : 0.9414225941422594\n",
      "Epoch 69:\t train loss : 0.5659757611634727; train accuracy : 0.9852476842529199; \n",
      " validation loss : 0.6103901392917543; validation accuracy : 0.9414225941422594\n",
      "Epoch 70:\t train loss : 0.5733225204119073; train accuracy : 0.9777660398401438; \n",
      " validation loss : 0.6160587008658793; validation accuracy : 0.9372384937238494\n",
      "Epoch 71:\t train loss : 0.5662139562112622; train accuracy : 0.9851253136714272; \n",
      " validation loss : 0.5996780205562542; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5671461938016078; train accuracy : 0.9841729917283683; \n",
      " validation loss : 0.6048521633855966; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5664671904072309; train accuracy : 0.9847829858421884; \n",
      " validation loss : 0.6128647670811792; validation accuracy : 0.9414225941422594\n",
      "Epoch 74:\t train loss : 0.5624446376279543; train accuracy : 0.9888568419096007; \n",
      " validation loss : 0.611266961454278; validation accuracy : 0.9414225941422594\n",
      "Epoch 75:\t train loss : 0.5624736202562295; train accuracy : 0.9888199758356826; \n",
      " validation loss : 0.6044415015583715; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5630917328814031; train accuracy : 0.9881752842405279; \n",
      " validation loss : 0.6137359005479908; validation accuracy : 0.9372384937238494\n",
      "Epoch 77:\t train loss : 0.5667234826414632; train accuracy : 0.9845506366368227; \n",
      " validation loss : 0.6104655425486855; validation accuracy : 0.9330543933054394\n",
      "Epoch 78:\t train loss : 0.5655767542522876; train accuracy : 0.9856076706217665; \n",
      " validation loss : 0.6098241144420984; validation accuracy : 0.9372384937238494\n",
      "Epoch 79:\t train loss : 0.5714950534625958; train accuracy : 0.9795201214411847; \n",
      " validation loss : 0.619684875543252; validation accuracy : 0.9330543933054394\n",
      "Epoch 80:\t train loss : 0.5691015597583007; train accuracy : 0.9822057684562718; \n",
      " validation loss : 0.6268085455354993; validation accuracy : 0.9205020920502092\n",
      "Epoch 81:\t train loss : 0.566808806203399; train accuracy : 0.9842349515164658; \n",
      " validation loss : 0.605295563924035; validation accuracy : 0.9456066945606695\n",
      "Epoch 82:\t train loss : 0.5671321666105699; train accuracy : 0.9841398432417361; \n",
      " validation loss : 0.6258991758104632; validation accuracy : 0.9246861924686193\n",
      "Epoch 83:\t train loss : 0.580975847658735; train accuracy : 0.9700520462220019; \n",
      " validation loss : 0.6100038331647266; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5694450653581742; train accuracy : 0.9817042039716224; \n",
      " validation loss : 0.6216987887869727; validation accuracy : 0.9288702928870293\n",
      "Epoch 85:\t train loss : 0.5607384174425873; train accuracy : 0.9905548499024134; \n",
      " validation loss : 0.6068833892095991; validation accuracy : 0.9414225941422594\n",
      "Epoch 86:\t train loss : 0.5624567141087118; train accuracy : 0.9888701632640416; \n",
      " validation loss : 0.601705284793468; validation accuracy : 0.9497907949790795\n",
      "Epoch 87:\t train loss : 0.5662763746649155; train accuracy : 0.9847984757892128; \n",
      " validation loss : 0.5941473018329037; validation accuracy : 0.9581589958158996\n",
      "Epoch 88:\t train loss : 0.5660505960440232; train accuracy : 0.9849784689736361; \n",
      " validation loss : 0.6217568348740585; validation accuracy : 0.9246861924686193\n",
      "Epoch 89:\t train loss : 0.5640623738529663; train accuracy : 0.987245887419065; \n",
      " validation loss : 0.6217962119359476; validation accuracy : 0.9288702928870293\n",
      "Epoch 90:\t train loss : 0.5639814594454398; train accuracy : 0.9873019610272933; \n",
      " validation loss : 0.6439755809885006; validation accuracy : 0.9037656903765691\n",
      "Epoch 91:\t train loss : 0.5617238407733443; train accuracy : 0.9896970166362031; \n",
      " validation loss : 0.6132159539118515; validation accuracy : 0.9372384937238494\n",
      "Epoch 92:\t train loss : 0.5605984511464066; train accuracy : 0.9907466154465752; \n",
      " validation loss : 0.5974093839228976; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5596464944500696; train accuracy : 0.9916642399082995; \n",
      " validation loss : 0.6331262503477139; validation accuracy : 0.9163179916317992\n",
      "Epoch 94:\t train loss : 0.5653703677194638; train accuracy : 0.9858613959540259; \n",
      " validation loss : 0.6031565272126806; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5621284624192899; train accuracy : 0.9890678149880727; \n",
      " validation loss : 0.595358001440904; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5683655189516442; train accuracy : 0.9829551720933114; \n",
      " validation loss : 0.6062785402855357; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.560845736603712; train accuracy : 0.9905452461352582; \n",
      " validation loss : 0.6064058003869444; validation accuracy : 0.9456066945606695\n",
      "Epoch 98:\t train loss : 0.561233244016293; train accuracy : 0.9901270175656; \n",
      " validation loss : 0.5925767113125275; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5635682766790008; train accuracy : 0.9876774373431643; \n",
      " validation loss : 0.6129923403007028; validation accuracy : 0.9372384937238494\n",
      "Epoch 100:\t train loss : 0.570266733124943; train accuracy : 0.9807748071501595; \n",
      " validation loss : 0.6010974657668143; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101:\t train loss : 0.5644213866134714; train accuracy : 0.986883732457635; \n",
      " validation loss : 0.6014730783156997; validation accuracy : 0.9497907949790795\n",
      "Epoch 102:\t train loss : 0.5716997450106778; train accuracy : 0.9795414975680783; \n",
      " validation loss : 0.5960987260626361; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5709072690137215; train accuracy : 0.9800291211004059; \n",
      " validation loss : 0.6116309119903459; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.5763315278880365; train accuracy : 0.9745906007001456; \n",
      " validation loss : 0.6271975519733901; validation accuracy : 0.9205020920502092\n",
      "Epoch 105:\t train loss : 0.5639393831107; train accuracy : 0.9872923572601382; \n",
      " validation loss : 0.6085636764894429; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.5615676404061957; train accuracy : 0.9897707487840391; \n",
      " validation loss : 0.5996963275275435; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5602408898761246; train accuracy : 0.9910815081012423; \n",
      " validation loss : 0.5901330159345106; validation accuracy : 0.9623430962343096\n",
      "Epoch 108:\t train loss : 0.5603752559779301; train accuracy : 0.9909324948108678; \n",
      " validation loss : 0.6002849113155764; validation accuracy : 0.9539748953974896\n",
      "Epoch 109:\t train loss : 0.5627631125424678; train accuracy : 0.9884850831810155; \n",
      " validation loss : 0.599710039965382; validation accuracy : 0.9497907949790795\n",
      "Epoch 110:\t train loss : 0.5657412717466229; train accuracy : 0.9856482542829703; \n",
      " validation loss : 0.5766977690181673; validation accuracy : 0.9748953974895398\n",
      "Epoch 111:\t train loss : 0.5690283268130837; train accuracy : 0.9820936212398154; \n",
      " validation loss : 0.5977818813545654; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5615039926244392; train accuracy : 0.9897921249109328; \n",
      " validation loss : 0.6156041758696218; validation accuracy : 0.9372384937238494\n",
      "Epoch 113:\t train loss : 0.562445700144432; train accuracy : 0.9887639022274544; \n",
      " validation loss : 0.6000204622910494; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5615024875398874; train accuracy : 0.9897862387310635; \n",
      " validation loss : 0.6010809293075348; validation accuracy : 0.9497907949790795\n",
      "Epoch 115:\t train loss : 0.5586236094553316; train accuracy : 0.992766194739614; \n",
      " validation loss : 0.6109204724872423; validation accuracy : 0.9414225941422594\n",
      "Epoch 116:\t train loss : 0.558957202815663; train accuracy : 0.9923730598841352; \n",
      " validation loss : 0.598838788372293; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5603168997927819; train accuracy : 0.9909420985780228; \n",
      " validation loss : 0.5826418061193317; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5591424686494342; train accuracy : 0.9922491403079401; \n",
      " validation loss : 0.605497534443989; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5625821433415031; train accuracy : 0.9887948821215031; \n",
      " validation loss : 0.5982489498841946; validation accuracy : 0.9539748953974896\n",
      "Epoch 120:\t train loss : 0.562895874879982; train accuracy : 0.9884172372130487; \n",
      " validation loss : 0.5930174063855198; validation accuracy : 0.9581589958158996\n",
      "Epoch 121:\t train loss : 0.5655282198406785; train accuracy : 0.9857898323987732; \n",
      " validation loss : 0.5882983116093826; validation accuracy : 0.9623430962343096\n",
      "Epoch 122:\t train loss : 0.561551646203888; train accuracy : 0.9897493726571455; \n",
      " validation loss : 0.5870876737895137; validation accuracy : 0.9665271966527197\n",
      "Epoch 123:\t train loss : 0.5638409492096371; train accuracy : 0.9873949007094396; \n",
      " validation loss : 0.6023689942024832; validation accuracy : 0.9497907949790795\n",
      "Epoch 124:\t train loss : 0.5640876329594526; train accuracy : 0.9870813841816661; \n",
      " validation loss : 0.5974459705028474; validation accuracy : 0.9539748953974896\n",
      "Epoch 125:\t train loss : 0.5605345634207597; train accuracy : 0.9907621053935995; \n",
      " validation loss : 0.599387421659416; validation accuracy : 0.9456066945606695\n",
      "Epoch 126:\t train loss : 0.5583204312784955; train accuracy : 0.9930081477121349; \n",
      " validation loss : 0.5991596941850641; validation accuracy : 0.9497907949790795\n",
      "Epoch 127:\t train loss : 0.5587635874667604; train accuracy : 0.9925183555872239; \n",
      " validation loss : 0.5886382316249349; validation accuracy : 0.9581589958158996\n",
      "Epoch 128:\t train loss : 0.557421859014508; train accuracy : 0.9938504910313206; \n",
      " validation loss : 0.6060353104209498; validation accuracy : 0.9456066945606695\n",
      "Epoch 129:\t train loss : 0.558315422106785; train accuracy : 0.9930605037330772; \n",
      " validation loss : 0.6082033726463766; validation accuracy : 0.9414225941422594\n",
      "Epoch 130:\t train loss : 0.5588958737700683; train accuracy : 0.9924446234393879; \n",
      " validation loss : 0.5906251785874169; validation accuracy : 0.9581589958158996\n",
      "Epoch 131:\t train loss : 0.5574322475131911; train accuracy : 0.9938969608723938; \n",
      " validation loss : 0.5980052734867989; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5565878316747094; train accuracy : 0.9948883174819542; \n",
      " validation loss : 0.5907400822358116; validation accuracy : 0.9581589958158996\n",
      "Epoch 133:\t train loss : 0.5609187076179294; train accuracy : 0.9903032931627374; \n",
      " validation loss : 0.6017868725316207; validation accuracy : 0.9497907949790795\n",
      "Epoch 134:\t train loss : 0.5599319404495977; train accuracy : 0.9913426686080734; \n",
      " validation loss : 0.6101559862667566; validation accuracy : 0.9372384937238494\n",
      "Epoch 135:\t train loss : 0.5708683511574424; train accuracy : 0.9801589268564701; \n",
      " validation loss : 0.5876445656865552; validation accuracy : 0.9623430962343096\n",
      "Epoch 136:\t train loss : 0.5598980568810783; train accuracy : 0.9913042535394528; \n",
      " validation loss : 0.6024813274142016; validation accuracy : 0.9456066945606695\n",
      "Epoch 137:\t train loss : 0.5586538434203654; train accuracy : 0.9926887450044921; \n",
      " validation loss : 0.591619757562568; validation accuracy : 0.9581589958158996\n",
      "Epoch 138:\t train loss : 0.5606007181416857; train accuracy : 0.9907525016264445; \n",
      " validation loss : 0.6203973494735607; validation accuracy : 0.9288702928870293\n",
      "Epoch 139:\t train loss : 0.5654702937510682; train accuracy : 0.9855884630874563; \n",
      " validation loss : 0.6038159148819103; validation accuracy : 0.9497907949790795\n",
      "Epoch 140:\t train loss : 0.5644652536817645; train accuracy : 0.9867133430403668; \n",
      " validation loss : 0.6064811546157665; validation accuracy : 0.9414225941422594\n",
      "Epoch 141:\t train loss : 0.5605441811369426; train accuracy : 0.9907060317853713; \n",
      " validation loss : 0.5870178628148776; validation accuracy : 0.9665271966527197\n",
      "Epoch 142:\t train loss : 0.5564132903608783; train accuracy : 0.9949657672170761; \n",
      " validation loss : 0.5802204106937536; validation accuracy : 0.9707112970711297\n",
      "Epoch 143:\t train loss : 0.5578684154068495; train accuracy : 0.9935871619319062; \n",
      " validation loss : 0.6049700900861122; validation accuracy : 0.9456066945606695\n",
      "Epoch 144:\t train loss : 0.5558305906841645; train accuracy : 0.9955853650980514; \n",
      " validation loss : 0.5974867380539177; validation accuracy : 0.9539748953974896\n",
      "Epoch 145:\t train loss : 0.5604019990412147; train accuracy : 0.990901514916819; \n",
      " validation loss : 0.6043385526238951; validation accuracy : 0.9456066945606695\n",
      "Epoch 146:\t train loss : 0.5590330607900508; train accuracy : 0.9922742340221197; \n",
      " validation loss : 0.6004432638766447; validation accuracy : 0.9497907949790795\n",
      "Epoch 147:\t train loss : 0.5613328657568762; train accuracy : 0.9899721180953561; \n",
      " validation loss : 0.6031293119809655; validation accuracy : 0.9456066945606695\n",
      "Epoch 148:\t train loss : 0.5604605453057225; train accuracy : 0.9907989714675176; \n",
      " validation loss : 0.6202659347979474; validation accuracy : 0.9288702928870293\n",
      "Epoch 149:\t train loss : 0.5567319837791734; train accuracy : 0.9946714582236129; \n",
      " validation loss : 0.610023344621791; validation accuracy : 0.9414225941422594\n",
      "Epoch 150:\t train loss : 0.5580572158157522; train accuracy : 0.9933083428854673; \n",
      " validation loss : 0.60400686044907; validation accuracy : 0.9456066945606695\n",
      "Epoch 151:\t train loss : 0.5556976171597496; train accuracy : 0.9957092846742464; \n",
      " validation loss : 0.5983147699401015; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152:\t train loss : 0.558034813995575; train accuracy : 0.9932773629914186; \n",
      " validation loss : 0.5851246818993777; validation accuracy : 0.9665271966527197\n",
      "Epoch 153:\t train loss : 0.5572121921636245; train accuracy : 0.9941293100777595; \n",
      " validation loss : 0.609888977731628; validation accuracy : 0.9414225941422594\n",
      "Epoch 154:\t train loss : 0.5583530233211755; train accuracy : 0.9930295238390284; \n",
      " validation loss : 0.6134938092881813; validation accuracy : 0.9372384937238494\n",
      "Epoch 155:\t train loss : 0.5618424587350527; train accuracy : 0.9894919297376003; \n",
      " validation loss : 0.5882467922562348; validation accuracy : 0.9623430962343096\n",
      "Epoch 156:\t train loss : 0.5573151241555512; train accuracy : 0.9940518603426376; \n",
      " validation loss : 0.5986069173934726; validation accuracy : 0.9539748953974896\n",
      "Epoch 157:\t train loss : 0.5589478751996639; train accuracy : 0.9923944360110288; \n",
      " validation loss : 0.6054122729011286; validation accuracy : 0.9456066945606695\n",
      "Epoch 158:\t train loss : 0.558881174188976; train accuracy : 0.9924718857461508; \n",
      " validation loss : 0.5768524154619001; validation accuracy : 0.9748953974895398\n",
      "Epoch 159:\t train loss : 0.5550367386555545; train accuracy : 0.996421822237368; \n",
      " validation loss : 0.6139208658410098; validation accuracy : 0.9372384937238494\n",
      "Epoch 160:\t train loss : 0.5604992917675619; train accuracy : 0.9908454413085908; \n",
      " validation loss : 0.592175011372211; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 160\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5657412717466229; Train accuracy : 0.9856482542829703; \n",
      " Validation loss : 0.5766977690181673; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 92 ! ---\n",
      "Epoch 1:\t train loss : 0.9637162748158209; train accuracy : 0.5636435453390749; \n",
      " validation loss : 0.8476773668764038; validation accuracy : 0.6736401673640168\n",
      "Epoch 2:\t train loss : 0.7738414599131862; train accuracy : 0.7735180767681774; \n",
      " validation loss : 0.766321219865393; validation accuracy : 0.7740585774058577\n",
      "Epoch 3:\t train loss : 0.7085099642458645; train accuracy : 0.8409907370116795; \n",
      " validation loss : 0.692321902460586; validation accuracy : 0.8493723849372385\n",
      "Epoch 4:\t train loss : 0.6792585835647871; train accuracy : 0.8707933950865888; \n",
      " validation loss : 0.686771642896033; validation accuracy : 0.8744769874476988\n",
      "Epoch 5:\t train loss : 0.6590399607786299; train accuracy : 0.8916332600142507; \n",
      " validation loss : 0.6622084928792905; validation accuracy : 0.891213389121339\n",
      "Epoch 6:\t train loss : 0.6510358994597525; train accuracy : 0.8995507915362929; \n",
      " validation loss : 0.6575252166750463; validation accuracy : 0.891213389121339\n",
      "Epoch 7:\t train loss : 0.6405282975024772; train accuracy : 0.9100219957247746; \n",
      " validation loss : 0.6593134247798351; validation accuracy : 0.8870292887029289\n",
      "Epoch 8:\t train loss : 0.628836144320156; train accuracy : 0.9221565104247343; \n",
      " validation loss : 0.6523645621365555; validation accuracy : 0.891213389121339\n",
      "Epoch 9:\t train loss : 0.6168917443979588; train accuracy : 0.9337665355184486; \n",
      " validation loss : 0.6489334949197054; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.609671369129221; train accuracy : 0.9419024752935345; \n",
      " validation loss : 0.6122069501532988; validation accuracy : 0.9372384937238494\n",
      "Epoch 11:\t train loss : 0.5989337779712585; train accuracy : 0.9525403513119985; \n",
      " validation loss : 0.6162939945024162; validation accuracy : 0.9330543933054394\n",
      "Epoch 12:\t train loss : 0.6080476505974373; train accuracy : 0.9426887450044921; \n",
      " validation loss : 0.6278345712879281; validation accuracy : 0.9163179916317992\n",
      "Epoch 13:\t train loss : 0.5997880700492726; train accuracy : 0.951515846215806; \n",
      " validation loss : 0.6259247212860517; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5927705413347206; train accuracy : 0.9588094426717061; \n",
      " validation loss : 0.6201033765801532; validation accuracy : 0.9330543933054394\n",
      "Epoch 15:\t train loss : 0.5940339421439604; train accuracy : 0.9570906781498807; \n",
      " validation loss : 0.6385958038629806; validation accuracy : 0.9079497907949791\n",
      "Epoch 16:\t train loss : 0.5857874825331497; train accuracy : 0.9653136714272437; \n",
      " validation loss : 0.6183069970789407; validation accuracy : 0.9330543933054394\n",
      "Epoch 17:\t train loss : 0.5839502345801865; train accuracy : 0.9675095263174199; \n",
      " validation loss : 0.6186872506399306; validation accuracy : 0.9288702928870293\n",
      "Epoch 18:\t train loss : 0.5836583245499339; train accuracy : 0.9673952105083801; \n",
      " validation loss : 0.6178450191278512; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.595927738015139; train accuracy : 0.9549877629418507; \n",
      " validation loss : 0.6031115515403253; validation accuracy : 0.9456066945606695\n",
      "Epoch 20:\t train loss : 0.5821331925914385; train accuracy : 0.9690953870937762; \n",
      " validation loss : 0.5910623257640906; validation accuracy : 0.9581589958158996\n",
      "Epoch 21:\t train loss : 0.5788534644200254; train accuracy : 0.9724390470584591; \n",
      " validation loss : 0.5900803791937704; validation accuracy : 0.9623430962343096\n",
      "Epoch 22:\t train loss : 0.5774045280172545; train accuracy : 0.9738294247033675; \n",
      " validation loss : 0.5915225519922737; validation accuracy : 0.9539748953974896\n",
      "Epoch 23:\t train loss : 0.5763921673255388; train accuracy : 0.9745825459276929; \n",
      " validation loss : 0.5891541789008691; validation accuracy : 0.9623430962343096\n",
      "Epoch 24:\t train loss : 0.577775201933949; train accuracy : 0.9734015923665541; \n",
      " validation loss : 0.6189621804586645; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.572658645434503; train accuracy : 0.9784166176151677; \n",
      " validation loss : 0.5952768123632318; validation accuracy : 0.9581589958158996\n",
      "Epoch 26:\t train loss : 0.5686100784419215; train accuracy : 0.9830171318814089; \n",
      " validation loss : 0.5881403889653743; validation accuracy : 0.9623430962343096\n",
      "Epoch 27:\t train loss : 0.5741640137294519; train accuracy : 0.9769274141082438; \n",
      " validation loss : 0.6163360886107341; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5770671434246167; train accuracy : 0.9740462839617089; \n",
      " validation loss : 0.5966476313680302; validation accuracy : 0.9581589958158996\n",
      "Epoch 29:\t train loss : 0.5725664382702176; train accuracy : 0.9789005235602094; \n",
      " validation loss : 0.605071821122293; validation accuracy : 0.9456066945606695\n",
      "Epoch 30:\t train loss : 0.5699588432935354; train accuracy : 0.9813693113169553; \n",
      " validation loss : 0.6006627563564885; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5734978456643547; train accuracy : 0.9775123145078843; \n",
      " validation loss : 0.5936342197857765; validation accuracy : 0.9539748953974896\n",
      "Epoch 32:\t train loss : 0.5649637085930911; train accuracy : 0.9864655038879767; \n",
      " validation loss : 0.600089442360629; validation accuracy : 0.9456066945606695\n",
      "Epoch 33:\t train loss : 0.5715332339207988; train accuracy : 0.9796750209114284; \n",
      " validation loss : 0.6037859301402138; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5738008316665753; train accuracy : 0.9771383871867159; \n",
      " validation loss : 0.6008955496320284; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.575223374684956; train accuracy : 0.9759456612658385; \n",
      " validation loss : 0.6133446292316108; validation accuracy : 0.9330543933054394\n",
      "Epoch 36:\t train loss : 0.5710209567723845; train accuracy : 0.9801957929303882; \n",
      " validation loss : 0.5919501371458693; validation accuracy : 0.9581589958158996\n",
      "Epoch 37:\t train loss : 0.5697096852359743; train accuracy : 0.9815743982155581; \n",
      " validation loss : 0.5810808158134045; validation accuracy : 0.9707112970711297\n",
      "Epoch 38:\t train loss : 0.5695835498198959; train accuracy : 0.9815706806282722; \n",
      " validation loss : 0.5942136767304228; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5659311947875707; train accuracy : 0.9853229653954584; \n",
      " validation loss : 0.5961684171076751; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.5680361864555424; train accuracy : 0.9831661451717835; \n",
      " validation loss : 0.6089173491248916; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5668807074593465; train accuracy : 0.9845292605099291; \n",
      " validation loss : 0.6021827589788177; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:\t train loss : 0.566714495557299; train accuracy : 0.9845447504569534; \n",
      " validation loss : 0.5917446700035441; validation accuracy : 0.9581589958158996\n",
      "Epoch 43:\t train loss : 0.567956165006235; train accuracy : 0.9833018371077171; \n",
      " validation loss : 0.5878609136811893; validation accuracy : 0.9623430962343096\n",
      "Epoch 44:\t train loss : 0.5626281076571743; train accuracy : 0.9885817404504477; \n",
      " validation loss : 0.6062066089013239; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.565550602509425; train accuracy : 0.9857743424517488; \n",
      " validation loss : 0.6166632582987687; validation accuracy : 0.9288702928870293\n",
      "Epoch 46:\t train loss : 0.5695582222896153; train accuracy : 0.9817565599925648; \n",
      " validation loss : 0.614276573188247; validation accuracy : 0.9330543933054394\n",
      "Epoch 47:\t train loss : 0.5688159083849412; train accuracy : 0.9822618420645002; \n",
      " validation loss : 0.6022546646656236; validation accuracy : 0.9497907949790795\n",
      "Epoch 48:\t train loss : 0.5647536762771053; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.5953329273553964; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5722326599847052; train accuracy : 0.9787920939310387; \n",
      " validation loss : 0.5996020301523869; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.5758873846529677; train accuracy : 0.9751423526131541; \n",
      " validation loss : 0.6012620868291844; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5688267451708732; train accuracy : 0.9822949905511323; \n",
      " validation loss : 0.6123788857899778; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.566367578887024; train accuracy : 0.9848833606989064; \n",
      " validation loss : 0.6038468518987087; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5664725760636609; train accuracy : 0.9846494624988382; \n",
      " validation loss : 0.599867620516633; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.563655327160551; train accuracy : 0.9875962700207566; \n",
      " validation loss : 0.6007123866908191; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.5619181753025114; train accuracy : 0.9894860435577311; \n",
      " validation loss : 0.5830263282489545; validation accuracy : 0.9665271966527197\n",
      "Epoch 56:\t train loss : 0.5639856350512703; train accuracy : 0.9872709811332445; \n",
      " validation loss : 0.6108405797469113; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5644790046496374; train accuracy : 0.98675981288144; \n",
      " validation loss : 0.5898695691583585; validation accuracy : 0.9623430962343096\n",
      "Epoch 58:\t train loss : 0.560726797015469; train accuracy : 0.9906477895845596; \n",
      " validation loss : 0.5801183281551231; validation accuracy : 0.9665271966527197\n",
      "Epoch 59:\t train loss : 0.5637676871941173; train accuracy : 0.9874376529632268; \n",
      " validation loss : 0.5998260233801124; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5644240357959966; train accuracy : 0.98700765203383; \n",
      " validation loss : 0.6112571261089228; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5672453726509491; train accuracy : 0.9838631927878807; \n",
      " validation loss : 0.5961187700813967; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5695847312591515; train accuracy : 0.9813287276557514; \n",
      " validation loss : 0.6017355668290226; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5668505033679797; train accuracy : 0.9843551535053751; \n",
      " validation loss : 0.5854893499917336; validation accuracy : 0.9665271966527197\n",
      "Epoch 64:\t train loss : 0.5811313958242248; train accuracy : 0.9697614548158245; \n",
      " validation loss : 0.6318590764963569; validation accuracy : 0.9163179916317992\n",
      "Epoch 65:\t train loss : 0.5666162378783599; train accuracy : 0.9844865082561418; \n",
      " validation loss : 0.6094240312710639; validation accuracy : 0.9372384937238494\n",
      "Epoch 66:\t train loss : 0.5622294431448834; train accuracy : 0.9890427212738933; \n",
      " validation loss : 0.5964218100208213; validation accuracy : 0.9497907949790795\n",
      "Epoch 67:\t train loss : 0.5615622248606188; train accuracy : 0.9896601505622851; \n",
      " validation loss : 0.6063379323250625; validation accuracy : 0.9414225941422594\n",
      "Epoch 68:\t train loss : 0.5662343133499375; train accuracy : 0.984867870751882; \n",
      " validation loss : 0.6058746746299936; validation accuracy : 0.9414225941422594\n",
      "Epoch 69:\t train loss : 0.5665251792859397; train accuracy : 0.9846745562130178; \n",
      " validation loss : 0.5691971730222298; validation accuracy : 0.9832635983263598\n",
      "Epoch 70:\t train loss : 0.5639760902825574; train accuracy : 0.9872186251123021; \n",
      " validation loss : 0.5930033312946118; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5663665959966795; train accuracy : 0.984831004677964; \n",
      " validation loss : 0.5996688051085051; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5625684855094257; train accuracy : 0.9886901700796183; \n",
      " validation loss : 0.5992643550136963; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5629763994750053; train accuracy : 0.988299203816723; \n",
      " validation loss : 0.5989205030958082; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.5610761536543044; train accuracy : 0.9902199572477463; \n",
      " validation loss : 0.5821179960909051; validation accuracy : 0.9707112970711297\n",
      "Epoch 75:\t train loss : 0.5655914022509593; train accuracy : 0.9855729731404319; \n",
      " validation loss : 0.6000438986405155; validation accuracy : 0.9497907949790795\n",
      "Epoch 76:\t train loss : 0.5616634576648929; train accuracy : 0.9895111372719105; \n",
      " validation loss : 0.5965389248467468; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5607499386413701; train accuracy : 0.9905644536695685; \n",
      " validation loss : 0.5918885422659045; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5642600483787182; train accuracy : 0.9870600080547725; \n",
      " validation loss : 0.5940750834092929; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5646971112029924; train accuracy : 0.9864013755072958; \n",
      " validation loss : 0.5883613703034338; validation accuracy : 0.9623430962343096\n",
      "Epoch 80:\t train loss : 0.5632481482952786; train accuracy : 0.9880299885374392; \n",
      " validation loss : 0.5932347355233302; validation accuracy : 0.9581589958158996\n",
      "Epoch 81:\t train loss : 0.563423305235147; train accuracy : 0.9878633167074569; \n",
      " validation loss : 0.5933805535424131; validation accuracy : 0.9581589958158996\n",
      "Epoch 82:\t train loss : 0.5609655050805624; train accuracy : 0.9903903466650144; \n",
      " validation loss : 0.6105020687100645; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5642822015231667; train accuracy : 0.9870172558009852; \n",
      " validation loss : 0.6063465524637507; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.566673276832247; train accuracy : 0.9844267170606277; \n",
      " validation loss : 0.5882109111410904; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.563915730885705; train accuracy : 0.9873078472071626; \n",
      " validation loss : 0.5921292975651883; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5620919884848068; train accuracy : 0.9892035069240063; \n",
      " validation loss : 0.6038041333175309; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.5624915685184694; train accuracy : 0.9888317481954212; \n",
      " validation loss : 0.5996020349348573; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.564908740198837; train accuracy : 0.9862582483967904; \n",
      " validation loss : 0.5943723494752234; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5709276520919228; train accuracy : 0.9801146256079805; \n",
      " validation loss : 0.5918546895573525; validation accuracy : 0.9581589958158996\n",
      "Epoch 90:\t train loss : 0.5602906847133893; train accuracy : 0.9909693608847858; \n",
      " validation loss : 0.5850450079961109; validation accuracy : 0.9665271966527197\n",
      "Epoch 91:\t train loss : 0.5616898126436104; train accuracy : 0.9895287958115183; \n",
      " validation loss : 0.5927177203686452; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5604607439816615; train accuracy : 0.9909052325041048; \n",
      " validation loss : 0.5900013637762654; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93:\t train loss : 0.5694180097597906; train accuracy : 0.9816577341305492; \n",
      " validation loss : 0.6180676564796683; validation accuracy : 0.9330543933054394\n",
      "Epoch 94:\t train loss : 0.5672824216188127; train accuracy : 0.983992998543945; \n",
      " validation loss : 0.6049075959597322; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5652105404661045; train accuracy : 0.9859270733294092; \n",
      " validation loss : 0.6252432636904565; validation accuracy : 0.9246861924686193\n",
      "Epoch 96:\t train loss : 0.5642888093567208; train accuracy : 0.9870364633352954; \n",
      " validation loss : 0.6098179904680822; validation accuracy : 0.9372384937238494\n",
      "Epoch 97:\t train loss : 0.5732016480881224; train accuracy : 0.9780544626537377; \n",
      " validation loss : 0.5952220867953486; validation accuracy : 0.9539748953974896\n",
      "Epoch 98:\t train loss : 0.5611825838476694; train accuracy : 0.9900436816506087; \n",
      " validation loss : 0.5913499983352228; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5602429808437527; train accuracy : 0.9911162055825768; \n",
      " validation loss : 0.592194601774971; validation accuracy : 0.9623430962343096\n",
      "Epoch 100:\t train loss : 0.5631949119426458; train accuracy : 0.988070572198643; \n",
      " validation loss : 0.5912113424633992; validation accuracy : 0.9581589958158996\n",
      "Epoch 101:\t train loss : 0.5618617545446378; train accuracy : 0.9894144800024783; \n",
      " validation loss : 0.5722697888369466; validation accuracy : 0.9790794979079498\n",
      "Epoch 102:\t train loss : 0.5601284375098654; train accuracy : 0.991313857306608; \n",
      " validation loss : 0.6006243749541467; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.5614791029645918; train accuracy : 0.9897397688899904; \n",
      " validation loss : 0.582246721527052; validation accuracy : 0.9707112970711297\n",
      "Epoch 104:\t train loss : 0.5629579335933546; train accuracy : 0.9882697729173766; \n",
      " validation loss : 0.6209225422407241; validation accuracy : 0.9330543933054394\n",
      "Epoch 105:\t train loss : 0.5730643797745998; train accuracy : 0.9779711267387465; \n",
      " validation loss : 0.6067987915762675; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.5595255623050401; train accuracy : 0.9918928715263794; \n",
      " validation loss : 0.5922045307061617; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5587411904022184; train accuracy : 0.9926983487716472; \n",
      " validation loss : 0.583666476518408; validation accuracy : 0.9665271966527197\n",
      "Epoch 108:\t train loss : 0.5576574153453749; train accuracy : 0.9936993091483627; \n",
      " validation loss : 0.5805134946012294; validation accuracy : 0.9707112970711297\n",
      "Epoch 109:\t train loss : 0.5612044608562315; train accuracy : 0.9900650577775024; \n",
      " validation loss : 0.5927905766434415; validation accuracy : 0.9581589958158996\n",
      "Epoch 110:\t train loss : 0.5592719413286508; train accuracy : 0.9920050187428359; \n",
      " validation loss : 0.5905261215851019; validation accuracy : 0.9623430962343096\n",
      "Epoch 111:\t train loss : 0.5652887444775172; train accuracy : 0.9858363022398463; \n",
      " validation loss : 0.595504523415292; validation accuracy : 0.9539748953974896\n",
      "Epoch 112:\t train loss : 0.5599417299110632; train accuracy : 0.9913817032745748; \n",
      " validation loss : 0.5915102119319743; validation accuracy : 0.9623430962343096\n",
      "Epoch 113:\t train loss : 0.5611053057751486; train accuracy : 0.9901270175656; \n",
      " validation loss : 0.5889223689889687; validation accuracy : 0.9623430962343096\n",
      "Epoch 114:\t train loss : 0.5614728554966666; train accuracy : 0.989811332445243; \n",
      " validation loss : 0.6136058008422789; validation accuracy : 0.9330543933054394\n",
      "Epoch 115:\t train loss : 0.5596314874694256; train accuracy : 0.991763065770315; \n",
      " validation loss : 0.5988333847684716; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5586040776515301; train accuracy : 0.9926865764119087; \n",
      " validation loss : 0.5813659425261443; validation accuracy : 0.9707112970711297\n",
      "Epoch 117:\t train loss : 0.5714269150275347; train accuracy : 0.9795377799807925; \n",
      " validation loss : 0.5858148323278967; validation accuracy : 0.9665271966527197\n",
      "Epoch 118:\t train loss : 0.5630823741910552; train accuracy : 0.9881207596270021; \n",
      " validation loss : 0.5897127992408687; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.5625516314680967; train accuracy : 0.9886090027572105; \n",
      " validation loss : 0.5805459790632169; validation accuracy : 0.9707112970711297\n",
      "Early stopping at epoch 119\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5665251792859397; Train accuracy : 0.9846745562130178; \n",
      " Validation loss : 0.5691971730222298; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 93 ! ---\n",
      "Epoch 1:\t train loss : 0.9175853762244044; train accuracy : 0.6105337835744602; \n",
      " validation loss : 0.8241763284189133; validation accuracy : 0.7238493723849372\n",
      "Epoch 2:\t train loss : 0.7481375403883848; train accuracy : 0.8011484246723877; \n",
      " validation loss : 0.7062979244962766; validation accuracy : 0.8410041841004184\n",
      "Epoch 3:\t train loss : 0.6986757094946869; train accuracy : 0.8514309613061123; \n",
      " validation loss : 0.6889824513738984; validation accuracy : 0.8535564853556485\n",
      "Epoch 4:\t train loss : 0.6762518731221726; train accuracy : 0.873391988599399; \n",
      " validation loss : 0.702872207324693; validation accuracy : 0.8368200836820083\n",
      "Epoch 5:\t train loss : 0.6581530644786435; train accuracy : 0.8927971746336627; \n",
      " validation loss : 0.6799704087117909; validation accuracy : 0.8619246861924686\n",
      "Epoch 6:\t train loss : 0.6420300079398803; train accuracy : 0.9086765389262369; \n",
      " validation loss : 0.6603771781304246; validation accuracy : 0.8828451882845189\n",
      "Epoch 7:\t train loss : 0.6284976409760737; train accuracy : 0.9224065181697079; \n",
      " validation loss : 0.6495744850016182; validation accuracy : 0.9163179916317992\n",
      "Epoch 8:\t train loss : 0.6091715313183491; train accuracy : 0.9420226772824437; \n",
      " validation loss : 0.6421012776410133; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.6050024492597766; train accuracy : 0.9466018154217912; \n",
      " validation loss : 0.645797201605849; validation accuracy : 0.899581589958159\n",
      "Epoch 10:\t train loss : 0.5953671380721768; train accuracy : 0.9558434276154776; \n",
      " validation loss : 0.632755766870301; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.587638977757493; train accuracy : 0.9639991945227547; \n",
      " validation loss : 0.6336488128621696; validation accuracy : 0.9205020920502092\n",
      "Epoch 12:\t train loss : 0.5954146221873997; train accuracy : 0.9558397100281917; \n",
      " validation loss : 0.6495900554351449; validation accuracy : 0.895397489539749\n",
      "Epoch 13:\t train loss : 0.5978459845091147; train accuracy : 0.9532219089810713; \n",
      " validation loss : 0.6498266712348251; validation accuracy : 0.9037656903765691\n",
      "Epoch 14:\t train loss : 0.5917941997856542; train accuracy : 0.959538089779733; \n",
      " validation loss : 0.6375820474896824; validation accuracy : 0.9079497907949791\n",
      "Epoch 15:\t train loss : 0.5870027876174133; train accuracy : 0.9644734967006413; \n",
      " validation loss : 0.6206930420658673; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.6021152963821707; train accuracy : 0.9489835496762601; \n",
      " validation loss : 0.6187213866928596; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5959723689404018; train accuracy : 0.9552356020942409; \n",
      " validation loss : 0.6451811903705141; validation accuracy : 0.9037656903765691\n",
      "Epoch 18:\t train loss : 0.5822444216082444; train accuracy : 0.969012051178785; \n",
      " validation loss : 0.6360559756725885; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.5780269901045749; train accuracy : 0.9731633569813192; \n",
      " validation loss : 0.6451525628979701; validation accuracy : 0.9037656903765691\n",
      "Epoch 20:\t train loss : 0.5843043146556928; train accuracy : 0.9668434585953716; \n",
      " validation loss : 0.6377381080229697; validation accuracy : 0.9121338912133892\n",
      "Epoch 21:\t train loss : 0.5846103838183717; train accuracy : 0.9665160011152761; \n",
      " validation loss : 0.6171885066303295; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5806619262254841; train accuracy : 0.9704216363580036; \n",
      " validation loss : 0.6122072177181412; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5737543346379244; train accuracy : 0.9773552464450571; \n",
      " validation loss : 0.6107128042930646; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:\t train loss : 0.5750919816822562; train accuracy : 0.9761742928839183; \n",
      " validation loss : 0.6325963446645662; validation accuracy : 0.9205020920502092\n",
      "Epoch 25:\t train loss : 0.5747582092942126; train accuracy : 0.9765342792527649; \n",
      " validation loss : 0.6198359573771278; validation accuracy : 0.9330543933054394\n",
      "Epoch 26:\t train loss : 0.5836218135619397; train accuracy : 0.9677824591839896; \n",
      " validation loss : 0.633960618700028; validation accuracy : 0.9079497907949791\n",
      "Epoch 27:\t train loss : 0.593638270992554; train accuracy : 0.9572610675671489; \n",
      " validation loss : 0.6341672809732868; validation accuracy : 0.9121338912133892\n",
      "Epoch 28:\t train loss : 0.5768697536777063; train accuracy : 0.974142941231141; \n",
      " validation loss : 0.6295291398181226; validation accuracy : 0.9163179916317992\n",
      "Epoch 29:\t train loss : 0.57731596763775; train accuracy : 0.973754143560829; \n",
      " validation loss : 0.6029812686395969; validation accuracy : 0.9497907949790795\n",
      "Epoch 30:\t train loss : 0.5705225077388623; train accuracy : 0.9810440224294433; \n",
      " validation loss : 0.6050252336941309; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5677226651116855; train accuracy : 0.9835998636884662; \n",
      " validation loss : 0.6143622810738372; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5682261293018065; train accuracy : 0.9830149632888255; \n",
      " validation loss : 0.6094476205980403; validation accuracy : 0.9372384937238494\n",
      "Epoch 33:\t train loss : 0.5676640468138461; train accuracy : 0.9834508503980917; \n",
      " validation loss : 0.6243251534565611; validation accuracy : 0.9205020920502092\n",
      "Epoch 34:\t train loss : 0.5716860294320507; train accuracy : 0.9792022677282444; \n",
      " validation loss : 0.614966136700043; validation accuracy : 0.9330543933054394\n",
      "Epoch 35:\t train loss : 0.5684268757386953; train accuracy : 0.9829145884321075; \n",
      " validation loss : 0.6138252983455191; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.5643329175845552; train accuracy : 0.9869707859599121; \n",
      " validation loss : 0.6262502409258207; validation accuracy : 0.9205020920502092\n",
      "Epoch 37:\t train loss : 0.5841025827872548; train accuracy : 0.9670234517797949; \n",
      " validation loss : 0.6459546783641688; validation accuracy : 0.9037656903765691\n",
      "Epoch 38:\t train loss : 0.5745761813150118; train accuracy : 0.9765150717184548; \n",
      " validation loss : 0.6433050817755165; validation accuracy : 0.9079497907949791\n",
      "Epoch 39:\t train loss : 0.5655336897674216; train accuracy : 0.9856872889494718; \n",
      " validation loss : 0.6065887476468043; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5622960467574494; train accuracy : 0.9891821307971127; \n",
      " validation loss : 0.5976702617984998; validation accuracy : 0.9539748953974896\n",
      "Epoch 41:\t train loss : 0.5662987021746707; train accuracy : 0.9850463149416029; \n",
      " validation loss : 0.6186647054222553; validation accuracy : 0.9330543933054394\n",
      "Epoch 42:\t train loss : 0.572458686042938; train accuracy : 0.9788016976981939; \n",
      " validation loss : 0.6122760558121967; validation accuracy : 0.9372384937238494\n",
      "Epoch 43:\t train loss : 0.569028532175947; train accuracy : 0.9821747885622231; \n",
      " validation loss : 0.6005781591342351; validation accuracy : 0.9497907949790795\n",
      "Epoch 44:\t train loss : 0.5748326463931187; train accuracy : 0.9761935004182286; \n",
      " validation loss : 0.6173689720514975; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5764612689767802; train accuracy : 0.9747978561913319; \n",
      " validation loss : 0.6089101174408186; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5659133595975199; train accuracy : 0.9853716038291149; \n",
      " validation loss : 0.6279580357793056; validation accuracy : 0.9246861924686193\n",
      "Epoch 47:\t train loss : 0.5649342662581776; train accuracy : 0.9862951144707085; \n",
      " validation loss : 0.6201165813625992; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5633974951866171; train accuracy : 0.9877784317977633; \n",
      " validation loss : 0.5966483553732911; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5629936494633974; train accuracy : 0.9881811704203972; \n",
      " validation loss : 0.5961235550075208; validation accuracy : 0.9581589958158996\n",
      "Epoch 50:\t train loss : 0.5635871727900935; train accuracy : 0.9876892097029029; \n",
      " validation loss : 0.594253718660376; validation accuracy : 0.9581589958158996\n",
      "Epoch 51:\t train loss : 0.5605843588067289; train accuracy : 0.9907466154465752; \n",
      " validation loss : 0.6353366288914126; validation accuracy : 0.9163179916317992\n",
      "Epoch 52:\t train loss : 0.5638828868738686; train accuracy : 0.9875305926453731; \n",
      " validation loss : 0.5890778575317737; validation accuracy : 0.9623430962343096\n",
      "Epoch 53:\t train loss : 0.5664130143498171; train accuracy : 0.9847365160011152; \n",
      " validation loss : 0.6210844199800725; validation accuracy : 0.9288702928870293\n",
      "Epoch 54:\t train loss : 0.5619713744459597; train accuracy : 0.989435856129372; \n",
      " validation loss : 0.6131286614732289; validation accuracy : 0.9414225941422594\n",
      "Epoch 55:\t train loss : 0.5728938408317417; train accuracy : 0.9780250317543914; \n",
      " validation loss : 0.6544264659346986; validation accuracy : 0.899581589958159\n",
      "Epoch 56:\t train loss : 0.569660244925898; train accuracy : 0.9815242107871991; \n",
      " validation loss : 0.6116234448056246; validation accuracy : 0.9288702928870293\n",
      "Epoch 57:\t train loss : 0.565055620490964; train accuracy : 0.9861674773072276; \n",
      " validation loss : 0.5979765764628984; validation accuracy : 0.9539748953974896\n",
      "Epoch 58:\t train loss : 0.5641153335500475; train accuracy : 0.9869921620868056; \n",
      " validation loss : 0.6262233452999242; validation accuracy : 0.9246861924686193\n",
      "Epoch 59:\t train loss : 0.5628790180734742; train accuracy : 0.9883515598376653; \n",
      " validation loss : 0.6238523211344447; validation accuracy : 0.9246861924686193\n",
      "Epoch 60:\t train loss : 0.562242078349458; train accuracy : 0.9889342916447226; \n",
      " validation loss : 0.6128725975853451; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.560807847314971; train accuracy : 0.9904309303262183; \n",
      " validation loss : 0.6087666740333793; validation accuracy : 0.9456066945606695\n",
      "Epoch 62:\t train loss : 0.5750022379551084; train accuracy : 0.9760060720592335; \n",
      " validation loss : 0.6071773292732934; validation accuracy : 0.9456066945606695\n",
      "Epoch 63:\t train loss : 0.5605183037101056; train accuracy : 0.9907525016264445; \n",
      " validation loss : 0.6058658674005998; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5621946352682485; train accuracy : 0.9890795873478113; \n",
      " validation loss : 0.6062874233815327; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.5620510507397917; train accuracy : 0.9891511509030639; \n",
      " validation loss : 0.5974691624024405; validation accuracy : 0.9539748953974896\n",
      "Epoch 66:\t train loss : 0.5577285420385487; train accuracy : 0.9937361752222807; \n",
      " validation loss : 0.613593871037492; validation accuracy : 0.9372384937238494\n",
      "Epoch 67:\t train loss : 0.5585544331368373; train accuracy : 0.9927507047925896; \n",
      " validation loss : 0.5986044748182874; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5588084371252019; train accuracy : 0.9925803153753214; \n",
      " validation loss : 0.6225375469749677; validation accuracy : 0.9288702928870293\n",
      "Epoch 69:\t train loss : 0.5594024259456669; train accuracy : 0.9918618916323306; \n",
      " validation loss : 0.591258759469901; validation accuracy : 0.9623430962343096\n",
      "Epoch 70:\t train loss : 0.5624991677376987; train accuracy : 0.9886805663124633; \n",
      " validation loss : 0.6063159325389911; validation accuracy : 0.9456066945606695\n",
      "Epoch 71:\t train loss : 0.5686917544957057; train accuracy : 0.9825310573437839; \n",
      " validation loss : 0.6080868824498261; validation accuracy : 0.9414225941422594\n",
      "Epoch 72:\t train loss : 0.5646944967010485; train accuracy : 0.9863858855602714; \n",
      " validation loss : 0.6430343582657503; validation accuracy : 0.9079497907949791\n",
      "Epoch 73:\t train loss : 0.5615752641247548; train accuracy : 0.9896836952817621; \n",
      " validation loss : 0.6134439980816; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5614089407159172; train accuracy : 0.9898076148579572; \n",
      " validation loss : 0.6097143271403315; validation accuracy : 0.9414225941422594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75:\t train loss : 0.5577075131659291; train accuracy : 0.9935502958579882; \n",
      " validation loss : 0.6100023213480549; validation accuracy : 0.9414225941422594\n",
      "Epoch 76:\t train loss : 0.5559903841842337; train accuracy : 0.9953375259456613; \n",
      " validation loss : 0.6071526080029375; validation accuracy : 0.9414225941422594\n",
      "Epoch 77:\t train loss : 0.5634859728156895; train accuracy : 0.9877260757768208; \n",
      " validation loss : 0.6087164169422195; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.558768279568662; train accuracy : 0.9924814895133058; \n",
      " validation loss : 0.5983773722423478; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5712433747123603; train accuracy : 0.9798358065615416; \n",
      " validation loss : 0.6030904982541795; validation accuracy : 0.9497907949790795\n",
      "Epoch 80:\t train loss : 0.5618833165650406; train accuracy : 0.9894048762353232; \n",
      " validation loss : 0.6133865044642778; validation accuracy : 0.9372384937238494\n",
      "Epoch 81:\t train loss : 0.5589821366811076; train accuracy : 0.9922550264878094; \n",
      " validation loss : 0.5898214571110774; validation accuracy : 0.9623430962343096\n",
      "Epoch 82:\t train loss : 0.5571486691565174; train accuracy : 0.9941602899718083; \n",
      " validation loss : 0.6042480343521848; validation accuracy : 0.9456066945606695\n",
      "Epoch 83:\t train loss : 0.5570404973243123; train accuracy : 0.9943808668174354; \n",
      " validation loss : 0.591807159911786; validation accuracy : 0.9581589958158996\n",
      "Epoch 84:\t train loss : 0.5564004368005543; train accuracy : 0.9949657672170761; \n",
      " validation loss : 0.6034205365633751; validation accuracy : 0.9456066945606695\n",
      "Epoch 85:\t train loss : 0.5592950096461153; train accuracy : 0.9920322810495988; \n",
      " validation loss : 0.6183872102939006; validation accuracy : 0.9330543933054394\n",
      "Epoch 86:\t train loss : 0.5572433309602931; train accuracy : 0.9940828402366864; \n",
      " validation loss : 0.6138178398086362; validation accuracy : 0.9372384937238494\n",
      "Epoch 87:\t train loss : 0.5610165174628314; train accuracy : 0.9901985811208526; \n",
      " validation loss : 0.6138983039828215; validation accuracy : 0.9372384937238494\n",
      "Epoch 88:\t train loss : 0.5608713113800702; train accuracy : 0.99048917252703; \n",
      " validation loss : 0.6101280191897289; validation accuracy : 0.9414225941422594\n",
      "Epoch 89:\t train loss : 0.5585254518667253; train accuracy : 0.9928436444747359; \n",
      " validation loss : 0.5733899184350166; validation accuracy : 0.9790794979079498\n",
      "Epoch 90:\t train loss : 0.5566791579819206; train accuracy : 0.9947120418848168; \n",
      " validation loss : 0.6080635039992297; validation accuracy : 0.9456066945606695\n",
      "Epoch 91:\t train loss : 0.5605188970604054; train accuracy : 0.9906905418383469; \n",
      " validation loss : 0.5945622760887975; validation accuracy : 0.9581589958158996\n",
      "Epoch 92:\t train loss : 0.5602528954894811; train accuracy : 0.9910254344930141; \n",
      " validation loss : 0.6206857021164794; validation accuracy : 0.9288702928870293\n",
      "Epoch 93:\t train loss : 0.5578092857472428; train accuracy : 0.9935967656990613; \n",
      " validation loss : 0.6014984006819907; validation accuracy : 0.9497907949790795\n",
      "Epoch 94:\t train loss : 0.5600676039455117; train accuracy : 0.9912481799312246; \n",
      " validation loss : 0.605113621312479; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5647397300870881; train accuracy : 0.9865525573902537; \n",
      " validation loss : 0.6030984854531947; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5589903666280266; train accuracy : 0.9923420799900864; \n",
      " validation loss : 0.6143902824484806; validation accuracy : 0.9330543933054394\n",
      "Epoch 97:\t train loss : 0.5589229456621989; train accuracy : 0.9924350196722327; \n",
      " validation loss : 0.6127099960765229; validation accuracy : 0.9372384937238494\n",
      "Epoch 98:\t train loss : 0.5560582076473205; train accuracy : 0.9953530158926857; \n",
      " validation loss : 0.5974572561357265; validation accuracy : 0.9539748953974896\n",
      "Epoch 99:\t train loss : 0.5564931730525774; train accuracy : 0.9948573375879054; \n",
      " validation loss : 0.5983514582353049; validation accuracy : 0.9497907949790795\n",
      "Epoch 100:\t train loss : 0.5572683010219444; train accuracy : 0.9941293100777595; \n",
      " validation loss : 0.6173977317228845; validation accuracy : 0.9330543933054394\n",
      "Epoch 101:\t train loss : 0.5615913282475843; train accuracy : 0.989563493292853; \n",
      " validation loss : 0.6804575115700955; validation accuracy : 0.8619246861924686\n",
      "Epoch 102:\t train loss : 0.561525718086983; train accuracy : 0.9897183927630967; \n",
      " validation loss : 0.6064762774278787; validation accuracy : 0.9456066945606695\n",
      "Epoch 103:\t train loss : 0.5722265420173415; train accuracy : 0.9789218996871031; \n",
      " validation loss : 0.5954616832919367; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.5712416031944895; train accuracy : 0.9799789336720468; \n",
      " validation loss : 0.6173126294368203; validation accuracy : 0.9372384937238494\n",
      "Epoch 105:\t train loss : 0.5660568618479892; train accuracy : 0.9849319991325629; \n",
      " validation loss : 0.6169486354214386; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.5587214533719832; train accuracy : 0.992527959354379; \n",
      " validation loss : 0.6025816255520824; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5559335753269401; train accuracy : 0.995445955574832; \n",
      " validation loss : 0.5994817537325219; validation accuracy : 0.9497907949790795\n",
      "Epoch 108:\t train loss : 0.5562444136625224; train accuracy : 0.9950741968462468; \n",
      " validation loss : 0.6049264576740574; validation accuracy : 0.9414225941422594\n",
      "Epoch 109:\t train loss : 0.561991829735671; train accuracy : 0.9892964466061526; \n",
      " validation loss : 0.6015113193494814; validation accuracy : 0.9497907949790795\n",
      "Epoch 110:\t train loss : 0.5667959106396752; train accuracy : 0.9843065150717184; \n",
      " validation loss : 0.6080891988910371; validation accuracy : 0.9456066945606695\n",
      "Epoch 111:\t train loss : 0.5688381562504929; train accuracy : 0.9821806747420924; \n",
      " validation loss : 0.6254306397002949; validation accuracy : 0.9246861924686193\n",
      "Epoch 112:\t train loss : 0.565305845148574; train accuracy : 0.9857647386845937; \n",
      " validation loss : 0.5972967206500832; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.55996802222843; train accuracy : 0.9912828774125593; \n",
      " validation loss : 0.6024113535127146; validation accuracy : 0.9497907949790795\n",
      "Epoch 114:\t train loss : 0.5583110598237603; train accuracy : 0.9929093218501193; \n",
      " validation loss : 0.5976515933779589; validation accuracy : 0.9539748953974896\n",
      "Epoch 115:\t train loss : 0.5571300664392981; train accuracy : 0.9941853836859877; \n",
      " validation loss : 0.6096298434167134; validation accuracy : 0.9414225941422594\n",
      "Epoch 116:\t train loss : 0.5585537495416152; train accuracy : 0.992766194739614; \n",
      " validation loss : 0.5963577681922378; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5568892165394504; train accuracy : 0.9944951826264754; \n",
      " validation loss : 0.5913380193158684; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5558660088639904; train accuracy : 0.9955234053099539; \n",
      " validation loss : 0.6006121578423514; validation accuracy : 0.9497907949790795\n",
      "Epoch 119:\t train loss : 0.5541003689631357; train accuracy : 0.9973202391647821; \n",
      " validation loss : 0.6112106060417185; validation accuracy : 0.9414225941422594\n",
      "Epoch 120:\t train loss : 0.5555846797287843; train accuracy : 0.9958332042504414; \n",
      " validation loss : 0.60271883249577; validation accuracy : 0.9456066945606695\n",
      "Epoch 121:\t train loss : 0.5580181801973952; train accuracy : 0.9932869667585736; \n",
      " validation loss : 0.5892863222328985; validation accuracy : 0.9623430962343096\n",
      "Epoch 122:\t train loss : 0.5614121826807634; train accuracy : 0.9898076148579572; \n",
      " validation loss : 0.5937341571800991; validation accuracy : 0.9539748953974896\n",
      "Epoch 123:\t train loss : 0.5584372943904026; train accuracy : 0.9929093218501193; \n",
      " validation loss : 0.60053882682911; validation accuracy : 0.9497907949790795\n",
      "Epoch 124:\t train loss : 0.5625361481657823; train accuracy : 0.9885684190960067; \n",
      " validation loss : 0.6258551392587994; validation accuracy : 0.9205020920502092\n",
      "Epoch 125:\t train loss : 0.5578147091063568; train accuracy : 0.9935193159639394; \n",
      " validation loss : 0.5800673610937418; validation accuracy : 0.9707112970711297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126:\t train loss : 0.5561644187390227; train accuracy : 0.9951863440627033; \n",
      " validation loss : 0.5932851739865589; validation accuracy : 0.9581589958158996\n",
      "Epoch 127:\t train loss : 0.557356166347047; train accuracy : 0.9939744106075157; \n",
      " validation loss : 0.6006441778312573; validation accuracy : 0.9497907949790795\n",
      "Epoch 128:\t train loss : 0.5550629787730225; train accuracy : 0.9964063322903436; \n",
      " validation loss : 0.6186661490664122; validation accuracy : 0.9330543933054394\n",
      "Epoch 129:\t train loss : 0.560761181818597; train accuracy : 0.9905917159763313; \n",
      " validation loss : 0.5899213273940179; validation accuracy : 0.9623430962343096\n",
      "Epoch 130:\t train loss : 0.5596031624825558; train accuracy : 0.9917128783419561; \n",
      " validation loss : 0.5738663612112531; validation accuracy : 0.9790794979079498\n",
      "Epoch 131:\t train loss : 0.5561575193133791; train accuracy : 0.9952232101366213; \n",
      " validation loss : 0.611496189557453; validation accuracy : 0.9414225941422594\n",
      "Epoch 132:\t train loss : 0.5698779650387382; train accuracy : 0.981198921899687; \n",
      " validation loss : 0.5988340160089698; validation accuracy : 0.9497907949790795\n",
      "Epoch 133:\t train loss : 0.5579789855625584; train accuracy : 0.993416772514638; \n",
      " validation loss : 0.6043169330589385; validation accuracy : 0.9456066945606695\n",
      "Epoch 134:\t train loss : 0.5581608618024383; train accuracy : 0.9932404969175005; \n",
      " validation loss : 0.6023586334401211; validation accuracy : 0.9456066945606695\n",
      "Epoch 135:\t train loss : 0.5587042325590679; train accuracy : 0.9926054090895009; \n",
      " validation loss : 0.6308464182086242; validation accuracy : 0.9163179916317992\n",
      "Epoch 136:\t train loss : 0.56453532482067; train accuracy : 0.9866476656649834; \n",
      " validation loss : 0.5845911740373726; validation accuracy : 0.9665271966527197\n",
      "Epoch 137:\t train loss : 0.5570203309640792; train accuracy : 0.9943616592831253; \n",
      " validation loss : 0.5890867071647088; validation accuracy : 0.9623430962343096\n",
      "Epoch 138:\t train loss : 0.5572451433002185; train accuracy : 0.994067350289662; \n",
      " validation loss : 0.5981021518524801; validation accuracy : 0.9539748953974896\n",
      "Epoch 139:\t train loss : 0.5558776320620806; train accuracy : 0.9954924254159051; \n",
      " validation loss : 0.5935119205071304; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 139\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5585254518667253; Train accuracy : 0.9928436444747359; \n",
      " Validation loss : 0.5733899184350166; Validation accuracy : 0.9790794979079498\n",
      "--- Let's train model 94 ! ---\n",
      "Epoch 1:\t train loss : 0.9108724357529319; train accuracy : 0.625156913163357; \n",
      " validation loss : 0.8200060596986553; validation accuracy : 0.7196652719665272\n",
      "Epoch 2:\t train loss : 0.740092290657549; train accuracy : 0.8093927940766442; \n",
      " validation loss : 0.7356817314053321; validation accuracy : 0.8200836820083682\n",
      "Epoch 3:\t train loss : 0.6868400447193138; train accuracy : 0.8632358499333932; \n",
      " validation loss : 0.7143641283073051; validation accuracy : 0.8368200836820083\n",
      "Epoch 4:\t train loss : 0.6625099644113291; train accuracy : 0.8873035100219957; \n",
      " validation loss : 0.7025174985870221; validation accuracy : 0.8493723849372385\n",
      "Epoch 5:\t train loss : 0.6531215583871006; train accuracy : 0.8976278695126862; \n",
      " validation loss : 0.6922152864916988; validation accuracy : 0.8535564853556485\n",
      "Epoch 6:\t train loss : 0.6366815891452472; train accuracy : 0.9144248582669847; \n",
      " validation loss : 0.6948713985911481; validation accuracy : 0.8535564853556485\n",
      "Epoch 7:\t train loss : 0.6248902449961099; train accuracy : 0.9259478298584218; \n",
      " validation loss : 0.6561169867264894; validation accuracy : 0.891213389121339\n",
      "Epoch 8:\t train loss : 0.6167702375559279; train accuracy : 0.9345174881501905; \n",
      " validation loss : 0.6438973435186163; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.6073921172500042; train accuracy : 0.9439043960469655; \n",
      " validation loss : 0.6489972963257765; validation accuracy : 0.895397489539749\n",
      "Epoch 10:\t train loss : 0.6052409752818454; train accuracy : 0.9457616406951889; \n",
      " validation loss : 0.6295357434620271; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.5942838310462096; train accuracy : 0.9571718454722885; \n",
      " validation loss : 0.6823188526916995; validation accuracy : 0.8619246861924686\n",
      "Epoch 12:\t train loss : 0.5976388867082394; train accuracy : 0.9535877815297872; \n",
      " validation loss : 0.6237985668044626; validation accuracy : 0.9288702928870293\n",
      "Epoch 13:\t train loss : 0.5864441085557801; train accuracy : 0.9650407385606741; \n",
      " validation loss : 0.6359594944085335; validation accuracy : 0.9121338912133892\n",
      "Epoch 14:\t train loss : 0.5856693078847897; train accuracy : 0.9656544502617801; \n",
      " validation loss : 0.6309981050037154; validation accuracy : 0.9205020920502092\n",
      "Epoch 15:\t train loss : 0.584064752752097; train accuracy : 0.9672558009851606; \n",
      " validation loss : 0.6289504319748093; validation accuracy : 0.9205020920502092\n",
      "Epoch 16:\t train loss : 0.5819543687327194; train accuracy : 0.9695040118962793; \n",
      " validation loss : 0.6378448824343479; validation accuracy : 0.9121338912133892\n",
      "Epoch 17:\t train loss : 0.5773201126278019; train accuracy : 0.974330989188017; \n",
      " validation loss : 0.6168876218422106; validation accuracy : 0.9330543933054394\n",
      "Epoch 18:\t train loss : 0.5831715192549073; train accuracy : 0.9676297283063292; \n",
      " validation loss : 0.5975465557984714; validation accuracy : 0.9539748953974896\n",
      "Epoch 19:\t train loss : 0.5830058862903329; train accuracy : 0.9680767681774528; \n",
      " validation loss : 0.621838582313472; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5759887635570187; train accuracy : 0.9755760711298367; \n",
      " validation loss : 0.6209036032113955; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5787131202600363; train accuracy : 0.9724390470584591; \n",
      " validation loss : 0.6369014121790842; validation accuracy : 0.9121338912133892\n",
      "Epoch 22:\t train loss : 0.573610899963418; train accuracy : 0.9776672139781282; \n",
      " validation loss : 0.6102636937293502; validation accuracy : 0.9372384937238494\n",
      "Epoch 23:\t train loss : 0.5767551686563183; train accuracy : 0.9743774590290901; \n",
      " validation loss : 0.6378960239737208; validation accuracy : 0.9079497907949791\n",
      "Epoch 24:\t train loss : 0.5740793983384328; train accuracy : 0.9770689922240466; \n",
      " validation loss : 0.629682955866178; validation accuracy : 0.9163179916317992\n",
      "Epoch 25:\t train loss : 0.5749805662035865; train accuracy : 0.976282722513089; \n",
      " validation loss : 0.6087134758096687; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5729652992001959; train accuracy : 0.9785250472443384; \n",
      " validation loss : 0.6353762121837054; validation accuracy : 0.9163179916317992\n",
      "Epoch 27:\t train loss : 0.5694164542135688; train accuracy : 0.9819616468911676; \n",
      " validation loss : 0.6291560184907514; validation accuracy : 0.9288702928870293\n",
      "Epoch 28:\t train loss : 0.5726039110756771; train accuracy : 0.9787360203228105; \n",
      " validation loss : 0.6046127071466242; validation accuracy : 0.9497907949790795\n",
      "Epoch 29:\t train loss : 0.5762597109562785; train accuracy : 0.9749003996406332; \n",
      " validation loss : 0.6271474199040912; validation accuracy : 0.9246861924686193\n",
      "Epoch 30:\t train loss : 0.5751306867763853; train accuracy : 0.9762207627249915; \n",
      " validation loss : 0.6234733153677285; validation accuracy : 0.9246861924686193\n",
      "Epoch 31:\t train loss : 0.5710504981924487; train accuracy : 0.9801205117878496; \n",
      " validation loss : 0.6147787045919249; validation accuracy : 0.9372384937238494\n",
      "Epoch 32:\t train loss : 0.5680943704257624; train accuracy : 0.9833328170017659; \n",
      " validation loss : 0.6086485321686785; validation accuracy : 0.9414225941422594\n",
      "Epoch 33:\t train loss : 0.5694254540363056; train accuracy : 0.9817255800985161; \n",
      " validation loss : 0.6142438603174478; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.5707786786721016; train accuracy : 0.9802754112580935; \n",
      " validation loss : 0.6319015551810675; validation accuracy : 0.9205020920502092\n",
      "Epoch 35:\t train loss : 0.5663731886667386; train accuracy : 0.9849784689736362; \n",
      " validation loss : 0.6303334825595028; validation accuracy : 0.9205020920502092\n",
      "Epoch 36:\t train loss : 0.5636604882774174; train accuracy : 0.987772545617894; \n",
      " validation loss : 0.6208422573443935; validation accuracy : 0.9246861924686193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:\t train loss : 0.5656435462557794; train accuracy : 0.9859174695622541; \n",
      " validation loss : 0.606567786523444; validation accuracy : 0.9414225941422594\n",
      "Epoch 38:\t train loss : 0.5686189184364261; train accuracy : 0.9823547817466465; \n",
      " validation loss : 0.6354339638087048; validation accuracy : 0.9121338912133892\n",
      "Epoch 39:\t train loss : 0.5722368163617302; train accuracy : 0.9789838594752006; \n",
      " validation loss : 0.6200931151728093; validation accuracy : 0.9246861924686193\n",
      "Epoch 40:\t train loss : 0.565322419434897; train accuracy : 0.9859078657950989; \n",
      " validation loss : 0.6171064559193457; validation accuracy : 0.9372384937238494\n",
      "Epoch 41:\t train loss : 0.5671202312060909; train accuracy : 0.9841382942470337; \n",
      " validation loss : 0.6107542655760531; validation accuracy : 0.9414225941422594\n",
      "Epoch 42:\t train loss : 0.5631440496474808; train accuracy : 0.9881443043464792; \n",
      " validation loss : 0.5958450616647567; validation accuracy : 0.9581589958158996\n",
      "Epoch 43:\t train loss : 0.5614684164072153; train accuracy : 0.989838594752006; \n",
      " validation loss : 0.6243694114309027; validation accuracy : 0.9205020920502092\n",
      "Epoch 44:\t train loss : 0.5611981938943721; train accuracy : 0.9900185879364293; \n",
      " validation loss : 0.616721251576711; validation accuracy : 0.9330543933054394\n",
      "Epoch 45:\t train loss : 0.5680881015301575; train accuracy : 0.9830481117754577; \n",
      " validation loss : 0.6257634916185746; validation accuracy : 0.9246861924686193\n",
      "Epoch 46:\t train loss : 0.5671159107379634; train accuracy : 0.984029864617863; \n",
      " validation loss : 0.6010759328766535; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5612735655577658; train accuracy : 0.9901462250999101; \n",
      " validation loss : 0.6264916900269036; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5621393640295541; train accuracy : 0.9891297747761703; \n",
      " validation loss : 0.6260012918028156; validation accuracy : 0.9205020920502092\n",
      "Epoch 49:\t train loss : 0.5597590378333515; train accuracy : 0.9916450323739893; \n",
      " validation loss : 0.629965859222088; validation accuracy : 0.9205020920502092\n",
      "Epoch 50:\t train loss : 0.5755882144324312; train accuracy : 0.975293534496112; \n",
      " validation loss : 0.6171843935339404; validation accuracy : 0.9330543933054394\n",
      "Epoch 51:\t train loss : 0.5609748104405714; train accuracy : 0.9903785743052759; \n",
      " validation loss : 0.6093888070399578; validation accuracy : 0.9372384937238494\n",
      "Epoch 52:\t train loss : 0.5626766614827861; train accuracy : 0.9886960562594876; \n",
      " validation loss : 0.6311971387904529; validation accuracy : 0.9205020920502092\n",
      "Epoch 53:\t train loss : 0.558787199523269; train accuracy : 0.9925028656401995; \n",
      " validation loss : 0.6128996962217426; validation accuracy : 0.9372384937238494\n",
      "Epoch 54:\t train loss : 0.5597992818648998; train accuracy : 0.9913720995074197; \n",
      " validation loss : 0.6135840591607719; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.5669424148080386; train accuracy : 0.9842718175903838; \n",
      " validation loss : 0.6148910337666307; validation accuracy : 0.9330543933054394\n",
      "Epoch 56:\t train loss : 0.5606269688761459; train accuracy : 0.9907621053935995; \n",
      " validation loss : 0.6124804227705887; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5621155347638949; train accuracy : 0.9891570370829331; \n",
      " validation loss : 0.6175906222674843; validation accuracy : 0.9330543933054394\n",
      "Epoch 58:\t train loss : 0.5633297074561673; train accuracy : 0.987896465194089; \n",
      " validation loss : 0.6140866586224746; validation accuracy : 0.9372384937238494\n",
      "Epoch 59:\t train loss : 0.5604483588517823; train accuracy : 0.9908646488429009; \n",
      " validation loss : 0.619446325783424; validation accuracy : 0.9330543933054394\n",
      "Epoch 60:\t train loss : 0.5599349335406248; train accuracy : 0.9912113138573067; \n",
      " validation loss : 0.6140705315583073; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5599971554604335; train accuracy : 0.9913758170947056; \n",
      " validation loss : 0.6160801604668442; validation accuracy : 0.9330543933054394\n",
      "Epoch 62:\t train loss : 0.5587902110540367; train accuracy : 0.9925589392484278; \n",
      " validation loss : 0.6279440064063249; validation accuracy : 0.9246861924686193\n",
      "Epoch 63:\t train loss : 0.5602459542636437; train accuracy : 0.9910542457944794; \n",
      " validation loss : 0.6317777084196721; validation accuracy : 0.9163179916317992\n",
      "Epoch 64:\t train loss : 0.5738323383434645; train accuracy : 0.9770785959912017; \n",
      " validation loss : 0.6476269263123975; validation accuracy : 0.9037656903765691\n",
      "Epoch 65:\t train loss : 0.5626507456699885; train accuracy : 0.9885219492549335; \n",
      " validation loss : 0.6316136626296862; validation accuracy : 0.9163179916317992\n",
      "Epoch 66:\t train loss : 0.5608686891803629; train accuracy : 0.990250937141795; \n",
      " validation loss : 0.6430254046786402; validation accuracy : 0.9037656903765691\n",
      "Epoch 67:\t train loss : 0.5620985493076276; train accuracy : 0.9891201710090152; \n",
      " validation loss : 0.6185820926997263; validation accuracy : 0.9330543933054394\n",
      "Epoch 68:\t train loss : 0.5569862866823311; train accuracy : 0.9943771492301496; \n",
      " validation loss : 0.615049236834504; validation accuracy : 0.9330543933054394\n",
      "Epoch 69:\t train loss : 0.5596448333049358; train accuracy : 0.9916295424269649; \n",
      " validation loss : 0.6014796879450829; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5594584674167263; train accuracy : 0.9918522878651755; \n",
      " validation loss : 0.6013112757618972; validation accuracy : 0.9497907949790795\n",
      "Epoch 71:\t train loss : 0.5580919481562142; train accuracy : 0.9931534434152235; \n",
      " validation loss : 0.6083025635638903; validation accuracy : 0.9456066945606695\n",
      "Epoch 72:\t train loss : 0.5579397008660084; train accuracy : 0.9934883360698906; \n",
      " validation loss : 0.6246201564428306; validation accuracy : 0.9288702928870293\n",
      "Epoch 73:\t train loss : 0.5784378558610395; train accuracy : 0.9723910282226835; \n",
      " validation loss : 0.6433150320210728; validation accuracy : 0.9079497907949791\n",
      "Epoch 74:\t train loss : 0.560304838826617; train accuracy : 0.9910003407788345; \n",
      " validation loss : 0.6280609065911131; validation accuracy : 0.9246861924686193\n",
      "Epoch 75:\t train loss : 0.562165519971775; train accuracy : 0.9891415471359087; \n",
      " validation loss : 0.61003793829928; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5611770531915465; train accuracy : 0.9902413333746398; \n",
      " validation loss : 0.6173271109238037; validation accuracy : 0.9330543933054394\n",
      "Epoch 77:\t train loss : 0.5606089169785071; train accuracy : 0.9907466154465752; \n",
      " validation loss : 0.6175534031099277; validation accuracy : 0.9330543933054394\n",
      "Epoch 78:\t train loss : 0.5578947975442518; train accuracy : 0.9934477524086868; \n",
      " validation loss : 0.6042901263633146; validation accuracy : 0.9456066945606695\n",
      "Epoch 79:\t train loss : 0.5561938353317354; train accuracy : 0.9951361566343443; \n",
      " validation loss : 0.6211442995057826; validation accuracy : 0.9288702928870293\n",
      "Epoch 80:\t train loss : 0.5584202113148297; train accuracy : 0.9928820595433564; \n",
      " validation loss : 0.6000496588522647; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5629224875754056; train accuracy : 0.9882527339756498; \n",
      " validation loss : 0.6042623396812585; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5592393126182965; train accuracy : 0.9921038446048515; \n",
      " validation loss : 0.590122609581936; validation accuracy : 0.9623430962343096\n",
      "Epoch 83:\t train loss : 0.5585637317014449; train accuracy : 0.9928126645806872; \n",
      " validation loss : 0.6086447566928177; validation accuracy : 0.9414225941422594\n",
      "Epoch 84:\t train loss : 0.5588836287711038; train accuracy : 0.992527959354379; \n",
      " validation loss : 0.6153995710722032; validation accuracy : 0.9372384937238494\n",
      "Epoch 85:\t train loss : 0.5596844536493283; train accuracy : 0.9916354286068342; \n",
      " validation loss : 0.5985294842467819; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5586291214458782; train accuracy : 0.9926961801790638; \n",
      " validation loss : 0.6397471998649903; validation accuracy : 0.9079497907949791\n",
      "Epoch 87:\t train loss : 0.5586495259097647; train accuracy : 0.9926112952693702; \n",
      " validation loss : 0.6157576376736258; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88:\t train loss : 0.5586962551810704; train accuracy : 0.9926865764119087; \n",
      " validation loss : 0.6114667310851114; validation accuracy : 0.9372384937238494\n",
      "Epoch 89:\t train loss : 0.5610548784809254; train accuracy : 0.9902156200625793; \n",
      " validation loss : 0.6449171862958826; validation accuracy : 0.9037656903765691\n",
      "Epoch 90:\t train loss : 0.56464544785938; train accuracy : 0.9865702159298615; \n",
      " validation loss : 0.5941924450178807; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5563049811849906; train accuracy : 0.9950624244865083; \n",
      " validation loss : 0.6095559649502541; validation accuracy : 0.9414225941422594\n",
      "Epoch 92:\t train loss : 0.5562578576230992; train accuracy : 0.995130270454475; \n",
      " validation loss : 0.6002765896322191; validation accuracy : 0.9497907949790795\n",
      "Epoch 93:\t train loss : 0.5577926677785967; train accuracy : 0.993503826016915; \n",
      " validation loss : 0.6072821671335065; validation accuracy : 0.9456066945606695\n",
      "Epoch 94:\t train loss : 0.5759734429738019; train accuracy : 0.975018433036959; \n",
      " validation loss : 0.6126123919266124; validation accuracy : 0.9372384937238494\n",
      "Epoch 95:\t train loss : 0.5606105345037649; train accuracy : 0.9907097493726571; \n",
      " validation loss : 0.6019713171301813; validation accuracy : 0.9497907949790795\n",
      "Epoch 96:\t train loss : 0.5558744601251061; train accuracy : 0.9955020291830602; \n",
      " validation loss : 0.6067882504945434; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.5564594707290891; train accuracy : 0.9949192973760029; \n",
      " validation loss : 0.5979454735154203; validation accuracy : 0.9539748953974896\n",
      "Epoch 98:\t train loss : 0.5571935427424433; train accuracy : 0.9941138201307351; \n",
      " validation loss : 0.6201261425043989; validation accuracy : 0.9288702928870293\n",
      "Epoch 99:\t train loss : 0.557423995618279; train accuracy : 0.9940245980358747; \n",
      " validation loss : 0.6214680981455177; validation accuracy : 0.9288702928870293\n",
      "Epoch 100:\t train loss : 0.5594726525320373; train accuracy : 0.9918154217912575; \n",
      " validation loss : 0.6079381655532436; validation accuracy : 0.9414225941422594\n",
      "Epoch 101:\t train loss : 0.5586943266195561; train accuracy : 0.9927138387186716; \n",
      " validation loss : 0.6178018822726432; validation accuracy : 0.9330543933054394\n",
      "Epoch 102:\t train loss : 0.5581455905974466; train accuracy : 0.9932095170234517; \n",
      " validation loss : 0.5997665479853026; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.571140104410723; train accuracy : 0.979938350010843; \n",
      " validation loss : 0.6063976117685909; validation accuracy : 0.9456066945606695\n",
      "Epoch 104:\t train loss : 0.561396927042138; train accuracy : 0.9898017286780879; \n",
      " validation loss : 0.5959486023159564; validation accuracy : 0.9539748953974896\n",
      "Epoch 105:\t train loss : 0.5584740712891524; train accuracy : 0.9928377582948666; \n",
      " validation loss : 0.6090688931267553; validation accuracy : 0.9414225941422594\n",
      "Epoch 106:\t train loss : 0.556224966535449; train accuracy : 0.9951553641686546; \n",
      " validation loss : 0.6113207536548775; validation accuracy : 0.9372384937238494\n",
      "Epoch 107:\t train loss : 0.5556236970555247; train accuracy : 0.9957712444623439; \n",
      " validation loss : 0.616941618288046; validation accuracy : 0.9330543933054394\n",
      "Epoch 108:\t train loss : 0.5540185963940131; train accuracy : 0.9973667090058552; \n",
      " validation loss : 0.5992203054998038; validation accuracy : 0.9539748953974896\n",
      "Epoch 109:\t train loss : 0.5537892330878537; train accuracy : 0.9976300381052696; \n",
      " validation loss : 0.5813206707562812; validation accuracy : 0.9707112970711297\n",
      "Epoch 110:\t train loss : 0.5572806974415072; train accuracy : 0.994030484215744; \n",
      " validation loss : 0.6130945295034791; validation accuracy : 0.9372384937238494\n",
      "Epoch 111:\t train loss : 0.5584291059890186; train accuracy : 0.9929306979770129; \n",
      " validation loss : 0.6127315284688098; validation accuracy : 0.9372384937238494\n",
      "Epoch 112:\t train loss : 0.5562284635533015; train accuracy : 0.9951826264754174; \n",
      " validation loss : 0.60889460820277; validation accuracy : 0.9414225941422594\n",
      "Epoch 113:\t train loss : 0.5626370260288797; train accuracy : 0.9887889959416338; \n",
      " validation loss : 0.6168678164053121; validation accuracy : 0.9372384937238494\n",
      "Epoch 114:\t train loss : 0.5594246962454802; train accuracy : 0.9919703212615013; \n",
      " validation loss : 0.6235030306762773; validation accuracy : 0.9288702928870293\n",
      "Epoch 115:\t train loss : 0.5584573898142723; train accuracy : 0.9928473620620217; \n",
      " validation loss : 0.6285431234402462; validation accuracy : 0.9246861924686193\n",
      "Epoch 116:\t train loss : 0.5647733040013735; train accuracy : 0.9864094302797485; \n",
      " validation loss : 0.6448002775838237; validation accuracy : 0.9037656903765691\n",
      "Epoch 117:\t train loss : 0.5572121975239227; train accuracy : 0.9941448000247839; \n",
      " validation loss : 0.6121704989782404; validation accuracy : 0.9414225941422594\n",
      "Epoch 118:\t train loss : 0.5560202420567686; train accuracy : 0.9953626196598407; \n",
      " validation loss : 0.6075100585822685; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5564213420700023; train accuracy : 0.9949598810372069; \n",
      " validation loss : 0.6352770688884324; validation accuracy : 0.9163179916317992\n",
      "Epoch 120:\t train loss : 0.5548585464477651; train accuracy : 0.9964971033799064; \n",
      " validation loss : 0.6224245993732955; validation accuracy : 0.9288702928870293\n",
      "Epoch 121:\t train loss : 0.5572478600600389; train accuracy : 0.9941057653582824; \n",
      " validation loss : 0.6269185667693973; validation accuracy : 0.9246861924686193\n",
      "Epoch 122:\t train loss : 0.55683247020104; train accuracy : 0.9945165587533691; \n",
      " validation loss : 0.6182848659574166; validation accuracy : 0.9330543933054394\n",
      "Epoch 123:\t train loss : 0.5595027248760683; train accuracy : 0.9918309117382819; \n",
      " validation loss : 0.623393622417873; validation accuracy : 0.9288702928870293\n",
      "Epoch 124:\t train loss : 0.5586415431264742; train accuracy : 0.9926887450044921; \n",
      " validation loss : 0.6447117031645735; validation accuracy : 0.9037656903765691\n",
      "Epoch 125:\t train loss : 0.5554561674711544; train accuracy : 0.9959202577527184; \n",
      " validation loss : 0.5891592429596261; validation accuracy : 0.9623430962343096\n",
      "Epoch 126:\t train loss : 0.554924531447115; train accuracy : 0.9963849561634499; \n",
      " validation loss : 0.6032304840881316; validation accuracy : 0.9497907949790795\n",
      "Epoch 127:\t train loss : 0.554618111426193; train accuracy : 0.9967353387651414; \n",
      " validation loss : 0.6438781303396945; validation accuracy : 0.9079497907949791\n",
      "Epoch 128:\t train loss : 0.5600986651738342; train accuracy : 0.9910291520802998; \n",
      " validation loss : 0.6054273968993035; validation accuracy : 0.9456066945606695\n",
      "Epoch 129:\t train loss : 0.5588086633475254; train accuracy : 0.9925161869946405; \n",
      " validation loss : 0.6268969968899015; validation accuracy : 0.9246861924686193\n",
      "Epoch 130:\t train loss : 0.5648998710967853; train accuracy : 0.9863939403327241; \n",
      " validation loss : 0.620629958911967; validation accuracy : 0.9288702928870293\n",
      "Epoch 131:\t train loss : 0.5566584715426831; train accuracy : 0.9946287059698256; \n",
      " validation loss : 0.6078238941135665; validation accuracy : 0.9414225941422594\n",
      "Epoch 132:\t train loss : 0.5579825498188172; train accuracy : 0.9934728461228662; \n",
      " validation loss : 0.6012626669146057; validation accuracy : 0.9497907949790795\n",
      "Epoch 133:\t train loss : 0.5550822120456627; train accuracy : 0.9962669227671241; \n",
      " validation loss : 0.5883038814512012; validation accuracy : 0.9623430962343096\n",
      "Epoch 134:\t train loss : 0.5574196619107882; train accuracy : 0.9939434307134669; \n",
      " validation loss : 0.6010420261588643; validation accuracy : 0.9497907949790795\n",
      "Epoch 135:\t train loss : 0.5553215666834928; train accuracy : 0.9960345735617584; \n",
      " validation loss : 0.6050886628560842; validation accuracy : 0.9456066945606695\n",
      "Epoch 136:\t train loss : 0.5552250784891113; train accuracy : 0.996106137117011; \n",
      " validation loss : 0.5962897512586469; validation accuracy : 0.9581589958158996\n",
      "Epoch 137:\t train loss : 0.5581207616629071; train accuracy : 0.993215403203321; \n",
      " validation loss : 0.5960788989833388; validation accuracy : 0.9539748953974896\n",
      "Epoch 138:\t train loss : 0.5576676147327516; train accuracy : 0.9936587254871588; \n",
      " validation loss : 0.6146175699104238; validation accuracy : 0.9372384937238494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139:\t train loss : 0.5758376245442225; train accuracy : 0.975219802348276; \n",
      " validation loss : 0.5998953046799557; validation accuracy : 0.9539748953974896\n",
      "Epoch 140:\t train loss : 0.5643053360067428; train accuracy : 0.9868121689023823; \n",
      " validation loss : 0.6010471327323518; validation accuracy : 0.9497907949790795\n",
      "Epoch 141:\t train loss : 0.5561359961071255; train accuracy : 0.9951767402955481; \n",
      " validation loss : 0.6050234888503698; validation accuracy : 0.9414225941422594\n",
      "Epoch 142:\t train loss : 0.5567952636556793; train accuracy : 0.9944951826264754; \n",
      " validation loss : 0.5986696505548228; validation accuracy : 0.9539748953974896\n",
      "Epoch 143:\t train loss : 0.555359239036767; train accuracy : 0.9960131974348647; \n",
      " validation loss : 0.5872683287350066; validation accuracy : 0.9665271966527197\n",
      "Epoch 144:\t train loss : 0.5542128928059766; train accuracy : 0.997159453514669; \n",
      " validation loss : 0.6177901510464006; validation accuracy : 0.9330543933054394\n",
      "Epoch 145:\t train loss : 0.5560133227247432; train accuracy : 0.9953412435329471; \n",
      " validation loss : 0.6027054000008082; validation accuracy : 0.9497907949790795\n",
      "Epoch 146:\t train loss : 0.5570758186626957; train accuracy : 0.9942222497599058; \n",
      " validation loss : 0.5930549383715088; validation accuracy : 0.9581589958158996\n",
      "Epoch 147:\t train loss : 0.55477752249351; train accuracy : 0.996595929241922; \n",
      " validation loss : 0.5910276344956582; validation accuracy : 0.9623430962343096\n",
      "Epoch 148:\t train loss : 0.5587554275385167; train accuracy : 0.9925493354812727; \n",
      " validation loss : 0.6163344171247348; validation accuracy : 0.9330543933054394\n",
      "Epoch 149:\t train loss : 0.5568034435553472; train accuracy : 0.9945453700548345; \n",
      " validation loss : 0.5857721968175357; validation accuracy : 0.9665271966527197\n",
      "Epoch 150:\t train loss : 0.5552084599504771; train accuracy : 0.9961430031909291; \n",
      " validation loss : 0.5967780733451845; validation accuracy : 0.9539748953974896\n",
      "Epoch 151:\t train loss : 0.5535468363829531; train accuracy : 0.9978778772576598; \n",
      " validation loss : 0.6050078573686554; validation accuracy : 0.9456066945606695\n",
      "Epoch 152:\t train loss : 0.5549288286373296; train accuracy : 0.9964410297716781; \n",
      " validation loss : 0.6010120642387338; validation accuracy : 0.9497907949790795\n",
      "Epoch 153:\t train loss : 0.5576601359076021; train accuracy : 0.9936026518789306; \n",
      " validation loss : 0.591735173914805; validation accuracy : 0.9581589958158996\n",
      "Epoch 154:\t train loss : 0.5569280259058077; train accuracy : 0.9944022429443291; \n",
      " validation loss : 0.5974606426942407; validation accuracy : 0.9539748953974896\n",
      "Epoch 155:\t train loss : 0.5584030506768404; train accuracy : 0.992866569596332; \n",
      " validation loss : 0.5922381471339042; validation accuracy : 0.9581589958158996\n",
      "Epoch 156:\t train loss : 0.5581076911833414; train accuracy : 0.9931630471823786; \n",
      " validation loss : 0.6079286421175438; validation accuracy : 0.9414225941422594\n",
      "Epoch 157:\t train loss : 0.5552451222826303; train accuracy : 0.9961430031909291; \n",
      " validation loss : 0.6008545574558278; validation accuracy : 0.9497907949790795\n",
      "Epoch 158:\t train loss : 0.5542453864025967; train accuracy : 0.9971188698534651; \n",
      " validation loss : 0.6015159539531238; validation accuracy : 0.9497907949790795\n",
      "Epoch 159:\t train loss : 0.5582227416822134; train accuracy : 0.9930465627807553; \n",
      " validation loss : 0.5952265958380136; validation accuracy : 0.9581589958158996\n",
      "Early stopping at epoch 159\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5537892330878537; Train accuracy : 0.9976300381052696; \n",
      " Validation loss : 0.5813206707562812; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 95 ! ---\n",
      "Epoch 1:\t train loss : 0.9317025752970651; train accuracy : 0.6051528857771307; \n",
      " validation loss : 0.8343826151737543; validation accuracy : 0.7154811715481172\n",
      "Epoch 2:\t train loss : 0.7535085247808333; train accuracy : 0.7952430372688125; \n",
      " validation loss : 0.7285437045815681; validation accuracy : 0.8200836820083682\n",
      "Epoch 3:\t train loss : 0.6994071994071298; train accuracy : 0.8508674370333653; \n",
      " validation loss : 0.7133730039599545; validation accuracy : 0.8451882845188284\n",
      "Epoch 4:\t train loss : 0.675425594797358; train accuracy : 0.8745212057374764; \n",
      " validation loss : 0.6659050839215064; validation accuracy : 0.891213389121339\n",
      "Epoch 5:\t train loss : 0.6568979033547916; train accuracy : 0.8936240280058242; \n",
      " validation loss : 0.6727940142205031; validation accuracy : 0.8744769874476988\n",
      "Epoch 6:\t train loss : 0.6478790291618893; train accuracy : 0.902189968710307; \n",
      " validation loss : 0.6437896721499303; validation accuracy : 0.899581589958159\n",
      "Epoch 7:\t train loss : 0.6367606049897541; train accuracy : 0.9132188109916665; \n",
      " validation loss : 0.6546505735833384; validation accuracy : 0.891213389121339\n",
      "Epoch 8:\t train loss : 0.6241367783275459; train accuracy : 0.9262613463861954; \n",
      " validation loss : 0.6646087289285556; validation accuracy : 0.8828451882845189\n",
      "Epoch 9:\t train loss : 0.6179118776574694; train accuracy : 0.9339449797081694; \n",
      " validation loss : 0.6430287529957347; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.614405825577921; train accuracy : 0.9361343288205954; \n",
      " validation loss : 0.6354705303489058; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.6076971796829013; train accuracy : 0.9435118807893677; \n",
      " validation loss : 0.636916787950734; validation accuracy : 0.9121338912133892\n",
      "Epoch 12:\t train loss : 0.603130717104564; train accuracy : 0.9475429846029927; \n",
      " validation loss : 0.6527867359586164; validation accuracy : 0.895397489539749\n",
      "Epoch 13:\t train loss : 0.5990489301139945; train accuracy : 0.9520874252610056; \n",
      " validation loss : 0.6310591619464634; validation accuracy : 0.9205020920502092\n",
      "Epoch 14:\t train loss : 0.5945386932166902; train accuracy : 0.956606772204839; \n",
      " validation loss : 0.6469367863234113; validation accuracy : 0.9079497907949791\n",
      "Epoch 15:\t train loss : 0.5895653335637789; train accuracy : 0.9616019703212615; \n",
      " validation loss : 0.6277831410310625; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.5902035291876224; train accuracy : 0.9609823724402863; \n",
      " validation loss : 0.6226389975013301; validation accuracy : 0.9246861924686193\n",
      "Epoch 17:\t train loss : 0.5851236800534775; train accuracy : 0.9659472102605409; \n",
      " validation loss : 0.6300124511031118; validation accuracy : 0.9163179916317992\n",
      "Epoch 18:\t train loss : 0.5840592049859146; train accuracy : 0.9668183648811921; \n",
      " validation loss : 0.6273334527112382; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5841377213195004; train accuracy : 0.9669946404783295; \n",
      " validation loss : 0.6447173327864374; validation accuracy : 0.899581589958159\n",
      "Epoch 20:\t train loss : 0.5830455099902981; train accuracy : 0.9678465875646706; \n",
      " validation loss : 0.6423418220808467; validation accuracy : 0.9037656903765691\n",
      "Epoch 21:\t train loss : 0.5868821877100021; train accuracy : 0.9640264568295176; \n",
      " validation loss : 0.6433774159526923; validation accuracy : 0.9037656903765691\n",
      "Epoch 22:\t train loss : 0.5770049211480159; train accuracy : 0.9741259022894142; \n",
      " validation loss : 0.6442414899388118; validation accuracy : 0.9037656903765691\n",
      "Epoch 23:\t train loss : 0.5741010064374612; train accuracy : 0.9771154620651198; \n",
      " validation loss : 0.6166152570513622; validation accuracy : 0.9330543933054394\n",
      "Epoch 24:\t train loss : 0.578239853036797; train accuracy : 0.9729582700827163; \n",
      " validation loss : 0.6151723276019199; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5772562272974102; train accuracy : 0.9741937482573809; \n",
      " validation loss : 0.6081343133617819; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5714932185041111; train accuracy : 0.9794330679389076; \n",
      " validation loss : 0.6187382977763377; validation accuracy : 0.9330543933054394\n",
      "Epoch 27:\t train loss : 0.5747631102531928; train accuracy : 0.9764317358034635; \n",
      " validation loss : 0.6392299158026071; validation accuracy : 0.9079497907949791\n",
      "Epoch 28:\t train loss : 0.5764327921768598; train accuracy : 0.974693144149447; \n",
      " validation loss : 0.6322207853552739; validation accuracy : 0.9205020920502092\n",
      "Epoch 29:\t train loss : 0.5694487745492843; train accuracy : 0.9819055732829394; \n",
      " validation loss : 0.61996246977468; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:\t train loss : 0.5665534064627086; train accuracy : 0.9846900461600422; \n",
      " validation loss : 0.6066202551362538; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5672503042199681; train accuracy : 0.9840394683850181; \n",
      " validation loss : 0.5985967531918511; validation accuracy : 0.9539748953974896\n",
      "Epoch 32:\t train loss : 0.5710929284011718; train accuracy : 0.9799405186034263; \n",
      " validation loss : 0.6373671665177861; validation accuracy : 0.9121338912133892\n",
      "Epoch 33:\t train loss : 0.5712683805628924; train accuracy : 0.979860900275721; \n",
      " validation loss : 0.6266407253590377; validation accuracy : 0.9246861924686193\n",
      "Epoch 34:\t train loss : 0.56602475609349; train accuracy : 0.9851739521050838; \n",
      " validation loss : 0.6211748316213377; validation accuracy : 0.9330543933054394\n",
      "Epoch 35:\t train loss : 0.5657901758494851; train accuracy : 0.9855014095851792; \n",
      " validation loss : 0.6238271728607271; validation accuracy : 0.9288702928870293\n",
      "Epoch 36:\t train loss : 0.5679696411943754; train accuracy : 0.9831816351188079; \n",
      " validation loss : 0.6333986239882664; validation accuracy : 0.9163179916317992\n",
      "Epoch 37:\t train loss : 0.5652669919901473; train accuracy : 0.98585767836674; \n",
      " validation loss : 0.621680163844369; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5671918432771439; train accuracy : 0.9837296694445306; \n",
      " validation loss : 0.599636547606648; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5667398942295832; train accuracy : 0.9844635831345456; \n",
      " validation loss : 0.6148995361552054; validation accuracy : 0.9372384937238494\n",
      "Epoch 40:\t train loss : 0.5654419149380633; train accuracy : 0.9857854952136064; \n",
      " validation loss : 0.6259424841177295; validation accuracy : 0.9246861924686193\n",
      "Epoch 41:\t train loss : 0.5697165894404547; train accuracy : 0.9813848012639796; \n",
      " validation loss : 0.6445521541573414; validation accuracy : 0.9037656903765691\n",
      "Epoch 42:\t train loss : 0.5644901820977136; train accuracy : 0.9866941355060566; \n",
      " validation loss : 0.630101031064146; validation accuracy : 0.9246861924686193\n",
      "Epoch 43:\t train loss : 0.5609922973645968; train accuracy : 0.9904272127389324; \n",
      " validation loss : 0.626354351203037; validation accuracy : 0.9246861924686193\n",
      "Epoch 44:\t train loss : 0.5772776041721611; train accuracy : 0.9737733510951393; \n",
      " validation loss : 0.6502986396729284; validation accuracy : 0.891213389121339\n",
      "Epoch 45:\t train loss : 0.58101099854033; train accuracy : 0.9697459648688002; \n",
      " validation loss : 0.6302904768284647; validation accuracy : 0.9163179916317992\n",
      "Epoch 46:\t train loss : 0.5735914284913174; train accuracy : 0.9773648502122123; \n",
      " validation loss : 0.646023012064494; validation accuracy : 0.9037656903765691\n",
      "Epoch 47:\t train loss : 0.5663095532816605; train accuracy : 0.9846745562130178; \n",
      " validation loss : 0.6139863720254041; validation accuracy : 0.9372384937238494\n",
      "Epoch 48:\t train loss : 0.5679954117686435; train accuracy : 0.9832665200285015; \n",
      " validation loss : 0.6329647700673183; validation accuracy : 0.9163179916317992\n",
      "Epoch 49:\t train loss : 0.5692639615585809; train accuracy : 0.9818436134948418; \n",
      " validation loss : 0.6212325725043796; validation accuracy : 0.9288702928870293\n",
      "Epoch 50:\t train loss : 0.56095583922651; train accuracy : 0.9903630843582515; \n",
      " validation loss : 0.6511996469770276; validation accuracy : 0.899581589958159\n",
      "Epoch 51:\t train loss : 0.5633083356362338; train accuracy : 0.9880550822516188; \n",
      " validation loss : 0.6164776214489976; validation accuracy : 0.9288702928870293\n",
      "Epoch 52:\t train loss : 0.56160609933955; train accuracy : 0.9896970166362031; \n",
      " validation loss : 0.618337124256366; validation accuracy : 0.9330543933054394\n",
      "Epoch 53:\t train loss : 0.5637076148343397; train accuracy : 0.9874354843706434; \n",
      " validation loss : 0.6133938323792778; validation accuracy : 0.9372384937238494\n",
      "Epoch 54:\t train loss : 0.5584289413253365; train accuracy : 0.9928938319030949; \n",
      " validation loss : 0.6181436631111749; validation accuracy : 0.9288702928870293\n",
      "Epoch 55:\t train loss : 0.5606601881304367; train accuracy : 0.9906072059233557; \n",
      " validation loss : 0.6210098735464358; validation accuracy : 0.9246861924686193\n",
      "Epoch 56:\t train loss : 0.5625658509647272; train accuracy : 0.988510176895195; \n",
      " validation loss : 0.6226098295118895; validation accuracy : 0.9330543933054394\n",
      "Epoch 57:\t train loss : 0.5650336353533592; train accuracy : 0.9860745376250813; \n",
      " validation loss : 0.6182043046654427; validation accuracy : 0.9288702928870293\n",
      "Epoch 58:\t train loss : 0.5979846742330848; train accuracy : 0.9525868211530717; \n",
      " validation loss : 0.6264797968201095; validation accuracy : 0.9246861924686193\n",
      "Epoch 59:\t train loss : 0.585122219569837; train accuracy : 0.9654397595960221; \n",
      " validation loss : 0.6107958398384083; validation accuracy : 0.9414225941422594\n",
      "Epoch 60:\t train loss : 0.5707315195083026; train accuracy : 0.9804414634901949; \n",
      " validation loss : 0.6321412525350889; validation accuracy : 0.9205020920502092\n",
      "Epoch 61:\t train loss : 0.5660206070164789; train accuracy : 0.9854025837231637; \n",
      " validation loss : 0.6057459980748545; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5636391999304066; train accuracy : 0.9877143034170823; \n",
      " validation loss : 0.6015554937795086; validation accuracy : 0.9497907949790795\n",
      "Epoch 63:\t train loss : 0.5690433700593441; train accuracy : 0.9818996871030701; \n",
      " validation loss : 0.6128661420701322; validation accuracy : 0.9414225941422594\n",
      "Epoch 64:\t train loss : 0.5608856050378497; train accuracy : 0.9905644536695685; \n",
      " validation loss : 0.6046365862556401; validation accuracy : 0.9456066945606695\n",
      "Epoch 65:\t train loss : 0.5611422408144122; train accuracy : 0.990049567830478; \n",
      " validation loss : 0.6117932007691916; validation accuracy : 0.9330543933054394\n",
      "Epoch 66:\t train loss : 0.5601019899857604; train accuracy : 0.9912305213916168; \n",
      " validation loss : 0.6072590010254509; validation accuracy : 0.9456066945606695\n",
      "Epoch 67:\t train loss : 0.5593007090334811; train accuracy : 0.9920979584249822; \n",
      " validation loss : 0.6050148235442574; validation accuracy : 0.9456066945606695\n",
      "Epoch 68:\t train loss : 0.5618367960524353; train accuracy : 0.9894395737166579; \n",
      " validation loss : 0.6140876987337204; validation accuracy : 0.9372384937238494\n",
      "Epoch 69:\t train loss : 0.5721216732511527; train accuracy : 0.9787301341429412; \n",
      " validation loss : 0.6512621402745895; validation accuracy : 0.895397489539749\n",
      "Epoch 70:\t train loss : 0.5652677911206526; train accuracy : 0.9858400198271322; \n",
      " validation loss : 0.6184516763436126; validation accuracy : 0.9288702928870293\n",
      "Epoch 71:\t train loss : 0.5604127341128509; train accuracy : 0.9907775953406239; \n",
      " validation loss : 0.6156333476364825; validation accuracy : 0.9330543933054394\n",
      "Epoch 72:\t train loss : 0.5667625096464318; train accuracy : 0.9843721924471018; \n",
      " validation loss : 0.6096236272871641; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5627139259565342; train accuracy : 0.9885256668422194; \n",
      " validation loss : 0.6160479491542225; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5633204426703721; train accuracy : 0.9879739149292109; \n",
      " validation loss : 0.6049541611040824; validation accuracy : 0.9456066945606695\n",
      "Epoch 75:\t train loss : 0.5701927295270829; train accuracy : 0.980836766938257; \n",
      " validation loss : 0.586232646408779; validation accuracy : 0.9665271966527197\n",
      "Epoch 76:\t train loss : 0.5608803132136639; train accuracy : 0.9904272127389324; \n",
      " validation loss : 0.622480001283549; validation accuracy : 0.9246861924686193\n",
      "Epoch 77:\t train loss : 0.5654686041114533; train accuracy : 0.9859019796152297; \n",
      " validation loss : 0.6074330484456268; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5615700815333456; train accuracy : 0.9895885870070324; \n",
      " validation loss : 0.6030281336002099; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5596061190637965; train accuracy : 0.9915366027448186; \n",
      " validation loss : 0.5883605972152416; validation accuracy : 0.9665271966527197\n",
      "Epoch 80:\t train loss : 0.5571064514189932; train accuracy : 0.9943093032621828; \n",
      " validation loss : 0.6048848233099458; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81:\t train loss : 0.556969644118938; train accuracy : 0.994369094457697; \n",
      " validation loss : 0.6569944233988996; validation accuracy : 0.895397489539749\n",
      "Epoch 82:\t train loss : 0.558004226896067; train accuracy : 0.9933489265466712; \n",
      " validation loss : 0.5999478604858384; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5646752234934739; train accuracy : 0.9864751076551318; \n",
      " validation loss : 0.6200737891705832; validation accuracy : 0.9330543933054394\n",
      "Epoch 84:\t train loss : 0.5647684363611353; train accuracy : 0.9864751076551318; \n",
      " validation loss : 0.5916209363978393; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.5629707875823456; train accuracy : 0.9882313578487562; \n",
      " validation loss : 0.5959613839728584; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.560262535450391; train accuracy : 0.9910873942811116; \n",
      " validation loss : 0.6397005512884055; validation accuracy : 0.9121338912133892\n",
      "Epoch 87:\t train loss : 0.558692403708734; train accuracy : 0.992615012856656; \n",
      " validation loss : 0.600225513322266; validation accuracy : 0.9456066945606695\n",
      "Epoch 88:\t train loss : 0.5610115651452885; train accuracy : 0.9902546547290808; \n",
      " validation loss : 0.605205537319373; validation accuracy : 0.9414225941422594\n",
      "Epoch 89:\t train loss : 0.5618061716303028; train accuracy : 0.9895287958115183; \n",
      " validation loss : 0.6104513347083428; validation accuracy : 0.9372384937238494\n",
      "Epoch 90:\t train loss : 0.5594307597965573; train accuracy : 0.991850119272592; \n",
      " validation loss : 0.5921735955745361; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5618565234935725; train accuracy : 0.9893370302673565; \n",
      " validation loss : 0.6198543329986739; validation accuracy : 0.9288702928870293\n",
      "Epoch 92:\t train loss : 0.558365101159045; train accuracy : 0.9928938319030949; \n",
      " validation loss : 0.5890423179021644; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.559239661922764; train accuracy : 0.9920691471235168; \n",
      " validation loss : 0.5894701335900954; validation accuracy : 0.9623430962343096\n",
      "Epoch 94:\t train loss : 0.5611105779355569; train accuracy : 0.990099755258837; \n",
      " validation loss : 0.6016118753327128; validation accuracy : 0.9497907949790795\n",
      "Epoch 95:\t train loss : 0.5635713312419024; train accuracy : 0.9874819542117166; \n",
      " validation loss : 0.5969158864629113; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5582623749023362; train accuracy : 0.9930081477121349; \n",
      " validation loss : 0.5995027408709345; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5650362639716603; train accuracy : 0.9862139471483008; \n",
      " validation loss : 0.589350808303383; validation accuracy : 0.9623430962343096\n",
      "Epoch 98:\t train loss : 0.5580637562010479; train accuracy : 0.9933489265466712; \n",
      " validation loss : 0.6172464256823844; validation accuracy : 0.9330543933054394\n",
      "Epoch 99:\t train loss : 0.5562155847129576; train accuracy : 0.9950875182006877; \n",
      " validation loss : 0.624496761874748; validation accuracy : 0.9288702928870293\n",
      "Epoch 100:\t train loss : 0.5571776960221008; train accuracy : 0.9942067598128814; \n",
      " validation loss : 0.608195110708513; validation accuracy : 0.9414225941422594\n",
      "Epoch 101:\t train loss : 0.5565464310074456; train accuracy : 0.994841847640881; \n",
      " validation loss : 0.6171279809361169; validation accuracy : 0.9330543933054394\n",
      "Epoch 102:\t train loss : 0.5595304876343098; train accuracy : 0.9917320858762663; \n",
      " validation loss : 0.6047032747048943; validation accuracy : 0.9414225941422594\n",
      "Epoch 103:\t train loss : 0.5573425826307773; train accuracy : 0.9940208804485888; \n",
      " validation loss : 0.6092003611727355; validation accuracy : 0.9414225941422594\n",
      "Epoch 104:\t train loss : 0.5583563847791763; train accuracy : 0.9928997180829642; \n",
      " validation loss : 0.6052980034371718; validation accuracy : 0.9456066945606695\n",
      "Epoch 105:\t train loss : 0.5610907047375239; train accuracy : 0.9901617150469345; \n",
      " validation loss : 0.5991399107224652; validation accuracy : 0.9497907949790795\n",
      "Epoch 106:\t train loss : 0.560109021621093; train accuracy : 0.991226803804331; \n",
      " validation loss : 0.6086407210251168; validation accuracy : 0.9414225941422594\n",
      "Epoch 107:\t train loss : 0.557359972039401; train accuracy : 0.9939877319619567; \n",
      " validation loss : 0.5983074176320582; validation accuracy : 0.9539748953974896\n",
      "Epoch 108:\t train loss : 0.5626297563508372; train accuracy : 0.988587626630317; \n",
      " validation loss : 0.6152083922263097; validation accuracy : 0.9372384937238494\n",
      "Epoch 109:\t train loss : 0.567517249376567; train accuracy : 0.9836986895504818; \n",
      " validation loss : 0.6142345309868671; validation accuracy : 0.9372384937238494\n",
      "Epoch 110:\t train loss : 0.563102284861307; train accuracy : 0.9880646860187738; \n",
      " validation loss : 0.6065580431199683; validation accuracy : 0.9456066945606695\n",
      "Epoch 111:\t train loss : 0.559282822237925; train accuracy : 0.9918677778121999; \n",
      " validation loss : 0.6052037969171254; validation accuracy : 0.9456066945606695\n",
      "Epoch 112:\t train loss : 0.5581692018354146; train accuracy : 0.9930450137860528; \n",
      " validation loss : 0.600905134198358; validation accuracy : 0.9497907949790795\n",
      "Epoch 113:\t train loss : 0.5591465692927817; train accuracy : 0.9921871805198426; \n",
      " validation loss : 0.6194930123152037; validation accuracy : 0.9330543933054394\n",
      "Epoch 114:\t train loss : 0.5595060179416113; train accuracy : 0.9917069921620868; \n",
      " validation loss : 0.6102317475108057; validation accuracy : 0.9414225941422594\n",
      "Epoch 115:\t train loss : 0.5599712697676855; train accuracy : 0.9912518975185105; \n",
      " validation loss : 0.5971877207446061; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5588431569146289; train accuracy : 0.9923495151646581; \n",
      " validation loss : 0.612904056161698; validation accuracy : 0.9372384937238494\n",
      "Epoch 117:\t train loss : 0.5638150967535029; train accuracy : 0.9873852969422845; \n",
      " validation loss : 0.6119254008932768; validation accuracy : 0.9372384937238494\n",
      "Epoch 118:\t train loss : 0.5607135957191776; train accuracy : 0.9905511323151275; \n",
      " validation loss : 0.6122162018248819; validation accuracy : 0.9372384937238494\n",
      "Epoch 119:\t train loss : 0.5570283448928608; train accuracy : 0.9943616592831253; \n",
      " validation loss : 0.5974857698290407; validation accuracy : 0.9539748953974896\n",
      "Epoch 120:\t train loss : 0.5584723906980416; train accuracy : 0.992816382167973; \n",
      " validation loss : 0.596669522887709; validation accuracy : 0.9539748953974896\n",
      "Epoch 121:\t train loss : 0.5582437324398036; train accuracy : 0.9930450137860528; \n",
      " validation loss : 0.6063798176163758; validation accuracy : 0.9456066945606695\n",
      "Epoch 122:\t train loss : 0.5603018073524667; train accuracy : 0.9910350382601691; \n",
      " validation loss : 0.6024085170077438; validation accuracy : 0.9497907949790795\n",
      "Epoch 123:\t train loss : 0.5553131777033646; train accuracy : 0.9960751572229622; \n",
      " validation loss : 0.5988287993964524; validation accuracy : 0.9539748953974896\n",
      "Epoch 124:\t train loss : 0.556480739985901; train accuracy : 0.9948573375879054; \n",
      " validation loss : 0.6138407485632431; validation accuracy : 0.9372384937238494\n",
      "Epoch 125:\t train loss : 0.5576714846112009; train accuracy : 0.9937302890424115; \n",
      " validation loss : 0.6068303265560356; validation accuracy : 0.9414225941422594\n",
      "Early stopping at epoch 125\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5701927295270829; Train accuracy : 0.980836766938257; \n",
      " Validation loss : 0.586232646408779; Validation accuracy : 0.9665271966527197\n",
      "--- Let's train model 96 ! ---\n",
      "Epoch 1:\t train loss : 0.9400388342506569; train accuracy : 0.5836748350320642; \n",
      " validation loss : 0.7973336972573408; validation accuracy : 0.7656903765690377\n",
      "Epoch 2:\t train loss : 0.7530521050661275; train accuracy : 0.7968592583413364; \n",
      " validation loss : 0.7392696566916666; validation accuracy : 0.8158995815899581\n",
      "Epoch 3:\t train loss : 0.6960036131405709; train accuracy : 0.8545828557266334; \n",
      " validation loss : 0.6748506110326379; validation accuracy : 0.8661087866108786\n",
      "Epoch 4:\t train loss : 0.6735458425933405; train accuracy : 0.8768381920133833; \n",
      " validation loss : 0.6768473454581331; validation accuracy : 0.8619246861924686\n",
      "Epoch 5:\t train loss : 0.6584031598836627; train accuracy : 0.8919350041822857; \n",
      " validation loss : 0.6668771068006383; validation accuracy : 0.8744769874476988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\t train loss : 0.649904795488867; train accuracy : 0.9005945041667958; \n",
      " validation loss : 0.6600266588795585; validation accuracy : 0.8870292887029289\n",
      "Epoch 7:\t train loss : 0.6416413229780246; train accuracy : 0.9090402428823693; \n",
      " validation loss : 0.6476788321767969; validation accuracy : 0.9037656903765691\n",
      "Epoch 8:\t train loss : 0.6354643255683468; train accuracy : 0.9146122866259797; \n",
      " validation loss : 0.6389994842577796; validation accuracy : 0.9079497907949791\n",
      "Epoch 9:\t train loss : 0.6191018310639651; train accuracy : 0.9322175408160104; \n",
      " validation loss : 0.6196185792662157; validation accuracy : 0.9372384937238494\n",
      "Epoch 10:\t train loss : 0.6187956429371094; train accuracy : 0.9323739892809567; \n",
      " validation loss : 0.6254728103547061; validation accuracy : 0.9288702928870293\n",
      "Epoch 11:\t train loss : 0.6206510217018686; train accuracy : 0.9302887326125344; \n",
      " validation loss : 0.6222051041217015; validation accuracy : 0.9205020920502092\n",
      "Epoch 12:\t train loss : 0.6071123931020154; train accuracy : 0.9444096781189009; \n",
      " validation loss : 0.6201433830042548; validation accuracy : 0.9330543933054394\n",
      "Epoch 13:\t train loss : 0.6065515035392719; train accuracy : 0.944328510796493; \n",
      " validation loss : 0.6450549813295108; validation accuracy : 0.9037656903765691\n",
      "Epoch 14:\t train loss : 0.5944790109139274; train accuracy : 0.9567285231884507; \n",
      " validation loss : 0.6203322834667157; validation accuracy : 0.9330543933054394\n",
      "Epoch 15:\t train loss : 0.5907641942846938; train accuracy : 0.960802379255863; \n",
      " validation loss : 0.6388893757188204; validation accuracy : 0.9037656903765691\n",
      "Epoch 16:\t train loss : 0.59058448703791; train accuracy : 0.9604535456488739; \n",
      " validation loss : 0.619246243911895; validation accuracy : 0.9330543933054394\n",
      "Epoch 17:\t train loss : 0.5951188695417556; train accuracy : 0.9558087301341429; \n",
      " validation loss : 0.6304390283191701; validation accuracy : 0.9163179916317992\n",
      "Epoch 18:\t train loss : 0.5886153484224332; train accuracy : 0.9623513739583011; \n",
      " validation loss : 0.6223496897451546; validation accuracy : 0.9288702928870293\n",
      "Epoch 19:\t train loss : 0.5850996088020666; train accuracy : 0.9659952290963165; \n",
      " validation loss : 0.6131843309377067; validation accuracy : 0.9372384937238494\n",
      "Epoch 20:\t train loss : 0.5841119041667491; train accuracy : 0.9670758078007373; \n",
      " validation loss : 0.6155857379452728; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5845269516801687; train accuracy : 0.9668301372409306; \n",
      " validation loss : 0.6168968341228196; validation accuracy : 0.9372384937238494\n",
      "Epoch 22:\t train loss : 0.5804084501951243; train accuracy : 0.9706716441029771; \n",
      " validation loss : 0.6025101283548694; validation accuracy : 0.9497907949790795\n",
      "Epoch 23:\t train loss : 0.5816353843563673; train accuracy : 0.9697363611016451; \n",
      " validation loss : 0.616225265426651; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.6086887206314103; train accuracy : 0.9418950401189627; \n",
      " validation loss : 0.6111994937988218; validation accuracy : 0.9414225941422594\n",
      "Epoch 25:\t train loss : 0.5798950167812967; train accuracy : 0.9713045633383933; \n",
      " validation loss : 0.6017396525288983; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5756741129431349; train accuracy : 0.9757811580284396; \n",
      " validation loss : 0.6173365036914105; validation accuracy : 0.9372384937238494\n",
      "Epoch 27:\t train loss : 0.5770323096610397; train accuracy : 0.9740772638557577; \n",
      " validation loss : 0.6140910105719383; validation accuracy : 0.9330543933054394\n",
      "Epoch 28:\t train loss : 0.5736341840989808; train accuracy : 0.9775779918832678; \n",
      " validation loss : 0.6053688234224641; validation accuracy : 0.9456066945606695\n",
      "Epoch 29:\t train loss : 0.5715831585289598; train accuracy : 0.9797967718950401; \n",
      " validation loss : 0.5986029307975792; validation accuracy : 0.9539748953974896\n",
      "Epoch 30:\t train loss : 0.5738064759033911; train accuracy : 0.9771789708479197; \n",
      " validation loss : 0.6015051640212802; validation accuracy : 0.9497907949790795\n",
      "Epoch 31:\t train loss : 0.5699020330457151; train accuracy : 0.9813228414758821; \n",
      " validation loss : 0.5865565073871525; validation accuracy : 0.9665271966527197\n",
      "Epoch 32:\t train loss : 0.5712672611648424; train accuracy : 0.9796809070912977; \n",
      " validation loss : 0.5977973906318002; validation accuracy : 0.9539748953974896\n",
      "Epoch 33:\t train loss : 0.5692732877616437; train accuracy : 0.9818612720344496; \n",
      " validation loss : 0.6141541828069594; validation accuracy : 0.9372384937238494\n",
      "Epoch 34:\t train loss : 0.5695722257523864; train accuracy : 0.9816326404163698; \n",
      " validation loss : 0.5895870850253425; validation accuracy : 0.9581589958158996\n",
      "Epoch 35:\t train loss : 0.5677265361793948; train accuracy : 0.9834818302921404; \n",
      " validation loss : 0.5964987108876592; validation accuracy : 0.9539748953974896\n",
      "Epoch 36:\t train loss : 0.5674004608097499; train accuracy : 0.9838012329997832; \n",
      " validation loss : 0.5824856791080586; validation accuracy : 0.9707112970711297\n",
      "Epoch 37:\t train loss : 0.5738085090911837; train accuracy : 0.9771383871867159; \n",
      " validation loss : 0.602456609508236; validation accuracy : 0.9497907949790795\n",
      "Epoch 38:\t train loss : 0.5713682420504718; train accuracy : 0.9797156045726324; \n",
      " validation loss : 0.6029516782954177; validation accuracy : 0.9497907949790795\n",
      "Epoch 39:\t train loss : 0.5681418544766104; train accuracy : 0.982980265807491; \n",
      " validation loss : 0.6109143131318541; validation accuracy : 0.9330543933054394\n",
      "Epoch 40:\t train loss : 0.5726903382345182; train accuracy : 0.9783893553084049; \n",
      " validation loss : 0.5882868610076222; validation accuracy : 0.9623430962343096\n",
      "Epoch 41:\t train loss : 0.5922183682344013; train accuracy : 0.9586994640478329; \n",
      " validation loss : 0.6152726803596267; validation accuracy : 0.9330543933054394\n",
      "Epoch 42:\t train loss : 0.5778417218625682; train accuracy : 0.9731751293410577; \n",
      " validation loss : 0.6039824867037046; validation accuracy : 0.9497907949790795\n",
      "Epoch 43:\t train loss : 0.5700715451886313; train accuracy : 0.9813538213699309; \n",
      " validation loss : 0.5954369039627324; validation accuracy : 0.9581589958158996\n",
      "Epoch 44:\t train loss : 0.5721642061548966; train accuracy : 0.9792066049134112; \n",
      " validation loss : 0.614096014556287; validation accuracy : 0.9372384937238494\n",
      "Epoch 45:\t train loss : 0.5690699855962329; train accuracy : 0.9820081167322408; \n",
      " validation loss : 0.5976133582621447; validation accuracy : 0.9497907949790795\n",
      "Epoch 46:\t train loss : 0.5660551539127104; train accuracy : 0.9851857244648223; \n",
      " validation loss : 0.5990435870643478; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.5710642053474252; train accuracy : 0.9800681557669073; \n",
      " validation loss : 0.6043467985270965; validation accuracy : 0.9456066945606695\n",
      "Epoch 48:\t train loss : 0.567902842673182; train accuracy : 0.9833018371077171; \n",
      " validation loss : 0.6095283844967231; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.5653625627078664; train accuracy : 0.985870999721181; \n",
      " validation loss : 0.611561011174167; validation accuracy : 0.9372384937238494\n",
      "Epoch 50:\t train loss : 0.5633701294895882; train accuracy : 0.9878809752470646; \n",
      " validation loss : 0.6059963169438112; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5640803479226743; train accuracy : 0.9870851017689519; \n",
      " validation loss : 0.6016750516941716; validation accuracy : 0.9497907949790795\n",
      "Epoch 52:\t train loss : 0.5658734814417717; train accuracy : 0.9853192478081725; \n",
      " validation loss : 0.6016089035627413; validation accuracy : 0.9456066945606695\n",
      "Epoch 53:\t train loss : 0.5669192540558657; train accuracy : 0.984331608785898; \n",
      " validation loss : 0.5988925853657346; validation accuracy : 0.9497907949790795\n",
      "Epoch 54:\t train loss : 0.5681300240609739; train accuracy : 0.9831447690448899; \n",
      " validation loss : 0.6045494358369935; validation accuracy : 0.9456066945606695\n",
      "Epoch 55:\t train loss : 0.5719601649210102; train accuracy : 0.9790185569565352; \n",
      " validation loss : 0.5975222217552965; validation accuracy : 0.9539748953974896\n",
      "Epoch 56:\t train loss : 0.5687210061613032; train accuracy : 0.98237615787354; \n",
      " validation loss : 0.6056493947025202; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57:\t train loss : 0.5765006878575742; train accuracy : 0.974367855261935; \n",
      " validation loss : 0.5942504908245442; validation accuracy : 0.9581589958158996\n",
      "Epoch 58:\t train loss : 0.5713239425263882; train accuracy : 0.979888162582484; \n",
      " validation loss : 0.6088962162170409; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5618858463201315; train accuracy : 0.9894919297376003; \n",
      " validation loss : 0.5998089743403545; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5641887993065834; train accuracy : 0.9869611821927569; \n",
      " validation loss : 0.5883416915613794; validation accuracy : 0.9623430962343096\n",
      "Epoch 61:\t train loss : 0.5629739837760651; train accuracy : 0.988258620155519; \n",
      " validation loss : 0.5994003392634912; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5627575622919382; train accuracy : 0.988510176895195; \n",
      " validation loss : 0.6047843919478202; validation accuracy : 0.9414225941422594\n",
      "Epoch 63:\t train loss : 0.5635291058642712; train accuracy : 0.9877009820626413; \n",
      " validation loss : 0.5899927408852929; validation accuracy : 0.9623430962343096\n",
      "Epoch 64:\t train loss : 0.5609615082291257; train accuracy : 0.9903417082313578; \n",
      " validation loss : 0.5785925450960153; validation accuracy : 0.9707112970711297\n",
      "Epoch 65:\t train loss : 0.5624864408031037; train accuracy : 0.988798599708789; \n",
      " validation loss : 0.5918986779064649; validation accuracy : 0.9581589958158996\n",
      "Epoch 66:\t train loss : 0.5676798936573109; train accuracy : 0.9835629976145481; \n",
      " validation loss : 0.6240176779702801; validation accuracy : 0.9246861924686193\n",
      "Epoch 67:\t train loss : 0.5645062153486757; train accuracy : 0.9866337247126615; \n",
      " validation loss : 0.592035427132066; validation accuracy : 0.9581589958158996\n",
      "Epoch 68:\t train loss : 0.5684251748114033; train accuracy : 0.9828253663372472; \n",
      " validation loss : 0.6056243940339597; validation accuracy : 0.9456066945606695\n",
      "Epoch 69:\t train loss : 0.575608615204523; train accuracy : 0.9752235199355618; \n",
      " validation loss : 0.6090647761514955; validation accuracy : 0.9414225941422594\n",
      "Epoch 70:\t train loss : 0.575167767287501; train accuracy : 0.9758954738374794; \n",
      " validation loss : 0.5907069422348329; validation accuracy : 0.9623430962343096\n",
      "Epoch 71:\t train loss : 0.5645922523999493; train accuracy : 0.9867347191672604; \n",
      " validation loss : 0.6008468589878042; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5644997550014013; train accuracy : 0.9866476656649834; \n",
      " validation loss : 0.6067939867264385; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5626484378958817; train accuracy : 0.988560364323554; \n",
      " validation loss : 0.6027655030215671; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.5624524729163078; train accuracy : 0.9886805663124633; \n",
      " validation loss : 0.5935785772103891; validation accuracy : 0.9581589958158996\n",
      "Epoch 75:\t train loss : 0.5597187631768313; train accuracy : 0.991561696458998; \n",
      " validation loss : 0.5996203988117607; validation accuracy : 0.9539748953974896\n",
      "Epoch 76:\t train loss : 0.5656612771657146; train accuracy : 0.9854372812044982; \n",
      " validation loss : 0.5956115553252032; validation accuracy : 0.9539748953974896\n",
      "Epoch 77:\t train loss : 0.5613071974957221; train accuracy : 0.9900281917035844; \n",
      " validation loss : 0.609804049377009; validation accuracy : 0.9414225941422594\n",
      "Epoch 78:\t train loss : 0.5642505799563695; train accuracy : 0.9869302022987081; \n",
      " validation loss : 0.5996674896017352; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.559454600525044; train accuracy : 0.9918464016853062; \n",
      " validation loss : 0.5895251011846339; validation accuracy : 0.9623430962343096\n",
      "Epoch 80:\t train loss : 0.5618688433829161; train accuracy : 0.9893872176957155; \n",
      " validation loss : 0.5817827040494672; validation accuracy : 0.9707112970711297\n",
      "Epoch 81:\t train loss : 0.5612890311531157; train accuracy : 0.9901056414387063; \n",
      " validation loss : 0.6089504571806319; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5706779046624803; train accuracy : 0.9803624647603705; \n",
      " validation loss : 0.6061631109325709; validation accuracy : 0.9456066945606695\n",
      "Epoch 83:\t train loss : 0.5672279805478514; train accuracy : 0.9839406425230026; \n",
      " validation loss : 0.6196444052171978; validation accuracy : 0.9288702928870293\n",
      "Epoch 84:\t train loss : 0.5689144663614611; train accuracy : 0.9821902785092474; \n",
      " validation loss : 0.581003785794122; validation accuracy : 0.9707112970711297\n",
      "Epoch 85:\t train loss : 0.5633693760174127; train accuracy : 0.9878190154589671; \n",
      " validation loss : 0.5861923427389454; validation accuracy : 0.9665271966527197\n",
      "Epoch 86:\t train loss : 0.5657423697245277; train accuracy : 0.9853929799560085; \n",
      " validation loss : 0.606284244510617; validation accuracy : 0.9456066945606695\n",
      "Epoch 87:\t train loss : 0.5601807214569872; train accuracy : 0.9911958239102823; \n",
      " validation loss : 0.5965102213185557; validation accuracy : 0.9497907949790795\n",
      "Epoch 88:\t train loss : 0.5606998769263984; train accuracy : 0.9905607360822826; \n",
      " validation loss : 0.6015054443599852; validation accuracy : 0.9497907949790795\n",
      "Epoch 89:\t train loss : 0.5647856745089392; train accuracy : 0.9864286378140587; \n",
      " validation loss : 0.5965543126620242; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5624290406426304; train accuracy : 0.9888295796028378; \n",
      " validation loss : 0.5974144927140501; validation accuracy : 0.9539748953974896\n",
      "Epoch 91:\t train loss : 0.5666215327928947; train accuracy : 0.9844496421822237; \n",
      " validation loss : 0.5999188760280046; validation accuracy : 0.9539748953974896\n",
      "Epoch 92:\t train loss : 0.5627656001612719; train accuracy : 0.9886031165773413; \n",
      " validation loss : 0.6198283670245692; validation accuracy : 0.9288702928870293\n",
      "Epoch 93:\t train loss : 0.5615745556573163; train accuracy : 0.9897029028160723; \n",
      " validation loss : 0.5880672225270425; validation accuracy : 0.9665271966527197\n",
      "Epoch 94:\t train loss : 0.5608350800352099; train accuracy : 0.9904870039344466; \n",
      " validation loss : 0.5864436935726425; validation accuracy : 0.9665271966527197\n",
      "Epoch 95:\t train loss : 0.5631490710489246; train accuracy : 0.9882254716688869; \n",
      " validation loss : 0.6154174415165258; validation accuracy : 0.9330543933054394\n",
      "Epoch 96:\t train loss : 0.5614140376131355; train accuracy : 0.9898556336937328; \n",
      " validation loss : 0.5934857505170477; validation accuracy : 0.9581589958158996\n",
      "Epoch 97:\t train loss : 0.5641922249759087; train accuracy : 0.98700765203383; \n",
      " validation loss : 0.5915392367348318; validation accuracy : 0.9623430962343096\n",
      "Epoch 98:\t train loss : 0.5637963242142054; train accuracy : 0.9874664642646922; \n",
      " validation loss : 0.5903037621944293; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5626977810916363; train accuracy : 0.9884754794138604; \n",
      " validation loss : 0.5814659246902281; validation accuracy : 0.9707112970711297\n",
      "Epoch 100:\t train loss : 0.5592989870111645; train accuracy : 0.9920942408376964; \n",
      " validation loss : 0.6045940314473197; validation accuracy : 0.9456066945606695\n",
      "Epoch 101:\t train loss : 0.567660235226532; train accuracy : 0.9835726013817033; \n",
      " validation loss : 0.6101226024948166; validation accuracy : 0.9372384937238494\n",
      "Epoch 102:\t train loss : 0.5680878536533146; train accuracy : 0.9831469376374733; \n",
      " validation loss : 0.5831251865018732; validation accuracy : 0.9665271966527197\n",
      "Epoch 103:\t train loss : 0.5666177679275706; train accuracy : 0.9845078843830354; \n",
      " validation loss : 0.5902346201587173; validation accuracy : 0.9623430962343096\n",
      "Epoch 104:\t train loss : 0.5611935772051564; train accuracy : 0.9900436816506087; \n",
      " validation loss : 0.5985734635487622; validation accuracy : 0.9497907949790795\n",
      "Epoch 105:\t train loss : 0.5595388844396787; train accuracy : 0.9917358034635522; \n",
      " validation loss : 0.6247321237138088; validation accuracy : 0.9288702928870293\n",
      "Epoch 106:\t train loss : 0.5620821541210878; train accuracy : 0.9891356609560396; \n",
      " validation loss : 0.599069113612606; validation accuracy : 0.9497907949790795\n",
      "Epoch 107:\t train loss : 0.5599388066086642; train accuracy : 0.991350723380526; \n",
      " validation loss : 0.6000266597355518; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108:\t train loss : 0.5599261246976832; train accuracy : 0.9913293472536324; \n",
      " validation loss : 0.6058366567377197; validation accuracy : 0.9497907949790795\n",
      "Epoch 109:\t train loss : 0.5625759919630818; train accuracy : 0.9887115462065119; \n",
      " validation loss : 0.6069702729983923; validation accuracy : 0.9414225941422594\n",
      "Epoch 110:\t train loss : 0.5708895877904456; train accuracy : 0.9802326590043062; \n",
      " validation loss : 0.601772190384986; validation accuracy : 0.9497907949790795\n",
      "Epoch 111:\t train loss : 0.5600668443102937; train accuracy : 0.9913817032745748; \n",
      " validation loss : 0.591081077791737; validation accuracy : 0.9581589958158996\n",
      "Epoch 112:\t train loss : 0.5593005052328174; train accuracy : 0.9920013011555501; \n",
      " validation loss : 0.5992860596086592; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5613285357906768; train accuracy : 0.9899566281483317; \n",
      " validation loss : 0.5966293217179661; validation accuracy : 0.9539748953974896\n",
      "Epoch 114:\t train loss : 0.5597458533763422; train accuracy : 0.991588958765761; \n",
      " validation loss : 0.6090055042445148; validation accuracy : 0.9414225941422594\n",
      "Early stopping at epoch 114\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5609615082291257; Train accuracy : 0.9903417082313578; \n",
      " Validation loss : 0.5785925450960153; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 97 ! ---\n",
      "Epoch 1:\t train loss : 0.9712038129257055; train accuracy : 0.5495919947953778; \n",
      " validation loss : 0.9019405187220089; validation accuracy : 0.6359832635983264\n",
      "Epoch 2:\t train loss : 0.7912180173842042; train accuracy : 0.7567263545958672; \n",
      " validation loss : 0.7976688567365335; validation accuracy : 0.7322175732217573\n",
      "Epoch 3:\t train loss : 0.7257682086269885; train accuracy : 0.8238427460578085; \n",
      " validation loss : 0.7386317307439705; validation accuracy : 0.8117154811715481\n",
      "Epoch 4:\t train loss : 0.6978547293114269; train accuracy : 0.8525573902537253; \n",
      " validation loss : 0.7159162839858595; validation accuracy : 0.8368200836820083\n",
      "Epoch 5:\t train loss : 0.6825533020586425; train accuracy : 0.8676718609622355; \n",
      " validation loss : 0.7129317375848441; validation accuracy : 0.8410041841004184\n",
      "Epoch 6:\t train loss : 0.6798209897309444; train accuracy : 0.870289662009356; \n",
      " validation loss : 0.7223760695091818; validation accuracy : 0.8242677824267782\n",
      "Epoch 7:\t train loss : 0.6697721240687102; train accuracy : 0.8810904922705164; \n",
      " validation loss : 0.667220668055644; validation accuracy : 0.8786610878661087\n",
      "Epoch 8:\t train loss : 0.6602628561776743; train accuracy : 0.8899950432169522; \n",
      " validation loss : 0.6496755488881057; validation accuracy : 0.9037656903765691\n",
      "Epoch 9:\t train loss : 0.6411171231346836; train accuracy : 0.9094584714520276; \n",
      " validation loss : 0.6379112274981419; validation accuracy : 0.9079497907949791\n",
      "Epoch 10:\t train loss : 0.6325730540257133; train accuracy : 0.9180281297437963; \n",
      " validation loss : 0.6577090000103148; validation accuracy : 0.895397489539749\n",
      "Epoch 11:\t train loss : 0.627239875570365; train accuracy : 0.9231884506954986; \n",
      " validation loss : 0.611386696734041; validation accuracy : 0.9372384937238494\n",
      "Epoch 12:\t train loss : 0.6246095395025935; train accuracy : 0.9265113541311689; \n",
      " validation loss : 0.6155519143911439; validation accuracy : 0.9414225941422594\n",
      "Epoch 13:\t train loss : 0.6128952463722875; train accuracy : 0.9384460485145141; \n",
      " validation loss : 0.6117868856278964; validation accuracy : 0.9414225941422594\n",
      "Epoch 14:\t train loss : 0.6100278687624944; train accuracy : 0.9411722791908051; \n",
      " validation loss : 0.6327545928548188; validation accuracy : 0.9121338912133892\n",
      "Epoch 15:\t train loss : 0.6193984197315694; train accuracy : 0.9314157811580285; \n",
      " validation loss : 0.6106181574288461; validation accuracy : 0.9414225941422594\n",
      "Epoch 16:\t train loss : 0.5965443803121545; train accuracy : 0.954668360234208; \n",
      " validation loss : 0.6094592435062091; validation accuracy : 0.9414225941422594\n",
      "Epoch 17:\t train loss : 0.5894327658800839; train accuracy : 0.9619796152297159; \n",
      " validation loss : 0.6005909781608519; validation accuracy : 0.9497907949790795\n",
      "Epoch 18:\t train loss : 0.5924519291842355; train accuracy : 0.9583896651073454; \n",
      " validation loss : 0.6140049569125231; validation accuracy : 0.9414225941422594\n",
      "Epoch 19:\t train loss : 0.5984519197809073; train accuracy : 0.9524740543387341; \n",
      " validation loss : 0.623244655424692; validation accuracy : 0.9288702928870293\n",
      "Epoch 20:\t train loss : 0.5912831311356018; train accuracy : 0.9596539545834754; \n",
      " validation loss : 0.6179366957709052; validation accuracy : 0.9330543933054394\n",
      "Epoch 21:\t train loss : 0.5822707201978287; train accuracy : 0.9691300845751107; \n",
      " validation loss : 0.5851724849326777; validation accuracy : 0.9665271966527197\n",
      "Epoch 22:\t train loss : 0.5864384706419963; train accuracy : 0.9647154496731621; \n",
      " validation loss : 0.6030304604901403; validation accuracy : 0.9497907949790795\n",
      "Epoch 23:\t train loss : 0.5852572332878739; train accuracy : 0.9659915115090306; \n",
      " validation loss : 0.595265849061338; validation accuracy : 0.9581589958158996\n",
      "Epoch 24:\t train loss : 0.5813017193682738; train accuracy : 0.9699259580532235; \n",
      " validation loss : 0.5905141862505789; validation accuracy : 0.9623430962343096\n",
      "Epoch 25:\t train loss : 0.5829267962616629; train accuracy : 0.9684448093187521; \n",
      " validation loss : 0.607287866479208; validation accuracy : 0.9414225941422594\n",
      "Epoch 26:\t train loss : 0.5821495283760543; train accuracy : 0.9689906750518913; \n",
      " validation loss : 0.6456404692785224; validation accuracy : 0.9037656903765691\n",
      "Epoch 27:\t train loss : 0.5812617769162478; train accuracy : 0.9699333932277951; \n",
      " validation loss : 0.609897582075693; validation accuracy : 0.9414225941422594\n",
      "Epoch 28:\t train loss : 0.5800986022676468; train accuracy : 0.9710331794665262; \n",
      " validation loss : 0.6159283755445419; validation accuracy : 0.9372384937238494\n",
      "Epoch 29:\t train loss : 0.585307540498358; train accuracy : 0.9654589671303324; \n",
      " validation loss : 0.6246913573871696; validation accuracy : 0.9288702928870293\n",
      "Epoch 30:\t train loss : 0.5805135639300563; train accuracy : 0.9704990860931255; \n",
      " validation loss : 0.5987486030069128; validation accuracy : 0.9497907949790795\n",
      "Epoch 31:\t train loss : 0.5794863874876188; train accuracy : 0.9715774962049629; \n",
      " validation loss : 0.5932147208326657; validation accuracy : 0.9581589958158996\n",
      "Epoch 32:\t train loss : 0.5803394575513258; train accuracy : 0.9708643390439605; \n",
      " validation loss : 0.654894770978049; validation accuracy : 0.891213389121339\n",
      "Epoch 33:\t train loss : 0.5848284685011084; train accuracy : 0.9662991418569349; \n",
      " validation loss : 0.6099689862730985; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5754051356913426; train accuracy : 0.975480962855107; \n",
      " validation loss : 0.5997331049376249; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.5708398617356398; train accuracy : 0.980350692400632; \n",
      " validation loss : 0.582647554858797; validation accuracy : 0.9748953974895398\n",
      "Epoch 36:\t train loss : 0.5735592980593255; train accuracy : 0.9775005421481459; \n",
      " validation loss : 0.5888514281331457; validation accuracy : 0.9623430962343096\n",
      "Epoch 37:\t train loss : 0.5720113858577072; train accuracy : 0.9793556182037857; \n",
      " validation loss : 0.591186467741868; validation accuracy : 0.9623430962343096\n",
      "Epoch 38:\t train loss : 0.5679402147277114; train accuracy : 0.983456736577961; \n",
      " validation loss : 0.5909874398565643; validation accuracy : 0.9581589958158996\n",
      "Epoch 39:\t train loss : 0.579289640406374; train accuracy : 0.9718371077170916; \n",
      " validation loss : 0.6154056819126585; validation accuracy : 0.9330543933054394\n",
      "Epoch 40:\t train loss : 0.575912404051314; train accuracy : 0.9752080299885374; \n",
      " validation loss : 0.6056120592040262; validation accuracy : 0.9456066945606695\n",
      "Epoch 41:\t train loss : 0.5763399919640843; train accuracy : 0.9746680504352675; \n",
      " validation loss : 0.6146389887897625; validation accuracy : 0.9414225941422594\n",
      "Epoch 42:\t train loss : 0.5690868858653059; train accuracy : 0.9821187149539948; \n",
      " validation loss : 0.5876561752769555; validation accuracy : 0.9665271966527197\n",
      "Epoch 43:\t train loss : 0.5650002539917605; train accuracy : 0.9864559001208216; \n",
      " validation loss : 0.5664532973547804; validation accuracy : 0.9832635983263598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:\t train loss : 0.5739149298336166; train accuracy : 0.9770785959912017; \n",
      " validation loss : 0.6240987044161526; validation accuracy : 0.9205020920502092\n",
      "Epoch 45:\t train loss : 0.5693038454330563; train accuracy : 0.9818377273149725; \n",
      " validation loss : 0.5871290035790929; validation accuracy : 0.9665271966527197\n",
      "Epoch 46:\t train loss : 0.5715381855350854; train accuracy : 0.9795569875151027; \n",
      " validation loss : 0.5982129273247256; validation accuracy : 0.9539748953974896\n",
      "Epoch 47:\t train loss : 0.567063490246931; train accuracy : 0.9842814213575389; \n",
      " validation loss : 0.5908743482954364; validation accuracy : 0.9623430962343096\n",
      "Epoch 48:\t train loss : 0.5662684839712766; train accuracy : 0.9849629790266118; \n",
      " validation loss : 0.573367803481865; validation accuracy : 0.9790794979079498\n",
      "Epoch 49:\t train loss : 0.5669481311983302; train accuracy : 0.9843433811456365; \n",
      " validation loss : 0.5977451052522791; validation accuracy : 0.9497907949790795\n",
      "Epoch 50:\t train loss : 0.570651903072707; train accuracy : 0.9805697202515568; \n",
      " validation loss : 0.5890913436504388; validation accuracy : 0.9623430962343096\n",
      "Epoch 51:\t train loss : 0.5645342778401384; train accuracy : 0.9868778462777658; \n",
      " validation loss : 0.5835406614661487; validation accuracy : 0.9665271966527197\n",
      "Epoch 52:\t train loss : 0.5706929376930067; train accuracy : 0.9804089346014436; \n",
      " validation loss : 0.5793994050144575; validation accuracy : 0.9707112970711297\n",
      "Epoch 53:\t train loss : 0.5695102683052018; train accuracy : 0.981527928374485; \n",
      " validation loss : 0.59239318087639; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.572768464538965; train accuracy : 0.9782772080919483; \n",
      " validation loss : 0.5979623577368199; validation accuracy : 0.9497907949790795\n",
      "Epoch 55:\t train loss : 0.5658063272294938; train accuracy : 0.9855014095851792; \n",
      " validation loss : 0.5911479468740093; validation accuracy : 0.9581589958158996\n",
      "Epoch 56:\t train loss : 0.5648143671068553; train accuracy : 0.9865643297499922; \n",
      " validation loss : 0.592098906704621; validation accuracy : 0.9581589958158996\n",
      "Epoch 57:\t train loss : 0.5685636558384723; train accuracy : 0.9825310573437839; \n",
      " validation loss : 0.5995906025297875; validation accuracy : 0.9497907949790795\n",
      "Epoch 58:\t train loss : 0.5756926521460275; train accuracy : 0.9753297809721491; \n",
      " validation loss : 0.6049140430736187; validation accuracy : 0.9456066945606695\n",
      "Epoch 59:\t train loss : 0.5779516496380219; train accuracy : 0.9731478670342948; \n",
      " validation loss : 0.599233992890439; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5733093807013442; train accuracy : 0.9778125096812169; \n",
      " validation loss : 0.5928591965533897; validation accuracy : 0.9539748953974896\n",
      "Epoch 61:\t train loss : 0.5736592047128055; train accuracy : 0.9772799653025187; \n",
      " validation loss : 0.5738982494960317; validation accuracy : 0.9790794979079498\n",
      "Epoch 62:\t train loss : 0.5811898570245974; train accuracy : 0.9698116422441835; \n",
      " validation loss : 0.5808386863199837; validation accuracy : 0.9707112970711297\n",
      "Epoch 63:\t train loss : 0.5709582274651354; train accuracy : 0.9800371758728585; \n",
      " validation loss : 0.6000989937011506; validation accuracy : 0.9497907949790795\n",
      "Epoch 64:\t train loss : 0.5684505177265068; train accuracy : 0.9825679234177019; \n",
      " validation loss : 0.5781257802111739; validation accuracy : 0.9748953974895398\n",
      "Epoch 65:\t train loss : 0.5664304077422219; train accuracy : 0.9848294556832615; \n",
      " validation loss : 0.5863234311576444; validation accuracy : 0.9623430962343096\n",
      "Epoch 66:\t train loss : 0.5640238735145928; train accuracy : 0.9871625515040738; \n",
      " validation loss : 0.5887136066503766; validation accuracy : 0.9623430962343096\n",
      "Epoch 67:\t train loss : 0.5652528750999272; train accuracy : 0.9858960934353604; \n",
      " validation loss : 0.5682045374335869; validation accuracy : 0.9832635983263598\n",
      "Epoch 68:\t train loss : 0.568938705772573; train accuracy : 0.9824204591220298; \n",
      " validation loss : 0.6134249812472228; validation accuracy : 0.9372384937238494\n",
      "Epoch 69:\t train loss : 0.5725545229831476; train accuracy : 0.9785191610644691; \n",
      " validation loss : 0.5777123041112302; validation accuracy : 0.9748953974895398\n",
      "Epoch 70:\t train loss : 0.5718390171452409; train accuracy : 0.9794389541187769; \n",
      " validation loss : 0.6043713283759384; validation accuracy : 0.9456066945606695\n",
      "Epoch 71:\t train loss : 0.5659579174127645; train accuracy : 0.9852631741999442; \n",
      " validation loss : 0.6020819639889493; validation accuracy : 0.9497907949790795\n",
      "Epoch 72:\t train loss : 0.5660909415466387; train accuracy : 0.9851643483379287; \n",
      " validation loss : 0.6010300156479337; validation accuracy : 0.9497907949790795\n",
      "Epoch 73:\t train loss : 0.5725144714151547; train accuracy : 0.9784107314352984; \n",
      " validation loss : 0.6082104764754319; validation accuracy : 0.9456066945606695\n",
      "Epoch 74:\t train loss : 0.5719781680795464; train accuracy : 0.979086402924502; \n",
      " validation loss : 0.5819210826376899; validation accuracy : 0.9707112970711297\n",
      "Epoch 75:\t train loss : 0.5639785441176902; train accuracy : 0.9873019610272933; \n",
      " validation loss : 0.5871959329828499; validation accuracy : 0.9665271966527197\n",
      "Epoch 76:\t train loss : 0.5666371000297604; train accuracy : 0.9845543542241085; \n",
      " validation loss : 0.6006806968724739; validation accuracy : 0.9497907949790795\n",
      "Epoch 77:\t train loss : 0.5667076691386018; train accuracy : 0.9844673007218315; \n",
      " validation loss : 0.5897460425197304; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5743164534129054; train accuracy : 0.9767687970507141; \n",
      " validation loss : 0.5928526931107448; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5696808152163592; train accuracy : 0.9813575389572168; \n",
      " validation loss : 0.5924833248731196; validation accuracy : 0.9581589958158996\n",
      "Epoch 80:\t train loss : 0.5659083845996005; train accuracy : 0.9852690603798135; \n",
      " validation loss : 0.5890093825233705; validation accuracy : 0.9623430962343096\n",
      "Epoch 81:\t train loss : 0.5655712295995338; train accuracy : 0.9855633693732767; \n",
      " validation loss : 0.5797170705455268; validation accuracy : 0.9707112970711297\n",
      "Epoch 82:\t train loss : 0.5651224118261754; train accuracy : 0.986146101180334; \n",
      " validation loss : 0.574661504512184; validation accuracy : 0.9790794979079498\n",
      "Epoch 83:\t train loss : 0.5673226081178168; train accuracy : 0.9838108367669383; \n",
      " validation loss : 0.5724320711886365; validation accuracy : 0.9790794979079498\n",
      "Epoch 84:\t train loss : 0.5788670632440021; train accuracy : 0.9722767124136436; \n",
      " validation loss : 0.6097551100309546; validation accuracy : 0.9372384937238494\n",
      "Epoch 85:\t train loss : 0.5738940456729914; train accuracy : 0.9773013414294123; \n",
      " validation loss : 0.579849401421032; validation accuracy : 0.9707112970711297\n",
      "Epoch 86:\t train loss : 0.5720292125232038; train accuracy : 0.9790303293162738; \n",
      " validation loss : 0.5903849192485943; validation accuracy : 0.9623430962343096\n",
      "Epoch 87:\t train loss : 0.5684130754335589; train accuracy : 0.9827169367080765; \n",
      " validation loss : 0.5891753681714036; validation accuracy : 0.9623430962343096\n",
      "Epoch 88:\t train loss : 0.5651363964726253; train accuracy : 0.9860125778369838; \n",
      " validation loss : 0.5843897547340613; validation accuracy : 0.9665271966527197\n",
      "Epoch 89:\t train loss : 0.5650361776127845; train accuracy : 0.9863010006505778; \n",
      " validation loss : 0.5658899952508226; validation accuracy : 0.9832635983263598\n",
      "Epoch 90:\t train loss : 0.5634568447928678; train accuracy : 0.9878654853000403; \n",
      " validation loss : 0.5895752603646397; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5659693824513862; train accuracy : 0.985257288020075; \n",
      " validation loss : 0.5748640793015553; validation accuracy : 0.9748953974895398\n",
      "Epoch 92:\t train loss : 0.5729172139796893; train accuracy : 0.9781319123888597; \n",
      " validation loss : 0.5870847996714602; validation accuracy : 0.9665271966527197\n",
      "Epoch 93:\t train loss : 0.5672712541013691; train accuracy : 0.9837451593915549; \n",
      " validation loss : 0.584745789090474; validation accuracy : 0.9665271966527197\n",
      "Epoch 94:\t train loss : 0.5652980162491582; train accuracy : 0.9860568790854736; \n",
      " validation loss : 0.5822084366378331; validation accuracy : 0.9665271966527197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95:\t train loss : 0.5638960788696517; train accuracy : 0.9873602032281049; \n",
      " validation loss : 0.5719843431839466; validation accuracy : 0.9790794979079498\n",
      "Epoch 96:\t train loss : 0.5627530683427573; train accuracy : 0.9883670497846897; \n",
      " validation loss : 0.596583137466368; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5599982118043245; train accuracy : 0.9912791598252734; \n",
      " validation loss : 0.5672017276753101; validation accuracy : 0.9832635983263598\n",
      "Epoch 98:\t train loss : 0.5616751911804525; train accuracy : 0.9895133058644939; \n",
      " validation loss : 0.5897875334153546; validation accuracy : 0.9623430962343096\n",
      "Epoch 99:\t train loss : 0.5652837173083084; train accuracy : 0.985944731869017; \n",
      " validation loss : 0.5888045018651323; validation accuracy : 0.9623430962343096\n",
      "Epoch 100:\t train loss : 0.5612159514902078; train accuracy : 0.9901734874066731; \n",
      " validation loss : 0.5881856023652025; validation accuracy : 0.9623430962343096\n",
      "Epoch 101:\t train loss : 0.5777898419657885; train accuracy : 0.9731943368753679; \n",
      " validation loss : 0.6082616041517458; validation accuracy : 0.9414225941422594\n",
      "Epoch 102:\t train loss : 0.5683717225695837; train accuracy : 0.9828039902103535; \n",
      " validation loss : 0.5979464422421542; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5652321249812322; train accuracy : 0.9860221816041389; \n",
      " validation loss : 0.5813206494499745; validation accuracy : 0.9623430962343096\n",
      "Epoch 104:\t train loss : 0.5606543007709955; train accuracy : 0.9905548499024134; \n",
      " validation loss : 0.5730707525465422; validation accuracy : 0.9790794979079498\n",
      "Epoch 105:\t train loss : 0.5602777107671404; train accuracy : 0.9910040583661204; \n",
      " validation loss : 0.6003429852686143; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.562895440022883; train accuracy : 0.9884076334458937; \n",
      " validation loss : 0.5717273258243375; validation accuracy : 0.9790794979079498\n",
      "Epoch 107:\t train loss : 0.5642926866797164; train accuracy : 0.9869419746584467; \n",
      " validation loss : 0.5934206555422101; validation accuracy : 0.9581589958158996\n",
      "Epoch 108:\t train loss : 0.5624972092794025; train accuracy : 0.9887735059946094; \n",
      " validation loss : 0.5795949652878926; validation accuracy : 0.9707112970711297\n",
      "Epoch 109:\t train loss : 0.5697530213804796; train accuracy : 0.9813036339415719; \n",
      " validation loss : 0.5893167384291693; validation accuracy : 0.9623430962343096\n",
      "Epoch 110:\t train loss : 0.5604051852941561; train accuracy : 0.9909266086309985; \n",
      " validation loss : 0.5984069212586145; validation accuracy : 0.9539748953974896\n",
      "Epoch 111:\t train loss : 0.5612897443607747; train accuracy : 0.9899101583072586; \n",
      " validation loss : 0.5793352133335996; validation accuracy : 0.9707112970711297\n",
      "Epoch 112:\t train loss : 0.563899395393763; train accuracy : 0.9872650949533752; \n",
      " validation loss : 0.5970151579469581; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5613316602109718; train accuracy : 0.9899507419684624; \n",
      " validation loss : 0.585787242676142; validation accuracy : 0.9665271966527197\n",
      "Epoch 114:\t train loss : 0.5605034643329622; train accuracy : 0.9909228910437127; \n",
      " validation loss : 0.5848495121825013; validation accuracy : 0.9707112970711297\n",
      "Epoch 115:\t train loss : 0.567986412159433; train accuracy : 0.983255367266644; \n",
      " validation loss : 0.5820577643371293; validation accuracy : 0.9665271966527197\n",
      "Epoch 116:\t train loss : 0.5623885152759254; train accuracy : 0.9888103720685275; \n",
      " validation loss : 0.5958851615796513; validation accuracy : 0.9497907949790795\n",
      "Epoch 117:\t train loss : 0.5626284882187145; train accuracy : 0.9886960562594876; \n",
      " validation loss : 0.5762521233134152; validation accuracy : 0.9790794979079498\n",
      "Epoch 118:\t train loss : 0.5609578144796268; train accuracy : 0.9903438768239412; \n",
      " validation loss : 0.5874221494118553; validation accuracy : 0.9623430962343096\n",
      "Epoch 119:\t train loss : 0.5607039082614791; train accuracy : 0.990539359955389; \n",
      " validation loss : 0.5804613132273762; validation accuracy : 0.9707112970711297\n",
      "Epoch 120:\t train loss : 0.5661018083063214; train accuracy : 0.9852049319991325; \n",
      " validation loss : 0.6027395816374278; validation accuracy : 0.9497907949790795\n",
      "Epoch 121:\t train loss : 0.5611896628578571; train accuracy : 0.9900436816506087; \n",
      " validation loss : 0.5687235218496142; validation accuracy : 0.9832635983263598\n",
      "Epoch 122:\t train loss : 0.5627241545574027; train accuracy : 0.9886591901855696; \n",
      " validation loss : 0.5787821132420146; validation accuracy : 0.9707112970711297\n",
      "Epoch 123:\t train loss : 0.558151642426912; train accuracy : 0.9933061742928839; \n",
      " validation loss : 0.6041208077944817; validation accuracy : 0.9456066945606695\n",
      "Epoch 124:\t train loss : 0.560775678075311; train accuracy : 0.9905666222621519; \n",
      " validation loss : 0.5891068079961536; validation accuracy : 0.9623430962343096\n",
      "Epoch 125:\t train loss : 0.5610835563500657; train accuracy : 0.9902258434276154; \n",
      " validation loss : 0.589509101320839; validation accuracy : 0.9623430962343096\n",
      "Epoch 126:\t train loss : 0.5592114075517547; train accuracy : 0.9921967842869978; \n",
      " validation loss : 0.5852219499940621; validation accuracy : 0.9665271966527197\n",
      "Epoch 127:\t train loss : 0.5606178669847586; train accuracy : 0.9905179838284953; \n",
      " validation loss : 0.5982775073522534; validation accuracy : 0.9539748953974896\n",
      "Epoch 128:\t train loss : 0.5611145291531184; train accuracy : 0.9901948635335667; \n",
      " validation loss : 0.5876251876350483; validation accuracy : 0.9623430962343096\n",
      "Epoch 129:\t train loss : 0.5646654254468157; train accuracy : 0.9866204033582205; \n",
      " validation loss : 0.599466175444665; validation accuracy : 0.9497907949790795\n",
      "Epoch 130:\t train loss : 0.5632048271682862; train accuracy : 0.9880919483255367; \n",
      " validation loss : 0.6035108341808091; validation accuracy : 0.9456066945606695\n",
      "Epoch 131:\t train loss : 0.5605557179977501; train accuracy : 0.9908256141763995; \n",
      " validation loss : 0.5998620029777796; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.560213274341236; train accuracy : 0.9910409244400384; \n",
      " validation loss : 0.5850324933248416; validation accuracy : 0.9665271966527197\n",
      "Epoch 133:\t train loss : 0.5573154910919879; train accuracy : 0.9940208804485888; \n",
      " validation loss : 0.5849441507385128; validation accuracy : 0.9623430962343096\n",
      "Epoch 134:\t train loss : 0.5585922534138852; train accuracy : 0.9927448186127203; \n",
      " validation loss : 0.607725424759671; validation accuracy : 0.9456066945606695\n",
      "Epoch 135:\t train loss : 0.565257731749605; train accuracy : 0.9859698255831965; \n",
      " validation loss : 0.5939640346834592; validation accuracy : 0.9581589958158996\n",
      "Epoch 136:\t train loss : 0.5652566050383122; train accuracy : 0.9858149261129527; \n",
      " validation loss : 0.5817849935622703; validation accuracy : 0.9665271966527197\n",
      "Epoch 137:\t train loss : 0.5668215829127043; train accuracy : 0.9843529849127916; \n",
      " validation loss : 0.5890927328028103; validation accuracy : 0.9623430962343096\n",
      "Epoch 138:\t train loss : 0.562070466776555; train accuracy : 0.9892072245112922; \n",
      " validation loss : 0.5958252775149456; validation accuracy : 0.9539748953974896\n",
      "Epoch 139:\t train loss : 0.5622642656434782; train accuracy : 0.9890619288082034; \n",
      " validation loss : 0.5897059955691445; validation accuracy : 0.9623430962343096\n",
      "Early stopping at epoch 139\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5650361776127845; Train accuracy : 0.9863010006505778; \n",
      " Validation loss : 0.5658899952508226; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 98 ! ---\n",
      "Epoch 1:\t train loss : 0.9276623470558025; train accuracy : 0.5995188822454227; \n",
      " validation loss : 0.78200929291233; validation accuracy : 0.7740585774058577\n",
      "Epoch 2:\t train loss : 0.7585671824058235; train accuracy : 0.7894048762353233; \n",
      " validation loss : 0.7285704736258917; validation accuracy : 0.8158995815899581\n",
      "Epoch 3:\t train loss : 0.695723166530437; train accuracy : 0.8546160042132656; \n",
      " validation loss : 0.6706068158658038; validation accuracy : 0.8870292887029289\n",
      "Epoch 4:\t train loss : 0.6604044807101948; train accuracy : 0.8905201524210787; \n",
      " validation loss : 0.693640528727469; validation accuracy : 0.8410041841004184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\t train loss : 0.6393331658201595; train accuracy : 0.9122525480962855; \n",
      " validation loss : 0.6608194670789387; validation accuracy : 0.891213389121339\n",
      "Epoch 6:\t train loss : 0.6279750276763567; train accuracy : 0.9229951361566343; \n",
      " validation loss : 0.6382214261268184; validation accuracy : 0.9079497907949791\n",
      "Epoch 7:\t train loss : 0.6207309450106411; train accuracy : 0.9305328541776388; \n",
      " validation loss : 0.6405268327762845; validation accuracy : 0.9079497907949791\n",
      "Epoch 8:\t train loss : 0.6053232778071093; train accuracy : 0.9462086805663125; \n",
      " validation loss : 0.6290840777817602; validation accuracy : 0.9246861924686193\n",
      "Epoch 9:\t train loss : 0.599574134704487; train accuracy : 0.9518993773041297; \n",
      " validation loss : 0.6225623886785703; validation accuracy : 0.9288702928870293\n",
      "Epoch 10:\t train loss : 0.5954817980657768; train accuracy : 0.9558706899222404; \n",
      " validation loss : 0.6130067987681219; validation accuracy : 0.9414225941422594\n",
      "Epoch 11:\t train loss : 0.5951494084771539; train accuracy : 0.956134019021655; \n",
      " validation loss : 0.6154565000457919; validation accuracy : 0.9246861924686193\n",
      "Epoch 12:\t train loss : 0.5866093653090623; train accuracy : 0.9649787787725765; \n",
      " validation loss : 0.6367450686129845; validation accuracy : 0.9079497907949791\n",
      "Epoch 13:\t train loss : 0.5879481607949031; train accuracy : 0.9633833142290653; \n",
      " validation loss : 0.6395626032842023; validation accuracy : 0.9079497907949791\n",
      "Epoch 14:\t train loss : 0.5931528899564102; train accuracy : 0.9580414510982372; \n",
      " validation loss : 0.6077486831567588; validation accuracy : 0.9497907949790795\n",
      "Epoch 15:\t train loss : 0.5793958874591605; train accuracy : 0.9719706310604418; \n",
      " validation loss : 0.6239404922793796; validation accuracy : 0.9246861924686193\n",
      "Epoch 16:\t train loss : 0.5759212248832285; train accuracy : 0.9754366616066174; \n",
      " validation loss : 0.6193009497213969; validation accuracy : 0.9330543933054394\n",
      "Epoch 17:\t train loss : 0.5789751867541276; train accuracy : 0.9723578797360513; \n",
      " validation loss : 0.6248213270584183; validation accuracy : 0.9246861924686193\n",
      "Epoch 18:\t train loss : 0.579917537310885; train accuracy : 0.9714476904488987; \n",
      " validation loss : 0.6118157883674937; validation accuracy : 0.9414225941422594\n",
      "Epoch 19:\t train loss : 0.5869105309475982; train accuracy : 0.9640493819511137; \n",
      " validation loss : 0.6106278871316754; validation accuracy : 0.9414225941422594\n",
      "Epoch 20:\t train loss : 0.58258387377555; train accuracy : 0.9686616685770935; \n",
      " validation loss : 0.621425127735555; validation accuracy : 0.9288702928870293\n",
      "Epoch 21:\t train loss : 0.5716509664630685; train accuracy : 0.9794950277270051; \n",
      " validation loss : 0.6031380906006296; validation accuracy : 0.9539748953974896\n",
      "Epoch 22:\t train loss : 0.5702988347285471; train accuracy : 0.981189318132532; \n",
      " validation loss : 0.6092788408314775; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.5703721404487563; train accuracy : 0.9809761764614765; \n",
      " validation loss : 0.5878419933869968; validation accuracy : 0.9665271966527197\n",
      "Epoch 24:\t train loss : 0.5683769326455415; train accuracy : 0.9832473124941913; \n",
      " validation loss : 0.5863073601150692; validation accuracy : 0.9665271966527197\n",
      "Epoch 25:\t train loss : 0.5710255707417876; train accuracy : 0.9802850150252487; \n",
      " validation loss : 0.6161995122494652; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5689167838671758; train accuracy : 0.9826277146132161; \n",
      " validation loss : 0.6221257399688241; validation accuracy : 0.9246861924686193\n",
      "Epoch 27:\t train loss : 0.5722487294937139; train accuracy : 0.9787087580160476; \n",
      " validation loss : 0.6495643923383205; validation accuracy : 0.895397489539749\n",
      "Epoch 28:\t train loss : 0.5731955177038884; train accuracy : 0.9777948511416091; \n",
      " validation loss : 0.6203640969803867; validation accuracy : 0.9330543933054394\n",
      "Epoch 29:\t train loss : 0.5689599589127864; train accuracy : 0.982292821958549; \n",
      " validation loss : 0.601902706293731; validation accuracy : 0.9497907949790795\n",
      "Epoch 30:\t train loss : 0.570504258574961; train accuracy : 0.9804863843365655; \n",
      " validation loss : 0.6070835870577914; validation accuracy : 0.9456066945606695\n",
      "Epoch 31:\t train loss : 0.5650625715858907; train accuracy : 0.9864035440998792; \n",
      " validation loss : 0.6401357224158812; validation accuracy : 0.9121338912133892\n",
      "Epoch 32:\t train loss : 0.5656630229301705; train accuracy : 0.9856445366956845; \n",
      " validation loss : 0.5946529447573751; validation accuracy : 0.9581589958158996\n",
      "Epoch 33:\t train loss : 0.5653977082020171; train accuracy : 0.9859174695622541; \n",
      " validation loss : 0.6161052375510473; validation accuracy : 0.9330543933054394\n",
      "Epoch 34:\t train loss : 0.5628633827161547; train accuracy : 0.9883899749062858; \n",
      " validation loss : 0.6115229096793633; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5724711387246518; train accuracy : 0.9787958115183246; \n",
      " validation loss : 0.6407763821693898; validation accuracy : 0.9079497907949791\n",
      "Epoch 36:\t train loss : 0.5711214213329348; train accuracy : 0.9798859939899005; \n",
      " validation loss : 0.6462216776355609; validation accuracy : 0.899581589958159\n",
      "Epoch 37:\t train loss : 0.568756339241423; train accuracy : 0.9823606679265157; \n",
      " validation loss : 0.6158034029849616; validation accuracy : 0.9330543933054394\n",
      "Epoch 38:\t train loss : 0.5662740457440595; train accuracy : 0.9848331732705474; \n",
      " validation loss : 0.5930312333597445; validation accuracy : 0.9539748953974896\n",
      "Epoch 39:\t train loss : 0.5635672137713656; train accuracy : 0.9877009820626413; \n",
      " validation loss : 0.6069875396446966; validation accuracy : 0.9456066945606695\n",
      "Epoch 40:\t train loss : 0.569179148381887; train accuracy : 0.9817410700455405; \n",
      " validation loss : 0.636661218911966; validation accuracy : 0.9121338912133892\n",
      "Epoch 41:\t train loss : 0.5627125287837849; train accuracy : 0.9885566467362682; \n",
      " validation loss : 0.6154002039724523; validation accuracy : 0.9372384937238494\n",
      "Epoch 42:\t train loss : 0.5609753447991562; train accuracy : 0.990223674835032; \n",
      " validation loss : 0.6072148638836737; validation accuracy : 0.9414225941422594\n",
      "Epoch 43:\t train loss : 0.5616212486074482; train accuracy : 0.9897840701384801; \n",
      " validation loss : 0.610140424362801; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5652760476411642; train accuracy : 0.9858960934353604; \n",
      " validation loss : 0.5860122314542592; validation accuracy : 0.9665271966527197\n",
      "Epoch 45:\t train loss : 0.5922432437087455; train accuracy : 0.9581161126428948; \n",
      " validation loss : 0.6461233490392019; validation accuracy : 0.899581589958159\n",
      "Epoch 46:\t train loss : 0.5807826146731443; train accuracy : 0.9701930047399238; \n",
      " validation loss : 0.6365577091202053; validation accuracy : 0.9163179916317992\n",
      "Epoch 47:\t train loss : 0.5706489508240035; train accuracy : 0.9806412838068094; \n",
      " validation loss : 0.5991512274042986; validation accuracy : 0.9497907949790795\n",
      "Epoch 48:\t train loss : 0.5653413787473266; train accuracy : 0.9859698255831965; \n",
      " validation loss : 0.5970877291426387; validation accuracy : 0.9539748953974896\n",
      "Epoch 49:\t train loss : 0.5633060214371629; train accuracy : 0.9881554571083367; \n",
      " validation loss : 0.6070084541135246; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5634726401037725; train accuracy : 0.9879894048762353; \n",
      " validation loss : 0.6074400166367206; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5664278284943595; train accuracy : 0.984891415471359; \n",
      " validation loss : 0.588290364140081; validation accuracy : 0.9623430962343096\n",
      "Epoch 52:\t train loss : 0.5647134087581356; train accuracy : 0.9864825428297035; \n",
      " validation loss : 0.6206527620179858; validation accuracy : 0.9330543933054394\n",
      "Epoch 53:\t train loss : 0.5686802556075313; train accuracy : 0.9825214535766288; \n",
      " validation loss : 0.594910714776951; validation accuracy : 0.9581589958158996\n",
      "Epoch 54:\t train loss : 0.5598700596527831; train accuracy : 0.9914591530096967; \n",
      " validation loss : 0.5869462853158738; validation accuracy : 0.9623430962343096\n",
      "Epoch 55:\t train loss : 0.5614458878328631; train accuracy : 0.9898481985191611; \n",
      " validation loss : 0.588513375938406; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56:\t train loss : 0.5659605412435816; train accuracy : 0.9851023885498311; \n",
      " validation loss : 0.6040843283803916; validation accuracy : 0.9414225941422594\n",
      "Epoch 57:\t train loss : 0.5592031814921039; train accuracy : 0.9920883546578271; \n",
      " validation loss : 0.5926201125894187; validation accuracy : 0.9581589958158996\n",
      "Epoch 58:\t train loss : 0.5573775589156456; train accuracy : 0.9939840143746709; \n",
      " validation loss : 0.6073500799111167; validation accuracy : 0.9414225941422594\n",
      "Epoch 59:\t train loss : 0.5600216240634999; train accuracy : 0.9913271786610489; \n",
      " validation loss : 0.6010099836359223; validation accuracy : 0.9497907949790795\n",
      "Epoch 60:\t train loss : 0.5599824799666517; train accuracy : 0.9914628705969826; \n",
      " validation loss : 0.6138674522249721; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5744296530053267; train accuracy : 0.9764397905759162; \n",
      " validation loss : 0.6025485420964289; validation accuracy : 0.9539748953974896\n",
      "Epoch 62:\t train loss : 0.5657360088231677; train accuracy : 0.98549552340531; \n",
      " validation loss : 0.6317841870031573; validation accuracy : 0.9205020920502092\n",
      "Epoch 63:\t train loss : 0.567715674443489; train accuracy : 0.9833210446420273; \n",
      " validation loss : 0.6054390768820966; validation accuracy : 0.9456066945606695\n",
      "Epoch 64:\t train loss : 0.5623868982934793; train accuracy : 0.9888568419096007; \n",
      " validation loss : 0.5868256316811024; validation accuracy : 0.9623430962343096\n",
      "Epoch 65:\t train loss : 0.5602463479173296; train accuracy : 0.9910815081012423; \n",
      " validation loss : 0.6013944176456099; validation accuracy : 0.9497907949790795\n",
      "Epoch 66:\t train loss : 0.562625977536227; train accuracy : 0.9885758542705784; \n",
      " validation loss : 0.5905001140191648; validation accuracy : 0.9581589958158996\n",
      "Epoch 67:\t train loss : 0.5628584227845843; train accuracy : 0.9883766535518449; \n",
      " validation loss : 0.5777277993294647; validation accuracy : 0.9748953974895398\n",
      "Epoch 68:\t train loss : 0.5632928622914375; train accuracy : 0.9880048948232597; \n",
      " validation loss : 0.5918732215447183; validation accuracy : 0.9623430962343096\n",
      "Epoch 69:\t train loss : 0.5615593139703652; train accuracy : 0.9896815266891787; \n",
      " validation loss : 0.5984200916708147; validation accuracy : 0.9539748953974896\n",
      "Epoch 70:\t train loss : 0.5606517957130466; train accuracy : 0.9906536757644289; \n",
      " validation loss : 0.5979229414049058; validation accuracy : 0.9539748953974896\n",
      "Epoch 71:\t train loss : 0.5633312420828528; train accuracy : 0.9878574305275876; \n",
      " validation loss : 0.5928305344310446; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5658280023663967; train accuracy : 0.9854180736701881; \n",
      " validation loss : 0.607886652328513; validation accuracy : 0.9456066945606695\n",
      "Epoch 73:\t train loss : 0.5577185355174071; train accuracy : 0.9935753895721676; \n",
      " validation loss : 0.5839805268954291; validation accuracy : 0.9665271966527197\n",
      "Epoch 74:\t train loss : 0.5580365884824274; train accuracy : 0.9932361597323337; \n",
      " validation loss : 0.6090396581235015; validation accuracy : 0.9414225941422594\n",
      "Epoch 75:\t train loss : 0.5602192699806773; train accuracy : 0.9910158307258589; \n",
      " validation loss : 0.595286147413947; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5617578429758964; train accuracy : 0.9894860435577311; \n",
      " validation loss : 0.5942672739929068; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5580097456478619; train accuracy : 0.9932250069704761; \n",
      " validation loss : 0.5951112668614285; validation accuracy : 0.9539748953974896\n",
      "Epoch 78:\t train loss : 0.5577143370548251; train accuracy : 0.9936838192013383; \n",
      " validation loss : 0.5925071365123091; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5684067706558859; train accuracy : 0.9825812447721429; \n",
      " validation loss : 0.5999847653989112; validation accuracy : 0.9539748953974896\n",
      "Epoch 80:\t train loss : 0.569138448130614; train accuracy : 0.9820332104464202; \n",
      " validation loss : 0.5981819765350634; validation accuracy : 0.9539748953974896\n",
      "Epoch 81:\t train loss : 0.5584857664849205; train accuracy : 0.9927795160940549; \n",
      " validation loss : 0.609620516126799; validation accuracy : 0.9414225941422594\n",
      "Epoch 82:\t train loss : 0.5595012279806897; train accuracy : 0.9918058180241024; \n",
      " validation loss : 0.6043402659513282; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.557855374351161; train accuracy : 0.9934204901019238; \n",
      " validation loss : 0.5973259293615729; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.5810301660238661; train accuracy : 0.9699200718733542; \n",
      " validation loss : 0.5893841841780093; validation accuracy : 0.9623430962343096\n",
      "Epoch 85:\t train loss : 0.563690719458748; train accuracy : 0.9874376529632268; \n",
      " validation loss : 0.5942888379256234; validation accuracy : 0.9581589958158996\n",
      "Epoch 86:\t train loss : 0.5581602823165552; train accuracy : 0.9931571610025094; \n",
      " validation loss : 0.5957451600025983; validation accuracy : 0.9539748953974896\n",
      "Epoch 87:\t train loss : 0.5590423928566081; train accuracy : 0.9922373679482016; \n",
      " validation loss : 0.5889790038643449; validation accuracy : 0.9623430962343096\n",
      "Epoch 88:\t train loss : 0.5623942618752502; train accuracy : 0.988761733634871; \n",
      " validation loss : 0.5984586608552911; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5600238991821499; train accuracy : 0.9912577836983797; \n",
      " validation loss : 0.5788217484972448; validation accuracy : 0.9707112970711297\n",
      "Epoch 90:\t train loss : 0.5601889389740404; train accuracy : 0.9910409244400384; \n",
      " validation loss : 0.5906708741523365; validation accuracy : 0.9623430962343096\n",
      "Epoch 91:\t train loss : 0.5578226818393575; train accuracy : 0.9935657858050125; \n",
      " validation loss : 0.5866358467716623; validation accuracy : 0.9623430962343096\n",
      "Epoch 92:\t train loss : 0.557657991214431; train accuracy : 0.9937110815081013; \n",
      " validation loss : 0.6010587331510561; validation accuracy : 0.9497907949790795\n",
      "Epoch 93:\t train loss : 0.5604137012309132; train accuracy : 0.9907813129279098; \n",
      " validation loss : 0.6143564319405501; validation accuracy : 0.9372384937238494\n",
      "Epoch 94:\t train loss : 0.5727698186998482; train accuracy : 0.9784534836890858; \n",
      " validation loss : 0.6058129971729168; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.5570542206494918; train accuracy : 0.9943498869233867; \n",
      " validation loss : 0.5987545884200846; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.5670022868766178; train accuracy : 0.9840704482790669; \n",
      " validation loss : 0.598040970201526; validation accuracy : 0.9539748953974896\n",
      "Epoch 97:\t train loss : 0.5579957870646601; train accuracy : 0.9932944019331453; \n",
      " validation loss : 0.5731805643050286; validation accuracy : 0.9790794979079498\n",
      "Epoch 98:\t train loss : 0.5584345920972156; train accuracy : 0.9929306979770129; \n",
      " validation loss : 0.6044953639249339; validation accuracy : 0.9414225941422594\n",
      "Epoch 99:\t train loss : 0.5590129540644798; train accuracy : 0.9922801202019889; \n",
      " validation loss : 0.594780536486554; validation accuracy : 0.9539748953974896\n",
      "Epoch 100:\t train loss : 0.5590396327697502; train accuracy : 0.9921946156944144; \n",
      " validation loss : 0.5909515237561274; validation accuracy : 0.9623430962343096\n",
      "Epoch 101:\t train loss : 0.560361627891099; train accuracy : 0.990901514916819; \n",
      " validation loss : 0.5976321832442101; validation accuracy : 0.9539748953974896\n",
      "Epoch 102:\t train loss : 0.5586439517035401; train accuracy : 0.9925434493014034; \n",
      " validation loss : 0.5979311552689528; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5566538033796409; train accuracy : 0.9946906657579231; \n",
      " validation loss : 0.6038053477369851; validation accuracy : 0.9456066945606695\n",
      "Epoch 104:\t train loss : 0.5627972574864314; train accuracy : 0.9885411567892438; \n",
      " validation loss : 0.6245333208114733; validation accuracy : 0.9246861924686193\n",
      "Epoch 105:\t train loss : 0.576057780641851; train accuracy : 0.9746386195359212; \n",
      " validation loss : 0.6192667273014556; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.566672402319299; train accuracy : 0.9844437560023545; \n",
      " validation loss : 0.5976958943454016; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107:\t train loss : 0.5584317636730574; train accuracy : 0.9928975494903808; \n",
      " validation loss : 0.5907312387470831; validation accuracy : 0.9623430962343096\n",
      "Epoch 108:\t train loss : 0.5568059177573053; train accuracy : 0.9945202763406549; \n",
      " validation loss : 0.5835553315888915; validation accuracy : 0.9665271966527197\n",
      "Epoch 109:\t train loss : 0.5580255174292105; train accuracy : 0.9933489265466712; \n",
      " validation loss : 0.589177161169519; validation accuracy : 0.9623430962343096\n",
      "Epoch 110:\t train loss : 0.5563461902702173; train accuracy : 0.9950218408253043; \n",
      " validation loss : 0.6138770857118326; validation accuracy : 0.9372384937238494\n",
      "Epoch 111:\t train loss : 0.557120557962055; train accuracy : 0.9942008736330121; \n",
      " validation loss : 0.5744838648345324; validation accuracy : 0.9748953974895398\n",
      "Epoch 112:\t train loss : 0.5556671244199658; train accuracy : 0.9955853650980514; \n",
      " validation loss : 0.598464557609334; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5560748610372555; train accuracy : 0.9952910561045881; \n",
      " validation loss : 0.5916454099003134; validation accuracy : 0.9581589958158996\n",
      "Epoch 114:\t train loss : 0.5579167330489122; train accuracy : 0.9933740202608506; \n",
      " validation loss : 0.5942735448253393; validation accuracy : 0.9581589958158996\n",
      "Epoch 115:\t train loss : 0.5576802831675682; train accuracy : 0.9936801016140525; \n",
      " validation loss : 0.5957539765842638; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5590446093685906; train accuracy : 0.9922218780011772; \n",
      " validation loss : 0.5739460159432456; validation accuracy : 0.9790794979079498\n",
      "Epoch 117:\t train loss : 0.5589947096787685; train accuracy : 0.9923885498311595; \n",
      " validation loss : 0.5891012818424617; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5558307865175058; train accuracy : 0.9955949688652065; \n",
      " validation loss : 0.6033273135013856; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5578027479126352; train accuracy : 0.9934765637101521; \n",
      " validation loss : 0.6109219559113823; validation accuracy : 0.9414225941422594\n",
      "Epoch 120:\t train loss : 0.5686726506942011; train accuracy : 0.9824049691750054; \n",
      " validation loss : 0.5977916610070041; validation accuracy : 0.9497907949790795\n",
      "Epoch 121:\t train loss : 0.5642661149074373; train accuracy : 0.9869574646054711; \n",
      " validation loss : 0.5917724926626624; validation accuracy : 0.9581589958158996\n",
      "Epoch 122:\t train loss : 0.5568867697140422; train accuracy : 0.994365376870411; \n",
      " validation loss : 0.5800331125317602; validation accuracy : 0.9707112970711297\n",
      "Epoch 123:\t train loss : 0.5580708938406316; train accuracy : 0.9931977446637132; \n",
      " validation loss : 0.5786744670691358; validation accuracy : 0.9748953974895398\n",
      "Epoch 124:\t train loss : 0.5555025351516933; train accuracy : 0.9958428080175966; \n",
      " validation loss : 0.5819542234156332; validation accuracy : 0.9707112970711297\n",
      "Epoch 125:\t train loss : 0.5570647280248139; train accuracy : 0.994278323368134; \n",
      " validation loss : 0.5920405392314615; validation accuracy : 0.9581589958158996\n",
      "Epoch 126:\t train loss : 0.5555349284329207; train accuracy : 0.995831035657858; \n",
      " validation loss : 0.5929542351550671; validation accuracy : 0.9581589958158996\n",
      "Epoch 127:\t train loss : 0.5554439969171887; train accuracy : 0.9959763313609468; \n",
      " validation loss : 0.5786821958738144; validation accuracy : 0.9748953974895398\n",
      "Epoch 128:\t train loss : 0.5595352865274038; train accuracy : 0.9917128783419561; \n",
      " validation loss : 0.5839815146740552; validation accuracy : 0.9707112970711297\n",
      "Epoch 129:\t train loss : 0.5565473449227694; train accuracy : 0.9947777192602001; \n",
      " validation loss : 0.5818847469622203; validation accuracy : 0.9707112970711297\n",
      "Epoch 130:\t train loss : 0.5617888263880854; train accuracy : 0.9894203661823476; \n",
      " validation loss : 0.599333720009131; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5572673226263193; train accuracy : 0.9939530344806221; \n",
      " validation loss : 0.5969825078909194; validation accuracy : 0.9539748953974896\n",
      "Epoch 132:\t train loss : 0.5565369789337787; train accuracy : 0.9947430217788655; \n",
      " validation loss : 0.5717590035835306; validation accuracy : 0.9790794979079498\n",
      "Epoch 133:\t train loss : 0.5565262773148051; train accuracy : 0.9949038074289785; \n",
      " validation loss : 0.5849703115999274; validation accuracy : 0.9665271966527197\n",
      "Epoch 134:\t train loss : 0.5548364876347075; train accuracy : 0.9965494594008488; \n",
      " validation loss : 0.5761104921678628; validation accuracy : 0.9748953974895398\n",
      "Epoch 135:\t train loss : 0.5557219192640077; train accuracy : 0.9956024040397782; \n",
      " validation loss : 0.5852707254387879; validation accuracy : 0.9665271966527197\n",
      "Epoch 136:\t train loss : 0.5566152982292129; train accuracy : 0.9948455652281669; \n",
      " validation loss : 0.5914675243042011; validation accuracy : 0.9581589958158996\n",
      "Epoch 137:\t train loss : 0.5588987641103692; train accuracy : 0.9923591189318133; \n",
      " validation loss : 0.5977838045220509; validation accuracy : 0.9539748953974896\n",
      "Epoch 138:\t train loss : 0.5571866476057635; train accuracy : 0.9941079339508658; \n",
      " validation loss : 0.5929322567573615; validation accuracy : 0.9581589958158996\n",
      "Epoch 139:\t train loss : 0.5563527827191945; train accuracy : 0.9950100684655658; \n",
      " validation loss : 0.5921718917080088; validation accuracy : 0.9581589958158996\n",
      "Epoch 140:\t train loss : 0.5574655317722118; train accuracy : 0.9937708727036153; \n",
      " validation loss : 0.6164530095750556; validation accuracy : 0.9330543933054394\n",
      "Epoch 141:\t train loss : 0.5590865527431452; train accuracy : 0.9921562006257938; \n",
      " validation loss : 0.5895059085489451; validation accuracy : 0.9581589958158996\n",
      "Epoch 142:\t train loss : 0.5591803688167155; train accuracy : 0.9921754081601041; \n",
      " validation loss : 0.6076977483121927; validation accuracy : 0.9456066945606695\n",
      "Epoch 143:\t train loss : 0.5592856695570774; train accuracy : 0.9921001270175656; \n",
      " validation loss : 0.5914736856469364; validation accuracy : 0.9581589958158996\n",
      "Epoch 144:\t train loss : 0.5602276007622036; train accuracy : 0.9910365872548715; \n",
      " validation loss : 0.5998496233929433; validation accuracy : 0.9497907949790795\n",
      "Epoch 145:\t train loss : 0.555953900234004; train accuracy : 0.9953663372471266; \n",
      " validation loss : 0.5803632381051307; validation accuracy : 0.9707112970711297\n",
      "Epoch 146:\t train loss : 0.5552381500013206; train accuracy : 0.9961371170110598; \n",
      " validation loss : 0.589477084446715; validation accuracy : 0.9623430962343096\n",
      "Epoch 147:\t train loss : 0.5545079385183816; train accuracy : 0.9969484804361969; \n",
      " validation loss : 0.5806812637870545; validation accuracy : 0.9665271966527197\n",
      "Epoch 148:\t train loss : 0.5539614242057908; train accuracy : 0.9974014064871898; \n",
      " validation loss : 0.5724226596825768; validation accuracy : 0.9790794979079498\n",
      "Epoch 149:\t train loss : 0.5597962511939096; train accuracy : 0.9914377768828031; \n",
      " validation loss : 0.6069720397380353; validation accuracy : 0.9456066945606695\n",
      "Epoch 150:\t train loss : 0.5569290548025898; train accuracy : 0.9944951826264754; \n",
      " validation loss : 0.6001631719344781; validation accuracy : 0.9497907949790795\n",
      "Epoch 151:\t train loss : 0.589381621312953; train accuracy : 0.9612360977725456; \n",
      " validation loss : 0.5959810221239167; validation accuracy : 0.9581589958158996\n",
      "Epoch 152:\t train loss : 0.5651512292818431; train accuracy : 0.9859890331175067; \n",
      " validation loss : 0.5871418967959274; validation accuracy : 0.9623430962343096\n",
      "Epoch 153:\t train loss : 0.5577689479401403; train accuracy : 0.993503826016915; \n",
      " validation loss : 0.5925438184560391; validation accuracy : 0.9581589958158996\n",
      "Epoch 154:\t train loss : 0.556452494725349; train accuracy : 0.9949347873230273; \n",
      " validation loss : 0.5826039199642996; validation accuracy : 0.9665271966527197\n",
      "Epoch 155:\t train loss : 0.557494979769417; train accuracy : 0.9938136249574027; \n",
      " validation loss : 0.5921890839796106; validation accuracy : 0.9581589958158996\n",
      "Epoch 156:\t train loss : 0.5635678953213827; train accuracy : 0.9875556863595526; \n",
      " validation loss : 0.6015978641113344; validation accuracy : 0.9497907949790795\n",
      "Epoch 157:\t train loss : 0.5593261608784116; train accuracy : 0.9919393413674525; \n",
      " validation loss : 0.5845219660568877; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158:\t train loss : 0.5563018927286586; train accuracy : 0.9950469345394839; \n",
      " validation loss : 0.584573627940409; validation accuracy : 0.9623430962343096\n",
      "Epoch 159:\t train loss : 0.5580869100224595; train accuracy : 0.9932693082189659; \n",
      " validation loss : 0.5940513274512569; validation accuracy : 0.9581589958158996\n",
      "Epoch 160:\t train loss : 0.5579172876013735; train accuracy : 0.9934551875832585; \n",
      " validation loss : 0.5924460129157976; validation accuracy : 0.9581589958158996\n",
      "Epoch 161:\t train loss : 0.5579420513617481; train accuracy : 0.9932906843458595; \n",
      " validation loss : 0.5824553132672075; validation accuracy : 0.9665271966527197\n",
      "Epoch 162:\t train loss : 0.5577849693488451; train accuracy : 0.9935016574243316; \n",
      " validation loss : 0.5858005305174376; validation accuracy : 0.9665271966527197\n",
      "Epoch 163:\t train loss : 0.5578367487929027; train accuracy : 0.9934920536571765; \n",
      " validation loss : 0.5897117431052672; validation accuracy : 0.9623430962343096\n",
      "Epoch 164:\t train loss : 0.556920663182094; train accuracy : 0.9944214504786394; \n",
      " validation loss : 0.5986139020035298; validation accuracy : 0.9539748953974896\n",
      "Epoch 165:\t train loss : 0.5568527893252503; train accuracy : 0.9945741813562997; \n",
      " validation loss : 0.5903139499177897; validation accuracy : 0.9581589958158996\n",
      "Epoch 166:\t train loss : 0.5573984986987653; train accuracy : 0.9938579262058924; \n",
      " validation loss : 0.5784891551632092; validation accuracy : 0.9707112970711297\n",
      "Epoch 167:\t train loss : 0.5579705423186314; train accuracy : 0.9934632423557112; \n",
      " validation loss : 0.6100192734324629; validation accuracy : 0.9414225941422594\n",
      "Epoch 168:\t train loss : 0.5575454829774324; train accuracy : 0.993829114904427; \n",
      " validation loss : 0.6104543203510301; validation accuracy : 0.9414225941422594\n",
      "Epoch 169:\t train loss : 0.5576748697179279; train accuracy : 0.9936875367886242; \n",
      " validation loss : 0.5933715682271957; validation accuracy : 0.9581589958158996\n",
      "Epoch 170:\t train loss : 0.556005253080475; train accuracy : 0.9953006598717432; \n",
      " validation loss : 0.5898688976345365; validation accuracy : 0.9623430962343096\n",
      "Epoch 171:\t train loss : 0.5601625441491523; train accuracy : 0.9911183741751604; \n",
      " validation loss : 0.5950893369059844; validation accuracy : 0.9497907949790795\n",
      "Epoch 172:\t train loss : 0.5549278103290887; train accuracy : 0.996444747358964; \n",
      " validation loss : 0.5766925236155593; validation accuracy : 0.9748953974895398\n",
      "Epoch 173:\t train loss : 0.5605016696143446; train accuracy : 0.9908101242293751; \n",
      " validation loss : 0.5942095763501282; validation accuracy : 0.9581589958158996\n",
      "Epoch 174:\t train loss : 0.5582821524007108; train accuracy : 0.9931320672883298; \n",
      " validation loss : 0.5890715237139822; validation accuracy : 0.9623430962343096\n",
      "Epoch 175:\t train loss : 0.5550708333023792; train accuracy : 0.9963133926081973; \n",
      " validation loss : 0.5915883863628694; validation accuracy : 0.9581589958158996\n",
      "Epoch 176:\t train loss : 0.5559946233455254; train accuracy : 0.9954224108553549; \n",
      " validation loss : 0.5683000665833398; validation accuracy : 0.9832635983263598\n",
      "Epoch 177:\t train loss : 0.5566857433767155; train accuracy : 0.9947430217788655; \n",
      " validation loss : 0.5879535725488477; validation accuracy : 0.9623430962343096\n",
      "Epoch 178:\t train loss : 0.5572415084327581; train accuracy : 0.9941020477709966; \n",
      " validation loss : 0.583021450874724; validation accuracy : 0.9665271966527197\n",
      "Epoch 179:\t train loss : 0.5634727169837916; train accuracy : 0.987708417237213; \n",
      " validation loss : 0.5925324313594477; validation accuracy : 0.9581589958158996\n",
      "Epoch 180:\t train loss : 0.567373014399187; train accuracy : 0.9838108367669383; \n",
      " validation loss : 0.5930890406993354; validation accuracy : 0.9581589958158996\n",
      "Epoch 181:\t train loss : 0.5562133566433548; train accuracy : 0.995180457882834; \n",
      " validation loss : 0.6015771161493235; validation accuracy : 0.9497907949790795\n",
      "Epoch 182:\t train loss : 0.5560881354207707; train accuracy : 0.9952520214380867; \n",
      " validation loss : 0.5874740533122951; validation accuracy : 0.9623430962343096\n",
      "Epoch 183:\t train loss : 0.5546529503585719; train accuracy : 0.996710245050962; \n",
      " validation loss : 0.5974676536874435; validation accuracy : 0.9539748953974896\n",
      "Epoch 184:\t train loss : 0.5552488543959397; train accuracy : 0.9961253446513213; \n",
      " validation loss : 0.6194719576310216; validation accuracy : 0.9288702928870293\n",
      "Epoch 185:\t train loss : 0.5558071012969609; train accuracy : 0.9955484990241333; \n",
      " validation loss : 0.6016737754147049; validation accuracy : 0.9497907949790795\n",
      "Epoch 186:\t train loss : 0.5549830596998456; train accuracy : 0.9964255398246538; \n",
      " validation loss : 0.5894418003378121; validation accuracy : 0.9623430962343096\n",
      "Epoch 187:\t train loss : 0.5552627753273006; train accuracy : 0.9960847609901174; \n",
      " validation loss : 0.6058264950127427; validation accuracy : 0.9456066945606695\n",
      "Epoch 188:\t train loss : 0.5565459345080667; train accuracy : 0.9948300752811425; \n",
      " validation loss : 0.5940112037327192; validation accuracy : 0.9539748953974896\n",
      "Epoch 189:\t train loss : 0.5554295786584762; train accuracy : 0.9959881037206852; \n",
      " validation loss : 0.5971651097648627; validation accuracy : 0.9539748953974896\n",
      "Epoch 190:\t train loss : 0.55605809226624; train accuracy : 0.9952792837448495; \n",
      " validation loss : 0.5890972048459838; validation accuracy : 0.9623430962343096\n",
      "Epoch 191:\t train loss : 0.555305133008918; train accuracy : 0.9960906471699866; \n",
      " validation loss : 0.5974596008837307; validation accuracy : 0.9539748953974896\n",
      "Epoch 192:\t train loss : 0.5625049490335426; train accuracy : 0.9887793921744787; \n",
      " validation loss : 0.6137803999389243; validation accuracy : 0.9372384937238494\n",
      "Epoch 193:\t train loss : 0.5572499335564552; train accuracy : 0.994117537718021; \n",
      " validation loss : 0.589183517201006; validation accuracy : 0.9623430962343096\n",
      "Epoch 194:\t train loss : 0.5560477080277823; train accuracy : 0.9953353573530779; \n",
      " validation loss : 0.597073454502803; validation accuracy : 0.9539748953974896\n",
      "Epoch 195:\t train loss : 0.5546461173948817; train accuracy : 0.9967663186591902; \n",
      " validation loss : 0.6052461974842446; validation accuracy : 0.9456066945606695\n",
      "Epoch 196:\t train loss : 0.5570304493411351; train accuracy : 0.9943167384367545; \n",
      " validation loss : 0.5880641105306823; validation accuracy : 0.9623430962343096\n",
      "Epoch 197:\t train loss : 0.5547417254165509; train accuracy : 0.9966018154217913; \n",
      " validation loss : 0.5806663975463049; validation accuracy : 0.9707112970711297\n",
      "Epoch 198:\t train loss : 0.5548782414299993; train accuracy : 0.996522197094086; \n",
      " validation loss : 0.6045519203624081; validation accuracy : 0.9456066945606695\n",
      "Epoch 199:\t train loss : 0.5627030406463863; train accuracy : 0.9885315530220886; \n",
      " validation loss : 0.5750058819514082; validation accuracy : 0.9748953974895398\n",
      "Epoch 200:\t train loss : 0.5600444389430906; train accuracy : 0.9911781653706744; \n",
      " validation loss : 0.6061239731209753; validation accuracy : 0.9456066945606695\n",
      "Epoch 201:\t train loss : 0.557326419506721; train accuracy : 0.9941485176120698; \n",
      " validation loss : 0.5928989733684855; validation accuracy : 0.9581589958158996\n",
      "Epoch 202:\t train loss : 0.5588189592774159; train accuracy : 0.9925161869946405; \n",
      " validation loss : 0.5988218846967349; validation accuracy : 0.9539748953974896\n",
      "Epoch 203:\t train loss : 0.5590048066922759; train accuracy : 0.9922956101490132; \n",
      " validation loss : 0.5870557174407955; validation accuracy : 0.9623430962343096\n",
      "Epoch 204:\t train loss : 0.5552506135095351; train accuracy : 0.9961312308311906; \n",
      " validation loss : 0.5929355083502204; validation accuracy : 0.9581589958158996\n",
      "Epoch 205:\t train loss : 0.5558066538537904; train accuracy : 0.9954961430031909; \n",
      " validation loss : 0.5981686664324648; validation accuracy : 0.9539748953974896\n",
      "Epoch 206:\t train loss : 0.5553174274429968; train accuracy : 0.9961312308311906; \n",
      " validation loss : 0.6103714312773177; validation accuracy : 0.9414225941422594\n",
      "Epoch 207:\t train loss : 0.556894269904464; train accuracy : 0.994405960531615; \n",
      " validation loss : 0.5849087178073245; validation accuracy : 0.9665271966527197\n",
      "Epoch 208:\t train loss : 0.5565998152397031; train accuracy : 0.994768115493045; \n",
      " validation loss : 0.5829822582087638; validation accuracy : 0.9707112970711297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209:\t train loss : 0.5560365174412973; train accuracy : 0.9953530158926857; \n",
      " validation loss : 0.6059529834246202; validation accuracy : 0.9456066945606695\n",
      "Epoch 210:\t train loss : 0.5577537824927913; train accuracy : 0.9935871619319062; \n",
      " validation loss : 0.6143653785079461; validation accuracy : 0.9372384937238494\n",
      "Epoch 211:\t train loss : 0.5541261898616974; train accuracy : 0.9972347346572075; \n",
      " validation loss : 0.5920565716400469; validation accuracy : 0.9581589958158996\n",
      "Epoch 212:\t train loss : 0.5578231911645974; train accuracy : 0.9935016574243316; \n",
      " validation loss : 0.5813555906028985; validation accuracy : 0.9707112970711297\n",
      "Epoch 213:\t train loss : 0.5558865058937524; train accuracy : 0.995533009077109; \n",
      " validation loss : 0.5975963175880692; validation accuracy : 0.9539748953974896\n",
      "Epoch 214:\t train loss : 0.5565845896328628; train accuracy : 0.9947777192602001; \n",
      " validation loss : 0.5841479485613219; validation accuracy : 0.9665271966527197\n",
      "Epoch 215:\t train loss : 0.5555092784737614; train accuracy : 0.9958679017317761; \n",
      " validation loss : 0.5730716293006327; validation accuracy : 0.9790794979079498\n",
      "Epoch 216:\t train loss : 0.5577929033320557; train accuracy : 0.993604200873633; \n",
      " validation loss : 0.5810041199470252; validation accuracy : 0.9707112970711297\n",
      "Epoch 217:\t train loss : 0.554613110216009; train accuracy : 0.9968031847331082; \n",
      " validation loss : 0.5840074512644756; validation accuracy : 0.9665271966527197\n",
      "Epoch 218:\t train loss : 0.5546760092000409; train accuracy : 0.9967176802255336; \n",
      " validation loss : 0.5935425739259884; validation accuracy : 0.9581589958158996\n",
      "Epoch 219:\t train loss : 0.5803687161746103; train accuracy : 0.9706443817962143; \n",
      " validation loss : 0.5807333977143457; validation accuracy : 0.9707112970711297\n",
      "Epoch 220:\t train loss : 0.5567167715650271; train accuracy : 0.994594008488491; \n",
      " validation loss : 0.5962510859105978; validation accuracy : 0.9539748953974896\n",
      "Epoch 221:\t train loss : 0.5538539410606047; train accuracy : 0.9975312122432541; \n",
      " validation loss : 0.5938331518491478; validation accuracy : 0.9581589958158996\n",
      "Epoch 222:\t train loss : 0.5541888826830548; train accuracy : 0.9972561107841011; \n",
      " validation loss : 0.5807334118192543; validation accuracy : 0.9707112970711297\n",
      "Epoch 223:\t train loss : 0.5563548836611626; train accuracy : 0.994969484804362; \n",
      " validation loss : 0.5974061907447956; validation accuracy : 0.9539748953974896\n",
      "Epoch 224:\t train loss : 0.5543925967052102; train accuracy : 0.9969890640974007; \n",
      " validation loss : 0.5982428218771516; validation accuracy : 0.9539748953974896\n",
      "Epoch 225:\t train loss : 0.5554207861842466; train accuracy : 0.9959667275937916; \n",
      " validation loss : 0.5999004337346774; validation accuracy : 0.9539748953974896\n",
      "Epoch 226:\t train loss : 0.5554220525452734; train accuracy : 0.9959261439325877; \n",
      " validation loss : 0.5722827911150976; validation accuracy : 0.9790794979079498\n",
      "Early stopping at epoch 226\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5559946233455254; Train accuracy : 0.9954224108553549; \n",
      " Validation loss : 0.5683000665833398; Validation accuracy : 0.9832635983263598\n",
      "--- Let's train model 99 ! ---\n",
      "Epoch 1:\t train loss : 0.9377157624212825; train accuracy : 0.5946358313454568; \n",
      " validation loss : 0.882915694329364; validation accuracy : 0.6569037656903766\n",
      "Epoch 2:\t train loss : 0.7575740121613029; train accuracy : 0.7910223365036092; \n",
      " validation loss : 0.7702531276849041; validation accuracy : 0.7907949790794979\n",
      "Epoch 3:\t train loss : 0.6974092554793017; train accuracy : 0.8526782118405155; \n",
      " validation loss : 0.7153008433742746; validation accuracy : 0.8368200836820083\n",
      "Epoch 4:\t train loss : 0.6719588694986947; train accuracy : 0.8791681898447907; \n",
      " validation loss : 0.7096669941705239; validation accuracy : 0.8410041841004184\n",
      "Epoch 5:\t train loss : 0.6535458388926724; train accuracy : 0.8973555562439977; \n",
      " validation loss : 0.7163073467649025; validation accuracy : 0.8368200836820083\n",
      "Epoch 6:\t train loss : 0.6465548865081405; train accuracy : 0.903592118714954; \n",
      " validation loss : 0.7007765852907375; validation accuracy : 0.8451882845188284\n",
      "Epoch 7:\t train loss : 0.634973717999183; train accuracy : 0.9160401499426872; \n",
      " validation loss : 0.6827770260343238; validation accuracy : 0.8661087866108786\n",
      "Epoch 8:\t train loss : 0.6259648969016942; train accuracy : 0.9247609901174138; \n",
      " validation loss : 0.6541945534321841; validation accuracy : 0.899581589958159\n",
      "Epoch 9:\t train loss : 0.6137665569416987; train accuracy : 0.9378056941045262; \n",
      " validation loss : 0.6755437897099879; validation accuracy : 0.8744769874476988\n",
      "Epoch 10:\t train loss : 0.6061039867706207; train accuracy : 0.9452755661575637; \n",
      " validation loss : 0.6354653565325733; validation accuracy : 0.9163179916317992\n",
      "Epoch 11:\t train loss : 0.6002728328407766; train accuracy : 0.9517231017069921; \n",
      " validation loss : 0.676844642487829; validation accuracy : 0.8786610878661087\n",
      "Epoch 12:\t train loss : 0.5957160332765543; train accuracy : 0.955557173394467; \n",
      " validation loss : 0.6526578346059904; validation accuracy : 0.9037656903765691\n",
      "Epoch 13:\t train loss : 0.591138314090602; train accuracy : 0.960513956442269; \n",
      " validation loss : 0.6261577442483756; validation accuracy : 0.9246861924686193\n",
      "Epoch 14:\t train loss : 0.5876189016124665; train accuracy : 0.9639254623749187; \n",
      " validation loss : 0.6360878189363911; validation accuracy : 0.9163179916317992\n",
      "Epoch 15:\t train loss : 0.5884373727229528; train accuracy : 0.9629399919452275; \n",
      " validation loss : 0.7076957214371989; validation accuracy : 0.8410041841004184\n",
      "Epoch 16:\t train loss : 0.5941135599037951; train accuracy : 0.9567477307227609; \n",
      " validation loss : 0.651059043530282; validation accuracy : 0.895397489539749\n",
      "Epoch 17:\t train loss : 0.5840048926276253; train accuracy : 0.9674357941695839; \n",
      " validation loss : 0.6301548252729993; validation accuracy : 0.9205020920502092\n",
      "Epoch 18:\t train loss : 0.582957305937365; train accuracy : 0.9685067691068496; \n",
      " validation loss : 0.6348969672928781; validation accuracy : 0.9079497907949791\n",
      "Epoch 19:\t train loss : 0.5789096990568908; train accuracy : 0.9724006319898386; \n",
      " validation loss : 0.6385624028779302; validation accuracy : 0.9121338912133892\n",
      "Epoch 20:\t train loss : 0.5779311699674368; train accuracy : 0.9734266860807336; \n",
      " validation loss : 0.6068995595990998; validation accuracy : 0.9456066945606695\n",
      "Epoch 21:\t train loss : 0.5795963918223589; train accuracy : 0.9716859258341336; \n",
      " validation loss : 0.6168685519284339; validation accuracy : 0.9330543933054394\n",
      "Epoch 22:\t train loss : 0.5847575730227303; train accuracy : 0.966369156417485; \n",
      " validation loss : 0.6100247928370983; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.5844554893793371; train accuracy : 0.9665764119086713; \n",
      " validation loss : 0.6437845924009096; validation accuracy : 0.9079497907949791\n",
      "Epoch 24:\t train loss : 0.5856599106135447; train accuracy : 0.9653527060937451; \n",
      " validation loss : 0.6172008503755186; validation accuracy : 0.9330543933054394\n",
      "Epoch 25:\t train loss : 0.5761342422238679; train accuracy : 0.9752448960624555; \n",
      " validation loss : 0.6118366170595247; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.572981660442052; train accuracy : 0.978472691223396; \n",
      " validation loss : 0.6358153278221753; validation accuracy : 0.9121338912133892\n",
      "Epoch 27:\t train loss : 0.5754498207396214; train accuracy : 0.975957433625577; \n",
      " validation loss : 0.6255269870797346; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.5749638698962048; train accuracy : 0.9762266489048608; \n",
      " validation loss : 0.6254538200984742; validation accuracy : 0.9163179916317992\n",
      "Epoch 29:\t train loss : 0.5709719298493353; train accuracy : 0.9801861891632331; \n",
      " validation loss : 0.605258427310487; validation accuracy : 0.9414225941422594\n",
      "Epoch 30:\t train loss : 0.5696616159161099; train accuracy : 0.9815530220886645; \n",
      " validation loss : 0.5963359799012972; validation accuracy : 0.9581589958158996\n",
      "Epoch 31:\t train loss : 0.5699445975186762; train accuracy : 0.9814777409461259; \n",
      " validation loss : 0.6195407904353036; validation accuracy : 0.9246861924686193\n",
      "Epoch 32:\t train loss : 0.5703254661667561; train accuracy : 0.9809297066204034; \n",
      " validation loss : 0.6186667077477915; validation accuracy : 0.9288702928870293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:\t train loss : 0.5744697159973781; train accuracy : 0.9767223272096409; \n",
      " validation loss : 0.636776376348724; validation accuracy : 0.9121338912133892\n",
      "Epoch 34:\t train loss : 0.5705880181415631; train accuracy : 0.9806450013940953; \n",
      " validation loss : 0.6109720552562444; validation accuracy : 0.9372384937238494\n",
      "Epoch 35:\t train loss : 0.5657848397041848; train accuracy : 0.9855515970135382; \n",
      " validation loss : 0.625955800188465; validation accuracy : 0.9288702928870293\n",
      "Epoch 36:\t train loss : 0.576956714637962; train accuracy : 0.9744858886582608; \n",
      " validation loss : 0.6592030007862067; validation accuracy : 0.891213389121339\n",
      "Epoch 37:\t train loss : 0.5708838528295814; train accuracy : 0.980300504972273; \n",
      " validation loss : 0.6430257427084726; validation accuracy : 0.9079497907949791\n",
      "Epoch 38:\t train loss : 0.576826373390898; train accuracy : 0.9741723721304874; \n",
      " validation loss : 0.6081203059062091; validation accuracy : 0.9456066945606695\n",
      "Epoch 39:\t train loss : 0.5655828309779304; train accuracy : 0.9858186437002385; \n",
      " validation loss : 0.6010044023724586; validation accuracy : 0.9497907949790795\n",
      "Epoch 40:\t train loss : 0.5706324765587178; train accuracy : 0.9806044177328913; \n",
      " validation loss : 0.5998887512937896; validation accuracy : 0.9497907949790795\n",
      "Epoch 41:\t train loss : 0.5640245487176391; train accuracy : 0.9873174509743177; \n",
      " validation loss : 0.613427137482516; validation accuracy : 0.9414225941422594\n",
      "Epoch 42:\t train loss : 0.5698749262907143; train accuracy : 0.9810750023234921; \n",
      " validation loss : 0.6083117879857806; validation accuracy : 0.9414225941422594\n",
      "Epoch 43:\t train loss : 0.5735144478139577; train accuracy : 0.9777136838192013; \n",
      " validation loss : 0.6164947296336094; validation accuracy : 0.9330543933054394\n",
      "Epoch 44:\t train loss : 0.5670316397033265; train accuracy : 0.9840859382260913; \n",
      " validation loss : 0.5981378064797974; validation accuracy : 0.9539748953974896\n",
      "Epoch 45:\t train loss : 0.5640288730340984; train accuracy : 0.9871529477369188; \n",
      " validation loss : 0.6283316952009; validation accuracy : 0.9246861924686193\n",
      "Epoch 46:\t train loss : 0.5702013798948469; train accuracy : 0.9808736330121751; \n",
      " validation loss : 0.6057483392407474; validation accuracy : 0.9414225941422594\n",
      "Epoch 47:\t train loss : 0.5681023211528136; train accuracy : 0.9828622324111651; \n",
      " validation loss : 0.6198357820750908; validation accuracy : 0.9288702928870293\n",
      "Epoch 48:\t train loss : 0.5684143364374931; train accuracy : 0.9826122246661917; \n",
      " validation loss : 0.6191254086129744; validation accuracy : 0.9330543933054394\n",
      "Epoch 49:\t train loss : 0.5693295665822269; train accuracy : 0.9816171504693454; \n",
      " validation loss : 0.6131957174392771; validation accuracy : 0.9372384937238494\n",
      "Epoch 50:\t train loss : 0.5632965485620599; train accuracy : 0.9879215589082685; \n",
      " validation loss : 0.6135889504744618; validation accuracy : 0.9330543933054394\n",
      "Epoch 51:\t train loss : 0.560829427859316; train accuracy : 0.9905548499024134; \n",
      " validation loss : 0.6331330748838132; validation accuracy : 0.9163179916317992\n",
      "Epoch 52:\t train loss : 0.5678238334669355; train accuracy : 0.9832590848539298; \n",
      " validation loss : 0.624536685787815; validation accuracy : 0.9246861924686193\n",
      "Epoch 53:\t train loss : 0.5617810245366508; train accuracy : 0.9896254530809505; \n",
      " validation loss : 0.600159379777805; validation accuracy : 0.9539748953974896\n",
      "Epoch 54:\t train loss : 0.5664568335497642; train accuracy : 0.984730629821246; \n",
      " validation loss : 0.619066604351139; validation accuracy : 0.9288702928870293\n",
      "Epoch 55:\t train loss : 0.5655360115785051; train accuracy : 0.9858459060070015; \n",
      " validation loss : 0.6279300961349124; validation accuracy : 0.9246861924686193\n",
      "Epoch 56:\t train loss : 0.5873676725054172; train accuracy : 0.9633046252981815; \n",
      " validation loss : 0.7626682851873364; validation accuracy : 0.7907949790794979\n",
      "Epoch 57:\t train loss : 0.5940909650965349; train accuracy : 0.956344992100127; \n",
      " validation loss : 0.6100656253112389; validation accuracy : 0.9372384937238494\n",
      "Epoch 58:\t train loss : 0.5781915094408728; train accuracy : 0.9727665045385545; \n",
      " validation loss : 0.6131613046910713; validation accuracy : 0.9330543933054394\n",
      "Epoch 59:\t train loss : 0.5712532184053029; train accuracy : 0.9798277517890889; \n",
      " validation loss : 0.6050035145273011; validation accuracy : 0.9456066945606695\n",
      "Epoch 60:\t train loss : 0.5656521905835196; train accuracy : 0.9855708045478484; \n",
      " validation loss : 0.5910924772225374; validation accuracy : 0.9581589958158996\n",
      "Epoch 61:\t train loss : 0.5609701227541909; train accuracy : 0.9902295610149013; \n",
      " validation loss : 0.6077925562004229; validation accuracy : 0.9414225941422594\n",
      "Epoch 62:\t train loss : 0.5621799312866558; train accuracy : 0.989123888596301; \n",
      " validation loss : 0.6127438369576296; validation accuracy : 0.9372384937238494\n",
      "Epoch 63:\t train loss : 0.5638942316433116; train accuracy : 0.9873756931751293; \n",
      " validation loss : 0.5952422844813193; validation accuracy : 0.9581589958158996\n",
      "Epoch 64:\t train loss : 0.5613263042198613; train accuracy : 0.9898578022863161; \n",
      " validation loss : 0.5951082409360374; validation accuracy : 0.9539748953974896\n",
      "Epoch 65:\t train loss : 0.5612231574900229; train accuracy : 0.9901056414387063; \n",
      " validation loss : 0.6011689850548824; validation accuracy : 0.9456066945606695\n",
      "Epoch 66:\t train loss : 0.5639880887244935; train accuracy : 0.9872415502338981; \n",
      " validation loss : 0.6242687071678488; validation accuracy : 0.9288702928870293\n",
      "Epoch 67:\t train loss : 0.5743773474443863; train accuracy : 0.976685461135723; \n",
      " validation loss : 0.6496056154220365; validation accuracy : 0.899581589958159\n",
      "Epoch 68:\t train loss : 0.5647322589057099; train accuracy : 0.9864596177081074; \n",
      " validation loss : 0.623586266441716; validation accuracy : 0.9288702928870293\n",
      "Epoch 69:\t train loss : 0.562847254080781; train accuracy : 0.9884423309272282; \n",
      " validation loss : 0.6068489876047899; validation accuracy : 0.9414225941422594\n",
      "Epoch 70:\t train loss : 0.5602995841765498; train accuracy : 0.9909826822392267; \n",
      " validation loss : 0.5965344823772215; validation accuracy : 0.9539748953974896\n",
      "Epoch 71:\t train loss : 0.5726488353567626; train accuracy : 0.9784144490225843; \n",
      " validation loss : 0.5930384466855632; validation accuracy : 0.9581589958158996\n",
      "Epoch 72:\t train loss : 0.5660193860816934; train accuracy : 0.9849880727407913; \n",
      " validation loss : 0.6128390087402842; validation accuracy : 0.9414225941422594\n",
      "Epoch 73:\t train loss : 0.5636670127820076; train accuracy : 0.9875807800737322; \n",
      " validation loss : 0.597637366475909; validation accuracy : 0.9539748953974896\n",
      "Epoch 74:\t train loss : 0.5622888420257373; train accuracy : 0.9888915393909353; \n",
      " validation loss : 0.6025172350684105; validation accuracy : 0.9497907949790795\n",
      "Epoch 75:\t train loss : 0.5604937127854946; train accuracy : 0.9908395551287215; \n",
      " validation loss : 0.6059903922429817; validation accuracy : 0.9456066945606695\n",
      "Epoch 76:\t train loss : 0.5625615056582035; train accuracy : 0.9886864524923324; \n",
      " validation loss : 0.5865192069589894; validation accuracy : 0.9623430962343096\n",
      "Epoch 77:\t train loss : 0.5604661797465132; train accuracy : 0.9908491588958765; \n",
      " validation loss : 0.6015109916798296; validation accuracy : 0.9497907949790795\n",
      "Epoch 78:\t train loss : 0.5635536733532798; train accuracy : 0.9876427398618297; \n",
      " validation loss : 0.5991562624531844; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5630965455125054; train accuracy : 0.9881229282195855; \n",
      " validation loss : 0.6121496146837458; validation accuracy : 0.9372384937238494\n",
      "Epoch 80:\t train loss : 0.5747064346867387; train accuracy : 0.9763019300473993; \n",
      " validation loss : 0.6384383070843925; validation accuracy : 0.9037656903765691\n",
      "Epoch 81:\t train loss : 0.563837052636621; train accuracy : 0.9874664642646922; \n",
      " validation loss : 0.6020701122320062; validation accuracy : 0.9497907949790795\n",
      "Epoch 82:\t train loss : 0.5642596525899594; train accuracy : 0.9870017658539608; \n",
      " validation loss : 0.5998938398134653; validation accuracy : 0.9539748953974896\n",
      "Epoch 83:\t train loss : 0.5610901567327519; train accuracy : 0.9903070107500233; \n",
      " validation loss : 0.6011957272996156; validation accuracy : 0.9497907949790795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84:\t train loss : 0.5647891477124382; train accuracy : 0.9865835372843025; \n",
      " validation loss : 0.5987471918775887; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5639651266545093; train accuracy : 0.9871817590383841; \n",
      " validation loss : 0.5990267656403856; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5608744886269228; train accuracy : 0.9904213265590631; \n",
      " validation loss : 0.6170003555177467; validation accuracy : 0.9330543933054394\n",
      "Epoch 87:\t train loss : 0.5625169539062054; train accuracy : 0.988785278354348; \n",
      " validation loss : 0.5780118015243771; validation accuracy : 0.9748953974895398\n",
      "Epoch 88:\t train loss : 0.5578921817063748; train accuracy : 0.9934359800489482; \n",
      " validation loss : 0.5922367522256737; validation accuracy : 0.9581589958158996\n",
      "Epoch 89:\t train loss : 0.5604980523329751; train accuracy : 0.990874252610056; \n",
      " validation loss : 0.5948031123807954; validation accuracy : 0.9539748953974896\n",
      "Epoch 90:\t train loss : 0.5610201791269673; train accuracy : 0.9904272127389324; \n",
      " validation loss : 0.6152784210579983; validation accuracy : 0.9330543933054394\n",
      "Epoch 91:\t train loss : 0.5619119083059954; train accuracy : 0.9893776139285604; \n",
      " validation loss : 0.6042688000486856; validation accuracy : 0.9456066945606695\n",
      "Epoch 92:\t train loss : 0.5618514101017608; train accuracy : 0.9893407478546423; \n",
      " validation loss : 0.5959490598147185; validation accuracy : 0.9539748953974896\n",
      "Epoch 93:\t train loss : 0.5619134059255616; train accuracy : 0.9892905604262834; \n",
      " validation loss : 0.6113057493125346; validation accuracy : 0.9372384937238494\n",
      "Epoch 94:\t train loss : 0.557109857302703; train accuracy : 0.9943189070293379; \n",
      " validation loss : 0.618539438450851; validation accuracy : 0.9330543933054394\n",
      "Epoch 95:\t train loss : 0.5577683954648472; train accuracy : 0.9933777378481365; \n",
      " validation loss : 0.597159737449627; validation accuracy : 0.9539748953974896\n",
      "Epoch 96:\t train loss : 0.561708502635798; train accuracy : 0.9896468292078441; \n",
      " validation loss : 0.6076027343417485; validation accuracy : 0.9456066945606695\n",
      "Epoch 97:\t train loss : 0.560980507296826; train accuracy : 0.9901772049939589; \n",
      " validation loss : 0.6214890466521399; validation accuracy : 0.9288702928870293\n",
      "Epoch 98:\t train loss : 0.5634674905121786; train accuracy : 0.9877297933641067; \n",
      " validation loss : 0.6011575518080439; validation accuracy : 0.9497907949790795\n",
      "Epoch 99:\t train loss : 0.5687185887004541; train accuracy : 0.9823857616406952; \n",
      " validation loss : 0.6008186314905887; validation accuracy : 0.9497907949790795\n",
      "Epoch 100:\t train loss : 0.5643762780798637; train accuracy : 0.9868992224046593; \n",
      " validation loss : 0.6290049910173051; validation accuracy : 0.9205020920502092\n",
      "Epoch 101:\t train loss : 0.5628438335347992; train accuracy : 0.9885256668422194; \n",
      " validation loss : 0.6378512489353413; validation accuracy : 0.9079497907949791\n",
      "Epoch 102:\t train loss : 0.5652029916466932; train accuracy : 0.9859484494563029; \n",
      " validation loss : 0.5979551854449994; validation accuracy : 0.9539748953974896\n",
      "Epoch 103:\t train loss : 0.5572927471103694; train accuracy : 0.9940363703956132; \n",
      " validation loss : 0.5947818660639844; validation accuracy : 0.9581589958158996\n",
      "Epoch 104:\t train loss : 0.5557456954161956; train accuracy : 0.9956665324204591; \n",
      " validation loss : 0.6031461941283068; validation accuracy : 0.9497907949790795\n",
      "Epoch 105:\t train loss : 0.5606029805950756; train accuracy : 0.9906322996375352; \n",
      " validation loss : 0.6057034776924178; validation accuracy : 0.9456066945606695\n",
      "Epoch 106:\t train loss : 0.5626255675003802; train accuracy : 0.9886938876669041; \n",
      " validation loss : 0.6044896248238654; validation accuracy : 0.9539748953974896\n",
      "Epoch 107:\t train loss : 0.5581004709352703; train accuracy : 0.9932597044518108; \n",
      " validation loss : 0.5909054965028223; validation accuracy : 0.9623430962343096\n",
      "Epoch 108:\t train loss : 0.5578266074656627; train accuracy : 0.9934824498900213; \n",
      " validation loss : 0.5916716776894881; validation accuracy : 0.9539748953974896\n",
      "Epoch 109:\t train loss : 0.5630248955327118; train accuracy : 0.9883339012980575; \n",
      " validation loss : 0.6099064352872039; validation accuracy : 0.9414225941422594\n",
      "Epoch 110:\t train loss : 0.5619771260958832; train accuracy : 0.9891415471359087; \n",
      " validation loss : 0.5916408591475172; validation accuracy : 0.9581589958158996\n",
      "Epoch 111:\t train loss : 0.5581173145353417; train accuracy : 0.9932810805787045; \n",
      " validation loss : 0.5998512975485695; validation accuracy : 0.9497907949790795\n",
      "Epoch 112:\t train loss : 0.5571633831894895; train accuracy : 0.9942473434740853; \n",
      " validation loss : 0.595395944702946; validation accuracy : 0.9539748953974896\n",
      "Epoch 113:\t train loss : 0.5589570906026705; train accuracy : 0.9923340252176337; \n",
      " validation loss : 0.6376562537958227; validation accuracy : 0.9121338912133892\n",
      "Epoch 114:\t train loss : 0.572717099563848; train accuracy : 0.9784785774032653; \n",
      " validation loss : 0.5923672530622657; validation accuracy : 0.9581589958158996\n",
      "Epoch 115:\t train loss : 0.5717124092118002; train accuracy : 0.9792722822887946; \n",
      " validation loss : 0.6162403413412443; validation accuracy : 0.9330543933054394\n",
      "Epoch 116:\t train loss : 0.5639716678903981; train accuracy : 0.9871064778958456; \n",
      " validation loss : 0.5969416194386168; validation accuracy : 0.9539748953974896\n",
      "Epoch 117:\t train loss : 0.5610259600389786; train accuracy : 0.9903166145171783; \n",
      " validation loss : 0.5961665930500263; validation accuracy : 0.9539748953974896\n",
      "Epoch 118:\t train loss : 0.5573097280468411; train accuracy : 0.9940518603426376; \n",
      " validation loss : 0.6053250039099932; validation accuracy : 0.9456066945606695\n",
      "Epoch 119:\t train loss : 0.5554664175433683; train accuracy : 0.9958486941974658; \n",
      " validation loss : 0.5906613985815241; validation accuracy : 0.9581589958158996\n",
      "Epoch 120:\t train loss : 0.5621310334164962; train accuracy : 0.9889652715387713; \n",
      " validation loss : 0.6155819567692765; validation accuracy : 0.9288702928870293\n",
      "Epoch 121:\t train loss : 0.5557325839358869; train accuracy : 0.9955484990241333; \n",
      " validation loss : 0.6068156949142165; validation accuracy : 0.9456066945606695\n",
      "Epoch 122:\t train loss : 0.5573724277601012; train accuracy : 0.9939626382477772; \n",
      " validation loss : 0.6105083145879874; validation accuracy : 0.9414225941422594\n",
      "Epoch 123:\t train loss : 0.557155057647959; train accuracy : 0.9942628334211097; \n",
      " validation loss : 0.6040015703896036; validation accuracy : 0.9456066945606695\n",
      "Epoch 124:\t train loss : 0.5566274728650171; train accuracy : 0.9946965519377924; \n",
      " validation loss : 0.6229844487805972; validation accuracy : 0.9288702928870293\n",
      "Epoch 125:\t train loss : 0.5576076631183754; train accuracy : 0.9938232287245578; \n",
      " validation loss : 0.6204625545533509; validation accuracy : 0.9288702928870293\n",
      "Epoch 126:\t train loss : 0.5586767265329712; train accuracy : 0.9926710864648842; \n",
      " validation loss : 0.6290333695979223; validation accuracy : 0.9205020920502092\n",
      "Epoch 127:\t train loss : 0.5600965321813002; train accuracy : 0.9912017100901515; \n",
      " validation loss : 0.5954510166158582; validation accuracy : 0.9581589958158996\n",
      "Epoch 128:\t train loss : 0.5562549473040425; train accuracy : 0.9951398742216302; \n",
      " validation loss : 0.6085905867999684; validation accuracy : 0.9414225941422594\n",
      "Epoch 129:\t train loss : 0.5563949880176707; train accuracy : 0.9950063508782799; \n",
      " validation loss : 0.5961711420803304; validation accuracy : 0.9539748953974896\n",
      "Epoch 130:\t train loss : 0.5565260534120136; train accuracy : 0.9947798878527835; \n",
      " validation loss : 0.5982686797142094; validation accuracy : 0.9539748953974896\n",
      "Epoch 131:\t train loss : 0.5582660348298388; train accuracy : 0.9930236376591592; \n",
      " validation loss : 0.5966876301575973; validation accuracy : 0.9581589958158996\n",
      "Epoch 132:\t train loss : 0.5578095026079336; train accuracy : 0.9935657858050125; \n",
      " validation loss : 0.6022206539002211; validation accuracy : 0.9497907949790795\n",
      "Epoch 133:\t train loss : 0.5706457535058235; train accuracy : 0.9804458006753617; \n",
      " validation loss : 0.616372048382275; validation accuracy : 0.9330543933054394\n",
      "Epoch 134:\t train loss : 0.5564843735638008; train accuracy : 0.9948263576938566; \n",
      " validation loss : 0.5868521175613237; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135:\t train loss : 0.5587096065199032; train accuracy : 0.9925914681371789; \n",
      " validation loss : 0.6081317373897259; validation accuracy : 0.9372384937238494\n",
      "Epoch 136:\t train loss : 0.5615377241495287; train accuracy : 0.9896350568481056; \n",
      " validation loss : 0.6149249738849808; validation accuracy : 0.9372384937238494\n",
      "Epoch 137:\t train loss : 0.5587283035092663; train accuracy : 0.9925183555872239; \n",
      " validation loss : 0.6160418343157854; validation accuracy : 0.9330543933054394\n",
      "Early stopping at epoch 137\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5625169539062054; Train accuracy : 0.988785278354348; \n",
      " Validation loss : 0.5780118015243771; Validation accuracy : 0.9748953974895398\n",
      "--- Let's train model 100 ! ---\n",
      "Epoch 1:\t train loss : 0.9420036558455748; train accuracy : 0.583930728956907; \n",
      " validation loss : 0.8247766659653019; validation accuracy : 0.7238493723849372\n",
      "Epoch 2:\t train loss : 0.7528331146118766; train accuracy : 0.7969236965209578; \n",
      " validation loss : 0.7139007061622161; validation accuracy : 0.8451882845188284\n",
      "Epoch 3:\t train loss : 0.7000813970932036; train accuracy : 0.8502772700517364; \n",
      " validation loss : 0.6831073143060281; validation accuracy : 0.8702928870292888\n",
      "Epoch 4:\t train loss : 0.6712616964297653; train accuracy : 0.8792899408284024; \n",
      " validation loss : 0.6723907029163927; validation accuracy : 0.8786610878661087\n",
      "Epoch 5:\t train loss : 0.6558567417901495; train accuracy : 0.8946621642553982; \n",
      " validation loss : 0.6655306252763089; validation accuracy : 0.8870292887029289\n",
      "Epoch 6:\t train loss : 0.6374701675620942; train accuracy : 0.91339260819728; \n",
      " validation loss : 0.6643769677387932; validation accuracy : 0.8870292887029289\n",
      "Epoch 7:\t train loss : 0.6408795440129086; train accuracy : 0.9106199076799157; \n",
      " validation loss : 0.6673565027842691; validation accuracy : 0.8786610878661087\n",
      "Epoch 8:\t train loss : 0.6292373463512085; train accuracy : 0.9218718051984263; \n",
      " validation loss : 0.6540693017318105; validation accuracy : 0.895397489539749\n",
      "Epoch 9:\t train loss : 0.6154939404708377; train accuracy : 0.9358778152978717; \n",
      " validation loss : 0.6345249772011895; validation accuracy : 0.9163179916317992\n",
      "Epoch 10:\t train loss : 0.6044762996445472; train accuracy : 0.9467610520772018; \n",
      " validation loss : 0.6250783221765589; validation accuracy : 0.9121338912133892\n",
      "Epoch 11:\t train loss : 0.5959447294809922; train accuracy : 0.9552805229406115; \n",
      " validation loss : 0.6241798939303133; validation accuracy : 0.9288702928870293\n",
      "Epoch 12:\t train loss : 0.5910677951696184; train accuracy : 0.9600545246135258; \n",
      " validation loss : 0.6295445205005895; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.590985630078147; train accuracy : 0.9602837758294867; \n",
      " validation loss : 0.6201486861374951; validation accuracy : 0.9288702928870293\n",
      "Epoch 14:\t train loss : 0.5853179521198858; train accuracy : 0.9663806189782831; \n",
      " validation loss : 0.617436364264872; validation accuracy : 0.9372384937238494\n",
      "Epoch 15:\t train loss : 0.5832456935467518; train accuracy : 0.9682827844728771; \n",
      " validation loss : 0.6167376200949857; validation accuracy : 0.9288702928870293\n",
      "Epoch 16:\t train loss : 0.5954993896929782; train accuracy : 0.9552867189194213; \n",
      " validation loss : 0.6727955729060412; validation accuracy : 0.8744769874476988\n",
      "Epoch 17:\t train loss : 0.5929261494871343; train accuracy : 0.9584900399640633; \n",
      " validation loss : 0.6331294282791944; validation accuracy : 0.9121338912133892\n",
      "Epoch 18:\t train loss : 0.5792769990348754; train accuracy : 0.9722791908051674; \n",
      " validation loss : 0.6287702765518461; validation accuracy : 0.9163179916317992\n",
      "Epoch 19:\t train loss : 0.5733535560019373; train accuracy : 0.9778617677127545; \n",
      " validation loss : 0.6267695230539786; validation accuracy : 0.9246861924686193\n",
      "Epoch 20:\t train loss : 0.5725944180304652; train accuracy : 0.9788562223117196; \n",
      " validation loss : 0.6114045378579401; validation accuracy : 0.9414225941422594\n",
      "Epoch 21:\t train loss : 0.5765425292495202; train accuracy : 0.9747544843396636; \n",
      " validation loss : 0.6315934126812002; validation accuracy : 0.9163179916317992\n",
      "Epoch 22:\t train loss : 0.5861239662464958; train accuracy : 0.9648192323182254; \n",
      " validation loss : 0.6170062711344003; validation accuracy : 0.9330543933054394\n",
      "Epoch 23:\t train loss : 0.5721234303853928; train accuracy : 0.9793147247436413; \n",
      " validation loss : 0.6000200963190959; validation accuracy : 0.9497907949790795\n",
      "Epoch 24:\t train loss : 0.5710980601818709; train accuracy : 0.9800923200842653; \n",
      " validation loss : 0.6006386485255495; validation accuracy : 0.9497907949790795\n",
      "Epoch 25:\t train loss : 0.5712902806899381; train accuracy : 0.9802781994485579; \n",
      " validation loss : 0.5985764610827494; validation accuracy : 0.9456066945606695\n",
      "Epoch 26:\t train loss : 0.5695388931873618; train accuracy : 0.9818426840980204; \n",
      " validation loss : 0.6046527649619277; validation accuracy : 0.9456066945606695\n",
      "Epoch 27:\t train loss : 0.5672127486786565; train accuracy : 0.9842219399609653; \n",
      " validation loss : 0.6198504286301177; validation accuracy : 0.9246861924686193\n",
      "Epoch 28:\t train loss : 0.569931055112998; train accuracy : 0.9812106942594256; \n",
      " validation loss : 0.6304183792383522; validation accuracy : 0.9205020920502092\n",
      "Epoch 29:\t train loss : 0.572351823495173; train accuracy : 0.9790390036866073; \n",
      " validation loss : 0.6009095739544461; validation accuracy : 0.9497907949790795\n",
      "Epoch 30:\t train loss : 0.5686012016749336; train accuracy : 0.9828960004956783; \n",
      " validation loss : 0.6295489221648548; validation accuracy : 0.9205020920502092\n",
      "Epoch 31:\t train loss : 0.5717676894371189; train accuracy : 0.9794479382880511; \n",
      " validation loss : 0.5877534920082464; validation accuracy : 0.9623430962343096\n",
      "Epoch 32:\t train loss : 0.5689546266831693; train accuracy : 0.982502555841259; \n",
      " validation loss : 0.6266864455541478; validation accuracy : 0.9205020920502092\n",
      "Epoch 33:\t train loss : 0.567388802516687; train accuracy : 0.9840577465225069; \n",
      " validation loss : 0.6313045368584447; validation accuracy : 0.9205020920502092\n",
      "Epoch 34:\t train loss : 0.5680803532485869; train accuracy : 0.9831500356268782; \n",
      " validation loss : 0.603684037440253; validation accuracy : 0.9497907949790795\n",
      "Epoch 35:\t train loss : 0.5706688056240155; train accuracy : 0.9804981566963041; \n",
      " validation loss : 0.6135755042098704; validation accuracy : 0.9372384937238494\n",
      "Epoch 36:\t train loss : 0.5868723199777858; train accuracy : 0.9635521546516311; \n",
      " validation loss : 0.6236990609780517; validation accuracy : 0.9205020920502092\n",
      "Epoch 37:\t train loss : 0.5723853515854262; train accuracy : 0.978899594163388; \n",
      " validation loss : 0.626688969645004; validation accuracy : 0.9205020920502092\n",
      "Epoch 38:\t train loss : 0.5666875830949107; train accuracy : 0.9846990303293163; \n",
      " validation loss : 0.620463948833925; validation accuracy : 0.9288702928870293\n",
      "Epoch 39:\t train loss : 0.5627515592919747; train accuracy : 0.9886210849158896; \n",
      " validation loss : 0.5896675701329197; validation accuracy : 0.9623430962343096\n",
      "Epoch 40:\t train loss : 0.5687537528512504; train accuracy : 0.9823941262120883; \n",
      " validation loss : 0.6001525886816417; validation accuracy : 0.9497907949790795\n",
      "Epoch 41:\t train loss : 0.5665635525689237; train accuracy : 0.9846773444034821; \n",
      " validation loss : 0.6125171300613745; validation accuracy : 0.9414225941422594\n",
      "Epoch 42:\t train loss : 0.5652000941860668; train accuracy : 0.9859970878899594; \n",
      " validation loss : 0.6193265233796063; validation accuracy : 0.9288702928870293\n",
      "Epoch 43:\t train loss : 0.5638915086815118; train accuracy : 0.9875832584652561; \n",
      " validation loss : 0.6076076251835707; validation accuracy : 0.9414225941422594\n",
      "Epoch 44:\t train loss : 0.5663833373265028; train accuracy : 0.9847919700114626; \n",
      " validation loss : 0.6294142015626403; validation accuracy : 0.9246861924686193\n",
      "Epoch 45:\t train loss : 0.5732498920874692; train accuracy : 0.9776573004120326; \n",
      " validation loss : 0.6218630064135713; validation accuracy : 0.9205020920502092\n",
      "Epoch 46:\t train loss : 0.5647230627979762; train accuracy : 0.9864524923324762; \n",
      " validation loss : 0.6225352266404911; validation accuracy : 0.9288702928870293\n",
      "Epoch 47:\t train loss : 0.5639458374270234; train accuracy : 0.9873756931751293; \n",
      " validation loss : 0.5986438386993839; validation accuracy : 0.9539748953974896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48:\t train loss : 0.56122955778078; train accuracy : 0.9900678459679668; \n",
      " validation loss : 0.607037459783721; validation accuracy : 0.9414225941422594\n",
      "Epoch 49:\t train loss : 0.5602379474190942; train accuracy : 0.9912079060689613; \n",
      " validation loss : 0.6039542981341953; validation accuracy : 0.9456066945606695\n",
      "Epoch 50:\t train loss : 0.5616494417296257; train accuracy : 0.9896805972923572; \n",
      " validation loss : 0.6076060711603708; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5639560187580483; train accuracy : 0.9872858514823879; \n",
      " validation loss : 0.6231898991461884; validation accuracy : 0.9288702928870293\n",
      "Epoch 52:\t train loss : 0.5689551972537447; train accuracy : 0.9821462870596983; \n",
      " validation loss : 0.6332736018010753; validation accuracy : 0.9205020920502092\n",
      "Epoch 53:\t train loss : 0.5716856721652821; train accuracy : 0.9794479382880511; \n",
      " validation loss : 0.6372606653454501; validation accuracy : 0.9121338912133892\n",
      "Epoch 54:\t train loss : 0.568976697552804; train accuracy : 0.9822144428266055; \n",
      " validation loss : 0.6628623723859641; validation accuracy : 0.8828451882845189\n",
      "Epoch 55:\t train loss : 0.5776578338351481; train accuracy : 0.973416152916757; \n",
      " validation loss : 0.6160407962454595; validation accuracy : 0.9330543933054394\n",
      "Epoch 56:\t train loss : 0.5639917341115146; train accuracy : 0.987335419312866; \n",
      " validation loss : 0.6018387788609234; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5605062055685717; train accuracy : 0.9907803835310883; \n",
      " validation loss : 0.608179945778909; validation accuracy : 0.9414225941422594\n",
      "Epoch 58:\t train loss : 0.5597429733514818; train accuracy : 0.9914836271259952; \n",
      " validation loss : 0.634899178439897; validation accuracy : 0.9121338912133892\n",
      "Epoch 59:\t train loss : 0.5618688289469681; train accuracy : 0.989414170203538; \n",
      " validation loss : 0.594295679375145; validation accuracy : 0.9539748953974896\n",
      "Epoch 60:\t train loss : 0.564386099862778; train accuracy : 0.9868428389974906; \n",
      " validation loss : 0.6200795550352279; validation accuracy : 0.9330543933054394\n",
      "Epoch 61:\t train loss : 0.5752173695765987; train accuracy : 0.9758511725889898; \n",
      " validation loss : 0.6978757218313671; validation accuracy : 0.8493723849372385\n",
      "Epoch 62:\t train loss : 0.5721565626188259; train accuracy : 0.9789274760680319; \n",
      " validation loss : 0.6115356761266582; validation accuracy : 0.9414225941422594\n",
      "Epoch 63:\t train loss : 0.5640355903582333; train accuracy : 0.9871495399485734; \n",
      " validation loss : 0.5979294991744625; validation accuracy : 0.9539748953974896\n",
      "Epoch 64:\t train loss : 0.5626767256711637; train accuracy : 0.9886458688311286; \n",
      " validation loss : 0.6098696610128428; validation accuracy : 0.9414225941422594\n",
      "Epoch 65:\t train loss : 0.5602742849824931; train accuracy : 0.9908950091390687; \n",
      " validation loss : 0.6126379749350472; validation accuracy : 0.9414225941422594\n",
      "Epoch 66:\t train loss : 0.5600261725871932; train accuracy : 0.9911583382384832; \n",
      " validation loss : 0.6186840791001306; validation accuracy : 0.9330543933054394\n",
      "Epoch 67:\t train loss : 0.5622114873791719; train accuracy : 0.9890888813160259; \n",
      " validation loss : 0.6163096860065292; validation accuracy : 0.9330543933054394\n",
      "Epoch 68:\t train loss : 0.5604488320131669; train accuracy : 0.9908361473403761; \n",
      " validation loss : 0.6087354140486001; validation accuracy : 0.9414225941422594\n",
      "Epoch 69:\t train loss : 0.558455193465472; train accuracy : 0.992890114315809; \n",
      " validation loss : 0.5908464880119461; validation accuracy : 0.9623430962343096\n",
      "Epoch 70:\t train loss : 0.5573991089512669; train accuracy : 0.9939651166393011; \n",
      " validation loss : 0.6076457570785835; validation accuracy : 0.9414225941422594\n",
      "Epoch 71:\t train loss : 0.5795924807093226; train accuracy : 0.9713219120790607; \n",
      " validation loss : 0.6093557453410288; validation accuracy : 0.9414225941422594\n",
      "Epoch 72:\t train loss : 0.5707094640643448; train accuracy : 0.9802905914061774; \n",
      " validation loss : 0.6226660011838492; validation accuracy : 0.9288702928870293\n",
      "Epoch 73:\t train loss : 0.5647527015603585; train accuracy : 0.9865640199510518; \n",
      " validation loss : 0.5976934967298868; validation accuracy : 0.9497907949790795\n",
      "Epoch 74:\t train loss : 0.560606501423503; train accuracy : 0.990712227764181; \n",
      " validation loss : 0.5854829612587134; validation accuracy : 0.9665271966527197\n",
      "Epoch 75:\t train loss : 0.5586915524655204; train accuracy : 0.9926143932587751; \n",
      " validation loss : 0.640790544468595; validation accuracy : 0.9079497907949791\n",
      "Epoch 76:\t train loss : 0.5587926271589284; train accuracy : 0.9925865113541311; \n",
      " validation loss : 0.593129905613284; validation accuracy : 0.9581589958158996\n",
      "Epoch 77:\t train loss : 0.5608050493627562; train accuracy : 0.9905046624740543; \n",
      " validation loss : 0.595229239389544; validation accuracy : 0.9581589958158996\n",
      "Epoch 78:\t train loss : 0.5562722522354361; train accuracy : 0.9950958827720809; \n",
      " validation loss : 0.5989926021979325; validation accuracy : 0.9497907949790795\n",
      "Epoch 79:\t train loss : 0.5582889707006727; train accuracy : 0.9931596393940333; \n",
      " validation loss : 0.6056980416866105; validation accuracy : 0.9456066945606695\n",
      "Epoch 80:\t train loss : 0.563056279440036; train accuracy : 0.98823383624028; \n",
      " validation loss : 0.6306014609795428; validation accuracy : 0.9163179916317992\n",
      "Epoch 81:\t train loss : 0.5610729870389676; train accuracy : 0.9902475293534496; \n",
      " validation loss : 0.5994670303827861; validation accuracy : 0.9539748953974896\n",
      "Epoch 82:\t train loss : 0.5603388383414669; train accuracy : 0.9909074010966883; \n",
      " validation loss : 0.6100235328543973; validation accuracy : 0.9414225941422594\n",
      "Epoch 83:\t train loss : 0.5632062971791937; train accuracy : 0.9879674091514606; \n",
      " validation loss : 0.6505217176525736; validation accuracy : 0.899581589958159\n",
      "Epoch 84:\t train loss : 0.566493431738329; train accuracy : 0.9844976610179993; \n",
      " validation loss : 0.627335647389409; validation accuracy : 0.9205020920502092\n",
      "Epoch 85:\t train loss : 0.5589325472913186; train accuracy : 0.9923851420428143; \n",
      " validation loss : 0.598589287470308; validation accuracy : 0.9539748953974896\n",
      "Epoch 86:\t train loss : 0.5606961222121757; train accuracy : 0.9905170544316738; \n",
      " validation loss : 0.6175852662458005; validation accuracy : 0.9330543933054394\n",
      "Epoch 87:\t train loss : 0.558822009508415; train accuracy : 0.9924718857461508; \n",
      " validation loss : 0.5899204025768476; validation accuracy : 0.9623430962343096\n",
      "Epoch 88:\t train loss : 0.5578007165194523; train accuracy : 0.9934229684934477; \n",
      " validation loss : 0.5967978423403046; validation accuracy : 0.9539748953974896\n",
      "Epoch 89:\t train loss : 0.5619351183633721; train accuracy : 0.9893800923200843; \n",
      " validation loss : 0.6226027764454956; validation accuracy : 0.9288702928870293\n",
      "Epoch 90:\t train loss : 0.5606320922787419; train accuracy : 0.9905914061773908; \n",
      " validation loss : 0.6209896522590951; validation accuracy : 0.9288702928870293\n",
      "Epoch 91:\t train loss : 0.5622402184292745; train accuracy : 0.988884414015304; \n",
      " validation loss : 0.618195105374004; validation accuracy : 0.9330543933054394\n",
      "Epoch 92:\t train loss : 0.5601059533129671; train accuracy : 0.9912141020477709; \n",
      " validation loss : 0.6055429994067831; validation accuracy : 0.9456066945606695\n",
      "Epoch 93:\t train loss : 0.5607795945285868; train accuracy : 0.9904303107283373; \n",
      " validation loss : 0.6150375562331443; validation accuracy : 0.9330543933054394\n",
      "Epoch 94:\t train loss : 0.558524516249482; train accuracy : 0.9928343505065212; \n",
      " validation loss : 0.6055375340907706; validation accuracy : 0.9456066945606695\n",
      "Epoch 95:\t train loss : 0.556437601649753; train accuracy : 0.9949347873230273; \n",
      " validation loss : 0.5813871408137583; validation accuracy : 0.9707112970711297\n",
      "Epoch 96:\t train loss : 0.5568139891494385; train accuracy : 0.9946156944143251; \n",
      " validation loss : 0.6218182461843614; validation accuracy : 0.9288702928870293\n",
      "Epoch 97:\t train loss : 0.5604872580433292; train accuracy : 0.9908237553827566; \n",
      " validation loss : 0.6283349779353911; validation accuracy : 0.9205020920502092\n",
      "Epoch 98:\t train loss : 0.5759323474483484; train accuracy : 0.9750890671953901; \n",
      " validation loss : 0.6067006901482892; validation accuracy : 0.9456066945606695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99:\t train loss : 0.5733758882900503; train accuracy : 0.9775395768146473; \n",
      " validation loss : 0.609632842388162; validation accuracy : 0.9414225941422594\n",
      "Epoch 100:\t train loss : 0.5624822377354686; train accuracy : 0.9886892406827968; \n",
      " validation loss : 0.5997530411695342; validation accuracy : 0.9497907949790795\n",
      "Epoch 101:\t train loss : 0.5600555614758554; train accuracy : 0.9912233960159856; \n",
      " validation loss : 0.607665143918228; validation accuracy : 0.9456066945606695\n",
      "Epoch 102:\t train loss : 0.5592053085835201; train accuracy : 0.9921342049010192; \n",
      " validation loss : 0.5998761000339276; validation accuracy : 0.9497907949790795\n",
      "Epoch 103:\t train loss : 0.55720257032105; train accuracy : 0.9941200161095449; \n",
      " validation loss : 0.6054197607165211; validation accuracy : 0.9456066945606695\n",
      "Epoch 104:\t train loss : 0.5581088063963713; train accuracy : 0.9931813253198674; \n",
      " validation loss : 0.6223349143880863; validation accuracy : 0.9288702928870293\n",
      "Epoch 105:\t train loss : 0.5573787002936277; train accuracy : 0.9939496266922767; \n",
      " validation loss : 0.6199607461891586; validation accuracy : 0.9330543933054394\n",
      "Epoch 106:\t train loss : 0.5602053811479567; train accuracy : 0.9911428482914588; \n",
      " validation loss : 0.6142699319364313; validation accuracy : 0.9372384937238494\n",
      "Epoch 107:\t train loss : 0.5587557708407885; train accuracy : 0.9926174912481799; \n",
      " validation loss : 0.6209114758486567; validation accuracy : 0.9288702928870293\n",
      "Epoch 108:\t train loss : 0.5603543014057203; train accuracy : 0.9909569689271662; \n",
      " validation loss : 0.6169481636507197; validation accuracy : 0.9330543933054394\n",
      "Epoch 109:\t train loss : 0.5607463130588511; train accuracy : 0.9904427026859568; \n",
      " validation loss : 0.5978909682378541; validation accuracy : 0.9539748953974896\n",
      "Epoch 110:\t train loss : 0.5612560428301837; train accuracy : 0.9899934942222498; \n",
      " validation loss : 0.6087400030418253; validation accuracy : 0.9414225941422594\n",
      "Epoch 111:\t train loss : 0.5657331175852048; train accuracy : 0.9854084699030329; \n",
      " validation loss : 0.6109090972378496; validation accuracy : 0.9414225941422594\n",
      "Epoch 112:\t train loss : 0.5658959777495662; train accuracy : 0.9852132965705257; \n",
      " validation loss : 0.6055363590339906; validation accuracy : 0.9456066945606695\n",
      "Epoch 113:\t train loss : 0.5603255832491402; train accuracy : 0.991114966386815; \n",
      " validation loss : 0.5857688816165976; validation accuracy : 0.9665271966527197\n",
      "Epoch 114:\t train loss : 0.5624363813328429; train accuracy : 0.9888441401530407; \n",
      " validation loss : 0.6184764084707788; validation accuracy : 0.9330543933054394\n",
      "Epoch 115:\t train loss : 0.5571160611684826; train accuracy : 0.9942284457387156; \n",
      " validation loss : 0.5951957832070556; validation accuracy : 0.9539748953974896\n",
      "Epoch 116:\t train loss : 0.5567646783154977; train accuracy : 0.9945537346262275; \n",
      " validation loss : 0.6135875174332731; validation accuracy : 0.9372384937238494\n",
      "Epoch 117:\t train loss : 0.5608269310809689; train accuracy : 0.9902444313640447; \n",
      " validation loss : 0.5918893616396902; validation accuracy : 0.9623430962343096\n",
      "Epoch 118:\t train loss : 0.5586007305587797; train accuracy : 0.9926391771740141; \n",
      " validation loss : 0.6197979167494908; validation accuracy : 0.9330543933054394\n",
      "Epoch 119:\t train loss : 0.5581902642316132; train accuracy : 0.9931844233092723; \n",
      " validation loss : 0.6156863876863397; validation accuracy : 0.9414225941422594\n",
      "Epoch 120:\t train loss : 0.5581429129724389; train accuracy : 0.9931999132562966; \n",
      " validation loss : 0.6004004427522329; validation accuracy : 0.9497907949790795\n",
      "Epoch 121:\t train loss : 0.5579532793252125; train accuracy : 0.9932835589702284; \n",
      " validation loss : 0.6100721147258121; validation accuracy : 0.9414225941422594\n",
      "Epoch 122:\t train loss : 0.5596633972899285; train accuracy : 0.9916013507233805; \n",
      " validation loss : 0.6236169169570792; validation accuracy : 0.9246861924686193\n",
      "Epoch 123:\t train loss : 0.557073470828004; train accuracy : 0.9942532296539546; \n",
      " validation loss : 0.5989740336429242; validation accuracy : 0.9497907949790795\n",
      "Epoch 124:\t train loss : 0.5565034746782949; train accuracy : 0.9948015737786177; \n",
      " validation loss : 0.6057400565873766; validation accuracy : 0.9456066945606695\n",
      "Epoch 125:\t train loss : 0.5573115552185122; train accuracy : 0.9940022925121595; \n",
      " validation loss : 0.6153897023749929; validation accuracy : 0.9372384937238494\n",
      "Epoch 126:\t train loss : 0.5583639403176498; train accuracy : 0.9929675640509309; \n",
      " validation loss : 0.6096770434976888; validation accuracy : 0.9414225941422594\n",
      "Epoch 127:\t train loss : 0.5574248951678015; train accuracy : 0.9939496266922767; \n",
      " validation loss : 0.6057934927825983; validation accuracy : 0.9414225941422594\n",
      "Epoch 128:\t train loss : 0.5589726737255893; train accuracy : 0.9924254159050776; \n",
      " validation loss : 0.598607397471729; validation accuracy : 0.9539748953974896\n",
      "Epoch 129:\t train loss : 0.5576787603976789; train accuracy : 0.9935871619319062; \n",
      " validation loss : 0.5951070097496378; validation accuracy : 0.9581589958158996\n",
      "Epoch 130:\t train loss : 0.5562684982420445; train accuracy : 0.9950896867932711; \n",
      " validation loss : 0.5984627695762464; validation accuracy : 0.9497907949790795\n",
      "Epoch 131:\t train loss : 0.5573703076086465; train accuracy : 0.9939434307134669; \n",
      " validation loss : 0.6113449043740595; validation accuracy : 0.9414225941422594\n",
      "Epoch 132:\t train loss : 0.5576985917600247; train accuracy : 0.9936862975928622; \n",
      " validation loss : 0.6035161571565024; validation accuracy : 0.9456066945606695\n",
      "Epoch 133:\t train loss : 0.5579107056656459; train accuracy : 0.9934291644722575; \n",
      " validation loss : 0.6002765200971665; validation accuracy : 0.9456066945606695\n",
      "Epoch 134:\t train loss : 0.5603109094589508; train accuracy : 0.9909724588741906; \n",
      " validation loss : 0.6128567642764194; validation accuracy : 0.9372384937238494\n",
      "Epoch 135:\t train loss : 0.5570010921948335; train accuracy : 0.9944391090182472; \n",
      " validation loss : 0.6024710457537357; validation accuracy : 0.9497907949790795\n",
      "Epoch 136:\t train loss : 0.6194457611691531; train accuracy : 0.9307506428328015; \n",
      " validation loss : 0.8263185091062659; validation accuracy : 0.7238493723849372\n",
      "Epoch 137:\t train loss : 0.6890160128509164; train accuracy : 0.8603178537129403; \n",
      " validation loss : 0.7154880504949845; validation accuracy : 0.8284518828451883\n",
      "Epoch 138:\t train loss : 0.6040982416017591; train accuracy : 0.9464543511261192; \n",
      " validation loss : 0.6223580328720161; validation accuracy : 0.9288702928870293\n",
      "Epoch 139:\t train loss : 0.5818715310716488; train accuracy : 0.9688961863750426; \n",
      " validation loss : 0.605011211138841; validation accuracy : 0.9497907949790795\n",
      "Epoch 140:\t train loss : 0.5759483797762885; train accuracy : 0.9748350320641903; \n",
      " validation loss : 0.6216654432493592; validation accuracy : 0.9246861924686193\n",
      "Epoch 141:\t train loss : 0.5715308608772585; train accuracy : 0.9793952724681682; \n",
      " validation loss : 0.6180537372517539; validation accuracy : 0.9330543933054394\n",
      "Epoch 142:\t train loss : 0.5681311821608642; train accuracy : 0.9829858421884197; \n",
      " validation loss : 0.6290733179225081; validation accuracy : 0.9246861924686193\n",
      "Epoch 143:\t train loss : 0.5667998815321514; train accuracy : 0.9843923293782335; \n",
      " validation loss : 0.6072393360662495; validation accuracy : 0.9414225941422594\n",
      "Epoch 144:\t train loss : 0.5637811988632786; train accuracy : 0.9875027107407293; \n",
      " validation loss : 0.616390277381889; validation accuracy : 0.9330543933054394\n",
      "Epoch 145:\t train loss : 0.5614833158213085; train accuracy : 0.9899996902010595; \n",
      " validation loss : 0.5915923754433156; validation accuracy : 0.9623430962343096\n",
      "Early stopping at epoch 145\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.556437601649753; Train accuracy : 0.9949347873230273; \n",
      " Validation loss : 0.5813871408137583; Validation accuracy : 0.9707112970711297\n",
      "--- Let's train model 101 ! ---\n",
      "Epoch 1:\t train loss : 0.9314430022081871; train accuracy : 0.5958521019858112; \n",
      " validation loss : 0.7989526704683145; validation accuracy : 0.7615062761506276\n",
      "Epoch 2:\t train loss : 0.7402135792898309; train accuracy : 0.8099947334180118; \n",
      " validation loss : 0.7325556963810942; validation accuracy : 0.8200836820083682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\t train loss : 0.6980058870459758; train accuracy : 0.8523699618947304; \n",
      " validation loss : 0.7015897077478839; validation accuracy : 0.8368200836820083\n",
      "Epoch 4:\t train loss : 0.6763226690240826; train accuracy : 0.8743154992409926; \n",
      " validation loss : 0.7012883216252606; validation accuracy : 0.8451882845188284\n",
      "Epoch 5:\t train loss : 0.657467415948857; train accuracy : 0.8930140338920041; \n",
      " validation loss : 0.6508128141518873; validation accuracy : 0.899581589958159\n",
      "Epoch 6:\t train loss : 0.6426106709643272; train accuracy : 0.9077177112054277; \n",
      " validation loss : 0.6802498989619925; validation accuracy : 0.8661087866108786\n",
      "Epoch 7:\t train loss : 0.6325599197770262; train accuracy : 0.918485392979956; \n",
      " validation loss : 0.6607386596132672; validation accuracy : 0.8786610878661087\n",
      "Epoch 8:\t train loss : 0.621150001864056; train accuracy : 0.929901483936925; \n",
      " validation loss : 0.6443098545690109; validation accuracy : 0.9037656903765691\n",
      "Epoch 9:\t train loss : 0.6116360484783027; train accuracy : 0.9390987948821216; \n",
      " validation loss : 0.6337873046981917; validation accuracy : 0.9205020920502092\n",
      "Epoch 10:\t train loss : 0.6041588245600753; train accuracy : 0.9467492797174634; \n",
      " validation loss : 0.6237918753918539; validation accuracy : 0.9330543933054394\n",
      "Epoch 11:\t train loss : 0.5935476957956821; train accuracy : 0.9581845782087425; \n",
      " validation loss : 0.6184997893501956; validation accuracy : 0.9330543933054394\n",
      "Epoch 12:\t train loss : 0.5922160694628229; train accuracy : 0.9593020229870813; \n",
      " validation loss : 0.6323654458157939; validation accuracy : 0.9205020920502092\n",
      "Epoch 13:\t train loss : 0.588538751999394; train accuracy : 0.9631494160289972; \n",
      " validation loss : 0.6159179517480459; validation accuracy : 0.9288702928870293\n",
      "Epoch 14:\t train loss : 0.5927016150911487; train accuracy : 0.9582177266953747; \n",
      " validation loss : 0.6210905349903605; validation accuracy : 0.9330543933054394\n",
      "Epoch 15:\t train loss : 0.5939692099630174; train accuracy : 0.957297933641067; \n",
      " validation loss : 0.6042397542717672; validation accuracy : 0.9497907949790795\n",
      "Epoch 16:\t train loss : 0.5844536557883715; train accuracy : 0.9668707209021346; \n",
      " validation loss : 0.6135592293215496; validation accuracy : 0.9288702928870293\n",
      "Epoch 17:\t train loss : 0.5881885762516899; train accuracy : 0.9627658849406735; \n",
      " validation loss : 0.5983381071079958; validation accuracy : 0.9539748953974896\n",
      "Epoch 18:\t train loss : 0.5826611615695418; train accuracy : 0.9686034263762818; \n",
      " validation loss : 0.6293486687433377; validation accuracy : 0.9246861924686193\n",
      "Epoch 19:\t train loss : 0.5789042804034968; train accuracy : 0.9723445583816104; \n",
      " validation loss : 0.6058797038709643; validation accuracy : 0.9414225941422594\n",
      "Epoch 20:\t train loss : 0.573849550617747; train accuracy : 0.9776576102109731; \n",
      " validation loss : 0.6067978119138521; validation accuracy : 0.9456066945606695\n",
      "Epoch 21:\t train loss : 0.5749850094252278; train accuracy : 0.9764435081632021; \n",
      " validation loss : 0.6383284452557295; validation accuracy : 0.9163179916317992\n",
      "Epoch 22:\t train loss : 0.571058361113007; train accuracy : 0.9802850150252486; \n",
      " validation loss : 0.6076877409847214; validation accuracy : 0.9414225941422594\n",
      "Epoch 23:\t train loss : 0.5755410873724187; train accuracy : 0.9759013600173487; \n",
      " validation loss : 0.6116860187095684; validation accuracy : 0.9372384937238494\n",
      "Epoch 24:\t train loss : 0.5720242545057233; train accuracy : 0.9793054307754268; \n",
      " validation loss : 0.5917519612904745; validation accuracy : 0.9623430962343096\n",
      "Epoch 25:\t train loss : 0.5709665168810512; train accuracy : 0.9803757861148115; \n",
      " validation loss : 0.611854373698537; validation accuracy : 0.9372384937238494\n",
      "Epoch 26:\t train loss : 0.5662045316407796; train accuracy : 0.9852845503268379; \n",
      " validation loss : 0.60395225233921; validation accuracy : 0.9414225941422594\n",
      "Epoch 27:\t train loss : 0.5730608332043187; train accuracy : 0.9783605440069395; \n",
      " validation loss : 0.59838706147129; validation accuracy : 0.9539748953974896\n",
      "Epoch 28:\t train loss : 0.5849435560529342; train accuracy : 0.9657105238700083; \n",
      " validation loss : 0.6282255055967559; validation accuracy : 0.9205020920502092\n",
      "Epoch 29:\t train loss : 0.5811466104711633; train accuracy : 0.9698757706248644; \n",
      " validation loss : 0.58504525186311; validation accuracy : 0.9707112970711297\n",
      "Epoch 30:\t train loss : 0.5700507265539212; train accuracy : 0.9811583382384832; \n",
      " validation loss : 0.5796837062279374; validation accuracy : 0.9748953974895398\n",
      "Epoch 31:\t train loss : 0.5750930041227656; train accuracy : 0.9760791846091886; \n",
      " validation loss : 0.6344020337782772; validation accuracy : 0.9121338912133892\n",
      "Epoch 32:\t train loss : 0.5729524423907347; train accuracy : 0.9782211344837201; \n",
      " validation loss : 0.593677896833894; validation accuracy : 0.9623430962343096\n",
      "Epoch 33:\t train loss : 0.5669114049938921; train accuracy : 0.9842467238762044; \n",
      " validation loss : 0.61072442574155; validation accuracy : 0.9414225941422594\n",
      "Epoch 34:\t train loss : 0.5654376771992434; train accuracy : 0.9858053223457975; \n",
      " validation loss : 0.5890489273317391; validation accuracy : 0.9623430962343096\n",
      "Epoch 35:\t train loss : 0.5672073422982374; train accuracy : 0.9841265218872951; \n",
      " validation loss : 0.6213917221713319; validation accuracy : 0.9246861924686193\n",
      "Epoch 36:\t train loss : 0.566083469633471; train accuracy : 0.9853620000619598; \n",
      " validation loss : 0.6389250112293725; validation accuracy : 0.9079497907949791\n",
      "Epoch 37:\t train loss : 0.5776438167909204; train accuracy : 0.9735468880696428; \n",
      " validation loss : 0.5855638759151999; validation accuracy : 0.9623430962343096\n",
      "Epoch 38:\t train loss : 0.5756141652562368; train accuracy : 0.9754986213947149; \n",
      " validation loss : 0.604517255913208; validation accuracy : 0.9414225941422594\n",
      "Epoch 39:\t train loss : 0.5682372975851769; train accuracy : 0.9827538027819945; \n",
      " validation loss : 0.5990042288231641; validation accuracy : 0.9539748953974896\n",
      "Epoch 40:\t train loss : 0.5642849315403157; train accuracy : 0.9871994175779919; \n",
      " validation loss : 0.5956239055986111; validation accuracy : 0.9539748953974896\n",
      "Epoch 41:\t train loss : 0.5647638684066879; train accuracy : 0.9865953096440411; \n",
      " validation loss : 0.6034805764505683; validation accuracy : 0.9456066945606695\n",
      "Epoch 42:\t train loss : 0.5700783804925097; train accuracy : 0.9810653985563369; \n",
      " validation loss : 0.5932710405806835; validation accuracy : 0.9623430962343096\n",
      "Epoch 43:\t train loss : 0.5648494283836158; train accuracy : 0.9864249202267729; \n",
      " validation loss : 0.6085536147443961; validation accuracy : 0.9456066945606695\n",
      "Epoch 44:\t train loss : 0.5655736637114225; train accuracy : 0.9857898323987732; \n",
      " validation loss : 0.6063080724360215; validation accuracy : 0.9456066945606695\n",
      "Epoch 45:\t train loss : 0.5661721335027199; train accuracy : 0.9848973016512284; \n",
      " validation loss : 0.6151754640316464; validation accuracy : 0.9372384937238494\n",
      "Epoch 46:\t train loss : 0.5675725727920229; train accuracy : 0.9835629976145481; \n",
      " validation loss : 0.6222431343885623; validation accuracy : 0.9246861924686193\n",
      "Epoch 47:\t train loss : 0.5670685040115345; train accuracy : 0.9840763344589362; \n",
      " validation loss : 0.5975667502842972; validation accuracy : 0.9581589958158996\n",
      "Epoch 48:\t train loss : 0.5646388951529653; train accuracy : 0.9865392360358127; \n",
      " validation loss : 0.6090110807973057; validation accuracy : 0.9372384937238494\n",
      "Epoch 49:\t train loss : 0.5635919722293248; train accuracy : 0.9877105858297964; \n",
      " validation loss : 0.5752265659212416; validation accuracy : 0.9748953974895398\n",
      "Epoch 50:\t train loss : 0.5614020549513854; train accuracy : 0.9900244741162986; \n",
      " validation loss : 0.604472854069935; validation accuracy : 0.9456066945606695\n",
      "Epoch 51:\t train loss : 0.5612829239316239; train accuracy : 0.9900687753647882; \n",
      " validation loss : 0.6213610770531262; validation accuracy : 0.9330543933054394\n",
      "Epoch 52:\t train loss : 0.5801516041545377; train accuracy : 0.9707181139440503; \n",
      " validation loss : 0.623619548907731; validation accuracy : 0.9246861924686193\n",
      "Epoch 53:\t train loss : 0.5729216852650881; train accuracy : 0.9781591746956225; \n",
      " validation loss : 0.5899179366727713; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54:\t train loss : 0.5645397198567426; train accuracy : 0.9867811890083336; \n",
      " validation loss : 0.6133883538441949; validation accuracy : 0.9372384937238494\n",
      "Epoch 55:\t train loss : 0.562461423452596; train accuracy : 0.9887542984602993; \n",
      " validation loss : 0.5891515505723947; validation accuracy : 0.9623430962343096\n",
      "Epoch 56:\t train loss : 0.564025064298949; train accuracy : 0.9872053037578612; \n",
      " validation loss : 0.6025457103854851; validation accuracy : 0.9497907949790795\n",
      "Epoch 57:\t train loss : 0.5636443450357065; train accuracy : 0.9876021562006257; \n",
      " validation loss : 0.5869307968900037; validation accuracy : 0.9665271966527197\n",
      "Epoch 58:\t train loss : 0.5721822364280036; train accuracy : 0.9789742557080455; \n",
      " validation loss : 0.6020602575586081; validation accuracy : 0.9497907949790795\n",
      "Epoch 59:\t train loss : 0.5689801539381705; train accuracy : 0.982289104371263; \n",
      " validation loss : 0.593145194311092; validation accuracy : 0.9581589958158996\n",
      "Epoch 60:\t train loss : 0.5612580622333952; train accuracy : 0.9900030979894049; \n",
      " validation loss : 0.6117215767352719; validation accuracy : 0.9372384937238494\n",
      "Epoch 61:\t train loss : 0.5613471175716627; train accuracy : 0.9900805477245268; \n",
      " validation loss : 0.5965444787088289; validation accuracy : 0.9581589958158996\n",
      "Epoch 62:\t train loss : 0.5615405366365634; train accuracy : 0.9897766349639084; \n",
      " validation loss : 0.5904880053156614; validation accuracy : 0.9581589958158996\n",
      "Epoch 63:\t train loss : 0.563571011044933; train accuracy : 0.9878035255119427; \n",
      " validation loss : 0.5902240603565989; validation accuracy : 0.9581589958158996\n",
      "Epoch 64:\t train loss : 0.5616376933512571; train accuracy : 0.9895848694197465; \n",
      " validation loss : 0.5865064468505936; validation accuracy : 0.9665271966527197\n",
      "Epoch 65:\t train loss : 0.5683111109721019; train accuracy : 0.9828836085380588; \n",
      " validation loss : 0.5813721901125594; validation accuracy : 0.9707112970711297\n",
      "Epoch 66:\t train loss : 0.5629850547433639; train accuracy : 0.9883301837107717; \n",
      " validation loss : 0.5923031457576702; validation accuracy : 0.9581589958158996\n",
      "Epoch 67:\t train loss : 0.5605401296544348; train accuracy : 0.9908085752346727; \n",
      " validation loss : 0.5949965758240153; validation accuracy : 0.9539748953974896\n",
      "Epoch 68:\t train loss : 0.5620353566955191; train accuracy : 0.9891821307971127; \n",
      " validation loss : 0.5689572005847925; validation accuracy : 0.9832635983263598\n",
      "Epoch 69:\t train loss : 0.5608590990947813; train accuracy : 0.9903497630038105; \n",
      " validation loss : 0.5992161521187821; validation accuracy : 0.9497907949790795\n",
      "Epoch 70:\t train loss : 0.5616724678410319; train accuracy : 0.989449177483813; \n",
      " validation loss : 0.6704245223045479; validation accuracy : 0.8786610878661087\n",
      "Epoch 71:\t train loss : 0.5686955120579812; train accuracy : 0.9824440038415069; \n",
      " validation loss : 0.5963859445199102; validation accuracy : 0.9539748953974896\n",
      "Epoch 72:\t train loss : 0.5588530370532082; train accuracy : 0.9925028656401995; \n",
      " validation loss : 0.5758180508152024; validation accuracy : 0.9790794979079498\n",
      "Epoch 73:\t train loss : 0.5608768683202175; train accuracy : 0.9904427026859568; \n",
      " validation loss : 0.6097046584466624; validation accuracy : 0.9372384937238494\n",
      "Epoch 74:\t train loss : 0.5592646728796089; train accuracy : 0.9920418848167539; \n",
      " validation loss : 0.5889498592687785; validation accuracy : 0.9623430962343096\n",
      "Epoch 75:\t train loss : 0.5613240172493503; train accuracy : 0.9900244741162986; \n",
      " validation loss : 0.593277290448647; validation accuracy : 0.9581589958158996\n",
      "Epoch 76:\t train loss : 0.5599168900242738; train accuracy : 0.9915152266179249; \n",
      " validation loss : 0.5999841721931033; validation accuracy : 0.9497907949790795\n",
      "Epoch 77:\t train loss : 0.5588265251602497; train accuracy : 0.9925199045819263; \n",
      " validation loss : 0.7075970276101154; validation accuracy : 0.8410041841004184\n",
      "Epoch 78:\t train loss : 0.6165912741312499; train accuracy : 0.9335459586728213; \n",
      " validation loss : 0.6000651008051915; validation accuracy : 0.9539748953974896\n",
      "Epoch 79:\t train loss : 0.5679249710686186; train accuracy : 0.9831934074785464; \n",
      " validation loss : 0.5944735653785949; validation accuracy : 0.9581589958158996\n",
      "Epoch 80:\t train loss : 0.5678277193517837; train accuracy : 0.9833771182502555; \n",
      " validation loss : 0.6184686512610396; validation accuracy : 0.9330543933054394\n",
      "Epoch 81:\t train loss : 0.5679804428374058; train accuracy : 0.9832030112457015; \n",
      " validation loss : 0.5751718386380394; validation accuracy : 0.9790794979079498\n",
      "Epoch 82:\t train loss : 0.5636922831156278; train accuracy : 0.987571176306577; \n",
      " validation loss : 0.5918864188883726; validation accuracy : 0.9581589958158996\n",
      "Epoch 83:\t train loss : 0.5696681154839675; train accuracy : 0.9813655937296695; \n",
      " validation loss : 0.5995861312514793; validation accuracy : 0.9539748953974896\n",
      "Epoch 84:\t train loss : 0.5614932812040303; train accuracy : 0.9898850645930791; \n",
      " validation loss : 0.6005558426084554; validation accuracy : 0.9497907949790795\n",
      "Epoch 85:\t train loss : 0.5614171456477594; train accuracy : 0.9898481985191611; \n",
      " validation loss : 0.6001905189149336; validation accuracy : 0.9497907949790795\n",
      "Epoch 86:\t train loss : 0.5634632855775245; train accuracy : 0.9877201895969516; \n",
      " validation loss : 0.6291554654899725; validation accuracy : 0.9205020920502092\n",
      "Epoch 87:\t train loss : 0.5638584498923572; train accuracy : 0.987296074847424; \n",
      " validation loss : 0.6230702254258771; validation accuracy : 0.9288702928870293\n",
      "Epoch 88:\t train loss : 0.5683692393519196; train accuracy : 0.9828681185910344; \n",
      " validation loss : 0.5916057345401183; validation accuracy : 0.9623430962343096\n",
      "Epoch 89:\t train loss : 0.5657403869183727; train accuracy : 0.9853620000619598; \n",
      " validation loss : 0.6204358619012175; validation accuracy : 0.9288702928870293\n",
      "Epoch 90:\t train loss : 0.5587081836887384; train accuracy : 0.9926828588246228; \n",
      " validation loss : 0.5896320818507162; validation accuracy : 0.9581589958158996\n",
      "Epoch 91:\t train loss : 0.5608635710491376; train accuracy : 0.9903807428978593; \n",
      " validation loss : 0.5895447243845355; validation accuracy : 0.9623430962343096\n",
      "Epoch 92:\t train loss : 0.5606345902843415; train accuracy : 0.9906440719972738; \n",
      " validation loss : 0.5913123656483117; validation accuracy : 0.9623430962343096\n",
      "Epoch 93:\t train loss : 0.5605934943207254; train accuracy : 0.9906691657114532; \n",
      " validation loss : 0.5905054869499672; validation accuracy : 0.9623430962343096\n",
      "Epoch 94:\t train loss : 0.5648170105872979; train accuracy : 0.9863688466185445; \n",
      " validation loss : 0.5858451316112704; validation accuracy : 0.9665271966527197\n",
      "Epoch 95:\t train loss : 0.560754922676668; train accuracy : 0.9903962328448837; \n",
      " validation loss : 0.5822975911987689; validation accuracy : 0.9665271966527197\n",
      "Epoch 96:\t train loss : 0.5575750366224761; train accuracy : 0.9937206852752564; \n",
      " validation loss : 0.5885426988121677; validation accuracy : 0.9623430962343096\n",
      "Epoch 97:\t train loss : 0.5597382242779477; train accuracy : 0.9913971932215991; \n",
      " validation loss : 0.585506171808759; validation accuracy : 0.9665271966527197\n",
      "Epoch 98:\t train loss : 0.5665361261022118; train accuracy : 0.9845137705629047; \n",
      " validation loss : 0.5909656988754631; validation accuracy : 0.9581589958158996\n",
      "Epoch 99:\t train loss : 0.5594125191201169; train accuracy : 0.9918464016853062; \n",
      " validation loss : 0.5896389528904268; validation accuracy : 0.9665271966527197\n",
      "Epoch 100:\t train loss : 0.5582214987271455; train accuracy : 0.9931379534681991; \n",
      " validation loss : 0.5947131015143574; validation accuracy : 0.9539748953974896\n",
      "Epoch 101:\t train loss : 0.5596918160244236; train accuracy : 0.9915926763530468; \n",
      " validation loss : 0.5924941347452712; validation accuracy : 0.9581589958158996\n",
      "Epoch 102:\t train loss : 0.5593579361515163; train accuracy : 0.991877381579355; \n",
      " validation loss : 0.5940246194220287; validation accuracy : 0.9581589958158996\n",
      "Epoch 103:\t train loss : 0.565902411727362; train accuracy : 0.9853406239350662; \n",
      " validation loss : 0.6030806569688764; validation accuracy : 0.9456066945606695\n",
      "Epoch 104:\t train loss : 0.5594397341820314; train accuracy : 0.9919393413674525; \n",
      " validation loss : 0.5874564631240137; validation accuracy : 0.9623430962343096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105:\t train loss : 0.5593307292256456; train accuracy : 0.9920167911025745; \n",
      " validation loss : 0.5949384535881522; validation accuracy : 0.9539748953974896\n",
      "Epoch 106:\t train loss : 0.5571799216973219; train accuracy : 0.9941853836859877; \n",
      " validation loss : 0.5893131155713132; validation accuracy : 0.9581589958158996\n",
      "Epoch 107:\t train loss : 0.5582191912577451; train accuracy : 0.9931165773413055; \n",
      " validation loss : 0.5798930822655968; validation accuracy : 0.9707112970711297\n",
      "Epoch 108:\t train loss : 0.5704149405539147; train accuracy : 0.9806877536478825; \n",
      " validation loss : 0.5941826110597157; validation accuracy : 0.9539748953974896\n",
      "Epoch 109:\t train loss : 0.5636236876196727; train accuracy : 0.987608042380495; \n",
      " validation loss : 0.6051918998409741; validation accuracy : 0.9456066945606695\n",
      "Epoch 110:\t train loss : 0.5587185357161325; train accuracy : 0.9925958053223458; \n",
      " validation loss : 0.604228877175267; validation accuracy : 0.9456066945606695\n",
      "Epoch 111:\t train loss : 0.5591752051531547; train accuracy : 0.9922122742340221; \n",
      " validation loss : 0.6175884312856992; validation accuracy : 0.9330543933054394\n",
      "Epoch 112:\t train loss : 0.5575299038504331; train accuracy : 0.9938600947984758; \n",
      " validation loss : 0.585408546274308; validation accuracy : 0.9623430962343096\n",
      "Epoch 113:\t train loss : 0.5579383973670689; train accuracy : 0.9934108863347687; \n",
      " validation loss : 0.6066262225456606; validation accuracy : 0.9414225941422594\n",
      "Epoch 114:\t train loss : 0.5568501217408292; train accuracy : 0.9945106725734998; \n",
      " validation loss : 0.5978334069719967; validation accuracy : 0.9539748953974896\n",
      "Epoch 115:\t train loss : 0.5576368866665816; train accuracy : 0.9936742154341832; \n",
      " validation loss : 0.5901079776673357; validation accuracy : 0.9581589958158996\n",
      "Epoch 116:\t train loss : 0.5714959386803327; train accuracy : 0.9793187521298677; \n",
      " validation loss : 0.6328358981936506; validation accuracy : 0.9163179916317992\n",
      "Epoch 117:\t train loss : 0.5705157080799257; train accuracy : 0.9804591220298027; \n",
      " validation loss : 0.6251289254108526; validation accuracy : 0.9246861924686193\n",
      "Epoch 118:\t train loss : 0.5573369837443997; train accuracy : 0.9939840143746709; \n",
      " validation loss : 0.5974883122247124; validation accuracy : 0.9497907949790795\n",
      "Early stopping at epoch 118\n",
      "----- Final result of the model ! -----\n",
      "Train loss : 0.5620353566955191; Train accuracy : 0.9891821307971127; \n",
      " Validation loss : 0.5689572005847925; Validation accuracy : 0.9832635983263598\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 273\n",
    "patience = 50\n",
    "models_list = []\n",
    "optimizers = []\n",
    "loss_train_list = []\n",
    "loss_val_list = []\n",
    "acc_train_list = []\n",
    "acc_val_list = []\n",
    "start = time.time()\n",
    "for i in range(len(train_dataset)):\n",
    "    print(\"--- Let's train model {} ! ---\".format(i+1))\n",
    "    model, loss, optimizer, device = createCNN(gpus_list)\n",
    "    path = \"../saved_models/covid_RAW/\"+str(i+1)+\".pckl\"\n",
    "    train_loss, val_loss, train_acc, val_acc = train(device, model, loss, optimizer, train_dataset[i], validation_dataset[i], num_epochs, patience, path, verbose=1)\n",
    "    #modelName = 'Model ' + str(i+1)\n",
    "    #visualizeTrain(modelName, train_loss, val_loss, train_acc, val_acc)\n",
    "    loss_train_list.append(train_loss)\n",
    "    loss_val_list.append(val_loss)\n",
    "    acc_train_list.append(train_acc)\n",
    "    acc_val_list.append(val_acc)\n",
    "    models_list.append(model)\n",
    "    optimizers.append(optimizer)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "funded-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 23.853519005576768\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time :\", (end-start)/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cooked-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Total time of training 23.0 h 51.0 m and 12.66842007637024 s ------------------------------\n"
     ]
    }
   ],
   "source": [
    "hT = (end-start)//3600\n",
    "mT = ((end-start)%3600)//60\n",
    "sT = (((end-start)%3600)%60)\n",
    "print(\"------------------------------ Total time of training {} h {} m and {} s ------------------------------\".format(hT, mT, sT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affiliated-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(models_list)):\n",
    "    #path = \"../saved_models/covid_RAW/\"+str(i)+\".pckl\"\n",
    "    #torch.save({\n",
    "            #'model': models_list[i].state_dict(),\n",
    "            #'optimizer': optimizers[i].state_dict()}, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-romance",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "introductory-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, test_set, device, batch_size=1):\n",
    "    test_acc = []\n",
    "    test_generator = DataLoader(test_set, batch_size=batch_size)\n",
    "    model.eval()\n",
    "    for i, (ramanSpectra, label) in enumerate(test_generator):\n",
    "        ramanSpectra = ramanSpectra.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        labelPredict = model(ramanSpectra)\n",
    "        labelPredict = torch.argmax(labelPredict, dim=1)\n",
    "        \n",
    "        acc = accuracy_score(label.cpu().detach().numpy(), labelPredict.cpu().detach().numpy())\n",
    "        test_acc.append(acc)\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "harmful-mercury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Let's predict with model 1 ! ---\n",
      "--- Let's predict with model 2 ! ---\n",
      "--- Let's predict with model 3 ! ---\n",
      "--- Let's predict with model 4 ! ---\n",
      "--- Let's predict with model 5 ! ---\n",
      "--- Let's predict with model 6 ! ---\n",
      "--- Let's predict with model 7 ! ---\n",
      "--- Let's predict with model 8 ! ---\n",
      "--- Let's predict with model 9 ! ---\n",
      "--- Let's predict with model 10 ! ---\n",
      "--- Let's predict with model 11 ! ---\n",
      "--- Let's predict with model 12 ! ---\n",
      "--- Let's predict with model 13 ! ---\n",
      "--- Let's predict with model 14 ! ---\n",
      "--- Let's predict with model 15 ! ---\n",
      "--- Let's predict with model 16 ! ---\n",
      "--- Let's predict with model 17 ! ---\n",
      "--- Let's predict with model 18 ! ---\n",
      "--- Let's predict with model 19 ! ---\n",
      "--- Let's predict with model 20 ! ---\n",
      "--- Let's predict with model 21 ! ---\n",
      "--- Let's predict with model 22 ! ---\n",
      "--- Let's predict with model 23 ! ---\n",
      "--- Let's predict with model 24 ! ---\n",
      "--- Let's predict with model 25 ! ---\n",
      "--- Let's predict with model 26 ! ---\n",
      "--- Let's predict with model 27 ! ---\n",
      "--- Let's predict with model 28 ! ---\n",
      "--- Let's predict with model 29 ! ---\n",
      "--- Let's predict with model 30 ! ---\n",
      "--- Let's predict with model 31 ! ---\n",
      "--- Let's predict with model 32 ! ---\n",
      "--- Let's predict with model 33 ! ---\n",
      "--- Let's predict with model 34 ! ---\n",
      "--- Let's predict with model 35 ! ---\n",
      "--- Let's predict with model 36 ! ---\n",
      "--- Let's predict with model 37 ! ---\n",
      "--- Let's predict with model 38 ! ---\n",
      "--- Let's predict with model 39 ! ---\n",
      "--- Let's predict with model 40 ! ---\n",
      "--- Let's predict with model 41 ! ---\n",
      "--- Let's predict with model 42 ! ---\n",
      "--- Let's predict with model 43 ! ---\n",
      "--- Let's predict with model 44 ! ---\n",
      "--- Let's predict with model 45 ! ---\n",
      "--- Let's predict with model 46 ! ---\n",
      "--- Let's predict with model 47 ! ---\n",
      "--- Let's predict with model 48 ! ---\n",
      "--- Let's predict with model 49 ! ---\n",
      "--- Let's predict with model 50 ! ---\n",
      "--- Let's predict with model 51 ! ---\n",
      "--- Let's predict with model 52 ! ---\n",
      "--- Let's predict with model 53 ! ---\n",
      "--- Let's predict with model 54 ! ---\n",
      "--- Let's predict with model 55 ! ---\n",
      "--- Let's predict with model 56 ! ---\n",
      "--- Let's predict with model 57 ! ---\n",
      "--- Let's predict with model 58 ! ---\n",
      "--- Let's predict with model 59 ! ---\n",
      "--- Let's predict with model 60 ! ---\n",
      "--- Let's predict with model 61 ! ---\n",
      "--- Let's predict with model 62 ! ---\n",
      "--- Let's predict with model 63 ! ---\n",
      "--- Let's predict with model 64 ! ---\n",
      "--- Let's predict with model 65 ! ---\n",
      "--- Let's predict with model 66 ! ---\n",
      "--- Let's predict with model 67 ! ---\n",
      "--- Let's predict with model 68 ! ---\n",
      "--- Let's predict with model 69 ! ---\n",
      "--- Let's predict with model 70 ! ---\n",
      "--- Let's predict with model 71 ! ---\n",
      "--- Let's predict with model 72 ! ---\n",
      "--- Let's predict with model 73 ! ---\n",
      "--- Let's predict with model 74 ! ---\n",
      "--- Let's predict with model 75 ! ---\n",
      "--- Let's predict with model 76 ! ---\n",
      "--- Let's predict with model 77 ! ---\n",
      "--- Let's predict with model 78 ! ---\n",
      "--- Let's predict with model 79 ! ---\n",
      "--- Let's predict with model 80 ! ---\n",
      "--- Let's predict with model 81 ! ---\n",
      "--- Let's predict with model 82 ! ---\n",
      "--- Let's predict with model 83 ! ---\n",
      "--- Let's predict with model 84 ! ---\n",
      "--- Let's predict with model 85 ! ---\n",
      "--- Let's predict with model 86 ! ---\n",
      "--- Let's predict with model 87 ! ---\n",
      "--- Let's predict with model 88 ! ---\n",
      "--- Let's predict with model 89 ! ---\n",
      "--- Let's predict with model 90 ! ---\n",
      "--- Let's predict with model 91 ! ---\n",
      "--- Let's predict with model 92 ! ---\n",
      "--- Let's predict with model 93 ! ---\n",
      "--- Let's predict with model 94 ! ---\n",
      "--- Let's predict with model 95 ! ---\n",
      "--- Let's predict with model 96 ! ---\n",
      "--- Let's predict with model 97 ! ---\n",
      "--- Let's predict with model 98 ! ---\n",
      "--- Let's predict with model 99 ! ---\n",
      "--- Let's predict with model 100 ! ---\n",
      "--- Let's predict with model 101 ! ---\n",
      "Model 1 predict with 0.9285714285714286 of accuracy\n",
      "Model 2 predict with 1.0 of accuracy\n",
      "Model 3 predict with 1.0 of accuracy\n",
      "Model 4 predict with 1.0 of accuracy\n",
      "Model 5 predict with 1.0 of accuracy\n",
      "Model 6 predict with 0.9 of accuracy\n",
      "Model 7 predict with 1.0 of accuracy\n",
      "Model 8 predict with 0.65 of accuracy\n",
      "Model 9 predict with 1.0 of accuracy\n",
      "Model 10 predict with 0.96 of accuracy\n",
      "Model 11 predict with 0.55 of accuracy\n",
      "Model 12 predict with 1.0 of accuracy\n",
      "Model 13 predict with 1.0 of accuracy\n",
      "Model 14 predict with 1.0 of accuracy\n",
      "Model 15 predict with 0.96 of accuracy\n",
      "Model 16 predict with 1.0 of accuracy\n",
      "Model 17 predict with 0.92 of accuracy\n",
      "Model 18 predict with 0.8 of accuracy\n",
      "Model 19 predict with 0.92 of accuracy\n",
      "Model 20 predict with 1.0 of accuracy\n",
      "Model 21 predict with 1.0 of accuracy\n",
      "Model 22 predict with 0.2 of accuracy\n",
      "Model 23 predict with 1.0 of accuracy\n",
      "Model 24 predict with 0.92 of accuracy\n",
      "Model 25 predict with 0.92 of accuracy\n",
      "Model 26 predict with 0.6 of accuracy\n",
      "Model 27 predict with 0.04 of accuracy\n",
      "Model 28 predict with 0.04 of accuracy\n",
      "Model 29 predict with 0.88 of accuracy\n",
      "Model 30 predict with 0.9565217391304348 of accuracy\n",
      "Model 31 predict with 0.8260869565217391 of accuracy\n",
      "Model 32 predict with 0.9285714285714286 of accuracy\n",
      "Model 33 predict with 1.0 of accuracy\n",
      "Model 34 predict with 0.84 of accuracy\n",
      "Model 35 predict with 1.0 of accuracy\n",
      "Model 36 predict with 1.0 of accuracy\n",
      "Model 37 predict with 1.0 of accuracy\n",
      "Model 38 predict with 1.0 of accuracy\n",
      "Model 39 predict with 1.0 of accuracy\n",
      "Model 40 predict with 1.0 of accuracy\n",
      "Model 41 predict with 1.0 of accuracy\n",
      "Model 42 predict with 1.0 of accuracy\n",
      "Model 43 predict with 1.0 of accuracy\n",
      "Model 44 predict with 0.9565217391304348 of accuracy\n",
      "Model 45 predict with 0.92 of accuracy\n",
      "Model 46 predict with 0.8 of accuracy\n",
      "Model 47 predict with 0.9411764705882353 of accuracy\n",
      "Model 48 predict with 0.96 of accuracy\n",
      "Model 49 predict with 0.8 of accuracy\n",
      "Model 50 predict with 1.0 of accuracy\n",
      "Model 51 predict with 0.56 of accuracy\n",
      "Model 52 predict with 0.05555555555555555 of accuracy\n",
      "Model 53 predict with 0.96 of accuracy\n",
      "Model 54 predict with 1.0 of accuracy\n",
      "Model 55 predict with 1.0 of accuracy\n",
      "Model 56 predict with 1.0 of accuracy\n",
      "Model 57 predict with 0.9 of accuracy\n",
      "Model 58 predict with 1.0 of accuracy\n",
      "Model 59 predict with 1.0 of accuracy\n",
      "Model 60 predict with 0.75 of accuracy\n",
      "Model 61 predict with 1.0 of accuracy\n",
      "Model 62 predict with 1.0 of accuracy\n",
      "Model 63 predict with 0.1 of accuracy\n",
      "Model 64 predict with 1.0 of accuracy\n",
      "Model 65 predict with 1.0 of accuracy\n",
      "Model 66 predict with 0.88 of accuracy\n",
      "Model 67 predict with 0.72 of accuracy\n",
      "Model 68 predict with 1.0 of accuracy\n",
      "Model 69 predict with 0.88 of accuracy\n",
      "Model 70 predict with 1.0 of accuracy\n",
      "Model 71 predict with 1.0 of accuracy\n",
      "Model 72 predict with 0.72 of accuracy\n",
      "Model 73 predict with 0.0 of accuracy\n",
      "Model 74 predict with 0.125 of accuracy\n",
      "Model 75 predict with 0.75 of accuracy\n",
      "Model 76 predict with 0.96 of accuracy\n",
      "Model 77 predict with 0.76 of accuracy\n",
      "Model 78 predict with 1.0 of accuracy\n",
      "Model 79 predict with 0.92 of accuracy\n",
      "Model 80 predict with 1.0 of accuracy\n",
      "Model 81 predict with 1.0 of accuracy\n",
      "Model 82 predict with 0.48 of accuracy\n",
      "Model 83 predict with 0.68 of accuracy\n",
      "Model 84 predict with 0.96 of accuracy\n",
      "Model 85 predict with 0.28 of accuracy\n",
      "Model 86 predict with 1.0 of accuracy\n",
      "Model 87 predict with 1.0 of accuracy\n",
      "Model 88 predict with 1.0 of accuracy\n",
      "Model 89 predict with 1.0 of accuracy\n",
      "Model 90 predict with 0.72 of accuracy\n",
      "Model 91 predict with 1.0 of accuracy\n",
      "Model 92 predict with 1.0 of accuracy\n",
      "Model 93 predict with 1.0 of accuracy\n",
      "Model 94 predict with 0.6 of accuracy\n",
      "Model 95 predict with 1.0 of accuracy\n",
      "Model 96 predict with 0.92 of accuracy\n",
      "Model 97 predict with 0.88 of accuracy\n",
      "Model 98 predict with 0.28 of accuracy\n",
      "Model 99 predict with 0.88 of accuracy\n",
      "Model 100 predict with 0.041666666666666664 of accuracy\n",
      "Model 101 predict with 0.12 of accuracy\n"
     ]
    }
   ],
   "source": [
    "test_accs = []\n",
    "for i in range(len(test_dataset)):\n",
    "    print(\"--- Let's predict with model {} ! ---\".format(i+1))\n",
    "    acc = testModel(models_list[i], test_dataset[i], device)\n",
    "    test_accs.append(acc)\n",
    "\n",
    "for i in range(len(test_accs)):\n",
    "    print(\"Model {} predict with {} of accuracy\".format(i+1, mean(test_accs[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hawaiian-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy is 0.8316799206409498\n"
     ]
    }
   ],
   "source": [
    "total_acc = 0\n",
    "for i in range(len(test_accs)):\n",
    "    total_acc += mean(test_accs[i])\n",
    "print(\"The mean accuracy is {}\".format(total_acc/len(test_accs))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
